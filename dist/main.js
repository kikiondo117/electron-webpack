/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/@mongodb-js/saslprep/dist/code-points-data.js":
/*!********************************************************************!*\
  !*** ./node_modules/@mongodb-js/saslprep/dist/code-points-data.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nconst zlib_1 = __webpack_require__(/*! zlib */ \"zlib\");\nexports[\"default\"] = (0, zlib_1.gunzipSync)(Buffer.from('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', 'base64'));\n//# sourceMappingURL=code-points-data.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/@mongodb-js/saslprep/dist/code-points-data.js?");

/***/ }),

/***/ "./node_modules/@mongodb-js/saslprep/dist/index.js":
/*!*********************************************************!*\
  !*** ./node_modules/@mongodb-js/saslprep/dist/index.js ***!
  \*********************************************************/
/***/ ((module) => {

"use strict";
eval("\nconst getCodePoint = (character) => character.codePointAt(0);\nconst first = (x) => x[0];\nconst last = (x) => x[x.length - 1];\nfunction toCodePoints(input) {\n    const codepoints = [];\n    const size = input.length;\n    for (let i = 0; i < size; i += 1) {\n        const before = input.charCodeAt(i);\n        if (before >= 0xd800 && before <= 0xdbff && size > i + 1) {\n            const next = input.charCodeAt(i + 1);\n            if (next >= 0xdc00 && next <= 0xdfff) {\n                codepoints.push((before - 0xd800) * 0x400 + next - 0xdc00 + 0x10000);\n                i += 1;\n                continue;\n            }\n        }\n        codepoints.push(before);\n    }\n    return codepoints;\n}\nfunction saslprep({ unassigned_code_points, commonly_mapped_to_nothing, non_ASCII_space_characters, prohibited_characters, bidirectional_r_al, bidirectional_l, }, input, opts = {}) {\n    const mapping2space = non_ASCII_space_characters;\n    const mapping2nothing = commonly_mapped_to_nothing;\n    if (typeof input !== 'string') {\n        throw new TypeError('Expected string.');\n    }\n    if (input.length === 0) {\n        return '';\n    }\n    const mapped_input = toCodePoints(input)\n        .map((character) => (mapping2space.get(character) ? 0x20 : character))\n        .filter((character) => !mapping2nothing.get(character));\n    const normalized_input = String.fromCodePoint\n        .apply(null, mapped_input)\n        .normalize('NFKC');\n    const normalized_map = toCodePoints(normalized_input);\n    const hasProhibited = normalized_map.some((character) => prohibited_characters.get(character));\n    if (hasProhibited) {\n        throw new Error('Prohibited character, see https://tools.ietf.org/html/rfc4013#section-2.3');\n    }\n    if (opts.allowUnassigned !== true) {\n        const hasUnassigned = normalized_map.some((character) => unassigned_code_points.get(character));\n        if (hasUnassigned) {\n            throw new Error('Unassigned code point, see https://tools.ietf.org/html/rfc4013#section-2.5');\n        }\n    }\n    const hasBidiRAL = normalized_map.some((character) => bidirectional_r_al.get(character));\n    const hasBidiL = normalized_map.some((character) => bidirectional_l.get(character));\n    if (hasBidiRAL && hasBidiL) {\n        throw new Error('String must not contain RandALCat and LCat at the same time,' +\n            ' see https://tools.ietf.org/html/rfc3454#section-6');\n    }\n    const isFirstBidiRAL = bidirectional_r_al.get(getCodePoint(first(normalized_input)));\n    const isLastBidiRAL = bidirectional_r_al.get(getCodePoint(last(normalized_input)));\n    if (hasBidiRAL && !(isFirstBidiRAL && isLastBidiRAL)) {\n        throw new Error('Bidirectional RandALCat character must be the first and the last' +\n            ' character of the string, see https://tools.ietf.org/html/rfc3454#section-6');\n    }\n    return normalized_input;\n}\nsaslprep.saslprep = saslprep;\nsaslprep.default = saslprep;\nmodule.exports = saslprep;\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/@mongodb-js/saslprep/dist/index.js?");

/***/ }),

/***/ "./node_modules/@mongodb-js/saslprep/dist/memory-code-points.js":
/*!**********************************************************************!*\
  !*** ./node_modules/@mongodb-js/saslprep/dist/memory-code-points.js ***!
  \**********************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.createMemoryCodePoints = void 0;\nconst sparse_bitfield_1 = __importDefault(__webpack_require__(/*! sparse-bitfield */ \"./node_modules/sparse-bitfield/index.js\"));\nfunction createMemoryCodePoints(data) {\n    let offset = 0;\n    function read() {\n        const size = data.readUInt32BE(offset);\n        offset += 4;\n        const codepoints = data.slice(offset, offset + size);\n        offset += size;\n        return (0, sparse_bitfield_1.default)({ buffer: codepoints });\n    }\n    const unassigned_code_points = read();\n    const commonly_mapped_to_nothing = read();\n    const non_ASCII_space_characters = read();\n    const prohibited_characters = read();\n    const bidirectional_r_al = read();\n    const bidirectional_l = read();\n    return {\n        unassigned_code_points,\n        commonly_mapped_to_nothing,\n        non_ASCII_space_characters,\n        prohibited_characters,\n        bidirectional_r_al,\n        bidirectional_l,\n    };\n}\nexports.createMemoryCodePoints = createMemoryCodePoints;\n//# sourceMappingURL=memory-code-points.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/@mongodb-js/saslprep/dist/memory-code-points.js?");

/***/ }),

/***/ "./node_modules/@mongodb-js/saslprep/dist/node.js":
/*!********************************************************!*\
  !*** ./node_modules/@mongodb-js/saslprep/dist/node.js ***!
  \********************************************************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

"use strict";
eval("\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nconst index_1 = __importDefault(__webpack_require__(/*! ./index */ \"./node_modules/@mongodb-js/saslprep/dist/index.js\"));\nconst memory_code_points_1 = __webpack_require__(/*! ./memory-code-points */ \"./node_modules/@mongodb-js/saslprep/dist/memory-code-points.js\");\nconst code_points_data_1 = __importDefault(__webpack_require__(/*! ./code-points-data */ \"./node_modules/@mongodb-js/saslprep/dist/code-points-data.js\"));\nconst codePoints = (0, memory_code_points_1.createMemoryCodePoints)(code_points_data_1.default);\nfunction saslprep(input, opts) {\n    return (0, index_1.default)(codePoints, input, opts);\n}\nsaslprep.saslprep = saslprep;\nsaslprep.default = saslprep;\nmodule.exports = saslprep;\n//# sourceMappingURL=node.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/@mongodb-js/saslprep/dist/node.js?");

/***/ }),

/***/ "./node_modules/debug/src/browser.js":
/*!*******************************************!*\
  !*** ./node_modules/debug/src/browser.js ***!
  \*******************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("/* eslint-env browser */\n\n/**\n * This is the web browser implementation of `debug()`.\n */\n\nexports.formatArgs = formatArgs;\nexports.save = save;\nexports.load = load;\nexports.useColors = useColors;\nexports.storage = localstorage();\nexports.destroy = (() => {\n\tlet warned = false;\n\n\treturn () => {\n\t\tif (!warned) {\n\t\t\twarned = true;\n\t\t\tconsole.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');\n\t\t}\n\t};\n})();\n\n/**\n * Colors.\n */\n\nexports.colors = [\n\t'#0000CC',\n\t'#0000FF',\n\t'#0033CC',\n\t'#0033FF',\n\t'#0066CC',\n\t'#0066FF',\n\t'#0099CC',\n\t'#0099FF',\n\t'#00CC00',\n\t'#00CC33',\n\t'#00CC66',\n\t'#00CC99',\n\t'#00CCCC',\n\t'#00CCFF',\n\t'#3300CC',\n\t'#3300FF',\n\t'#3333CC',\n\t'#3333FF',\n\t'#3366CC',\n\t'#3366FF',\n\t'#3399CC',\n\t'#3399FF',\n\t'#33CC00',\n\t'#33CC33',\n\t'#33CC66',\n\t'#33CC99',\n\t'#33CCCC',\n\t'#33CCFF',\n\t'#6600CC',\n\t'#6600FF',\n\t'#6633CC',\n\t'#6633FF',\n\t'#66CC00',\n\t'#66CC33',\n\t'#9900CC',\n\t'#9900FF',\n\t'#9933CC',\n\t'#9933FF',\n\t'#99CC00',\n\t'#99CC33',\n\t'#CC0000',\n\t'#CC0033',\n\t'#CC0066',\n\t'#CC0099',\n\t'#CC00CC',\n\t'#CC00FF',\n\t'#CC3300',\n\t'#CC3333',\n\t'#CC3366',\n\t'#CC3399',\n\t'#CC33CC',\n\t'#CC33FF',\n\t'#CC6600',\n\t'#CC6633',\n\t'#CC9900',\n\t'#CC9933',\n\t'#CCCC00',\n\t'#CCCC33',\n\t'#FF0000',\n\t'#FF0033',\n\t'#FF0066',\n\t'#FF0099',\n\t'#FF00CC',\n\t'#FF00FF',\n\t'#FF3300',\n\t'#FF3333',\n\t'#FF3366',\n\t'#FF3399',\n\t'#FF33CC',\n\t'#FF33FF',\n\t'#FF6600',\n\t'#FF6633',\n\t'#FF9900',\n\t'#FF9933',\n\t'#FFCC00',\n\t'#FFCC33'\n];\n\n/**\n * Currently only WebKit-based Web Inspectors, Firefox >= v31,\n * and the Firebug extension (any Firefox version) are known\n * to support \"%c\" CSS customizations.\n *\n * TODO: add a `localStorage` variable to explicitly enable/disable colors\n */\n\n// eslint-disable-next-line complexity\nfunction useColors() {\n\t// NB: In an Electron preload script, document will be defined but not fully\n\t// initialized. Since we know we're in Chrome, we'll just detect this case\n\t// explicitly\n\tif (typeof window !== 'undefined' && window.process && (window.process.type === 'renderer' || window.process.__nwjs)) {\n\t\treturn true;\n\t}\n\n\t// Internet Explorer and Edge do not support colors.\n\tif (typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/(edge|trident)\\/(\\d+)/)) {\n\t\treturn false;\n\t}\n\n\tlet m;\n\n\t// Is webkit? http://stackoverflow.com/a/16459606/376773\n\t// document is undefined in react-native: https://github.com/facebook/react-native/pull/1632\n\treturn (typeof document !== 'undefined' && document.documentElement && document.documentElement.style && document.documentElement.style.WebkitAppearance) ||\n\t\t// Is firebug? http://stackoverflow.com/a/398120/376773\n\t\t(typeof window !== 'undefined' && window.console && (window.console.firebug || (window.console.exception && window.console.table))) ||\n\t\t// Is firefox >= v31?\n\t\t// https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages\n\t\t(typeof navigator !== 'undefined' && navigator.userAgent && (m = navigator.userAgent.toLowerCase().match(/firefox\\/(\\d+)/)) && parseInt(m[1], 10) >= 31) ||\n\t\t// Double check webkit in userAgent just in case we are in a worker\n\t\t(typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\\/(\\d+)/));\n}\n\n/**\n * Colorize log arguments if enabled.\n *\n * @api public\n */\n\nfunction formatArgs(args) {\n\targs[0] = (this.useColors ? '%c' : '') +\n\t\tthis.namespace +\n\t\t(this.useColors ? ' %c' : ' ') +\n\t\targs[0] +\n\t\t(this.useColors ? '%c ' : ' ') +\n\t\t'+' + module.exports.humanize(this.diff);\n\n\tif (!this.useColors) {\n\t\treturn;\n\t}\n\n\tconst c = 'color: ' + this.color;\n\targs.splice(1, 0, c, 'color: inherit');\n\n\t// The final \"%c\" is somewhat tricky, because there could be other\n\t// arguments passed either before or after the %c, so we need to\n\t// figure out the correct index to insert the CSS into\n\tlet index = 0;\n\tlet lastC = 0;\n\targs[0].replace(/%[a-zA-Z%]/g, match => {\n\t\tif (match === '%%') {\n\t\t\treturn;\n\t\t}\n\t\tindex++;\n\t\tif (match === '%c') {\n\t\t\t// We only are interested in the *last* %c\n\t\t\t// (the user may have provided their own)\n\t\t\tlastC = index;\n\t\t}\n\t});\n\n\targs.splice(lastC, 0, c);\n}\n\n/**\n * Invokes `console.debug()` when available.\n * No-op when `console.debug` is not a \"function\".\n * If `console.debug` is not available, falls back\n * to `console.log`.\n *\n * @api public\n */\nexports.log = console.debug || console.log || (() => {});\n\n/**\n * Save `namespaces`.\n *\n * @param {String} namespaces\n * @api private\n */\nfunction save(namespaces) {\n\ttry {\n\t\tif (namespaces) {\n\t\t\texports.storage.setItem('debug', namespaces);\n\t\t} else {\n\t\t\texports.storage.removeItem('debug');\n\t\t}\n\t} catch (error) {\n\t\t// Swallow\n\t\t// XXX (@Qix-) should we be logging these?\n\t}\n}\n\n/**\n * Load `namespaces`.\n *\n * @return {String} returns the previously persisted debug modes\n * @api private\n */\nfunction load() {\n\tlet r;\n\ttry {\n\t\tr = exports.storage.getItem('debug');\n\t} catch (error) {\n\t\t// Swallow\n\t\t// XXX (@Qix-) should we be logging these?\n\t}\n\n\t// If debug isn't set in LS, and we're in Electron, try to load $DEBUG\n\tif (!r && typeof process !== 'undefined' && 'env' in process) {\n\t\tr = process.env.DEBUG;\n\t}\n\n\treturn r;\n}\n\n/**\n * Localstorage attempts to return the localstorage.\n *\n * This is necessary because safari throws\n * when a user disables cookies/localstorage\n * and you attempt to access it.\n *\n * @return {LocalStorage}\n * @api private\n */\n\nfunction localstorage() {\n\ttry {\n\t\t// TVMLKit (Apple TV JS Runtime) does not have a window object, just localStorage in the global context\n\t\t// The Browser also has localStorage in the global context.\n\t\treturn localStorage;\n\t} catch (error) {\n\t\t// Swallow\n\t\t// XXX (@Qix-) should we be logging these?\n\t}\n}\n\nmodule.exports = __webpack_require__(/*! ./common */ \"./node_modules/debug/src/common.js\")(exports);\n\nconst {formatters} = module.exports;\n\n/**\n * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.\n */\n\nformatters.j = function (v) {\n\ttry {\n\t\treturn JSON.stringify(v);\n\t} catch (error) {\n\t\treturn '[UnexpectedJSONParseError]: ' + error.message;\n\t}\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/debug/src/browser.js?");

/***/ }),

/***/ "./node_modules/debug/src/common.js":
/*!******************************************!*\
  !*** ./node_modules/debug/src/common.js ***!
  \******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("\n/**\n * This is the common logic for both the Node.js and web browser\n * implementations of `debug()`.\n */\n\nfunction setup(env) {\n\tcreateDebug.debug = createDebug;\n\tcreateDebug.default = createDebug;\n\tcreateDebug.coerce = coerce;\n\tcreateDebug.disable = disable;\n\tcreateDebug.enable = enable;\n\tcreateDebug.enabled = enabled;\n\tcreateDebug.humanize = __webpack_require__(/*! ms */ \"./node_modules/ms/index.js\");\n\tcreateDebug.destroy = destroy;\n\n\tObject.keys(env).forEach(key => {\n\t\tcreateDebug[key] = env[key];\n\t});\n\n\t/**\n\t* The currently active debug mode names, and names to skip.\n\t*/\n\n\tcreateDebug.names = [];\n\tcreateDebug.skips = [];\n\n\t/**\n\t* Map of special \"%n\" handling functions, for the debug \"format\" argument.\n\t*\n\t* Valid key names are a single, lower or upper-case letter, i.e. \"n\" and \"N\".\n\t*/\n\tcreateDebug.formatters = {};\n\n\t/**\n\t* Selects a color for a debug namespace\n\t* @param {String} namespace The namespace string for the debug instance to be colored\n\t* @return {Number|String} An ANSI color code for the given namespace\n\t* @api private\n\t*/\n\tfunction selectColor(namespace) {\n\t\tlet hash = 0;\n\n\t\tfor (let i = 0; i < namespace.length; i++) {\n\t\t\thash = ((hash << 5) - hash) + namespace.charCodeAt(i);\n\t\t\thash |= 0; // Convert to 32bit integer\n\t\t}\n\n\t\treturn createDebug.colors[Math.abs(hash) % createDebug.colors.length];\n\t}\n\tcreateDebug.selectColor = selectColor;\n\n\t/**\n\t* Create a debugger with the given `namespace`.\n\t*\n\t* @param {String} namespace\n\t* @return {Function}\n\t* @api public\n\t*/\n\tfunction createDebug(namespace) {\n\t\tlet prevTime;\n\t\tlet enableOverride = null;\n\t\tlet namespacesCache;\n\t\tlet enabledCache;\n\n\t\tfunction debug(...args) {\n\t\t\t// Disabled?\n\t\t\tif (!debug.enabled) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tconst self = debug;\n\n\t\t\t// Set `diff` timestamp\n\t\t\tconst curr = Number(new Date());\n\t\t\tconst ms = curr - (prevTime || curr);\n\t\t\tself.diff = ms;\n\t\t\tself.prev = prevTime;\n\t\t\tself.curr = curr;\n\t\t\tprevTime = curr;\n\n\t\t\targs[0] = createDebug.coerce(args[0]);\n\n\t\t\tif (typeof args[0] !== 'string') {\n\t\t\t\t// Anything else let's inspect with %O\n\t\t\t\targs.unshift('%O');\n\t\t\t}\n\n\t\t\t// Apply any `formatters` transformations\n\t\t\tlet index = 0;\n\t\t\targs[0] = args[0].replace(/%([a-zA-Z%])/g, (match, format) => {\n\t\t\t\t// If we encounter an escaped % then don't increase the array index\n\t\t\t\tif (match === '%%') {\n\t\t\t\t\treturn '%';\n\t\t\t\t}\n\t\t\t\tindex++;\n\t\t\t\tconst formatter = createDebug.formatters[format];\n\t\t\t\tif (typeof formatter === 'function') {\n\t\t\t\t\tconst val = args[index];\n\t\t\t\t\tmatch = formatter.call(self, val);\n\n\t\t\t\t\t// Now we need to remove `args[index]` since it's inlined in the `format`\n\t\t\t\t\targs.splice(index, 1);\n\t\t\t\t\tindex--;\n\t\t\t\t}\n\t\t\t\treturn match;\n\t\t\t});\n\n\t\t\t// Apply env-specific formatting (colors, etc.)\n\t\t\tcreateDebug.formatArgs.call(self, args);\n\n\t\t\tconst logFn = self.log || createDebug.log;\n\t\t\tlogFn.apply(self, args);\n\t\t}\n\n\t\tdebug.namespace = namespace;\n\t\tdebug.useColors = createDebug.useColors();\n\t\tdebug.color = createDebug.selectColor(namespace);\n\t\tdebug.extend = extend;\n\t\tdebug.destroy = createDebug.destroy; // XXX Temporary. Will be removed in the next major release.\n\n\t\tObject.defineProperty(debug, 'enabled', {\n\t\t\tenumerable: true,\n\t\t\tconfigurable: false,\n\t\t\tget: () => {\n\t\t\t\tif (enableOverride !== null) {\n\t\t\t\t\treturn enableOverride;\n\t\t\t\t}\n\t\t\t\tif (namespacesCache !== createDebug.namespaces) {\n\t\t\t\t\tnamespacesCache = createDebug.namespaces;\n\t\t\t\t\tenabledCache = createDebug.enabled(namespace);\n\t\t\t\t}\n\n\t\t\t\treturn enabledCache;\n\t\t\t},\n\t\t\tset: v => {\n\t\t\t\tenableOverride = v;\n\t\t\t}\n\t\t});\n\n\t\t// Env-specific initialization logic for debug instances\n\t\tif (typeof createDebug.init === 'function') {\n\t\t\tcreateDebug.init(debug);\n\t\t}\n\n\t\treturn debug;\n\t}\n\n\tfunction extend(namespace, delimiter) {\n\t\tconst newDebug = createDebug(this.namespace + (typeof delimiter === 'undefined' ? ':' : delimiter) + namespace);\n\t\tnewDebug.log = this.log;\n\t\treturn newDebug;\n\t}\n\n\t/**\n\t* Enables a debug mode by namespaces. This can include modes\n\t* separated by a colon and wildcards.\n\t*\n\t* @param {String} namespaces\n\t* @api public\n\t*/\n\tfunction enable(namespaces) {\n\t\tcreateDebug.save(namespaces);\n\t\tcreateDebug.namespaces = namespaces;\n\n\t\tcreateDebug.names = [];\n\t\tcreateDebug.skips = [];\n\n\t\tlet i;\n\t\tconst split = (typeof namespaces === 'string' ? namespaces : '').split(/[\\s,]+/);\n\t\tconst len = split.length;\n\n\t\tfor (i = 0; i < len; i++) {\n\t\t\tif (!split[i]) {\n\t\t\t\t// ignore empty strings\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tnamespaces = split[i].replace(/\\*/g, '.*?');\n\n\t\t\tif (namespaces[0] === '-') {\n\t\t\t\tcreateDebug.skips.push(new RegExp('^' + namespaces.slice(1) + '$'));\n\t\t\t} else {\n\t\t\t\tcreateDebug.names.push(new RegExp('^' + namespaces + '$'));\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t* Disable debug output.\n\t*\n\t* @return {String} namespaces\n\t* @api public\n\t*/\n\tfunction disable() {\n\t\tconst namespaces = [\n\t\t\t...createDebug.names.map(toNamespace),\n\t\t\t...createDebug.skips.map(toNamespace).map(namespace => '-' + namespace)\n\t\t].join(',');\n\t\tcreateDebug.enable('');\n\t\treturn namespaces;\n\t}\n\n\t/**\n\t* Returns true if the given mode name is enabled, false otherwise.\n\t*\n\t* @param {String} name\n\t* @return {Boolean}\n\t* @api public\n\t*/\n\tfunction enabled(name) {\n\t\tif (name[name.length - 1] === '*') {\n\t\t\treturn true;\n\t\t}\n\n\t\tlet i;\n\t\tlet len;\n\n\t\tfor (i = 0, len = createDebug.skips.length; i < len; i++) {\n\t\t\tif (createDebug.skips[i].test(name)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\n\t\tfor (i = 0, len = createDebug.names.length; i < len; i++) {\n\t\t\tif (createDebug.names[i].test(name)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\n\t\treturn false;\n\t}\n\n\t/**\n\t* Convert regexp to namespace\n\t*\n\t* @param {RegExp} regxep\n\t* @return {String} namespace\n\t* @api private\n\t*/\n\tfunction toNamespace(regexp) {\n\t\treturn regexp.toString()\n\t\t\t.substring(2, regexp.toString().length - 2)\n\t\t\t.replace(/\\.\\*\\?$/, '*');\n\t}\n\n\t/**\n\t* Coerce `val`.\n\t*\n\t* @param {Mixed} val\n\t* @return {Mixed}\n\t* @api private\n\t*/\n\tfunction coerce(val) {\n\t\tif (val instanceof Error) {\n\t\t\treturn val.stack || val.message;\n\t\t}\n\t\treturn val;\n\t}\n\n\t/**\n\t* XXX DO NOT USE. This is a temporary stub function.\n\t* XXX It WILL be removed in the next major release.\n\t*/\n\tfunction destroy() {\n\t\tconsole.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');\n\t}\n\n\tcreateDebug.enable(createDebug.load());\n\n\treturn createDebug;\n}\n\nmodule.exports = setup;\n\n\n//# sourceURL=webpack://experimento/./node_modules/debug/src/common.js?");

/***/ }),

/***/ "./node_modules/debug/src/index.js":
/*!*****************************************!*\
  !*** ./node_modules/debug/src/index.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/**\n * Detect Electron renderer / nwjs process, which is node, but we should\n * treat as a browser.\n */\n\nif (typeof process === 'undefined' || process.type === 'renderer' || process.browser === true || process.__nwjs) {\n\tmodule.exports = __webpack_require__(/*! ./browser.js */ \"./node_modules/debug/src/browser.js\");\n} else {\n\tmodule.exports = __webpack_require__(/*! ./node.js */ \"./node_modules/debug/src/node.js\");\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/debug/src/index.js?");

/***/ }),

/***/ "./node_modules/debug/src/node.js":
/*!****************************************!*\
  !*** ./node_modules/debug/src/node.js ***!
  \****************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("/**\n * Module dependencies.\n */\n\nconst tty = __webpack_require__(/*! tty */ \"tty\");\nconst util = __webpack_require__(/*! util */ \"util\");\n\n/**\n * This is the Node.js implementation of `debug()`.\n */\n\nexports.init = init;\nexports.log = log;\nexports.formatArgs = formatArgs;\nexports.save = save;\nexports.load = load;\nexports.useColors = useColors;\nexports.destroy = util.deprecate(\n\t() => {},\n\t'Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.'\n);\n\n/**\n * Colors.\n */\n\nexports.colors = [6, 2, 3, 4, 5, 1];\n\ntry {\n\t// Optional dependency (as in, doesn't need to be installed, NOT like optionalDependencies in package.json)\n\t// eslint-disable-next-line import/no-extraneous-dependencies\n\tconst supportsColor = __webpack_require__(/*! supports-color */ \"./node_modules/supports-color/index.js\");\n\n\tif (supportsColor && (supportsColor.stderr || supportsColor).level >= 2) {\n\t\texports.colors = [\n\t\t\t20,\n\t\t\t21,\n\t\t\t26,\n\t\t\t27,\n\t\t\t32,\n\t\t\t33,\n\t\t\t38,\n\t\t\t39,\n\t\t\t40,\n\t\t\t41,\n\t\t\t42,\n\t\t\t43,\n\t\t\t44,\n\t\t\t45,\n\t\t\t56,\n\t\t\t57,\n\t\t\t62,\n\t\t\t63,\n\t\t\t68,\n\t\t\t69,\n\t\t\t74,\n\t\t\t75,\n\t\t\t76,\n\t\t\t77,\n\t\t\t78,\n\t\t\t79,\n\t\t\t80,\n\t\t\t81,\n\t\t\t92,\n\t\t\t93,\n\t\t\t98,\n\t\t\t99,\n\t\t\t112,\n\t\t\t113,\n\t\t\t128,\n\t\t\t129,\n\t\t\t134,\n\t\t\t135,\n\t\t\t148,\n\t\t\t149,\n\t\t\t160,\n\t\t\t161,\n\t\t\t162,\n\t\t\t163,\n\t\t\t164,\n\t\t\t165,\n\t\t\t166,\n\t\t\t167,\n\t\t\t168,\n\t\t\t169,\n\t\t\t170,\n\t\t\t171,\n\t\t\t172,\n\t\t\t173,\n\t\t\t178,\n\t\t\t179,\n\t\t\t184,\n\t\t\t185,\n\t\t\t196,\n\t\t\t197,\n\t\t\t198,\n\t\t\t199,\n\t\t\t200,\n\t\t\t201,\n\t\t\t202,\n\t\t\t203,\n\t\t\t204,\n\t\t\t205,\n\t\t\t206,\n\t\t\t207,\n\t\t\t208,\n\t\t\t209,\n\t\t\t214,\n\t\t\t215,\n\t\t\t220,\n\t\t\t221\n\t\t];\n\t}\n} catch (error) {\n\t// Swallow - we only care if `supports-color` is available; it doesn't have to be.\n}\n\n/**\n * Build up the default `inspectOpts` object from the environment variables.\n *\n *   $ DEBUG_COLORS=no DEBUG_DEPTH=10 DEBUG_SHOW_HIDDEN=enabled node script.js\n */\n\nexports.inspectOpts = Object.keys(process.env).filter(key => {\n\treturn /^debug_/i.test(key);\n}).reduce((obj, key) => {\n\t// Camel-case\n\tconst prop = key\n\t\t.substring(6)\n\t\t.toLowerCase()\n\t\t.replace(/_([a-z])/g, (_, k) => {\n\t\t\treturn k.toUpperCase();\n\t\t});\n\n\t// Coerce string value into JS value\n\tlet val = process.env[key];\n\tif (/^(yes|on|true|enabled)$/i.test(val)) {\n\t\tval = true;\n\t} else if (/^(no|off|false|disabled)$/i.test(val)) {\n\t\tval = false;\n\t} else if (val === 'null') {\n\t\tval = null;\n\t} else {\n\t\tval = Number(val);\n\t}\n\n\tobj[prop] = val;\n\treturn obj;\n}, {});\n\n/**\n * Is stdout a TTY? Colored output is enabled when `true`.\n */\n\nfunction useColors() {\n\treturn 'colors' in exports.inspectOpts ?\n\t\tBoolean(exports.inspectOpts.colors) :\n\t\ttty.isatty(process.stderr.fd);\n}\n\n/**\n * Adds ANSI color escape codes if enabled.\n *\n * @api public\n */\n\nfunction formatArgs(args) {\n\tconst {namespace: name, useColors} = this;\n\n\tif (useColors) {\n\t\tconst c = this.color;\n\t\tconst colorCode = '\\u001B[3' + (c < 8 ? c : '8;5;' + c);\n\t\tconst prefix = `  ${colorCode};1m${name} \\u001B[0m`;\n\n\t\targs[0] = prefix + args[0].split('\\n').join('\\n' + prefix);\n\t\targs.push(colorCode + 'm+' + module.exports.humanize(this.diff) + '\\u001B[0m');\n\t} else {\n\t\targs[0] = getDate() + name + ' ' + args[0];\n\t}\n}\n\nfunction getDate() {\n\tif (exports.inspectOpts.hideDate) {\n\t\treturn '';\n\t}\n\treturn new Date().toISOString() + ' ';\n}\n\n/**\n * Invokes `util.formatWithOptions()` with the specified arguments and writes to stderr.\n */\n\nfunction log(...args) {\n\treturn process.stderr.write(util.formatWithOptions(exports.inspectOpts, ...args) + '\\n');\n}\n\n/**\n * Save `namespaces`.\n *\n * @param {String} namespaces\n * @api private\n */\nfunction save(namespaces) {\n\tif (namespaces) {\n\t\tprocess.env.DEBUG = namespaces;\n\t} else {\n\t\t// If you set a process.env field to null or undefined, it gets cast to the\n\t\t// string 'null' or 'undefined'. Just delete instead.\n\t\tdelete process.env.DEBUG;\n\t}\n}\n\n/**\n * Load `namespaces`.\n *\n * @return {String} returns the previously persisted debug modes\n * @api private\n */\n\nfunction load() {\n\treturn process.env.DEBUG;\n}\n\n/**\n * Init logic for `debug` instances.\n *\n * Create a new `inspectOpts` object in case `useColors` is set\n * differently for a particular `debug` instance.\n */\n\nfunction init(debug) {\n\tdebug.inspectOpts = {};\n\n\tconst keys = Object.keys(exports.inspectOpts);\n\tfor (let i = 0; i < keys.length; i++) {\n\t\tdebug.inspectOpts[keys[i]] = exports.inspectOpts[keys[i]];\n\t}\n}\n\nmodule.exports = __webpack_require__(/*! ./common */ \"./node_modules/debug/src/common.js\")(exports);\n\nconst {formatters} = module.exports;\n\n/**\n * Map %o to `util.inspect()`, all on a single line.\n */\n\nformatters.o = function (v) {\n\tthis.inspectOpts.colors = this.useColors;\n\treturn util.inspect(v, this.inspectOpts)\n\t\t.split('\\n')\n\t\t.map(str => str.trim())\n\t\t.join(' ');\n};\n\n/**\n * Map %O to `util.inspect()`, allowing multiple lines if needed.\n */\n\nformatters.O = function (v) {\n\tthis.inspectOpts.colors = this.useColors;\n\treturn util.inspect(v, this.inspectOpts);\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/debug/src/node.js?");

/***/ }),

/***/ "./node_modules/has-flag/index.js":
/*!****************************************!*\
  !*** ./node_modules/has-flag/index.js ***!
  \****************************************/
/***/ ((module) => {

"use strict";
eval("\nmodule.exports = (flag, argv) => {\n\targv = argv || process.argv;\n\tconst prefix = flag.startsWith('-') ? '' : (flag.length === 1 ? '-' : '--');\n\tconst pos = argv.indexOf(prefix + flag);\n\tconst terminatorPos = argv.indexOf('--');\n\treturn pos !== -1 && (terminatorPos === -1 ? true : pos < terminatorPos);\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/has-flag/index.js?");

/***/ }),

/***/ "./node_modules/kareem/index.js":
/*!**************************************!*\
  !*** ./node_modules/kareem/index.js ***!
  \**************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/**\n * Create a new instance\n */\nfunction Kareem() {\n  this._pres = new Map();\n  this._posts = new Map();\n}\n\nKareem.skipWrappedFunction = function skipWrappedFunction() {\n  if (!(this instanceof Kareem.skipWrappedFunction)) {\n    return new Kareem.skipWrappedFunction(...arguments);\n  }\n\n  this.args = [...arguments];\n};\n\nKareem.overwriteResult = function overwriteResult() {\n  if (!(this instanceof Kareem.overwriteResult)) {\n    return new Kareem.overwriteResult(...arguments);\n  }\n\n  this.args = [...arguments];\n};\n\n/**\n * Execute all \"pre\" hooks for \"name\"\n * @param {String} name The hook name to execute\n * @param {*} context Overwrite the \"this\" for the hook\n * @param {Array|Function} args Optional arguments or directly the callback\n * @param {Function} [callback] The callback to call when executing all hooks are finished\n * @returns {void}\n */\nKareem.prototype.execPre = function(name, context, args, callback) {\n  if (arguments.length === 3) {\n    callback = args;\n    args = [];\n  }\n  const pres = this._pres.get(name) || [];\n  const numPres = pres.length;\n  const numAsyncPres = pres.numAsync || 0;\n  let currentPre = 0;\n  let asyncPresLeft = numAsyncPres;\n  let done = false;\n  const $args = args;\n  let shouldSkipWrappedFunction = null;\n\n  if (!numPres) {\n    return nextTick(function() {\n      callback(null);\n    });\n  }\n\n  function next() {\n    if (currentPre >= numPres) {\n      return;\n    }\n    const pre = pres[currentPre];\n\n    if (pre.isAsync) {\n      const args = [\n        decorateNextFn(_next),\n        decorateNextFn(function(error) {\n          if (error) {\n            if (done) {\n              return;\n            }\n            if (error instanceof Kareem.skipWrappedFunction) {\n              shouldSkipWrappedFunction = error;\n            } else {\n              done = true;\n              return callback(error);\n            }\n          }\n          if (--asyncPresLeft === 0 && currentPre >= numPres) {\n            return callback(shouldSkipWrappedFunction);\n          }\n        })\n      ];\n\n      callMiddlewareFunction(pre.fn, context, args, args[0]);\n    } else if (pre.fn.length > 0) {\n      const args = [decorateNextFn(_next)];\n      const _args = arguments.length >= 2 ? arguments : [null].concat($args);\n      for (let i = 1; i < _args.length; ++i) {\n        if (i === _args.length - 1 && typeof _args[i] === 'function') {\n          continue; // skip callbacks to avoid accidentally calling the callback from a hook\n        }\n        args.push(_args[i]);\n      }\n\n      callMiddlewareFunction(pre.fn, context, args, args[0]);\n    } else {\n      let maybePromiseLike = null;\n      try {\n        maybePromiseLike = pre.fn.call(context);\n      } catch (err) {\n        if (err != null) {\n          return callback(err);\n        }\n      }\n\n      if (isPromiseLike(maybePromiseLike)) {\n        maybePromiseLike.then(() => _next(), err => _next(err));\n      } else {\n        if (++currentPre >= numPres) {\n          if (asyncPresLeft > 0) {\n            // Leave parallel hooks to run\n            return;\n          } else {\n            return nextTick(function() {\n              callback(shouldSkipWrappedFunction);\n            });\n          }\n        }\n        next();\n      }\n    }\n  }\n\n  next.apply(null, [null].concat(args));\n\n  function _next(error) {\n    if (error) {\n      if (done) {\n        return;\n      }\n      if (error instanceof Kareem.skipWrappedFunction) {\n        shouldSkipWrappedFunction = error;\n      } else {\n        done = true;\n        return callback(error);\n      }\n    }\n\n    if (++currentPre >= numPres) {\n      if (asyncPresLeft > 0) {\n        // Leave parallel hooks to run\n        return;\n      } else {\n        return callback(shouldSkipWrappedFunction);\n      }\n    }\n\n    next.apply(context, arguments);\n  }\n};\n\n/**\n * Execute all \"pre\" hooks for \"name\" synchronously\n * @param {String} name The hook name to execute\n * @param {*} context Overwrite the \"this\" for the hook\n * @param {Array} [args] Apply custom arguments to the hook\n * @returns {void}\n */\nKareem.prototype.execPreSync = function(name, context, args) {\n  const pres = this._pres.get(name) || [];\n  const numPres = pres.length;\n\n  for (let i = 0; i < numPres; ++i) {\n    pres[i].fn.apply(context, args || []);\n  }\n};\n\n/**\n * Execute all \"post\" hooks for \"name\"\n * @param {String} name The hook name to execute\n * @param {*} context Overwrite the \"this\" for the hook\n * @param {Array|Function} args Apply custom arguments to the hook\n * @param {*} options Optional options or directly the callback\n * @param {Function} [callback] The callback to call when executing all hooks are finished\n * @returns {void}\n */\nKareem.prototype.execPost = function(name, context, args, options, callback) {\n  if (arguments.length < 5) {\n    callback = options;\n    options = null;\n  }\n  const posts = this._posts.get(name) || [];\n  const numPosts = posts.length;\n  let currentPost = 0;\n\n  let firstError = null;\n  if (options && options.error) {\n    firstError = options.error;\n  }\n\n  if (!numPosts) {\n    return nextTick(function() {\n      callback.apply(null, [firstError].concat(args));\n    });\n  }\n\n  function next() {\n    const post = posts[currentPost].fn;\n    let numArgs = 0;\n    const argLength = args.length;\n    const newArgs = [];\n    for (let i = 0; i < argLength; ++i) {\n      numArgs += args[i] && args[i]._kareemIgnore ? 0 : 1;\n      if (!args[i] || !args[i]._kareemIgnore) {\n        newArgs.push(args[i]);\n      }\n    }\n\n    if (firstError) {\n      if (isErrorHandlingMiddleware(posts[currentPost], numArgs)) {\n        const _cb = decorateNextFn(function(error) {\n          if (error) {\n            if (error instanceof Kareem.overwriteResult) {\n              args = error.args;\n              if (++currentPost >= numPosts) {\n                return callback.call(null, firstError);\n              }\n              return next();\n            }\n            firstError = error;\n          }\n          if (++currentPost >= numPosts) {\n            return callback.call(null, firstError);\n          }\n          next();\n        });\n\n        callMiddlewareFunction(post, context,\n          [firstError].concat(newArgs).concat([_cb]), _cb);\n      } else {\n        if (++currentPost >= numPosts) {\n          return callback.call(null, firstError);\n        }\n        next();\n      }\n    } else {\n      const _cb = decorateNextFn(function(error) {\n        if (error) {\n          if (error instanceof Kareem.overwriteResult) {\n            args = error.args;\n            if (++currentPost >= numPosts) {\n              return callback.apply(null, [null].concat(args));\n            }\n            return next();\n          }\n          firstError = error;\n          return next();\n        }\n\n        if (++currentPost >= numPosts) {\n          return callback.apply(null, [null].concat(args));\n        }\n\n        next();\n      });\n\n      if (isErrorHandlingMiddleware(posts[currentPost], numArgs)) {\n        // Skip error handlers if no error\n        if (++currentPost >= numPosts) {\n          return callback.apply(null, [null].concat(args));\n        }\n        return next();\n      }\n      if (post.length === numArgs + 1) {\n        callMiddlewareFunction(post, context, newArgs.concat([_cb]), _cb);\n      } else {\n        let error;\n        let maybePromiseLike;\n        try {\n          maybePromiseLike = post.apply(context, newArgs);\n        } catch (err) {\n          error = err;\n          firstError = err;\n        }\n\n        if (isPromiseLike(maybePromiseLike)) {\n          return maybePromiseLike.then(\n            (res) => {\n              _cb(res instanceof Kareem.overwriteResult ? res : null);\n            },\n            err => _cb(err)\n          );\n        }\n\n        if (maybePromiseLike instanceof Kareem.overwriteResult) {\n          args = maybePromiseLike.args;\n        }\n\n        if (++currentPost >= numPosts) {\n          return callback.apply(null, [error].concat(args));\n        }\n\n        next();\n      }\n    }\n  }\n\n  next();\n};\n\n/**\n * Execute all \"post\" hooks for \"name\" synchronously\n * @param {String} name The hook name to execute\n * @param {*} context Overwrite the \"this\" for the hook\n * @param {Array|Function} args Apply custom arguments to the hook\n * @returns {Array} The used arguments\n */\nKareem.prototype.execPostSync = function(name, context, args) {\n  const posts = this._posts.get(name) || [];\n  const numPosts = posts.length;\n\n  for (let i = 0; i < numPosts; ++i) {\n    const res = posts[i].fn.apply(context, args || []);\n    if (res instanceof Kareem.overwriteResult) {\n      args = res.args;\n    }\n  }\n\n  return args;\n};\n\n/**\n * Create a synchronous wrapper for \"fn\"\n * @param {String} name The name of the hook\n * @param {Function} fn The function to wrap\n * @returns {Function} The wrapped function\n */\nKareem.prototype.createWrapperSync = function(name, fn) {\n  const _this = this;\n  return function syncWrapper() {\n    _this.execPreSync(name, this, arguments);\n\n    const toReturn = fn.apply(this, arguments);\n\n    const result = _this.execPostSync(name, this, [toReturn]);\n\n    return result[0];\n  };\n};\n\nfunction _handleWrapError(instance, error, name, context, args, options, callback) {\n  if (options.useErrorHandlers) {\n    return instance.execPost(name, context, args, { error: error }, function(error) {\n      return typeof callback === 'function' && callback(error);\n    });\n  } else {\n    return typeof callback === 'function' && callback(error);\n  }\n}\n\n/**\n * Executes pre hooks, followed by the wrapped function, followed by post hooks.\n * @param {String} name The name of the hook\n * @param {Function} fn The function for the hook\n * @param {*} context Overwrite the \"this\" for the hook\n * @param {Array} args Apply custom arguments to the hook\n * @param {Object} [options]\n * @param {Boolean} [options.checkForPromise]\n * @returns {void}\n */\nKareem.prototype.wrap = function(name, fn, context, args, options) {\n  const lastArg = (args.length > 0 ? args[args.length - 1] : null);\n  const argsWithoutCb = Array.from(args);\n  typeof lastArg === 'function' && argsWithoutCb.pop();\n  const _this = this;\n\n  options = options || {};\n  const checkForPromise = options.checkForPromise;\n\n  this.execPre(name, context, args, function(error) {\n    if (error && !(error instanceof Kareem.skipWrappedFunction)) {\n      const numCallbackParams = options.numCallbackParams || 0;\n      const errorArgs = options.contextParameter ? [context] : [];\n      for (let i = errorArgs.length; i < numCallbackParams; ++i) {\n        errorArgs.push(null);\n      }\n      return _handleWrapError(_this, error, name, context, errorArgs,\n        options, lastArg);\n    }\n\n    const numParameters = fn.length;\n    let ret;\n\n    if (error instanceof Kareem.skipWrappedFunction) {\n      ret = error.args[0];\n      return _cb(null, ...error.args);\n    } else {\n      try {\n        ret = fn.apply(context, argsWithoutCb.concat(_cb));\n      } catch (err) {\n        return _cb(err);\n      }\n    }\n\n    if (checkForPromise) {\n      if (isPromiseLike(ret)) {\n        // Thenable, use it\n        return ret.then(\n          res => _cb(null, res),\n          err => _cb(err)\n        );\n      }\n\n      // If `fn()` doesn't have a callback argument and doesn't return a\n      // promise, assume it is sync\n      if (numParameters < argsWithoutCb.length + 1) {\n        return _cb(null, ret);\n      }\n    }\n\n    function _cb() {\n      const argsWithoutError = Array.from(arguments);\n      argsWithoutError.shift();\n      if (options.nullResultByDefault && argsWithoutError.length === 0) {\n        argsWithoutError.push(null);\n      }\n      if (arguments[0]) {\n        // Assume error\n        return _handleWrapError(_this, arguments[0], name, context,\n          argsWithoutError, options, lastArg);\n      } else {\n        _this.execPost(name, context, argsWithoutError, function() {\n          if (lastArg === null) {\n            return;\n          }\n          arguments[0]\n            ? lastArg(arguments[0])\n            : lastArg.apply(context, arguments);\n        });\n      }\n    }\n  });\n};\n\n/**\n * Filter current instance for something specific and return the filtered clone\n * @param {Function} fn The filter function\n * @returns {Kareem} The cloned and filtered instance\n */\nKareem.prototype.filter = function(fn) {\n  const clone = this.clone();\n\n  const pres = Array.from(clone._pres.keys());\n  for (const name of pres) {\n    const hooks = this._pres.get(name).\n      map(h => Object.assign({}, h, { name: name })).\n      filter(fn);\n\n    if (hooks.length === 0) {\n      clone._pres.delete(name);\n      continue;\n    }\n\n    hooks.numAsync = hooks.filter(h => h.isAsync).length;\n\n    clone._pres.set(name, hooks);\n  }\n\n  const posts = Array.from(clone._posts.keys());\n  for (const name of posts) {\n    const hooks = this._posts.get(name).\n      map(h => Object.assign({}, h, { name: name })).\n      filter(fn);\n\n    if (hooks.length === 0) {\n      clone._posts.delete(name);\n      continue;\n    }\n\n    clone._posts.set(name, hooks);\n  }\n\n  return clone;\n};\n\n/**\n * Check for a \"name\" to exist either in pre or post hooks\n * @param {String} name The name of the hook\n * @returns {Boolean} \"true\" if found, \"false\" otherwise\n */\nKareem.prototype.hasHooks = function(name) {\n  return this._pres.has(name) || this._posts.has(name);\n};\n\n/**\n * Create a Wrapper for \"fn\" on \"name\" and return the wrapped function\n * @param {String} name The name of the hook\n * @param {Function} fn The function to wrap\n * @param {*} context Overwrite the \"this\" for the hook\n * @param {Object} [options]\n * @returns {Function} The wrapped function\n */\nKareem.prototype.createWrapper = function(name, fn, context, options) {\n  const _this = this;\n  if (!this.hasHooks(name)) {\n    // Fast path: if there's no hooks for this function, just return the\n    // function wrapped in a nextTick()\n    return function() {\n      nextTick(() => fn.apply(this, arguments));\n    };\n  }\n  return function() {\n    const _context = context || this;\n    _this.wrap(name, fn, _context, Array.from(arguments), options);\n  };\n};\n\n/**\n * Register a new hook for \"pre\"\n * @param {String} name The name of the hook\n * @param {Boolean} [isAsync]\n * @param {Function} fn The function to register for \"name\"\n * @param {never} error Unused\n * @param {Boolean} [unshift] Wheter to \"push\" or to \"unshift\" the new hook\n * @returns {Kareem}\n */\nKareem.prototype.pre = function(name, isAsync, fn, error, unshift) {\n  let options = {};\n  if (typeof isAsync === 'object' && isAsync !== null) {\n    options = isAsync;\n    isAsync = options.isAsync;\n  } else if (typeof arguments[1] !== 'boolean') {\n    fn = isAsync;\n    isAsync = false;\n  }\n\n  const pres = this._pres.get(name) || [];\n  this._pres.set(name, pres);\n\n  if (isAsync) {\n    pres.numAsync = pres.numAsync || 0;\n    ++pres.numAsync;\n  }\n\n  if (typeof fn !== 'function') {\n    throw new Error('pre() requires a function, got \"' + typeof fn + '\"');\n  }\n\n  if (unshift) {\n    pres.unshift(Object.assign({}, options, { fn: fn, isAsync: isAsync }));\n  } else {\n    pres.push(Object.assign({}, options, { fn: fn, isAsync: isAsync }));\n  }\n\n  return this;\n};\n\n/**\n * Register a new hook for \"post\"\n * @param {String} name The name of the hook\n * @param {Object} [options]\n * @param {Function} fn The function to register for \"name\"\n * @param {Boolean} [unshift] Wheter to \"push\" or to \"unshift\" the new hook\n * @returns {Kareem}\n */\nKareem.prototype.post = function(name, options, fn, unshift) {\n  const posts = this._posts.get(name) || [];\n\n  if (typeof options === 'function') {\n    unshift = !!fn;\n    fn = options;\n    options = {};\n  }\n\n  if (typeof fn !== 'function') {\n    throw new Error('post() requires a function, got \"' + typeof fn + '\"');\n  }\n\n  if (unshift) {\n    posts.unshift(Object.assign({}, options, { fn: fn }));\n  } else {\n    posts.push(Object.assign({}, options, { fn: fn }));\n  }\n  this._posts.set(name, posts);\n  return this;\n};\n\n/**\n * Clone the current instance\n * @returns {Kareem} The cloned instance\n */\nKareem.prototype.clone = function() {\n  const n = new Kareem();\n\n  for (const key of this._pres.keys()) {\n    const clone = this._pres.get(key).slice();\n    clone.numAsync = this._pres.get(key).numAsync;\n    n._pres.set(key, clone);\n  }\n  for (const key of this._posts.keys()) {\n    n._posts.set(key, this._posts.get(key).slice());\n  }\n\n  return n;\n};\n\n/**\n * Merge \"other\" into self or \"clone\"\n * @param {Kareem} other The instance to merge with\n * @param {Kareem} [clone] The instance to merge onto (if not defined, using \"this\")\n * @returns {Kareem} The merged instance\n */\nKareem.prototype.merge = function(other, clone) {\n  clone = arguments.length === 1 ? true : clone;\n  const ret = clone ? this.clone() : this;\n\n  for (const key of other._pres.keys()) {\n    const sourcePres = ret._pres.get(key) || [];\n    const deduplicated = other._pres.get(key).\n      // Deduplicate based on `fn`\n      filter(p => sourcePres.map(_p => _p.fn).indexOf(p.fn) === -1);\n    const combined = sourcePres.concat(deduplicated);\n    combined.numAsync = sourcePres.numAsync || 0;\n    combined.numAsync += deduplicated.filter(p => p.isAsync).length;\n    ret._pres.set(key, combined);\n  }\n  for (const key of other._posts.keys()) {\n    const sourcePosts = ret._posts.get(key) || [];\n    const deduplicated = other._posts.get(key).\n      filter(p => sourcePosts.indexOf(p) === -1);\n    ret._posts.set(key, sourcePosts.concat(deduplicated));\n  }\n\n  return ret;\n};\n\nfunction callMiddlewareFunction(fn, context, args, next) {\n  let maybePromiseLike;\n  try {\n    maybePromiseLike = fn.apply(context, args);\n  } catch (error) {\n    return next(error);\n  }\n\n  if (isPromiseLike(maybePromiseLike)) {\n    maybePromiseLike.then(() => next(), err => next(err));\n  }\n}\n\nfunction isPromiseLike(v) {\n  return (typeof v === 'object' && v !== null && typeof v.then === 'function');\n}\n\nfunction decorateNextFn(fn) {\n  let called = false;\n  const _this = this;\n  return function() {\n    // Ensure this function can only be called once\n    if (called) {\n      return;\n    }\n    called = true;\n    // Make sure to clear the stack so try/catch doesn't catch errors\n    // in subsequent middleware\n    return nextTick(() => fn.apply(_this, arguments));\n  };\n}\n\nconst nextTick = typeof process === 'object' && process !== null && process.nextTick || function nextTick(cb) {\n  setTimeout(cb, 0);\n};\n\nfunction isErrorHandlingMiddleware(post, numArgs) {\n  if (post.errorHandler) {\n    return true;\n  }\n  return post.fn.length === numArgs + 2;\n}\n\nmodule.exports = Kareem;\n\n\n//# sourceURL=webpack://experimento/./node_modules/kareem/index.js?");

/***/ }),

/***/ "./node_modules/memory-pager/index.js":
/*!********************************************!*\
  !*** ./node_modules/memory-pager/index.js ***!
  \********************************************/
/***/ ((module) => {

eval("module.exports = Pager\n\nfunction Pager (pageSize, opts) {\n  if (!(this instanceof Pager)) return new Pager(pageSize, opts)\n\n  this.length = 0\n  this.updates = []\n  this.path = new Uint16Array(4)\n  this.pages = new Array(32768)\n  this.maxPages = this.pages.length\n  this.level = 0\n  this.pageSize = pageSize || 1024\n  this.deduplicate = opts ? opts.deduplicate : null\n  this.zeros = this.deduplicate ? alloc(this.deduplicate.length) : null\n}\n\nPager.prototype.updated = function (page) {\n  while (this.deduplicate && page.buffer[page.deduplicate] === this.deduplicate[page.deduplicate]) {\n    page.deduplicate++\n    if (page.deduplicate === this.deduplicate.length) {\n      page.deduplicate = 0\n      if (page.buffer.equals && page.buffer.equals(this.deduplicate)) page.buffer = this.deduplicate\n      break\n    }\n  }\n  if (page.updated || !this.updates) return\n  page.updated = true\n  this.updates.push(page)\n}\n\nPager.prototype.lastUpdate = function () {\n  if (!this.updates || !this.updates.length) return null\n  var page = this.updates.pop()\n  page.updated = false\n  return page\n}\n\nPager.prototype._array = function (i, noAllocate) {\n  if (i >= this.maxPages) {\n    if (noAllocate) return\n    grow(this, i)\n  }\n\n  factor(i, this.path)\n\n  var arr = this.pages\n\n  for (var j = this.level; j > 0; j--) {\n    var p = this.path[j]\n    var next = arr[p]\n\n    if (!next) {\n      if (noAllocate) return\n      next = arr[p] = new Array(32768)\n    }\n\n    arr = next\n  }\n\n  return arr\n}\n\nPager.prototype.get = function (i, noAllocate) {\n  var arr = this._array(i, noAllocate)\n  var first = this.path[0]\n  var page = arr && arr[first]\n\n  if (!page && !noAllocate) {\n    page = arr[first] = new Page(i, alloc(this.pageSize))\n    if (i >= this.length) this.length = i + 1\n  }\n\n  if (page && page.buffer === this.deduplicate && this.deduplicate && !noAllocate) {\n    page.buffer = copy(page.buffer)\n    page.deduplicate = 0\n  }\n\n  return page\n}\n\nPager.prototype.set = function (i, buf) {\n  var arr = this._array(i, false)\n  var first = this.path[0]\n\n  if (i >= this.length) this.length = i + 1\n\n  if (!buf || (this.zeros && buf.equals && buf.equals(this.zeros))) {\n    arr[first] = undefined\n    return\n  }\n\n  if (this.deduplicate && buf.equals && buf.equals(this.deduplicate)) {\n    buf = this.deduplicate\n  }\n\n  var page = arr[first]\n  var b = truncate(buf, this.pageSize)\n\n  if (page) page.buffer = b\n  else arr[first] = new Page(i, b)\n}\n\nPager.prototype.toBuffer = function () {\n  var list = new Array(this.length)\n  var empty = alloc(this.pageSize)\n  var ptr = 0\n\n  while (ptr < list.length) {\n    var arr = this._array(ptr, true)\n    for (var i = 0; i < 32768 && ptr < list.length; i++) {\n      list[ptr++] = (arr && arr[i]) ? arr[i].buffer : empty\n    }\n  }\n\n  return Buffer.concat(list)\n}\n\nfunction grow (pager, index) {\n  while (pager.maxPages < index) {\n    var old = pager.pages\n    pager.pages = new Array(32768)\n    pager.pages[0] = old\n    pager.level++\n    pager.maxPages *= 32768\n  }\n}\n\nfunction truncate (buf, len) {\n  if (buf.length === len) return buf\n  if (buf.length > len) return buf.slice(0, len)\n  var cpy = alloc(len)\n  buf.copy(cpy)\n  return cpy\n}\n\nfunction alloc (size) {\n  if (Buffer.alloc) return Buffer.alloc(size)\n  var buf = new Buffer(size)\n  buf.fill(0)\n  return buf\n}\n\nfunction copy (buf) {\n  var cpy = Buffer.allocUnsafe ? Buffer.allocUnsafe(buf.length) : new Buffer(buf.length)\n  buf.copy(cpy)\n  return cpy\n}\n\nfunction Page (i, buf) {\n  this.offset = i * buf.length\n  this.buffer = buf\n  this.updated = false\n  this.deduplicate = 0\n}\n\nfunction factor (n, out) {\n  n = (n - (out[0] = (n & 32767))) / 32768\n  n = (n - (out[1] = (n & 32767))) / 32768\n  out[3] = ((n - (out[2] = (n & 32767))) / 32768) & 32767\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/memory-pager/index.js?");

/***/ }),

/***/ "./node_modules/mongodb-connection-string-url/lib/index.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mongodb-connection-string-url/lib/index.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CommaAndColonSeparatedRecord = exports.ConnectionString = exports.redactConnectionString = void 0;\nconst whatwg_url_1 = __webpack_require__(/*! whatwg-url */ \"./node_modules/whatwg-url/index.js\");\nconst redact_1 = __webpack_require__(/*! ./redact */ \"./node_modules/mongodb-connection-string-url/lib/redact.js\");\nObject.defineProperty(exports, \"redactConnectionString\", ({ enumerable: true, get: function () { return redact_1.redactConnectionString; } }));\nconst DUMMY_HOSTNAME = '__this_is_a_placeholder__';\nfunction connectionStringHasValidScheme(connectionString) {\n    return (connectionString.startsWith('mongodb://') ||\n        connectionString.startsWith('mongodb+srv://'));\n}\nconst HOSTS_REGEX = /^(?<protocol>[^/]+):\\/\\/(?:(?<username>[^:@]*)(?::(?<password>[^@]*))?@)?(?<hosts>(?!:)[^/?@]*)(?<rest>.*)/;\nclass CaseInsensitiveMap extends Map {\n    delete(name) {\n        return super.delete(this._normalizeKey(name));\n    }\n    get(name) {\n        return super.get(this._normalizeKey(name));\n    }\n    has(name) {\n        return super.has(this._normalizeKey(name));\n    }\n    set(name, value) {\n        return super.set(this._normalizeKey(name), value);\n    }\n    _normalizeKey(name) {\n        name = `${name}`;\n        for (const key of this.keys()) {\n            if (key.toLowerCase() === name.toLowerCase()) {\n                name = key;\n                break;\n            }\n        }\n        return name;\n    }\n}\nfunction caseInsenstiveURLSearchParams(Ctor) {\n    return class CaseInsenstiveURLSearchParams extends Ctor {\n        append(name, value) {\n            return super.append(this._normalizeKey(name), value);\n        }\n        delete(name) {\n            return super.delete(this._normalizeKey(name));\n        }\n        get(name) {\n            return super.get(this._normalizeKey(name));\n        }\n        getAll(name) {\n            return super.getAll(this._normalizeKey(name));\n        }\n        has(name) {\n            return super.has(this._normalizeKey(name));\n        }\n        set(name, value) {\n            return super.set(this._normalizeKey(name), value);\n        }\n        keys() {\n            return super.keys();\n        }\n        values() {\n            return super.values();\n        }\n        entries() {\n            return super.entries();\n        }\n        [Symbol.iterator]() {\n            return super[Symbol.iterator]();\n        }\n        _normalizeKey(name) {\n            return CaseInsensitiveMap.prototype._normalizeKey.call(this, name);\n        }\n    };\n}\nclass URLWithoutHost extends whatwg_url_1.URL {\n}\nclass MongoParseError extends Error {\n    get name() {\n        return 'MongoParseError';\n    }\n}\nclass ConnectionString extends URLWithoutHost {\n    constructor(uri, options = {}) {\n        var _a;\n        const { looseValidation } = options;\n        if (!looseValidation && !connectionStringHasValidScheme(uri)) {\n            throw new MongoParseError('Invalid scheme, expected connection string to start with \"mongodb://\" or \"mongodb+srv://\"');\n        }\n        const match = uri.match(HOSTS_REGEX);\n        if (!match) {\n            throw new MongoParseError(`Invalid connection string \"${uri}\"`);\n        }\n        const { protocol, username, password, hosts, rest } = (_a = match.groups) !== null && _a !== void 0 ? _a : {};\n        if (!looseValidation) {\n            if (!protocol || !hosts) {\n                throw new MongoParseError(`Protocol and host list are required in \"${uri}\"`);\n            }\n            try {\n                decodeURIComponent(username !== null && username !== void 0 ? username : '');\n                decodeURIComponent(password !== null && password !== void 0 ? password : '');\n            }\n            catch (err) {\n                throw new MongoParseError(err.message);\n            }\n            const illegalCharacters = /[:/?#[\\]@]/gi;\n            if (username === null || username === void 0 ? void 0 : username.match(illegalCharacters)) {\n                throw new MongoParseError(`Username contains unescaped characters ${username}`);\n            }\n            if (!username || !password) {\n                const uriWithoutProtocol = uri.replace(`${protocol}://`, '');\n                if (uriWithoutProtocol.startsWith('@') || uriWithoutProtocol.startsWith(':')) {\n                    throw new MongoParseError('URI contained empty userinfo section');\n                }\n            }\n            if (password === null || password === void 0 ? void 0 : password.match(illegalCharacters)) {\n                throw new MongoParseError('Password contains unescaped characters');\n            }\n        }\n        let authString = '';\n        if (typeof username === 'string')\n            authString += username;\n        if (typeof password === 'string')\n            authString += `:${password}`;\n        if (authString)\n            authString += '@';\n        try {\n            super(`${protocol.toLowerCase()}://${authString}${DUMMY_HOSTNAME}${rest}`);\n        }\n        catch (err) {\n            if (looseValidation) {\n                new ConnectionString(uri, {\n                    ...options,\n                    looseValidation: false\n                });\n            }\n            if (typeof err.message === 'string') {\n                err.message = err.message.replace(DUMMY_HOSTNAME, hosts);\n            }\n            throw err;\n        }\n        this._hosts = hosts.split(',');\n        if (!looseValidation) {\n            if (this.isSRV && this.hosts.length !== 1) {\n                throw new MongoParseError('mongodb+srv URI cannot have multiple service names');\n            }\n            if (this.isSRV && this.hosts.some(host => host.includes(':'))) {\n                throw new MongoParseError('mongodb+srv URI cannot have port number');\n            }\n        }\n        if (!this.pathname) {\n            this.pathname = '/';\n        }\n        Object.setPrototypeOf(this.searchParams, caseInsenstiveURLSearchParams(this.searchParams.constructor).prototype);\n    }\n    get host() { return DUMMY_HOSTNAME; }\n    set host(_ignored) { throw new Error('No single host for connection string'); }\n    get hostname() { return DUMMY_HOSTNAME; }\n    set hostname(_ignored) { throw new Error('No single host for connection string'); }\n    get port() { return ''; }\n    set port(_ignored) { throw new Error('No single host for connection string'); }\n    get href() { return this.toString(); }\n    set href(_ignored) { throw new Error('Cannot set href for connection strings'); }\n    get isSRV() {\n        return this.protocol.includes('srv');\n    }\n    get hosts() {\n        return this._hosts;\n    }\n    set hosts(list) {\n        this._hosts = list;\n    }\n    toString() {\n        return super.toString().replace(DUMMY_HOSTNAME, this.hosts.join(','));\n    }\n    clone() {\n        return new ConnectionString(this.toString(), {\n            looseValidation: true\n        });\n    }\n    redact(options) {\n        return (0, redact_1.redactValidConnectionString)(this, options);\n    }\n    typedSearchParams() {\n        const sametype =  false && 0;\n        return this.searchParams;\n    }\n    [Symbol.for('nodejs.util.inspect.custom')]() {\n        const { href, origin, protocol, username, password, hosts, pathname, search, searchParams, hash } = this;\n        return { href, origin, protocol, username, password, hosts, pathname, search, searchParams, hash };\n    }\n}\nexports.ConnectionString = ConnectionString;\nclass CommaAndColonSeparatedRecord extends CaseInsensitiveMap {\n    constructor(from) {\n        super();\n        for (const entry of (from !== null && from !== void 0 ? from : '').split(',')) {\n            if (!entry)\n                continue;\n            const colonIndex = entry.indexOf(':');\n            if (colonIndex === -1) {\n                this.set(entry, '');\n            }\n            else {\n                this.set(entry.slice(0, colonIndex), entry.slice(colonIndex + 1));\n            }\n        }\n    }\n    toString() {\n        return [...this].map(entry => entry.join(':')).join(',');\n    }\n}\nexports.CommaAndColonSeparatedRecord = CommaAndColonSeparatedRecord;\nexports[\"default\"] = ConnectionString;\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb-connection-string-url/lib/index.js?");

/***/ }),

/***/ "./node_modules/mongodb-connection-string-url/lib/redact.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongodb-connection-string-url/lib/redact.js ***!
  \******************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.redactConnectionString = exports.redactValidConnectionString = void 0;\nconst index_1 = __importStar(__webpack_require__(/*! ./index */ \"./node_modules/mongodb-connection-string-url/lib/index.js\"));\nfunction redactValidConnectionString(inputUrl, options) {\n    var _a, _b;\n    const url = inputUrl.clone();\n    const replacementString = (_a = options === null || options === void 0 ? void 0 : options.replacementString) !== null && _a !== void 0 ? _a : '_credentials_';\n    const redactUsernames = (_b = options === null || options === void 0 ? void 0 : options.redactUsernames) !== null && _b !== void 0 ? _b : true;\n    if ((url.username || url.password) && redactUsernames) {\n        url.username = replacementString;\n        url.password = '';\n    }\n    else if (url.password) {\n        url.password = replacementString;\n    }\n    if (url.searchParams.has('authMechanismProperties')) {\n        const props = new index_1.CommaAndColonSeparatedRecord(url.searchParams.get('authMechanismProperties'));\n        if (props.get('AWS_SESSION_TOKEN')) {\n            props.set('AWS_SESSION_TOKEN', replacementString);\n            url.searchParams.set('authMechanismProperties', props.toString());\n        }\n    }\n    if (url.searchParams.has('tlsCertificateKeyFilePassword')) {\n        url.searchParams.set('tlsCertificateKeyFilePassword', replacementString);\n    }\n    if (url.searchParams.has('proxyUsername') && redactUsernames) {\n        url.searchParams.set('proxyUsername', replacementString);\n    }\n    if (url.searchParams.has('proxyPassword')) {\n        url.searchParams.set('proxyPassword', replacementString);\n    }\n    return url;\n}\nexports.redactValidConnectionString = redactValidConnectionString;\nfunction redactConnectionString(uri, options) {\n    var _a, _b;\n    const replacementString = (_a = options === null || options === void 0 ? void 0 : options.replacementString) !== null && _a !== void 0 ? _a : '<credentials>';\n    const redactUsernames = (_b = options === null || options === void 0 ? void 0 : options.redactUsernames) !== null && _b !== void 0 ? _b : true;\n    let parsed;\n    try {\n        parsed = new index_1.default(uri);\n    }\n    catch (_c) { }\n    if (parsed) {\n        options = { ...options, replacementString: '___credentials___' };\n        return parsed.redact(options).toString().replace(/___credentials___/g, replacementString);\n    }\n    const R = replacementString;\n    const replacements = [\n        uri => uri.replace(redactUsernames ? /(\\/\\/)(.*)(@)/g : /(\\/\\/[^@]*:)(.*)(@)/g, `$1${R}$3`),\n        uri => uri.replace(/(AWS_SESSION_TOKEN(:|%3A))([^,&]+)/gi, `$1${R}`),\n        uri => uri.replace(/(tlsCertificateKeyFilePassword=)([^&]+)/gi, `$1${R}`),\n        uri => redactUsernames ? uri.replace(/(proxyUsername=)([^&]+)/gi, `$1${R}`) : uri,\n        uri => uri.replace(/(proxyPassword=)([^&]+)/gi, `$1${R}`)\n    ];\n    for (const replacer of replacements) {\n        uri = replacer(uri);\n    }\n    return uri;\n}\nexports.redactConnectionString = redactConnectionString;\n//# sourceMappingURL=redact.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb-connection-string-url/lib/redact.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/admin.js":
/*!*******************************************!*\
  !*** ./node_modules/mongodb/lib/admin.js ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Admin = void 0;\nconst bson_1 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst execute_operation_1 = __webpack_require__(/*! ./operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst list_databases_1 = __webpack_require__(/*! ./operations/list_databases */ \"./node_modules/mongodb/lib/operations/list_databases.js\");\nconst remove_user_1 = __webpack_require__(/*! ./operations/remove_user */ \"./node_modules/mongodb/lib/operations/remove_user.js\");\nconst run_command_1 = __webpack_require__(/*! ./operations/run_command */ \"./node_modules/mongodb/lib/operations/run_command.js\");\nconst validate_collection_1 = __webpack_require__(/*! ./operations/validate_collection */ \"./node_modules/mongodb/lib/operations/validate_collection.js\");\n/**\n * The **Admin** class is an internal class that allows convenient access to\n * the admin functionality and commands for MongoDB.\n *\n * **ADMIN Cannot directly be instantiated**\n * @public\n *\n * @example\n * ```ts\n * import { MongoClient } from 'mongodb';\n *\n * const client = new MongoClient('mongodb://localhost:27017');\n * const admin = client.db().admin();\n * const dbInfo = await admin.listDatabases();\n * for (const db of dbInfo.databases) {\n *   console.log(db.name);\n * }\n * ```\n */\nclass Admin {\n    /**\n     * Create a new Admin instance\n     * @internal\n     */\n    constructor(db) {\n        this.s = { db };\n    }\n    /**\n     * Execute a command\n     *\n     * The driver will ensure the following fields are attached to the command sent to the server:\n     * - `lsid` - sourced from an implicit session or options.session\n     * - `$readPreference` - defaults to primary or can be configured by options.readPreference\n     * - `$db` - sourced from the name of this database\n     *\n     * If the client has a serverApi setting:\n     * - `apiVersion`\n     * - `apiStrict`\n     * - `apiDeprecationErrors`\n     *\n     * When in a transaction:\n     * - `readConcern` - sourced from readConcern set on the TransactionOptions\n     * - `writeConcern` - sourced from writeConcern set on the TransactionOptions\n     *\n     * Attaching any of the above fields to the command will have no effect as the driver will overwrite the value.\n     *\n     * @param command - The command to execute\n     * @param options - Optional settings for the command\n     */\n    async command(command, options) {\n        return await (0, execute_operation_1.executeOperation)(this.s.db.client, new run_command_1.RunAdminCommandOperation(command, {\n            ...(0, bson_1.resolveBSONOptions)(options),\n            session: options?.session,\n            readPreference: options?.readPreference\n        }));\n    }\n    /**\n     * Retrieve the server build information\n     *\n     * @param options - Optional settings for the command\n     */\n    async buildInfo(options) {\n        return await this.command({ buildinfo: 1 }, options);\n    }\n    /**\n     * Retrieve the server build information\n     *\n     * @param options - Optional settings for the command\n     */\n    async serverInfo(options) {\n        return await this.command({ buildinfo: 1 }, options);\n    }\n    /**\n     * Retrieve this db's server status.\n     *\n     * @param options - Optional settings for the command\n     */\n    async serverStatus(options) {\n        return await this.command({ serverStatus: 1 }, options);\n    }\n    /**\n     * Ping the MongoDB server and retrieve results\n     *\n     * @param options - Optional settings for the command\n     */\n    async ping(options) {\n        return await this.command({ ping: 1 }, options);\n    }\n    /**\n     * Remove a user from a database\n     *\n     * @param username - The username to remove\n     * @param options - Optional settings for the command\n     */\n    async removeUser(username, options) {\n        return await (0, execute_operation_1.executeOperation)(this.s.db.client, new remove_user_1.RemoveUserOperation(this.s.db, username, { dbName: 'admin', ...options }));\n    }\n    /**\n     * Validate an existing collection\n     *\n     * @param collectionName - The name of the collection to validate.\n     * @param options - Optional settings for the command\n     */\n    async validateCollection(collectionName, options = {}) {\n        return await (0, execute_operation_1.executeOperation)(this.s.db.client, new validate_collection_1.ValidateCollectionOperation(this, collectionName, options));\n    }\n    /**\n     * List the available databases\n     *\n     * @param options - Optional settings for the command\n     */\n    async listDatabases(options) {\n        return await (0, execute_operation_1.executeOperation)(this.s.db.client, new list_databases_1.ListDatabasesOperation(this.s.db, options));\n    }\n    /**\n     * Get ReplicaSet status\n     *\n     * @param options - Optional settings for the command\n     */\n    async replSetGetStatus(options) {\n        return await this.command({ replSetGetStatus: 1 }, options);\n    }\n}\nexports.Admin = Admin;\n//# sourceMappingURL=admin.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/admin.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/bson.js":
/*!******************************************!*\
  !*** ./node_modules/mongodb/lib/bson.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.resolveBSONOptions = exports.pluckBSONSerializeOptions = exports.toUTF8 = exports.getBigInt64LE = exports.getFloat64LE = exports.getInt32LE = exports.parseToElementsToArray = exports.UUID = exports.Timestamp = exports.serialize = exports.ObjectId = exports.MinKey = exports.MaxKey = exports.Long = exports.Int32 = exports.EJSON = exports.Double = exports.deserialize = exports.Decimal128 = exports.DBRef = exports.Code = exports.calculateObjectSize = exports.BSONType = exports.BSONSymbol = exports.BSONRegExp = exports.BSONError = exports.BSON = exports.Binary = void 0;\nconst bson_1 = __webpack_require__(/*! bson */ \"./node_modules/bson/lib/bson.cjs\");\nvar bson_2 = __webpack_require__(/*! bson */ \"./node_modules/bson/lib/bson.cjs\");\nObject.defineProperty(exports, \"Binary\", ({ enumerable: true, get: function () { return bson_2.Binary; } }));\nObject.defineProperty(exports, \"BSON\", ({ enumerable: true, get: function () { return bson_2.BSON; } }));\nObject.defineProperty(exports, \"BSONError\", ({ enumerable: true, get: function () { return bson_2.BSONError; } }));\nObject.defineProperty(exports, \"BSONRegExp\", ({ enumerable: true, get: function () { return bson_2.BSONRegExp; } }));\nObject.defineProperty(exports, \"BSONSymbol\", ({ enumerable: true, get: function () { return bson_2.BSONSymbol; } }));\nObject.defineProperty(exports, \"BSONType\", ({ enumerable: true, get: function () { return bson_2.BSONType; } }));\nObject.defineProperty(exports, \"calculateObjectSize\", ({ enumerable: true, get: function () { return bson_2.calculateObjectSize; } }));\nObject.defineProperty(exports, \"Code\", ({ enumerable: true, get: function () { return bson_2.Code; } }));\nObject.defineProperty(exports, \"DBRef\", ({ enumerable: true, get: function () { return bson_2.DBRef; } }));\nObject.defineProperty(exports, \"Decimal128\", ({ enumerable: true, get: function () { return bson_2.Decimal128; } }));\nObject.defineProperty(exports, \"deserialize\", ({ enumerable: true, get: function () { return bson_2.deserialize; } }));\nObject.defineProperty(exports, \"Double\", ({ enumerable: true, get: function () { return bson_2.Double; } }));\nObject.defineProperty(exports, \"EJSON\", ({ enumerable: true, get: function () { return bson_2.EJSON; } }));\nObject.defineProperty(exports, \"Int32\", ({ enumerable: true, get: function () { return bson_2.Int32; } }));\nObject.defineProperty(exports, \"Long\", ({ enumerable: true, get: function () { return bson_2.Long; } }));\nObject.defineProperty(exports, \"MaxKey\", ({ enumerable: true, get: function () { return bson_2.MaxKey; } }));\nObject.defineProperty(exports, \"MinKey\", ({ enumerable: true, get: function () { return bson_2.MinKey; } }));\nObject.defineProperty(exports, \"ObjectId\", ({ enumerable: true, get: function () { return bson_2.ObjectId; } }));\nObject.defineProperty(exports, \"serialize\", ({ enumerable: true, get: function () { return bson_2.serialize; } }));\nObject.defineProperty(exports, \"Timestamp\", ({ enumerable: true, get: function () { return bson_2.Timestamp; } }));\nObject.defineProperty(exports, \"UUID\", ({ enumerable: true, get: function () { return bson_2.UUID; } }));\nfunction parseToElementsToArray(bytes, offset) {\n    const res = bson_1.BSON.onDemand.parseToElements(bytes, offset);\n    return Array.isArray(res) ? res : [...res];\n}\nexports.parseToElementsToArray = parseToElementsToArray;\nexports.getInt32LE = bson_1.BSON.onDemand.NumberUtils.getInt32LE;\nexports.getFloat64LE = bson_1.BSON.onDemand.NumberUtils.getFloat64LE;\nexports.getBigInt64LE = bson_1.BSON.onDemand.NumberUtils.getBigInt64LE;\nexports.toUTF8 = bson_1.BSON.onDemand.ByteUtils.toUTF8;\nfunction pluckBSONSerializeOptions(options) {\n    const { fieldsAsRaw, useBigInt64, promoteValues, promoteBuffers, promoteLongs, serializeFunctions, ignoreUndefined, bsonRegExp, raw, enableUtf8Validation } = options;\n    return {\n        fieldsAsRaw,\n        useBigInt64,\n        promoteValues,\n        promoteBuffers,\n        promoteLongs,\n        serializeFunctions,\n        ignoreUndefined,\n        bsonRegExp,\n        raw,\n        enableUtf8Validation\n    };\n}\nexports.pluckBSONSerializeOptions = pluckBSONSerializeOptions;\n/**\n * Merge the given BSONSerializeOptions, preferring options over the parent's options, and\n * substituting defaults for values not set.\n *\n * @internal\n */\nfunction resolveBSONOptions(options, parent) {\n    const parentOptions = parent?.bsonOptions;\n    return {\n        raw: options?.raw ?? parentOptions?.raw ?? false,\n        useBigInt64: options?.useBigInt64 ?? parentOptions?.useBigInt64 ?? false,\n        promoteLongs: options?.promoteLongs ?? parentOptions?.promoteLongs ?? true,\n        promoteValues: options?.promoteValues ?? parentOptions?.promoteValues ?? true,\n        promoteBuffers: options?.promoteBuffers ?? parentOptions?.promoteBuffers ?? false,\n        ignoreUndefined: options?.ignoreUndefined ?? parentOptions?.ignoreUndefined ?? false,\n        bsonRegExp: options?.bsonRegExp ?? parentOptions?.bsonRegExp ?? false,\n        serializeFunctions: options?.serializeFunctions ?? parentOptions?.serializeFunctions ?? false,\n        fieldsAsRaw: options?.fieldsAsRaw ?? parentOptions?.fieldsAsRaw ?? {},\n        enableUtf8Validation: options?.enableUtf8Validation ?? parentOptions?.enableUtf8Validation ?? true\n    };\n}\nexports.resolveBSONOptions = resolveBSONOptions;\n//# sourceMappingURL=bson.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/bson.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/bulk/common.js":
/*!*************************************************!*\
  !*** ./node_modules/mongodb/lib/bulk/common.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.BulkOperationBase = exports.BulkWriteShimOperation = exports.FindOperators = exports.MongoBulkWriteError = exports.mergeBatchResults = exports.WriteError = exports.WriteConcernError = exports.BulkWriteResult = exports.Batch = exports.BatchType = void 0;\nconst util_1 = __webpack_require__(/*! util */ \"util\");\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst delete_1 = __webpack_require__(/*! ../operations/delete */ \"./node_modules/mongodb/lib/operations/delete.js\");\nconst execute_operation_1 = __webpack_require__(/*! ../operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst insert_1 = __webpack_require__(/*! ../operations/insert */ \"./node_modules/mongodb/lib/operations/insert.js\");\nconst operation_1 = __webpack_require__(/*! ../operations/operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\nconst update_1 = __webpack_require__(/*! ../operations/update */ \"./node_modules/mongodb/lib/operations/update.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst utils_2 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst write_concern_1 = __webpack_require__(/*! ../write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\n/** @internal */\nconst kServerError = Symbol('serverError');\n/** @public */\nexports.BatchType = Object.freeze({\n    INSERT: 1,\n    UPDATE: 2,\n    DELETE: 3\n});\n/**\n * Keeps the state of a unordered batch so we can rewrite the results\n * correctly after command execution\n *\n * @public\n */\nclass Batch {\n    constructor(batchType, originalZeroIndex) {\n        this.originalZeroIndex = originalZeroIndex;\n        this.currentIndex = 0;\n        this.originalIndexes = [];\n        this.batchType = batchType;\n        this.operations = [];\n        this.size = 0;\n        this.sizeBytes = 0;\n    }\n}\nexports.Batch = Batch;\n/**\n * @public\n * The result of a bulk write.\n */\nclass BulkWriteResult {\n    static generateIdMap(ids) {\n        const idMap = {};\n        for (const doc of ids) {\n            idMap[doc.index] = doc._id;\n        }\n        return idMap;\n    }\n    /**\n     * Create a new BulkWriteResult instance\n     * @internal\n     */\n    constructor(bulkResult, isOrdered) {\n        this.result = bulkResult;\n        this.insertedCount = this.result.nInserted ?? 0;\n        this.matchedCount = this.result.nMatched ?? 0;\n        this.modifiedCount = this.result.nModified ?? 0;\n        this.deletedCount = this.result.nRemoved ?? 0;\n        this.upsertedCount = this.result.upserted.length ?? 0;\n        this.upsertedIds = BulkWriteResult.generateIdMap(this.result.upserted);\n        this.insertedIds = BulkWriteResult.generateIdMap(this.getSuccessfullyInsertedIds(bulkResult, isOrdered));\n        Object.defineProperty(this, 'result', { value: this.result, enumerable: false });\n    }\n    /** Evaluates to true if the bulk operation correctly executes */\n    get ok() {\n        return this.result.ok;\n    }\n    /**\n     * Returns document_ids that were actually inserted\n     * @internal\n     */\n    getSuccessfullyInsertedIds(bulkResult, isOrdered) {\n        if (bulkResult.writeErrors.length === 0)\n            return bulkResult.insertedIds;\n        if (isOrdered) {\n            return bulkResult.insertedIds.slice(0, bulkResult.writeErrors[0].index);\n        }\n        return bulkResult.insertedIds.filter(({ index }) => !bulkResult.writeErrors.some(writeError => index === writeError.index));\n    }\n    /** Returns the upserted id at the given index */\n    getUpsertedIdAt(index) {\n        return this.result.upserted[index];\n    }\n    /** Returns raw internal result */\n    getRawResponse() {\n        return this.result;\n    }\n    /** Returns true if the bulk operation contains a write error */\n    hasWriteErrors() {\n        return this.result.writeErrors.length > 0;\n    }\n    /** Returns the number of write errors off the bulk operation */\n    getWriteErrorCount() {\n        return this.result.writeErrors.length;\n    }\n    /** Returns a specific write error object */\n    getWriteErrorAt(index) {\n        return index < this.result.writeErrors.length ? this.result.writeErrors[index] : undefined;\n    }\n    /** Retrieve all write errors */\n    getWriteErrors() {\n        return this.result.writeErrors;\n    }\n    /** Retrieve the write concern error if one exists */\n    getWriteConcernError() {\n        if (this.result.writeConcernErrors.length === 0) {\n            return;\n        }\n        else if (this.result.writeConcernErrors.length === 1) {\n            // Return the error\n            return this.result.writeConcernErrors[0];\n        }\n        else {\n            // Combine the errors\n            let errmsg = '';\n            for (let i = 0; i < this.result.writeConcernErrors.length; i++) {\n                const err = this.result.writeConcernErrors[i];\n                errmsg = errmsg + err.errmsg;\n                // TODO: Something better\n                if (i === 0)\n                    errmsg = errmsg + ' and ';\n            }\n            return new WriteConcernError({ errmsg, code: error_1.MONGODB_ERROR_CODES.WriteConcernFailed });\n        }\n    }\n    toString() {\n        return `BulkWriteResult(${this.result})`;\n    }\n    isOk() {\n        return this.result.ok === 1;\n    }\n}\nexports.BulkWriteResult = BulkWriteResult;\n/**\n * An error representing a failure by the server to apply the requested write concern to the bulk operation.\n * @public\n * @category Error\n */\nclass WriteConcernError {\n    constructor(error) {\n        this[kServerError] = error;\n    }\n    /** Write concern error code. */\n    get code() {\n        return this[kServerError].code;\n    }\n    /** Write concern error message. */\n    get errmsg() {\n        return this[kServerError].errmsg;\n    }\n    /** Write concern error info. */\n    get errInfo() {\n        return this[kServerError].errInfo;\n    }\n    toJSON() {\n        return this[kServerError];\n    }\n    toString() {\n        return `WriteConcernError(${this.errmsg})`;\n    }\n}\nexports.WriteConcernError = WriteConcernError;\n/**\n * An error that occurred during a BulkWrite on the server.\n * @public\n * @category Error\n */\nclass WriteError {\n    constructor(err) {\n        this.err = err;\n    }\n    /** WriteError code. */\n    get code() {\n        return this.err.code;\n    }\n    /** WriteError original bulk operation index. */\n    get index() {\n        return this.err.index;\n    }\n    /** WriteError message. */\n    get errmsg() {\n        return this.err.errmsg;\n    }\n    /** WriteError details. */\n    get errInfo() {\n        return this.err.errInfo;\n    }\n    /** Returns the underlying operation that caused the error */\n    getOperation() {\n        return this.err.op;\n    }\n    toJSON() {\n        return { code: this.err.code, index: this.err.index, errmsg: this.err.errmsg, op: this.err.op };\n    }\n    toString() {\n        return `WriteError(${JSON.stringify(this.toJSON())})`;\n    }\n}\nexports.WriteError = WriteError;\n/** Merges results into shared data structure */\nfunction mergeBatchResults(batch, bulkResult, err, result) {\n    // If we have an error set the result to be the err object\n    if (err) {\n        result = err;\n    }\n    else if (result && result.result) {\n        result = result.result;\n    }\n    if (result == null) {\n        return;\n    }\n    // Do we have a top level error stop processing and return\n    if (result.ok === 0 && bulkResult.ok === 1) {\n        bulkResult.ok = 0;\n        const writeError = {\n            index: 0,\n            code: result.code || 0,\n            errmsg: result.message,\n            errInfo: result.errInfo,\n            op: batch.operations[0]\n        };\n        bulkResult.writeErrors.push(new WriteError(writeError));\n        return;\n    }\n    else if (result.ok === 0 && bulkResult.ok === 0) {\n        return;\n    }\n    // If we have an insert Batch type\n    if (isInsertBatch(batch) && result.n) {\n        bulkResult.nInserted = bulkResult.nInserted + result.n;\n    }\n    // If we have an insert Batch type\n    if (isDeleteBatch(batch) && result.n) {\n        bulkResult.nRemoved = bulkResult.nRemoved + result.n;\n    }\n    let nUpserted = 0;\n    // We have an array of upserted values, we need to rewrite the indexes\n    if (Array.isArray(result.upserted)) {\n        nUpserted = result.upserted.length;\n        for (let i = 0; i < result.upserted.length; i++) {\n            bulkResult.upserted.push({\n                index: result.upserted[i].index + batch.originalZeroIndex,\n                _id: result.upserted[i]._id\n            });\n        }\n    }\n    else if (result.upserted) {\n        nUpserted = 1;\n        bulkResult.upserted.push({\n            index: batch.originalZeroIndex,\n            _id: result.upserted\n        });\n    }\n    // If we have an update Batch type\n    if (isUpdateBatch(batch) && result.n) {\n        const nModified = result.nModified;\n        bulkResult.nUpserted = bulkResult.nUpserted + nUpserted;\n        bulkResult.nMatched = bulkResult.nMatched + (result.n - nUpserted);\n        if (typeof nModified === 'number') {\n            bulkResult.nModified = bulkResult.nModified + nModified;\n        }\n        else {\n            bulkResult.nModified = 0;\n        }\n    }\n    if (Array.isArray(result.writeErrors)) {\n        for (let i = 0; i < result.writeErrors.length; i++) {\n            const writeError = {\n                index: batch.originalIndexes[result.writeErrors[i].index],\n                code: result.writeErrors[i].code,\n                errmsg: result.writeErrors[i].errmsg,\n                errInfo: result.writeErrors[i].errInfo,\n                op: batch.operations[result.writeErrors[i].index]\n            };\n            bulkResult.writeErrors.push(new WriteError(writeError));\n        }\n    }\n    if (result.writeConcernError) {\n        bulkResult.writeConcernErrors.push(new WriteConcernError(result.writeConcernError));\n    }\n}\nexports.mergeBatchResults = mergeBatchResults;\nfunction executeCommands(bulkOperation, options, callback) {\n    if (bulkOperation.s.batches.length === 0) {\n        return callback(undefined, new BulkWriteResult(bulkOperation.s.bulkResult, bulkOperation.isOrdered));\n    }\n    const batch = bulkOperation.s.batches.shift();\n    function resultHandler(err, result) {\n        // Error is a driver related error not a bulk op error, return early\n        if (err && 'message' in err && !(err instanceof error_1.MongoWriteConcernError)) {\n            return callback(new MongoBulkWriteError(err, new BulkWriteResult(bulkOperation.s.bulkResult, bulkOperation.isOrdered)));\n        }\n        if (err instanceof error_1.MongoWriteConcernError) {\n            return handleMongoWriteConcernError(batch, bulkOperation.s.bulkResult, bulkOperation.isOrdered, err, callback);\n        }\n        // Merge the results together\n        mergeBatchResults(batch, bulkOperation.s.bulkResult, err, result);\n        const writeResult = new BulkWriteResult(bulkOperation.s.bulkResult, bulkOperation.isOrdered);\n        if (bulkOperation.handleWriteError(callback, writeResult))\n            return;\n        // Execute the next command in line\n        executeCommands(bulkOperation, options, callback);\n    }\n    const finalOptions = (0, utils_2.resolveOptions)(bulkOperation, {\n        ...options,\n        ordered: bulkOperation.isOrdered\n    });\n    if (finalOptions.bypassDocumentValidation !== true) {\n        delete finalOptions.bypassDocumentValidation;\n    }\n    // Set an operationIf if provided\n    if (bulkOperation.operationId) {\n        resultHandler.operationId = bulkOperation.operationId;\n    }\n    // Is the bypassDocumentValidation options specific\n    if (bulkOperation.s.bypassDocumentValidation === true) {\n        finalOptions.bypassDocumentValidation = true;\n    }\n    // Is the checkKeys option disabled\n    if (bulkOperation.s.checkKeys === false) {\n        finalOptions.checkKeys = false;\n    }\n    if (finalOptions.retryWrites) {\n        if (isUpdateBatch(batch)) {\n            finalOptions.retryWrites = finalOptions.retryWrites && !batch.operations.some(op => op.multi);\n        }\n        if (isDeleteBatch(batch)) {\n            finalOptions.retryWrites =\n                finalOptions.retryWrites && !batch.operations.some(op => op.limit === 0);\n        }\n    }\n    try {\n        const operation = isInsertBatch(batch)\n            ? new insert_1.InsertOperation(bulkOperation.s.namespace, batch.operations, finalOptions)\n            : isUpdateBatch(batch)\n                ? new update_1.UpdateOperation(bulkOperation.s.namespace, batch.operations, finalOptions)\n                : isDeleteBatch(batch)\n                    ? new delete_1.DeleteOperation(bulkOperation.s.namespace, batch.operations, finalOptions)\n                    : null;\n        if (operation != null) {\n            // eslint-disable-next-line github/no-then\n            (0, execute_operation_1.executeOperation)(bulkOperation.s.collection.client, operation).then(result => resultHandler(undefined, result), error => resultHandler(error));\n        }\n    }\n    catch (err) {\n        // Force top level error\n        err.ok = 0;\n        // Merge top level error and return\n        mergeBatchResults(batch, bulkOperation.s.bulkResult, err, undefined);\n        callback();\n    }\n}\nfunction handleMongoWriteConcernError(batch, bulkResult, isOrdered, err, callback) {\n    mergeBatchResults(batch, bulkResult, undefined, err.result);\n    callback(new MongoBulkWriteError({\n        message: err.result?.writeConcernError.errmsg,\n        code: err.result?.writeConcernError.result\n    }, new BulkWriteResult(bulkResult, isOrdered)));\n}\n/**\n * An error indicating an unsuccessful Bulk Write\n * @public\n * @category Error\n */\nclass MongoBulkWriteError extends error_1.MongoServerError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(error, result) {\n        super(error);\n        this.writeErrors = [];\n        if (error instanceof WriteConcernError)\n            this.err = error;\n        else if (!(error instanceof Error)) {\n            this.message = error.message;\n            this.code = error.code;\n            this.writeErrors = error.writeErrors ?? [];\n        }\n        this.result = result;\n        Object.assign(this, error);\n    }\n    get name() {\n        return 'MongoBulkWriteError';\n    }\n    /** Number of documents inserted. */\n    get insertedCount() {\n        return this.result.insertedCount;\n    }\n    /** Number of documents matched for update. */\n    get matchedCount() {\n        return this.result.matchedCount;\n    }\n    /** Number of documents modified. */\n    get modifiedCount() {\n        return this.result.modifiedCount;\n    }\n    /** Number of documents deleted. */\n    get deletedCount() {\n        return this.result.deletedCount;\n    }\n    /** Number of documents upserted. */\n    get upsertedCount() {\n        return this.result.upsertedCount;\n    }\n    /** Inserted document generated Id's, hash key is the index of the originating operation */\n    get insertedIds() {\n        return this.result.insertedIds;\n    }\n    /** Upserted document generated Id's, hash key is the index of the originating operation */\n    get upsertedIds() {\n        return this.result.upsertedIds;\n    }\n}\nexports.MongoBulkWriteError = MongoBulkWriteError;\n/**\n * A builder object that is returned from {@link BulkOperationBase#find}.\n * Is used to build a write operation that involves a query filter.\n *\n * @public\n */\nclass FindOperators {\n    /**\n     * Creates a new FindOperators object.\n     * @internal\n     */\n    constructor(bulkOperation) {\n        this.bulkOperation = bulkOperation;\n    }\n    /** Add a multiple update operation to the bulk operation */\n    update(updateDocument) {\n        const currentOp = buildCurrentOp(this.bulkOperation);\n        return this.bulkOperation.addToOperationsList(exports.BatchType.UPDATE, (0, update_1.makeUpdateStatement)(currentOp.selector, updateDocument, {\n            ...currentOp,\n            multi: true\n        }));\n    }\n    /** Add a single update operation to the bulk operation */\n    updateOne(updateDocument) {\n        if (!(0, utils_2.hasAtomicOperators)(updateDocument)) {\n            throw new error_1.MongoInvalidArgumentError('Update document requires atomic operators');\n        }\n        const currentOp = buildCurrentOp(this.bulkOperation);\n        return this.bulkOperation.addToOperationsList(exports.BatchType.UPDATE, (0, update_1.makeUpdateStatement)(currentOp.selector, updateDocument, { ...currentOp, multi: false }));\n    }\n    /** Add a replace one operation to the bulk operation */\n    replaceOne(replacement) {\n        if ((0, utils_2.hasAtomicOperators)(replacement)) {\n            throw new error_1.MongoInvalidArgumentError('Replacement document must not use atomic operators');\n        }\n        const currentOp = buildCurrentOp(this.bulkOperation);\n        return this.bulkOperation.addToOperationsList(exports.BatchType.UPDATE, (0, update_1.makeUpdateStatement)(currentOp.selector, replacement, { ...currentOp, multi: false }));\n    }\n    /** Add a delete one operation to the bulk operation */\n    deleteOne() {\n        const currentOp = buildCurrentOp(this.bulkOperation);\n        return this.bulkOperation.addToOperationsList(exports.BatchType.DELETE, (0, delete_1.makeDeleteStatement)(currentOp.selector, { ...currentOp, limit: 1 }));\n    }\n    /** Add a delete many operation to the bulk operation */\n    delete() {\n        const currentOp = buildCurrentOp(this.bulkOperation);\n        return this.bulkOperation.addToOperationsList(exports.BatchType.DELETE, (0, delete_1.makeDeleteStatement)(currentOp.selector, { ...currentOp, limit: 0 }));\n    }\n    /** Upsert modifier for update bulk operation, noting that this operation is an upsert. */\n    upsert() {\n        if (!this.bulkOperation.s.currentOp) {\n            this.bulkOperation.s.currentOp = {};\n        }\n        this.bulkOperation.s.currentOp.upsert = true;\n        return this;\n    }\n    /** Specifies the collation for the query condition. */\n    collation(collation) {\n        if (!this.bulkOperation.s.currentOp) {\n            this.bulkOperation.s.currentOp = {};\n        }\n        this.bulkOperation.s.currentOp.collation = collation;\n        return this;\n    }\n    /** Specifies arrayFilters for UpdateOne or UpdateMany bulk operations. */\n    arrayFilters(arrayFilters) {\n        if (!this.bulkOperation.s.currentOp) {\n            this.bulkOperation.s.currentOp = {};\n        }\n        this.bulkOperation.s.currentOp.arrayFilters = arrayFilters;\n        return this;\n    }\n    /** Specifies hint for the bulk operation. */\n    hint(hint) {\n        if (!this.bulkOperation.s.currentOp) {\n            this.bulkOperation.s.currentOp = {};\n        }\n        this.bulkOperation.s.currentOp.hint = hint;\n        return this;\n    }\n}\nexports.FindOperators = FindOperators;\nconst executeCommandsAsync = (0, util_1.promisify)(executeCommands);\n/**\n * TODO(NODE-4063)\n * BulkWrites merge complexity is implemented in executeCommands\n * This provides a vehicle to treat bulkOperations like any other operation (hence \"shim\")\n * We would like this logic to simply live inside the BulkWriteOperation class\n * @internal\n */\nclass BulkWriteShimOperation extends operation_1.AbstractOperation {\n    constructor(bulkOperation, options) {\n        super(options);\n        this.bulkOperation = bulkOperation;\n    }\n    get commandName() {\n        return 'bulkWrite';\n    }\n    execute(_server, session) {\n        if (this.options.session == null) {\n            // An implicit session could have been created by 'executeOperation'\n            // So if we stick it on finalOptions here, each bulk operation\n            // will use this same session, it'll be passed in the same way\n            // an explicit session would be\n            this.options.session = session;\n        }\n        return executeCommandsAsync(this.bulkOperation, this.options);\n    }\n}\nexports.BulkWriteShimOperation = BulkWriteShimOperation;\n/** @public */\nclass BulkOperationBase {\n    /**\n     * Create a new OrderedBulkOperation or UnorderedBulkOperation instance\n     * @internal\n     */\n    constructor(collection, options, isOrdered) {\n        this.collection = collection;\n        // determine whether bulkOperation is ordered or unordered\n        this.isOrdered = isOrdered;\n        const topology = (0, utils_2.getTopology)(collection);\n        options = options == null ? {} : options;\n        // TODO Bring from driver information in hello\n        // Get the namespace for the write operations\n        const namespace = collection.s.namespace;\n        // Used to mark operation as executed\n        const executed = false;\n        // Current item\n        const currentOp = undefined;\n        // Set max byte size\n        const hello = topology.lastHello();\n        // If we have autoEncryption on, batch-splitting must be done on 2mb chunks, but single documents\n        // over 2mb are still allowed\n        const usingAutoEncryption = !!(topology.s.options && topology.s.options.autoEncrypter);\n        const maxBsonObjectSize = hello && hello.maxBsonObjectSize ? hello.maxBsonObjectSize : 1024 * 1024 * 16;\n        const maxBatchSizeBytes = usingAutoEncryption ? 1024 * 1024 * 2 : maxBsonObjectSize;\n        const maxWriteBatchSize = hello && hello.maxWriteBatchSize ? hello.maxWriteBatchSize : 1000;\n        // Calculates the largest possible size of an Array key, represented as a BSON string\n        // element. This calculation:\n        //     1 byte for BSON type\n        //     # of bytes = length of (string representation of (maxWriteBatchSize - 1))\n        //   + 1 bytes for null terminator\n        const maxKeySize = (maxWriteBatchSize - 1).toString(10).length + 2;\n        // Final options for retryable writes\n        let finalOptions = Object.assign({}, options);\n        finalOptions = (0, utils_2.applyRetryableWrites)(finalOptions, collection.s.db);\n        // Final results\n        const bulkResult = {\n            ok: 1,\n            writeErrors: [],\n            writeConcernErrors: [],\n            insertedIds: [],\n            nInserted: 0,\n            nUpserted: 0,\n            nMatched: 0,\n            nModified: 0,\n            nRemoved: 0,\n            upserted: []\n        };\n        // Internal state\n        this.s = {\n            // Final result\n            bulkResult,\n            // Current batch state\n            currentBatch: undefined,\n            currentIndex: 0,\n            // ordered specific\n            currentBatchSize: 0,\n            currentBatchSizeBytes: 0,\n            // unordered specific\n            currentInsertBatch: undefined,\n            currentUpdateBatch: undefined,\n            currentRemoveBatch: undefined,\n            batches: [],\n            // Write concern\n            writeConcern: write_concern_1.WriteConcern.fromOptions(options),\n            // Max batch size options\n            maxBsonObjectSize,\n            maxBatchSizeBytes,\n            maxWriteBatchSize,\n            maxKeySize,\n            // Namespace\n            namespace,\n            // Topology\n            topology,\n            // Options\n            options: finalOptions,\n            // BSON options\n            bsonOptions: (0, bson_1.resolveBSONOptions)(options),\n            // Current operation\n            currentOp,\n            // Executed\n            executed,\n            // Collection\n            collection,\n            // Fundamental error\n            err: undefined,\n            // check keys\n            checkKeys: typeof options.checkKeys === 'boolean' ? options.checkKeys : false\n        };\n        // bypass Validation\n        if (options.bypassDocumentValidation === true) {\n            this.s.bypassDocumentValidation = true;\n        }\n    }\n    /**\n     * Add a single insert document to the bulk operation\n     *\n     * @example\n     * ```ts\n     * const bulkOp = collection.initializeOrderedBulkOp();\n     *\n     * // Adds three inserts to the bulkOp.\n     * bulkOp\n     *   .insert({ a: 1 })\n     *   .insert({ b: 2 })\n     *   .insert({ c: 3 });\n     * await bulkOp.execute();\n     * ```\n     */\n    insert(document) {\n        (0, utils_1.maybeAddIdToDocuments)(this.collection, document, {\n            forceServerObjectId: this.shouldForceServerObjectId()\n        });\n        return this.addToOperationsList(exports.BatchType.INSERT, document);\n    }\n    /**\n     * Builds a find operation for an update/updateOne/delete/deleteOne/replaceOne.\n     * Returns a builder object used to complete the definition of the operation.\n     *\n     * @example\n     * ```ts\n     * const bulkOp = collection.initializeOrderedBulkOp();\n     *\n     * // Add an updateOne to the bulkOp\n     * bulkOp.find({ a: 1 }).updateOne({ $set: { b: 2 } });\n     *\n     * // Add an updateMany to the bulkOp\n     * bulkOp.find({ c: 3 }).update({ $set: { d: 4 } });\n     *\n     * // Add an upsert\n     * bulkOp.find({ e: 5 }).upsert().updateOne({ $set: { f: 6 } });\n     *\n     * // Add a deletion\n     * bulkOp.find({ g: 7 }).deleteOne();\n     *\n     * // Add a multi deletion\n     * bulkOp.find({ h: 8 }).delete();\n     *\n     * // Add a replaceOne\n     * bulkOp.find({ i: 9 }).replaceOne({writeConcern: { j: 10 }});\n     *\n     * // Update using a pipeline (requires Mongodb 4.2 or higher)\n     * bulk.find({ k: 11, y: { $exists: true }, z: { $exists: true } }).updateOne([\n     *   { $set: { total: { $sum: [ '$y', '$z' ] } } }\n     * ]);\n     *\n     * // All of the ops will now be executed\n     * await bulkOp.execute();\n     * ```\n     */\n    find(selector) {\n        if (!selector) {\n            throw new error_1.MongoInvalidArgumentError('Bulk find operation must specify a selector');\n        }\n        // Save a current selector\n        this.s.currentOp = {\n            selector: selector\n        };\n        return new FindOperators(this);\n    }\n    /** Specifies a raw operation to perform in the bulk write. */\n    raw(op) {\n        if (op == null || typeof op !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('Operation must be an object with an operation key');\n        }\n        if ('insertOne' in op) {\n            const forceServerObjectId = this.shouldForceServerObjectId();\n            const document = op.insertOne && op.insertOne.document == null\n                ? // TODO(NODE-6003): remove support for omitting the `documents` subdocument in bulk inserts\n                    op.insertOne\n                : op.insertOne.document;\n            (0, utils_1.maybeAddIdToDocuments)(this.collection, document, { forceServerObjectId });\n            return this.addToOperationsList(exports.BatchType.INSERT, document);\n        }\n        if ('replaceOne' in op || 'updateOne' in op || 'updateMany' in op) {\n            if ('replaceOne' in op) {\n                if ('q' in op.replaceOne) {\n                    throw new error_1.MongoInvalidArgumentError('Raw operations are not allowed');\n                }\n                const updateStatement = (0, update_1.makeUpdateStatement)(op.replaceOne.filter, op.replaceOne.replacement, { ...op.replaceOne, multi: false });\n                if ((0, utils_2.hasAtomicOperators)(updateStatement.u)) {\n                    throw new error_1.MongoInvalidArgumentError('Replacement document must not use atomic operators');\n                }\n                return this.addToOperationsList(exports.BatchType.UPDATE, updateStatement);\n            }\n            if ('updateOne' in op) {\n                if ('q' in op.updateOne) {\n                    throw new error_1.MongoInvalidArgumentError('Raw operations are not allowed');\n                }\n                const updateStatement = (0, update_1.makeUpdateStatement)(op.updateOne.filter, op.updateOne.update, {\n                    ...op.updateOne,\n                    multi: false\n                });\n                if (!(0, utils_2.hasAtomicOperators)(updateStatement.u)) {\n                    throw new error_1.MongoInvalidArgumentError('Update document requires atomic operators');\n                }\n                return this.addToOperationsList(exports.BatchType.UPDATE, updateStatement);\n            }\n            if ('updateMany' in op) {\n                if ('q' in op.updateMany) {\n                    throw new error_1.MongoInvalidArgumentError('Raw operations are not allowed');\n                }\n                const updateStatement = (0, update_1.makeUpdateStatement)(op.updateMany.filter, op.updateMany.update, {\n                    ...op.updateMany,\n                    multi: true\n                });\n                if (!(0, utils_2.hasAtomicOperators)(updateStatement.u)) {\n                    throw new error_1.MongoInvalidArgumentError('Update document requires atomic operators');\n                }\n                return this.addToOperationsList(exports.BatchType.UPDATE, updateStatement);\n            }\n        }\n        if ('deleteOne' in op) {\n            if ('q' in op.deleteOne) {\n                throw new error_1.MongoInvalidArgumentError('Raw operations are not allowed');\n            }\n            return this.addToOperationsList(exports.BatchType.DELETE, (0, delete_1.makeDeleteStatement)(op.deleteOne.filter, { ...op.deleteOne, limit: 1 }));\n        }\n        if ('deleteMany' in op) {\n            if ('q' in op.deleteMany) {\n                throw new error_1.MongoInvalidArgumentError('Raw operations are not allowed');\n            }\n            return this.addToOperationsList(exports.BatchType.DELETE, (0, delete_1.makeDeleteStatement)(op.deleteMany.filter, { ...op.deleteMany, limit: 0 }));\n        }\n        // otherwise an unknown operation was provided\n        throw new error_1.MongoInvalidArgumentError('bulkWrite only supports insertOne, updateOne, updateMany, deleteOne, deleteMany');\n    }\n    get bsonOptions() {\n        return this.s.bsonOptions;\n    }\n    get writeConcern() {\n        return this.s.writeConcern;\n    }\n    get batches() {\n        const batches = [...this.s.batches];\n        if (this.isOrdered) {\n            if (this.s.currentBatch)\n                batches.push(this.s.currentBatch);\n        }\n        else {\n            if (this.s.currentInsertBatch)\n                batches.push(this.s.currentInsertBatch);\n            if (this.s.currentUpdateBatch)\n                batches.push(this.s.currentUpdateBatch);\n            if (this.s.currentRemoveBatch)\n                batches.push(this.s.currentRemoveBatch);\n        }\n        return batches;\n    }\n    async execute(options = {}) {\n        if (this.s.executed) {\n            throw new error_1.MongoBatchReExecutionError();\n        }\n        const writeConcern = write_concern_1.WriteConcern.fromOptions(options);\n        if (writeConcern) {\n            this.s.writeConcern = writeConcern;\n        }\n        // If we have current batch\n        if (this.isOrdered) {\n            if (this.s.currentBatch)\n                this.s.batches.push(this.s.currentBatch);\n        }\n        else {\n            if (this.s.currentInsertBatch)\n                this.s.batches.push(this.s.currentInsertBatch);\n            if (this.s.currentUpdateBatch)\n                this.s.batches.push(this.s.currentUpdateBatch);\n            if (this.s.currentRemoveBatch)\n                this.s.batches.push(this.s.currentRemoveBatch);\n        }\n        // If we have no operations in the bulk raise an error\n        if (this.s.batches.length === 0) {\n            throw new error_1.MongoInvalidArgumentError('Invalid BulkOperation, Batch cannot be empty');\n        }\n        this.s.executed = true;\n        const finalOptions = { ...this.s.options, ...options };\n        const operation = new BulkWriteShimOperation(this, finalOptions);\n        return await (0, execute_operation_1.executeOperation)(this.s.collection.client, operation);\n    }\n    /**\n     * Handles the write error before executing commands\n     * @internal\n     */\n    handleWriteError(callback, writeResult) {\n        if (this.s.bulkResult.writeErrors.length > 0) {\n            const msg = this.s.bulkResult.writeErrors[0].errmsg\n                ? this.s.bulkResult.writeErrors[0].errmsg\n                : 'write operation failed';\n            callback(new MongoBulkWriteError({\n                message: msg,\n                code: this.s.bulkResult.writeErrors[0].code,\n                writeErrors: this.s.bulkResult.writeErrors\n            }, writeResult));\n            return true;\n        }\n        const writeConcernError = writeResult.getWriteConcernError();\n        if (writeConcernError) {\n            callback(new MongoBulkWriteError(writeConcernError, writeResult));\n            return true;\n        }\n        return false;\n    }\n    shouldForceServerObjectId() {\n        return (this.s.options.forceServerObjectId === true ||\n            this.s.collection.s.db.options?.forceServerObjectId === true);\n    }\n}\nexports.BulkOperationBase = BulkOperationBase;\nObject.defineProperty(BulkOperationBase.prototype, 'length', {\n    enumerable: true,\n    get() {\n        return this.s.currentIndex;\n    }\n});\nfunction isInsertBatch(batch) {\n    return batch.batchType === exports.BatchType.INSERT;\n}\nfunction isUpdateBatch(batch) {\n    return batch.batchType === exports.BatchType.UPDATE;\n}\nfunction isDeleteBatch(batch) {\n    return batch.batchType === exports.BatchType.DELETE;\n}\nfunction buildCurrentOp(bulkOp) {\n    let { currentOp } = bulkOp.s;\n    bulkOp.s.currentOp = undefined;\n    if (!currentOp)\n        currentOp = {};\n    return currentOp;\n}\n//# sourceMappingURL=common.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/bulk/common.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/bulk/ordered.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/bulk/ordered.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.OrderedBulkOperation = void 0;\nconst BSON = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst common_1 = __webpack_require__(/*! ./common */ \"./node_modules/mongodb/lib/bulk/common.js\");\n/** @public */\nclass OrderedBulkOperation extends common_1.BulkOperationBase {\n    /** @internal */\n    constructor(collection, options) {\n        super(collection, options, true);\n    }\n    addToOperationsList(batchType, document) {\n        // Get the bsonSize\n        const bsonSize = BSON.calculateObjectSize(document, {\n            checkKeys: false,\n            // Since we don't know what the user selected for BSON options here,\n            // err on the safe side, and check the size with ignoreUndefined: false.\n            ignoreUndefined: false\n        });\n        // Throw error if the doc is bigger than the max BSON size\n        if (bsonSize >= this.s.maxBsonObjectSize)\n            // TODO(NODE-3483): Change this to MongoBSONError\n            throw new error_1.MongoInvalidArgumentError(`Document is larger than the maximum size ${this.s.maxBsonObjectSize}`);\n        // Create a new batch object if we don't have a current one\n        if (this.s.currentBatch == null) {\n            this.s.currentBatch = new common_1.Batch(batchType, this.s.currentIndex);\n        }\n        const maxKeySize = this.s.maxKeySize;\n        // Check if we need to create a new batch\n        if (\n        // New batch if we exceed the max batch op size\n        this.s.currentBatchSize + 1 >= this.s.maxWriteBatchSize ||\n            // New batch if we exceed the maxBatchSizeBytes. Only matters if batch already has a doc,\n            // since we can't sent an empty batch\n            (this.s.currentBatchSize > 0 &&\n                this.s.currentBatchSizeBytes + maxKeySize + bsonSize >= this.s.maxBatchSizeBytes) ||\n            // New batch if the new op does not have the same op type as the current batch\n            this.s.currentBatch.batchType !== batchType) {\n            // Save the batch to the execution stack\n            this.s.batches.push(this.s.currentBatch);\n            // Create a new batch\n            this.s.currentBatch = new common_1.Batch(batchType, this.s.currentIndex);\n            // Reset the current size trackers\n            this.s.currentBatchSize = 0;\n            this.s.currentBatchSizeBytes = 0;\n        }\n        if (batchType === common_1.BatchType.INSERT) {\n            this.s.bulkResult.insertedIds.push({\n                index: this.s.currentIndex,\n                _id: document._id\n            });\n        }\n        // We have an array of documents\n        if (Array.isArray(document)) {\n            throw new error_1.MongoInvalidArgumentError('Operation passed in cannot be an Array');\n        }\n        this.s.currentBatch.originalIndexes.push(this.s.currentIndex);\n        this.s.currentBatch.operations.push(document);\n        this.s.currentBatchSize += 1;\n        this.s.currentBatchSizeBytes += maxKeySize + bsonSize;\n        this.s.currentIndex += 1;\n        return this;\n    }\n}\nexports.OrderedBulkOperation = OrderedBulkOperation;\n//# sourceMappingURL=ordered.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/bulk/ordered.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/bulk/unordered.js":
/*!****************************************************!*\
  !*** ./node_modules/mongodb/lib/bulk/unordered.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.UnorderedBulkOperation = void 0;\nconst BSON = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst common_1 = __webpack_require__(/*! ./common */ \"./node_modules/mongodb/lib/bulk/common.js\");\n/** @public */\nclass UnorderedBulkOperation extends common_1.BulkOperationBase {\n    /** @internal */\n    constructor(collection, options) {\n        super(collection, options, false);\n    }\n    handleWriteError(callback, writeResult) {\n        if (this.s.batches.length) {\n            return false;\n        }\n        return super.handleWriteError(callback, writeResult);\n    }\n    addToOperationsList(batchType, document) {\n        // Get the bsonSize\n        const bsonSize = BSON.calculateObjectSize(document, {\n            checkKeys: false,\n            // Since we don't know what the user selected for BSON options here,\n            // err on the safe side, and check the size with ignoreUndefined: false.\n            ignoreUndefined: false\n        });\n        // Throw error if the doc is bigger than the max BSON size\n        if (bsonSize >= this.s.maxBsonObjectSize) {\n            // TODO(NODE-3483): Change this to MongoBSONError\n            throw new error_1.MongoInvalidArgumentError(`Document is larger than the maximum size ${this.s.maxBsonObjectSize}`);\n        }\n        // Holds the current batch\n        this.s.currentBatch = undefined;\n        // Get the right type of batch\n        if (batchType === common_1.BatchType.INSERT) {\n            this.s.currentBatch = this.s.currentInsertBatch;\n        }\n        else if (batchType === common_1.BatchType.UPDATE) {\n            this.s.currentBatch = this.s.currentUpdateBatch;\n        }\n        else if (batchType === common_1.BatchType.DELETE) {\n            this.s.currentBatch = this.s.currentRemoveBatch;\n        }\n        const maxKeySize = this.s.maxKeySize;\n        // Create a new batch object if we don't have a current one\n        if (this.s.currentBatch == null) {\n            this.s.currentBatch = new common_1.Batch(batchType, this.s.currentIndex);\n        }\n        // Check if we need to create a new batch\n        if (\n        // New batch if we exceed the max batch op size\n        this.s.currentBatch.size + 1 >= this.s.maxWriteBatchSize ||\n            // New batch if we exceed the maxBatchSizeBytes. Only matters if batch already has a doc,\n            // since we can't sent an empty batch\n            (this.s.currentBatch.size > 0 &&\n                this.s.currentBatch.sizeBytes + maxKeySize + bsonSize >= this.s.maxBatchSizeBytes) ||\n            // New batch if the new op does not have the same op type as the current batch\n            this.s.currentBatch.batchType !== batchType) {\n            // Save the batch to the execution stack\n            this.s.batches.push(this.s.currentBatch);\n            // Create a new batch\n            this.s.currentBatch = new common_1.Batch(batchType, this.s.currentIndex);\n        }\n        // We have an array of documents\n        if (Array.isArray(document)) {\n            throw new error_1.MongoInvalidArgumentError('Operation passed in cannot be an Array');\n        }\n        this.s.currentBatch.operations.push(document);\n        this.s.currentBatch.originalIndexes.push(this.s.currentIndex);\n        this.s.currentIndex = this.s.currentIndex + 1;\n        // Save back the current Batch to the right type\n        if (batchType === common_1.BatchType.INSERT) {\n            this.s.currentInsertBatch = this.s.currentBatch;\n            this.s.bulkResult.insertedIds.push({\n                index: this.s.bulkResult.insertedIds.length,\n                _id: document._id\n            });\n        }\n        else if (batchType === common_1.BatchType.UPDATE) {\n            this.s.currentUpdateBatch = this.s.currentBatch;\n        }\n        else if (batchType === common_1.BatchType.DELETE) {\n            this.s.currentRemoveBatch = this.s.currentBatch;\n        }\n        // Update current batch size\n        this.s.currentBatch.size += 1;\n        this.s.currentBatch.sizeBytes += maxKeySize + bsonSize;\n        return this;\n    }\n}\nexports.UnorderedBulkOperation = UnorderedBulkOperation;\n//# sourceMappingURL=unordered.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/bulk/unordered.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/change_stream.js":
/*!***************************************************!*\
  !*** ./node_modules/mongodb/lib/change_stream.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ChangeStream = void 0;\nconst collection_1 = __webpack_require__(/*! ./collection */ \"./node_modules/mongodb/lib/collection.js\");\nconst constants_1 = __webpack_require__(/*! ./constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst change_stream_cursor_1 = __webpack_require__(/*! ./cursor/change_stream_cursor */ \"./node_modules/mongodb/lib/cursor/change_stream_cursor.js\");\nconst db_1 = __webpack_require__(/*! ./db */ \"./node_modules/mongodb/lib/db.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_client_1 = __webpack_require__(/*! ./mongo_client */ \"./node_modules/mongodb/lib/mongo_client.js\");\nconst mongo_types_1 = __webpack_require__(/*! ./mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/mongodb/lib/utils.js\");\n/** @internal */\nconst kCursorStream = Symbol('cursorStream');\n/** @internal */\nconst kClosed = Symbol('closed');\n/** @internal */\nconst kMode = Symbol('mode');\nconst CHANGE_STREAM_OPTIONS = [\n    'resumeAfter',\n    'startAfter',\n    'startAtOperationTime',\n    'fullDocument',\n    'fullDocumentBeforeChange',\n    'showExpandedEvents'\n];\nconst CHANGE_DOMAIN_TYPES = {\n    COLLECTION: Symbol('Collection'),\n    DATABASE: Symbol('Database'),\n    CLUSTER: Symbol('Cluster')\n};\nconst CHANGE_STREAM_EVENTS = [constants_1.RESUME_TOKEN_CHANGED, constants_1.END, constants_1.CLOSE];\nconst NO_RESUME_TOKEN_ERROR = 'A change stream document has been received that lacks a resume token (_id).';\nconst CHANGESTREAM_CLOSED_ERROR = 'ChangeStream is closed';\n/**\n * Creates a new Change Stream instance. Normally created using {@link Collection#watch|Collection.watch()}.\n * @public\n */\nclass ChangeStream extends mongo_types_1.TypedEventEmitter {\n    /**\n     * @internal\n     *\n     * @param parent - The parent object that created this change stream\n     * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents\n     */\n    constructor(parent, pipeline = [], options = {}) {\n        super();\n        this.pipeline = pipeline;\n        this.options = { ...options };\n        delete this.options.writeConcern;\n        if (parent instanceof collection_1.Collection) {\n            this.type = CHANGE_DOMAIN_TYPES.COLLECTION;\n        }\n        else if (parent instanceof db_1.Db) {\n            this.type = CHANGE_DOMAIN_TYPES.DATABASE;\n        }\n        else if (parent instanceof mongo_client_1.MongoClient) {\n            this.type = CHANGE_DOMAIN_TYPES.CLUSTER;\n        }\n        else {\n            throw new error_1.MongoChangeStreamError('Parent provided to ChangeStream constructor must be an instance of Collection, Db, or MongoClient');\n        }\n        this.parent = parent;\n        this.namespace = parent.s.namespace;\n        if (!this.options.readPreference && parent.readPreference) {\n            this.options.readPreference = parent.readPreference;\n        }\n        // Create contained Change Stream cursor\n        this.cursor = this._createChangeStreamCursor(options);\n        this[kClosed] = false;\n        this[kMode] = false;\n        // Listen for any `change` listeners being added to ChangeStream\n        this.on('newListener', eventName => {\n            if (eventName === 'change' && this.cursor && this.listenerCount('change') === 0) {\n                this._streamEvents(this.cursor);\n            }\n        });\n        this.on('removeListener', eventName => {\n            if (eventName === 'change' && this.listenerCount('change') === 0 && this.cursor) {\n                this[kCursorStream]?.removeAllListeners('data');\n            }\n        });\n    }\n    /** @internal */\n    get cursorStream() {\n        return this[kCursorStream];\n    }\n    /** The cached resume token that is used to resume after the most recently returned change. */\n    get resumeToken() {\n        return this.cursor?.resumeToken;\n    }\n    /** Check if there is any document still available in the Change Stream */\n    async hasNext() {\n        this._setIsIterator();\n        // Change streams must resume indefinitely while each resume event succeeds.\n        // This loop continues until either a change event is received or until a resume attempt\n        // fails.\n        // eslint-disable-next-line no-constant-condition\n        while (true) {\n            try {\n                const hasNext = await this.cursor.hasNext();\n                return hasNext;\n            }\n            catch (error) {\n                try {\n                    await this._processErrorIteratorMode(error);\n                }\n                catch (error) {\n                    try {\n                        await this.close();\n                    }\n                    catch (error) {\n                        (0, utils_1.squashError)(error);\n                    }\n                    throw error;\n                }\n            }\n        }\n    }\n    /** Get the next available document from the Change Stream. */\n    async next() {\n        this._setIsIterator();\n        // Change streams must resume indefinitely while each resume event succeeds.\n        // This loop continues until either a change event is received or until a resume attempt\n        // fails.\n        // eslint-disable-next-line no-constant-condition\n        while (true) {\n            try {\n                const change = await this.cursor.next();\n                const processedChange = this._processChange(change ?? null);\n                return processedChange;\n            }\n            catch (error) {\n                try {\n                    await this._processErrorIteratorMode(error);\n                }\n                catch (error) {\n                    try {\n                        await this.close();\n                    }\n                    catch (error) {\n                        (0, utils_1.squashError)(error);\n                    }\n                    throw error;\n                }\n            }\n        }\n    }\n    /**\n     * Try to get the next available document from the Change Stream's cursor or `null` if an empty batch is returned\n     */\n    async tryNext() {\n        this._setIsIterator();\n        // Change streams must resume indefinitely while each resume event succeeds.\n        // This loop continues until either a change event is received or until a resume attempt\n        // fails.\n        // eslint-disable-next-line no-constant-condition\n        while (true) {\n            try {\n                const change = await this.cursor.tryNext();\n                return change ?? null;\n            }\n            catch (error) {\n                try {\n                    await this._processErrorIteratorMode(error);\n                }\n                catch (error) {\n                    try {\n                        await this.close();\n                    }\n                    catch (error) {\n                        (0, utils_1.squashError)(error);\n                    }\n                    throw error;\n                }\n            }\n        }\n    }\n    async *[Symbol.asyncIterator]() {\n        if (this.closed) {\n            return;\n        }\n        try {\n            // Change streams run indefinitely as long as errors are resumable\n            // So the only loop breaking condition is if `next()` throws\n            while (true) {\n                yield await this.next();\n            }\n        }\n        finally {\n            try {\n                await this.close();\n            }\n            catch (error) {\n                (0, utils_1.squashError)(error);\n            }\n        }\n    }\n    /** Is the cursor closed */\n    get closed() {\n        return this[kClosed] || this.cursor.closed;\n    }\n    /** Close the Change Stream */\n    async close() {\n        this[kClosed] = true;\n        const cursor = this.cursor;\n        try {\n            await cursor.close();\n        }\n        finally {\n            this._endStream();\n        }\n    }\n    /**\n     * Return a modified Readable stream including a possible transform method.\n     *\n     * NOTE: When using a Stream to process change stream events, the stream will\n     * NOT automatically resume in the case a resumable error is encountered.\n     *\n     * @throws MongoChangeStreamError if the underlying cursor or the change stream is closed\n     */\n    stream(options) {\n        if (this.closed) {\n            throw new error_1.MongoChangeStreamError(CHANGESTREAM_CLOSED_ERROR);\n        }\n        this.streamOptions = options;\n        return this.cursor.stream(options);\n    }\n    /** @internal */\n    _setIsEmitter() {\n        if (this[kMode] === 'iterator') {\n            // TODO(NODE-3485): Replace with MongoChangeStreamModeError\n            throw new error_1.MongoAPIError('ChangeStream cannot be used as an EventEmitter after being used as an iterator');\n        }\n        this[kMode] = 'emitter';\n    }\n    /** @internal */\n    _setIsIterator() {\n        if (this[kMode] === 'emitter') {\n            // TODO(NODE-3485): Replace with MongoChangeStreamModeError\n            throw new error_1.MongoAPIError('ChangeStream cannot be used as an iterator after being used as an EventEmitter');\n        }\n        this[kMode] = 'iterator';\n    }\n    /**\n     * Create a new change stream cursor based on self's configuration\n     * @internal\n     */\n    _createChangeStreamCursor(options) {\n        const changeStreamStageOptions = (0, utils_1.filterOptions)(options, CHANGE_STREAM_OPTIONS);\n        if (this.type === CHANGE_DOMAIN_TYPES.CLUSTER) {\n            changeStreamStageOptions.allChangesForCluster = true;\n        }\n        const pipeline = [{ $changeStream: changeStreamStageOptions }, ...this.pipeline];\n        const client = this.type === CHANGE_DOMAIN_TYPES.CLUSTER\n            ? this.parent\n            : this.type === CHANGE_DOMAIN_TYPES.DATABASE\n                ? this.parent.client\n                : this.type === CHANGE_DOMAIN_TYPES.COLLECTION\n                    ? this.parent.client\n                    : null;\n        if (client == null) {\n            // This should never happen because of the assertion in the constructor\n            throw new error_1.MongoRuntimeError(`Changestream type should only be one of cluster, database, collection. Found ${this.type.toString()}`);\n        }\n        const changeStreamCursor = new change_stream_cursor_1.ChangeStreamCursor(client, this.namespace, pipeline, options);\n        for (const event of CHANGE_STREAM_EVENTS) {\n            changeStreamCursor.on(event, e => this.emit(event, e));\n        }\n        if (this.listenerCount(ChangeStream.CHANGE) > 0) {\n            this._streamEvents(changeStreamCursor);\n        }\n        return changeStreamCursor;\n    }\n    /** @internal */\n    _closeEmitterModeWithError(error) {\n        this.emit(ChangeStream.ERROR, error);\n        // eslint-disable-next-line github/no-then\n        this.close().then(undefined, utils_1.squashError);\n    }\n    /** @internal */\n    _streamEvents(cursor) {\n        this._setIsEmitter();\n        const stream = this[kCursorStream] ?? cursor.stream();\n        this[kCursorStream] = stream;\n        stream.on('data', change => {\n            try {\n                const processedChange = this._processChange(change);\n                this.emit(ChangeStream.CHANGE, processedChange);\n            }\n            catch (error) {\n                this.emit(ChangeStream.ERROR, error);\n            }\n        });\n        stream.on('error', error => this._processErrorStreamMode(error));\n    }\n    /** @internal */\n    _endStream() {\n        const cursorStream = this[kCursorStream];\n        if (cursorStream) {\n            ['data', 'close', 'end', 'error'].forEach(event => cursorStream.removeAllListeners(event));\n            cursorStream.destroy();\n        }\n        this[kCursorStream] = undefined;\n    }\n    /** @internal */\n    _processChange(change) {\n        if (this[kClosed]) {\n            // TODO(NODE-3485): Replace with MongoChangeStreamClosedError\n            throw new error_1.MongoAPIError(CHANGESTREAM_CLOSED_ERROR);\n        }\n        // a null change means the cursor has been notified, implicitly closing the change stream\n        if (change == null) {\n            // TODO(NODE-3485): Replace with MongoChangeStreamClosedError\n            throw new error_1.MongoRuntimeError(CHANGESTREAM_CLOSED_ERROR);\n        }\n        if (change && !change._id) {\n            throw new error_1.MongoChangeStreamError(NO_RESUME_TOKEN_ERROR);\n        }\n        // cache the resume token\n        this.cursor.cacheResumeToken(change._id);\n        // wipe the startAtOperationTime if there was one so that there won't be a conflict\n        // between resumeToken and startAtOperationTime if we need to reconnect the cursor\n        this.options.startAtOperationTime = undefined;\n        return change;\n    }\n    /** @internal */\n    _processErrorStreamMode(changeStreamError) {\n        // If the change stream has been closed explicitly, do not process error.\n        if (this[kClosed])\n            return;\n        if ((0, error_1.isResumableError)(changeStreamError, this.cursor.maxWireVersion)) {\n            this._endStream();\n            // eslint-disable-next-line github/no-then\n            this.cursor.close().then(undefined, utils_1.squashError);\n            const topology = (0, utils_1.getTopology)(this.parent);\n            topology\n                .selectServer(this.cursor.readPreference, {\n                operationName: 'reconnect topology in change stream'\n            })\n                // eslint-disable-next-line github/no-then\n                .then(() => {\n                this.cursor = this._createChangeStreamCursor(this.cursor.resumeOptions);\n            }, () => this._closeEmitterModeWithError(changeStreamError));\n        }\n        else {\n            this._closeEmitterModeWithError(changeStreamError);\n        }\n    }\n    /** @internal */\n    async _processErrorIteratorMode(changeStreamError) {\n        if (this[kClosed]) {\n            // TODO(NODE-3485): Replace with MongoChangeStreamClosedError\n            throw new error_1.MongoAPIError(CHANGESTREAM_CLOSED_ERROR);\n        }\n        if (!(0, error_1.isResumableError)(changeStreamError, this.cursor.maxWireVersion)) {\n            try {\n                await this.close();\n            }\n            catch (error) {\n                (0, utils_1.squashError)(error);\n            }\n            throw changeStreamError;\n        }\n        try {\n            await this.cursor.close();\n        }\n        catch (error) {\n            (0, utils_1.squashError)(error);\n        }\n        const topology = (0, utils_1.getTopology)(this.parent);\n        try {\n            await topology.selectServer(this.cursor.readPreference, {\n                operationName: 'reconnect topology in change stream'\n            });\n            this.cursor = this._createChangeStreamCursor(this.cursor.resumeOptions);\n        }\n        catch {\n            // if the topology can't reconnect, close the stream\n            await this.close();\n            throw changeStreamError;\n        }\n    }\n}\n/** @event */\nChangeStream.RESPONSE = constants_1.RESPONSE;\n/** @event */\nChangeStream.MORE = constants_1.MORE;\n/** @event */\nChangeStream.INIT = constants_1.INIT;\n/** @event */\nChangeStream.CLOSE = constants_1.CLOSE;\n/**\n * Fired for each new matching change in the specified namespace. Attaching a `change`\n * event listener to a Change Stream will switch the stream into flowing mode. Data will\n * then be passed as soon as it is available.\n * @event\n */\nChangeStream.CHANGE = constants_1.CHANGE;\n/** @event */\nChangeStream.END = constants_1.END;\n/** @event */\nChangeStream.ERROR = constants_1.ERROR;\n/**\n * Emitted each time the change stream stores a new resume token.\n * @event\n */\nChangeStream.RESUME_TOKEN_CHANGED = constants_1.RESUME_TOKEN_CHANGED;\nexports.ChangeStream = ChangeStream;\n//# sourceMappingURL=change_stream.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/change_stream.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/auto_encrypter.js":
/*!***************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/auto_encrypter.js ***!
  \***************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nvar _a;\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AutoEncrypter = exports.AutoEncryptionLoggerLevel = void 0;\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst deps_1 = __webpack_require__(/*! ../deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_client_1 = __webpack_require__(/*! ../mongo_client */ \"./node_modules/mongodb/lib/mongo_client.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst cryptoCallbacks = __webpack_require__(/*! ./crypto_callbacks */ \"./node_modules/mongodb/lib/client-side-encryption/crypto_callbacks.js\");\nconst errors_1 = __webpack_require__(/*! ./errors */ \"./node_modules/mongodb/lib/client-side-encryption/errors.js\");\nconst mongocryptd_manager_1 = __webpack_require__(/*! ./mongocryptd_manager */ \"./node_modules/mongodb/lib/client-side-encryption/mongocryptd_manager.js\");\nconst providers_1 = __webpack_require__(/*! ./providers */ \"./node_modules/mongodb/lib/client-side-encryption/providers/index.js\");\nconst state_machine_1 = __webpack_require__(/*! ./state_machine */ \"./node_modules/mongodb/lib/client-side-encryption/state_machine.js\");\n/** @public */\nexports.AutoEncryptionLoggerLevel = Object.freeze({\n    FatalError: 0,\n    Error: 1,\n    Warning: 2,\n    Info: 3,\n    Trace: 4\n});\n// Typescript errors if we index objects with `Symbol.for(...)`, so\n// to avoid TS errors we pull them out into variables.  Then we can type\n// the objects (and class) that we expect to see them on and prevent TS\n// errors.\n/** @internal */\nconst kDecorateResult = Symbol.for('@@mdb.decorateDecryptionResult');\n/** @internal */\nconst kDecoratedKeys = Symbol.for('@@mdb.decryptedKeys');\n/**\n * @internal An internal class to be used by the driver for auto encryption\n * **NOTE**: Not meant to be instantiated directly, this is for internal use only.\n */\nclass AutoEncrypter {\n    /** @internal */\n    static getMongoCrypt() {\n        const encryption = (0, deps_1.getMongoDBClientEncryption)();\n        if ('kModuleError' in encryption) {\n            throw encryption.kModuleError;\n        }\n        return encryption.MongoCrypt;\n    }\n    /**\n     * Create an AutoEncrypter\n     *\n     * **Note**: Do not instantiate this class directly. Rather, supply the relevant options to a MongoClient\n     *\n     * **Note**: Supplying `options.schemaMap` provides more security than relying on JSON Schemas obtained from the server.\n     * It protects against a malicious server advertising a false JSON Schema, which could trick the client into sending unencrypted data that should be encrypted.\n     * Schemas supplied in the schemaMap only apply to configuring automatic encryption for Client-Side Field Level Encryption.\n     * Other validation rules in the JSON schema will not be enforced by the driver and will result in an error.\n     *\n     * @example <caption>Create an AutoEncrypter that makes use of mongocryptd</caption>\n     * ```ts\n     * // Enabling autoEncryption via a MongoClient using mongocryptd\n     * const { MongoClient } = require('mongodb');\n     * const client = new MongoClient(URL, {\n     *   autoEncryption: {\n     *     kmsProviders: {\n     *       aws: {\n     *         accessKeyId: AWS_ACCESS_KEY,\n     *         secretAccessKey: AWS_SECRET_KEY\n     *       }\n     *     }\n     *   }\n     * });\n     * ```\n     *\n     * await client.connect();\n     * // From here on, the client will be encrypting / decrypting automatically\n     * @example <caption>Create an AutoEncrypter that makes use of libmongocrypt's CSFLE shared library</caption>\n     * ```ts\n     * // Enabling autoEncryption via a MongoClient using CSFLE shared library\n     * const { MongoClient } = require('mongodb');\n     * const client = new MongoClient(URL, {\n     *   autoEncryption: {\n     *     kmsProviders: {\n     *       aws: {}\n     *     },\n     *     extraOptions: {\n     *       cryptSharedLibPath: '/path/to/local/crypt/shared/lib',\n     *       cryptSharedLibRequired: true\n     *     }\n     *   }\n     * });\n     * ```\n     *\n     * await client.connect();\n     * // From here on, the client will be encrypting / decrypting automatically\n     */\n    constructor(client, options) {\n        /**\n         * Used by devtools to enable decorating decryption results.\n         *\n         * When set and enabled, `decrypt` will automatically recursively\n         * traverse a decrypted document and if a field has been decrypted,\n         * it will mark it as decrypted.  Compass uses this to determine which\n         * fields were decrypted.\n         */\n        this[_a] = false;\n        this._client = client;\n        this._bypassEncryption = options.bypassAutoEncryption === true;\n        this._keyVaultNamespace = options.keyVaultNamespace || 'admin.datakeys';\n        this._keyVaultClient = options.keyVaultClient || client;\n        this._metaDataClient = options.metadataClient || client;\n        this._proxyOptions = options.proxyOptions || {};\n        this._tlsOptions = options.tlsOptions || {};\n        this._kmsProviders = options.kmsProviders || {};\n        const mongoCryptOptions = {\n            cryptoCallbacks\n        };\n        if (options.schemaMap) {\n            mongoCryptOptions.schemaMap = Buffer.isBuffer(options.schemaMap)\n                ? options.schemaMap\n                : (0, bson_1.serialize)(options.schemaMap);\n        }\n        if (options.encryptedFieldsMap) {\n            mongoCryptOptions.encryptedFieldsMap = Buffer.isBuffer(options.encryptedFieldsMap)\n                ? options.encryptedFieldsMap\n                : (0, bson_1.serialize)(options.encryptedFieldsMap);\n        }\n        mongoCryptOptions.kmsProviders = !Buffer.isBuffer(this._kmsProviders)\n            ? (0, bson_1.serialize)(this._kmsProviders)\n            : this._kmsProviders;\n        if (options.options?.logger) {\n            mongoCryptOptions.logger = options.options.logger;\n        }\n        if (options.extraOptions && options.extraOptions.cryptSharedLibPath) {\n            mongoCryptOptions.cryptSharedLibPath = options.extraOptions.cryptSharedLibPath;\n        }\n        if (options.bypassQueryAnalysis) {\n            mongoCryptOptions.bypassQueryAnalysis = options.bypassQueryAnalysis;\n        }\n        this._bypassMongocryptdAndCryptShared = this._bypassEncryption || !!options.bypassQueryAnalysis;\n        if (options.extraOptions && options.extraOptions.cryptSharedLibSearchPaths) {\n            // Only for driver testing\n            mongoCryptOptions.cryptSharedLibSearchPaths = options.extraOptions.cryptSharedLibSearchPaths;\n        }\n        else if (!this._bypassMongocryptdAndCryptShared) {\n            mongoCryptOptions.cryptSharedLibSearchPaths = ['$SYSTEM'];\n        }\n        const MongoCrypt = AutoEncrypter.getMongoCrypt();\n        this._mongocrypt = new MongoCrypt(mongoCryptOptions);\n        this._contextCounter = 0;\n        if (options.extraOptions &&\n            options.extraOptions.cryptSharedLibRequired &&\n            !this.cryptSharedLibVersionInfo) {\n            throw new errors_1.MongoCryptInvalidArgumentError('`cryptSharedLibRequired` set but no crypt_shared library loaded');\n        }\n        // Only instantiate mongocryptd manager/client once we know for sure\n        // that we are not using the CSFLE shared library.\n        if (!this._bypassMongocryptdAndCryptShared && !this.cryptSharedLibVersionInfo) {\n            this._mongocryptdManager = new mongocryptd_manager_1.MongocryptdManager(options.extraOptions);\n            const clientOptions = {\n                serverSelectionTimeoutMS: 10000\n            };\n            if (options.extraOptions == null || typeof options.extraOptions.mongocryptdURI !== 'string') {\n                clientOptions.family = 4;\n            }\n            this._mongocryptdClient = new mongo_client_1.MongoClient(this._mongocryptdManager.uri, clientOptions);\n        }\n    }\n    /**\n     * Initializes the auto encrypter by spawning a mongocryptd and connecting to it.\n     *\n     * This function is a no-op when bypassSpawn is set or the crypt shared library is used.\n     */\n    async init() {\n        if (this._bypassMongocryptdAndCryptShared || this.cryptSharedLibVersionInfo) {\n            return;\n        }\n        if (!this._mongocryptdManager) {\n            throw new error_1.MongoRuntimeError('Reached impossible state: mongocryptdManager is undefined when neither bypassSpawn nor the shared lib are specified.');\n        }\n        if (!this._mongocryptdClient) {\n            throw new error_1.MongoRuntimeError('Reached impossible state: mongocryptdClient is undefined when neither bypassSpawn nor the shared lib are specified.');\n        }\n        if (!this._mongocryptdManager.bypassSpawn) {\n            await this._mongocryptdManager.spawn();\n        }\n        try {\n            const client = await this._mongocryptdClient.connect();\n            return client;\n        }\n        catch (error) {\n            const { message } = error;\n            if (message && (message.match(/timed out after/) || message.match(/ENOTFOUND/))) {\n                throw new error_1.MongoRuntimeError('Unable to connect to `mongocryptd`, please make sure it is running or in your PATH for auto-spawn', { cause: error });\n            }\n            throw error;\n        }\n    }\n    /**\n     * Cleans up the `_mongocryptdClient`, if present.\n     */\n    async teardown(force) {\n        await this._mongocryptdClient?.close(force);\n    }\n    /**\n     * Encrypt a command for a given namespace.\n     */\n    async encrypt(ns, cmd, options = {}) {\n        if (this._bypassEncryption) {\n            // If `bypassAutoEncryption` has been specified, don't encrypt\n            return cmd;\n        }\n        const commandBuffer = Buffer.isBuffer(cmd) ? cmd : (0, bson_1.serialize)(cmd, options);\n        const context = this._mongocrypt.makeEncryptionContext(utils_1.MongoDBCollectionNamespace.fromString(ns).db, commandBuffer);\n        context.id = this._contextCounter++;\n        context.ns = ns;\n        context.document = cmd;\n        const stateMachine = new state_machine_1.StateMachine({\n            promoteValues: false,\n            promoteLongs: false,\n            proxyOptions: this._proxyOptions,\n            tlsOptions: this._tlsOptions\n        });\n        return await stateMachine.execute(this, context);\n    }\n    /**\n     * Decrypt a command response\n     */\n    async decrypt(response, options = {}) {\n        const buffer = Buffer.isBuffer(response) ? response : (0, bson_1.serialize)(response, options);\n        const context = this._mongocrypt.makeDecryptionContext(buffer);\n        context.id = this._contextCounter++;\n        const stateMachine = new state_machine_1.StateMachine({\n            ...options,\n            proxyOptions: this._proxyOptions,\n            tlsOptions: this._tlsOptions\n        });\n        const decorateResult = this[kDecorateResult];\n        const result = await stateMachine.execute(this, context);\n        if (decorateResult) {\n            decorateDecryptionResult(result, response);\n        }\n        return result;\n    }\n    /**\n     * Ask the user for KMS credentials.\n     *\n     * This returns anything that looks like the kmsProviders original input\n     * option. It can be empty, and any provider specified here will override\n     * the original ones.\n     */\n    async askForKMSCredentials() {\n        return await (0, providers_1.refreshKMSCredentials)(this._kmsProviders);\n    }\n    /**\n     * Return the current libmongocrypt's CSFLE shared library version\n     * as `{ version: bigint, versionStr: string }`, or `null` if no CSFLE\n     * shared library was loaded.\n     */\n    get cryptSharedLibVersionInfo() {\n        return this._mongocrypt.cryptSharedLibVersionInfo;\n    }\n    static get libmongocryptVersion() {\n        return AutoEncrypter.getMongoCrypt().libmongocryptVersion;\n    }\n}\nexports.AutoEncrypter = AutoEncrypter;\n_a = kDecorateResult;\n/**\n * Recurse through the (identically-shaped) `decrypted` and `original`\n * objects and attach a `decryptedKeys` property on each sub-object that\n * contained encrypted fields. Because we only call this on BSON responses,\n * we do not need to worry about circular references.\n *\n * @internal\n */\nfunction decorateDecryptionResult(decrypted, original, isTopLevelDecorateCall = true) {\n    if (isTopLevelDecorateCall) {\n        // The original value could have been either a JS object or a BSON buffer\n        if (Buffer.isBuffer(original)) {\n            original = (0, bson_1.deserialize)(original);\n        }\n        if (Buffer.isBuffer(decrypted)) {\n            throw new error_1.MongoRuntimeError('Expected result of decryption to be deserialized BSON object');\n        }\n    }\n    if (!decrypted || typeof decrypted !== 'object')\n        return;\n    for (const k of Object.keys(decrypted)) {\n        const originalValue = original[k];\n        // An object was decrypted by libmongocrypt if and only if it was\n        // a BSON Binary object with subtype 6.\n        if (originalValue && originalValue._bsontype === 'Binary' && originalValue.sub_type === 6) {\n            if (!decrypted[kDecoratedKeys]) {\n                Object.defineProperty(decrypted, kDecoratedKeys, {\n                    value: [],\n                    configurable: true,\n                    enumerable: false,\n                    writable: false\n                });\n            }\n            // this is defined in the preceding if-statement\n            // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n            decrypted[kDecoratedKeys].push(k);\n            // Do not recurse into this decrypted value. It could be a sub-document/array,\n            // in which case there is no original value associated with its subfields.\n            continue;\n        }\n        decorateDecryptionResult(decrypted[k], originalValue, false);\n    }\n}\n//# sourceMappingURL=auto_encrypter.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/client-side-encryption/auto_encrypter.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/client_encryption.js":
/*!******************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/client_encryption.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ClientEncryption = void 0;\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst deps_1 = __webpack_require__(/*! ../deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst cryptoCallbacks = __webpack_require__(/*! ./crypto_callbacks */ \"./node_modules/mongodb/lib/client-side-encryption/crypto_callbacks.js\");\nconst errors_1 = __webpack_require__(/*! ./errors */ \"./node_modules/mongodb/lib/client-side-encryption/errors.js\");\nconst index_1 = __webpack_require__(/*! ./providers/index */ \"./node_modules/mongodb/lib/client-side-encryption/providers/index.js\");\nconst state_machine_1 = __webpack_require__(/*! ./state_machine */ \"./node_modules/mongodb/lib/client-side-encryption/state_machine.js\");\n/**\n * @public\n * The public interface for explicit in-use encryption\n */\nclass ClientEncryption {\n    /** @internal */\n    static getMongoCrypt() {\n        const encryption = (0, deps_1.getMongoDBClientEncryption)();\n        if ('kModuleError' in encryption) {\n            throw encryption.kModuleError;\n        }\n        return encryption.MongoCrypt;\n    }\n    /**\n     * Create a new encryption instance\n     *\n     * @example\n     * ```ts\n     * new ClientEncryption(mongoClient, {\n     *   keyVaultNamespace: 'client.encryption',\n     *   kmsProviders: {\n     *     local: {\n     *       key: masterKey // The master key used for encryption/decryption. A 96-byte long Buffer\n     *     }\n     *   }\n     * });\n     * ```\n     *\n     * @example\n     * ```ts\n     * new ClientEncryption(mongoClient, {\n     *   keyVaultNamespace: 'client.encryption',\n     *   kmsProviders: {\n     *     aws: {\n     *       accessKeyId: AWS_ACCESS_KEY,\n     *       secretAccessKey: AWS_SECRET_KEY\n     *     }\n     *   }\n     * });\n     * ```\n     */\n    constructor(client, options) {\n        this._client = client;\n        this._proxyOptions = options.proxyOptions ?? {};\n        this._tlsOptions = options.tlsOptions ?? {};\n        this._kmsProviders = options.kmsProviders || {};\n        if (options.keyVaultNamespace == null) {\n            throw new errors_1.MongoCryptInvalidArgumentError('Missing required option `keyVaultNamespace`');\n        }\n        const mongoCryptOptions = {\n            ...options,\n            cryptoCallbacks,\n            kmsProviders: !Buffer.isBuffer(this._kmsProviders)\n                ? (0, bson_1.serialize)(this._kmsProviders)\n                : this._kmsProviders\n        };\n        this._keyVaultNamespace = options.keyVaultNamespace;\n        this._keyVaultClient = options.keyVaultClient || client;\n        const MongoCrypt = ClientEncryption.getMongoCrypt();\n        this._mongoCrypt = new MongoCrypt(mongoCryptOptions);\n    }\n    /**\n     * Creates a data key used for explicit encryption and inserts it into the key vault namespace\n     *\n     * @example\n     * ```ts\n     * // Using async/await to create a local key\n     * const dataKeyId = await clientEncryption.createDataKey('local');\n     * ```\n     *\n     * @example\n     * ```ts\n     * // Using async/await to create an aws key\n     * const dataKeyId = await clientEncryption.createDataKey('aws', {\n     *   masterKey: {\n     *     region: 'us-east-1',\n     *     key: 'xxxxxxxxxxxxxx' // CMK ARN here\n     *   }\n     * });\n     * ```\n     *\n     * @example\n     * ```ts\n     * // Using async/await to create an aws key with a keyAltName\n     * const dataKeyId = await clientEncryption.createDataKey('aws', {\n     *   masterKey: {\n     *     region: 'us-east-1',\n     *     key: 'xxxxxxxxxxxxxx' // CMK ARN here\n     *   },\n     *   keyAltNames: [ 'mySpecialKey' ]\n     * });\n     * ```\n     */\n    async createDataKey(provider, options = {}) {\n        if (options.keyAltNames && !Array.isArray(options.keyAltNames)) {\n            throw new errors_1.MongoCryptInvalidArgumentError(`Option \"keyAltNames\" must be an array of strings, but was of type ${typeof options.keyAltNames}.`);\n        }\n        let keyAltNames = undefined;\n        if (options.keyAltNames && options.keyAltNames.length > 0) {\n            keyAltNames = options.keyAltNames.map((keyAltName, i) => {\n                if (typeof keyAltName !== 'string') {\n                    throw new errors_1.MongoCryptInvalidArgumentError(`Option \"keyAltNames\" must be an array of strings, but item at index ${i} was of type ${typeof keyAltName}`);\n                }\n                return (0, bson_1.serialize)({ keyAltName });\n            });\n        }\n        let keyMaterial = undefined;\n        if (options.keyMaterial) {\n            keyMaterial = (0, bson_1.serialize)({ keyMaterial: options.keyMaterial });\n        }\n        const dataKeyBson = (0, bson_1.serialize)({\n            provider,\n            ...options.masterKey\n        });\n        const context = this._mongoCrypt.makeDataKeyContext(dataKeyBson, {\n            keyAltNames,\n            keyMaterial\n        });\n        const stateMachine = new state_machine_1.StateMachine({\n            proxyOptions: this._proxyOptions,\n            tlsOptions: this._tlsOptions\n        });\n        const dataKey = await stateMachine.execute(this, context);\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);\n        const { insertedId } = await this._keyVaultClient\n            .db(dbName)\n            .collection(collectionName)\n            .insertOne(dataKey, { writeConcern: { w: 'majority' } });\n        return insertedId;\n    }\n    /**\n     * Searches the keyvault for any data keys matching the provided filter.  If there are matches, rewrapManyDataKey then attempts to re-wrap the data keys using the provided options.\n     *\n     * If no matches are found, then no bulk write is performed.\n     *\n     * @example\n     * ```ts\n     * // rewrapping all data data keys (using a filter that matches all documents)\n     * const filter = {};\n     *\n     * const result = await clientEncryption.rewrapManyDataKey(filter);\n     * if (result.bulkWriteResult != null) {\n     *  // keys were re-wrapped, results will be available in the bulkWrite object.\n     * }\n     * ```\n     *\n     * @example\n     * ```ts\n     * // attempting to rewrap all data keys with no matches\n     * const filter = { _id: new Binary() } // assume _id matches no documents in the database\n     * const result = await clientEncryption.rewrapManyDataKey(filter);\n     *\n     * if (result.bulkWriteResult == null) {\n     *  // no keys matched, `bulkWriteResult` does not exist on the result object\n     * }\n     * ```\n     */\n    async rewrapManyDataKey(filter, options) {\n        let keyEncryptionKeyBson = undefined;\n        if (options) {\n            const keyEncryptionKey = Object.assign({ provider: options.provider }, options.masterKey);\n            keyEncryptionKeyBson = (0, bson_1.serialize)(keyEncryptionKey);\n        }\n        const filterBson = (0, bson_1.serialize)(filter);\n        const context = this._mongoCrypt.makeRewrapManyDataKeyContext(filterBson, keyEncryptionKeyBson);\n        const stateMachine = new state_machine_1.StateMachine({\n            proxyOptions: this._proxyOptions,\n            tlsOptions: this._tlsOptions\n        });\n        const { v: dataKeys } = await stateMachine.execute(this, context);\n        if (dataKeys.length === 0) {\n            return {};\n        }\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);\n        const replacements = dataKeys.map((key) => ({\n            updateOne: {\n                filter: { _id: key._id },\n                update: {\n                    $set: {\n                        masterKey: key.masterKey,\n                        keyMaterial: key.keyMaterial\n                    },\n                    $currentDate: {\n                        updateDate: true\n                    }\n                }\n            }\n        }));\n        const result = await this._keyVaultClient\n            .db(dbName)\n            .collection(collectionName)\n            .bulkWrite(replacements, {\n            writeConcern: { w: 'majority' }\n        });\n        return { bulkWriteResult: result };\n    }\n    /**\n     * Deletes the key with the provided id from the keyvault, if it exists.\n     *\n     * @example\n     * ```ts\n     * // delete a key by _id\n     * const id = new Binary(); // id is a bson binary subtype 4 object\n     * const { deletedCount } = await clientEncryption.deleteKey(id);\n     *\n     * if (deletedCount != null && deletedCount > 0) {\n     *   // successful deletion\n     * }\n     * ```\n     *\n     */\n    async deleteKey(_id) {\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);\n        return await this._keyVaultClient\n            .db(dbName)\n            .collection(collectionName)\n            .deleteOne({ _id }, { writeConcern: { w: 'majority' } });\n    }\n    /**\n     * Finds all the keys currently stored in the keyvault.\n     *\n     * This method will not throw.\n     *\n     * @returns a FindCursor over all keys in the keyvault.\n     * @example\n     * ```ts\n     * // fetching all keys\n     * const keys = await clientEncryption.getKeys().toArray();\n     * ```\n     */\n    getKeys() {\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);\n        return this._keyVaultClient\n            .db(dbName)\n            .collection(collectionName)\n            .find({}, { readConcern: { level: 'majority' } });\n    }\n    /**\n     * Finds a key in the keyvault with the specified _id.\n     *\n     * Returns a promise that either resolves to a {@link DataKey} if a document matches the key or null if no documents\n     * match the id.  The promise rejects with an error if an error is thrown.\n     * @example\n     * ```ts\n     * // getting a key by id\n     * const id = new Binary(); // id is a bson binary subtype 4 object\n     * const key = await clientEncryption.getKey(id);\n     * if (!key) {\n     *  // key is null if there was no matching key\n     * }\n     * ```\n     */\n    async getKey(_id) {\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);\n        return await this._keyVaultClient\n            .db(dbName)\n            .collection(collectionName)\n            .findOne({ _id }, { readConcern: { level: 'majority' } });\n    }\n    /**\n     * Finds a key in the keyvault which has the specified keyAltName.\n     *\n     * @param keyAltName - a keyAltName to search for a key\n     * @returns Returns a promise that either resolves to a {@link DataKey} if a document matches the key or null if no documents\n     * match the keyAltName.  The promise rejects with an error if an error is thrown.\n     * @example\n     * ```ts\n     * // get a key by alt name\n     * const keyAltName = 'keyAltName';\n     * const key = await clientEncryption.getKeyByAltName(keyAltName);\n     * if (!key) {\n     *  // key is null if there is no matching key\n     * }\n     * ```\n     */\n    async getKeyByAltName(keyAltName) {\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);\n        return await this._keyVaultClient\n            .db(dbName)\n            .collection(collectionName)\n            .findOne({ keyAltNames: keyAltName }, { readConcern: { level: 'majority' } });\n    }\n    /**\n     * Adds a keyAltName to a key identified by the provided _id.\n     *\n     * This method resolves to/returns the *old* key value (prior to adding the new altKeyName).\n     *\n     * @param _id - The id of the document to update.\n     * @param keyAltName - a keyAltName to search for a key\n     * @returns Returns a promise that either resolves to a {@link DataKey} if a document matches the key or null if no documents\n     * match the id.  The promise rejects with an error if an error is thrown.\n     * @example\n     * ```ts\n     * // adding an keyAltName to a data key\n     * const id = new Binary();  // id is a bson binary subtype 4 object\n     * const keyAltName = 'keyAltName';\n     * const oldKey = await clientEncryption.addKeyAltName(id, keyAltName);\n     * if (!oldKey) {\n     *  // null is returned if there is no matching document with an id matching the supplied id\n     * }\n     * ```\n     */\n    async addKeyAltName(_id, keyAltName) {\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);\n        const value = await this._keyVaultClient\n            .db(dbName)\n            .collection(collectionName)\n            .findOneAndUpdate({ _id }, { $addToSet: { keyAltNames: keyAltName } }, { writeConcern: { w: 'majority' }, returnDocument: 'before' });\n        return value;\n    }\n    /**\n     * Adds a keyAltName to a key identified by the provided _id.\n     *\n     * This method resolves to/returns the *old* key value (prior to removing the new altKeyName).\n     *\n     * If the removed keyAltName is the last keyAltName for that key, the `altKeyNames` property is unset from the document.\n     *\n     * @param _id - The id of the document to update.\n     * @param keyAltName - a keyAltName to search for a key\n     * @returns Returns a promise that either resolves to a {@link DataKey} if a document matches the key or null if no documents\n     * match the id.  The promise rejects with an error if an error is thrown.\n     * @example\n     * ```ts\n     * // removing a key alt name from a data key\n     * const id = new Binary();  // id is a bson binary subtype 4 object\n     * const keyAltName = 'keyAltName';\n     * const oldKey = await clientEncryption.removeKeyAltName(id, keyAltName);\n     *\n     * if (!oldKey) {\n     *  // null is returned if there is no matching document with an id matching the supplied id\n     * }\n     * ```\n     */\n    async removeKeyAltName(_id, keyAltName) {\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);\n        const pipeline = [\n            {\n                $set: {\n                    keyAltNames: {\n                        $cond: [\n                            {\n                                $eq: ['$keyAltNames', [keyAltName]]\n                            },\n                            '$$REMOVE',\n                            {\n                                $filter: {\n                                    input: '$keyAltNames',\n                                    cond: {\n                                        $ne: ['$$this', keyAltName]\n                                    }\n                                }\n                            }\n                        ]\n                    }\n                }\n            }\n        ];\n        const value = await this._keyVaultClient\n            .db(dbName)\n            .collection(collectionName)\n            .findOneAndUpdate({ _id }, pipeline, {\n            writeConcern: { w: 'majority' },\n            returnDocument: 'before'\n        });\n        return value;\n    }\n    /**\n     * A convenience method for creating an encrypted collection.\n     * This method will create data keys for any encryptedFields that do not have a `keyId` defined\n     * and then create a new collection with the full set of encryptedFields.\n     *\n     * @param db - A Node.js driver Db object with which to create the collection\n     * @param name - The name of the collection to be created\n     * @param options - Options for createDataKey and for createCollection\n     * @returns created collection and generated encryptedFields\n     * @throws MongoCryptCreateDataKeyError - If part way through the process a createDataKey invocation fails, an error will be rejected that has the partial `encryptedFields` that were created.\n     * @throws MongoCryptCreateEncryptedCollectionError - If creating the collection fails, an error will be rejected that has the entire `encryptedFields` that were created.\n     */\n    async createEncryptedCollection(db, name, options) {\n        const { provider, masterKey, createCollectionOptions: { encryptedFields: { ...encryptedFields }, ...createCollectionOptions } } = options;\n        if (Array.isArray(encryptedFields.fields)) {\n            const createDataKeyPromises = encryptedFields.fields.map(async (field) => field == null || typeof field !== 'object' || field.keyId != null\n                ? field\n                : {\n                    ...field,\n                    keyId: await this.createDataKey(provider, { masterKey })\n                });\n            const createDataKeyResolutions = await Promise.allSettled(createDataKeyPromises);\n            encryptedFields.fields = createDataKeyResolutions.map((resolution, index) => resolution.status === 'fulfilled' ? resolution.value : encryptedFields.fields[index]);\n            const rejection = createDataKeyResolutions.find((result) => result.status === 'rejected');\n            if (rejection != null) {\n                throw new errors_1.MongoCryptCreateDataKeyError(encryptedFields, { cause: rejection.reason });\n            }\n        }\n        try {\n            const collection = await db.createCollection(name, {\n                ...createCollectionOptions,\n                encryptedFields\n            });\n            return { collection, encryptedFields };\n        }\n        catch (cause) {\n            throw new errors_1.MongoCryptCreateEncryptedCollectionError(encryptedFields, { cause });\n        }\n    }\n    /**\n     * Explicitly encrypt a provided value. Note that either `options.keyId` or `options.keyAltName` must\n     * be specified. Specifying both `options.keyId` and `options.keyAltName` is considered an error.\n     *\n     * @param value - The value that you wish to serialize. Must be of a type that can be serialized into BSON\n     * @param options -\n     * @returns a Promise that either resolves with the encrypted value, or rejects with an error.\n     *\n     * @example\n     * ```ts\n     * // Encryption with async/await api\n     * async function encryptMyData(value) {\n     *   const keyId = await clientEncryption.createDataKey('local');\n     *   return clientEncryption.encrypt(value, { keyId, algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic' });\n     * }\n     * ```\n     *\n     * @example\n     * ```ts\n     * // Encryption using a keyAltName\n     * async function encryptMyData(value) {\n     *   await clientEncryption.createDataKey('local', { keyAltNames: 'mySpecialKey' });\n     *   return clientEncryption.encrypt(value, { keyAltName: 'mySpecialKey', algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic' });\n     * }\n     * ```\n     */\n    async encrypt(value, options) {\n        return await this._encrypt(value, false, options);\n    }\n    /**\n     * Encrypts a Match Expression or Aggregate Expression to query a range index.\n     *\n     * Only supported when queryType is \"rangePreview\" and algorithm is \"RangePreview\".\n     *\n     * @experimental The Range algorithm is experimental only. It is not intended for production use. It is subject to breaking changes.\n     *\n     * @param expression - a BSON document of one of the following forms:\n     *  1. A Match Expression of this form:\n     *      `{$and: [{<field>: {$gt: <value1>}}, {<field>: {$lt: <value2> }}]}`\n     *  2. An Aggregate Expression of this form:\n     *      `{$and: [{$gt: [<fieldpath>, <value1>]}, {$lt: [<fieldpath>, <value2>]}]}`\n     *\n     *    `$gt` may also be `$gte`. `$lt` may also be `$lte`.\n     *\n     * @param options -\n     * @returns Returns a Promise that either resolves with the encrypted value or rejects with an error.\n     */\n    async encryptExpression(expression, options) {\n        return await this._encrypt(expression, true, options);\n    }\n    /**\n     * Explicitly decrypt a provided encrypted value\n     *\n     * @param value - An encrypted value\n     * @returns a Promise that either resolves with the decrypted value, or rejects with an error\n     *\n     * @example\n     * ```ts\n     * // Decrypting value with async/await API\n     * async function decryptMyValue(value) {\n     *   return clientEncryption.decrypt(value);\n     * }\n     * ```\n     */\n    async decrypt(value) {\n        const valueBuffer = (0, bson_1.serialize)({ v: value });\n        const context = this._mongoCrypt.makeExplicitDecryptionContext(valueBuffer);\n        const stateMachine = new state_machine_1.StateMachine({\n            proxyOptions: this._proxyOptions,\n            tlsOptions: this._tlsOptions\n        });\n        const { v } = await stateMachine.execute(this, context);\n        return v;\n    }\n    /**\n     * @internal\n     * Ask the user for KMS credentials.\n     *\n     * This returns anything that looks like the kmsProviders original input\n     * option. It can be empty, and any provider specified here will override\n     * the original ones.\n     */\n    async askForKMSCredentials() {\n        return await (0, index_1.refreshKMSCredentials)(this._kmsProviders);\n    }\n    static get libmongocryptVersion() {\n        return ClientEncryption.getMongoCrypt().libmongocryptVersion;\n    }\n    /**\n     * @internal\n     * A helper that perform explicit encryption of values and expressions.\n     * Explicitly encrypt a provided value. Note that either `options.keyId` or `options.keyAltName` must\n     * be specified. Specifying both `options.keyId` and `options.keyAltName` is considered an error.\n     *\n     * @param value - The value that you wish to encrypt. Must be of a type that can be serialized into BSON\n     * @param expressionMode - a boolean that indicates whether or not to encrypt the value as an expression\n     * @param options - options to pass to encrypt\n     * @returns the raw result of the call to stateMachine.execute().  When expressionMode is set to true, the return\n     *          value will be a bson document.  When false, the value will be a BSON Binary.\n     *\n     */\n    async _encrypt(value, expressionMode, options) {\n        const { algorithm, keyId, keyAltName, contentionFactor, queryType, rangeOptions } = options;\n        const contextOptions = {\n            expressionMode,\n            algorithm\n        };\n        if (keyId) {\n            contextOptions.keyId = keyId.buffer;\n        }\n        if (keyAltName) {\n            if (keyId) {\n                throw new errors_1.MongoCryptInvalidArgumentError(`\"options\" cannot contain both \"keyId\" and \"keyAltName\"`);\n            }\n            if (typeof keyAltName !== 'string') {\n                throw new errors_1.MongoCryptInvalidArgumentError(`\"options.keyAltName\" must be of type string, but was of type ${typeof keyAltName}`);\n            }\n            contextOptions.keyAltName = (0, bson_1.serialize)({ keyAltName });\n        }\n        if (typeof contentionFactor === 'number' || typeof contentionFactor === 'bigint') {\n            contextOptions.contentionFactor = contentionFactor;\n        }\n        if (typeof queryType === 'string') {\n            contextOptions.queryType = queryType;\n        }\n        if (typeof rangeOptions === 'object') {\n            contextOptions.rangeOptions = (0, bson_1.serialize)(rangeOptions);\n        }\n        const valueBuffer = (0, bson_1.serialize)({ v: value });\n        const stateMachine = new state_machine_1.StateMachine({\n            proxyOptions: this._proxyOptions,\n            tlsOptions: this._tlsOptions\n        });\n        const context = this._mongoCrypt.makeExplicitEncryptionContext(valueBuffer, contextOptions);\n        const result = await stateMachine.execute(this, context);\n        return result.v;\n    }\n}\nexports.ClientEncryption = ClientEncryption;\n//# sourceMappingURL=client_encryption.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/client-side-encryption/client_encryption.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/crypto_callbacks.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/crypto_callbacks.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.hmacSha256Hook = exports.hmacSha512Hook = exports.aes256CtrDecryptHook = exports.aes256CtrEncryptHook = exports.aes256CbcDecryptHook = exports.aes256CbcEncryptHook = exports.signRsaSha256Hook = exports.makeHmacHook = exports.sha256Hook = exports.randomHook = exports.makeAES256Hook = void 0;\nconst crypto = __webpack_require__(/*! crypto */ \"crypto\");\nfunction makeAES256Hook(method, mode) {\n    return function (key, iv, input, output) {\n        let result;\n        try {\n            const cipher = crypto[method](mode, key, iv);\n            cipher.setAutoPadding(false);\n            result = cipher.update(input);\n            const final = cipher.final();\n            if (final.length > 0) {\n                result = Buffer.concat([result, final]);\n            }\n        }\n        catch (e) {\n            return e;\n        }\n        result.copy(output);\n        return result.length;\n    };\n}\nexports.makeAES256Hook = makeAES256Hook;\nfunction randomHook(buffer, count) {\n    try {\n        crypto.randomFillSync(buffer, 0, count);\n    }\n    catch (e) {\n        return e;\n    }\n    return count;\n}\nexports.randomHook = randomHook;\nfunction sha256Hook(input, output) {\n    let result;\n    try {\n        result = crypto.createHash('sha256').update(input).digest();\n    }\n    catch (e) {\n        return e;\n    }\n    result.copy(output);\n    return result.length;\n}\nexports.sha256Hook = sha256Hook;\nfunction makeHmacHook(algorithm) {\n    return (key, input, output) => {\n        let result;\n        try {\n            result = crypto.createHmac(algorithm, key).update(input).digest();\n        }\n        catch (e) {\n            return e;\n        }\n        result.copy(output);\n        return result.length;\n    };\n}\nexports.makeHmacHook = makeHmacHook;\nfunction signRsaSha256Hook(key, input, output) {\n    let result;\n    try {\n        const signer = crypto.createSign('sha256WithRSAEncryption');\n        const privateKey = Buffer.from(`-----BEGIN PRIVATE KEY-----\\n${key.toString('base64')}\\n-----END PRIVATE KEY-----\\n`);\n        result = signer.update(input).end().sign(privateKey);\n    }\n    catch (e) {\n        return e;\n    }\n    result.copy(output);\n    return result.length;\n}\nexports.signRsaSha256Hook = signRsaSha256Hook;\nexports.aes256CbcEncryptHook = makeAES256Hook('createCipheriv', 'aes-256-cbc');\nexports.aes256CbcDecryptHook = makeAES256Hook('createDecipheriv', 'aes-256-cbc');\nexports.aes256CtrEncryptHook = makeAES256Hook('createCipheriv', 'aes-256-ctr');\nexports.aes256CtrDecryptHook = makeAES256Hook('createDecipheriv', 'aes-256-ctr');\nexports.hmacSha512Hook = makeHmacHook('sha512');\nexports.hmacSha256Hook = makeHmacHook('sha256');\n//# sourceMappingURL=crypto_callbacks.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/client-side-encryption/crypto_callbacks.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/errors.js":
/*!*******************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/errors.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoCryptKMSRequestNetworkTimeoutError = exports.MongoCryptAzureKMSRequestError = exports.MongoCryptCreateEncryptedCollectionError = exports.MongoCryptCreateDataKeyError = exports.MongoCryptInvalidArgumentError = exports.MongoCryptError = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\n/**\n * @public\n * An error indicating that something went wrong specifically with MongoDB Client Encryption\n */\nclass MongoCryptError extends error_1.MongoError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options = {}) {\n        super(message, options);\n    }\n    get name() {\n        return 'MongoCryptError';\n    }\n}\nexports.MongoCryptError = MongoCryptError;\n/**\n * @public\n *\n * An error indicating an invalid argument was provided to an encryption API.\n */\nclass MongoCryptInvalidArgumentError extends MongoCryptError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoCryptInvalidArgumentError';\n    }\n}\nexports.MongoCryptInvalidArgumentError = MongoCryptInvalidArgumentError;\n/**\n * @public\n * An error indicating that `ClientEncryption.createEncryptedCollection()` failed to create data keys\n */\nclass MongoCryptCreateDataKeyError extends MongoCryptError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(encryptedFields, { cause }) {\n        super(`Unable to complete creating data keys: ${cause.message}`, { cause });\n        this.encryptedFields = encryptedFields;\n    }\n    get name() {\n        return 'MongoCryptCreateDataKeyError';\n    }\n}\nexports.MongoCryptCreateDataKeyError = MongoCryptCreateDataKeyError;\n/**\n * @public\n * An error indicating that `ClientEncryption.createEncryptedCollection()` failed to create a collection\n */\nclass MongoCryptCreateEncryptedCollectionError extends MongoCryptError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(encryptedFields, { cause }) {\n        super(`Unable to create collection: ${cause.message}`, { cause });\n        this.encryptedFields = encryptedFields;\n    }\n    get name() {\n        return 'MongoCryptCreateEncryptedCollectionError';\n    }\n}\nexports.MongoCryptCreateEncryptedCollectionError = MongoCryptCreateEncryptedCollectionError;\n/**\n * @public\n * An error indicating that mongodb-client-encryption failed to auto-refresh Azure KMS credentials.\n */\nclass MongoCryptAzureKMSRequestError extends MongoCryptError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, body) {\n        super(message);\n        this.body = body;\n    }\n    get name() {\n        return 'MongoCryptAzureKMSRequestError';\n    }\n}\nexports.MongoCryptAzureKMSRequestError = MongoCryptAzureKMSRequestError;\n/** @public */\nclass MongoCryptKMSRequestNetworkTimeoutError extends MongoCryptError {\n    get name() {\n        return 'MongoCryptKMSRequestNetworkTimeoutError';\n    }\n}\nexports.MongoCryptKMSRequestNetworkTimeoutError = MongoCryptKMSRequestNetworkTimeoutError;\n//# sourceMappingURL=errors.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/client-side-encryption/errors.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/mongocryptd_manager.js":
/*!********************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/mongocryptd_manager.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongocryptdManager = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\n/**\n * @internal\n * An internal class that handles spawning a mongocryptd.\n */\nclass MongocryptdManager {\n    constructor(extraOptions = {}) {\n        this.uri =\n            typeof extraOptions.mongocryptdURI === 'string' && extraOptions.mongocryptdURI.length > 0\n                ? extraOptions.mongocryptdURI\n                : MongocryptdManager.DEFAULT_MONGOCRYPTD_URI;\n        this.bypassSpawn = !!extraOptions.mongocryptdBypassSpawn;\n        this.spawnPath = extraOptions.mongocryptdSpawnPath || '';\n        this.spawnArgs = [];\n        if (Array.isArray(extraOptions.mongocryptdSpawnArgs)) {\n            this.spawnArgs = this.spawnArgs.concat(extraOptions.mongocryptdSpawnArgs);\n        }\n        if (this.spawnArgs\n            .filter(arg => typeof arg === 'string')\n            .every(arg => arg.indexOf('--idleShutdownTimeoutSecs') < 0)) {\n            this.spawnArgs.push('--idleShutdownTimeoutSecs', '60');\n        }\n    }\n    /**\n     * Will check to see if a mongocryptd is up. If it is not up, it will attempt\n     * to spawn a mongocryptd in a detached process, and then wait for it to be up.\n     */\n    async spawn() {\n        const cmdName = this.spawnPath || 'mongocryptd';\n        // eslint-disable-next-line @typescript-eslint/no-var-requires\n        const { spawn } = __webpack_require__(/*! child_process */ \"child_process\");\n        // Spawned with stdio: ignore and detached: true\n        // to ensure child can outlive parent.\n        this._child = spawn(cmdName, this.spawnArgs, {\n            stdio: 'ignore',\n            detached: true\n        });\n        this._child.on('error', () => {\n            // From the FLE spec:\n            // \"The stdout and stderr of the spawned process MUST not be exposed in the driver\n            // (e.g. redirect to /dev/null). Users can pass the argument --logpath to\n            // extraOptions.mongocryptdSpawnArgs if they need to inspect mongocryptd logs.\n            // If spawning is necessary, the driver MUST spawn mongocryptd whenever server\n            // selection on the MongoClient to mongocryptd fails. If the MongoClient fails to\n            // connect after spawning, the server selection error is propagated to the user.\"\n            // The AutoEncrypter and MongoCryptdManager should work together to spawn\n            // mongocryptd whenever necessary.  Additionally, the `mongocryptd` intentionally\n            // shuts down after 60s and gets respawned when necessary.  We rely on server\n            // selection timeouts when connecting to the `mongocryptd` to inform users that something\n            // has been configured incorrectly.  For those reasons, we suppress stderr from\n            // the `mongocryptd` process and immediately unref the process.\n        });\n        // unref child to remove handle from event loop\n        this._child.unref();\n    }\n    /**\n     * @returns the result of `fn` or rejects with an error.\n     */\n    async withRespawn(fn) {\n        try {\n            const result = await fn();\n            return result;\n        }\n        catch (err) {\n            // If we are not bypassing spawning, then we should retry once on a MongoTimeoutError (server selection error)\n            const shouldSpawn = err instanceof error_1.MongoNetworkTimeoutError && !this.bypassSpawn;\n            if (!shouldSpawn) {\n                throw err;\n            }\n        }\n        await this.spawn();\n        const result = await fn();\n        return result;\n    }\n}\nMongocryptdManager.DEFAULT_MONGOCRYPTD_URI = 'mongodb://localhost:27020';\nexports.MongocryptdManager = MongocryptdManager;\n//# sourceMappingURL=mongocryptd_manager.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/client-side-encryption/mongocryptd_manager.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/providers/aws.js":
/*!**************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/providers/aws.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.loadAWSCredentials = void 0;\nconst aws_temporary_credentials_1 = __webpack_require__(/*! ../../cmap/auth/aws_temporary_credentials */ \"./node_modules/mongodb/lib/cmap/auth/aws_temporary_credentials.js\");\n/**\n * @internal\n */\nasync function loadAWSCredentials(kmsProviders) {\n    const credentialProvider = new aws_temporary_credentials_1.AWSSDKCredentialProvider();\n    // We shouldn't ever receive a response from the AWS SDK that doesn't have a `SecretAccessKey`\n    // or `AccessKeyId`.  However, TS says these fields are optional.  We provide empty strings\n    // and let libmongocrypt error if we're unable to fetch the required keys.\n    const { SecretAccessKey = '', AccessKeyId = '', Token } = await credentialProvider.getCredentials();\n    const aws = {\n        secretAccessKey: SecretAccessKey,\n        accessKeyId: AccessKeyId\n    };\n    // the AWS session token is only required for temporary credentials so only attach it to the\n    // result if it's present in the response from the aws sdk\n    Token != null && (aws.sessionToken = Token);\n    return { ...kmsProviders, aws };\n}\nexports.loadAWSCredentials = loadAWSCredentials;\n//# sourceMappingURL=aws.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/client-side-encryption/providers/aws.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/providers/azure.js":
/*!****************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/providers/azure.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.loadAzureCredentials = exports.fetchAzureKMSToken = exports.prepareRequest = exports.addAzureParams = exports.tokenCache = exports.AzureCredentialCache = exports.AZURE_BASE_URL = void 0;\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst errors_1 = __webpack_require__(/*! ../errors */ \"./node_modules/mongodb/lib/client-side-encryption/errors.js\");\nconst MINIMUM_TOKEN_REFRESH_IN_MILLISECONDS = 6000;\n/** Base URL for getting Azure tokens. */\nexports.AZURE_BASE_URL = 'http://169.254.169.254/metadata/identity/oauth2/token?';\n/**\n * @internal\n */\nclass AzureCredentialCache {\n    constructor() {\n        this.cachedToken = null;\n    }\n    async getToken() {\n        if (this.cachedToken == null || this.needsRefresh(this.cachedToken)) {\n            this.cachedToken = await this._getToken();\n        }\n        return { accessToken: this.cachedToken.accessToken };\n    }\n    needsRefresh(token) {\n        const timeUntilExpirationMS = token.expiresOnTimestamp - Date.now();\n        return timeUntilExpirationMS <= MINIMUM_TOKEN_REFRESH_IN_MILLISECONDS;\n    }\n    /**\n     * exposed for testing\n     */\n    resetCache() {\n        this.cachedToken = null;\n    }\n    /**\n     * exposed for testing\n     */\n    _getToken() {\n        return fetchAzureKMSToken();\n    }\n}\nexports.AzureCredentialCache = AzureCredentialCache;\n/** @internal */\nexports.tokenCache = new AzureCredentialCache();\n/** @internal */\nasync function parseResponse(response) {\n    const { status, body: rawBody } = response;\n    const body = (() => {\n        try {\n            return JSON.parse(rawBody);\n        }\n        catch {\n            throw new errors_1.MongoCryptAzureKMSRequestError('Malformed JSON body in GET request.');\n        }\n    })();\n    if (status !== 200) {\n        throw new errors_1.MongoCryptAzureKMSRequestError('Unable to complete request.', body);\n    }\n    if (!body.access_token) {\n        throw new errors_1.MongoCryptAzureKMSRequestError('Malformed response body - missing field `access_token`.');\n    }\n    if (!body.expires_in) {\n        throw new errors_1.MongoCryptAzureKMSRequestError('Malformed response body - missing field `expires_in`.');\n    }\n    const expiresInMS = Number(body.expires_in) * 1000;\n    if (Number.isNaN(expiresInMS)) {\n        throw new errors_1.MongoCryptAzureKMSRequestError('Malformed response body - unable to parse int from `expires_in` field.');\n    }\n    return {\n        accessToken: body.access_token,\n        expiresOnTimestamp: Date.now() + expiresInMS\n    };\n}\n/**\n * @internal\n * Get the Azure endpoint URL.\n */\nfunction addAzureParams(url, resource, username) {\n    url.searchParams.append('api-version', '2018-02-01');\n    url.searchParams.append('resource', resource);\n    if (username) {\n        url.searchParams.append('client_id', username);\n    }\n    return url;\n}\nexports.addAzureParams = addAzureParams;\n/**\n * @internal\n *\n * parses any options provided by prose tests to `fetchAzureKMSToken` and merges them with\n * the default values for headers and the request url.\n */\nfunction prepareRequest(options) {\n    const url = new URL(options.url?.toString() ?? exports.AZURE_BASE_URL);\n    addAzureParams(url, 'https://vault.azure.net');\n    const headers = { ...options.headers, 'Content-Type': 'application/json', Metadata: true };\n    return { headers, url };\n}\nexports.prepareRequest = prepareRequest;\n/**\n * @internal\n *\n * `AzureKMSRequestOptions` allows prose tests to modify the http request sent to the idms\n * servers.  This is required to simulate different server conditions.  No options are expected to\n * be set outside of tests.\n *\n * exposed for CSFLE\n * [prose test 18](https://github.com/mongodb/specifications/tree/master/source/client-side-encryption/tests#azure-imds-credentials)\n */\nasync function fetchAzureKMSToken(options = {}) {\n    const { headers, url } = prepareRequest(options);\n    try {\n        const response = await (0, utils_1.get)(url, { headers });\n        return await parseResponse(response);\n    }\n    catch (error) {\n        if (error instanceof error_1.MongoNetworkTimeoutError) {\n            throw new errors_1.MongoCryptAzureKMSRequestError(`[Azure KMS] ${error.message}`);\n        }\n        throw error;\n    }\n}\nexports.fetchAzureKMSToken = fetchAzureKMSToken;\n/**\n * @internal\n *\n * @throws Will reject with a `MongoCryptError` if the http request fails or the http response is malformed.\n */\nasync function loadAzureCredentials(kmsProviders) {\n    const azure = await exports.tokenCache.getToken();\n    return { ...kmsProviders, azure };\n}\nexports.loadAzureCredentials = loadAzureCredentials;\n//# sourceMappingURL=azure.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/client-side-encryption/providers/azure.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/providers/gcp.js":
/*!**************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/providers/gcp.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.loadGCPCredentials = void 0;\nconst deps_1 = __webpack_require__(/*! ../../deps */ \"./node_modules/mongodb/lib/deps.js\");\n/** @internal */\nasync function loadGCPCredentials(kmsProviders) {\n    const gcpMetadata = (0, deps_1.getGcpMetadata)();\n    if ('kModuleError' in gcpMetadata) {\n        return kmsProviders;\n    }\n    const { access_token: accessToken } = await gcpMetadata.instance({\n        property: 'service-accounts/default/token'\n    });\n    return { ...kmsProviders, gcp: { accessToken } };\n}\nexports.loadGCPCredentials = loadGCPCredentials;\n//# sourceMappingURL=gcp.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/client-side-encryption/providers/gcp.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/providers/index.js":
/*!****************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/providers/index.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.refreshKMSCredentials = exports.isEmptyCredentials = void 0;\nconst aws_1 = __webpack_require__(/*! ./aws */ \"./node_modules/mongodb/lib/client-side-encryption/providers/aws.js\");\nconst azure_1 = __webpack_require__(/*! ./azure */ \"./node_modules/mongodb/lib/client-side-encryption/providers/azure.js\");\nconst gcp_1 = __webpack_require__(/*! ./gcp */ \"./node_modules/mongodb/lib/client-side-encryption/providers/gcp.js\");\n/**\n * Auto credential fetching should only occur when the provider is defined on the kmsProviders map\n * and the settings are an empty object.\n *\n * This is distinct from a nullish provider key.\n *\n * @internal - exposed for testing purposes only\n */\nfunction isEmptyCredentials(providerName, kmsProviders) {\n    const provider = kmsProviders[providerName];\n    if (provider == null) {\n        return false;\n    }\n    return typeof provider === 'object' && Object.keys(provider).length === 0;\n}\nexports.isEmptyCredentials = isEmptyCredentials;\n/**\n * Load cloud provider credentials for the user provided KMS providers.\n * Credentials will only attempt to get loaded if they do not exist\n * and no existing credentials will get overwritten.\n *\n * @internal\n */\nasync function refreshKMSCredentials(kmsProviders) {\n    let finalKMSProviders = kmsProviders;\n    if (isEmptyCredentials('aws', kmsProviders)) {\n        finalKMSProviders = await (0, aws_1.loadAWSCredentials)(finalKMSProviders);\n    }\n    if (isEmptyCredentials('gcp', kmsProviders)) {\n        finalKMSProviders = await (0, gcp_1.loadGCPCredentials)(finalKMSProviders);\n    }\n    if (isEmptyCredentials('azure', kmsProviders)) {\n        finalKMSProviders = await (0, azure_1.loadAzureCredentials)(finalKMSProviders);\n    }\n    return finalKMSProviders;\n}\nexports.refreshKMSCredentials = refreshKMSCredentials;\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/client-side-encryption/providers/index.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/state_machine.js":
/*!**************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/state_machine.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.StateMachine = void 0;\nconst fs = __webpack_require__(/*! fs/promises */ \"fs/promises\");\nconst net = __webpack_require__(/*! net */ \"net\");\nconst tls = __webpack_require__(/*! tls */ \"tls\");\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst deps_1 = __webpack_require__(/*! ../deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst errors_1 = __webpack_require__(/*! ./errors */ \"./node_modules/mongodb/lib/client-side-encryption/errors.js\");\nlet socks = null;\nfunction loadSocks() {\n    if (socks == null) {\n        const socksImport = (0, deps_1.getSocks)();\n        if ('kModuleError' in socksImport) {\n            throw socksImport.kModuleError;\n        }\n        socks = socksImport;\n    }\n    return socks;\n}\n// libmongocrypt states\nconst MONGOCRYPT_CTX_ERROR = 0;\nconst MONGOCRYPT_CTX_NEED_MONGO_COLLINFO = 1;\nconst MONGOCRYPT_CTX_NEED_MONGO_MARKINGS = 2;\nconst MONGOCRYPT_CTX_NEED_MONGO_KEYS = 3;\nconst MONGOCRYPT_CTX_NEED_KMS_CREDENTIALS = 7;\nconst MONGOCRYPT_CTX_NEED_KMS = 4;\nconst MONGOCRYPT_CTX_READY = 5;\nconst MONGOCRYPT_CTX_DONE = 6;\nconst HTTPS_PORT = 443;\nconst stateToString = new Map([\n    [MONGOCRYPT_CTX_ERROR, 'MONGOCRYPT_CTX_ERROR'],\n    [MONGOCRYPT_CTX_NEED_MONGO_COLLINFO, 'MONGOCRYPT_CTX_NEED_MONGO_COLLINFO'],\n    [MONGOCRYPT_CTX_NEED_MONGO_MARKINGS, 'MONGOCRYPT_CTX_NEED_MONGO_MARKINGS'],\n    [MONGOCRYPT_CTX_NEED_MONGO_KEYS, 'MONGOCRYPT_CTX_NEED_MONGO_KEYS'],\n    [MONGOCRYPT_CTX_NEED_KMS_CREDENTIALS, 'MONGOCRYPT_CTX_NEED_KMS_CREDENTIALS'],\n    [MONGOCRYPT_CTX_NEED_KMS, 'MONGOCRYPT_CTX_NEED_KMS'],\n    [MONGOCRYPT_CTX_READY, 'MONGOCRYPT_CTX_READY'],\n    [MONGOCRYPT_CTX_DONE, 'MONGOCRYPT_CTX_DONE']\n]);\nconst INSECURE_TLS_OPTIONS = [\n    'tlsInsecure',\n    'tlsAllowInvalidCertificates',\n    'tlsAllowInvalidHostnames',\n    // These options are disallowed by the spec, so we explicitly filter them out if provided, even\n    // though the StateMachine does not declare support for these options.\n    'tlsDisableOCSPEndpointCheck',\n    'tlsDisableCertificateRevocationCheck'\n];\n/**\n * Helper function for logging. Enabled by setting the environment flag MONGODB_CRYPT_DEBUG.\n * @param msg - Anything you want to be logged.\n */\nfunction debug(msg) {\n    if (process.env.MONGODB_CRYPT_DEBUG) {\n        // eslint-disable-next-line no-console\n        console.error(msg);\n    }\n}\n/**\n * @internal\n * An internal class that executes across a MongoCryptContext until either\n * a finishing state or an error is reached. Do not instantiate directly.\n */\nclass StateMachine {\n    constructor(options, bsonOptions = (0, bson_1.pluckBSONSerializeOptions)(options)) {\n        this.options = options;\n        this.bsonOptions = bsonOptions;\n    }\n    /**\n     * Executes the state machine according to the specification\n     */\n    async execute(executor, context) {\n        const keyVaultNamespace = executor._keyVaultNamespace;\n        const keyVaultClient = executor._keyVaultClient;\n        const metaDataClient = executor._metaDataClient;\n        const mongocryptdClient = executor._mongocryptdClient;\n        const mongocryptdManager = executor._mongocryptdManager;\n        let result = null;\n        while (context.state !== MONGOCRYPT_CTX_DONE && context.state !== MONGOCRYPT_CTX_ERROR) {\n            debug(`[context#${context.id}] ${stateToString.get(context.state) || context.state}`);\n            switch (context.state) {\n                case MONGOCRYPT_CTX_NEED_MONGO_COLLINFO: {\n                    const filter = (0, bson_1.deserialize)(context.nextMongoOperation());\n                    if (!metaDataClient) {\n                        throw new errors_1.MongoCryptError('unreachable state machine state: entered MONGOCRYPT_CTX_NEED_MONGO_COLLINFO but metadata client is undefined');\n                    }\n                    const collInfo = await this.fetchCollectionInfo(metaDataClient, context.ns, filter);\n                    if (collInfo) {\n                        context.addMongoOperationResponse(collInfo);\n                    }\n                    context.finishMongoOperation();\n                    break;\n                }\n                case MONGOCRYPT_CTX_NEED_MONGO_MARKINGS: {\n                    const command = context.nextMongoOperation();\n                    if (!mongocryptdClient) {\n                        throw new errors_1.MongoCryptError('unreachable state machine state: entered MONGOCRYPT_CTX_NEED_MONGO_MARKINGS but mongocryptdClient is undefined');\n                    }\n                    // When we are using the shared library, we don't have a mongocryptd manager.\n                    const markedCommand = mongocryptdManager\n                        ? await mongocryptdManager.withRespawn(this.markCommand.bind(this, mongocryptdClient, context.ns, command))\n                        : await this.markCommand(mongocryptdClient, context.ns, command);\n                    context.addMongoOperationResponse(markedCommand);\n                    context.finishMongoOperation();\n                    break;\n                }\n                case MONGOCRYPT_CTX_NEED_MONGO_KEYS: {\n                    const filter = context.nextMongoOperation();\n                    const keys = await this.fetchKeys(keyVaultClient, keyVaultNamespace, filter);\n                    if (keys.length === 0) {\n                        // This is kind of a hack.  For `rewrapManyDataKey`, we have tests that\n                        // guarantee that when there are no matching keys, `rewrapManyDataKey` returns\n                        // nothing.  We also have tests for auto encryption that guarantee for `encrypt`\n                        // we return an error when there are no matching keys.  This error is generated in\n                        // subsequent iterations of the state machine.\n                        // Some apis (`encrypt`) throw if there are no filter matches and others (`rewrapManyDataKey`)\n                        // do not.  We set the result manually here, and let the state machine continue.  `libmongocrypt`\n                        // will inform us if we need to error by setting the state to `MONGOCRYPT_CTX_ERROR` but\n                        // otherwise we'll return `{ v: [] }`.\n                        result = { v: [] };\n                    }\n                    for await (const key of keys) {\n                        context.addMongoOperationResponse((0, bson_1.serialize)(key));\n                    }\n                    context.finishMongoOperation();\n                    break;\n                }\n                case MONGOCRYPT_CTX_NEED_KMS_CREDENTIALS: {\n                    const kmsProviders = await executor.askForKMSCredentials();\n                    context.provideKMSProviders((0, bson_1.serialize)(kmsProviders));\n                    break;\n                }\n                case MONGOCRYPT_CTX_NEED_KMS: {\n                    const requests = Array.from(this.requests(context));\n                    await Promise.all(requests);\n                    context.finishKMSRequests();\n                    break;\n                }\n                case MONGOCRYPT_CTX_READY: {\n                    const finalizedContext = context.finalize();\n                    // @ts-expect-error finalize can change the state, check for error\n                    if (context.state === MONGOCRYPT_CTX_ERROR) {\n                        const message = context.status.message || 'Finalization error';\n                        throw new errors_1.MongoCryptError(message);\n                    }\n                    result = (0, bson_1.deserialize)(finalizedContext, this.options);\n                    break;\n                }\n                default:\n                    throw new errors_1.MongoCryptError(`Unknown state: ${context.state}`);\n            }\n        }\n        if (context.state === MONGOCRYPT_CTX_ERROR || result == null) {\n            const message = context.status.message;\n            if (!message) {\n                debug(`unidentifiable error in MongoCrypt - received an error status from \\`libmongocrypt\\` but received no error message.`);\n            }\n            throw new errors_1.MongoCryptError(message ??\n                'unidentifiable error in MongoCrypt - received an error status from `libmongocrypt` but received no error message.');\n        }\n        return result;\n    }\n    /**\n     * Handles the request to the KMS service. Exposed for testing purposes. Do not directly invoke.\n     * @param kmsContext - A C++ KMS context returned from the bindings\n     * @returns A promise that resolves when the KMS reply has be fully parsed\n     */\n    async kmsRequest(request) {\n        const parsedUrl = request.endpoint.split(':');\n        const port = parsedUrl[1] != null ? Number.parseInt(parsedUrl[1], 10) : HTTPS_PORT;\n        const options = {\n            host: parsedUrl[0],\n            servername: parsedUrl[0],\n            port\n        };\n        const message = request.message;\n        const buffer = new utils_1.BufferPool();\n        const netSocket = new net.Socket();\n        let socket;\n        function destroySockets() {\n            for (const sock of [socket, netSocket]) {\n                if (sock) {\n                    sock.removeAllListeners();\n                    sock.destroy();\n                }\n            }\n        }\n        function ontimeout() {\n            return new errors_1.MongoCryptError('KMS request timed out');\n        }\n        function onerror(cause) {\n            return new errors_1.MongoCryptError('KMS request failed', { cause });\n        }\n        function onclose() {\n            return new errors_1.MongoCryptError('KMS request closed');\n        }\n        const tlsOptions = this.options.tlsOptions;\n        if (tlsOptions) {\n            const kmsProvider = request.kmsProvider;\n            const providerTlsOptions = tlsOptions[kmsProvider];\n            if (providerTlsOptions) {\n                const error = this.validateTlsOptions(kmsProvider, providerTlsOptions);\n                if (error) {\n                    throw error;\n                }\n                try {\n                    await this.setTlsOptions(providerTlsOptions, options);\n                }\n                catch (err) {\n                    throw onerror(err);\n                }\n            }\n        }\n        const { promise: willConnect, reject: rejectOnNetSocketError, resolve: resolveOnNetSocketConnect } = (0, utils_1.promiseWithResolvers)();\n        netSocket\n            .once('timeout', () => rejectOnNetSocketError(ontimeout()))\n            .once('error', err => rejectOnNetSocketError(onerror(err)))\n            .once('close', () => rejectOnNetSocketError(onclose()))\n            .once('connect', () => resolveOnNetSocketConnect());\n        try {\n            if (this.options.proxyOptions && this.options.proxyOptions.proxyHost) {\n                netSocket.connect({\n                    host: this.options.proxyOptions.proxyHost,\n                    port: this.options.proxyOptions.proxyPort || 1080\n                });\n                await willConnect;\n                try {\n                    socks ??= loadSocks();\n                    options.socket = (await socks.SocksClient.createConnection({\n                        existing_socket: netSocket,\n                        command: 'connect',\n                        destination: { host: options.host, port: options.port },\n                        proxy: {\n                            // host and port are ignored because we pass existing_socket\n                            host: 'iLoveJavaScript',\n                            port: 0,\n                            type: 5,\n                            userId: this.options.proxyOptions.proxyUsername,\n                            password: this.options.proxyOptions.proxyPassword\n                        }\n                    })).socket;\n                }\n                catch (err) {\n                    throw onerror(err);\n                }\n            }\n            socket = tls.connect(options, () => {\n                socket.write(message);\n            });\n            const { promise: willResolveKmsRequest, reject: rejectOnTlsSocketError, resolve } = (0, utils_1.promiseWithResolvers)();\n            socket\n                .once('timeout', () => rejectOnTlsSocketError(ontimeout()))\n                .once('error', err => rejectOnTlsSocketError(onerror(err)))\n                .once('close', () => rejectOnTlsSocketError(onclose()))\n                .on('data', data => {\n                buffer.append(data);\n                while (request.bytesNeeded > 0 && buffer.length) {\n                    const bytesNeeded = Math.min(request.bytesNeeded, buffer.length);\n                    request.addResponse(buffer.read(bytesNeeded));\n                }\n                if (request.bytesNeeded <= 0) {\n                    resolve();\n                }\n            });\n            await willResolveKmsRequest;\n        }\n        finally {\n            // There's no need for any more activity on this socket at this point.\n            destroySockets();\n        }\n    }\n    *requests(context) {\n        for (let request = context.nextKMSRequest(); request != null; request = context.nextKMSRequest()) {\n            yield this.kmsRequest(request);\n        }\n    }\n    /**\n     * Validates the provided TLS options are secure.\n     *\n     * @param kmsProvider - The KMS provider name.\n     * @param tlsOptions - The client TLS options for the provider.\n     *\n     * @returns An error if any option is invalid.\n     */\n    validateTlsOptions(kmsProvider, tlsOptions) {\n        const tlsOptionNames = Object.keys(tlsOptions);\n        for (const option of INSECURE_TLS_OPTIONS) {\n            if (tlsOptionNames.includes(option)) {\n                return new errors_1.MongoCryptError(`Insecure TLS options prohibited for ${kmsProvider}: ${option}`);\n            }\n        }\n    }\n    /**\n     * Sets only the valid secure TLS options.\n     *\n     * @param tlsOptions - The client TLS options for the provider.\n     * @param options - The existing connection options.\n     */\n    async setTlsOptions(tlsOptions, options) {\n        if (tlsOptions.tlsCertificateKeyFile) {\n            const cert = await fs.readFile(tlsOptions.tlsCertificateKeyFile);\n            options.cert = options.key = cert;\n        }\n        if (tlsOptions.tlsCAFile) {\n            options.ca = await fs.readFile(tlsOptions.tlsCAFile);\n        }\n        if (tlsOptions.tlsCertificateKeyFilePassword) {\n            options.passphrase = tlsOptions.tlsCertificateKeyFilePassword;\n        }\n    }\n    /**\n     * Fetches collection info for a provided namespace, when libmongocrypt\n     * enters the `MONGOCRYPT_CTX_NEED_MONGO_COLLINFO` state. The result is\n     * used to inform libmongocrypt of the schema associated with this\n     * namespace. Exposed for testing purposes. Do not directly invoke.\n     *\n     * @param client - A MongoClient connected to the topology\n     * @param ns - The namespace to list collections from\n     * @param filter - A filter for the listCollections command\n     * @param callback - Invoked with the info of the requested collection, or with an error\n     */\n    async fetchCollectionInfo(client, ns, filter) {\n        const { db } = utils_1.MongoDBCollectionNamespace.fromString(ns);\n        const collections = await client\n            .db(db)\n            .listCollections(filter, {\n            promoteLongs: false,\n            promoteValues: false\n        })\n            .toArray();\n        const info = collections.length > 0 ? (0, bson_1.serialize)(collections[0]) : null;\n        return info;\n    }\n    /**\n     * Calls to the mongocryptd to provide markings for a command.\n     * Exposed for testing purposes. Do not directly invoke.\n     * @param client - A MongoClient connected to a mongocryptd\n     * @param ns - The namespace (database.collection) the command is being executed on\n     * @param command - The command to execute.\n     * @param callback - Invoked with the serialized and marked bson command, or with an error\n     */\n    async markCommand(client, ns, command) {\n        const options = { promoteLongs: false, promoteValues: false };\n        const { db } = utils_1.MongoDBCollectionNamespace.fromString(ns);\n        const rawCommand = (0, bson_1.deserialize)(command, options);\n        const response = await client.db(db).command(rawCommand, options);\n        return (0, bson_1.serialize)(response, this.bsonOptions);\n    }\n    /**\n     * Requests keys from the keyVault collection on the topology.\n     * Exposed for testing purposes. Do not directly invoke.\n     * @param client - A MongoClient connected to the topology\n     * @param keyVaultNamespace - The namespace (database.collection) of the keyVault Collection\n     * @param filter - The filter for the find query against the keyVault Collection\n     * @param callback - Invoked with the found keys, or with an error\n     */\n    fetchKeys(client, keyVaultNamespace, filter) {\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(keyVaultNamespace);\n        return client\n            .db(dbName)\n            .collection(collectionName, { readConcern: { level: 'majority' } })\n            .find((0, bson_1.deserialize)(filter))\n            .toArray();\n    }\n}\nexports.StateMachine = StateMachine;\n//# sourceMappingURL=state_machine.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/client-side-encryption/state_machine.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/auth_provider.js":
/*!*************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/auth_provider.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AuthProvider = exports.AuthContext = void 0;\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\n/**\n * Context used during authentication\n * @internal\n */\nclass AuthContext {\n    constructor(connection, credentials, options) {\n        /** If the context is for reauthentication. */\n        this.reauthenticating = false;\n        this.connection = connection;\n        this.credentials = credentials;\n        this.options = options;\n    }\n}\nexports.AuthContext = AuthContext;\n/**\n * Provider used during authentication.\n * @internal\n */\nclass AuthProvider {\n    /**\n     * Prepare the handshake document before the initial handshake.\n     *\n     * @param handshakeDoc - The document used for the initial handshake on a connection\n     * @param authContext - Context for authentication flow\n     */\n    async prepare(handshakeDoc, _authContext) {\n        return handshakeDoc;\n    }\n    /**\n     * Reauthenticate.\n     * @param context - The shared auth context.\n     */\n    async reauth(context) {\n        if (context.reauthenticating) {\n            throw new error_1.MongoRuntimeError('Reauthentication already in progress.');\n        }\n        try {\n            context.reauthenticating = true;\n            await this.auth(context);\n        }\n        finally {\n            context.reauthenticating = false;\n        }\n    }\n}\nexports.AuthProvider = AuthProvider;\n//# sourceMappingURL=auth_provider.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/auth/auth_provider.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/aws_temporary_credentials.js":
/*!*************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/aws_temporary_credentials.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.LegacyAWSTemporaryCredentialProvider = exports.AWSSDKCredentialProvider = exports.AWSTemporaryCredentialProvider = void 0;\nconst deps_1 = __webpack_require__(/*! ../../deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst AWS_RELATIVE_URI = 'http://169.254.170.2';\nconst AWS_EC2_URI = 'http://169.254.169.254';\nconst AWS_EC2_PATH = '/latest/meta-data/iam/security-credentials';\n/**\n * @internal\n *\n * Fetches temporary AWS credentials.\n */\nclass AWSTemporaryCredentialProvider {\n    static get awsSDK() {\n        AWSTemporaryCredentialProvider._awsSDK ??= (0, deps_1.getAwsCredentialProvider)();\n        return AWSTemporaryCredentialProvider._awsSDK;\n    }\n    static get isAWSSDKInstalled() {\n        return !('kModuleError' in AWSTemporaryCredentialProvider.awsSDK);\n    }\n}\nexports.AWSTemporaryCredentialProvider = AWSTemporaryCredentialProvider;\n/** @internal */\nclass AWSSDKCredentialProvider extends AWSTemporaryCredentialProvider {\n    /**\n     * The AWS SDK caches credentials automatically and handles refresh when the credentials have expired.\n     * To ensure this occurs, we need to cache the `provider` returned by the AWS sdk and re-use it when fetching credentials.\n     */\n    get provider() {\n        if ('kModuleError' in AWSTemporaryCredentialProvider.awsSDK) {\n            throw AWSTemporaryCredentialProvider.awsSDK.kModuleError;\n        }\n        if (this._provider) {\n            return this._provider;\n        }\n        let { AWS_STS_REGIONAL_ENDPOINTS = '', AWS_REGION = '' } = process.env;\n        AWS_STS_REGIONAL_ENDPOINTS = AWS_STS_REGIONAL_ENDPOINTS.toLowerCase();\n        AWS_REGION = AWS_REGION.toLowerCase();\n        /** The option setting should work only for users who have explicit settings in their environment, the driver should not encode \"defaults\" */\n        const awsRegionSettingsExist = AWS_REGION.length !== 0 && AWS_STS_REGIONAL_ENDPOINTS.length !== 0;\n        /**\n         * The following regions use the global AWS STS endpoint, sts.amazonaws.com, by default\n         * https://docs.aws.amazon.com/sdkref/latest/guide/feature-sts-regionalized-endpoints.html\n         */\n        const LEGACY_REGIONS = new Set([\n            'ap-northeast-1',\n            'ap-south-1',\n            'ap-southeast-1',\n            'ap-southeast-2',\n            'aws-global',\n            'ca-central-1',\n            'eu-central-1',\n            'eu-north-1',\n            'eu-west-1',\n            'eu-west-2',\n            'eu-west-3',\n            'sa-east-1',\n            'us-east-1',\n            'us-east-2',\n            'us-west-1',\n            'us-west-2'\n        ]);\n        /**\n         * If AWS_STS_REGIONAL_ENDPOINTS is set to regional, users are opting into the new behavior of respecting the region settings\n         *\n         * If AWS_STS_REGIONAL_ENDPOINTS is set to legacy, then \"old\" regions need to keep using the global setting.\n         * Technically the SDK gets this wrong, it reaches out to 'sts.us-east-1.amazonaws.com' when it should be 'sts.amazonaws.com'.\n         * That is not our bug to fix here. We leave that up to the SDK.\n         */\n        const useRegionalSts = AWS_STS_REGIONAL_ENDPOINTS === 'regional' ||\n            (AWS_STS_REGIONAL_ENDPOINTS === 'legacy' && !LEGACY_REGIONS.has(AWS_REGION));\n        this._provider =\n            awsRegionSettingsExist && useRegionalSts\n                ? AWSTemporaryCredentialProvider.awsSDK.fromNodeProviderChain({\n                    clientConfig: { region: AWS_REGION }\n                })\n                : AWSTemporaryCredentialProvider.awsSDK.fromNodeProviderChain();\n        return this._provider;\n    }\n    async getCredentials() {\n        /*\n         * Creates a credential provider that will attempt to find credentials from the\n         * following sources (listed in order of precedence):\n         *\n         * - Environment variables exposed via process.env\n         * - SSO credentials from token cache\n         * - Web identity token credentials\n         * - Shared credentials and config ini files\n         * - The EC2/ECS Instance Metadata Service\n         */\n        try {\n            const creds = await this.provider();\n            return {\n                AccessKeyId: creds.accessKeyId,\n                SecretAccessKey: creds.secretAccessKey,\n                Token: creds.sessionToken,\n                Expiration: creds.expiration\n            };\n        }\n        catch (error) {\n            throw new error_1.MongoAWSError(error.message, { cause: error });\n        }\n    }\n}\nexports.AWSSDKCredentialProvider = AWSSDKCredentialProvider;\n/**\n * @internal\n * Fetches credentials manually (without the AWS SDK), as outlined in the [Obtaining Credentials](https://github.com/mongodb/specifications/blob/master/source/auth/auth.md#obtaining-credentials)\n * section of the Auth spec.\n */\nclass LegacyAWSTemporaryCredentialProvider extends AWSTemporaryCredentialProvider {\n    async getCredentials() {\n        // If the environment variable AWS_CONTAINER_CREDENTIALS_RELATIVE_URI\n        // is set then drivers MUST assume that it was set by an AWS ECS agent\n        if (process.env.AWS_CONTAINER_CREDENTIALS_RELATIVE_URI) {\n            return await (0, utils_1.request)(`${AWS_RELATIVE_URI}${process.env.AWS_CONTAINER_CREDENTIALS_RELATIVE_URI}`);\n        }\n        // Otherwise assume we are on an EC2 instance\n        // get a token\n        const token = await (0, utils_1.request)(`${AWS_EC2_URI}/latest/api/token`, {\n            method: 'PUT',\n            json: false,\n            headers: { 'X-aws-ec2-metadata-token-ttl-seconds': 30 }\n        });\n        // get role name\n        const roleName = await (0, utils_1.request)(`${AWS_EC2_URI}/${AWS_EC2_PATH}`, {\n            json: false,\n            headers: { 'X-aws-ec2-metadata-token': token }\n        });\n        // get temp credentials\n        const creds = await (0, utils_1.request)(`${AWS_EC2_URI}/${AWS_EC2_PATH}/${roleName}`, {\n            headers: { 'X-aws-ec2-metadata-token': token }\n        });\n        return creds;\n    }\n}\nexports.LegacyAWSTemporaryCredentialProvider = LegacyAWSTemporaryCredentialProvider;\n//# sourceMappingURL=aws_temporary_credentials.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/auth/aws_temporary_credentials.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/gssapi.js":
/*!******************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/gssapi.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.resolveCname = exports.performGSSAPICanonicalizeHostName = exports.GSSAPI = exports.GSSAPICanonicalizationValue = void 0;\nconst dns = __webpack_require__(/*! dns */ \"dns\");\nconst deps_1 = __webpack_require__(/*! ../../deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst auth_provider_1 = __webpack_require__(/*! ./auth_provider */ \"./node_modules/mongodb/lib/cmap/auth/auth_provider.js\");\n/** @public */\nexports.GSSAPICanonicalizationValue = Object.freeze({\n    on: true,\n    off: false,\n    none: 'none',\n    forward: 'forward',\n    forwardAndReverse: 'forwardAndReverse'\n});\nasync function externalCommand(connection, command) {\n    const response = await connection.command((0, utils_1.ns)('$external.$cmd'), command);\n    return response;\n}\nlet krb;\nclass GSSAPI extends auth_provider_1.AuthProvider {\n    async auth(authContext) {\n        const { connection, credentials } = authContext;\n        if (credentials == null) {\n            throw new error_1.MongoMissingCredentialsError('Credentials required for GSSAPI authentication');\n        }\n        const { username } = credentials;\n        const client = await makeKerberosClient(authContext);\n        const payload = await client.step('');\n        const saslStartResponse = await externalCommand(connection, saslStart(payload));\n        const negotiatedPayload = await negotiate(client, 10, saslStartResponse.payload);\n        const saslContinueResponse = await externalCommand(connection, saslContinue(negotiatedPayload, saslStartResponse.conversationId));\n        const finalizePayload = await finalize(client, username, saslContinueResponse.payload);\n        await externalCommand(connection, {\n            saslContinue: 1,\n            conversationId: saslContinueResponse.conversationId,\n            payload: finalizePayload\n        });\n    }\n}\nexports.GSSAPI = GSSAPI;\nasync function makeKerberosClient(authContext) {\n    const { hostAddress } = authContext.options;\n    const { credentials } = authContext;\n    if (!hostAddress || typeof hostAddress.host !== 'string' || !credentials) {\n        throw new error_1.MongoInvalidArgumentError('Connection must have host and port and credentials defined.');\n    }\n    loadKrb();\n    if ('kModuleError' in krb) {\n        throw krb['kModuleError'];\n    }\n    const { initializeClient } = krb;\n    const { username, password } = credentials;\n    const mechanismProperties = credentials.mechanismProperties;\n    const serviceName = mechanismProperties.SERVICE_NAME ?? 'mongodb';\n    const host = await performGSSAPICanonicalizeHostName(hostAddress.host, mechanismProperties);\n    const initOptions = {};\n    if (password != null) {\n        // TODO(NODE-5139): These do not match the typescript options in initializeClient\n        Object.assign(initOptions, { user: username, password: password });\n    }\n    const spnHost = mechanismProperties.SERVICE_HOST ?? host;\n    let spn = `${serviceName}${process.platform === 'win32' ? '/' : '@'}${spnHost}`;\n    if ('SERVICE_REALM' in mechanismProperties) {\n        spn = `${spn}@${mechanismProperties.SERVICE_REALM}`;\n    }\n    return await initializeClient(spn, initOptions);\n}\nfunction saslStart(payload) {\n    return {\n        saslStart: 1,\n        mechanism: 'GSSAPI',\n        payload,\n        autoAuthorize: 1\n    };\n}\nfunction saslContinue(payload, conversationId) {\n    return {\n        saslContinue: 1,\n        conversationId,\n        payload\n    };\n}\nasync function negotiate(client, retries, payload) {\n    try {\n        const response = await client.step(payload);\n        return response || '';\n    }\n    catch (error) {\n        if (retries === 0) {\n            // Retries exhausted, raise error\n            throw error;\n        }\n        // Adjust number of retries and call step again\n        return await negotiate(client, retries - 1, payload);\n    }\n}\nasync function finalize(client, user, payload) {\n    // GSS Client Unwrap\n    const response = await client.unwrap(payload);\n    return await client.wrap(response || '', { user });\n}\nasync function performGSSAPICanonicalizeHostName(host, mechanismProperties) {\n    const mode = mechanismProperties.CANONICALIZE_HOST_NAME;\n    if (!mode || mode === exports.GSSAPICanonicalizationValue.none) {\n        return host;\n    }\n    // If forward and reverse or true\n    if (mode === exports.GSSAPICanonicalizationValue.on ||\n        mode === exports.GSSAPICanonicalizationValue.forwardAndReverse) {\n        // Perform the lookup of the ip address.\n        const { address } = await dns.promises.lookup(host);\n        try {\n            // Perform a reverse ptr lookup on the ip address.\n            const results = await dns.promises.resolvePtr(address);\n            // If the ptr did not error but had no results, return the host.\n            return results.length > 0 ? results[0] : host;\n        }\n        catch (error) {\n            // This can error as ptr records may not exist for all ips. In this case\n            // fallback to a cname lookup as dns.lookup() does not return the\n            // cname.\n            return await resolveCname(host);\n        }\n    }\n    else {\n        // The case for forward is just to resolve the cname as dns.lookup()\n        // will not return it.\n        return await resolveCname(host);\n    }\n}\nexports.performGSSAPICanonicalizeHostName = performGSSAPICanonicalizeHostName;\nasync function resolveCname(host) {\n    // Attempt to resolve the host name\n    try {\n        const results = await dns.promises.resolveCname(host);\n        // Get the first resolved host id\n        return results.length > 0 ? results[0] : host;\n    }\n    catch {\n        return host;\n    }\n}\nexports.resolveCname = resolveCname;\n/**\n * Load the Kerberos library.\n */\nfunction loadKrb() {\n    if (!krb) {\n        krb = (0, deps_1.getKerberos)();\n    }\n}\n//# sourceMappingURL=gssapi.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/auth/gssapi.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongo_credentials.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongo_credentials.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoCredentials = exports.DEFAULT_ALLOWED_HOSTS = void 0;\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst gssapi_1 = __webpack_require__(/*! ./gssapi */ \"./node_modules/mongodb/lib/cmap/auth/gssapi.js\");\nconst providers_1 = __webpack_require__(/*! ./providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\n// https://github.com/mongodb/specifications/blob/master/source/auth/auth.rst\nfunction getDefaultAuthMechanism(hello) {\n    if (hello) {\n        // If hello contains saslSupportedMechs, use scram-sha-256\n        // if it is available, else scram-sha-1\n        if (Array.isArray(hello.saslSupportedMechs)) {\n            return hello.saslSupportedMechs.includes(providers_1.AuthMechanism.MONGODB_SCRAM_SHA256)\n                ? providers_1.AuthMechanism.MONGODB_SCRAM_SHA256\n                : providers_1.AuthMechanism.MONGODB_SCRAM_SHA1;\n        }\n        // Fallback to legacy selection method. If wire version >= 3, use scram-sha-1\n        if (hello.maxWireVersion >= 3) {\n            return providers_1.AuthMechanism.MONGODB_SCRAM_SHA1;\n        }\n    }\n    // Default for wireprotocol < 3\n    return providers_1.AuthMechanism.MONGODB_CR;\n}\nconst ALLOWED_ENVIRONMENT_NAMES = [\n    'test',\n    'azure',\n    'gcp'\n];\nconst ALLOWED_HOSTS_ERROR = 'Auth mechanism property ALLOWED_HOSTS must be an array of strings.';\n/** @internal */\nexports.DEFAULT_ALLOWED_HOSTS = [\n    '*.mongodb.net',\n    '*.mongodb-qa.net',\n    '*.mongodb-dev.net',\n    '*.mongodbgov.net',\n    'localhost',\n    '127.0.0.1',\n    '::1'\n];\n/** Error for when the token audience is missing in the environment. */\nconst TOKEN_RESOURCE_MISSING_ERROR = 'TOKEN_RESOURCE must be set in the auth mechanism properties when ENVIRONMENT is azure or gcp.';\n/**\n * A representation of the credentials used by MongoDB\n * @public\n */\nclass MongoCredentials {\n    constructor(options) {\n        this.username = options.username ?? '';\n        this.password = options.password;\n        this.source = options.source;\n        if (!this.source && options.db) {\n            this.source = options.db;\n        }\n        this.mechanism = options.mechanism || providers_1.AuthMechanism.MONGODB_DEFAULT;\n        this.mechanismProperties = options.mechanismProperties || {};\n        if (this.mechanism.match(/MONGODB-AWS/i)) {\n            if (!this.username && process.env.AWS_ACCESS_KEY_ID) {\n                this.username = process.env.AWS_ACCESS_KEY_ID;\n            }\n            if (!this.password && process.env.AWS_SECRET_ACCESS_KEY) {\n                this.password = process.env.AWS_SECRET_ACCESS_KEY;\n            }\n            if (this.mechanismProperties.AWS_SESSION_TOKEN == null &&\n                process.env.AWS_SESSION_TOKEN != null) {\n                this.mechanismProperties = {\n                    ...this.mechanismProperties,\n                    AWS_SESSION_TOKEN: process.env.AWS_SESSION_TOKEN\n                };\n            }\n        }\n        if (this.mechanism === providers_1.AuthMechanism.MONGODB_OIDC && !this.mechanismProperties.ALLOWED_HOSTS) {\n            this.mechanismProperties = {\n                ...this.mechanismProperties,\n                ALLOWED_HOSTS: exports.DEFAULT_ALLOWED_HOSTS\n            };\n        }\n        Object.freeze(this.mechanismProperties);\n        Object.freeze(this);\n    }\n    /** Determines if two MongoCredentials objects are equivalent */\n    equals(other) {\n        return (this.mechanism === other.mechanism &&\n            this.username === other.username &&\n            this.password === other.password &&\n            this.source === other.source);\n    }\n    /**\n     * If the authentication mechanism is set to \"default\", resolves the authMechanism\n     * based on the server version and server supported sasl mechanisms.\n     *\n     * @param hello - A hello response from the server\n     */\n    resolveAuthMechanism(hello) {\n        // If the mechanism is not \"default\", then it does not need to be resolved\n        if (this.mechanism.match(/DEFAULT/i)) {\n            return new MongoCredentials({\n                username: this.username,\n                password: this.password,\n                source: this.source,\n                mechanism: getDefaultAuthMechanism(hello),\n                mechanismProperties: this.mechanismProperties\n            });\n        }\n        return this;\n    }\n    validate() {\n        if ((this.mechanism === providers_1.AuthMechanism.MONGODB_GSSAPI ||\n            this.mechanism === providers_1.AuthMechanism.MONGODB_CR ||\n            this.mechanism === providers_1.AuthMechanism.MONGODB_PLAIN ||\n            this.mechanism === providers_1.AuthMechanism.MONGODB_SCRAM_SHA1 ||\n            this.mechanism === providers_1.AuthMechanism.MONGODB_SCRAM_SHA256) &&\n            !this.username) {\n            throw new error_1.MongoMissingCredentialsError(`Username required for mechanism '${this.mechanism}'`);\n        }\n        if (this.mechanism === providers_1.AuthMechanism.MONGODB_OIDC) {\n            if (this.username &&\n                this.mechanismProperties.ENVIRONMENT &&\n                this.mechanismProperties.ENVIRONMENT !== 'azure') {\n                throw new error_1.MongoInvalidArgumentError(`username and ENVIRONMENT '${this.mechanismProperties.ENVIRONMENT}' may not be used together for mechanism '${this.mechanism}'.`);\n            }\n            if (this.username && this.password) {\n                throw new error_1.MongoInvalidArgumentError(`No password is allowed in ENVIRONMENT '${this.mechanismProperties.ENVIRONMENT}' for '${this.mechanism}'.`);\n            }\n            if ((this.mechanismProperties.ENVIRONMENT === 'azure' ||\n                this.mechanismProperties.ENVIRONMENT === 'gcp') &&\n                !this.mechanismProperties.TOKEN_RESOURCE) {\n                throw new error_1.MongoInvalidArgumentError(TOKEN_RESOURCE_MISSING_ERROR);\n            }\n            if (this.mechanismProperties.ENVIRONMENT &&\n                !ALLOWED_ENVIRONMENT_NAMES.includes(this.mechanismProperties.ENVIRONMENT)) {\n                throw new error_1.MongoInvalidArgumentError(`Currently only a ENVIRONMENT in ${ALLOWED_ENVIRONMENT_NAMES.join(',')} is supported for mechanism '${this.mechanism}'.`);\n            }\n            if (!this.mechanismProperties.ENVIRONMENT &&\n                !this.mechanismProperties.OIDC_CALLBACK &&\n                !this.mechanismProperties.OIDC_HUMAN_CALLBACK) {\n                throw new error_1.MongoInvalidArgumentError(`Either a ENVIRONMENT, OIDC_CALLBACK, or OIDC_HUMAN_CALLBACK must be specified for mechanism '${this.mechanism}'.`);\n            }\n            if (this.mechanismProperties.ALLOWED_HOSTS) {\n                const hosts = this.mechanismProperties.ALLOWED_HOSTS;\n                if (!Array.isArray(hosts)) {\n                    throw new error_1.MongoInvalidArgumentError(ALLOWED_HOSTS_ERROR);\n                }\n                for (const host of hosts) {\n                    if (typeof host !== 'string') {\n                        throw new error_1.MongoInvalidArgumentError(ALLOWED_HOSTS_ERROR);\n                    }\n                }\n            }\n        }\n        if (providers_1.AUTH_MECHS_AUTH_SRC_EXTERNAL.has(this.mechanism)) {\n            if (this.source != null && this.source !== '$external') {\n                // TODO(NODE-3485): Replace this with a MongoAuthValidationError\n                throw new error_1.MongoAPIError(`Invalid source '${this.source}' for mechanism '${this.mechanism}' specified.`);\n            }\n        }\n        if (this.mechanism === providers_1.AuthMechanism.MONGODB_PLAIN && this.source == null) {\n            // TODO(NODE-3485): Replace this with a MongoAuthValidationError\n            throw new error_1.MongoAPIError('PLAIN Authentication Mechanism needs an auth source');\n        }\n        if (this.mechanism === providers_1.AuthMechanism.MONGODB_X509 && this.password != null) {\n            if (this.password === '') {\n                Reflect.set(this, 'password', undefined);\n                return;\n            }\n            // TODO(NODE-3485): Replace this with a MongoAuthValidationError\n            throw new error_1.MongoAPIError(`Password not allowed for mechanism MONGODB-X509`);\n        }\n        const canonicalization = this.mechanismProperties.CANONICALIZE_HOST_NAME ?? false;\n        if (!Object.values(gssapi_1.GSSAPICanonicalizationValue).includes(canonicalization)) {\n            throw new error_1.MongoAPIError(`Invalid CANONICALIZE_HOST_NAME value: ${canonicalization}`);\n        }\n    }\n    static merge(creds, options) {\n        return new MongoCredentials({\n            username: options.username ?? creds?.username ?? '',\n            password: options.password ?? creds?.password ?? '',\n            mechanism: options.mechanism ?? creds?.mechanism ?? providers_1.AuthMechanism.MONGODB_DEFAULT,\n            mechanismProperties: options.mechanismProperties ?? creds?.mechanismProperties ?? {},\n            source: options.source ?? options.db ?? creds?.source ?? 'admin'\n        });\n    }\n}\nexports.MongoCredentials = MongoCredentials;\n//# sourceMappingURL=mongo_credentials.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/auth/mongo_credentials.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongocr.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongocr.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoCR = void 0;\nconst crypto = __webpack_require__(/*! crypto */ \"crypto\");\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst auth_provider_1 = __webpack_require__(/*! ./auth_provider */ \"./node_modules/mongodb/lib/cmap/auth/auth_provider.js\");\nclass MongoCR extends auth_provider_1.AuthProvider {\n    async auth(authContext) {\n        const { connection, credentials } = authContext;\n        if (!credentials) {\n            throw new error_1.MongoMissingCredentialsError('AuthContext must provide credentials.');\n        }\n        const { username, password, source } = credentials;\n        const { nonce } = await connection.command((0, utils_1.ns)(`${source}.$cmd`), { getnonce: 1 }, undefined);\n        const hashPassword = crypto\n            .createHash('md5')\n            .update(`${username}:mongo:${password}`, 'utf8')\n            .digest('hex');\n        // Final key\n        const key = crypto\n            .createHash('md5')\n            .update(`${nonce}${username}${hashPassword}`, 'utf8')\n            .digest('hex');\n        const authenticateCommand = {\n            authenticate: 1,\n            user: username,\n            nonce,\n            key\n        };\n        await connection.command((0, utils_1.ns)(`${source}.$cmd`), authenticateCommand, undefined);\n    }\n}\nexports.MongoCR = MongoCR;\n//# sourceMappingURL=mongocr.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/auth/mongocr.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_aws.js":
/*!***********************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_aws.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoDBAWS = void 0;\nconst BSON = __webpack_require__(/*! ../../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst deps_1 = __webpack_require__(/*! ../../deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst auth_provider_1 = __webpack_require__(/*! ./auth_provider */ \"./node_modules/mongodb/lib/cmap/auth/auth_provider.js\");\nconst aws_temporary_credentials_1 = __webpack_require__(/*! ./aws_temporary_credentials */ \"./node_modules/mongodb/lib/cmap/auth/aws_temporary_credentials.js\");\nconst mongo_credentials_1 = __webpack_require__(/*! ./mongo_credentials */ \"./node_modules/mongodb/lib/cmap/auth/mongo_credentials.js\");\nconst providers_1 = __webpack_require__(/*! ./providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\nconst ASCII_N = 110;\nconst bsonOptions = {\n    useBigInt64: false,\n    promoteLongs: true,\n    promoteValues: true,\n    promoteBuffers: false,\n    bsonRegExp: false\n};\nclass MongoDBAWS extends auth_provider_1.AuthProvider {\n    constructor() {\n        super();\n        this.credentialFetcher = aws_temporary_credentials_1.AWSTemporaryCredentialProvider.isAWSSDKInstalled\n            ? new aws_temporary_credentials_1.AWSSDKCredentialProvider()\n            : new aws_temporary_credentials_1.LegacyAWSTemporaryCredentialProvider();\n    }\n    async auth(authContext) {\n        const { connection } = authContext;\n        if (!authContext.credentials) {\n            throw new error_1.MongoMissingCredentialsError('AuthContext must provide credentials.');\n        }\n        if ('kModuleError' in deps_1.aws4) {\n            throw deps_1.aws4['kModuleError'];\n        }\n        const { sign } = deps_1.aws4;\n        if ((0, utils_1.maxWireVersion)(connection) < 9) {\n            throw new error_1.MongoCompatibilityError('MONGODB-AWS authentication requires MongoDB version 4.4 or later');\n        }\n        if (!authContext.credentials.username) {\n            authContext.credentials = await makeTempCredentials(authContext.credentials, this.credentialFetcher);\n        }\n        const { credentials } = authContext;\n        const accessKeyId = credentials.username;\n        const secretAccessKey = credentials.password;\n        // Allow the user to specify an AWS session token for authentication with temporary credentials.\n        const sessionToken = credentials.mechanismProperties.AWS_SESSION_TOKEN;\n        // If all three defined, include sessionToken, else include username and pass, else no credentials\n        const awsCredentials = accessKeyId && secretAccessKey && sessionToken\n            ? { accessKeyId, secretAccessKey, sessionToken }\n            : accessKeyId && secretAccessKey\n                ? { accessKeyId, secretAccessKey }\n                : undefined;\n        const db = credentials.source;\n        const nonce = await (0, utils_1.randomBytes)(32);\n        // All messages between MongoDB clients and servers are sent as BSON objects\n        // in the payload field of saslStart and saslContinue.\n        const saslStart = {\n            saslStart: 1,\n            mechanism: 'MONGODB-AWS',\n            payload: BSON.serialize({ r: nonce, p: ASCII_N }, bsonOptions)\n        };\n        const saslStartResponse = await connection.command((0, utils_1.ns)(`${db}.$cmd`), saslStart, undefined);\n        const serverResponse = BSON.deserialize(saslStartResponse.payload.buffer, bsonOptions);\n        const host = serverResponse.h;\n        const serverNonce = serverResponse.s.buffer;\n        if (serverNonce.length !== 64) {\n            // TODO(NODE-3483)\n            throw new error_1.MongoRuntimeError(`Invalid server nonce length ${serverNonce.length}, expected 64`);\n        }\n        if (!utils_1.ByteUtils.equals(serverNonce.subarray(0, nonce.byteLength), nonce)) {\n            // throw because the serverNonce's leading 32 bytes must equal the client nonce's 32 bytes\n            // https://github.com/mongodb/specifications/blob/875446db44aade414011731840831f38a6c668df/source/auth/auth.rst#id11\n            // TODO(NODE-3483)\n            throw new error_1.MongoRuntimeError('Server nonce does not begin with client nonce');\n        }\n        if (host.length < 1 || host.length > 255 || host.indexOf('..') !== -1) {\n            // TODO(NODE-3483)\n            throw new error_1.MongoRuntimeError(`Server returned an invalid host: \"${host}\"`);\n        }\n        const body = 'Action=GetCallerIdentity&Version=2011-06-15';\n        const options = sign({\n            method: 'POST',\n            host,\n            region: deriveRegion(serverResponse.h),\n            service: 'sts',\n            headers: {\n                'Content-Type': 'application/x-www-form-urlencoded',\n                'Content-Length': body.length,\n                'X-MongoDB-Server-Nonce': utils_1.ByteUtils.toBase64(serverNonce),\n                'X-MongoDB-GS2-CB-Flag': 'n'\n            },\n            path: '/',\n            body\n        }, awsCredentials);\n        const payload = {\n            a: options.headers.Authorization,\n            d: options.headers['X-Amz-Date']\n        };\n        if (sessionToken) {\n            payload.t = sessionToken;\n        }\n        const saslContinue = {\n            saslContinue: 1,\n            conversationId: 1,\n            payload: BSON.serialize(payload, bsonOptions)\n        };\n        await connection.command((0, utils_1.ns)(`${db}.$cmd`), saslContinue, undefined);\n    }\n}\nexports.MongoDBAWS = MongoDBAWS;\nasync function makeTempCredentials(credentials, awsCredentialFetcher) {\n    function makeMongoCredentialsFromAWSTemp(creds) {\n        // The AWS session token (creds.Token) may or may not be set.\n        if (!creds.AccessKeyId || !creds.SecretAccessKey) {\n            throw new error_1.MongoMissingCredentialsError('Could not obtain temporary MONGODB-AWS credentials');\n        }\n        return new mongo_credentials_1.MongoCredentials({\n            username: creds.AccessKeyId,\n            password: creds.SecretAccessKey,\n            source: credentials.source,\n            mechanism: providers_1.AuthMechanism.MONGODB_AWS,\n            mechanismProperties: {\n                AWS_SESSION_TOKEN: creds.Token\n            }\n        });\n    }\n    const temporaryCredentials = await awsCredentialFetcher.getCredentials();\n    return makeMongoCredentialsFromAWSTemp(temporaryCredentials);\n}\nfunction deriveRegion(host) {\n    const parts = host.split('.');\n    if (parts.length === 1 || parts[1] === 'amazonaws') {\n        return 'us-east-1';\n    }\n    return parts[1];\n}\n//# sourceMappingURL=mongodb_aws.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/auth/mongodb_aws.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc.js":
/*!************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoDBOIDC = exports.OIDC_WORKFLOWS = exports.OIDC_VERSION = void 0;\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst auth_provider_1 = __webpack_require__(/*! ./auth_provider */ \"./node_modules/mongodb/lib/cmap/auth/auth_provider.js\");\nconst azure_machine_workflow_1 = __webpack_require__(/*! ./mongodb_oidc/azure_machine_workflow */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/azure_machine_workflow.js\");\nconst gcp_machine_workflow_1 = __webpack_require__(/*! ./mongodb_oidc/gcp_machine_workflow */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/gcp_machine_workflow.js\");\nconst token_cache_1 = __webpack_require__(/*! ./mongodb_oidc/token_cache */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/token_cache.js\");\nconst token_machine_workflow_1 = __webpack_require__(/*! ./mongodb_oidc/token_machine_workflow */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/token_machine_workflow.js\");\n/** Error when credentials are missing. */\nconst MISSING_CREDENTIALS_ERROR = 'AuthContext must provide credentials.';\n/** The current version of OIDC implementation. */\nexports.OIDC_VERSION = 1;\n/** @internal */\nexports.OIDC_WORKFLOWS = new Map();\nexports.OIDC_WORKFLOWS.set('test', () => new token_machine_workflow_1.TokenMachineWorkflow(new token_cache_1.TokenCache()));\nexports.OIDC_WORKFLOWS.set('azure', () => new azure_machine_workflow_1.AzureMachineWorkflow(new token_cache_1.TokenCache()));\nexports.OIDC_WORKFLOWS.set('gcp', () => new gcp_machine_workflow_1.GCPMachineWorkflow(new token_cache_1.TokenCache()));\n/**\n * OIDC auth provider.\n */\nclass MongoDBOIDC extends auth_provider_1.AuthProvider {\n    /**\n     * Instantiate the auth provider.\n     */\n    constructor(workflow) {\n        super();\n        if (!workflow) {\n            throw new error_1.MongoInvalidArgumentError('No workflow provided to the OIDC auth provider.');\n        }\n        this.workflow = workflow;\n    }\n    /**\n     * Authenticate using OIDC\n     */\n    async auth(authContext) {\n        const { connection, reauthenticating, response } = authContext;\n        if (response?.speculativeAuthenticate?.done) {\n            return;\n        }\n        const credentials = getCredentials(authContext);\n        if (reauthenticating) {\n            await this.workflow.reauthenticate(connection, credentials);\n        }\n        else {\n            await this.workflow.execute(connection, credentials, response);\n        }\n    }\n    /**\n     * Add the speculative auth for the initial handshake.\n     */\n    async prepare(handshakeDoc, authContext) {\n        const { connection } = authContext;\n        const credentials = getCredentials(authContext);\n        const result = await this.workflow.speculativeAuth(connection, credentials);\n        return { ...handshakeDoc, ...result };\n    }\n}\nexports.MongoDBOIDC = MongoDBOIDC;\n/**\n * Get credentials from the auth context, throwing if they do not exist.\n */\nfunction getCredentials(authContext) {\n    const { credentials } = authContext;\n    if (!credentials) {\n        throw new error_1.MongoMissingCredentialsError(MISSING_CREDENTIALS_ERROR);\n    }\n    return credentials;\n}\n//# sourceMappingURL=mongodb_oidc.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/automated_callback_workflow.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/automated_callback_workflow.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AutomatedCallbackWorkflow = void 0;\nconst error_1 = __webpack_require__(/*! ../../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst timeout_1 = __webpack_require__(/*! ../../../timeout */ \"./node_modules/mongodb/lib/timeout.js\");\nconst mongodb_oidc_1 = __webpack_require__(/*! ../mongodb_oidc */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc.js\");\nconst callback_workflow_1 = __webpack_require__(/*! ./callback_workflow */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/callback_workflow.js\");\n/**\n * Class implementing behaviour for the non human callback workflow.\n * @internal\n */\nclass AutomatedCallbackWorkflow extends callback_workflow_1.CallbackWorkflow {\n    /**\n     * Instantiate the human callback workflow.\n     */\n    constructor(cache, callback) {\n        super(cache, callback);\n    }\n    /**\n     * Execute the OIDC callback workflow.\n     */\n    async execute(connection, credentials) {\n        // If there is a cached access token, try to authenticate with it. If\n        // authentication fails with an Authentication error (18),\n        // invalidate the access token, fetch a new access token, and try\n        // to authenticate again.\n        // If the server fails for any other reason, do not clear the cache.\n        if (this.cache.hasAccessToken) {\n            const token = this.cache.getAccessToken();\n            try {\n                return await this.finishAuthentication(connection, credentials, token);\n            }\n            catch (error) {\n                if (error instanceof error_1.MongoError &&\n                    error.code === error_1.MONGODB_ERROR_CODES.AuthenticationFailed) {\n                    this.cache.removeAccessToken();\n                    return await this.execute(connection, credentials);\n                }\n                else {\n                    throw error;\n                }\n            }\n        }\n        const response = await this.fetchAccessToken(credentials);\n        this.cache.put(response);\n        connection.accessToken = response.accessToken;\n        await this.finishAuthentication(connection, credentials, response.accessToken);\n    }\n    /**\n     * Fetches the access token using the callback.\n     */\n    async fetchAccessToken(credentials) {\n        const controller = new AbortController();\n        const params = {\n            timeoutContext: controller.signal,\n            version: mongodb_oidc_1.OIDC_VERSION\n        };\n        if (credentials.username) {\n            params.username = credentials.username;\n        }\n        const timeout = timeout_1.Timeout.expires(callback_workflow_1.AUTOMATED_TIMEOUT_MS);\n        try {\n            return await Promise.race([this.executeAndValidateCallback(params), timeout]);\n        }\n        catch (error) {\n            if (timeout_1.TimeoutError.is(error)) {\n                controller.abort();\n                throw new error_1.MongoOIDCError(`OIDC callback timed out after ${callback_workflow_1.AUTOMATED_TIMEOUT_MS}ms.`);\n            }\n            throw error;\n        }\n        finally {\n            timeout.clear();\n        }\n    }\n}\nexports.AutomatedCallbackWorkflow = AutomatedCallbackWorkflow;\n//# sourceMappingURL=automated_callback_workflow.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/automated_callback_workflow.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/azure_machine_workflow.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/azure_machine_workflow.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AzureMachineWorkflow = void 0;\nconst azure_1 = __webpack_require__(/*! ../../../client-side-encryption/providers/azure */ \"./node_modules/mongodb/lib/client-side-encryption/providers/azure.js\");\nconst error_1 = __webpack_require__(/*! ../../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst machine_workflow_1 = __webpack_require__(/*! ./machine_workflow */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/machine_workflow.js\");\n/** Azure request headers. */\nconst AZURE_HEADERS = Object.freeze({ Metadata: 'true', Accept: 'application/json' });\n/** Invalid endpoint result error. */\nconst ENDPOINT_RESULT_ERROR = 'Azure endpoint did not return a value with only access_token and expires_in properties';\n/** Error for when the token audience is missing in the environment. */\nconst TOKEN_RESOURCE_MISSING_ERROR = 'TOKEN_RESOURCE must be set in the auth mechanism properties when ENVIRONMENT is azure.';\n/**\n * Device workflow implementation for Azure.\n *\n * @internal\n */\nclass AzureMachineWorkflow extends machine_workflow_1.MachineWorkflow {\n    /**\n     * Instantiate the machine workflow.\n     */\n    constructor(cache) {\n        super(cache);\n    }\n    /**\n     * Get the token from the environment.\n     */\n    async getToken(credentials) {\n        const tokenAudience = credentials?.mechanismProperties.TOKEN_RESOURCE;\n        const username = credentials?.username;\n        if (!tokenAudience) {\n            throw new error_1.MongoAzureError(TOKEN_RESOURCE_MISSING_ERROR);\n        }\n        const response = await getAzureTokenData(tokenAudience, username);\n        if (!isEndpointResultValid(response)) {\n            throw new error_1.MongoAzureError(ENDPOINT_RESULT_ERROR);\n        }\n        return response;\n    }\n}\nexports.AzureMachineWorkflow = AzureMachineWorkflow;\n/**\n * Hit the Azure endpoint to get the token data.\n */\nasync function getAzureTokenData(tokenAudience, username) {\n    const url = new URL(azure_1.AZURE_BASE_URL);\n    (0, azure_1.addAzureParams)(url, tokenAudience, username);\n    const response = await (0, utils_1.get)(url, {\n        headers: AZURE_HEADERS\n    });\n    if (response.status !== 200) {\n        throw new error_1.MongoAzureError(`Status code ${response.status} returned from the Azure endpoint. Response body: ${response.body}`);\n    }\n    const result = JSON.parse(response.body);\n    return {\n        access_token: result.access_token,\n        expires_in: Number(result.expires_in)\n    };\n}\n/**\n * Determines if a result returned from the endpoint is valid.\n * This means the result is not nullish, contains the access_token required field\n * and the expires_in required field.\n */\nfunction isEndpointResultValid(token) {\n    if (token == null || typeof token !== 'object')\n        return false;\n    return ('access_token' in token &&\n        typeof token.access_token === 'string' &&\n        'expires_in' in token &&\n        typeof token.expires_in === 'number');\n}\n//# sourceMappingURL=azure_machine_workflow.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/azure_machine_workflow.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/callback_workflow.js":
/*!******************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/callback_workflow.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CallbackWorkflow = exports.AUTOMATED_TIMEOUT_MS = exports.HUMAN_TIMEOUT_MS = void 0;\nconst promises_1 = __webpack_require__(/*! timers/promises */ \"timers/promises\");\nconst error_1 = __webpack_require__(/*! ../../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_builders_1 = __webpack_require__(/*! ./command_builders */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/command_builders.js\");\n/** 5 minutes in milliseconds */\nexports.HUMAN_TIMEOUT_MS = 300000;\n/** 1 minute in milliseconds */\nexports.AUTOMATED_TIMEOUT_MS = 60000;\n/** Properties allowed on results of callbacks. */\nconst RESULT_PROPERTIES = ['accessToken', 'expiresInSeconds', 'refreshToken'];\n/** Error message when the callback result is invalid. */\nconst CALLBACK_RESULT_ERROR = 'User provided OIDC callbacks must return a valid object with an accessToken.';\n/** The time to throttle callback calls. */\nconst THROTTLE_MS = 100;\n/**\n * OIDC implementation of a callback based workflow.\n * @internal\n */\nclass CallbackWorkflow {\n    /**\n     * Instantiate the callback workflow.\n     */\n    constructor(cache, callback) {\n        this.cache = cache;\n        this.callback = this.withLock(callback);\n        this.lastExecutionTime = Date.now() - THROTTLE_MS;\n    }\n    /**\n     * Get the document to add for speculative authentication. This also needs\n     * to add a db field from the credentials source.\n     */\n    async speculativeAuth(connection, credentials) {\n        // Check if the Client Cache has an access token.\n        // If it does, cache the access token in the Connection Cache and send a JwtStepRequest\n        // with the cached access token in the speculative authentication SASL payload.\n        if (this.cache.hasAccessToken) {\n            const accessToken = this.cache.getAccessToken();\n            connection.accessToken = accessToken;\n            const document = (0, command_builders_1.finishCommandDocument)(accessToken);\n            document.db = credentials.source;\n            return { speculativeAuthenticate: document };\n        }\n        return {};\n    }\n    /**\n     * Reauthenticate the callback workflow. For this we invalidated the access token\n     * in the cache and run the authentication steps again. No initial handshake needs\n     * to be sent.\n     */\n    async reauthenticate(connection, credentials) {\n        if (this.cache.hasAccessToken) {\n            // Reauthentication implies the token has expired.\n            if (connection.accessToken === this.cache.getAccessToken()) {\n                // If connection's access token is the same as the cache's, remove\n                // the token from the cache and connection.\n                this.cache.removeAccessToken();\n                delete connection.accessToken;\n            }\n            else {\n                // If the connection's access token is different from the cache's, set\n                // the cache's token on the connection and do not remove from the\n                // cache.\n                connection.accessToken = this.cache.getAccessToken();\n            }\n        }\n        await this.execute(connection, credentials);\n    }\n    /**\n     * Starts the callback authentication process. If there is a speculative\n     * authentication document from the initial handshake, then we will use that\n     * value to get the issuer, otherwise we will send the saslStart command.\n     */\n    async startAuthentication(connection, credentials, response) {\n        let result;\n        if (response?.speculativeAuthenticate) {\n            result = response.speculativeAuthenticate;\n        }\n        else {\n            result = await connection.command((0, utils_1.ns)(credentials.source), (0, command_builders_1.startCommandDocument)(credentials), undefined);\n        }\n        return result;\n    }\n    /**\n     * Finishes the callback authentication process.\n     */\n    async finishAuthentication(connection, credentials, token, conversationId) {\n        await connection.command((0, utils_1.ns)(credentials.source), (0, command_builders_1.finishCommandDocument)(token, conversationId), undefined);\n    }\n    /**\n     * Executes the callback and validates the output.\n     */\n    async executeAndValidateCallback(params) {\n        const result = await this.callback(params);\n        // Validate that the result returned by the callback is acceptable. If it is not\n        // we must clear the token result from the cache.\n        if (isCallbackResultInvalid(result)) {\n            throw new error_1.MongoMissingCredentialsError(CALLBACK_RESULT_ERROR);\n        }\n        return result;\n    }\n    /**\n     * Ensure the callback is only executed one at a time and throttles the calls\n     * to every 100ms.\n     */\n    withLock(callback) {\n        let lock = Promise.resolve();\n        return async (params) => {\n            // We do this to ensure that we would never return the result of the\n            // previous lock, only the current callback's value would get returned.\n            await lock;\n            lock = lock\n                // eslint-disable-next-line github/no-then\n                .catch(() => null)\n                // eslint-disable-next-line github/no-then\n                .then(async () => {\n                const difference = Date.now() - this.lastExecutionTime;\n                if (difference <= THROTTLE_MS) {\n                    await (0, promises_1.setTimeout)(THROTTLE_MS - difference, { signal: params.timeoutContext });\n                }\n                this.lastExecutionTime = Date.now();\n                return await callback(params);\n            });\n            return await lock;\n        };\n    }\n}\nexports.CallbackWorkflow = CallbackWorkflow;\n/**\n * Determines if a result returned from a request or refresh callback\n * function is invalid. This means the result is nullish, doesn't contain\n * the accessToken required field, and does not contain extra fields.\n */\nfunction isCallbackResultInvalid(tokenResult) {\n    if (tokenResult == null || typeof tokenResult !== 'object')\n        return true;\n    if (!('accessToken' in tokenResult))\n        return true;\n    return !Object.getOwnPropertyNames(tokenResult).every(prop => RESULT_PROPERTIES.includes(prop));\n}\n//# sourceMappingURL=callback_workflow.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/callback_workflow.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/command_builders.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/command_builders.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.startCommandDocument = exports.finishCommandDocument = void 0;\nconst bson_1 = __webpack_require__(/*! bson */ \"./node_modules/bson/lib/bson.cjs\");\nconst providers_1 = __webpack_require__(/*! ../providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\n/**\n * Generate the finishing command document for authentication. Will be a\n * saslStart or saslContinue depending on the presence of a conversation id.\n */\nfunction finishCommandDocument(token, conversationId) {\n    if (conversationId != null) {\n        return {\n            saslContinue: 1,\n            conversationId: conversationId,\n            payload: new bson_1.Binary(bson_1.BSON.serialize({ jwt: token }))\n        };\n    }\n    // saslContinue requires a conversationId in the command to be valid so in this\n    // case the server allows \"step two\" to actually be a saslStart with the token\n    // as the jwt since the use of the cached value has no correlating conversating\n    // on the particular connection.\n    return {\n        saslStart: 1,\n        mechanism: providers_1.AuthMechanism.MONGODB_OIDC,\n        payload: new bson_1.Binary(bson_1.BSON.serialize({ jwt: token }))\n    };\n}\nexports.finishCommandDocument = finishCommandDocument;\n/**\n * Generate the saslStart command document.\n */\nfunction startCommandDocument(credentials) {\n    const payload = {};\n    if (credentials.username) {\n        payload.n = credentials.username;\n    }\n    return {\n        saslStart: 1,\n        autoAuthorize: 1,\n        mechanism: providers_1.AuthMechanism.MONGODB_OIDC,\n        payload: new bson_1.Binary(bson_1.BSON.serialize(payload))\n    };\n}\nexports.startCommandDocument = startCommandDocument;\n//# sourceMappingURL=command_builders.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/command_builders.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/gcp_machine_workflow.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/gcp_machine_workflow.js ***!
  \*********************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.GCPMachineWorkflow = void 0;\nconst error_1 = __webpack_require__(/*! ../../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst machine_workflow_1 = __webpack_require__(/*! ./machine_workflow */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/machine_workflow.js\");\n/** GCP base URL. */\nconst GCP_BASE_URL = 'http://metadata/computeMetadata/v1/instance/service-accounts/default/identity';\n/** GCP request headers. */\nconst GCP_HEADERS = Object.freeze({ 'Metadata-Flavor': 'Google' });\n/** Error for when the token audience is missing in the environment. */\nconst TOKEN_RESOURCE_MISSING_ERROR = 'TOKEN_RESOURCE must be set in the auth mechanism properties when ENVIRONMENT is gcp.';\nclass GCPMachineWorkflow extends machine_workflow_1.MachineWorkflow {\n    /**\n     * Instantiate the machine workflow.\n     */\n    constructor(cache) {\n        super(cache);\n    }\n    /**\n     * Get the token from the environment.\n     */\n    async getToken(credentials) {\n        const tokenAudience = credentials?.mechanismProperties.TOKEN_RESOURCE;\n        if (!tokenAudience) {\n            throw new error_1.MongoGCPError(TOKEN_RESOURCE_MISSING_ERROR);\n        }\n        return await getGcpTokenData(tokenAudience);\n    }\n}\nexports.GCPMachineWorkflow = GCPMachineWorkflow;\n/**\n * Hit the GCP endpoint to get the token data.\n */\nasync function getGcpTokenData(tokenAudience) {\n    const url = new URL(GCP_BASE_URL);\n    url.searchParams.append('audience', tokenAudience);\n    const response = await (0, utils_1.get)(url, {\n        headers: GCP_HEADERS\n    });\n    if (response.status !== 200) {\n        throw new error_1.MongoGCPError(`Status code ${response.status} returned from the GCP endpoint. Response body: ${response.body}`);\n    }\n    return { access_token: response.body };\n}\n//# sourceMappingURL=gcp_machine_workflow.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/gcp_machine_workflow.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/human_callback_workflow.js":
/*!************************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/human_callback_workflow.js ***!
  \************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.HumanCallbackWorkflow = void 0;\nconst bson_1 = __webpack_require__(/*! bson */ \"./node_modules/bson/lib/bson.cjs\");\nconst error_1 = __webpack_require__(/*! ../../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst timeout_1 = __webpack_require__(/*! ../../../timeout */ \"./node_modules/mongodb/lib/timeout.js\");\nconst mongodb_oidc_1 = __webpack_require__(/*! ../mongodb_oidc */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc.js\");\nconst callback_workflow_1 = __webpack_require__(/*! ./callback_workflow */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/callback_workflow.js\");\n/**\n * Class implementing behaviour for the non human callback workflow.\n * @internal\n */\nclass HumanCallbackWorkflow extends callback_workflow_1.CallbackWorkflow {\n    /**\n     * Instantiate the human callback workflow.\n     */\n    constructor(cache, callback) {\n        super(cache, callback);\n    }\n    /**\n     * Execute the OIDC human callback workflow.\n     */\n    async execute(connection, credentials) {\n        // Check if the Client Cache has an access token.\n        // If it does, cache the access token in the Connection Cache and perform a One-Step SASL conversation\n        // using the access token. If the server returns an Authentication error (18),\n        // invalidate the access token token from the Client Cache, clear the Connection Cache,\n        // and restart the authentication flow. Raise any other errors to the user. On success, exit the algorithm.\n        if (this.cache.hasAccessToken) {\n            const token = this.cache.getAccessToken();\n            connection.accessToken = token;\n            try {\n                return await this.finishAuthentication(connection, credentials, token);\n            }\n            catch (error) {\n                if (error instanceof error_1.MongoError &&\n                    error.code === error_1.MONGODB_ERROR_CODES.AuthenticationFailed) {\n                    this.cache.removeAccessToken();\n                    delete connection.accessToken;\n                    return await this.execute(connection, credentials);\n                }\n                else {\n                    throw error;\n                }\n            }\n        }\n        // Check if the Client Cache has a refresh token.\n        // If it does, call the OIDC Human Callback with the cached refresh token and IdpInfo to get a\n        // new access token. Cache the new access token in the Client Cache and Connection Cache.\n        // Perform a One-Step SASL conversation using the new access token. If the the server returns\n        // an Authentication error (18), clear the refresh token, invalidate the access token from the\n        // Client Cache, clear the Connection Cache, and restart the authentication flow. Raise any other\n        // errors to the user. On success, exit the algorithm.\n        if (this.cache.hasRefreshToken) {\n            const refreshToken = this.cache.getRefreshToken();\n            const result = await this.fetchAccessToken(this.cache.getIdpInfo(), credentials, refreshToken);\n            this.cache.put(result);\n            connection.accessToken = result.accessToken;\n            try {\n                return await this.finishAuthentication(connection, credentials, result.accessToken);\n            }\n            catch (error) {\n                if (error instanceof error_1.MongoError &&\n                    error.code === error_1.MONGODB_ERROR_CODES.AuthenticationFailed) {\n                    this.cache.removeRefreshToken();\n                    delete connection.accessToken;\n                    return await this.execute(connection, credentials);\n                }\n                else {\n                    throw error;\n                }\n            }\n        }\n        // Start a new Two-Step SASL conversation.\n        // Run a PrincipalStepRequest to get the IdpInfo.\n        // Call the OIDC Human Callback with the new IdpInfo to get a new access token and optional refresh\n        // token. Drivers MUST NOT pass a cached refresh token to the callback when performing\n        // a new Two-Step conversation. Cache the new IdpInfo and refresh token in the Client Cache and the\n        // new access token in the Client Cache and Connection Cache.\n        // Attempt to authenticate using a JwtStepRequest with the new access token. Raise any errors to the user.\n        const startResponse = await this.startAuthentication(connection, credentials);\n        const conversationId = startResponse.conversationId;\n        const idpInfo = bson_1.BSON.deserialize(startResponse.payload.buffer);\n        const callbackResponse = await this.fetchAccessToken(idpInfo, credentials);\n        this.cache.put(callbackResponse, idpInfo);\n        connection.accessToken = callbackResponse.accessToken;\n        return await this.finishAuthentication(connection, credentials, callbackResponse.accessToken, conversationId);\n    }\n    /**\n     * Fetches an access token using the callback.\n     */\n    async fetchAccessToken(idpInfo, credentials, refreshToken) {\n        const controller = new AbortController();\n        const params = {\n            timeoutContext: controller.signal,\n            version: mongodb_oidc_1.OIDC_VERSION,\n            idpInfo: idpInfo\n        };\n        if (credentials.username) {\n            params.username = credentials.username;\n        }\n        if (refreshToken) {\n            params.refreshToken = refreshToken;\n        }\n        const timeout = timeout_1.Timeout.expires(callback_workflow_1.HUMAN_TIMEOUT_MS);\n        try {\n            return await Promise.race([this.executeAndValidateCallback(params), timeout]);\n        }\n        catch (error) {\n            if (timeout_1.TimeoutError.is(error)) {\n                controller.abort();\n                throw new error_1.MongoOIDCError(`OIDC callback timed out after ${callback_workflow_1.HUMAN_TIMEOUT_MS}ms.`);\n            }\n            throw error;\n        }\n        finally {\n            timeout.clear();\n        }\n    }\n}\nexports.HumanCallbackWorkflow = HumanCallbackWorkflow;\n//# sourceMappingURL=human_callback_workflow.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/human_callback_workflow.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/machine_workflow.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/machine_workflow.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MachineWorkflow = void 0;\nconst promises_1 = __webpack_require__(/*! timers/promises */ \"timers/promises\");\nconst utils_1 = __webpack_require__(/*! ../../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_builders_1 = __webpack_require__(/*! ./command_builders */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/command_builders.js\");\n/** The time to throttle callback calls. */\nconst THROTTLE_MS = 100;\n/**\n * Common behaviour for OIDC machine workflows.\n * @internal\n */\nclass MachineWorkflow {\n    /**\n     * Instantiate the machine workflow.\n     */\n    constructor(cache) {\n        this.cache = cache;\n        this.callback = this.withLock(this.getToken.bind(this));\n        this.lastExecutionTime = Date.now() - THROTTLE_MS;\n    }\n    /**\n     * Execute the workflow. Gets the token from the subclass implementation.\n     */\n    async execute(connection, credentials) {\n        const token = await this.getTokenFromCacheOrEnv(connection, credentials);\n        const command = (0, command_builders_1.finishCommandDocument)(token);\n        await connection.command((0, utils_1.ns)(credentials.source), command, undefined);\n    }\n    /**\n     * Reauthenticate on a machine workflow just grabs the token again since the server\n     * has said the current access token is invalid or expired.\n     */\n    async reauthenticate(connection, credentials) {\n        if (this.cache.hasAccessToken) {\n            // Reauthentication implies the token has expired.\n            if (connection.accessToken === this.cache.getAccessToken()) {\n                // If connection's access token is the same as the cache's, remove\n                // the token from the cache and connection.\n                this.cache.removeAccessToken();\n                delete connection.accessToken;\n            }\n            else {\n                // If the connection's access token is different from the cache's, set\n                // the cache's token on the connection and do not remove from the\n                // cache.\n                connection.accessToken = this.cache.getAccessToken();\n            }\n        }\n        await this.execute(connection, credentials);\n    }\n    /**\n     * Get the document to add for speculative authentication.\n     */\n    async speculativeAuth(connection, credentials) {\n        // The spec states only cached access tokens can use speculative auth.\n        if (!this.cache.hasAccessToken) {\n            return {};\n        }\n        const token = await this.getTokenFromCacheOrEnv(connection, credentials);\n        const document = (0, command_builders_1.finishCommandDocument)(token);\n        document.db = credentials.source;\n        return { speculativeAuthenticate: document };\n    }\n    /**\n     * Get the token from the cache or environment.\n     */\n    async getTokenFromCacheOrEnv(connection, credentials) {\n        if (this.cache.hasAccessToken) {\n            return this.cache.getAccessToken();\n        }\n        else {\n            const token = await this.callback(credentials);\n            this.cache.put({ accessToken: token.access_token, expiresInSeconds: token.expires_in });\n            // Put the access token on the connection as well.\n            connection.accessToken = token.access_token;\n            return token.access_token;\n        }\n    }\n    /**\n     * Ensure the callback is only executed one at a time, and throttled to\n     * only once per 100ms.\n     */\n    withLock(callback) {\n        let lock = Promise.resolve();\n        return async (credentials) => {\n            // We do this to ensure that we would never return the result of the\n            // previous lock, only the current callback's value would get returned.\n            await lock;\n            lock = lock\n                // eslint-disable-next-line github/no-then\n                .catch(() => null)\n                // eslint-disable-next-line github/no-then\n                .then(async () => {\n                const difference = Date.now() - this.lastExecutionTime;\n                if (difference <= THROTTLE_MS) {\n                    await (0, promises_1.setTimeout)(THROTTLE_MS - difference);\n                }\n                this.lastExecutionTime = Date.now();\n                return await callback(credentials);\n            });\n            return await lock;\n        };\n    }\n}\nexports.MachineWorkflow = MachineWorkflow;\n//# sourceMappingURL=machine_workflow.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/machine_workflow.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/token_cache.js":
/*!************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/token_cache.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TokenCache = void 0;\nconst error_1 = __webpack_require__(/*! ../../../error */ \"./node_modules/mongodb/lib/error.js\");\nclass MongoOIDCError extends error_1.MongoDriverError {\n}\n/** @internal */\nclass TokenCache {\n    get hasAccessToken() {\n        return !!this.accessToken;\n    }\n    get hasRefreshToken() {\n        return !!this.refreshToken;\n    }\n    get hasIdpInfo() {\n        return !!this.idpInfo;\n    }\n    getAccessToken() {\n        if (!this.accessToken) {\n            throw new MongoOIDCError('Attempted to get an access token when none exists.');\n        }\n        return this.accessToken;\n    }\n    getRefreshToken() {\n        if (!this.refreshToken) {\n            throw new MongoOIDCError('Attempted to get a refresh token when none exists.');\n        }\n        return this.refreshToken;\n    }\n    getIdpInfo() {\n        if (!this.idpInfo) {\n            throw new MongoOIDCError('Attempted to get IDP information when none exists.');\n        }\n        return this.idpInfo;\n    }\n    put(response, idpInfo) {\n        this.accessToken = response.accessToken;\n        this.refreshToken = response.refreshToken;\n        this.expiresInSeconds = response.expiresInSeconds;\n        if (idpInfo) {\n            this.idpInfo = idpInfo;\n        }\n    }\n    removeAccessToken() {\n        this.accessToken = undefined;\n    }\n    removeRefreshToken() {\n        this.refreshToken = undefined;\n    }\n}\nexports.TokenCache = TokenCache;\n//# sourceMappingURL=token_cache.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/token_cache.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/token_machine_workflow.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/token_machine_workflow.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TokenMachineWorkflow = void 0;\nconst fs = __webpack_require__(/*! fs */ \"fs\");\nconst error_1 = __webpack_require__(/*! ../../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst machine_workflow_1 = __webpack_require__(/*! ./machine_workflow */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/machine_workflow.js\");\n/** Error for when the token is missing in the environment. */\nconst TOKEN_MISSING_ERROR = 'OIDC_TOKEN_FILE must be set in the environment.';\n/**\n * Device workflow implementation for AWS.\n *\n * @internal\n */\nclass TokenMachineWorkflow extends machine_workflow_1.MachineWorkflow {\n    /**\n     * Instantiate the machine workflow.\n     */\n    constructor(cache) {\n        super(cache);\n    }\n    /**\n     * Get the token from the environment.\n     */\n    async getToken() {\n        const tokenFile = process.env.OIDC_TOKEN_FILE;\n        if (!tokenFile) {\n            throw new error_1.MongoAWSError(TOKEN_MISSING_ERROR);\n        }\n        const token = await fs.promises.readFile(tokenFile, 'utf8');\n        return { access_token: token };\n    }\n}\nexports.TokenMachineWorkflow = TokenMachineWorkflow;\n//# sourceMappingURL=token_machine_workflow.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/token_machine_workflow.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/plain.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/plain.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Plain = void 0;\nconst bson_1 = __webpack_require__(/*! ../../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst auth_provider_1 = __webpack_require__(/*! ./auth_provider */ \"./node_modules/mongodb/lib/cmap/auth/auth_provider.js\");\nclass Plain extends auth_provider_1.AuthProvider {\n    async auth(authContext) {\n        const { connection, credentials } = authContext;\n        if (!credentials) {\n            throw new error_1.MongoMissingCredentialsError('AuthContext must provide credentials.');\n        }\n        const { username, password } = credentials;\n        const payload = new bson_1.Binary(Buffer.from(`\\x00${username}\\x00${password}`));\n        const command = {\n            saslStart: 1,\n            mechanism: 'PLAIN',\n            payload: payload,\n            autoAuthorize: 1\n        };\n        await connection.command((0, utils_1.ns)('$external.$cmd'), command, undefined);\n    }\n}\nexports.Plain = Plain;\n//# sourceMappingURL=plain.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/auth/plain.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/providers.js":
/*!*********************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/providers.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AUTH_MECHS_AUTH_SRC_EXTERNAL = exports.AuthMechanism = void 0;\n/** @public */\nexports.AuthMechanism = Object.freeze({\n    MONGODB_AWS: 'MONGODB-AWS',\n    MONGODB_CR: 'MONGODB-CR',\n    MONGODB_DEFAULT: 'DEFAULT',\n    MONGODB_GSSAPI: 'GSSAPI',\n    MONGODB_PLAIN: 'PLAIN',\n    MONGODB_SCRAM_SHA1: 'SCRAM-SHA-1',\n    MONGODB_SCRAM_SHA256: 'SCRAM-SHA-256',\n    MONGODB_X509: 'MONGODB-X509',\n    MONGODB_OIDC: 'MONGODB-OIDC'\n});\n/** @internal */\nexports.AUTH_MECHS_AUTH_SRC_EXTERNAL = new Set([\n    exports.AuthMechanism.MONGODB_GSSAPI,\n    exports.AuthMechanism.MONGODB_AWS,\n    exports.AuthMechanism.MONGODB_OIDC,\n    exports.AuthMechanism.MONGODB_X509\n]);\n//# sourceMappingURL=providers.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/auth/providers.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/scram.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/scram.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ScramSHA256 = exports.ScramSHA1 = void 0;\nconst saslprep_1 = __webpack_require__(/*! @mongodb-js/saslprep */ \"./node_modules/@mongodb-js/saslprep/dist/node.js\");\nconst crypto = __webpack_require__(/*! crypto */ \"crypto\");\nconst bson_1 = __webpack_require__(/*! ../../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst auth_provider_1 = __webpack_require__(/*! ./auth_provider */ \"./node_modules/mongodb/lib/cmap/auth/auth_provider.js\");\nconst providers_1 = __webpack_require__(/*! ./providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\nclass ScramSHA extends auth_provider_1.AuthProvider {\n    constructor(cryptoMethod) {\n        super();\n        this.cryptoMethod = cryptoMethod || 'sha1';\n    }\n    async prepare(handshakeDoc, authContext) {\n        const cryptoMethod = this.cryptoMethod;\n        const credentials = authContext.credentials;\n        if (!credentials) {\n            throw new error_1.MongoMissingCredentialsError('AuthContext must provide credentials.');\n        }\n        const nonce = await (0, utils_1.randomBytes)(24);\n        // store the nonce for later use\n        authContext.nonce = nonce;\n        const request = {\n            ...handshakeDoc,\n            speculativeAuthenticate: {\n                ...makeFirstMessage(cryptoMethod, credentials, nonce),\n                db: credentials.source\n            }\n        };\n        return request;\n    }\n    async auth(authContext) {\n        const { reauthenticating, response } = authContext;\n        if (response?.speculativeAuthenticate && !reauthenticating) {\n            return await continueScramConversation(this.cryptoMethod, response.speculativeAuthenticate, authContext);\n        }\n        return await executeScram(this.cryptoMethod, authContext);\n    }\n}\nfunction cleanUsername(username) {\n    return username.replace('=', '=3D').replace(',', '=2C');\n}\nfunction clientFirstMessageBare(username, nonce) {\n    // NOTE: This is done b/c Javascript uses UTF-16, but the server is hashing in UTF-8.\n    // Since the username is not sasl-prep-d, we need to do this here.\n    return Buffer.concat([\n        Buffer.from('n=', 'utf8'),\n        Buffer.from(username, 'utf8'),\n        Buffer.from(',r=', 'utf8'),\n        Buffer.from(nonce.toString('base64'), 'utf8')\n    ]);\n}\nfunction makeFirstMessage(cryptoMethod, credentials, nonce) {\n    const username = cleanUsername(credentials.username);\n    const mechanism = cryptoMethod === 'sha1' ? providers_1.AuthMechanism.MONGODB_SCRAM_SHA1 : providers_1.AuthMechanism.MONGODB_SCRAM_SHA256;\n    // NOTE: This is done b/c Javascript uses UTF-16, but the server is hashing in UTF-8.\n    // Since the username is not sasl-prep-d, we need to do this here.\n    return {\n        saslStart: 1,\n        mechanism,\n        payload: new bson_1.Binary(Buffer.concat([Buffer.from('n,,', 'utf8'), clientFirstMessageBare(username, nonce)])),\n        autoAuthorize: 1,\n        options: { skipEmptyExchange: true }\n    };\n}\nasync function executeScram(cryptoMethod, authContext) {\n    const { connection, credentials } = authContext;\n    if (!credentials) {\n        throw new error_1.MongoMissingCredentialsError('AuthContext must provide credentials.');\n    }\n    if (!authContext.nonce) {\n        throw new error_1.MongoInvalidArgumentError('AuthContext must contain a valid nonce property');\n    }\n    const nonce = authContext.nonce;\n    const db = credentials.source;\n    const saslStartCmd = makeFirstMessage(cryptoMethod, credentials, nonce);\n    const response = await connection.command((0, utils_1.ns)(`${db}.$cmd`), saslStartCmd, undefined);\n    await continueScramConversation(cryptoMethod, response, authContext);\n}\nasync function continueScramConversation(cryptoMethod, response, authContext) {\n    const connection = authContext.connection;\n    const credentials = authContext.credentials;\n    if (!credentials) {\n        throw new error_1.MongoMissingCredentialsError('AuthContext must provide credentials.');\n    }\n    if (!authContext.nonce) {\n        throw new error_1.MongoInvalidArgumentError('Unable to continue SCRAM without valid nonce');\n    }\n    const nonce = authContext.nonce;\n    const db = credentials.source;\n    const username = cleanUsername(credentials.username);\n    const password = credentials.password;\n    const processedPassword = cryptoMethod === 'sha256' ? (0, saslprep_1.saslprep)(password) : passwordDigest(username, password);\n    const payload = Buffer.isBuffer(response.payload)\n        ? new bson_1.Binary(response.payload)\n        : response.payload;\n    const dict = parsePayload(payload);\n    const iterations = parseInt(dict.i, 10);\n    if (iterations && iterations < 4096) {\n        // TODO(NODE-3483)\n        throw new error_1.MongoRuntimeError(`Server returned an invalid iteration count ${iterations}`);\n    }\n    const salt = dict.s;\n    const rnonce = dict.r;\n    if (rnonce.startsWith('nonce')) {\n        // TODO(NODE-3483)\n        throw new error_1.MongoRuntimeError(`Server returned an invalid nonce: ${rnonce}`);\n    }\n    // Set up start of proof\n    const withoutProof = `c=biws,r=${rnonce}`;\n    const saltedPassword = HI(processedPassword, Buffer.from(salt, 'base64'), iterations, cryptoMethod);\n    const clientKey = HMAC(cryptoMethod, saltedPassword, 'Client Key');\n    const serverKey = HMAC(cryptoMethod, saltedPassword, 'Server Key');\n    const storedKey = H(cryptoMethod, clientKey);\n    const authMessage = [\n        clientFirstMessageBare(username, nonce),\n        payload.toString('utf8'),\n        withoutProof\n    ].join(',');\n    const clientSignature = HMAC(cryptoMethod, storedKey, authMessage);\n    const clientProof = `p=${xor(clientKey, clientSignature)}`;\n    const clientFinal = [withoutProof, clientProof].join(',');\n    const serverSignature = HMAC(cryptoMethod, serverKey, authMessage);\n    const saslContinueCmd = {\n        saslContinue: 1,\n        conversationId: response.conversationId,\n        payload: new bson_1.Binary(Buffer.from(clientFinal))\n    };\n    const r = await connection.command((0, utils_1.ns)(`${db}.$cmd`), saslContinueCmd, undefined);\n    const parsedResponse = parsePayload(r.payload);\n    if (!compareDigest(Buffer.from(parsedResponse.v, 'base64'), serverSignature)) {\n        throw new error_1.MongoRuntimeError('Server returned an invalid signature');\n    }\n    if (r.done !== false) {\n        // If the server sends r.done === true we can save one RTT\n        return;\n    }\n    const retrySaslContinueCmd = {\n        saslContinue: 1,\n        conversationId: r.conversationId,\n        payload: Buffer.alloc(0)\n    };\n    await connection.command((0, utils_1.ns)(`${db}.$cmd`), retrySaslContinueCmd, undefined);\n}\nfunction parsePayload(payload) {\n    const payloadStr = payload.toString('utf8');\n    const dict = {};\n    const parts = payloadStr.split(',');\n    for (let i = 0; i < parts.length; i++) {\n        const valueParts = (parts[i].match(/^([^=]*)=(.*)$/) ?? []).slice(1);\n        dict[valueParts[0]] = valueParts[1];\n    }\n    return dict;\n}\nfunction passwordDigest(username, password) {\n    if (typeof username !== 'string') {\n        throw new error_1.MongoInvalidArgumentError('Username must be a string');\n    }\n    if (typeof password !== 'string') {\n        throw new error_1.MongoInvalidArgumentError('Password must be a string');\n    }\n    if (password.length === 0) {\n        throw new error_1.MongoInvalidArgumentError('Password cannot be empty');\n    }\n    let md5;\n    try {\n        md5 = crypto.createHash('md5');\n    }\n    catch (err) {\n        if (crypto.getFips()) {\n            // This error is (slightly) more helpful than what comes from OpenSSL directly, e.g.\n            // 'Error: error:060800C8:digital envelope routines:EVP_DigestInit_ex:disabled for FIPS'\n            throw new Error('Auth mechanism SCRAM-SHA-1 is not supported in FIPS mode');\n        }\n        throw err;\n    }\n    md5.update(`${username}:mongo:${password}`, 'utf8');\n    return md5.digest('hex');\n}\n// XOR two buffers\nfunction xor(a, b) {\n    if (!Buffer.isBuffer(a)) {\n        a = Buffer.from(a);\n    }\n    if (!Buffer.isBuffer(b)) {\n        b = Buffer.from(b);\n    }\n    const length = Math.max(a.length, b.length);\n    const res = [];\n    for (let i = 0; i < length; i += 1) {\n        res.push(a[i] ^ b[i]);\n    }\n    return Buffer.from(res).toString('base64');\n}\nfunction H(method, text) {\n    return crypto.createHash(method).update(text).digest();\n}\nfunction HMAC(method, key, text) {\n    return crypto.createHmac(method, key).update(text).digest();\n}\nlet _hiCache = {};\nlet _hiCacheCount = 0;\nfunction _hiCachePurge() {\n    _hiCache = {};\n    _hiCacheCount = 0;\n}\nconst hiLengthMap = {\n    sha256: 32,\n    sha1: 20\n};\nfunction HI(data, salt, iterations, cryptoMethod) {\n    // omit the work if already generated\n    const key = [data, salt.toString('base64'), iterations].join('_');\n    if (_hiCache[key] != null) {\n        return _hiCache[key];\n    }\n    // generate the salt\n    const saltedData = crypto.pbkdf2Sync(data, salt, iterations, hiLengthMap[cryptoMethod], cryptoMethod);\n    // cache a copy to speed up the next lookup, but prevent unbounded cache growth\n    if (_hiCacheCount >= 200) {\n        _hiCachePurge();\n    }\n    _hiCache[key] = saltedData;\n    _hiCacheCount += 1;\n    return saltedData;\n}\nfunction compareDigest(lhs, rhs) {\n    if (lhs.length !== rhs.length) {\n        return false;\n    }\n    if (typeof crypto.timingSafeEqual === 'function') {\n        return crypto.timingSafeEqual(lhs, rhs);\n    }\n    let result = 0;\n    for (let i = 0; i < lhs.length; i++) {\n        result |= lhs[i] ^ rhs[i];\n    }\n    return result === 0;\n}\nclass ScramSHA1 extends ScramSHA {\n    constructor() {\n        super('sha1');\n    }\n}\nexports.ScramSHA1 = ScramSHA1;\nclass ScramSHA256 extends ScramSHA {\n    constructor() {\n        super('sha256');\n    }\n}\nexports.ScramSHA256 = ScramSHA256;\n//# sourceMappingURL=scram.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/auth/scram.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/x509.js":
/*!****************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/x509.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.X509 = void 0;\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst auth_provider_1 = __webpack_require__(/*! ./auth_provider */ \"./node_modules/mongodb/lib/cmap/auth/auth_provider.js\");\nclass X509 extends auth_provider_1.AuthProvider {\n    async prepare(handshakeDoc, authContext) {\n        const { credentials } = authContext;\n        if (!credentials) {\n            throw new error_1.MongoMissingCredentialsError('AuthContext must provide credentials.');\n        }\n        return { ...handshakeDoc, speculativeAuthenticate: x509AuthenticateCommand(credentials) };\n    }\n    async auth(authContext) {\n        const connection = authContext.connection;\n        const credentials = authContext.credentials;\n        if (!credentials) {\n            throw new error_1.MongoMissingCredentialsError('AuthContext must provide credentials.');\n        }\n        const response = authContext.response;\n        if (response?.speculativeAuthenticate) {\n            return;\n        }\n        await connection.command((0, utils_1.ns)('$external.$cmd'), x509AuthenticateCommand(credentials), undefined);\n    }\n}\nexports.X509 = X509;\nfunction x509AuthenticateCommand(credentials) {\n    const command = { authenticate: 1, mechanism: 'MONGODB-X509' };\n    if (credentials.username) {\n        command.user = credentials.username;\n    }\n    return command;\n}\n//# sourceMappingURL=x509.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/auth/x509.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/command_monitoring_events.js":
/*!********************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/command_monitoring_events.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SENSITIVE_COMMANDS = exports.CommandFailedEvent = exports.CommandSucceededEvent = exports.CommandStartedEvent = void 0;\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst commands_1 = __webpack_require__(/*! ./commands */ \"./node_modules/mongodb/lib/cmap/commands.js\");\n/**\n * An event indicating the start of a given command\n * @public\n * @category Event\n */\nclass CommandStartedEvent {\n    /**\n     * Create a started event\n     *\n     * @internal\n     * @param pool - the pool that originated the command\n     * @param command - the command\n     */\n    constructor(connection, command, serverConnectionId) {\n        /** @internal */\n        this.name = constants_1.COMMAND_STARTED;\n        const cmd = extractCommand(command);\n        const commandName = extractCommandName(cmd);\n        const { address, connectionId, serviceId } = extractConnectionDetails(connection);\n        // TODO: remove in major revision, this is not spec behavior\n        if (exports.SENSITIVE_COMMANDS.has(commandName)) {\n            this.commandObj = {};\n            this.commandObj[commandName] = true;\n        }\n        this.address = address;\n        this.connectionId = connectionId;\n        this.serviceId = serviceId;\n        this.requestId = command.requestId;\n        this.databaseName = command.databaseName;\n        this.commandName = commandName;\n        this.command = maybeRedact(commandName, cmd, cmd);\n        this.serverConnectionId = serverConnectionId;\n    }\n    /* @internal */\n    get hasServiceId() {\n        return !!this.serviceId;\n    }\n}\nexports.CommandStartedEvent = CommandStartedEvent;\n/**\n * An event indicating the success of a given command\n * @public\n * @category Event\n */\nclass CommandSucceededEvent {\n    /**\n     * Create a succeeded event\n     *\n     * @internal\n     * @param pool - the pool that originated the command\n     * @param command - the command\n     * @param reply - the reply for this command from the server\n     * @param started - a high resolution tuple timestamp of when the command was first sent, to calculate duration\n     */\n    constructor(connection, command, reply, started, serverConnectionId) {\n        /** @internal */\n        this.name = constants_1.COMMAND_SUCCEEDED;\n        const cmd = extractCommand(command);\n        const commandName = extractCommandName(cmd);\n        const { address, connectionId, serviceId } = extractConnectionDetails(connection);\n        this.address = address;\n        this.connectionId = connectionId;\n        this.serviceId = serviceId;\n        this.requestId = command.requestId;\n        this.commandName = commandName;\n        this.duration = (0, utils_1.calculateDurationInMs)(started);\n        this.reply = maybeRedact(commandName, cmd, extractReply(command, reply));\n        this.serverConnectionId = serverConnectionId;\n    }\n    /* @internal */\n    get hasServiceId() {\n        return !!this.serviceId;\n    }\n}\nexports.CommandSucceededEvent = CommandSucceededEvent;\n/**\n * An event indicating the failure of a given command\n * @public\n * @category Event\n */\nclass CommandFailedEvent {\n    /**\n     * Create a failure event\n     *\n     * @internal\n     * @param pool - the pool that originated the command\n     * @param command - the command\n     * @param error - the generated error or a server error response\n     * @param started - a high resolution tuple timestamp of when the command was first sent, to calculate duration\n     */\n    constructor(connection, command, error, started, serverConnectionId) {\n        /** @internal */\n        this.name = constants_1.COMMAND_FAILED;\n        const cmd = extractCommand(command);\n        const commandName = extractCommandName(cmd);\n        const { address, connectionId, serviceId } = extractConnectionDetails(connection);\n        this.address = address;\n        this.connectionId = connectionId;\n        this.serviceId = serviceId;\n        this.requestId = command.requestId;\n        this.commandName = commandName;\n        this.duration = (0, utils_1.calculateDurationInMs)(started);\n        this.failure = maybeRedact(commandName, cmd, error);\n        this.serverConnectionId = serverConnectionId;\n    }\n    /* @internal */\n    get hasServiceId() {\n        return !!this.serviceId;\n    }\n}\nexports.CommandFailedEvent = CommandFailedEvent;\n/**\n * Commands that we want to redact because of the sensitive nature of their contents\n * @internal\n */\nexports.SENSITIVE_COMMANDS = new Set([\n    'authenticate',\n    'saslStart',\n    'saslContinue',\n    'getnonce',\n    'createUser',\n    'updateUser',\n    'copydbgetnonce',\n    'copydbsaslstart',\n    'copydb'\n]);\nconst HELLO_COMMANDS = new Set(['hello', constants_1.LEGACY_HELLO_COMMAND, constants_1.LEGACY_HELLO_COMMAND_CAMEL_CASE]);\n// helper methods\nconst extractCommandName = (commandDoc) => Object.keys(commandDoc)[0];\nconst namespace = (command) => command.ns;\nconst collectionName = (command) => command.ns.split('.')[1];\nconst maybeRedact = (commandName, commandDoc, result) => exports.SENSITIVE_COMMANDS.has(commandName) ||\n    (HELLO_COMMANDS.has(commandName) && commandDoc.speculativeAuthenticate)\n    ? {}\n    : result;\nconst LEGACY_FIND_QUERY_MAP = {\n    $query: 'filter',\n    $orderby: 'sort',\n    $hint: 'hint',\n    $comment: 'comment',\n    $maxScan: 'maxScan',\n    $max: 'max',\n    $min: 'min',\n    $returnKey: 'returnKey',\n    $showDiskLoc: 'showRecordId',\n    $maxTimeMS: 'maxTimeMS',\n    $snapshot: 'snapshot'\n};\nconst LEGACY_FIND_OPTIONS_MAP = {\n    numberToSkip: 'skip',\n    numberToReturn: 'batchSize',\n    returnFieldSelector: 'projection'\n};\nconst OP_QUERY_KEYS = [\n    'tailable',\n    'oplogReplay',\n    'noCursorTimeout',\n    'awaitData',\n    'partial',\n    'exhaust'\n];\n/** Extract the actual command from the query, possibly up-converting if it's a legacy format */\nfunction extractCommand(command) {\n    if (command instanceof commands_1.OpMsgRequest) {\n        return (0, utils_1.deepCopy)(command.command);\n    }\n    if (command.query?.$query) {\n        let result;\n        if (command.ns === 'admin.$cmd') {\n            // up-convert legacy command\n            result = Object.assign({}, command.query.$query);\n        }\n        else {\n            // up-convert legacy find command\n            result = { find: collectionName(command) };\n            Object.keys(LEGACY_FIND_QUERY_MAP).forEach(key => {\n                if (command.query[key] != null) {\n                    result[LEGACY_FIND_QUERY_MAP[key]] = (0, utils_1.deepCopy)(command.query[key]);\n                }\n            });\n        }\n        Object.keys(LEGACY_FIND_OPTIONS_MAP).forEach(key => {\n            const legacyKey = key;\n            if (command[legacyKey] != null) {\n                result[LEGACY_FIND_OPTIONS_MAP[legacyKey]] = (0, utils_1.deepCopy)(command[legacyKey]);\n            }\n        });\n        OP_QUERY_KEYS.forEach(key => {\n            if (command[key]) {\n                result[key] = command[key];\n            }\n        });\n        if (command.pre32Limit != null) {\n            result.limit = command.pre32Limit;\n        }\n        if (command.query.$explain) {\n            return { explain: result };\n        }\n        return result;\n    }\n    const clonedQuery = {};\n    const clonedCommand = {};\n    if (command.query) {\n        for (const k in command.query) {\n            clonedQuery[k] = (0, utils_1.deepCopy)(command.query[k]);\n        }\n        clonedCommand.query = clonedQuery;\n    }\n    for (const k in command) {\n        if (k === 'query')\n            continue;\n        clonedCommand[k] = (0, utils_1.deepCopy)(command[k]);\n    }\n    return command.query ? clonedQuery : clonedCommand;\n}\nfunction extractReply(command, reply) {\n    if (!reply) {\n        return reply;\n    }\n    if (command instanceof commands_1.OpMsgRequest) {\n        return (0, utils_1.deepCopy)(reply.result ? reply.result : reply);\n    }\n    // is this a legacy find command?\n    if (command.query && command.query.$query != null) {\n        return {\n            ok: 1,\n            cursor: {\n                id: (0, utils_1.deepCopy)(reply.cursorId),\n                ns: namespace(command),\n                firstBatch: (0, utils_1.deepCopy)(reply.documents)\n            }\n        };\n    }\n    return (0, utils_1.deepCopy)(reply.result ? reply.result : reply);\n}\nfunction extractConnectionDetails(connection) {\n    let connectionId;\n    if ('id' in connection) {\n        connectionId = connection.id;\n    }\n    return {\n        address: connection.address,\n        serviceId: connection.serviceId,\n        connectionId\n    };\n}\n//# sourceMappingURL=command_monitoring_events.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/command_monitoring_events.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/commands.js":
/*!***************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/commands.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.OpCompressedRequest = exports.OpMsgResponse = exports.OpMsgRequest = exports.OpReply = exports.OpQueryRequest = void 0;\nconst BSON = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst compression_1 = __webpack_require__(/*! ./wire_protocol/compression */ \"./node_modules/mongodb/lib/cmap/wire_protocol/compression.js\");\nconst constants_1 = __webpack_require__(/*! ./wire_protocol/constants */ \"./node_modules/mongodb/lib/cmap/wire_protocol/constants.js\");\n// Incrementing request id\nlet _requestId = 0;\n// Query flags\nconst OPTS_TAILABLE_CURSOR = 2;\nconst OPTS_SECONDARY = 4;\nconst OPTS_OPLOG_REPLAY = 8;\nconst OPTS_NO_CURSOR_TIMEOUT = 16;\nconst OPTS_AWAIT_DATA = 32;\nconst OPTS_EXHAUST = 64;\nconst OPTS_PARTIAL = 128;\n// Response flags\nconst CURSOR_NOT_FOUND = 1;\nconst QUERY_FAILURE = 2;\nconst SHARD_CONFIG_STALE = 4;\nconst AWAIT_CAPABLE = 8;\n/** @internal */\nclass OpQueryRequest {\n    constructor(databaseName, query, options) {\n        this.databaseName = databaseName;\n        this.query = query;\n        // Basic options needed to be passed in\n        // TODO(NODE-3483): Replace with MongoCommandError\n        const ns = `${databaseName}.$cmd`;\n        if (typeof databaseName !== 'string') {\n            throw new error_1.MongoRuntimeError('Database name must be a string for a query');\n        }\n        // TODO(NODE-3483): Replace with MongoCommandError\n        if (query == null)\n            throw new error_1.MongoRuntimeError('A query document must be specified for query');\n        // Validate that we are not passing 0x00 in the collection name\n        if (ns.indexOf('\\x00') !== -1) {\n            // TODO(NODE-3483): Use MongoNamespace static method\n            throw new error_1.MongoRuntimeError('Namespace cannot contain a null character');\n        }\n        // Basic options\n        this.ns = ns;\n        // Additional options\n        this.numberToSkip = options.numberToSkip || 0;\n        this.numberToReturn = options.numberToReturn || 0;\n        this.returnFieldSelector = options.returnFieldSelector || undefined;\n        this.requestId = options.requestId ?? OpQueryRequest.getRequestId();\n        // special case for pre-3.2 find commands, delete ASAP\n        this.pre32Limit = options.pre32Limit;\n        // Serialization option\n        this.serializeFunctions =\n            typeof options.serializeFunctions === 'boolean' ? options.serializeFunctions : false;\n        this.ignoreUndefined =\n            typeof options.ignoreUndefined === 'boolean' ? options.ignoreUndefined : false;\n        this.maxBsonSize = options.maxBsonSize || 1024 * 1024 * 16;\n        this.checkKeys = typeof options.checkKeys === 'boolean' ? options.checkKeys : false;\n        this.batchSize = this.numberToReturn;\n        // Flags\n        this.tailable = false;\n        this.secondaryOk = typeof options.secondaryOk === 'boolean' ? options.secondaryOk : false;\n        this.oplogReplay = false;\n        this.noCursorTimeout = false;\n        this.awaitData = false;\n        this.exhaust = false;\n        this.partial = false;\n    }\n    /** Assign next request Id. */\n    incRequestId() {\n        this.requestId = _requestId++;\n    }\n    /** Peek next request Id. */\n    nextRequestId() {\n        return _requestId + 1;\n    }\n    /** Increment then return next request Id. */\n    static getRequestId() {\n        return ++_requestId;\n    }\n    // Uses a single allocated buffer for the process, avoiding multiple memory allocations\n    toBin() {\n        const buffers = [];\n        let projection = null;\n        // Set up the flags\n        let flags = 0;\n        if (this.tailable) {\n            flags |= OPTS_TAILABLE_CURSOR;\n        }\n        if (this.secondaryOk) {\n            flags |= OPTS_SECONDARY;\n        }\n        if (this.oplogReplay) {\n            flags |= OPTS_OPLOG_REPLAY;\n        }\n        if (this.noCursorTimeout) {\n            flags |= OPTS_NO_CURSOR_TIMEOUT;\n        }\n        if (this.awaitData) {\n            flags |= OPTS_AWAIT_DATA;\n        }\n        if (this.exhaust) {\n            flags |= OPTS_EXHAUST;\n        }\n        if (this.partial) {\n            flags |= OPTS_PARTIAL;\n        }\n        // If batchSize is different to this.numberToReturn\n        if (this.batchSize !== this.numberToReturn)\n            this.numberToReturn = this.batchSize;\n        // Allocate write protocol header buffer\n        const header = Buffer.alloc(4 * 4 + // Header\n            4 + // Flags\n            Buffer.byteLength(this.ns) +\n            1 + // namespace\n            4 + // numberToSkip\n            4 // numberToReturn\n        );\n        // Add header to buffers\n        buffers.push(header);\n        // Serialize the query\n        const query = BSON.serialize(this.query, {\n            checkKeys: this.checkKeys,\n            serializeFunctions: this.serializeFunctions,\n            ignoreUndefined: this.ignoreUndefined\n        });\n        // Add query document\n        buffers.push(query);\n        if (this.returnFieldSelector && Object.keys(this.returnFieldSelector).length > 0) {\n            // Serialize the projection document\n            projection = BSON.serialize(this.returnFieldSelector, {\n                checkKeys: this.checkKeys,\n                serializeFunctions: this.serializeFunctions,\n                ignoreUndefined: this.ignoreUndefined\n            });\n            // Add projection document\n            buffers.push(projection);\n        }\n        // Total message size\n        const totalLength = header.length + query.length + (projection ? projection.length : 0);\n        // Set up the index\n        let index = 4;\n        // Write total document length\n        header[3] = (totalLength >> 24) & 0xff;\n        header[2] = (totalLength >> 16) & 0xff;\n        header[1] = (totalLength >> 8) & 0xff;\n        header[0] = totalLength & 0xff;\n        // Write header information requestId\n        header[index + 3] = (this.requestId >> 24) & 0xff;\n        header[index + 2] = (this.requestId >> 16) & 0xff;\n        header[index + 1] = (this.requestId >> 8) & 0xff;\n        header[index] = this.requestId & 0xff;\n        index = index + 4;\n        // Write header information responseTo\n        header[index + 3] = (0 >> 24) & 0xff;\n        header[index + 2] = (0 >> 16) & 0xff;\n        header[index + 1] = (0 >> 8) & 0xff;\n        header[index] = 0 & 0xff;\n        index = index + 4;\n        // Write header information OP_QUERY\n        header[index + 3] = (constants_1.OP_QUERY >> 24) & 0xff;\n        header[index + 2] = (constants_1.OP_QUERY >> 16) & 0xff;\n        header[index + 1] = (constants_1.OP_QUERY >> 8) & 0xff;\n        header[index] = constants_1.OP_QUERY & 0xff;\n        index = index + 4;\n        // Write header information flags\n        header[index + 3] = (flags >> 24) & 0xff;\n        header[index + 2] = (flags >> 16) & 0xff;\n        header[index + 1] = (flags >> 8) & 0xff;\n        header[index] = flags & 0xff;\n        index = index + 4;\n        // Write collection name\n        index = index + header.write(this.ns, index, 'utf8') + 1;\n        header[index - 1] = 0;\n        // Write header information flags numberToSkip\n        header[index + 3] = (this.numberToSkip >> 24) & 0xff;\n        header[index + 2] = (this.numberToSkip >> 16) & 0xff;\n        header[index + 1] = (this.numberToSkip >> 8) & 0xff;\n        header[index] = this.numberToSkip & 0xff;\n        index = index + 4;\n        // Write header information flags numberToReturn\n        header[index + 3] = (this.numberToReturn >> 24) & 0xff;\n        header[index + 2] = (this.numberToReturn >> 16) & 0xff;\n        header[index + 1] = (this.numberToReturn >> 8) & 0xff;\n        header[index] = this.numberToReturn & 0xff;\n        index = index + 4;\n        // Return the buffers\n        return buffers;\n    }\n}\nexports.OpQueryRequest = OpQueryRequest;\n/** @internal */\nclass OpReply {\n    constructor(message, msgHeader, msgBody, opts) {\n        this.index = 0;\n        this.sections = [];\n        /** moreToCome is an OP_MSG only concept */\n        this.moreToCome = false;\n        this.parsed = false;\n        this.raw = message;\n        this.data = msgBody;\n        this.opts = opts ?? {\n            useBigInt64: false,\n            promoteLongs: true,\n            promoteValues: true,\n            promoteBuffers: false,\n            bsonRegExp: false\n        };\n        // Read the message header\n        this.length = msgHeader.length;\n        this.requestId = msgHeader.requestId;\n        this.responseTo = msgHeader.responseTo;\n        this.opCode = msgHeader.opCode;\n        this.fromCompressed = msgHeader.fromCompressed;\n        // Flag values\n        this.useBigInt64 = typeof this.opts.useBigInt64 === 'boolean' ? this.opts.useBigInt64 : false;\n        this.promoteLongs = typeof this.opts.promoteLongs === 'boolean' ? this.opts.promoteLongs : true;\n        this.promoteValues =\n            typeof this.opts.promoteValues === 'boolean' ? this.opts.promoteValues : true;\n        this.promoteBuffers =\n            typeof this.opts.promoteBuffers === 'boolean' ? this.opts.promoteBuffers : false;\n        this.bsonRegExp = typeof this.opts.bsonRegExp === 'boolean' ? this.opts.bsonRegExp : false;\n    }\n    isParsed() {\n        return this.parsed;\n    }\n    parse() {\n        // Don't parse again if not needed\n        if (this.parsed)\n            return this.sections[0];\n        // Position within OP_REPLY at which documents start\n        // (See https://www.mongodb.com/docs/manual/reference/mongodb-wire-protocol/#wire-op-reply)\n        this.index = 20;\n        // Read the message body\n        this.responseFlags = this.data.readInt32LE(0);\n        this.cursorId = new BSON.Long(this.data.readInt32LE(4), this.data.readInt32LE(8));\n        this.startingFrom = this.data.readInt32LE(12);\n        this.numberReturned = this.data.readInt32LE(16);\n        if (this.numberReturned < 0 || this.numberReturned > 2 ** 32 - 1) {\n            throw new RangeError(`OP_REPLY numberReturned is an invalid array length ${this.numberReturned}`);\n        }\n        this.cursorNotFound = (this.responseFlags & CURSOR_NOT_FOUND) !== 0;\n        this.queryFailure = (this.responseFlags & QUERY_FAILURE) !== 0;\n        this.shardConfigStale = (this.responseFlags & SHARD_CONFIG_STALE) !== 0;\n        this.awaitCapable = (this.responseFlags & AWAIT_CAPABLE) !== 0;\n        // Parse Body\n        for (let i = 0; i < this.numberReturned; i++) {\n            const bsonSize = this.data[this.index] |\n                (this.data[this.index + 1] << 8) |\n                (this.data[this.index + 2] << 16) |\n                (this.data[this.index + 3] << 24);\n            const section = this.data.subarray(this.index, this.index + bsonSize);\n            this.sections.push(section);\n            // Adjust the index\n            this.index = this.index + bsonSize;\n        }\n        // Set parsed\n        this.parsed = true;\n        return this.sections[0];\n    }\n}\nexports.OpReply = OpReply;\n// Msg Flags\nconst OPTS_CHECKSUM_PRESENT = 1;\nconst OPTS_MORE_TO_COME = 2;\nconst OPTS_EXHAUST_ALLOWED = 1 << 16;\n/** @internal */\nclass OpMsgRequest {\n    constructor(databaseName, command, options) {\n        this.databaseName = databaseName;\n        this.command = command;\n        this.options = options;\n        // Basic options needed to be passed in\n        if (command == null)\n            throw new error_1.MongoInvalidArgumentError('Query document must be specified for query');\n        // Basic options\n        this.command.$db = databaseName;\n        // Ensure empty options\n        this.options = options ?? {};\n        // Additional options\n        this.requestId = options.requestId ? options.requestId : OpMsgRequest.getRequestId();\n        // Serialization option\n        this.serializeFunctions =\n            typeof options.serializeFunctions === 'boolean' ? options.serializeFunctions : false;\n        this.ignoreUndefined =\n            typeof options.ignoreUndefined === 'boolean' ? options.ignoreUndefined : false;\n        this.checkKeys = typeof options.checkKeys === 'boolean' ? options.checkKeys : false;\n        this.maxBsonSize = options.maxBsonSize || 1024 * 1024 * 16;\n        // flags\n        this.checksumPresent = false;\n        this.moreToCome = options.moreToCome || false;\n        this.exhaustAllowed =\n            typeof options.exhaustAllowed === 'boolean' ? options.exhaustAllowed : false;\n    }\n    toBin() {\n        const buffers = [];\n        let flags = 0;\n        if (this.checksumPresent) {\n            flags |= OPTS_CHECKSUM_PRESENT;\n        }\n        if (this.moreToCome) {\n            flags |= OPTS_MORE_TO_COME;\n        }\n        if (this.exhaustAllowed) {\n            flags |= OPTS_EXHAUST_ALLOWED;\n        }\n        const header = Buffer.alloc(4 * 4 + // Header\n            4 // Flags\n        );\n        buffers.push(header);\n        let totalLength = header.length;\n        const command = this.command;\n        totalLength += this.makeDocumentSegment(buffers, command);\n        header.writeInt32LE(totalLength, 0); // messageLength\n        header.writeInt32LE(this.requestId, 4); // requestID\n        header.writeInt32LE(0, 8); // responseTo\n        header.writeInt32LE(constants_1.OP_MSG, 12); // opCode\n        header.writeUInt32LE(flags, 16); // flags\n        return buffers;\n    }\n    makeDocumentSegment(buffers, document) {\n        const payloadTypeBuffer = Buffer.alloc(1);\n        payloadTypeBuffer[0] = 0;\n        const documentBuffer = this.serializeBson(document);\n        buffers.push(payloadTypeBuffer);\n        buffers.push(documentBuffer);\n        return payloadTypeBuffer.length + documentBuffer.length;\n    }\n    serializeBson(document) {\n        return BSON.serialize(document, {\n            checkKeys: this.checkKeys,\n            serializeFunctions: this.serializeFunctions,\n            ignoreUndefined: this.ignoreUndefined\n        });\n    }\n    static getRequestId() {\n        _requestId = (_requestId + 1) & 0x7fffffff;\n        return _requestId;\n    }\n}\nexports.OpMsgRequest = OpMsgRequest;\n/** @internal */\nclass OpMsgResponse {\n    constructor(message, msgHeader, msgBody, opts) {\n        this.index = 0;\n        this.sections = [];\n        this.parsed = false;\n        this.raw = message;\n        this.data = msgBody;\n        this.opts = opts ?? {\n            useBigInt64: false,\n            promoteLongs: true,\n            promoteValues: true,\n            promoteBuffers: false,\n            bsonRegExp: false\n        };\n        // Read the message header\n        this.length = msgHeader.length;\n        this.requestId = msgHeader.requestId;\n        this.responseTo = msgHeader.responseTo;\n        this.opCode = msgHeader.opCode;\n        this.fromCompressed = msgHeader.fromCompressed;\n        // Read response flags\n        this.responseFlags = msgBody.readInt32LE(0);\n        this.checksumPresent = (this.responseFlags & OPTS_CHECKSUM_PRESENT) !== 0;\n        this.moreToCome = (this.responseFlags & OPTS_MORE_TO_COME) !== 0;\n        this.exhaustAllowed = (this.responseFlags & OPTS_EXHAUST_ALLOWED) !== 0;\n        this.useBigInt64 = typeof this.opts.useBigInt64 === 'boolean' ? this.opts.useBigInt64 : false;\n        this.promoteLongs = typeof this.opts.promoteLongs === 'boolean' ? this.opts.promoteLongs : true;\n        this.promoteValues =\n            typeof this.opts.promoteValues === 'boolean' ? this.opts.promoteValues : true;\n        this.promoteBuffers =\n            typeof this.opts.promoteBuffers === 'boolean' ? this.opts.promoteBuffers : false;\n        this.bsonRegExp = typeof this.opts.bsonRegExp === 'boolean' ? this.opts.bsonRegExp : false;\n    }\n    isParsed() {\n        return this.parsed;\n    }\n    parse() {\n        // Don't parse again if not needed\n        if (this.parsed)\n            return this.sections[0];\n        this.index = 4;\n        while (this.index < this.data.length) {\n            const payloadType = this.data.readUInt8(this.index++);\n            if (payloadType === 0) {\n                const bsonSize = this.data.readUInt32LE(this.index);\n                const bin = this.data.subarray(this.index, this.index + bsonSize);\n                this.sections.push(bin);\n                this.index += bsonSize;\n            }\n            else if (payloadType === 1) {\n                // It was decided that no driver makes use of payload type 1\n                // TODO(NODE-3483): Replace with MongoDeprecationError\n                throw new error_1.MongoRuntimeError('OP_MSG Payload Type 1 detected unsupported protocol');\n            }\n        }\n        this.parsed = true;\n        return this.sections[0];\n    }\n}\nexports.OpMsgResponse = OpMsgResponse;\nconst MESSAGE_HEADER_SIZE = 16;\nconst COMPRESSION_DETAILS_SIZE = 9; // originalOpcode + uncompressedSize, compressorID\n/**\n * @internal\n *\n * An OP_COMPRESSED request wraps either an OP_QUERY or OP_MSG message.\n */\nclass OpCompressedRequest {\n    constructor(command, options) {\n        this.command = command;\n        this.options = options;\n    }\n    // Return whether a command contains an uncompressible command term\n    // Will return true if command contains no uncompressible command terms\n    static canCompress(command) {\n        const commandDoc = command instanceof OpMsgRequest ? command.command : command.query;\n        const commandName = Object.keys(commandDoc)[0];\n        return !compression_1.uncompressibleCommands.has(commandName);\n    }\n    async toBin() {\n        const concatenatedOriginalCommandBuffer = Buffer.concat(this.command.toBin());\n        // otherwise, compress the message\n        const messageToBeCompressed = concatenatedOriginalCommandBuffer.slice(MESSAGE_HEADER_SIZE);\n        // Extract information needed for OP_COMPRESSED from the uncompressed message\n        const originalCommandOpCode = concatenatedOriginalCommandBuffer.readInt32LE(12);\n        // Compress the message body\n        const compressedMessage = await (0, compression_1.compress)(this.options, messageToBeCompressed);\n        // Create the msgHeader of OP_COMPRESSED\n        const msgHeader = Buffer.alloc(MESSAGE_HEADER_SIZE);\n        msgHeader.writeInt32LE(MESSAGE_HEADER_SIZE + COMPRESSION_DETAILS_SIZE + compressedMessage.length, 0); // messageLength\n        msgHeader.writeInt32LE(this.command.requestId, 4); // requestID\n        msgHeader.writeInt32LE(0, 8); // responseTo (zero)\n        msgHeader.writeInt32LE(constants_1.OP_COMPRESSED, 12); // opCode\n        // Create the compression details of OP_COMPRESSED\n        const compressionDetails = Buffer.alloc(COMPRESSION_DETAILS_SIZE);\n        compressionDetails.writeInt32LE(originalCommandOpCode, 0); // originalOpcode\n        compressionDetails.writeInt32LE(messageToBeCompressed.length, 4); // Size of the uncompressed compressedMessage, excluding the MsgHeader\n        compressionDetails.writeUInt8(compression_1.Compressor[this.options.agreedCompressor], 8); // compressorID\n        return [msgHeader, compressionDetails, compressedMessage];\n    }\n}\nexports.OpCompressedRequest = OpCompressedRequest;\n//# sourceMappingURL=commands.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/commands.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/connect.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/connect.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.makeSocket = exports.LEGAL_TCP_SOCKET_OPTIONS = exports.LEGAL_TLS_SOCKET_OPTIONS = exports.prepareHandshakeDocument = exports.performInitialHandshake = exports.makeConnection = exports.connect = void 0;\nconst net = __webpack_require__(/*! net */ \"net\");\nconst tls = __webpack_require__(/*! tls */ \"tls\");\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst deps_1 = __webpack_require__(/*! ../deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst auth_provider_1 = __webpack_require__(/*! ./auth/auth_provider */ \"./node_modules/mongodb/lib/cmap/auth/auth_provider.js\");\nconst providers_1 = __webpack_require__(/*! ./auth/providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\nconst connection_1 = __webpack_require__(/*! ./connection */ \"./node_modules/mongodb/lib/cmap/connection.js\");\nconst constants_2 = __webpack_require__(/*! ./wire_protocol/constants */ \"./node_modules/mongodb/lib/cmap/wire_protocol/constants.js\");\nasync function connect(options) {\n    let connection = null;\n    try {\n        const socket = await makeSocket(options);\n        connection = makeConnection(options, socket);\n        await performInitialHandshake(connection, options);\n        return connection;\n    }\n    catch (error) {\n        connection?.destroy();\n        throw error;\n    }\n}\nexports.connect = connect;\nfunction makeConnection(options, socket) {\n    let ConnectionType = options.connectionType ?? connection_1.Connection;\n    if (options.autoEncrypter) {\n        ConnectionType = connection_1.CryptoConnection;\n    }\n    return new ConnectionType(socket, options);\n}\nexports.makeConnection = makeConnection;\nfunction checkSupportedServer(hello, options) {\n    const maxWireVersion = Number(hello.maxWireVersion);\n    const minWireVersion = Number(hello.minWireVersion);\n    const serverVersionHighEnough = !Number.isNaN(maxWireVersion) && maxWireVersion >= constants_2.MIN_SUPPORTED_WIRE_VERSION;\n    const serverVersionLowEnough = !Number.isNaN(minWireVersion) && minWireVersion <= constants_2.MAX_SUPPORTED_WIRE_VERSION;\n    if (serverVersionHighEnough) {\n        if (serverVersionLowEnough) {\n            return null;\n        }\n        const message = `Server at ${options.hostAddress} reports minimum wire version ${JSON.stringify(hello.minWireVersion)}, but this version of the Node.js Driver requires at most ${constants_2.MAX_SUPPORTED_WIRE_VERSION} (MongoDB ${constants_2.MAX_SUPPORTED_SERVER_VERSION})`;\n        return new error_1.MongoCompatibilityError(message);\n    }\n    const message = `Server at ${options.hostAddress} reports maximum wire version ${JSON.stringify(hello.maxWireVersion) ?? 0}, but this version of the Node.js Driver requires at least ${constants_2.MIN_SUPPORTED_WIRE_VERSION} (MongoDB ${constants_2.MIN_SUPPORTED_SERVER_VERSION})`;\n    return new error_1.MongoCompatibilityError(message);\n}\nasync function performInitialHandshake(conn, options) {\n    const credentials = options.credentials;\n    if (credentials) {\n        if (!(credentials.mechanism === providers_1.AuthMechanism.MONGODB_DEFAULT) &&\n            !options.authProviders.getOrCreateProvider(credentials.mechanism, credentials.mechanismProperties)) {\n            throw new error_1.MongoInvalidArgumentError(`AuthMechanism '${credentials.mechanism}' not supported`);\n        }\n    }\n    const authContext = new auth_provider_1.AuthContext(conn, credentials, options);\n    conn.authContext = authContext;\n    const handshakeDoc = await prepareHandshakeDocument(authContext);\n    // @ts-expect-error: TODO(NODE-5141): The options need to be filtered properly, Connection options differ from Command options\n    const handshakeOptions = { ...options, raw: false };\n    if (typeof options.connectTimeoutMS === 'number') {\n        // The handshake technically is a monitoring check, so its socket timeout should be connectTimeoutMS\n        handshakeOptions.socketTimeoutMS = options.connectTimeoutMS;\n    }\n    const start = new Date().getTime();\n    const response = await conn.command((0, utils_1.ns)('admin.$cmd'), handshakeDoc, handshakeOptions);\n    if (!('isWritablePrimary' in response)) {\n        // Provide hello-style response document.\n        response.isWritablePrimary = response[constants_1.LEGACY_HELLO_COMMAND];\n    }\n    if (response.helloOk) {\n        conn.helloOk = true;\n    }\n    const supportedServerErr = checkSupportedServer(response, options);\n    if (supportedServerErr) {\n        throw supportedServerErr;\n    }\n    if (options.loadBalanced) {\n        if (!response.serviceId) {\n            throw new error_1.MongoCompatibilityError('Driver attempted to initialize in load balancing mode, ' +\n                'but the server does not support this mode.');\n        }\n    }\n    // NOTE: This is metadata attached to the connection while porting away from\n    //       handshake being done in the `Server` class. Likely, it should be\n    //       relocated, or at very least restructured.\n    conn.hello = response;\n    conn.lastHelloMS = new Date().getTime() - start;\n    if (!response.arbiterOnly && credentials) {\n        // store the response on auth context\n        authContext.response = response;\n        const resolvedCredentials = credentials.resolveAuthMechanism(response);\n        const provider = options.authProviders.getOrCreateProvider(resolvedCredentials.mechanism, resolvedCredentials.mechanismProperties);\n        if (!provider) {\n            throw new error_1.MongoInvalidArgumentError(`No AuthProvider for ${resolvedCredentials.mechanism} defined.`);\n        }\n        try {\n            await provider.auth(authContext);\n        }\n        catch (error) {\n            if (error instanceof error_1.MongoError) {\n                error.addErrorLabel(error_1.MongoErrorLabel.HandshakeError);\n                if ((0, error_1.needsRetryableWriteLabel)(error, response.maxWireVersion)) {\n                    error.addErrorLabel(error_1.MongoErrorLabel.RetryableWriteError);\n                }\n            }\n            throw error;\n        }\n    }\n    // Connection establishment is socket creation (tcp handshake, tls handshake, MongoDB handshake (saslStart, saslContinue))\n    // Once connection is established, command logging can log events (if enabled)\n    conn.established = true;\n}\nexports.performInitialHandshake = performInitialHandshake;\n/**\n * @internal\n *\n * This function is only exposed for testing purposes.\n */\nasync function prepareHandshakeDocument(authContext) {\n    const options = authContext.options;\n    const compressors = options.compressors ? options.compressors : [];\n    const { serverApi } = authContext.connection;\n    const clientMetadata = await options.extendedMetadata;\n    const handshakeDoc = {\n        [serverApi?.version || options.loadBalanced === true ? 'hello' : constants_1.LEGACY_HELLO_COMMAND]: 1,\n        helloOk: true,\n        client: clientMetadata,\n        compression: compressors\n    };\n    if (options.loadBalanced === true) {\n        handshakeDoc.loadBalanced = true;\n    }\n    const credentials = authContext.credentials;\n    if (credentials) {\n        if (credentials.mechanism === providers_1.AuthMechanism.MONGODB_DEFAULT && credentials.username) {\n            handshakeDoc.saslSupportedMechs = `${credentials.source}.${credentials.username}`;\n            const provider = authContext.options.authProviders.getOrCreateProvider(providers_1.AuthMechanism.MONGODB_SCRAM_SHA256, credentials.mechanismProperties);\n            if (!provider) {\n                // This auth mechanism is always present.\n                throw new error_1.MongoInvalidArgumentError(`No AuthProvider for ${providers_1.AuthMechanism.MONGODB_SCRAM_SHA256} defined.`);\n            }\n            return await provider.prepare(handshakeDoc, authContext);\n        }\n        const provider = authContext.options.authProviders.getOrCreateProvider(credentials.mechanism, credentials.mechanismProperties);\n        if (!provider) {\n            throw new error_1.MongoInvalidArgumentError(`No AuthProvider for ${credentials.mechanism} defined.`);\n        }\n        return await provider.prepare(handshakeDoc, authContext);\n    }\n    return handshakeDoc;\n}\nexports.prepareHandshakeDocument = prepareHandshakeDocument;\n/** @public */\nexports.LEGAL_TLS_SOCKET_OPTIONS = [\n    'ALPNProtocols',\n    'ca',\n    'cert',\n    'checkServerIdentity',\n    'ciphers',\n    'crl',\n    'ecdhCurve',\n    'key',\n    'minDHSize',\n    'passphrase',\n    'pfx',\n    'rejectUnauthorized',\n    'secureContext',\n    'secureProtocol',\n    'servername',\n    'session'\n];\n/** @public */\nexports.LEGAL_TCP_SOCKET_OPTIONS = [\n    'family',\n    'hints',\n    'localAddress',\n    'localPort',\n    'lookup'\n];\nfunction parseConnectOptions(options) {\n    const hostAddress = options.hostAddress;\n    if (!hostAddress)\n        throw new error_1.MongoInvalidArgumentError('Option \"hostAddress\" is required');\n    const result = {};\n    for (const name of exports.LEGAL_TCP_SOCKET_OPTIONS) {\n        if (options[name] != null) {\n            result[name] = options[name];\n        }\n    }\n    if (typeof hostAddress.socketPath === 'string') {\n        result.path = hostAddress.socketPath;\n        return result;\n    }\n    else if (typeof hostAddress.host === 'string') {\n        result.host = hostAddress.host;\n        result.port = hostAddress.port;\n        return result;\n    }\n    else {\n        // This should never happen since we set up HostAddresses\n        // But if we don't throw here the socket could hang until timeout\n        // TODO(NODE-3483)\n        throw new error_1.MongoRuntimeError(`Unexpected HostAddress ${JSON.stringify(hostAddress)}`);\n    }\n}\nfunction parseSslOptions(options) {\n    const result = parseConnectOptions(options);\n    // Merge in valid SSL options\n    for (const name of exports.LEGAL_TLS_SOCKET_OPTIONS) {\n        if (options[name] != null) {\n            result[name] = options[name];\n        }\n    }\n    if (options.existingSocket) {\n        result.socket = options.existingSocket;\n    }\n    // Set default sni servername to be the same as host\n    if (result.servername == null && result.host && !net.isIP(result.host)) {\n        result.servername = result.host;\n    }\n    return result;\n}\nasync function makeSocket(options) {\n    const useTLS = options.tls ?? false;\n    const noDelay = options.noDelay ?? true;\n    const connectTimeoutMS = options.connectTimeoutMS ?? 30000;\n    const existingSocket = options.existingSocket;\n    let socket;\n    if (options.proxyHost != null) {\n        // Currently, only Socks5 is supported.\n        return await makeSocks5Connection({\n            ...options,\n            connectTimeoutMS // Should always be present for Socks5\n        });\n    }\n    if (useTLS) {\n        const tlsSocket = tls.connect(parseSslOptions(options));\n        if (typeof tlsSocket.disableRenegotiation === 'function') {\n            tlsSocket.disableRenegotiation();\n        }\n        socket = tlsSocket;\n    }\n    else if (existingSocket) {\n        // In the TLS case, parseSslOptions() sets options.socket to existingSocket,\n        // so we only need to handle the non-TLS case here (where existingSocket\n        // gives us all we need out of the box).\n        socket = existingSocket;\n    }\n    else {\n        socket = net.createConnection(parseConnectOptions(options));\n    }\n    socket.setKeepAlive(true, 300000);\n    socket.setTimeout(connectTimeoutMS);\n    socket.setNoDelay(noDelay);\n    let cancellationHandler = null;\n    const { promise: connectedSocket, resolve, reject } = (0, utils_1.promiseWithResolvers)();\n    if (existingSocket) {\n        resolve(socket);\n    }\n    else {\n        const connectEvent = useTLS ? 'secureConnect' : 'connect';\n        socket\n            .once(connectEvent, () => resolve(socket))\n            .once('error', error => reject(connectionFailureError('error', error)))\n            .once('timeout', () => reject(connectionFailureError('timeout')))\n            .once('close', () => reject(connectionFailureError('close')));\n        if (options.cancellationToken != null) {\n            cancellationHandler = () => reject(connectionFailureError('cancel'));\n            options.cancellationToken.once('cancel', cancellationHandler);\n        }\n    }\n    try {\n        socket = await connectedSocket;\n        return socket;\n    }\n    catch (error) {\n        socket.destroy();\n        throw error;\n    }\n    finally {\n        socket.setTimeout(0);\n        socket.removeAllListeners();\n        if (cancellationHandler != null) {\n            options.cancellationToken?.removeListener('cancel', cancellationHandler);\n        }\n    }\n}\nexports.makeSocket = makeSocket;\nlet socks = null;\nfunction loadSocks() {\n    if (socks == null) {\n        const socksImport = (0, deps_1.getSocks)();\n        if ('kModuleError' in socksImport) {\n            throw socksImport.kModuleError;\n        }\n        socks = socksImport;\n    }\n    return socks;\n}\nasync function makeSocks5Connection(options) {\n    const hostAddress = utils_1.HostAddress.fromHostPort(options.proxyHost ?? '', // proxyHost is guaranteed to set here\n    options.proxyPort ?? 1080);\n    // First, connect to the proxy server itself:\n    const rawSocket = await makeSocket({\n        ...options,\n        hostAddress,\n        tls: false,\n        proxyHost: undefined\n    });\n    const destination = parseConnectOptions(options);\n    if (typeof destination.host !== 'string' || typeof destination.port !== 'number') {\n        throw new error_1.MongoInvalidArgumentError('Can only make Socks5 connections to TCP hosts');\n    }\n    socks ??= loadSocks();\n    try {\n        // Then, establish the Socks5 proxy connection:\n        const { socket } = await socks.SocksClient.createConnection({\n            existing_socket: rawSocket,\n            timeout: options.connectTimeoutMS,\n            command: 'connect',\n            destination: {\n                host: destination.host,\n                port: destination.port\n            },\n            proxy: {\n                // host and port are ignored because we pass existing_socket\n                host: 'iLoveJavaScript',\n                port: 0,\n                type: 5,\n                userId: options.proxyUsername || undefined,\n                password: options.proxyPassword || undefined\n            }\n        });\n        // Finally, now treat the resulting duplex stream as the\n        // socket over which we send and receive wire protocol messages:\n        return await makeSocket({\n            ...options,\n            existingSocket: socket,\n            proxyHost: undefined\n        });\n    }\n    catch (error) {\n        throw connectionFailureError('error', error);\n    }\n}\nfunction connectionFailureError(type, cause) {\n    switch (type) {\n        case 'error':\n            return new error_1.MongoNetworkError(error_1.MongoError.buildErrorMessage(cause), { cause });\n        case 'timeout':\n            return new error_1.MongoNetworkTimeoutError('connection timed out');\n        case 'close':\n            return new error_1.MongoNetworkError('connection closed');\n        case 'cancel':\n            return new error_1.MongoNetworkError('connection establishment was cancelled');\n        default:\n            return new error_1.MongoNetworkError('unknown network error');\n    }\n}\n//# sourceMappingURL=connect.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/connect.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/connection.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/connection.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CryptoConnection = exports.SizedMessageTransform = exports.Connection = exports.hasSessionSupport = void 0;\nconst stream_1 = __webpack_require__(/*! stream */ \"stream\");\nconst timers_1 = __webpack_require__(/*! timers */ \"timers\");\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_logger_1 = __webpack_require__(/*! ../mongo_logger */ \"./node_modules/mongodb/lib/mongo_logger.js\");\nconst mongo_types_1 = __webpack_require__(/*! ../mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst read_preference_1 = __webpack_require__(/*! ../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst common_1 = __webpack_require__(/*! ../sdam/common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst sessions_1 = __webpack_require__(/*! ../sessions */ \"./node_modules/mongodb/lib/sessions.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_monitoring_events_1 = __webpack_require__(/*! ./command_monitoring_events */ \"./node_modules/mongodb/lib/cmap/command_monitoring_events.js\");\nconst commands_1 = __webpack_require__(/*! ./commands */ \"./node_modules/mongodb/lib/cmap/commands.js\");\nconst stream_description_1 = __webpack_require__(/*! ./stream_description */ \"./node_modules/mongodb/lib/cmap/stream_description.js\");\nconst compression_1 = __webpack_require__(/*! ./wire_protocol/compression */ \"./node_modules/mongodb/lib/cmap/wire_protocol/compression.js\");\nconst on_data_1 = __webpack_require__(/*! ./wire_protocol/on_data */ \"./node_modules/mongodb/lib/cmap/wire_protocol/on_data.js\");\nconst responses_1 = __webpack_require__(/*! ./wire_protocol/responses */ \"./node_modules/mongodb/lib/cmap/wire_protocol/responses.js\");\nconst shared_1 = __webpack_require__(/*! ./wire_protocol/shared */ \"./node_modules/mongodb/lib/cmap/wire_protocol/shared.js\");\n/** @internal */\nfunction hasSessionSupport(conn) {\n    const description = conn.description;\n    return description.logicalSessionTimeoutMinutes != null;\n}\nexports.hasSessionSupport = hasSessionSupport;\nfunction streamIdentifier(stream, options) {\n    if (options.proxyHost) {\n        // If proxy options are specified, the properties of `stream` itself\n        // will not accurately reflect what endpoint this is connected to.\n        return options.hostAddress.toString();\n    }\n    const { remoteAddress, remotePort } = stream;\n    if (typeof remoteAddress === 'string' && typeof remotePort === 'number') {\n        return utils_1.HostAddress.fromHostPort(remoteAddress, remotePort).toString();\n    }\n    return (0, utils_1.uuidV4)().toString('hex');\n}\n/** @internal */\nclass Connection extends mongo_types_1.TypedEventEmitter {\n    constructor(stream, options) {\n        super();\n        this.lastHelloMS = -1;\n        this.helloOk = false;\n        this.delayedTimeoutId = null;\n        /** Indicates that the connection (including underlying TCP socket) has been closed. */\n        this.closed = false;\n        this.clusterTime = null;\n        this.error = null;\n        this.dataEvents = null;\n        this.socket = stream;\n        this.id = options.id;\n        this.address = streamIdentifier(stream, options);\n        this.socketTimeoutMS = options.socketTimeoutMS ?? 0;\n        this.monitorCommands = options.monitorCommands;\n        this.serverApi = options.serverApi;\n        this.mongoLogger = options.mongoLogger;\n        this.established = false;\n        this.description = new stream_description_1.StreamDescription(this.address, options);\n        this.generation = options.generation;\n        this.lastUseTime = (0, utils_1.now)();\n        this.messageStream = this.socket\n            .on('error', this.onError.bind(this))\n            .pipe(new SizedMessageTransform({ connection: this }))\n            .on('error', this.onError.bind(this));\n        this.socket.on('close', this.onClose.bind(this));\n        this.socket.on('timeout', this.onTimeout.bind(this));\n    }\n    get hello() {\n        return this.description.hello;\n    }\n    // the `connect` method stores the result of the handshake hello on the connection\n    set hello(response) {\n        this.description.receiveResponse(response);\n        Object.freeze(this.description);\n    }\n    get serviceId() {\n        return this.hello?.serviceId;\n    }\n    get loadBalanced() {\n        return this.description.loadBalanced;\n    }\n    get idleTime() {\n        return (0, utils_1.calculateDurationInMs)(this.lastUseTime);\n    }\n    get hasSessionSupport() {\n        return this.description.logicalSessionTimeoutMinutes != null;\n    }\n    get supportsOpMsg() {\n        return (this.description != null &&\n            (0, utils_1.maxWireVersion)(this) >= 6 &&\n            !this.description.__nodejs_mock_server__);\n    }\n    get shouldEmitAndLogCommand() {\n        return ((this.monitorCommands ||\n            (this.established &&\n                !this.authContext?.reauthenticating &&\n                this.mongoLogger?.willLog(mongo_logger_1.MongoLoggableComponent.COMMAND, mongo_logger_1.SeverityLevel.DEBUG))) ??\n            false);\n    }\n    markAvailable() {\n        this.lastUseTime = (0, utils_1.now)();\n    }\n    onError(error) {\n        this.cleanup(error);\n    }\n    onClose() {\n        const message = `connection ${this.id} to ${this.address} closed`;\n        this.cleanup(new error_1.MongoNetworkError(message));\n    }\n    onTimeout() {\n        this.delayedTimeoutId = (0, timers_1.setTimeout)(() => {\n            const message = `connection ${this.id} to ${this.address} timed out`;\n            const beforeHandshake = this.hello == null;\n            this.cleanup(new error_1.MongoNetworkTimeoutError(message, { beforeHandshake }));\n        }, 1).unref(); // No need for this timer to hold the event loop open\n    }\n    destroy() {\n        if (this.closed) {\n            return;\n        }\n        // load balanced mode requires that these listeners remain on the connection\n        // after cleanup on timeouts, errors or close so we remove them before calling\n        // cleanup.\n        this.removeAllListeners(Connection.PINNED);\n        this.removeAllListeners(Connection.UNPINNED);\n        const message = `connection ${this.id} to ${this.address} closed`;\n        this.cleanup(new error_1.MongoNetworkError(message));\n    }\n    /**\n     * A method that cleans up the connection.  When `force` is true, this method\n     * forcibly destroys the socket.\n     *\n     * If an error is provided, any in-flight operations will be closed with the error.\n     *\n     * This method does nothing if the connection is already closed.\n     */\n    cleanup(error) {\n        if (this.closed) {\n            return;\n        }\n        this.socket.destroy();\n        this.error = error;\n        // eslint-disable-next-line github/no-then\n        this.dataEvents?.throw(error).then(undefined, utils_1.squashError);\n        this.closed = true;\n        this.emit(Connection.CLOSE);\n    }\n    prepareCommand(db, command, options) {\n        let cmd = { ...command };\n        const readPreference = (0, shared_1.getReadPreference)(options);\n        const session = options?.session;\n        let clusterTime = this.clusterTime;\n        if (this.serverApi) {\n            const { version, strict, deprecationErrors } = this.serverApi;\n            cmd.apiVersion = version;\n            if (strict != null)\n                cmd.apiStrict = strict;\n            if (deprecationErrors != null)\n                cmd.apiDeprecationErrors = deprecationErrors;\n        }\n        if (this.hasSessionSupport && session) {\n            if (session.clusterTime &&\n                clusterTime &&\n                session.clusterTime.clusterTime.greaterThan(clusterTime.clusterTime)) {\n                clusterTime = session.clusterTime;\n            }\n            const sessionError = (0, sessions_1.applySession)(session, cmd, options);\n            if (sessionError)\n                throw sessionError;\n        }\n        else if (session?.explicit) {\n            throw new error_1.MongoCompatibilityError('Current topology does not support sessions');\n        }\n        // if we have a known cluster time, gossip it\n        if (clusterTime) {\n            cmd.$clusterTime = clusterTime;\n        }\n        // For standalone, drivers MUST NOT set $readPreference.\n        if (this.description.type !== common_1.ServerType.Standalone) {\n            if (!(0, shared_1.isSharded)(this) &&\n                !this.description.loadBalanced &&\n                this.supportsOpMsg &&\n                options.directConnection === true &&\n                readPreference?.mode === 'primary') {\n                // For mongos and load balancers with 'primary' mode, drivers MUST NOT set $readPreference.\n                // For all other types with a direct connection, if the read preference is 'primary'\n                // (driver sets 'primary' as default if no read preference is configured),\n                // the $readPreference MUST be set to 'primaryPreferred'\n                // to ensure that any server type can handle the request.\n                cmd.$readPreference = read_preference_1.ReadPreference.primaryPreferred.toJSON();\n            }\n            else if ((0, shared_1.isSharded)(this) && !this.supportsOpMsg && readPreference?.mode !== 'primary') {\n                // When sending a read operation via OP_QUERY and the $readPreference modifier,\n                // the query MUST be provided using the $query modifier.\n                cmd = {\n                    $query: cmd,\n                    $readPreference: readPreference.toJSON()\n                };\n            }\n            else if (readPreference?.mode !== 'primary') {\n                // For mode 'primary', drivers MUST NOT set $readPreference.\n                // For all other read preference modes (i.e. 'secondary', 'primaryPreferred', ...),\n                // drivers MUST set $readPreference\n                cmd.$readPreference = readPreference.toJSON();\n            }\n        }\n        const commandOptions = {\n            numberToSkip: 0,\n            numberToReturn: -1,\n            checkKeys: false,\n            // This value is not overridable\n            secondaryOk: readPreference.secondaryOk(),\n            ...options\n        };\n        const message = this.supportsOpMsg\n            ? new commands_1.OpMsgRequest(db, cmd, commandOptions)\n            : new commands_1.OpQueryRequest(db, cmd, commandOptions);\n        return message;\n    }\n    async *sendWire(message, options, responseType) {\n        this.throwIfAborted();\n        if (typeof options.socketTimeoutMS === 'number') {\n            this.socket.setTimeout(options.socketTimeoutMS);\n        }\n        else if (this.socketTimeoutMS !== 0) {\n            this.socket.setTimeout(this.socketTimeoutMS);\n        }\n        try {\n            await this.writeCommand(message, {\n                agreedCompressor: this.description.compressor ?? 'none',\n                zlibCompressionLevel: this.description.zlibCompressionLevel\n            });\n            if (options.noResponse) {\n                yield responses_1.MongoDBResponse.empty;\n                return;\n            }\n            this.throwIfAborted();\n            for await (const response of this.readMany()) {\n                this.socket.setTimeout(0);\n                const bson = response.parse();\n                const document = responseType == null\n                    ? new responses_1.MongoDBResponse(bson)\n                    : (0, responses_1.isErrorResponse)(bson)\n                        ? new responses_1.MongoDBResponse(bson)\n                        : new responseType(bson);\n                yield document;\n                this.throwIfAborted();\n                if (typeof options.socketTimeoutMS === 'number') {\n                    this.socket.setTimeout(options.socketTimeoutMS);\n                }\n                else if (this.socketTimeoutMS !== 0) {\n                    this.socket.setTimeout(this.socketTimeoutMS);\n                }\n            }\n        }\n        finally {\n            this.socket.setTimeout(0);\n        }\n    }\n    async *sendCommand(ns, command, options, responseType) {\n        const message = this.prepareCommand(ns.db, command, options);\n        let started = 0;\n        if (this.shouldEmitAndLogCommand) {\n            started = (0, utils_1.now)();\n            this.emitAndLogCommand(this.monitorCommands, Connection.COMMAND_STARTED, message.databaseName, this.established, new command_monitoring_events_1.CommandStartedEvent(this, message, this.description.serverConnectionId));\n        }\n        // If `documentsReturnedIn` not set or raw is not enabled, use input bson options\n        // Otherwise, support raw flag. Raw only works for cursors that hardcode firstBatch/nextBatch fields\n        const bsonOptions = options.documentsReturnedIn == null || !options.raw\n            ? options\n            : {\n                ...options,\n                raw: false,\n                fieldsAsRaw: { [options.documentsReturnedIn]: true }\n            };\n        /** MongoDBResponse instance or subclass */\n        let document = undefined;\n        /** Cached result of a toObject call */\n        let object = undefined;\n        try {\n            this.throwIfAborted();\n            for await (document of this.sendWire(message, options, responseType)) {\n                object = undefined;\n                if (options.session != null) {\n                    (0, sessions_1.updateSessionFromResponse)(options.session, document);\n                }\n                if (document.$clusterTime) {\n                    this.clusterTime = document.$clusterTime;\n                    this.emit(Connection.CLUSTER_TIME_RECEIVED, document.$clusterTime);\n                }\n                if (document.has('writeConcernError')) {\n                    object ??= document.toObject(bsonOptions);\n                    throw new error_1.MongoWriteConcernError(object.writeConcernError, object);\n                }\n                if (document.isError) {\n                    throw new error_1.MongoServerError((object ??= document.toObject(bsonOptions)));\n                }\n                if (this.shouldEmitAndLogCommand) {\n                    this.emitAndLogCommand(this.monitorCommands, Connection.COMMAND_SUCCEEDED, message.databaseName, this.established, new command_monitoring_events_1.CommandSucceededEvent(this, message, options.noResponse ? undefined : (object ??= document.toObject(bsonOptions)), started, this.description.serverConnectionId));\n                }\n                if (responseType == null) {\n                    yield (object ??= document.toObject(bsonOptions));\n                }\n                else {\n                    yield document;\n                }\n                this.throwIfAborted();\n            }\n        }\n        catch (error) {\n            if (this.shouldEmitAndLogCommand) {\n                if (error.name === 'MongoWriteConcernError') {\n                    this.emitAndLogCommand(this.monitorCommands, Connection.COMMAND_SUCCEEDED, message.databaseName, this.established, new command_monitoring_events_1.CommandSucceededEvent(this, message, options.noResponse ? undefined : (object ??= document?.toObject(bsonOptions)), started, this.description.serverConnectionId));\n                }\n                else {\n                    this.emitAndLogCommand(this.monitorCommands, Connection.COMMAND_FAILED, message.databaseName, this.established, new command_monitoring_events_1.CommandFailedEvent(this, message, error, started, this.description.serverConnectionId));\n                }\n            }\n            throw error;\n        }\n    }\n    async command(ns, command, options = {}, responseType) {\n        this.throwIfAborted();\n        for await (const document of this.sendCommand(ns, command, options, responseType)) {\n            return document;\n        }\n        throw new error_1.MongoUnexpectedServerResponseError('Unable to get response from server');\n    }\n    exhaustCommand(ns, command, options, replyListener) {\n        const exhaustLoop = async () => {\n            this.throwIfAborted();\n            for await (const reply of this.sendCommand(ns, command, options)) {\n                replyListener(undefined, reply);\n                this.throwIfAborted();\n            }\n            throw new error_1.MongoUnexpectedServerResponseError('Server ended moreToCome unexpectedly');\n        };\n        // eslint-disable-next-line github/no-then\n        exhaustLoop().then(undefined, replyListener);\n    }\n    throwIfAborted() {\n        if (this.error)\n            throw this.error;\n    }\n    /**\n     * @internal\n     *\n     * Writes an OP_MSG or OP_QUERY request to the socket, optionally compressing the command. This method\n     * waits until the socket's buffer has emptied (the Nodejs socket `drain` event has fired).\n     */\n    async writeCommand(command, options) {\n        const finalCommand = options.agreedCompressor === 'none' || !commands_1.OpCompressedRequest.canCompress(command)\n            ? command\n            : new commands_1.OpCompressedRequest(command, {\n                agreedCompressor: options.agreedCompressor ?? 'none',\n                zlibCompressionLevel: options.zlibCompressionLevel ?? 0\n            });\n        const buffer = Buffer.concat(await finalCommand.toBin());\n        if (this.socket.write(buffer))\n            return;\n        return await (0, utils_1.once)(this.socket, 'drain');\n    }\n    /**\n     * @internal\n     *\n     * Returns an async generator that yields full wire protocol messages from the underlying socket.  This function\n     * yields messages until `moreToCome` is false or not present in a response, or the caller cancels the request\n     * by calling `return` on the generator.\n     *\n     * Note that `for-await` loops call `return` automatically when the loop is exited.\n     */\n    async *readMany() {\n        try {\n            this.dataEvents = (0, on_data_1.onData)(this.messageStream);\n            for await (const message of this.dataEvents) {\n                const response = await (0, compression_1.decompressResponse)(message);\n                yield response;\n                if (!response.moreToCome) {\n                    return;\n                }\n            }\n        }\n        finally {\n            this.dataEvents = null;\n            this.throwIfAborted();\n        }\n    }\n}\n/** @event */\nConnection.COMMAND_STARTED = constants_1.COMMAND_STARTED;\n/** @event */\nConnection.COMMAND_SUCCEEDED = constants_1.COMMAND_SUCCEEDED;\n/** @event */\nConnection.COMMAND_FAILED = constants_1.COMMAND_FAILED;\n/** @event */\nConnection.CLUSTER_TIME_RECEIVED = constants_1.CLUSTER_TIME_RECEIVED;\n/** @event */\nConnection.CLOSE = constants_1.CLOSE;\n/** @event */\nConnection.PINNED = constants_1.PINNED;\n/** @event */\nConnection.UNPINNED = constants_1.UNPINNED;\nexports.Connection = Connection;\n/** @internal */\nclass SizedMessageTransform extends stream_1.Transform {\n    constructor({ connection }) {\n        super({ objectMode: false });\n        this.bufferPool = new utils_1.BufferPool();\n        this.connection = connection;\n    }\n    _transform(chunk, encoding, callback) {\n        if (this.connection.delayedTimeoutId != null) {\n            (0, timers_1.clearTimeout)(this.connection.delayedTimeoutId);\n            this.connection.delayedTimeoutId = null;\n        }\n        this.bufferPool.append(chunk);\n        const sizeOfMessage = this.bufferPool.getInt32();\n        if (sizeOfMessage == null) {\n            return callback();\n        }\n        if (sizeOfMessage < 0) {\n            return callback(new error_1.MongoParseError(`Invalid message size: ${sizeOfMessage}, too small`));\n        }\n        if (sizeOfMessage > this.bufferPool.length) {\n            return callback();\n        }\n        const message = this.bufferPool.read(sizeOfMessage);\n        return callback(null, message);\n    }\n}\nexports.SizedMessageTransform = SizedMessageTransform;\n/** @internal */\nclass CryptoConnection extends Connection {\n    constructor(stream, options) {\n        super(stream, options);\n        this.autoEncrypter = options.autoEncrypter;\n    }\n    async command(ns, cmd, options, _responseType) {\n        const { autoEncrypter } = this;\n        if (!autoEncrypter) {\n            // TODO(NODE-6065): throw a MongoRuntimeError in Node V7\n            // @ts-expect-error No cause provided because there is no underlying error.\n            throw new error_1.MongoMissingDependencyError('No AutoEncrypter available for encryption', {\n                dependencyName: 'n/a'\n            });\n        }\n        const serverWireVersion = (0, utils_1.maxWireVersion)(this);\n        if (serverWireVersion === 0) {\n            // This means the initial handshake hasn't happened yet\n            return await super.command(ns, cmd, options, undefined);\n        }\n        if (serverWireVersion < 8) {\n            throw new error_1.MongoCompatibilityError('Auto-encryption requires a minimum MongoDB version of 4.2');\n        }\n        // Save sort or indexKeys based on the command being run\n        // the encrypt API serializes our JS objects to BSON to pass to the native code layer\n        // and then deserializes the encrypted result, the protocol level components\n        // of the command (ex. sort) are then converted to JS objects potentially losing\n        // import key order information. These fields are never encrypted so we can save the values\n        // from before the encryption and replace them after encryption has been performed\n        const sort = cmd.find || cmd.findAndModify ? cmd.sort : null;\n        const indexKeys = cmd.createIndexes\n            ? cmd.indexes.map((index) => index.key)\n            : null;\n        const encrypted = await autoEncrypter.encrypt(ns.toString(), cmd, options);\n        // Replace the saved values\n        if (sort != null && (cmd.find || cmd.findAndModify)) {\n            encrypted.sort = sort;\n        }\n        if (indexKeys != null && cmd.createIndexes) {\n            for (const [offset, index] of indexKeys.entries()) {\n                // @ts-expect-error `encrypted` is a generic \"command\", but we've narrowed for only `createIndexes` commands here\n                encrypted.indexes[offset].key = index;\n            }\n        }\n        const response = await super.command(ns, encrypted, options, undefined);\n        return await autoEncrypter.decrypt(response, options);\n    }\n}\nexports.CryptoConnection = CryptoConnection;\n//# sourceMappingURL=connection.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/connection.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/connection_pool.js":
/*!**********************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/connection_pool.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConnectionPool = exports.PoolState = void 0;\nconst timers_1 = __webpack_require__(/*! timers */ \"timers\");\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_types_1 = __webpack_require__(/*! ../mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst timeout_1 = __webpack_require__(/*! ../timeout */ \"./node_modules/mongodb/lib/timeout.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst connect_1 = __webpack_require__(/*! ./connect */ \"./node_modules/mongodb/lib/cmap/connect.js\");\nconst connection_1 = __webpack_require__(/*! ./connection */ \"./node_modules/mongodb/lib/cmap/connection.js\");\nconst connection_pool_events_1 = __webpack_require__(/*! ./connection_pool_events */ \"./node_modules/mongodb/lib/cmap/connection_pool_events.js\");\nconst errors_1 = __webpack_require__(/*! ./errors */ \"./node_modules/mongodb/lib/cmap/errors.js\");\nconst metrics_1 = __webpack_require__(/*! ./metrics */ \"./node_modules/mongodb/lib/cmap/metrics.js\");\n/** @internal */\nconst kServer = Symbol('server');\n/** @internal */\nconst kConnections = Symbol('connections');\n/** @internal */\nconst kPending = Symbol('pending');\n/** @internal */\nconst kCheckedOut = Symbol('checkedOut');\n/** @internal */\nconst kMinPoolSizeTimer = Symbol('minPoolSizeTimer');\n/** @internal */\nconst kGeneration = Symbol('generation');\n/** @internal */\nconst kServiceGenerations = Symbol('serviceGenerations');\n/** @internal */\nconst kConnectionCounter = Symbol('connectionCounter');\n/** @internal */\nconst kCancellationToken = Symbol('cancellationToken');\n/** @internal */\nconst kWaitQueue = Symbol('waitQueue');\n/** @internal */\nconst kCancelled = Symbol('cancelled');\n/** @internal */\nconst kMetrics = Symbol('metrics');\n/** @internal */\nconst kProcessingWaitQueue = Symbol('processingWaitQueue');\n/** @internal */\nconst kPoolState = Symbol('poolState');\n/** @internal */\nexports.PoolState = Object.freeze({\n    paused: 'paused',\n    ready: 'ready',\n    closed: 'closed'\n});\n/**\n * A pool of connections which dynamically resizes, and emit events related to pool activity\n * @internal\n */\nclass ConnectionPool extends mongo_types_1.TypedEventEmitter {\n    constructor(server, options) {\n        super();\n        this.options = Object.freeze({\n            connectionType: connection_1.Connection,\n            ...options,\n            maxPoolSize: options.maxPoolSize ?? 100,\n            minPoolSize: options.minPoolSize ?? 0,\n            maxConnecting: options.maxConnecting ?? 2,\n            maxIdleTimeMS: options.maxIdleTimeMS ?? 0,\n            waitQueueTimeoutMS: options.waitQueueTimeoutMS ?? 0,\n            minPoolSizeCheckFrequencyMS: options.minPoolSizeCheckFrequencyMS ?? 100,\n            autoEncrypter: options.autoEncrypter\n        });\n        if (this.options.minPoolSize > this.options.maxPoolSize) {\n            throw new error_1.MongoInvalidArgumentError('Connection pool minimum size must not be greater than maximum pool size');\n        }\n        this[kPoolState] = exports.PoolState.paused;\n        this[kServer] = server;\n        this[kConnections] = new utils_1.List();\n        this[kPending] = 0;\n        this[kCheckedOut] = new Set();\n        this[kMinPoolSizeTimer] = undefined;\n        this[kGeneration] = 0;\n        this[kServiceGenerations] = new Map();\n        this[kConnectionCounter] = (0, utils_1.makeCounter)(1);\n        this[kCancellationToken] = new mongo_types_1.CancellationToken();\n        this[kCancellationToken].setMaxListeners(Infinity);\n        this[kWaitQueue] = new utils_1.List();\n        this[kMetrics] = new metrics_1.ConnectionPoolMetrics();\n        this[kProcessingWaitQueue] = false;\n        this.mongoLogger = this[kServer].topology.client?.mongoLogger;\n        this.component = 'connection';\n        process.nextTick(() => {\n            this.emitAndLog(ConnectionPool.CONNECTION_POOL_CREATED, new connection_pool_events_1.ConnectionPoolCreatedEvent(this));\n        });\n    }\n    /** The address of the endpoint the pool is connected to */\n    get address() {\n        return this.options.hostAddress.toString();\n    }\n    /**\n     * Check if the pool has been closed\n     *\n     * TODO(NODE-3263): We can remove this property once shell no longer needs it\n     */\n    get closed() {\n        return this[kPoolState] === exports.PoolState.closed;\n    }\n    /** An integer representing the SDAM generation of the pool */\n    get generation() {\n        return this[kGeneration];\n    }\n    /** An integer expressing how many total connections (available + pending + in use) the pool currently has */\n    get totalConnectionCount() {\n        return (this.availableConnectionCount + this.pendingConnectionCount + this.currentCheckedOutCount);\n    }\n    /** An integer expressing how many connections are currently available in the pool. */\n    get availableConnectionCount() {\n        return this[kConnections].length;\n    }\n    get pendingConnectionCount() {\n        return this[kPending];\n    }\n    get currentCheckedOutCount() {\n        return this[kCheckedOut].size;\n    }\n    get waitQueueSize() {\n        return this[kWaitQueue].length;\n    }\n    get loadBalanced() {\n        return this.options.loadBalanced;\n    }\n    get serviceGenerations() {\n        return this[kServiceGenerations];\n    }\n    get serverError() {\n        return this[kServer].description.error;\n    }\n    /**\n     * This is exposed ONLY for use in mongosh, to enable\n     * killing all connections if a user quits the shell with\n     * operations in progress.\n     *\n     * This property may be removed as a part of NODE-3263.\n     */\n    get checkedOutConnections() {\n        return this[kCheckedOut];\n    }\n    /**\n     * Get the metrics information for the pool when a wait queue timeout occurs.\n     */\n    waitQueueErrorMetrics() {\n        return this[kMetrics].info(this.options.maxPoolSize);\n    }\n    /**\n     * Set the pool state to \"ready\"\n     */\n    ready() {\n        if (this[kPoolState] !== exports.PoolState.paused) {\n            return;\n        }\n        this[kPoolState] = exports.PoolState.ready;\n        this.emitAndLog(ConnectionPool.CONNECTION_POOL_READY, new connection_pool_events_1.ConnectionPoolReadyEvent(this));\n        (0, timers_1.clearTimeout)(this[kMinPoolSizeTimer]);\n        this.ensureMinPoolSize();\n    }\n    /**\n     * Check a connection out of this pool. The connection will continue to be tracked, but no reference to it\n     * will be held by the pool. This means that if a connection is checked out it MUST be checked back in or\n     * explicitly destroyed by the new owner.\n     */\n    async checkOut() {\n        this.emitAndLog(ConnectionPool.CONNECTION_CHECK_OUT_STARTED, new connection_pool_events_1.ConnectionCheckOutStartedEvent(this));\n        const waitQueueTimeoutMS = this.options.waitQueueTimeoutMS;\n        const { promise, resolve, reject } = (0, utils_1.promiseWithResolvers)();\n        const timeout = timeout_1.Timeout.expires(waitQueueTimeoutMS);\n        const waitQueueMember = {\n            resolve,\n            reject,\n            timeout\n        };\n        this[kWaitQueue].push(waitQueueMember);\n        process.nextTick(() => this.processWaitQueue());\n        try {\n            return await Promise.race([promise, waitQueueMember.timeout]);\n        }\n        catch (error) {\n            if (timeout_1.TimeoutError.is(error)) {\n                waitQueueMember[kCancelled] = true;\n                waitQueueMember.timeout.clear();\n                this.emitAndLog(ConnectionPool.CONNECTION_CHECK_OUT_FAILED, new connection_pool_events_1.ConnectionCheckOutFailedEvent(this, 'timeout'));\n                const timeoutError = new errors_1.WaitQueueTimeoutError(this.loadBalanced\n                    ? this.waitQueueErrorMetrics()\n                    : 'Timed out while checking out a connection from connection pool', this.address);\n                throw timeoutError;\n            }\n            throw error;\n        }\n    }\n    /**\n     * Check a connection into the pool.\n     *\n     * @param connection - The connection to check in\n     */\n    checkIn(connection) {\n        if (!this[kCheckedOut].has(connection)) {\n            return;\n        }\n        const poolClosed = this.closed;\n        const stale = this.connectionIsStale(connection);\n        const willDestroy = !!(poolClosed || stale || connection.closed);\n        if (!willDestroy) {\n            connection.markAvailable();\n            this[kConnections].unshift(connection);\n        }\n        this[kCheckedOut].delete(connection);\n        this.emitAndLog(ConnectionPool.CONNECTION_CHECKED_IN, new connection_pool_events_1.ConnectionCheckedInEvent(this, connection));\n        if (willDestroy) {\n            const reason = connection.closed ? 'error' : poolClosed ? 'poolClosed' : 'stale';\n            this.destroyConnection(connection, reason);\n        }\n        process.nextTick(() => this.processWaitQueue());\n    }\n    /**\n     * Clear the pool\n     *\n     * Pool reset is handled by incrementing the pool's generation count. Any existing connection of a\n     * previous generation will eventually be pruned during subsequent checkouts.\n     */\n    clear(options = {}) {\n        if (this.closed) {\n            return;\n        }\n        // handle load balanced case\n        if (this.loadBalanced) {\n            const { serviceId } = options;\n            if (!serviceId) {\n                throw new error_1.MongoRuntimeError('ConnectionPool.clear() called in load balanced mode with no serviceId.');\n            }\n            const sid = serviceId.toHexString();\n            const generation = this.serviceGenerations.get(sid);\n            // Only need to worry if the generation exists, since it should\n            // always be there but typescript needs the check.\n            if (generation == null) {\n                throw new error_1.MongoRuntimeError('Service generations are required in load balancer mode.');\n            }\n            else {\n                // Increment the generation for the service id.\n                this.serviceGenerations.set(sid, generation + 1);\n            }\n            this.emitAndLog(ConnectionPool.CONNECTION_POOL_CLEARED, new connection_pool_events_1.ConnectionPoolClearedEvent(this, { serviceId }));\n            return;\n        }\n        // handle non load-balanced case\n        const interruptInUseConnections = options.interruptInUseConnections ?? false;\n        const oldGeneration = this[kGeneration];\n        this[kGeneration] += 1;\n        const alreadyPaused = this[kPoolState] === exports.PoolState.paused;\n        this[kPoolState] = exports.PoolState.paused;\n        this.clearMinPoolSizeTimer();\n        if (!alreadyPaused) {\n            this.emitAndLog(ConnectionPool.CONNECTION_POOL_CLEARED, new connection_pool_events_1.ConnectionPoolClearedEvent(this, {\n                interruptInUseConnections\n            }));\n        }\n        if (interruptInUseConnections) {\n            process.nextTick(() => this.interruptInUseConnections(oldGeneration));\n        }\n        this.processWaitQueue();\n    }\n    /**\n     * Closes all stale in-use connections in the pool with a resumable PoolClearedOnNetworkError.\n     *\n     * Only connections where `connection.generation <= minGeneration` are killed.\n     */\n    interruptInUseConnections(minGeneration) {\n        for (const connection of this[kCheckedOut]) {\n            if (connection.generation <= minGeneration) {\n                connection.onError(new errors_1.PoolClearedOnNetworkError(this));\n                this.checkIn(connection);\n            }\n        }\n    }\n    /** Close the pool */\n    close() {\n        if (this.closed) {\n            return;\n        }\n        // immediately cancel any in-flight connections\n        this[kCancellationToken].emit('cancel');\n        // end the connection counter\n        if (typeof this[kConnectionCounter].return === 'function') {\n            this[kConnectionCounter].return(undefined);\n        }\n        this[kPoolState] = exports.PoolState.closed;\n        this.clearMinPoolSizeTimer();\n        this.processWaitQueue();\n        for (const conn of this[kConnections]) {\n            this.emitAndLog(ConnectionPool.CONNECTION_CLOSED, new connection_pool_events_1.ConnectionClosedEvent(this, conn, 'poolClosed'));\n            conn.destroy();\n        }\n        this[kConnections].clear();\n        this.emitAndLog(ConnectionPool.CONNECTION_POOL_CLOSED, new connection_pool_events_1.ConnectionPoolClosedEvent(this));\n    }\n    /**\n     * @internal\n     * Reauthenticate a connection\n     */\n    async reauthenticate(connection) {\n        const authContext = connection.authContext;\n        if (!authContext) {\n            throw new error_1.MongoRuntimeError('No auth context found on connection.');\n        }\n        const credentials = authContext.credentials;\n        if (!credentials) {\n            throw new error_1.MongoMissingCredentialsError('Connection is missing credentials when asked to reauthenticate');\n        }\n        const resolvedCredentials = credentials.resolveAuthMechanism(connection.hello);\n        const provider = this[kServer].topology.client.s.authProviders.getOrCreateProvider(resolvedCredentials.mechanism, resolvedCredentials.mechanismProperties);\n        if (!provider) {\n            throw new error_1.MongoMissingCredentialsError(`Reauthenticate failed due to no auth provider for ${credentials.mechanism}`);\n        }\n        await provider.reauth(authContext);\n        return;\n    }\n    /** Clear the min pool size timer */\n    clearMinPoolSizeTimer() {\n        const minPoolSizeTimer = this[kMinPoolSizeTimer];\n        if (minPoolSizeTimer) {\n            (0, timers_1.clearTimeout)(minPoolSizeTimer);\n        }\n    }\n    destroyConnection(connection, reason) {\n        this.emitAndLog(ConnectionPool.CONNECTION_CLOSED, new connection_pool_events_1.ConnectionClosedEvent(this, connection, reason));\n        // destroy the connection\n        connection.destroy();\n    }\n    connectionIsStale(connection) {\n        const serviceId = connection.serviceId;\n        if (this.loadBalanced && serviceId) {\n            const sid = serviceId.toHexString();\n            const generation = this.serviceGenerations.get(sid);\n            return connection.generation !== generation;\n        }\n        return connection.generation !== this[kGeneration];\n    }\n    connectionIsIdle(connection) {\n        return !!(this.options.maxIdleTimeMS && connection.idleTime > this.options.maxIdleTimeMS);\n    }\n    /**\n     * Destroys a connection if the connection is perished.\n     *\n     * @returns `true` if the connection was destroyed, `false` otherwise.\n     */\n    destroyConnectionIfPerished(connection) {\n        const isStale = this.connectionIsStale(connection);\n        const isIdle = this.connectionIsIdle(connection);\n        if (!isStale && !isIdle && !connection.closed) {\n            return false;\n        }\n        const reason = connection.closed ? 'error' : isStale ? 'stale' : 'idle';\n        this.destroyConnection(connection, reason);\n        return true;\n    }\n    createConnection(callback) {\n        const connectOptions = {\n            ...this.options,\n            id: this[kConnectionCounter].next().value,\n            generation: this[kGeneration],\n            cancellationToken: this[kCancellationToken],\n            mongoLogger: this.mongoLogger,\n            authProviders: this[kServer].topology.client.s.authProviders\n        };\n        this[kPending]++;\n        // This is our version of a \"virtual\" no-I/O connection as the spec requires\n        this.emitAndLog(ConnectionPool.CONNECTION_CREATED, new connection_pool_events_1.ConnectionCreatedEvent(this, { id: connectOptions.id }));\n        // eslint-disable-next-line github/no-then\n        (0, connect_1.connect)(connectOptions).then(connection => {\n            // The pool might have closed since we started trying to create a connection\n            if (this[kPoolState] !== exports.PoolState.ready) {\n                this[kPending]--;\n                connection.destroy();\n                callback(this.closed ? new errors_1.PoolClosedError(this) : new errors_1.PoolClearedError(this));\n                return;\n            }\n            // forward all events from the connection to the pool\n            for (const event of [...constants_1.APM_EVENTS, connection_1.Connection.CLUSTER_TIME_RECEIVED]) {\n                connection.on(event, (e) => this.emit(event, e));\n            }\n            if (this.loadBalanced) {\n                connection.on(connection_1.Connection.PINNED, pinType => this[kMetrics].markPinned(pinType));\n                connection.on(connection_1.Connection.UNPINNED, pinType => this[kMetrics].markUnpinned(pinType));\n                const serviceId = connection.serviceId;\n                if (serviceId) {\n                    let generation;\n                    const sid = serviceId.toHexString();\n                    if ((generation = this.serviceGenerations.get(sid))) {\n                        connection.generation = generation;\n                    }\n                    else {\n                        this.serviceGenerations.set(sid, 0);\n                        connection.generation = 0;\n                    }\n                }\n            }\n            connection.markAvailable();\n            this.emitAndLog(ConnectionPool.CONNECTION_READY, new connection_pool_events_1.ConnectionReadyEvent(this, connection));\n            this[kPending]--;\n            callback(undefined, connection);\n        }, error => {\n            this[kPending]--;\n            this.emitAndLog(ConnectionPool.CONNECTION_CLOSED, new connection_pool_events_1.ConnectionClosedEvent(this, { id: connectOptions.id, serviceId: undefined }, 'error', \n            // TODO(NODE-5192): Remove this cast\n            error));\n            if (error instanceof error_1.MongoNetworkError || error instanceof error_1.MongoServerError) {\n                error.connectionGeneration = connectOptions.generation;\n            }\n            callback(error ?? new error_1.MongoRuntimeError('Connection creation failed without error'));\n        });\n    }\n    ensureMinPoolSize() {\n        const minPoolSize = this.options.minPoolSize;\n        if (this[kPoolState] !== exports.PoolState.ready || minPoolSize === 0) {\n            return;\n        }\n        this[kConnections].prune(connection => this.destroyConnectionIfPerished(connection));\n        if (this.totalConnectionCount < minPoolSize &&\n            this.pendingConnectionCount < this.options.maxConnecting) {\n            // NOTE: ensureMinPoolSize should not try to get all the pending\n            // connection permits because that potentially delays the availability of\n            // the connection to a checkout request\n            this.createConnection((err, connection) => {\n                if (err) {\n                    this[kServer].handleError(err);\n                }\n                if (!err && connection) {\n                    this[kConnections].push(connection);\n                    process.nextTick(() => this.processWaitQueue());\n                }\n                if (this[kPoolState] === exports.PoolState.ready) {\n                    (0, timers_1.clearTimeout)(this[kMinPoolSizeTimer]);\n                    this[kMinPoolSizeTimer] = (0, timers_1.setTimeout)(() => this.ensureMinPoolSize(), this.options.minPoolSizeCheckFrequencyMS);\n                }\n            });\n        }\n        else {\n            (0, timers_1.clearTimeout)(this[kMinPoolSizeTimer]);\n            this[kMinPoolSizeTimer] = (0, timers_1.setTimeout)(() => this.ensureMinPoolSize(), this.options.minPoolSizeCheckFrequencyMS);\n        }\n    }\n    processWaitQueue() {\n        if (this[kProcessingWaitQueue]) {\n            return;\n        }\n        this[kProcessingWaitQueue] = true;\n        while (this.waitQueueSize) {\n            const waitQueueMember = this[kWaitQueue].first();\n            if (!waitQueueMember) {\n                this[kWaitQueue].shift();\n                continue;\n            }\n            if (waitQueueMember[kCancelled]) {\n                this[kWaitQueue].shift();\n                continue;\n            }\n            if (this[kPoolState] !== exports.PoolState.ready) {\n                const reason = this.closed ? 'poolClosed' : 'connectionError';\n                const error = this.closed ? new errors_1.PoolClosedError(this) : new errors_1.PoolClearedError(this);\n                this.emitAndLog(ConnectionPool.CONNECTION_CHECK_OUT_FAILED, new connection_pool_events_1.ConnectionCheckOutFailedEvent(this, reason, error));\n                waitQueueMember.timeout.clear();\n                this[kWaitQueue].shift();\n                waitQueueMember.reject(error);\n                continue;\n            }\n            if (!this.availableConnectionCount) {\n                break;\n            }\n            const connection = this[kConnections].shift();\n            if (!connection) {\n                break;\n            }\n            if (!this.destroyConnectionIfPerished(connection)) {\n                this[kCheckedOut].add(connection);\n                this.emitAndLog(ConnectionPool.CONNECTION_CHECKED_OUT, new connection_pool_events_1.ConnectionCheckedOutEvent(this, connection));\n                waitQueueMember.timeout.clear();\n                this[kWaitQueue].shift();\n                waitQueueMember.resolve(connection);\n            }\n        }\n        const { maxPoolSize, maxConnecting } = this.options;\n        while (this.waitQueueSize > 0 &&\n            this.pendingConnectionCount < maxConnecting &&\n            (maxPoolSize === 0 || this.totalConnectionCount < maxPoolSize)) {\n            const waitQueueMember = this[kWaitQueue].shift();\n            if (!waitQueueMember || waitQueueMember[kCancelled]) {\n                continue;\n            }\n            this.createConnection((err, connection) => {\n                if (waitQueueMember[kCancelled]) {\n                    if (!err && connection) {\n                        this[kConnections].push(connection);\n                    }\n                }\n                else {\n                    if (err) {\n                        this.emitAndLog(ConnectionPool.CONNECTION_CHECK_OUT_FAILED, \n                        // TODO(NODE-5192): Remove this cast\n                        new connection_pool_events_1.ConnectionCheckOutFailedEvent(this, 'connectionError', err));\n                        waitQueueMember.reject(err);\n                    }\n                    else if (connection) {\n                        this[kCheckedOut].add(connection);\n                        this.emitAndLog(ConnectionPool.CONNECTION_CHECKED_OUT, new connection_pool_events_1.ConnectionCheckedOutEvent(this, connection));\n                        waitQueueMember.resolve(connection);\n                    }\n                    waitQueueMember.timeout.clear();\n                }\n                process.nextTick(() => this.processWaitQueue());\n            });\n        }\n        this[kProcessingWaitQueue] = false;\n    }\n}\n/**\n * Emitted when the connection pool is created.\n * @event\n */\nConnectionPool.CONNECTION_POOL_CREATED = constants_1.CONNECTION_POOL_CREATED;\n/**\n * Emitted once when the connection pool is closed\n * @event\n */\nConnectionPool.CONNECTION_POOL_CLOSED = constants_1.CONNECTION_POOL_CLOSED;\n/**\n * Emitted each time the connection pool is cleared and it's generation incremented\n * @event\n */\nConnectionPool.CONNECTION_POOL_CLEARED = constants_1.CONNECTION_POOL_CLEARED;\n/**\n * Emitted each time the connection pool is marked ready\n * @event\n */\nConnectionPool.CONNECTION_POOL_READY = constants_1.CONNECTION_POOL_READY;\n/**\n * Emitted when a connection is created.\n * @event\n */\nConnectionPool.CONNECTION_CREATED = constants_1.CONNECTION_CREATED;\n/**\n * Emitted when a connection becomes established, and is ready to use\n * @event\n */\nConnectionPool.CONNECTION_READY = constants_1.CONNECTION_READY;\n/**\n * Emitted when a connection is closed\n * @event\n */\nConnectionPool.CONNECTION_CLOSED = constants_1.CONNECTION_CLOSED;\n/**\n * Emitted when an attempt to check out a connection begins\n * @event\n */\nConnectionPool.CONNECTION_CHECK_OUT_STARTED = constants_1.CONNECTION_CHECK_OUT_STARTED;\n/**\n * Emitted when an attempt to check out a connection fails\n * @event\n */\nConnectionPool.CONNECTION_CHECK_OUT_FAILED = constants_1.CONNECTION_CHECK_OUT_FAILED;\n/**\n * Emitted each time a connection is successfully checked out of the connection pool\n * @event\n */\nConnectionPool.CONNECTION_CHECKED_OUT = constants_1.CONNECTION_CHECKED_OUT;\n/**\n * Emitted each time a connection is successfully checked into the connection pool\n * @event\n */\nConnectionPool.CONNECTION_CHECKED_IN = constants_1.CONNECTION_CHECKED_IN;\nexports.ConnectionPool = ConnectionPool;\n//# sourceMappingURL=connection_pool.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/connection_pool.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/connection_pool_events.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/connection_pool_events.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConnectionPoolClearedEvent = exports.ConnectionCheckedInEvent = exports.ConnectionCheckedOutEvent = exports.ConnectionCheckOutFailedEvent = exports.ConnectionCheckOutStartedEvent = exports.ConnectionClosedEvent = exports.ConnectionReadyEvent = exports.ConnectionCreatedEvent = exports.ConnectionPoolClosedEvent = exports.ConnectionPoolReadyEvent = exports.ConnectionPoolCreatedEvent = exports.ConnectionPoolMonitoringEvent = void 0;\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\n/**\n * The base export class for all monitoring events published from the connection pool\n * @public\n * @category Event\n */\nclass ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool) {\n        this.time = new Date();\n        this.address = pool.address;\n    }\n}\nexports.ConnectionPoolMonitoringEvent = ConnectionPoolMonitoringEvent;\n/**\n * An event published when a connection pool is created\n * @public\n * @category Event\n */\nclass ConnectionPoolCreatedEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_POOL_CREATED;\n        const { maxConnecting, maxPoolSize, minPoolSize, maxIdleTimeMS, waitQueueTimeoutMS } = pool.options;\n        this.options = { maxConnecting, maxPoolSize, minPoolSize, maxIdleTimeMS, waitQueueTimeoutMS };\n    }\n}\nexports.ConnectionPoolCreatedEvent = ConnectionPoolCreatedEvent;\n/**\n * An event published when a connection pool is ready\n * @public\n * @category Event\n */\nclass ConnectionPoolReadyEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_POOL_READY;\n    }\n}\nexports.ConnectionPoolReadyEvent = ConnectionPoolReadyEvent;\n/**\n * An event published when a connection pool is closed\n * @public\n * @category Event\n */\nclass ConnectionPoolClosedEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_POOL_CLOSED;\n    }\n}\nexports.ConnectionPoolClosedEvent = ConnectionPoolClosedEvent;\n/**\n * An event published when a connection pool creates a new connection\n * @public\n * @category Event\n */\nclass ConnectionCreatedEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool, connection) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_CREATED;\n        this.connectionId = connection.id;\n    }\n}\nexports.ConnectionCreatedEvent = ConnectionCreatedEvent;\n/**\n * An event published when a connection is ready for use\n * @public\n * @category Event\n */\nclass ConnectionReadyEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool, connection) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_READY;\n        this.connectionId = connection.id;\n    }\n}\nexports.ConnectionReadyEvent = ConnectionReadyEvent;\n/**\n * An event published when a connection is closed\n * @public\n * @category Event\n */\nclass ConnectionClosedEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool, connection, reason, error) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_CLOSED;\n        this.connectionId = connection.id;\n        this.reason = reason;\n        this.serviceId = connection.serviceId;\n        this.error = error ?? null;\n    }\n}\nexports.ConnectionClosedEvent = ConnectionClosedEvent;\n/**\n * An event published when a request to check a connection out begins\n * @public\n * @category Event\n */\nclass ConnectionCheckOutStartedEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_CHECK_OUT_STARTED;\n    }\n}\nexports.ConnectionCheckOutStartedEvent = ConnectionCheckOutStartedEvent;\n/**\n * An event published when a request to check a connection out fails\n * @public\n * @category Event\n */\nclass ConnectionCheckOutFailedEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool, reason, error) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_CHECK_OUT_FAILED;\n        this.reason = reason;\n        this.error = error;\n    }\n}\nexports.ConnectionCheckOutFailedEvent = ConnectionCheckOutFailedEvent;\n/**\n * An event published when a connection is checked out of the connection pool\n * @public\n * @category Event\n */\nclass ConnectionCheckedOutEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool, connection) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_CHECKED_OUT;\n        this.connectionId = connection.id;\n    }\n}\nexports.ConnectionCheckedOutEvent = ConnectionCheckedOutEvent;\n/**\n * An event published when a connection is checked into the connection pool\n * @public\n * @category Event\n */\nclass ConnectionCheckedInEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool, connection) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_CHECKED_IN;\n        this.connectionId = connection.id;\n    }\n}\nexports.ConnectionCheckedInEvent = ConnectionCheckedInEvent;\n/**\n * An event published when a connection pool is cleared\n * @public\n * @category Event\n */\nclass ConnectionPoolClearedEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool, options = {}) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_POOL_CLEARED;\n        this.serviceId = options.serviceId;\n        this.interruptInUseConnections = options.interruptInUseConnections;\n    }\n}\nexports.ConnectionPoolClearedEvent = ConnectionPoolClearedEvent;\n//# sourceMappingURL=connection_pool_events.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/connection_pool_events.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/errors.js":
/*!*************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/errors.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.WaitQueueTimeoutError = exports.PoolClearedOnNetworkError = exports.PoolClearedError = exports.PoolClosedError = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\n/**\n * An error indicating a connection pool is closed\n * @category Error\n */\nclass PoolClosedError extends error_1.MongoDriverError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(pool) {\n        super('Attempted to check out a connection from closed connection pool');\n        this.address = pool.address;\n    }\n    get name() {\n        return 'MongoPoolClosedError';\n    }\n}\nexports.PoolClosedError = PoolClosedError;\n/**\n * An error indicating a connection pool is currently paused\n * @category Error\n */\nclass PoolClearedError extends error_1.MongoNetworkError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(pool, message) {\n        const errorMessage = message\n            ? message\n            : `Connection pool for ${pool.address} was cleared because another operation failed with: \"${pool.serverError?.message}\"`;\n        super(errorMessage, pool.serverError ? { cause: pool.serverError } : undefined);\n        this.address = pool.address;\n        this.addErrorLabel(error_1.MongoErrorLabel.PoolRequstedRetry);\n    }\n    get name() {\n        return 'MongoPoolClearedError';\n    }\n}\nexports.PoolClearedError = PoolClearedError;\n/**\n * An error indicating that a connection pool has been cleared after the monitor for that server timed out.\n * @category Error\n */\nclass PoolClearedOnNetworkError extends PoolClearedError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(pool) {\n        super(pool, `Connection to ${pool.address} interrupted due to server monitor timeout`);\n    }\n    get name() {\n        return 'PoolClearedOnNetworkError';\n    }\n}\nexports.PoolClearedOnNetworkError = PoolClearedOnNetworkError;\n/**\n * An error thrown when a request to check out a connection times out\n * @category Error\n */\nclass WaitQueueTimeoutError extends error_1.MongoDriverError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, address) {\n        super(message);\n        this.address = address;\n    }\n    get name() {\n        return 'MongoWaitQueueTimeoutError';\n    }\n}\nexports.WaitQueueTimeoutError = WaitQueueTimeoutError;\n//# sourceMappingURL=errors.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/errors.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/handshake/client_metadata.js":
/*!********************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/handshake/client_metadata.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.getFAASEnv = exports.addContainerMetadata = exports.makeClientMetadata = exports.LimitedSizeDocument = void 0;\nconst os = __webpack_require__(/*! os */ \"os\");\nconst process = __webpack_require__(/*! process */ \"process\");\nconst bson_1 = __webpack_require__(/*! ../../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../utils */ \"./node_modules/mongodb/lib/utils.js\");\n// eslint-disable-next-line @typescript-eslint/no-var-requires\nconst NODE_DRIVER_VERSION = (__webpack_require__(/*! ../../../package.json */ \"./node_modules/mongodb/package.json\").version);\n/** @internal */\nclass LimitedSizeDocument {\n    constructor(maxSize) {\n        this.maxSize = maxSize;\n        this.document = new Map();\n        /** BSON overhead: Int32 + Null byte */\n        this.documentSize = 5;\n    }\n    /** Only adds key/value if the bsonByteLength is less than MAX_SIZE */\n    ifItFitsItSits(key, value) {\n        // The BSON byteLength of the new element is the same as serializing it to its own document\n        // subtracting the document size int32 and the null terminator.\n        const newElementSize = bson_1.BSON.serialize(new Map().set(key, value)).byteLength - 5;\n        if (newElementSize + this.documentSize > this.maxSize) {\n            return false;\n        }\n        this.documentSize += newElementSize;\n        this.document.set(key, value);\n        return true;\n    }\n    toObject() {\n        return bson_1.BSON.deserialize(bson_1.BSON.serialize(this.document), {\n            promoteLongs: false,\n            promoteBuffers: false,\n            promoteValues: false,\n            useBigInt64: false\n        });\n    }\n}\nexports.LimitedSizeDocument = LimitedSizeDocument;\n/**\n * From the specs:\n * Implementors SHOULD cumulatively update fields in the following order until the document is under the size limit:\n * 1. Omit fields from `env` except `env.name`.\n * 2. Omit fields from `os` except `os.type`.\n * 3. Omit the `env` document entirely.\n * 4. Truncate `platform`. -- special we do not truncate this field\n */\nfunction makeClientMetadata(options) {\n    const metadataDocument = new LimitedSizeDocument(512);\n    const { appName = '' } = options;\n    // Add app name first, it must be sent\n    if (appName.length > 0) {\n        const name = Buffer.byteLength(appName, 'utf8') <= 128\n            ? options.appName\n            : Buffer.from(appName, 'utf8').subarray(0, 128).toString('utf8');\n        metadataDocument.ifItFitsItSits('application', { name });\n    }\n    const { name = '', version = '', platform = '' } = options.driverInfo;\n    const driverInfo = {\n        name: name.length > 0 ? `nodejs|${name}` : 'nodejs',\n        version: version.length > 0 ? `${NODE_DRIVER_VERSION}|${version}` : NODE_DRIVER_VERSION\n    };\n    if (!metadataDocument.ifItFitsItSits('driver', driverInfo)) {\n        throw new error_1.MongoInvalidArgumentError('Unable to include driverInfo name and version, metadata cannot exceed 512 bytes');\n    }\n    let runtimeInfo = getRuntimeInfo();\n    if (platform.length > 0) {\n        runtimeInfo = `${runtimeInfo}|${platform}`;\n    }\n    if (!metadataDocument.ifItFitsItSits('platform', runtimeInfo)) {\n        throw new error_1.MongoInvalidArgumentError('Unable to include driverInfo platform, metadata cannot exceed 512 bytes');\n    }\n    // Note: order matters, os.type is last so it will be removed last if we're at maxSize\n    const osInfo = new Map()\n        .set('name', process.platform)\n        .set('architecture', process.arch)\n        .set('version', os.release())\n        .set('type', os.type());\n    if (!metadataDocument.ifItFitsItSits('os', osInfo)) {\n        for (const key of osInfo.keys()) {\n            osInfo.delete(key);\n            if (osInfo.size === 0)\n                break;\n            if (metadataDocument.ifItFitsItSits('os', osInfo))\n                break;\n        }\n    }\n    const faasEnv = getFAASEnv();\n    if (faasEnv != null) {\n        if (!metadataDocument.ifItFitsItSits('env', faasEnv)) {\n            for (const key of faasEnv.keys()) {\n                faasEnv.delete(key);\n                if (faasEnv.size === 0)\n                    break;\n                if (metadataDocument.ifItFitsItSits('env', faasEnv))\n                    break;\n            }\n        }\n    }\n    return metadataDocument.toObject();\n}\nexports.makeClientMetadata = makeClientMetadata;\nlet dockerPromise;\n/** @internal */\nasync function getContainerMetadata() {\n    const containerMetadata = {};\n    dockerPromise ??= (0, utils_1.fileIsAccessible)('/.dockerenv');\n    const isDocker = await dockerPromise;\n    const { KUBERNETES_SERVICE_HOST = '' } = process.env;\n    const isKubernetes = KUBERNETES_SERVICE_HOST.length > 0 ? true : false;\n    if (isDocker)\n        containerMetadata.runtime = 'docker';\n    if (isKubernetes)\n        containerMetadata.orchestrator = 'kubernetes';\n    return containerMetadata;\n}\n/**\n * @internal\n * Re-add each metadata value.\n * Attempt to add new env container metadata, but keep old data if it does not fit.\n */\nasync function addContainerMetadata(originalMetadata) {\n    const containerMetadata = await getContainerMetadata();\n    if (Object.keys(containerMetadata).length === 0)\n        return originalMetadata;\n    const extendedMetadata = new LimitedSizeDocument(512);\n    const extendedEnvMetadata = { ...originalMetadata?.env, container: containerMetadata };\n    for (const [key, val] of Object.entries(originalMetadata)) {\n        if (key !== 'env') {\n            extendedMetadata.ifItFitsItSits(key, val);\n        }\n        else {\n            if (!extendedMetadata.ifItFitsItSits('env', extendedEnvMetadata)) {\n                // add in old data if newer / extended metadata does not fit\n                extendedMetadata.ifItFitsItSits('env', val);\n            }\n        }\n    }\n    if (!('env' in originalMetadata)) {\n        extendedMetadata.ifItFitsItSits('env', extendedEnvMetadata);\n    }\n    return extendedMetadata.toObject();\n}\nexports.addContainerMetadata = addContainerMetadata;\n/**\n * Collects FaaS metadata.\n * - `name` MUST be the last key in the Map returned.\n */\nfunction getFAASEnv() {\n    const { AWS_EXECUTION_ENV = '', AWS_LAMBDA_RUNTIME_API = '', FUNCTIONS_WORKER_RUNTIME = '', K_SERVICE = '', FUNCTION_NAME = '', VERCEL = '', AWS_LAMBDA_FUNCTION_MEMORY_SIZE = '', AWS_REGION = '', FUNCTION_MEMORY_MB = '', FUNCTION_REGION = '', FUNCTION_TIMEOUT_SEC = '', VERCEL_REGION = '' } = process.env;\n    const isAWSFaaS = AWS_EXECUTION_ENV.startsWith('AWS_Lambda_') || AWS_LAMBDA_RUNTIME_API.length > 0;\n    const isAzureFaaS = FUNCTIONS_WORKER_RUNTIME.length > 0;\n    const isGCPFaaS = K_SERVICE.length > 0 || FUNCTION_NAME.length > 0;\n    const isVercelFaaS = VERCEL.length > 0;\n    // Note: order matters, name must always be the last key\n    const faasEnv = new Map();\n    // When isVercelFaaS is true so is isAWSFaaS; Vercel inherits the AWS env\n    if (isVercelFaaS && !(isAzureFaaS || isGCPFaaS)) {\n        if (VERCEL_REGION.length > 0) {\n            faasEnv.set('region', VERCEL_REGION);\n        }\n        faasEnv.set('name', 'vercel');\n        return faasEnv;\n    }\n    if (isAWSFaaS && !(isAzureFaaS || isGCPFaaS || isVercelFaaS)) {\n        if (AWS_REGION.length > 0) {\n            faasEnv.set('region', AWS_REGION);\n        }\n        if (AWS_LAMBDA_FUNCTION_MEMORY_SIZE.length > 0 &&\n            Number.isInteger(+AWS_LAMBDA_FUNCTION_MEMORY_SIZE)) {\n            faasEnv.set('memory_mb', new bson_1.Int32(AWS_LAMBDA_FUNCTION_MEMORY_SIZE));\n        }\n        faasEnv.set('name', 'aws.lambda');\n        return faasEnv;\n    }\n    if (isAzureFaaS && !(isGCPFaaS || isAWSFaaS || isVercelFaaS)) {\n        faasEnv.set('name', 'azure.func');\n        return faasEnv;\n    }\n    if (isGCPFaaS && !(isAzureFaaS || isAWSFaaS || isVercelFaaS)) {\n        if (FUNCTION_REGION.length > 0) {\n            faasEnv.set('region', FUNCTION_REGION);\n        }\n        if (FUNCTION_MEMORY_MB.length > 0 && Number.isInteger(+FUNCTION_MEMORY_MB)) {\n            faasEnv.set('memory_mb', new bson_1.Int32(FUNCTION_MEMORY_MB));\n        }\n        if (FUNCTION_TIMEOUT_SEC.length > 0 && Number.isInteger(+FUNCTION_TIMEOUT_SEC)) {\n            faasEnv.set('timeout_sec', new bson_1.Int32(FUNCTION_TIMEOUT_SEC));\n        }\n        faasEnv.set('name', 'gcp.func');\n        return faasEnv;\n    }\n    return null;\n}\nexports.getFAASEnv = getFAASEnv;\n/**\n * @internal\n * Get current JavaScript runtime platform\n *\n * NOTE: The version information fetching is intentionally written defensively\n * to avoid having a released driver version that becomes incompatible\n * with a future change to these global objects.\n */\nfunction getRuntimeInfo() {\n    if ('Deno' in globalThis) {\n        const version = typeof Deno?.version?.deno === 'string' ? Deno?.version?.deno : '0.0.0-unknown';\n        return `Deno v${version}, ${os.endianness()}`;\n    }\n    if ('Bun' in globalThis) {\n        const version = typeof Bun?.version === 'string' ? Bun?.version : '0.0.0-unknown';\n        return `Bun v${version}, ${os.endianness()}`;\n    }\n    return `Node.js ${process.version}, ${os.endianness()}`;\n}\n//# sourceMappingURL=client_metadata.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/handshake/client_metadata.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/metrics.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/metrics.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConnectionPoolMetrics = void 0;\n/** @internal */\nclass ConnectionPoolMetrics {\n    constructor() {\n        this.txnConnections = 0;\n        this.cursorConnections = 0;\n        this.otherConnections = 0;\n    }\n    /**\n     * Mark a connection as pinned for a specific operation.\n     */\n    markPinned(pinType) {\n        if (pinType === ConnectionPoolMetrics.TXN) {\n            this.txnConnections += 1;\n        }\n        else if (pinType === ConnectionPoolMetrics.CURSOR) {\n            this.cursorConnections += 1;\n        }\n        else {\n            this.otherConnections += 1;\n        }\n    }\n    /**\n     * Unmark a connection as pinned for an operation.\n     */\n    markUnpinned(pinType) {\n        if (pinType === ConnectionPoolMetrics.TXN) {\n            this.txnConnections -= 1;\n        }\n        else if (pinType === ConnectionPoolMetrics.CURSOR) {\n            this.cursorConnections -= 1;\n        }\n        else {\n            this.otherConnections -= 1;\n        }\n    }\n    /**\n     * Return information about the cmap metrics as a string.\n     */\n    info(maxPoolSize) {\n        return ('Timed out while checking out a connection from connection pool: ' +\n            `maxPoolSize: ${maxPoolSize}, ` +\n            `connections in use by cursors: ${this.cursorConnections}, ` +\n            `connections in use by transactions: ${this.txnConnections}, ` +\n            `connections in use by other operations: ${this.otherConnections}`);\n    }\n    /**\n     * Reset the metrics to the initial values.\n     */\n    reset() {\n        this.txnConnections = 0;\n        this.cursorConnections = 0;\n        this.otherConnections = 0;\n    }\n}\nConnectionPoolMetrics.TXN = 'txn';\nConnectionPoolMetrics.CURSOR = 'cursor';\nConnectionPoolMetrics.OTHER = 'other';\nexports.ConnectionPoolMetrics = ConnectionPoolMetrics;\n//# sourceMappingURL=metrics.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/metrics.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/stream_description.js":
/*!*************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/stream_description.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.StreamDescription = void 0;\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst common_1 = __webpack_require__(/*! ../sdam/common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst server_description_1 = __webpack_require__(/*! ../sdam/server_description */ \"./node_modules/mongodb/lib/sdam/server_description.js\");\nconst RESPONSE_FIELDS = [\n    'minWireVersion',\n    'maxWireVersion',\n    'maxBsonObjectSize',\n    'maxMessageSizeBytes',\n    'maxWriteBatchSize',\n    'logicalSessionTimeoutMinutes'\n];\n/** @public */\nclass StreamDescription {\n    constructor(address, options) {\n        this.hello = null;\n        this.address = address;\n        this.type = common_1.ServerType.Unknown;\n        this.minWireVersion = undefined;\n        this.maxWireVersion = undefined;\n        this.maxBsonObjectSize = 16777216;\n        this.maxMessageSizeBytes = 48000000;\n        this.maxWriteBatchSize = 100000;\n        this.logicalSessionTimeoutMinutes = options?.logicalSessionTimeoutMinutes;\n        this.loadBalanced = !!options?.loadBalanced;\n        this.compressors =\n            options && options.compressors && Array.isArray(options.compressors)\n                ? options.compressors\n                : [];\n        this.serverConnectionId = null;\n    }\n    receiveResponse(response) {\n        if (response == null) {\n            return;\n        }\n        this.hello = response;\n        this.type = (0, server_description_1.parseServerType)(response);\n        if ('connectionId' in response) {\n            this.serverConnectionId = this.parseServerConnectionID(response.connectionId);\n        }\n        else {\n            this.serverConnectionId = null;\n        }\n        for (const field of RESPONSE_FIELDS) {\n            if (response[field] != null) {\n                this[field] = response[field];\n            }\n            // testing case\n            if ('__nodejs_mock_server__' in response) {\n                this.__nodejs_mock_server__ = response['__nodejs_mock_server__'];\n            }\n        }\n        if (response.compression) {\n            this.compressor = this.compressors.filter(c => response.compression?.includes(c))[0];\n        }\n    }\n    /* @internal */\n    parseServerConnectionID(serverConnectionId) {\n        // Connection ids are always integral, so it's safe to coerce doubles as well as\n        // any integral type.\n        return bson_1.Long.isLong(serverConnectionId)\n            ? serverConnectionId.toBigInt()\n            : // @ts-expect-error: Doubles are coercible to number\n                BigInt(serverConnectionId);\n    }\n}\nexports.StreamDescription = StreamDescription;\n//# sourceMappingURL=stream_description.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/stream_description.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/wire_protocol/compression.js":
/*!********************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/wire_protocol/compression.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.decompressResponse = exports.compressCommand = exports.decompress = exports.compress = exports.uncompressibleCommands = exports.Compressor = void 0;\nconst util_1 = __webpack_require__(/*! util */ \"util\");\nconst zlib = __webpack_require__(/*! zlib */ \"zlib\");\nconst constants_1 = __webpack_require__(/*! ../../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst deps_1 = __webpack_require__(/*! ../../deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst commands_1 = __webpack_require__(/*! ../commands */ \"./node_modules/mongodb/lib/cmap/commands.js\");\nconst constants_2 = __webpack_require__(/*! ./constants */ \"./node_modules/mongodb/lib/cmap/wire_protocol/constants.js\");\n/** @public */\nexports.Compressor = Object.freeze({\n    none: 0,\n    snappy: 1,\n    zlib: 2,\n    zstd: 3\n});\nexports.uncompressibleCommands = new Set([\n    constants_1.LEGACY_HELLO_COMMAND,\n    'saslStart',\n    'saslContinue',\n    'getnonce',\n    'authenticate',\n    'createUser',\n    'updateUser',\n    'copydbSaslStart',\n    'copydbgetnonce',\n    'copydb'\n]);\nconst ZSTD_COMPRESSION_LEVEL = 3;\nconst zlibInflate = (0, util_1.promisify)(zlib.inflate.bind(zlib));\nconst zlibDeflate = (0, util_1.promisify)(zlib.deflate.bind(zlib));\nlet zstd;\nlet Snappy = null;\nfunction loadSnappy() {\n    if (Snappy == null) {\n        const snappyImport = (0, deps_1.getSnappy)();\n        if ('kModuleError' in snappyImport) {\n            throw snappyImport.kModuleError;\n        }\n        Snappy = snappyImport;\n    }\n    return Snappy;\n}\n// Facilitate compressing a message using an agreed compressor\nasync function compress(options, dataToBeCompressed) {\n    const zlibOptions = {};\n    switch (options.agreedCompressor) {\n        case 'snappy': {\n            Snappy ??= loadSnappy();\n            return await Snappy.compress(dataToBeCompressed);\n        }\n        case 'zstd': {\n            loadZstd();\n            if ('kModuleError' in zstd) {\n                throw zstd['kModuleError'];\n            }\n            return await zstd.compress(dataToBeCompressed, ZSTD_COMPRESSION_LEVEL);\n        }\n        case 'zlib': {\n            if (options.zlibCompressionLevel) {\n                zlibOptions.level = options.zlibCompressionLevel;\n            }\n            return await zlibDeflate(dataToBeCompressed, zlibOptions);\n        }\n        default: {\n            throw new error_1.MongoInvalidArgumentError(`Unknown compressor ${options.agreedCompressor} failed to compress`);\n        }\n    }\n}\nexports.compress = compress;\n// Decompress a message using the given compressor\nasync function decompress(compressorID, compressedData) {\n    if (compressorID !== exports.Compressor.snappy &&\n        compressorID !== exports.Compressor.zstd &&\n        compressorID !== exports.Compressor.zlib &&\n        compressorID !== exports.Compressor.none) {\n        throw new error_1.MongoDecompressionError(`Server sent message compressed using an unsupported compressor. (Received compressor ID ${compressorID})`);\n    }\n    switch (compressorID) {\n        case exports.Compressor.snappy: {\n            Snappy ??= loadSnappy();\n            return await Snappy.uncompress(compressedData, { asBuffer: true });\n        }\n        case exports.Compressor.zstd: {\n            loadZstd();\n            if ('kModuleError' in zstd) {\n                throw zstd['kModuleError'];\n            }\n            return await zstd.decompress(compressedData);\n        }\n        case exports.Compressor.zlib: {\n            return await zlibInflate(compressedData);\n        }\n        default: {\n            return compressedData;\n        }\n    }\n}\nexports.decompress = decompress;\n/**\n * Load ZStandard if it is not already set.\n */\nfunction loadZstd() {\n    if (!zstd) {\n        zstd = (0, deps_1.getZstdLibrary)();\n    }\n}\nconst MESSAGE_HEADER_SIZE = 16;\n/**\n * @internal\n *\n * Compresses an OP_MSG or OP_QUERY message, if compression is configured.  This method\n * also serializes the command to BSON.\n */\nasync function compressCommand(command, description) {\n    const finalCommand = description.agreedCompressor === 'none' || !commands_1.OpCompressedRequest.canCompress(command)\n        ? command\n        : new commands_1.OpCompressedRequest(command, {\n            agreedCompressor: description.agreedCompressor ?? 'none',\n            zlibCompressionLevel: description.zlibCompressionLevel ?? 0\n        });\n    const data = await finalCommand.toBin();\n    return Buffer.concat(data);\n}\nexports.compressCommand = compressCommand;\n/**\n * @internal\n *\n * Decompresses an OP_MSG or OP_QUERY response from the server, if compression is configured.\n *\n * This method does not parse the response's BSON.\n */\nasync function decompressResponse(message) {\n    const messageHeader = {\n        length: message.readInt32LE(0),\n        requestId: message.readInt32LE(4),\n        responseTo: message.readInt32LE(8),\n        opCode: message.readInt32LE(12)\n    };\n    if (messageHeader.opCode !== constants_2.OP_COMPRESSED) {\n        const ResponseType = messageHeader.opCode === constants_2.OP_MSG ? commands_1.OpMsgResponse : commands_1.OpReply;\n        const messageBody = message.subarray(MESSAGE_HEADER_SIZE);\n        return new ResponseType(message, messageHeader, messageBody);\n    }\n    const header = {\n        ...messageHeader,\n        fromCompressed: true,\n        opCode: message.readInt32LE(MESSAGE_HEADER_SIZE),\n        length: message.readInt32LE(MESSAGE_HEADER_SIZE + 4)\n    };\n    const compressorID = message[MESSAGE_HEADER_SIZE + 8];\n    const compressedBuffer = message.slice(MESSAGE_HEADER_SIZE + 9);\n    // recalculate based on wrapped opcode\n    const ResponseType = header.opCode === constants_2.OP_MSG ? commands_1.OpMsgResponse : commands_1.OpReply;\n    const messageBody = await decompress(compressorID, compressedBuffer);\n    if (messageBody.length !== header.length) {\n        throw new error_1.MongoDecompressionError('Message body and message header must be the same length');\n    }\n    return new ResponseType(message, header, messageBody);\n}\nexports.decompressResponse = decompressResponse;\n//# sourceMappingURL=compression.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/wire_protocol/compression.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/wire_protocol/constants.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/wire_protocol/constants.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.OP_MSG = exports.OP_COMPRESSED = exports.OP_DELETE = exports.OP_QUERY = exports.OP_INSERT = exports.OP_UPDATE = exports.OP_REPLY = exports.MIN_SUPPORTED_QE_SERVER_VERSION = exports.MIN_SUPPORTED_QE_WIRE_VERSION = exports.MAX_SUPPORTED_WIRE_VERSION = exports.MIN_SUPPORTED_WIRE_VERSION = exports.MAX_SUPPORTED_SERVER_VERSION = exports.MIN_SUPPORTED_SERVER_VERSION = void 0;\nexports.MIN_SUPPORTED_SERVER_VERSION = '3.6';\nexports.MAX_SUPPORTED_SERVER_VERSION = '7.0';\nexports.MIN_SUPPORTED_WIRE_VERSION = 6;\nexports.MAX_SUPPORTED_WIRE_VERSION = 21;\nexports.MIN_SUPPORTED_QE_WIRE_VERSION = 21;\nexports.MIN_SUPPORTED_QE_SERVER_VERSION = '7.0';\nexports.OP_REPLY = 1;\nexports.OP_UPDATE = 2001;\nexports.OP_INSERT = 2002;\nexports.OP_QUERY = 2004;\nexports.OP_DELETE = 2006;\nexports.OP_COMPRESSED = 2012;\nexports.OP_MSG = 2013;\n//# sourceMappingURL=constants.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/wire_protocol/constants.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/wire_protocol/on_data.js":
/*!****************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/wire_protocol/on_data.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.onData = void 0;\nconst utils_1 = __webpack_require__(/*! ../../utils */ \"./node_modules/mongodb/lib/utils.js\");\n/**\n * onData is adapted from Node.js' events.on helper\n * https://nodejs.org/api/events.html#eventsonemitter-eventname-options\n *\n * Returns an AsyncIterator that iterates each 'data' event emitted from emitter.\n * It will reject upon an error event.\n */\nfunction onData(emitter) {\n    // Setup pending events and pending promise lists\n    /**\n     * When the caller has not yet called .next(), we store the\n     * value from the event in this list. Next time they call .next()\n     * we pull the first value out of this list and resolve a promise with it.\n     */\n    const unconsumedEvents = new utils_1.List();\n    /**\n     * When there has not yet been an event, a new promise will be created\n     * and implicitly stored in this list. When an event occurs we take the first\n     * promise in this list and resolve it.\n     */\n    const unconsumedPromises = new utils_1.List();\n    /**\n     * Stored an error created by an error event.\n     * This error will turn into a rejection for the subsequent .next() call\n     */\n    let error = null;\n    /** Set to true only after event listeners have been removed. */\n    let finished = false;\n    const iterator = {\n        next() {\n            // First, we consume all unread events\n            const value = unconsumedEvents.shift();\n            if (value != null) {\n                return Promise.resolve({ value, done: false });\n            }\n            // Then we error, if an error happened\n            // This happens one time if at all, because after 'error'\n            // we stop listening\n            if (error != null) {\n                const p = Promise.reject(error);\n                // Only the first element errors\n                error = null;\n                return p;\n            }\n            // If the iterator is finished, resolve to done\n            if (finished)\n                return closeHandler();\n            // Wait until an event happens\n            const { promise, resolve, reject } = (0, utils_1.promiseWithResolvers)();\n            unconsumedPromises.push({ resolve, reject });\n            return promise;\n        },\n        return() {\n            return closeHandler();\n        },\n        throw(err) {\n            errorHandler(err);\n            return Promise.resolve({ value: undefined, done: true });\n        },\n        [Symbol.asyncIterator]() {\n            return this;\n        }\n    };\n    // Adding event handlers\n    emitter.on('data', eventHandler);\n    emitter.on('error', errorHandler);\n    return iterator;\n    function eventHandler(value) {\n        const promise = unconsumedPromises.shift();\n        if (promise != null)\n            promise.resolve({ value, done: false });\n        else\n            unconsumedEvents.push(value);\n    }\n    function errorHandler(err) {\n        const promise = unconsumedPromises.shift();\n        if (promise != null)\n            promise.reject(err);\n        else\n            error = err;\n        void closeHandler();\n    }\n    function closeHandler() {\n        // Adding event handlers\n        emitter.off('data', eventHandler);\n        emitter.off('error', errorHandler);\n        finished = true;\n        const doneResult = { value: undefined, done: finished };\n        for (const promise of unconsumedPromises) {\n            promise.resolve(doneResult);\n        }\n        return Promise.resolve(doneResult);\n    }\n}\nexports.onData = onData;\n//# sourceMappingURL=on_data.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/wire_protocol/on_data.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/wire_protocol/on_demand/document.js":
/*!***************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/wire_protocol/on_demand/document.js ***!
  \***************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.OnDemandDocument = void 0;\nconst bson_1 = __webpack_require__(/*! ../../../bson */ \"./node_modules/mongodb/lib/bson.js\");\n/** @internal */\nclass OnDemandDocument {\n    constructor(\n    /** BSON bytes, this document begins at offset */\n    bson, \n    /** The start of the document */\n    offset = 0, \n    /** If this is an embedded document, indicates if this was a BSON array */\n    isArray = false) {\n        this.bson = bson;\n        this.offset = offset;\n        this.isArray = isArray;\n        /**\n         * Maps JS strings to elements and jsValues for speeding up subsequent lookups.\n         * - If `false` then name does not exist in the BSON document\n         * - If `CachedBSONElement` instance name exists\n         * - If `cache[name].value == null` jsValue has not yet been parsed\n         *   - Null/Undefined values do not get cached because they are zero-length values.\n         */\n        this.cache = Object.create(null);\n        /** Caches the index of elements that have been named */\n        this.indexFound = Object.create(null);\n        this.elements = (0, bson_1.parseToElementsToArray)(this.bson, offset);\n    }\n    /** Only supports basic latin strings */\n    isElementName(name, element) {\n        const nameLength = element[2 /* BSONElementOffset.nameLength */];\n        const nameOffset = element[1 /* BSONElementOffset.nameOffset */];\n        if (name.length !== nameLength)\n            return false;\n        for (let i = 0; i < name.length; i++) {\n            if (this.bson[nameOffset + i] !== name.charCodeAt(i))\n                return false;\n        }\n        return true;\n    }\n    /**\n     * Seeks into the elements array for an element matching the given name.\n     *\n     * @remarks\n     * Caching:\n     * - Caches the existence of a property making subsequent look ups for non-existent properties return immediately\n     * - Caches names mapped to elements to avoid reiterating the array and comparing the name again\n     * - Caches the index at which an element has been found to prevent rechecking against elements already determined to belong to another name\n     *\n     * @param name - a basic latin string name of a BSON element\n     * @returns\n     */\n    getElement(name) {\n        const cachedElement = this.cache[name];\n        if (cachedElement === false)\n            return null;\n        if (cachedElement != null) {\n            return cachedElement;\n        }\n        if (typeof name === 'number') {\n            if (this.isArray) {\n                if (name < this.elements.length) {\n                    const element = this.elements[name];\n                    const cachedElement = { element, value: undefined };\n                    this.cache[name] = cachedElement;\n                    this.indexFound[name] = true;\n                    return cachedElement;\n                }\n                else {\n                    return null;\n                }\n            }\n            else {\n                return null;\n            }\n        }\n        for (let index = 0; index < this.elements.length; index++) {\n            const element = this.elements[index];\n            // skip this element if it has already been associated with a name\n            if (!this.indexFound[index] && this.isElementName(name, element)) {\n                const cachedElement = { element, value: undefined };\n                this.cache[name] = cachedElement;\n                this.indexFound[index] = true;\n                return cachedElement;\n            }\n        }\n        this.cache[name] = false;\n        return null;\n    }\n    toJSValue(element, as) {\n        const type = element[0 /* BSONElementOffset.type */];\n        const offset = element[3 /* BSONElementOffset.offset */];\n        const length = element[4 /* BSONElementOffset.length */];\n        if (as !== type) {\n            return null;\n        }\n        switch (as) {\n            case bson_1.BSONType.null:\n            case bson_1.BSONType.undefined:\n                return null;\n            case bson_1.BSONType.double:\n                return (0, bson_1.getFloat64LE)(this.bson, offset);\n            case bson_1.BSONType.int:\n                return (0, bson_1.getInt32LE)(this.bson, offset);\n            case bson_1.BSONType.long:\n                return (0, bson_1.getBigInt64LE)(this.bson, offset);\n            case bson_1.BSONType.bool:\n                return Boolean(this.bson[offset]);\n            case bson_1.BSONType.objectId:\n                return new bson_1.ObjectId(this.bson.subarray(offset, offset + 12));\n            case bson_1.BSONType.timestamp:\n                return new bson_1.Timestamp((0, bson_1.getBigInt64LE)(this.bson, offset));\n            case bson_1.BSONType.string:\n                return (0, bson_1.toUTF8)(this.bson, offset + 4, offset + length - 1, false);\n            case bson_1.BSONType.binData: {\n                const totalBinarySize = (0, bson_1.getInt32LE)(this.bson, offset);\n                const subType = this.bson[offset + 4];\n                if (subType === 2) {\n                    const subType2BinarySize = (0, bson_1.getInt32LE)(this.bson, offset + 1 + 4);\n                    if (subType2BinarySize < 0)\n                        throw new bson_1.BSONError('Negative binary type element size found for subtype 0x02');\n                    if (subType2BinarySize > totalBinarySize - 4)\n                        throw new bson_1.BSONError('Binary type with subtype 0x02 contains too long binary size');\n                    if (subType2BinarySize < totalBinarySize - 4)\n                        throw new bson_1.BSONError('Binary type with subtype 0x02 contains too short binary size');\n                    return new bson_1.Binary(this.bson.subarray(offset + 1 + 4 + 4, offset + 1 + 4 + 4 + subType2BinarySize), 2);\n                }\n                return new bson_1.Binary(this.bson.subarray(offset + 1 + 4, offset + 1 + 4 + totalBinarySize), subType);\n            }\n            case bson_1.BSONType.date:\n                // Pretend this is correct.\n                return new Date(Number((0, bson_1.getBigInt64LE)(this.bson, offset)));\n            case bson_1.BSONType.object:\n                return new OnDemandDocument(this.bson, offset);\n            case bson_1.BSONType.array:\n                return new OnDemandDocument(this.bson, offset, true);\n            default:\n                throw new bson_1.BSONError(`Unsupported BSON type: ${as}`);\n        }\n    }\n    /**\n     * Returns the number of elements in this BSON document\n     */\n    size() {\n        return this.elements.length;\n    }\n    /**\n     * Checks for the existence of an element by name.\n     *\n     * @remarks\n     * Uses `getElement` with the expectation that will populate caches such that a `has` call\n     * followed by a `getElement` call will not repeat the cost paid by the first look up.\n     *\n     * @param name - element name\n     */\n    has(name) {\n        const cachedElement = this.cache[name];\n        if (cachedElement === false)\n            return false;\n        if (cachedElement != null)\n            return true;\n        return this.getElement(name) != null;\n    }\n    get(name, as, required) {\n        const element = this.getElement(name);\n        if (element == null) {\n            if (required === true) {\n                throw new bson_1.BSONError(`BSON element \"${name}\" is missing`);\n            }\n            else {\n                return null;\n            }\n        }\n        if (element.value == null) {\n            const value = this.toJSValue(element.element, as);\n            if (value == null) {\n                if (required === true) {\n                    throw new bson_1.BSONError(`BSON element \"${name}\" is missing`);\n                }\n                else {\n                    return null;\n                }\n            }\n            // It is important to never store null\n            element.value = value;\n        }\n        return element.value;\n    }\n    getNumber(name, required) {\n        const maybeBool = this.get(name, bson_1.BSONType.bool);\n        const bool = maybeBool == null ? null : maybeBool ? 1 : 0;\n        const maybeLong = this.get(name, bson_1.BSONType.long);\n        const long = maybeLong == null ? null : Number(maybeLong);\n        const result = bool ?? long ?? this.get(name, bson_1.BSONType.int) ?? this.get(name, bson_1.BSONType.double);\n        if (required === true && result == null) {\n            throw new bson_1.BSONError(`BSON element \"${name}\" is missing`);\n        }\n        return result;\n    }\n    /**\n     * Deserialize this object, DOES NOT cache result so avoid multiple invocations\n     * @param options - BSON deserialization options\n     */\n    toObject(options) {\n        return bson_1.BSON.deserialize(this.bson, {\n            ...options,\n            index: this.offset,\n            allowObjectSmallerThanBufferSize: true\n        });\n    }\n    /** Returns this document's bytes only */\n    toBytes() {\n        const size = (0, bson_1.getInt32LE)(this.bson, this.offset);\n        return this.bson.subarray(this.offset, this.offset + size);\n    }\n}\nexports.OnDemandDocument = OnDemandDocument;\n//# sourceMappingURL=document.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/wire_protocol/on_demand/document.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/wire_protocol/responses.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/wire_protocol/responses.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CursorResponse = exports.MongoDBResponse = exports.isErrorResponse = void 0;\nconst bson_1 = __webpack_require__(/*! ../../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst document_1 = __webpack_require__(/*! ./on_demand/document */ \"./node_modules/mongodb/lib/cmap/wire_protocol/on_demand/document.js\");\n/**\n * Accepts a BSON payload and checks for na \"ok: 0\" element.\n * This utility is intended to prevent calling response class constructors\n * that expect the result to be a success and demand certain properties to exist.\n *\n * For example, a cursor response always expects a cursor embedded document.\n * In order to write the class such that the properties reflect that assertion (non-null)\n * we cannot invoke the subclass constructor if the BSON represents an error.\n *\n * @param bytes - BSON document returned from the server\n */\nfunction isErrorResponse(bson) {\n    const elements = (0, bson_1.parseToElementsToArray)(bson, 0);\n    for (let eIdx = 0; eIdx < elements.length; eIdx++) {\n        const element = elements[eIdx];\n        if (element[2 /* BSONElementOffset.nameLength */] === 2) {\n            const nameOffset = element[1 /* BSONElementOffset.nameOffset */];\n            // 111 == \"o\", 107 == \"k\"\n            if (bson[nameOffset] === 111 && bson[nameOffset + 1] === 107) {\n                const valueOffset = element[3 /* BSONElementOffset.offset */];\n                const valueLength = element[4 /* BSONElementOffset.length */];\n                // If any byte in the length of the ok number (works for any type) is non zero,\n                // then it is considered \"ok: 1\"\n                for (let i = valueOffset; i < valueOffset + valueLength; i++) {\n                    if (bson[i] !== 0x00)\n                        return false;\n                }\n                return true;\n            }\n        }\n    }\n    return true;\n}\nexports.isErrorResponse = isErrorResponse;\n/** @internal */\nclass MongoDBResponse extends document_1.OnDemandDocument {\n    static is(value) {\n        return value instanceof MongoDBResponse;\n    }\n    /** Indicates this document is a server error */\n    get isError() {\n        let isError = this.ok === 0;\n        isError ||= this.has('errmsg');\n        isError ||= this.has('code');\n        isError ||= this.has('$err'); // The '$err' field is used in OP_REPLY responses\n        return isError;\n    }\n    /**\n     * Drivers can safely assume that the `recoveryToken` field is always a BSON document but drivers MUST NOT modify the\n     * contents of the document.\n     */\n    get recoveryToken() {\n        return (this.get('recoveryToken', bson_1.BSONType.object)?.toObject({\n            promoteValues: false,\n            promoteLongs: false,\n            promoteBuffers: false\n        }) ?? null);\n    }\n    /**\n     * The server creates a cursor in response to a snapshot find/aggregate command and reports atClusterTime within the cursor field in the response.\n     * For the distinct command the server adds a top-level atClusterTime field to the response.\n     * The atClusterTime field represents the timestamp of the read and is guaranteed to be majority committed.\n     */\n    get atClusterTime() {\n        return (this.get('cursor', bson_1.BSONType.object)?.get('atClusterTime', bson_1.BSONType.timestamp) ??\n            this.get('atClusterTime', bson_1.BSONType.timestamp));\n    }\n    get operationTime() {\n        return this.get('operationTime', bson_1.BSONType.timestamp);\n    }\n    get ok() {\n        return this.getNumber('ok') ? 1 : 0;\n    }\n    get $err() {\n        return this.get('$err', bson_1.BSONType.string);\n    }\n    get errmsg() {\n        return this.get('errmsg', bson_1.BSONType.string);\n    }\n    get code() {\n        return this.getNumber('code');\n    }\n    get $clusterTime() {\n        if (!('clusterTime' in this)) {\n            const clusterTimeDoc = this.get('$clusterTime', bson_1.BSONType.object);\n            if (clusterTimeDoc == null) {\n                this.clusterTime = null;\n                return null;\n            }\n            const clusterTime = clusterTimeDoc.get('clusterTime', bson_1.BSONType.timestamp, true);\n            const signature = clusterTimeDoc.get('signature', bson_1.BSONType.object)?.toObject();\n            // @ts-expect-error: `signature` is incorrectly typed. It is public API.\n            this.clusterTime = { clusterTime, signature };\n        }\n        return this.clusterTime ?? null;\n    }\n    toObject(options) {\n        const exactBSONOptions = {\n            useBigInt64: options?.useBigInt64,\n            promoteLongs: options?.promoteLongs,\n            promoteValues: options?.promoteValues,\n            promoteBuffers: options?.promoteBuffers,\n            bsonRegExp: options?.bsonRegExp,\n            raw: options?.raw ?? false,\n            fieldsAsRaw: options?.fieldsAsRaw ?? {},\n            validation: this.parseBsonSerializationOptions(options)\n        };\n        return super.toObject(exactBSONOptions);\n    }\n    parseBsonSerializationOptions(options) {\n        const enableUtf8Validation = options?.enableUtf8Validation;\n        if (enableUtf8Validation === false) {\n            return { utf8: false };\n        }\n        return { utf8: { writeErrors: false } };\n    }\n}\n// {ok:1}\nMongoDBResponse.empty = new MongoDBResponse(new Uint8Array([13, 0, 0, 0, 16, 111, 107, 0, 1, 0, 0, 0, 0]));\nexports.MongoDBResponse = MongoDBResponse;\n/** @internal */\nclass CursorResponse extends MongoDBResponse {\n    static is(value) {\n        return value instanceof CursorResponse || value === CursorResponse.emptyGetMore;\n    }\n    constructor(bytes, offset, isArray) {\n        super(bytes, offset, isArray);\n        this.ns = null;\n        this.batchSize = 0;\n        this.iterated = 0;\n        const cursor = this.get('cursor', bson_1.BSONType.object, true);\n        const id = cursor.get('id', bson_1.BSONType.long, true);\n        this.id = new bson_1.Long(Number(id & 0xffffffffn), Number((id >> 32n) & 0xffffffffn));\n        const namespace = cursor.get('ns', bson_1.BSONType.string);\n        if (namespace != null)\n            this.ns = (0, utils_1.ns)(namespace);\n        if (cursor.has('firstBatch'))\n            this.batch = cursor.get('firstBatch', bson_1.BSONType.array, true);\n        else if (cursor.has('nextBatch'))\n            this.batch = cursor.get('nextBatch', bson_1.BSONType.array, true);\n        else\n            throw new error_1.MongoUnexpectedServerResponseError('Cursor document did not contain a batch');\n        this.batchSize = this.batch.size();\n    }\n    get length() {\n        return Math.max(this.batchSize - this.iterated, 0);\n    }\n    shift(options) {\n        if (this.iterated >= this.batchSize) {\n            return null;\n        }\n        const result = this.batch.get(this.iterated, bson_1.BSONType.object, true) ?? null;\n        this.iterated += 1;\n        if (options?.raw) {\n            return result.toBytes();\n        }\n        else {\n            return result.toObject(options);\n        }\n    }\n    clear() {\n        this.iterated = this.batchSize;\n    }\n    pushMany() {\n        throw new Error('pushMany Unsupported method');\n    }\n    push() {\n        throw new Error('push Unsupported method');\n    }\n}\n/**\n * This supports a feature of the FindCursor.\n * It is an optimization to avoid an extra getMore when the limit has been reached\n */\nCursorResponse.emptyGetMore = { id: new bson_1.Long(0), length: 0, shift: () => null };\nexports.CursorResponse = CursorResponse;\n//# sourceMappingURL=responses.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/wire_protocol/responses.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/wire_protocol/shared.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/wire_protocol/shared.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.isSharded = exports.getReadPreference = void 0;\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_preference_1 = __webpack_require__(/*! ../../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst common_1 = __webpack_require__(/*! ../../sdam/common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst topology_description_1 = __webpack_require__(/*! ../../sdam/topology_description */ \"./node_modules/mongodb/lib/sdam/topology_description.js\");\nfunction getReadPreference(options) {\n    // Default to command version of the readPreference.\n    let readPreference = options?.readPreference ?? read_preference_1.ReadPreference.primary;\n    if (typeof readPreference === 'string') {\n        readPreference = read_preference_1.ReadPreference.fromString(readPreference);\n    }\n    if (!(readPreference instanceof read_preference_1.ReadPreference)) {\n        throw new error_1.MongoInvalidArgumentError('Option \"readPreference\" must be a ReadPreference instance');\n    }\n    return readPreference;\n}\nexports.getReadPreference = getReadPreference;\nfunction isSharded(topologyOrServer) {\n    if (topologyOrServer == null) {\n        return false;\n    }\n    if (topologyOrServer.description && topologyOrServer.description.type === common_1.ServerType.Mongos) {\n        return true;\n    }\n    // NOTE: This is incredibly inefficient, and should be removed once command construction\n    // happens based on `Server` not `Topology`.\n    if (topologyOrServer.description && topologyOrServer.description instanceof topology_description_1.TopologyDescription) {\n        const servers = Array.from(topologyOrServer.description.servers.values());\n        return servers.some((server) => server.type === common_1.ServerType.Mongos);\n    }\n    return false;\n}\nexports.isSharded = isSharded;\n//# sourceMappingURL=shared.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cmap/wire_protocol/shared.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/collection.js":
/*!************************************************!*\
  !*** ./node_modules/mongodb/lib/collection.js ***!
  \************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Collection = void 0;\nconst bson_1 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst ordered_1 = __webpack_require__(/*! ./bulk/ordered */ \"./node_modules/mongodb/lib/bulk/ordered.js\");\nconst unordered_1 = __webpack_require__(/*! ./bulk/unordered */ \"./node_modules/mongodb/lib/bulk/unordered.js\");\nconst change_stream_1 = __webpack_require__(/*! ./change_stream */ \"./node_modules/mongodb/lib/change_stream.js\");\nconst aggregation_cursor_1 = __webpack_require__(/*! ./cursor/aggregation_cursor */ \"./node_modules/mongodb/lib/cursor/aggregation_cursor.js\");\nconst find_cursor_1 = __webpack_require__(/*! ./cursor/find_cursor */ \"./node_modules/mongodb/lib/cursor/find_cursor.js\");\nconst list_indexes_cursor_1 = __webpack_require__(/*! ./cursor/list_indexes_cursor */ \"./node_modules/mongodb/lib/cursor/list_indexes_cursor.js\");\nconst list_search_indexes_cursor_1 = __webpack_require__(/*! ./cursor/list_search_indexes_cursor */ \"./node_modules/mongodb/lib/cursor/list_search_indexes_cursor.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst bulk_write_1 = __webpack_require__(/*! ./operations/bulk_write */ \"./node_modules/mongodb/lib/operations/bulk_write.js\");\nconst count_1 = __webpack_require__(/*! ./operations/count */ \"./node_modules/mongodb/lib/operations/count.js\");\nconst count_documents_1 = __webpack_require__(/*! ./operations/count_documents */ \"./node_modules/mongodb/lib/operations/count_documents.js\");\nconst delete_1 = __webpack_require__(/*! ./operations/delete */ \"./node_modules/mongodb/lib/operations/delete.js\");\nconst distinct_1 = __webpack_require__(/*! ./operations/distinct */ \"./node_modules/mongodb/lib/operations/distinct.js\");\nconst drop_1 = __webpack_require__(/*! ./operations/drop */ \"./node_modules/mongodb/lib/operations/drop.js\");\nconst estimated_document_count_1 = __webpack_require__(/*! ./operations/estimated_document_count */ \"./node_modules/mongodb/lib/operations/estimated_document_count.js\");\nconst execute_operation_1 = __webpack_require__(/*! ./operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst find_and_modify_1 = __webpack_require__(/*! ./operations/find_and_modify */ \"./node_modules/mongodb/lib/operations/find_and_modify.js\");\nconst indexes_1 = __webpack_require__(/*! ./operations/indexes */ \"./node_modules/mongodb/lib/operations/indexes.js\");\nconst insert_1 = __webpack_require__(/*! ./operations/insert */ \"./node_modules/mongodb/lib/operations/insert.js\");\nconst is_capped_1 = __webpack_require__(/*! ./operations/is_capped */ \"./node_modules/mongodb/lib/operations/is_capped.js\");\nconst options_operation_1 = __webpack_require__(/*! ./operations/options_operation */ \"./node_modules/mongodb/lib/operations/options_operation.js\");\nconst rename_1 = __webpack_require__(/*! ./operations/rename */ \"./node_modules/mongodb/lib/operations/rename.js\");\nconst create_1 = __webpack_require__(/*! ./operations/search_indexes/create */ \"./node_modules/mongodb/lib/operations/search_indexes/create.js\");\nconst drop_2 = __webpack_require__(/*! ./operations/search_indexes/drop */ \"./node_modules/mongodb/lib/operations/search_indexes/drop.js\");\nconst update_1 = __webpack_require__(/*! ./operations/search_indexes/update */ \"./node_modules/mongodb/lib/operations/search_indexes/update.js\");\nconst update_2 = __webpack_require__(/*! ./operations/update */ \"./node_modules/mongodb/lib/operations/update.js\");\nconst read_concern_1 = __webpack_require__(/*! ./read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst read_preference_1 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst write_concern_1 = __webpack_require__(/*! ./write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\n/**\n * The **Collection** class is an internal class that embodies a MongoDB collection\n * allowing for insert/find/update/delete and other command operation on that MongoDB collection.\n *\n * **COLLECTION Cannot directly be instantiated**\n * @public\n *\n * @example\n * ```ts\n * import { MongoClient } from 'mongodb';\n *\n * interface Pet {\n *   name: string;\n *   kind: 'dog' | 'cat' | 'fish';\n * }\n *\n * const client = new MongoClient('mongodb://localhost:27017');\n * const pets = client.db().collection<Pet>('pets');\n *\n * const petCursor = pets.find();\n *\n * for await (const pet of petCursor) {\n *   console.log(`${pet.name} is a ${pet.kind}!`);\n * }\n * ```\n */\nclass Collection {\n    /**\n     * Create a new Collection instance\n     * @internal\n     */\n    constructor(db, name, options) {\n        // Internal state\n        this.s = {\n            db,\n            options,\n            namespace: new utils_1.MongoDBCollectionNamespace(db.databaseName, name),\n            pkFactory: db.options?.pkFactory ?? utils_1.DEFAULT_PK_FACTORY,\n            readPreference: read_preference_1.ReadPreference.fromOptions(options),\n            bsonOptions: (0, bson_1.resolveBSONOptions)(options, db),\n            readConcern: read_concern_1.ReadConcern.fromOptions(options),\n            writeConcern: write_concern_1.WriteConcern.fromOptions(options)\n        };\n        this.client = db.client;\n    }\n    /**\n     * The name of the database this collection belongs to\n     */\n    get dbName() {\n        return this.s.namespace.db;\n    }\n    /**\n     * The name of this collection\n     */\n    get collectionName() {\n        return this.s.namespace.collection;\n    }\n    /**\n     * The namespace of this collection, in the format `${this.dbName}.${this.collectionName}`\n     */\n    get namespace() {\n        return this.fullNamespace.toString();\n    }\n    /**\n     *  @internal\n     *\n     * The `MongoDBNamespace` for the collection.\n     */\n    get fullNamespace() {\n        return this.s.namespace;\n    }\n    /**\n     * The current readConcern of the collection. If not explicitly defined for\n     * this collection, will be inherited from the parent DB\n     */\n    get readConcern() {\n        if (this.s.readConcern == null) {\n            return this.s.db.readConcern;\n        }\n        return this.s.readConcern;\n    }\n    /**\n     * The current readPreference of the collection. If not explicitly defined for\n     * this collection, will be inherited from the parent DB\n     */\n    get readPreference() {\n        if (this.s.readPreference == null) {\n            return this.s.db.readPreference;\n        }\n        return this.s.readPreference;\n    }\n    get bsonOptions() {\n        return this.s.bsonOptions;\n    }\n    /**\n     * The current writeConcern of the collection. If not explicitly defined for\n     * this collection, will be inherited from the parent DB\n     */\n    get writeConcern() {\n        if (this.s.writeConcern == null) {\n            return this.s.db.writeConcern;\n        }\n        return this.s.writeConcern;\n    }\n    /** The current index hint for the collection */\n    get hint() {\n        return this.s.collectionHint;\n    }\n    set hint(v) {\n        this.s.collectionHint = (0, utils_1.normalizeHintField)(v);\n    }\n    /**\n     * Inserts a single document into MongoDB. If documents passed in do not contain the **_id** field,\n     * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n     * can be overridden by setting the **forceServerObjectId** flag.\n     *\n     * @param doc - The document to insert\n     * @param options - Optional settings for the command\n     */\n    async insertOne(doc, options) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new insert_1.InsertOneOperation(this, doc, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Inserts an array of documents into MongoDB. If documents passed in do not contain the **_id** field,\n     * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n     * can be overridden by setting the **forceServerObjectId** flag.\n     *\n     * @param docs - The documents to insert\n     * @param options - Optional settings for the command\n     */\n    async insertMany(docs, options) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new insert_1.InsertManyOperation(this, docs, (0, utils_1.resolveOptions)(this, options ?? { ordered: true })));\n    }\n    /**\n     * Perform a bulkWrite operation without a fluent API\n     *\n     * Legal operation types are\n     * - `insertOne`\n     * - `replaceOne`\n     * - `updateOne`\n     * - `updateMany`\n     * - `deleteOne`\n     * - `deleteMany`\n     *\n     * If documents passed in do not contain the **_id** field,\n     * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n     * can be overridden by setting the **forceServerObjectId** flag.\n     *\n     * @param operations - Bulk operations to perform\n     * @param options - Optional settings for the command\n     * @throws MongoDriverError if operations is not an array\n     */\n    async bulkWrite(operations, options) {\n        if (!Array.isArray(operations)) {\n            throw new error_1.MongoInvalidArgumentError('Argument \"operations\" must be an array of documents');\n        }\n        return await (0, execute_operation_1.executeOperation)(this.client, new bulk_write_1.BulkWriteOperation(this, operations, (0, utils_1.resolveOptions)(this, options ?? { ordered: true })));\n    }\n    /**\n     * Update a single document in a collection\n     *\n     * The value of `update` can be either:\n     * - UpdateFilter<TSchema> - A document that contains update operator expressions,\n     * - Document[] - an aggregation pipeline.\n     *\n     * @param filter - The filter used to select the document to update\n     * @param update - The modifications to apply\n     * @param options - Optional settings for the command\n     */\n    async updateOne(filter, update, options) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new update_2.UpdateOneOperation(this, filter, update, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Replace a document in a collection with another document\n     *\n     * @param filter - The filter used to select the document to replace\n     * @param replacement - The Document that replaces the matching document\n     * @param options - Optional settings for the command\n     */\n    async replaceOne(filter, replacement, options) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new update_2.ReplaceOneOperation(this, filter, replacement, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Update multiple documents in a collection\n     *\n     * The value of `update` can be either:\n     * - UpdateFilter<TSchema> - A document that contains update operator expressions,\n     * - Document[] - an aggregation pipeline.\n     *\n     * @param filter - The filter used to select the document to update\n     * @param update - The modifications to apply\n     * @param options - Optional settings for the command\n     */\n    async updateMany(filter, update, options) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new update_2.UpdateManyOperation(this, filter, update, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Delete a document from a collection\n     *\n     * @param filter - The filter used to select the document to remove\n     * @param options - Optional settings for the command\n     */\n    async deleteOne(filter = {}, options = {}) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new delete_1.DeleteOneOperation(this, filter, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Delete multiple documents from a collection\n     *\n     * @param filter - The filter used to select the documents to remove\n     * @param options - Optional settings for the command\n     */\n    async deleteMany(filter = {}, options = {}) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new delete_1.DeleteManyOperation(this, filter, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Rename the collection.\n     *\n     * @remarks\n     * This operation does not inherit options from the Db or MongoClient.\n     *\n     * @param newName - New name of of the collection.\n     * @param options - Optional settings for the command\n     */\n    async rename(newName, options) {\n        // Intentionally, we do not inherit options from parent for this operation.\n        return await (0, execute_operation_1.executeOperation)(this.client, new rename_1.RenameOperation(this, newName, {\n            ...options,\n            readPreference: read_preference_1.ReadPreference.PRIMARY\n        }));\n    }\n    /**\n     * Drop the collection from the database, removing it permanently. New accesses will create a new collection.\n     *\n     * @param options - Optional settings for the command\n     */\n    async drop(options) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new drop_1.DropCollectionOperation(this.s.db, this.collectionName, options));\n    }\n    async findOne(filter = {}, options = {}) {\n        const cursor = this.find(filter, options).limit(-1).batchSize(1);\n        const res = await cursor.next();\n        await cursor.close();\n        return res;\n    }\n    find(filter = {}, options = {}) {\n        return new find_cursor_1.FindCursor(this.client, this.s.namespace, filter, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * Returns the options of the collection.\n     *\n     * @param options - Optional settings for the command\n     */\n    async options(options) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new options_operation_1.OptionsOperation(this, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Returns if the collection is a capped collection\n     *\n     * @param options - Optional settings for the command\n     */\n    async isCapped(options) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new is_capped_1.IsCappedOperation(this, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Creates an index on the db and collection collection.\n     *\n     * @param indexSpec - The field name or index specification to create an index for\n     * @param options - Optional settings for the command\n     *\n     * @example\n     * ```ts\n     * const collection = client.db('foo').collection('bar');\n     *\n     * await collection.createIndex({ a: 1, b: -1 });\n     *\n     * // Alternate syntax for { c: 1, d: -1 } that ensures order of indexes\n     * await collection.createIndex([ [c, 1], [d, -1] ]);\n     *\n     * // Equivalent to { e: 1 }\n     * await collection.createIndex('e');\n     *\n     * // Equivalent to { f: 1, g: 1 }\n     * await collection.createIndex(['f', 'g'])\n     *\n     * // Equivalent to { h: 1, i: -1 }\n     * await collection.createIndex([ { h: 1 }, { i: -1 } ]);\n     *\n     * // Equivalent to { j: 1, k: -1, l: 2d }\n     * await collection.createIndex(['j', ['k', -1], { l: '2d' }])\n     * ```\n     */\n    async createIndex(indexSpec, options) {\n        const indexes = await (0, execute_operation_1.executeOperation)(this.client, indexes_1.CreateIndexesOperation.fromIndexSpecification(this, this.collectionName, indexSpec, (0, utils_1.resolveOptions)(this, options)));\n        return indexes[0];\n    }\n    /**\n     * Creates multiple indexes in the collection, this method is only supported for\n     * MongoDB 2.6 or higher. Earlier version of MongoDB will throw a command not supported\n     * error.\n     *\n     * **Note**: Unlike {@link Collection#createIndex| createIndex}, this function takes in raw index specifications.\n     * Index specifications are defined {@link https://www.mongodb.com/docs/manual/reference/command/createIndexes/| here}.\n     *\n     * @param indexSpecs - An array of index specifications to be created\n     * @param options - Optional settings for the command\n     *\n     * @example\n     * ```ts\n     * const collection = client.db('foo').collection('bar');\n     * await collection.createIndexes([\n     *   // Simple index on field fizz\n     *   {\n     *     key: { fizz: 1 },\n     *   }\n     *   // wildcard index\n     *   {\n     *     key: { '$**': 1 }\n     *   },\n     *   // named index on darmok and jalad\n     *   {\n     *     key: { darmok: 1, jalad: -1 }\n     *     name: 'tanagra'\n     *   }\n     * ]);\n     * ```\n     */\n    async createIndexes(indexSpecs, options) {\n        return await (0, execute_operation_1.executeOperation)(this.client, indexes_1.CreateIndexesOperation.fromIndexDescriptionArray(this, this.collectionName, indexSpecs, (0, utils_1.resolveOptions)(this, { ...options, maxTimeMS: undefined })));\n    }\n    /**\n     * Drops an index from this collection.\n     *\n     * @param indexName - Name of the index to drop.\n     * @param options - Optional settings for the command\n     */\n    async dropIndex(indexName, options) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new indexes_1.DropIndexOperation(this, indexName, {\n            ...(0, utils_1.resolveOptions)(this, options),\n            readPreference: read_preference_1.ReadPreference.primary\n        }));\n    }\n    /**\n     * Drops all indexes from this collection.\n     *\n     * @param options - Optional settings for the command\n     */\n    async dropIndexes(options) {\n        try {\n            await (0, execute_operation_1.executeOperation)(this.client, new indexes_1.DropIndexOperation(this, '*', (0, utils_1.resolveOptions)(this, options)));\n            return true;\n        }\n        catch {\n            return false;\n        }\n    }\n    /**\n     * Get the list of all indexes information for the collection.\n     *\n     * @param options - Optional settings for the command\n     */\n    listIndexes(options) {\n        return new list_indexes_cursor_1.ListIndexesCursor(this, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * Checks if one or more indexes exist on the collection, fails on first non-existing index\n     *\n     * @param indexes - One or more index names to check.\n     * @param options - Optional settings for the command\n     */\n    async indexExists(indexes, options) {\n        const indexNames = Array.isArray(indexes) ? indexes : [indexes];\n        const allIndexes = new Set(await this.listIndexes(options)\n            .map(({ name }) => name)\n            .toArray());\n        return indexNames.every(name => allIndexes.has(name));\n    }\n    async indexInformation(options) {\n        return await this.indexes({\n            ...options,\n            full: options?.full ?? false\n        });\n    }\n    /**\n     * Gets an estimate of the count of documents in a collection using collection metadata.\n     * This will always run a count command on all server versions.\n     *\n     * due to an oversight in versions 5.0.0-5.0.8 of MongoDB, the count command,\n     * which estimatedDocumentCount uses in its implementation, was not included in v1 of\n     * the Stable API, and so users of the Stable API with estimatedDocumentCount are\n     * recommended to upgrade their server version to 5.0.9+ or set apiStrict: false to avoid\n     * encountering errors.\n     *\n     * @see {@link https://www.mongodb.com/docs/manual/reference/command/count/#behavior|Count: Behavior}\n     * @param options - Optional settings for the command\n     */\n    async estimatedDocumentCount(options) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new estimated_document_count_1.EstimatedDocumentCountOperation(this, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Gets the number of documents matching the filter.\n     * For a fast count of the total documents in a collection see {@link Collection#estimatedDocumentCount| estimatedDocumentCount}.\n     * **Note**: When migrating from {@link Collection#count| count} to {@link Collection#countDocuments| countDocuments}\n     * the following query operators must be replaced:\n     *\n     * | Operator | Replacement |\n     * | -------- | ----------- |\n     * | `$where`   | [`$expr`][1] |\n     * | `$near`    | [`$geoWithin`][2] with [`$center`][3] |\n     * | `$nearSphere` | [`$geoWithin`][2] with [`$centerSphere`][4] |\n     *\n     * [1]: https://www.mongodb.com/docs/manual/reference/operator/query/expr/\n     * [2]: https://www.mongodb.com/docs/manual/reference/operator/query/geoWithin/\n     * [3]: https://www.mongodb.com/docs/manual/reference/operator/query/center/#op._S_center\n     * [4]: https://www.mongodb.com/docs/manual/reference/operator/query/centerSphere/#op._S_centerSphere\n     *\n     * @param filter - The filter for the count\n     * @param options - Optional settings for the command\n     *\n     * @see https://www.mongodb.com/docs/manual/reference/operator/query/expr/\n     * @see https://www.mongodb.com/docs/manual/reference/operator/query/geoWithin/\n     * @see https://www.mongodb.com/docs/manual/reference/operator/query/center/#op._S_center\n     * @see https://www.mongodb.com/docs/manual/reference/operator/query/centerSphere/#op._S_centerSphere\n     */\n    async countDocuments(filter = {}, options = {}) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new count_documents_1.CountDocumentsOperation(this, filter, (0, utils_1.resolveOptions)(this, options)));\n    }\n    async distinct(key, filter = {}, options = {}) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new distinct_1.DistinctOperation(this, key, filter, (0, utils_1.resolveOptions)(this, options)));\n    }\n    async indexes(options) {\n        const indexes = await this.listIndexes(options).toArray();\n        const full = options?.full ?? true;\n        if (full) {\n            return indexes;\n        }\n        const object = Object.fromEntries(indexes.map(({ name, key }) => [name, Object.entries(key)]));\n        return object;\n    }\n    async findOneAndDelete(filter, options) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new find_and_modify_1.FindOneAndDeleteOperation(this, filter, (0, utils_1.resolveOptions)(this, options)));\n    }\n    async findOneAndReplace(filter, replacement, options) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new find_and_modify_1.FindOneAndReplaceOperation(this, filter, replacement, (0, utils_1.resolveOptions)(this, options)));\n    }\n    async findOneAndUpdate(filter, update, options) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new find_and_modify_1.FindOneAndUpdateOperation(this, filter, update, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Execute an aggregation framework pipeline against the collection, needs MongoDB \\>= 2.2\n     *\n     * @param pipeline - An array of aggregation pipelines to execute\n     * @param options - Optional settings for the command\n     */\n    aggregate(pipeline = [], options) {\n        if (!Array.isArray(pipeline)) {\n            throw new error_1.MongoInvalidArgumentError('Argument \"pipeline\" must be an array of aggregation stages');\n        }\n        return new aggregation_cursor_1.AggregationCursor(this.client, this.s.namespace, pipeline, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * Create a new Change Stream, watching for new changes (insertions, updates, replacements, deletions, and invalidations) in this collection.\n     *\n     * @remarks\n     * watch() accepts two generic arguments for distinct use cases:\n     * - The first is to override the schema that may be defined for this specific collection\n     * - The second is to override the shape of the change stream document entirely, if it is not provided the type will default to ChangeStreamDocument of the first argument\n     * @example\n     * By just providing the first argument I can type the change to be `ChangeStreamDocument<{ _id: number }>`\n     * ```ts\n     * collection.watch<{ _id: number }>()\n     *   .on('change', change => console.log(change._id.toFixed(4)));\n     * ```\n     *\n     * @example\n     * Passing a second argument provides a way to reflect the type changes caused by an advanced pipeline.\n     * Here, we are using a pipeline to have MongoDB filter for insert changes only and add a comment.\n     * No need start from scratch on the ChangeStreamInsertDocument type!\n     * By using an intersection we can save time and ensure defaults remain the same type!\n     * ```ts\n     * collection\n     *   .watch<Schema, ChangeStreamInsertDocument<Schema> & { comment: string }>([\n     *     { $addFields: { comment: 'big changes' } },\n     *     { $match: { operationType: 'insert' } }\n     *   ])\n     *   .on('change', change => {\n     *     change.comment.startsWith('big');\n     *     change.operationType === 'insert';\n     *     // No need to narrow in code because the generics did that for us!\n     *     expectType<Schema>(change.fullDocument);\n     *   });\n     * ```\n     *\n     * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents. This allows for filtering (using $match) and manipulating the change stream documents.\n     * @param options - Optional settings for the command\n     * @typeParam TLocal - Type of the data being detected by the change stream\n     * @typeParam TChange - Type of the whole change stream document emitted\n     */\n    watch(pipeline = [], options = {}) {\n        // Allow optionally not specifying a pipeline\n        if (!Array.isArray(pipeline)) {\n            options = pipeline;\n            pipeline = [];\n        }\n        return new change_stream_1.ChangeStream(this, pipeline, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * Initiate an Out of order batch write operation. All operations will be buffered into insert/update/remove commands executed out of order.\n     *\n     * @throws MongoNotConnectedError\n     * @remarks\n     * **NOTE:** MongoClient must be connected prior to calling this method due to a known limitation in this legacy implementation.\n     * However, `collection.bulkWrite()` provides an equivalent API that does not require prior connecting.\n     */\n    initializeUnorderedBulkOp(options) {\n        return new unordered_1.UnorderedBulkOperation(this, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * Initiate an In order bulk write operation. Operations will be serially executed in the order they are added, creating a new operation for each switch in types.\n     *\n     * @throws MongoNotConnectedError\n     * @remarks\n     * **NOTE:** MongoClient must be connected prior to calling this method due to a known limitation in this legacy implementation.\n     * However, `collection.bulkWrite()` provides an equivalent API that does not require prior connecting.\n     */\n    initializeOrderedBulkOp(options) {\n        return new ordered_1.OrderedBulkOperation(this, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * An estimated count of matching documents in the db to a filter.\n     *\n     * **NOTE:** This method has been deprecated, since it does not provide an accurate count of the documents\n     * in a collection. To obtain an accurate count of documents in the collection, use {@link Collection#countDocuments| countDocuments}.\n     * To obtain an estimated count of all documents in the collection, use {@link Collection#estimatedDocumentCount| estimatedDocumentCount}.\n     *\n     * @deprecated use {@link Collection#countDocuments| countDocuments} or {@link Collection#estimatedDocumentCount| estimatedDocumentCount} instead\n     *\n     * @param filter - The filter for the count.\n     * @param options - Optional settings for the command\n     */\n    async count(filter = {}, options = {}) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new count_1.CountOperation(this.fullNamespace, filter, (0, utils_1.resolveOptions)(this, options)));\n    }\n    listSearchIndexes(indexNameOrOptions, options) {\n        options =\n            typeof indexNameOrOptions === 'object' ? indexNameOrOptions : options == null ? {} : options;\n        const indexName = indexNameOrOptions == null\n            ? null\n            : typeof indexNameOrOptions === 'object'\n                ? null\n                : indexNameOrOptions;\n        return new list_search_indexes_cursor_1.ListSearchIndexesCursor(this, indexName, options);\n    }\n    /**\n     * Creates a single search index for the collection.\n     *\n     * @param description - The index description for the new search index.\n     * @returns A promise that resolves to the name of the new search index.\n     *\n     * @remarks Only available when used against a 7.0+ Atlas cluster.\n     */\n    async createSearchIndex(description) {\n        const [index] = await this.createSearchIndexes([description]);\n        return index;\n    }\n    /**\n     * Creates multiple search indexes for the current collection.\n     *\n     * @param descriptions - An array of `SearchIndexDescription`s for the new search indexes.\n     * @returns A promise that resolves to an array of the newly created search index names.\n     *\n     * @remarks Only available when used against a 7.0+ Atlas cluster.\n     * @returns\n     */\n    async createSearchIndexes(descriptions) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new create_1.CreateSearchIndexesOperation(this, descriptions));\n    }\n    /**\n     * Deletes a search index by index name.\n     *\n     * @param name - The name of the search index to be deleted.\n     *\n     * @remarks Only available when used against a 7.0+ Atlas cluster.\n     */\n    async dropSearchIndex(name) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new drop_2.DropSearchIndexOperation(this, name));\n    }\n    /**\n     * Updates a search index by replacing the existing index definition with the provided definition.\n     *\n     * @param name - The name of the search index to update.\n     * @param definition - The new search index definition.\n     *\n     * @remarks Only available when used against a 7.0+ Atlas cluster.\n     */\n    async updateSearchIndex(name, definition) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new update_1.UpdateSearchIndexOperation(this, name, definition));\n    }\n}\nexports.Collection = Collection;\n//# sourceMappingURL=collection.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/collection.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/connection_string.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongodb/lib/connection_string.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.FEATURE_FLAGS = exports.DEFAULT_OPTIONS = exports.OPTIONS = exports.parseOptions = exports.resolveSRVRecord = void 0;\nconst dns = __webpack_require__(/*! dns */ \"dns\");\nconst mongodb_connection_string_url_1 = __webpack_require__(/*! mongodb-connection-string-url */ \"./node_modules/mongodb-connection-string-url/lib/index.js\");\nconst url_1 = __webpack_require__(/*! url */ \"url\");\nconst mongo_credentials_1 = __webpack_require__(/*! ./cmap/auth/mongo_credentials */ \"./node_modules/mongodb/lib/cmap/auth/mongo_credentials.js\");\nconst providers_1 = __webpack_require__(/*! ./cmap/auth/providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\nconst client_metadata_1 = __webpack_require__(/*! ./cmap/handshake/client_metadata */ \"./node_modules/mongodb/lib/cmap/handshake/client_metadata.js\");\nconst compression_1 = __webpack_require__(/*! ./cmap/wire_protocol/compression */ \"./node_modules/mongodb/lib/cmap/wire_protocol/compression.js\");\nconst encrypter_1 = __webpack_require__(/*! ./encrypter */ \"./node_modules/mongodb/lib/encrypter.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_client_1 = __webpack_require__(/*! ./mongo_client */ \"./node_modules/mongodb/lib/mongo_client.js\");\nconst mongo_logger_1 = __webpack_require__(/*! ./mongo_logger */ \"./node_modules/mongodb/lib/mongo_logger.js\");\nconst read_concern_1 = __webpack_require__(/*! ./read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst read_preference_1 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst monitor_1 = __webpack_require__(/*! ./sdam/monitor */ \"./node_modules/mongodb/lib/sdam/monitor.js\");\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst write_concern_1 = __webpack_require__(/*! ./write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\nconst VALID_TXT_RECORDS = ['authSource', 'replicaSet', 'loadBalanced'];\nconst LB_SINGLE_HOST_ERROR = 'loadBalanced option only supported with a single host in the URI';\nconst LB_REPLICA_SET_ERROR = 'loadBalanced option not supported with a replicaSet option';\nconst LB_DIRECT_CONNECTION_ERROR = 'loadBalanced option not supported when directConnection is provided';\n/**\n * Lookup a `mongodb+srv` connection string, combine the parts and reparse it as a normal\n * connection string.\n *\n * @param uri - The connection string to parse\n * @param options - Optional user provided connection string options\n */\nasync function resolveSRVRecord(options) {\n    if (typeof options.srvHost !== 'string') {\n        throw new error_1.MongoAPIError('Option \"srvHost\" must not be empty');\n    }\n    if (options.srvHost.split('.').length < 3) {\n        // TODO(NODE-3484): Replace with MongoConnectionStringError\n        throw new error_1.MongoAPIError('URI must include hostname, domain name, and tld');\n    }\n    // Asynchronously start TXT resolution so that we do not have to wait until\n    // the SRV record is resolved before starting a second DNS query.\n    const lookupAddress = options.srvHost;\n    const txtResolutionPromise = dns.promises.resolveTxt(lookupAddress);\n    // eslint-disable-next-line github/no-then\n    txtResolutionPromise.then(undefined, utils_1.squashError); // rejections will be handled later\n    // Resolve the SRV record and use the result as the list of hosts to connect to.\n    const addresses = await dns.promises.resolveSrv(`_${options.srvServiceName}._tcp.${lookupAddress}`);\n    if (addresses.length === 0) {\n        throw new error_1.MongoAPIError('No addresses found at host');\n    }\n    for (const { name } of addresses) {\n        if (!(0, utils_1.matchesParentDomain)(name, lookupAddress)) {\n            throw new error_1.MongoAPIError('Server record does not share hostname with parent URI');\n        }\n    }\n    const hostAddresses = addresses.map(r => utils_1.HostAddress.fromString(`${r.name}:${r.port ?? 27017}`));\n    validateLoadBalancedOptions(hostAddresses, options, true);\n    // Use the result of resolving the TXT record and add options from there if they exist.\n    let record;\n    try {\n        record = await txtResolutionPromise;\n    }\n    catch (error) {\n        if (error.code !== 'ENODATA' && error.code !== 'ENOTFOUND') {\n            throw error;\n        }\n        return hostAddresses;\n    }\n    if (record.length > 1) {\n        throw new error_1.MongoParseError('Multiple text records not allowed');\n    }\n    const txtRecordOptions = new url_1.URLSearchParams(record[0].join(''));\n    const txtRecordOptionKeys = [...txtRecordOptions.keys()];\n    if (txtRecordOptionKeys.some(key => !VALID_TXT_RECORDS.includes(key))) {\n        throw new error_1.MongoParseError(`Text record may only set any of: ${VALID_TXT_RECORDS.join(', ')}`);\n    }\n    if (VALID_TXT_RECORDS.some(option => txtRecordOptions.get(option) === '')) {\n        throw new error_1.MongoParseError('Cannot have empty URI params in DNS TXT Record');\n    }\n    const source = txtRecordOptions.get('authSource') ?? undefined;\n    const replicaSet = txtRecordOptions.get('replicaSet') ?? undefined;\n    const loadBalanced = txtRecordOptions.get('loadBalanced') ?? undefined;\n    if (!options.userSpecifiedAuthSource &&\n        source &&\n        options.credentials &&\n        !providers_1.AUTH_MECHS_AUTH_SRC_EXTERNAL.has(options.credentials.mechanism)) {\n        options.credentials = mongo_credentials_1.MongoCredentials.merge(options.credentials, { source });\n    }\n    if (!options.userSpecifiedReplicaSet && replicaSet) {\n        options.replicaSet = replicaSet;\n    }\n    if (loadBalanced === 'true') {\n        options.loadBalanced = true;\n    }\n    if (options.replicaSet && options.srvMaxHosts > 0) {\n        throw new error_1.MongoParseError('Cannot combine replicaSet option with srvMaxHosts');\n    }\n    validateLoadBalancedOptions(hostAddresses, options, true);\n    return hostAddresses;\n}\nexports.resolveSRVRecord = resolveSRVRecord;\n/**\n * Checks if TLS options are valid\n *\n * @param allOptions - All options provided by user or included in default options map\n * @throws MongoAPIError if TLS options are invalid\n */\nfunction checkTLSOptions(allOptions) {\n    if (!allOptions)\n        return;\n    const check = (a, b) => {\n        if (allOptions.has(a) && allOptions.has(b)) {\n            throw new error_1.MongoAPIError(`The '${a}' option cannot be used with the '${b}' option`);\n        }\n    };\n    check('tlsInsecure', 'tlsAllowInvalidCertificates');\n    check('tlsInsecure', 'tlsAllowInvalidHostnames');\n    check('tlsInsecure', 'tlsDisableCertificateRevocationCheck');\n    check('tlsInsecure', 'tlsDisableOCSPEndpointCheck');\n    check('tlsAllowInvalidCertificates', 'tlsDisableCertificateRevocationCheck');\n    check('tlsAllowInvalidCertificates', 'tlsDisableOCSPEndpointCheck');\n    check('tlsDisableCertificateRevocationCheck', 'tlsDisableOCSPEndpointCheck');\n}\nfunction getBoolean(name, value) {\n    if (typeof value === 'boolean')\n        return value;\n    switch (value) {\n        case 'true':\n            return true;\n        case 'false':\n            return false;\n        default:\n            throw new error_1.MongoParseError(`${name} must be either \"true\" or \"false\"`);\n    }\n}\nfunction getIntFromOptions(name, value) {\n    const parsedInt = (0, utils_1.parseInteger)(value);\n    if (parsedInt != null) {\n        return parsedInt;\n    }\n    throw new error_1.MongoParseError(`Expected ${name} to be stringified int value, got: ${value}`);\n}\nfunction getUIntFromOptions(name, value) {\n    const parsedValue = getIntFromOptions(name, value);\n    if (parsedValue < 0) {\n        throw new error_1.MongoParseError(`${name} can only be a positive int value, got: ${value}`);\n    }\n    return parsedValue;\n}\nfunction* entriesFromString(value) {\n    if (value === '') {\n        return;\n    }\n    const keyValuePairs = value.split(',');\n    for (const keyValue of keyValuePairs) {\n        const [key, value] = keyValue.split(/:(.*)/);\n        if (value == null) {\n            throw new error_1.MongoParseError('Cannot have undefined values in key value pairs');\n        }\n        yield [key, value];\n    }\n}\nclass CaseInsensitiveMap extends Map {\n    constructor(entries = []) {\n        super(entries.map(([k, v]) => [k.toLowerCase(), v]));\n    }\n    has(k) {\n        return super.has(k.toLowerCase());\n    }\n    get(k) {\n        return super.get(k.toLowerCase());\n    }\n    set(k, v) {\n        return super.set(k.toLowerCase(), v);\n    }\n    delete(k) {\n        return super.delete(k.toLowerCase());\n    }\n}\nfunction parseOptions(uri, mongoClient = undefined, options = {}) {\n    if (mongoClient != null && !(mongoClient instanceof mongo_client_1.MongoClient)) {\n        options = mongoClient;\n        mongoClient = undefined;\n    }\n    // validate BSONOptions\n    if (options.useBigInt64 && typeof options.promoteLongs === 'boolean' && !options.promoteLongs) {\n        throw new error_1.MongoAPIError('Must request either bigint or Long for int64 deserialization');\n    }\n    if (options.useBigInt64 && typeof options.promoteValues === 'boolean' && !options.promoteValues) {\n        throw new error_1.MongoAPIError('Must request either bigint or Long for int64 deserialization');\n    }\n    const url = new mongodb_connection_string_url_1.default(uri);\n    const { hosts, isSRV } = url;\n    const mongoOptions = Object.create(null);\n    // Feature flags\n    for (const flag of Object.getOwnPropertySymbols(options)) {\n        if (exports.FEATURE_FLAGS.has(flag)) {\n            mongoOptions[flag] = options[flag];\n        }\n    }\n    mongoOptions.hosts = isSRV ? [] : hosts.map(utils_1.HostAddress.fromString);\n    const urlOptions = new CaseInsensitiveMap();\n    if (url.pathname !== '/' && url.pathname !== '') {\n        const dbName = decodeURIComponent(url.pathname[0] === '/' ? url.pathname.slice(1) : url.pathname);\n        if (dbName) {\n            urlOptions.set('dbName', [dbName]);\n        }\n    }\n    if (url.username !== '') {\n        const auth = {\n            username: decodeURIComponent(url.username)\n        };\n        if (typeof url.password === 'string') {\n            auth.password = decodeURIComponent(url.password);\n        }\n        urlOptions.set('auth', [auth]);\n    }\n    for (const key of url.searchParams.keys()) {\n        const values = url.searchParams.getAll(key);\n        const isReadPreferenceTags = /readPreferenceTags/i.test(key);\n        if (!isReadPreferenceTags && values.length > 1) {\n            throw new error_1.MongoInvalidArgumentError(`URI option \"${key}\" cannot appear more than once in the connection string`);\n        }\n        if (!isReadPreferenceTags && values.includes('')) {\n            throw new error_1.MongoAPIError(`URI option \"${key}\" cannot be specified with no value`);\n        }\n        if (!urlOptions.has(key)) {\n            urlOptions.set(key, values);\n        }\n    }\n    const objectOptions = new CaseInsensitiveMap(Object.entries(options).filter(([, v]) => v != null));\n    // Validate options that can only be provided by one of uri or object\n    if (urlOptions.has('serverApi')) {\n        throw new error_1.MongoParseError('URI cannot contain `serverApi`, it can only be passed to the client');\n    }\n    const uriMechanismProperties = urlOptions.get('authMechanismProperties');\n    if (uriMechanismProperties) {\n        for (const property of uriMechanismProperties) {\n            if (/(^|,)ALLOWED_HOSTS:/.test(property)) {\n                throw new error_1.MongoParseError('Auth mechanism property ALLOWED_HOSTS is not allowed in the connection string.');\n            }\n        }\n    }\n    if (objectOptions.has('loadBalanced')) {\n        throw new error_1.MongoParseError('loadBalanced is only a valid option in the URI');\n    }\n    // All option collection\n    const allProvidedOptions = new CaseInsensitiveMap();\n    const allProvidedKeys = new Set([...urlOptions.keys(), ...objectOptions.keys()]);\n    for (const key of allProvidedKeys) {\n        const values = [];\n        const objectOptionValue = objectOptions.get(key);\n        if (objectOptionValue != null) {\n            values.push(objectOptionValue);\n        }\n        const urlValues = urlOptions.get(key) ?? [];\n        values.push(...urlValues);\n        allProvidedOptions.set(key, values);\n    }\n    if (allProvidedOptions.has('tls') || allProvidedOptions.has('ssl')) {\n        const tlsAndSslOpts = (allProvidedOptions.get('tls') || [])\n            .concat(allProvidedOptions.get('ssl') || [])\n            .map(getBoolean.bind(null, 'tls/ssl'));\n        if (new Set(tlsAndSslOpts).size !== 1) {\n            throw new error_1.MongoParseError('All values of tls/ssl must be the same.');\n        }\n    }\n    checkTLSOptions(allProvidedOptions);\n    const unsupportedOptions = (0, utils_1.setDifference)(allProvidedKeys, Array.from(Object.keys(exports.OPTIONS)).map(s => s.toLowerCase()));\n    if (unsupportedOptions.size !== 0) {\n        const optionWord = unsupportedOptions.size > 1 ? 'options' : 'option';\n        const isOrAre = unsupportedOptions.size > 1 ? 'are' : 'is';\n        throw new error_1.MongoParseError(`${optionWord} ${Array.from(unsupportedOptions).join(', ')} ${isOrAre} not supported`);\n    }\n    // Option parsing and setting\n    for (const [key, descriptor] of Object.entries(exports.OPTIONS)) {\n        const values = allProvidedOptions.get(key);\n        if (!values || values.length === 0) {\n            if (exports.DEFAULT_OPTIONS.has(key)) {\n                setOption(mongoOptions, key, descriptor, [exports.DEFAULT_OPTIONS.get(key)]);\n            }\n        }\n        else {\n            const { deprecated } = descriptor;\n            if (deprecated) {\n                const deprecatedMsg = typeof deprecated === 'string' ? `: ${deprecated}` : '';\n                (0, utils_1.emitWarning)(`${key} is a deprecated option${deprecatedMsg}`);\n            }\n            setOption(mongoOptions, key, descriptor, values);\n        }\n    }\n    if (mongoOptions.credentials) {\n        const isGssapi = mongoOptions.credentials.mechanism === providers_1.AuthMechanism.MONGODB_GSSAPI;\n        const isX509 = mongoOptions.credentials.mechanism === providers_1.AuthMechanism.MONGODB_X509;\n        const isAws = mongoOptions.credentials.mechanism === providers_1.AuthMechanism.MONGODB_AWS;\n        const isOidc = mongoOptions.credentials.mechanism === providers_1.AuthMechanism.MONGODB_OIDC;\n        if ((isGssapi || isX509) &&\n            allProvidedOptions.has('authSource') &&\n            mongoOptions.credentials.source !== '$external') {\n            // If authSource was explicitly given and its incorrect, we error\n            throw new error_1.MongoParseError(`authMechanism ${mongoOptions.credentials.mechanism} requires an authSource of '$external'`);\n        }\n        if (!(isGssapi || isX509 || isAws || isOidc) &&\n            mongoOptions.dbName &&\n            !allProvidedOptions.has('authSource')) {\n            // inherit the dbName unless GSSAPI or X509, then silently ignore dbName\n            // and there was no specific authSource given\n            mongoOptions.credentials = mongo_credentials_1.MongoCredentials.merge(mongoOptions.credentials, {\n                source: mongoOptions.dbName\n            });\n        }\n        if (isAws && mongoOptions.credentials.username && !mongoOptions.credentials.password) {\n            throw new error_1.MongoMissingCredentialsError(`When using ${mongoOptions.credentials.mechanism} password must be set when a username is specified`);\n        }\n        mongoOptions.credentials.validate();\n        // Check if the only auth related option provided was authSource, if so we can remove credentials\n        if (mongoOptions.credentials.password === '' &&\n            mongoOptions.credentials.username === '' &&\n            mongoOptions.credentials.mechanism === providers_1.AuthMechanism.MONGODB_DEFAULT &&\n            Object.keys(mongoOptions.credentials.mechanismProperties).length === 0) {\n            delete mongoOptions.credentials;\n        }\n    }\n    if (!mongoOptions.dbName) {\n        // dbName default is applied here because of the credential validation above\n        mongoOptions.dbName = 'test';\n    }\n    validateLoadBalancedOptions(hosts, mongoOptions, isSRV);\n    if (mongoClient && mongoOptions.autoEncryption) {\n        encrypter_1.Encrypter.checkForMongoCrypt();\n        mongoOptions.encrypter = new encrypter_1.Encrypter(mongoClient, uri, options);\n        mongoOptions.autoEncrypter = mongoOptions.encrypter.autoEncrypter;\n    }\n    // Potential SRV Overrides and SRV connection string validations\n    mongoOptions.userSpecifiedAuthSource =\n        objectOptions.has('authSource') || urlOptions.has('authSource');\n    mongoOptions.userSpecifiedReplicaSet =\n        objectOptions.has('replicaSet') || urlOptions.has('replicaSet');\n    if (isSRV) {\n        // SRV Record is resolved upon connecting\n        mongoOptions.srvHost = hosts[0];\n        if (mongoOptions.directConnection) {\n            throw new error_1.MongoAPIError('SRV URI does not support directConnection');\n        }\n        if (mongoOptions.srvMaxHosts > 0 && typeof mongoOptions.replicaSet === 'string') {\n            throw new error_1.MongoParseError('Cannot use srvMaxHosts option with replicaSet');\n        }\n        // SRV turns on TLS by default, but users can override and turn it off\n        const noUserSpecifiedTLS = !objectOptions.has('tls') && !urlOptions.has('tls');\n        const noUserSpecifiedSSL = !objectOptions.has('ssl') && !urlOptions.has('ssl');\n        if (noUserSpecifiedTLS && noUserSpecifiedSSL) {\n            mongoOptions.tls = true;\n        }\n    }\n    else {\n        const userSpecifiedSrvOptions = urlOptions.has('srvMaxHosts') ||\n            objectOptions.has('srvMaxHosts') ||\n            urlOptions.has('srvServiceName') ||\n            objectOptions.has('srvServiceName');\n        if (userSpecifiedSrvOptions) {\n            throw new error_1.MongoParseError('Cannot use srvMaxHosts or srvServiceName with a non-srv connection string');\n        }\n    }\n    if (mongoOptions.directConnection && mongoOptions.hosts.length !== 1) {\n        throw new error_1.MongoParseError('directConnection option requires exactly one host');\n    }\n    if (!mongoOptions.proxyHost &&\n        (mongoOptions.proxyPort || mongoOptions.proxyUsername || mongoOptions.proxyPassword)) {\n        throw new error_1.MongoParseError('Must specify proxyHost if other proxy options are passed');\n    }\n    if ((mongoOptions.proxyUsername && !mongoOptions.proxyPassword) ||\n        (!mongoOptions.proxyUsername && mongoOptions.proxyPassword)) {\n        throw new error_1.MongoParseError('Can only specify both of proxy username/password or neither');\n    }\n    const proxyOptions = ['proxyHost', 'proxyPort', 'proxyUsername', 'proxyPassword'].map(key => urlOptions.get(key) ?? []);\n    if (proxyOptions.some(options => options.length > 1)) {\n        throw new error_1.MongoParseError('Proxy options cannot be specified multiple times in the connection string');\n    }\n    const loggerFeatureFlag = Symbol.for('@@mdb.enableMongoLogger');\n    mongoOptions[loggerFeatureFlag] = mongoOptions[loggerFeatureFlag] ?? false;\n    let loggerEnvOptions = {};\n    let loggerClientOptions = {};\n    if (mongoOptions[loggerFeatureFlag]) {\n        loggerEnvOptions = {\n            MONGODB_LOG_COMMAND: process.env.MONGODB_LOG_COMMAND,\n            MONGODB_LOG_TOPOLOGY: process.env.MONGODB_LOG_TOPOLOGY,\n            MONGODB_LOG_SERVER_SELECTION: process.env.MONGODB_LOG_SERVER_SELECTION,\n            MONGODB_LOG_CONNECTION: process.env.MONGODB_LOG_CONNECTION,\n            MONGODB_LOG_CLIENT: process.env.MONGODB_LOG_CLIENT,\n            MONGODB_LOG_ALL: process.env.MONGODB_LOG_ALL,\n            MONGODB_LOG_MAX_DOCUMENT_LENGTH: process.env.MONGODB_LOG_MAX_DOCUMENT_LENGTH,\n            MONGODB_LOG_PATH: process.env.MONGODB_LOG_PATH,\n            ...mongoOptions[Symbol.for('@@mdb.internalLoggerConfig')]\n        };\n        loggerClientOptions = {\n            mongodbLogPath: mongoOptions.mongodbLogPath,\n            mongodbLogComponentSeverities: mongoOptions.mongodbLogComponentSeverities,\n            mongodbLogMaxDocumentLength: mongoOptions.mongodbLogMaxDocumentLength\n        };\n    }\n    mongoOptions.mongoLoggerOptions = mongo_logger_1.MongoLogger.resolveOptions(loggerEnvOptions, loggerClientOptions);\n    mongoOptions.metadata = (0, client_metadata_1.makeClientMetadata)(mongoOptions);\n    // eslint-disable-next-line github/no-then\n    mongoOptions.extendedMetadata = (0, client_metadata_1.addContainerMetadata)(mongoOptions.metadata).then(undefined, utils_1.squashError); // rejections will be handled later\n    return mongoOptions;\n}\nexports.parseOptions = parseOptions;\n/**\n * #### Throws if LB mode is true:\n * - hosts contains more than one host\n * - there is a replicaSet name set\n * - directConnection is set\n * - if srvMaxHosts is used when an srv connection string is passed in\n *\n * @throws MongoParseError\n */\nfunction validateLoadBalancedOptions(hosts, mongoOptions, isSrv) {\n    if (mongoOptions.loadBalanced) {\n        if (hosts.length > 1) {\n            throw new error_1.MongoParseError(LB_SINGLE_HOST_ERROR);\n        }\n        if (mongoOptions.replicaSet) {\n            throw new error_1.MongoParseError(LB_REPLICA_SET_ERROR);\n        }\n        if (mongoOptions.directConnection) {\n            throw new error_1.MongoParseError(LB_DIRECT_CONNECTION_ERROR);\n        }\n        if (isSrv && mongoOptions.srvMaxHosts > 0) {\n            throw new error_1.MongoParseError('Cannot limit srv hosts with loadBalanced enabled');\n        }\n    }\n    return;\n}\nfunction setOption(mongoOptions, key, descriptor, values) {\n    const { target, type, transform } = descriptor;\n    const name = target ?? key;\n    switch (type) {\n        case 'boolean':\n            mongoOptions[name] = getBoolean(name, values[0]);\n            break;\n        case 'int':\n            mongoOptions[name] = getIntFromOptions(name, values[0]);\n            break;\n        case 'uint':\n            mongoOptions[name] = getUIntFromOptions(name, values[0]);\n            break;\n        case 'string':\n            if (values[0] == null) {\n                break;\n            }\n            mongoOptions[name] = String(values[0]);\n            break;\n        case 'record':\n            if (!(0, utils_1.isRecord)(values[0])) {\n                throw new error_1.MongoParseError(`${name} must be an object`);\n            }\n            mongoOptions[name] = values[0];\n            break;\n        case 'any':\n            mongoOptions[name] = values[0];\n            break;\n        default: {\n            if (!transform) {\n                throw new error_1.MongoParseError('Descriptors missing a type must define a transform');\n            }\n            const transformValue = transform({ name, options: mongoOptions, values });\n            mongoOptions[name] = transformValue;\n            break;\n        }\n    }\n}\nexports.OPTIONS = {\n    appName: {\n        type: 'string'\n    },\n    auth: {\n        target: 'credentials',\n        transform({ name, options, values: [value] }) {\n            if (!(0, utils_1.isRecord)(value, ['username', 'password'])) {\n                throw new error_1.MongoParseError(`${name} must be an object with 'username' and 'password' properties`);\n            }\n            return mongo_credentials_1.MongoCredentials.merge(options.credentials, {\n                username: value.username,\n                password: value.password\n            });\n        }\n    },\n    authMechanism: {\n        target: 'credentials',\n        transform({ options, values: [value] }) {\n            const mechanisms = Object.values(providers_1.AuthMechanism);\n            const [mechanism] = mechanisms.filter(m => m.match(RegExp(String.raw `\\b${value}\\b`, 'i')));\n            if (!mechanism) {\n                throw new error_1.MongoParseError(`authMechanism one of ${mechanisms}, got ${value}`);\n            }\n            let source = options.credentials?.source;\n            if (mechanism === providers_1.AuthMechanism.MONGODB_PLAIN ||\n                providers_1.AUTH_MECHS_AUTH_SRC_EXTERNAL.has(mechanism)) {\n                // some mechanisms have '$external' as the Auth Source\n                source = '$external';\n            }\n            let password = options.credentials?.password;\n            if (mechanism === providers_1.AuthMechanism.MONGODB_X509 && password === '') {\n                password = undefined;\n            }\n            return mongo_credentials_1.MongoCredentials.merge(options.credentials, {\n                mechanism,\n                source,\n                password\n            });\n        }\n    },\n    // Note that if the authMechanismProperties contain a TOKEN_RESOURCE that has a\n    // comma in it, it MUST be supplied as a MongoClient option instead of in the\n    // connection string.\n    authMechanismProperties: {\n        target: 'credentials',\n        transform({ options, values }) {\n            // We can have a combination of options passed in the URI and options passed\n            // as an object to the MongoClient. So we must transform the string options\n            // as well as merge them together with a potentially provided object.\n            let mechanismProperties = Object.create(null);\n            for (const optionValue of values) {\n                if (typeof optionValue === 'string') {\n                    for (const [key, value] of entriesFromString(optionValue)) {\n                        try {\n                            mechanismProperties[key] = getBoolean(key, value);\n                        }\n                        catch {\n                            mechanismProperties[key] = value;\n                        }\n                    }\n                }\n                else {\n                    if (!(0, utils_1.isRecord)(optionValue)) {\n                        throw new error_1.MongoParseError('AuthMechanismProperties must be an object');\n                    }\n                    mechanismProperties = { ...optionValue };\n                }\n            }\n            return mongo_credentials_1.MongoCredentials.merge(options.credentials, {\n                mechanismProperties\n            });\n        }\n    },\n    authSource: {\n        target: 'credentials',\n        transform({ options, values: [value] }) {\n            const source = String(value);\n            return mongo_credentials_1.MongoCredentials.merge(options.credentials, { source });\n        }\n    },\n    autoEncryption: {\n        type: 'record'\n    },\n    bsonRegExp: {\n        type: 'boolean'\n    },\n    serverApi: {\n        target: 'serverApi',\n        transform({ values: [version] }) {\n            const serverApiToValidate = typeof version === 'string' ? { version } : version;\n            const versionToValidate = serverApiToValidate && serverApiToValidate.version;\n            if (!versionToValidate) {\n                throw new error_1.MongoParseError(`Invalid \\`serverApi\\` property; must specify a version from the following enum: [\"${Object.values(mongo_client_1.ServerApiVersion).join('\", \"')}\"]`);\n            }\n            if (!Object.values(mongo_client_1.ServerApiVersion).some(v => v === versionToValidate)) {\n                throw new error_1.MongoParseError(`Invalid server API version=${versionToValidate}; must be in the following enum: [\"${Object.values(mongo_client_1.ServerApiVersion).join('\", \"')}\"]`);\n            }\n            return serverApiToValidate;\n        }\n    },\n    checkKeys: {\n        type: 'boolean'\n    },\n    compressors: {\n        default: 'none',\n        target: 'compressors',\n        transform({ values }) {\n            const compressionList = new Set();\n            for (const compVal of values) {\n                const compValArray = typeof compVal === 'string' ? compVal.split(',') : compVal;\n                if (!Array.isArray(compValArray)) {\n                    throw new error_1.MongoInvalidArgumentError('compressors must be an array or a comma-delimited list of strings');\n                }\n                for (const c of compValArray) {\n                    if (Object.keys(compression_1.Compressor).includes(String(c))) {\n                        compressionList.add(String(c));\n                    }\n                    else {\n                        throw new error_1.MongoInvalidArgumentError(`${c} is not a valid compression mechanism. Must be one of: ${Object.keys(compression_1.Compressor)}.`);\n                    }\n                }\n            }\n            return [...compressionList];\n        }\n    },\n    connectTimeoutMS: {\n        default: 30000,\n        type: 'uint'\n    },\n    dbName: {\n        type: 'string'\n    },\n    directConnection: {\n        default: false,\n        type: 'boolean'\n    },\n    driverInfo: {\n        default: {},\n        type: 'record'\n    },\n    enableUtf8Validation: { type: 'boolean', default: true },\n    family: {\n        transform({ name, values: [value] }) {\n            const transformValue = getIntFromOptions(name, value);\n            if (transformValue === 4 || transformValue === 6) {\n                return transformValue;\n            }\n            throw new error_1.MongoParseError(`Option 'family' must be 4 or 6 got ${transformValue}.`);\n        }\n    },\n    fieldsAsRaw: {\n        type: 'record'\n    },\n    forceServerObjectId: {\n        default: false,\n        type: 'boolean'\n    },\n    fsync: {\n        deprecated: 'Please use journal instead',\n        target: 'writeConcern',\n        transform({ name, options, values: [value] }) {\n            const wc = write_concern_1.WriteConcern.fromOptions({\n                writeConcern: {\n                    ...options.writeConcern,\n                    fsync: getBoolean(name, value)\n                }\n            });\n            if (!wc)\n                throw new error_1.MongoParseError(`Unable to make a writeConcern from fsync=${value}`);\n            return wc;\n        }\n    },\n    heartbeatFrequencyMS: {\n        default: 10000,\n        type: 'uint'\n    },\n    ignoreUndefined: {\n        type: 'boolean'\n    },\n    j: {\n        deprecated: 'Please use journal instead',\n        target: 'writeConcern',\n        transform({ name, options, values: [value] }) {\n            const wc = write_concern_1.WriteConcern.fromOptions({\n                writeConcern: {\n                    ...options.writeConcern,\n                    journal: getBoolean(name, value)\n                }\n            });\n            if (!wc)\n                throw new error_1.MongoParseError(`Unable to make a writeConcern from journal=${value}`);\n            return wc;\n        }\n    },\n    journal: {\n        target: 'writeConcern',\n        transform({ name, options, values: [value] }) {\n            const wc = write_concern_1.WriteConcern.fromOptions({\n                writeConcern: {\n                    ...options.writeConcern,\n                    journal: getBoolean(name, value)\n                }\n            });\n            if (!wc)\n                throw new error_1.MongoParseError(`Unable to make a writeConcern from journal=${value}`);\n            return wc;\n        }\n    },\n    loadBalanced: {\n        default: false,\n        type: 'boolean'\n    },\n    localThresholdMS: {\n        default: 15,\n        type: 'uint'\n    },\n    maxConnecting: {\n        default: 2,\n        transform({ name, values: [value] }) {\n            const maxConnecting = getUIntFromOptions(name, value);\n            if (maxConnecting === 0) {\n                throw new error_1.MongoInvalidArgumentError('maxConnecting must be > 0 if specified');\n            }\n            return maxConnecting;\n        }\n    },\n    maxIdleTimeMS: {\n        default: 0,\n        type: 'uint'\n    },\n    maxPoolSize: {\n        default: 100,\n        type: 'uint'\n    },\n    maxStalenessSeconds: {\n        target: 'readPreference',\n        transform({ name, options, values: [value] }) {\n            const maxStalenessSeconds = getUIntFromOptions(name, value);\n            if (options.readPreference) {\n                return read_preference_1.ReadPreference.fromOptions({\n                    readPreference: { ...options.readPreference, maxStalenessSeconds }\n                });\n            }\n            else {\n                return new read_preference_1.ReadPreference('secondary', undefined, { maxStalenessSeconds });\n            }\n        }\n    },\n    minInternalBufferSize: {\n        type: 'uint'\n    },\n    minPoolSize: {\n        default: 0,\n        type: 'uint'\n    },\n    minHeartbeatFrequencyMS: {\n        default: 500,\n        type: 'uint'\n    },\n    monitorCommands: {\n        default: false,\n        type: 'boolean'\n    },\n    name: {\n        target: 'driverInfo',\n        transform({ values: [value], options }) {\n            return { ...options.driverInfo, name: String(value) };\n        }\n    },\n    noDelay: {\n        default: true,\n        type: 'boolean'\n    },\n    pkFactory: {\n        default: utils_1.DEFAULT_PK_FACTORY,\n        transform({ values: [value] }) {\n            if ((0, utils_1.isRecord)(value, ['createPk']) && typeof value.createPk === 'function') {\n                return value;\n            }\n            throw new error_1.MongoParseError(`Option pkFactory must be an object with a createPk function, got ${value}`);\n        }\n    },\n    promoteBuffers: {\n        type: 'boolean'\n    },\n    promoteLongs: {\n        type: 'boolean'\n    },\n    promoteValues: {\n        type: 'boolean'\n    },\n    useBigInt64: {\n        type: 'boolean'\n    },\n    proxyHost: {\n        type: 'string'\n    },\n    proxyPassword: {\n        type: 'string'\n    },\n    proxyPort: {\n        type: 'uint'\n    },\n    proxyUsername: {\n        type: 'string'\n    },\n    raw: {\n        default: false,\n        type: 'boolean'\n    },\n    readConcern: {\n        transform({ values: [value], options }) {\n            if (value instanceof read_concern_1.ReadConcern || (0, utils_1.isRecord)(value, ['level'])) {\n                return read_concern_1.ReadConcern.fromOptions({ ...options.readConcern, ...value });\n            }\n            throw new error_1.MongoParseError(`ReadConcern must be an object, got ${JSON.stringify(value)}`);\n        }\n    },\n    readConcernLevel: {\n        target: 'readConcern',\n        transform({ values: [level], options }) {\n            return read_concern_1.ReadConcern.fromOptions({\n                ...options.readConcern,\n                level: level\n            });\n        }\n    },\n    readPreference: {\n        default: read_preference_1.ReadPreference.primary,\n        transform({ values: [value], options }) {\n            if (value instanceof read_preference_1.ReadPreference) {\n                return read_preference_1.ReadPreference.fromOptions({\n                    readPreference: { ...options.readPreference, ...value },\n                    ...value\n                });\n            }\n            if ((0, utils_1.isRecord)(value, ['mode'])) {\n                const rp = read_preference_1.ReadPreference.fromOptions({\n                    readPreference: { ...options.readPreference, ...value },\n                    ...value\n                });\n                if (rp)\n                    return rp;\n                else\n                    throw new error_1.MongoParseError(`Cannot make read preference from ${JSON.stringify(value)}`);\n            }\n            if (typeof value === 'string') {\n                const rpOpts = {\n                    hedge: options.readPreference?.hedge,\n                    maxStalenessSeconds: options.readPreference?.maxStalenessSeconds\n                };\n                return new read_preference_1.ReadPreference(value, options.readPreference?.tags, rpOpts);\n            }\n            throw new error_1.MongoParseError(`Unknown ReadPreference value: ${value}`);\n        }\n    },\n    readPreferenceTags: {\n        target: 'readPreference',\n        transform({ values, options }) {\n            const tags = Array.isArray(values[0])\n                ? values[0]\n                : values;\n            const readPreferenceTags = [];\n            for (const tag of tags) {\n                const readPreferenceTag = Object.create(null);\n                if (typeof tag === 'string') {\n                    for (const [k, v] of entriesFromString(tag)) {\n                        readPreferenceTag[k] = v;\n                    }\n                }\n                if ((0, utils_1.isRecord)(tag)) {\n                    for (const [k, v] of Object.entries(tag)) {\n                        readPreferenceTag[k] = v;\n                    }\n                }\n                readPreferenceTags.push(readPreferenceTag);\n            }\n            return read_preference_1.ReadPreference.fromOptions({\n                readPreference: options.readPreference,\n                readPreferenceTags\n            });\n        }\n    },\n    replicaSet: {\n        type: 'string'\n    },\n    retryReads: {\n        default: true,\n        type: 'boolean'\n    },\n    retryWrites: {\n        default: true,\n        type: 'boolean'\n    },\n    serializeFunctions: {\n        type: 'boolean'\n    },\n    serverMonitoringMode: {\n        default: 'auto',\n        transform({ values: [value] }) {\n            if (!Object.values(monitor_1.ServerMonitoringMode).includes(value)) {\n                throw new error_1.MongoParseError('serverMonitoringMode must be one of `auto`, `poll`, or `stream`');\n            }\n            return value;\n        }\n    },\n    serverSelectionTimeoutMS: {\n        default: 30000,\n        type: 'uint'\n    },\n    servername: {\n        type: 'string'\n    },\n    socketTimeoutMS: {\n        default: 0,\n        type: 'uint'\n    },\n    srvMaxHosts: {\n        type: 'uint',\n        default: 0\n    },\n    srvServiceName: {\n        type: 'string',\n        default: 'mongodb'\n    },\n    ssl: {\n        target: 'tls',\n        type: 'boolean'\n    },\n    timeoutMS: {\n        type: 'uint'\n    },\n    tls: {\n        type: 'boolean'\n    },\n    tlsAllowInvalidCertificates: {\n        target: 'rejectUnauthorized',\n        transform({ name, values: [value] }) {\n            // allowInvalidCertificates is the inverse of rejectUnauthorized\n            return !getBoolean(name, value);\n        }\n    },\n    tlsAllowInvalidHostnames: {\n        target: 'checkServerIdentity',\n        transform({ name, values: [value] }) {\n            // tlsAllowInvalidHostnames means setting the checkServerIdentity function to a noop\n            return getBoolean(name, value) ? () => undefined : undefined;\n        }\n    },\n    tlsCAFile: {\n        type: 'string'\n    },\n    tlsCRLFile: {\n        type: 'string'\n    },\n    tlsCertificateKeyFile: {\n        type: 'string'\n    },\n    tlsCertificateKeyFilePassword: {\n        target: 'passphrase',\n        type: 'any'\n    },\n    tlsInsecure: {\n        transform({ name, options, values: [value] }) {\n            const tlsInsecure = getBoolean(name, value);\n            if (tlsInsecure) {\n                options.checkServerIdentity = () => undefined;\n                options.rejectUnauthorized = false;\n            }\n            else {\n                options.checkServerIdentity = options.tlsAllowInvalidHostnames\n                    ? () => undefined\n                    : undefined;\n                options.rejectUnauthorized = options.tlsAllowInvalidCertificates ? false : true;\n            }\n            return tlsInsecure;\n        }\n    },\n    w: {\n        target: 'writeConcern',\n        transform({ values: [value], options }) {\n            return write_concern_1.WriteConcern.fromOptions({ writeConcern: { ...options.writeConcern, w: value } });\n        }\n    },\n    waitQueueTimeoutMS: {\n        default: 0,\n        type: 'uint'\n    },\n    writeConcern: {\n        target: 'writeConcern',\n        transform({ values: [value], options }) {\n            if ((0, utils_1.isRecord)(value) || value instanceof write_concern_1.WriteConcern) {\n                return write_concern_1.WriteConcern.fromOptions({\n                    writeConcern: {\n                        ...options.writeConcern,\n                        ...value\n                    }\n                });\n            }\n            else if (value === 'majority' || typeof value === 'number') {\n                return write_concern_1.WriteConcern.fromOptions({\n                    writeConcern: {\n                        ...options.writeConcern,\n                        w: value\n                    }\n                });\n            }\n            throw new error_1.MongoParseError(`Invalid WriteConcern cannot parse: ${JSON.stringify(value)}`);\n        }\n    },\n    wtimeout: {\n        deprecated: 'Please use wtimeoutMS instead',\n        target: 'writeConcern',\n        transform({ values: [value], options }) {\n            const wc = write_concern_1.WriteConcern.fromOptions({\n                writeConcern: {\n                    ...options.writeConcern,\n                    wtimeout: getUIntFromOptions('wtimeout', value)\n                }\n            });\n            if (wc)\n                return wc;\n            throw new error_1.MongoParseError(`Cannot make WriteConcern from wtimeout`);\n        }\n    },\n    wtimeoutMS: {\n        target: 'writeConcern',\n        transform({ values: [value], options }) {\n            const wc = write_concern_1.WriteConcern.fromOptions({\n                writeConcern: {\n                    ...options.writeConcern,\n                    wtimeoutMS: getUIntFromOptions('wtimeoutMS', value)\n                }\n            });\n            if (wc)\n                return wc;\n            throw new error_1.MongoParseError(`Cannot make WriteConcern from wtimeout`);\n        }\n    },\n    zlibCompressionLevel: {\n        default: 0,\n        type: 'int'\n    },\n    // Custom types for modifying core behavior\n    connectionType: { type: 'any' },\n    srvPoller: { type: 'any' },\n    // Accepted NodeJS Options\n    minDHSize: { type: 'any' },\n    pskCallback: { type: 'any' },\n    secureContext: { type: 'any' },\n    enableTrace: { type: 'any' },\n    requestCert: { type: 'any' },\n    rejectUnauthorized: { type: 'any' },\n    checkServerIdentity: { type: 'any' },\n    ALPNProtocols: { type: 'any' },\n    SNICallback: { type: 'any' },\n    session: { type: 'any' },\n    requestOCSP: { type: 'any' },\n    localAddress: { type: 'any' },\n    localPort: { type: 'any' },\n    hints: { type: 'any' },\n    lookup: { type: 'any' },\n    ca: { type: 'any' },\n    cert: { type: 'any' },\n    ciphers: { type: 'any' },\n    crl: { type: 'any' },\n    ecdhCurve: { type: 'any' },\n    key: { type: 'any' },\n    passphrase: { type: 'any' },\n    pfx: { type: 'any' },\n    secureProtocol: { type: 'any' },\n    index: { type: 'any' },\n    // Legacy options from v3 era\n    useNewUrlParser: {\n        type: 'boolean',\n        deprecated: 'useNewUrlParser has no effect since Node.js Driver version 4.0.0 and will be removed in the next major version'\n    },\n    useUnifiedTopology: {\n        type: 'boolean',\n        deprecated: 'useUnifiedTopology has no effect since Node.js Driver version 4.0.0 and will be removed in the next major version'\n    },\n    // MongoLogger\n    /**\n     * @internal\n     * TODO: NODE-5671 - remove internal flag\n     */\n    mongodbLogPath: {\n        transform({ values: [value] }) {\n            if (!((typeof value === 'string' && ['stderr', 'stdout'].includes(value)) ||\n                (value &&\n                    typeof value === 'object' &&\n                    'write' in value &&\n                    typeof value.write === 'function'))) {\n                throw new error_1.MongoAPIError(`Option 'mongodbLogPath' must be of type 'stderr' | 'stdout' | MongoDBLogWritable`);\n            }\n            return value;\n        }\n    },\n    /**\n     * @internal\n     * TODO: NODE-5671 - remove internal flag\n     */\n    mongodbLogComponentSeverities: {\n        transform({ values: [value] }) {\n            if (typeof value !== 'object' || !value) {\n                throw new error_1.MongoAPIError(`Option 'mongodbLogComponentSeverities' must be a non-null object`);\n            }\n            for (const [k, v] of Object.entries(value)) {\n                if (typeof v !== 'string' || typeof k !== 'string') {\n                    throw new error_1.MongoAPIError(`User input for option 'mongodbLogComponentSeverities' object cannot include a non-string key or value`);\n                }\n                if (!Object.values(mongo_logger_1.MongoLoggableComponent).some(val => val === k) && k !== 'default') {\n                    throw new error_1.MongoAPIError(`User input for option 'mongodbLogComponentSeverities' contains invalid key: ${k}`);\n                }\n                if (!Object.values(mongo_logger_1.SeverityLevel).some(val => val === v)) {\n                    throw new error_1.MongoAPIError(`Option 'mongodbLogComponentSeverities' does not support ${v} as a value for ${k}`);\n                }\n            }\n            return value;\n        }\n    },\n    /**\n     * @internal\n     * TODO: NODE-5671 - remove internal flag\n     */\n    mongodbLogMaxDocumentLength: { type: 'uint' }\n};\nexports.DEFAULT_OPTIONS = new CaseInsensitiveMap(Object.entries(exports.OPTIONS)\n    .filter(([, descriptor]) => descriptor.default != null)\n    .map(([k, d]) => [k, d.default]));\n/**\n * Set of permitted feature flags\n * @internal\n */\nexports.FEATURE_FLAGS = new Set([\n    Symbol.for('@@mdb.skipPingOnConnect'),\n    Symbol.for('@@mdb.enableMongoLogger'),\n    Symbol.for('@@mdb.internalLoggerConfig')\n]);\n//# sourceMappingURL=connection_string.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/connection_string.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/constants.js":
/*!***********************************************!*\
  !*** ./node_modules/mongodb/lib/constants.js ***!
  \***********************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.END = exports.CHANGE = exports.INIT = exports.MORE = exports.RESPONSE = exports.SERVER_HEARTBEAT_FAILED = exports.SERVER_HEARTBEAT_SUCCEEDED = exports.SERVER_HEARTBEAT_STARTED = exports.COMMAND_FAILED = exports.COMMAND_SUCCEEDED = exports.COMMAND_STARTED = exports.CLUSTER_TIME_RECEIVED = exports.CONNECTION_CHECKED_IN = exports.CONNECTION_CHECKED_OUT = exports.CONNECTION_CHECK_OUT_FAILED = exports.CONNECTION_CHECK_OUT_STARTED = exports.CONNECTION_CLOSED = exports.CONNECTION_READY = exports.CONNECTION_CREATED = exports.CONNECTION_POOL_READY = exports.CONNECTION_POOL_CLEARED = exports.CONNECTION_POOL_CLOSED = exports.CONNECTION_POOL_CREATED = exports.WAITING_FOR_SUITABLE_SERVER = exports.SERVER_SELECTION_SUCCEEDED = exports.SERVER_SELECTION_FAILED = exports.SERVER_SELECTION_STARTED = exports.TOPOLOGY_DESCRIPTION_CHANGED = exports.TOPOLOGY_CLOSED = exports.TOPOLOGY_OPENING = exports.SERVER_DESCRIPTION_CHANGED = exports.SERVER_CLOSED = exports.SERVER_OPENING = exports.DESCRIPTION_RECEIVED = exports.UNPINNED = exports.PINNED = exports.MESSAGE = exports.ENDED = exports.CLOSED = exports.CONNECT = exports.OPEN = exports.CLOSE = exports.TIMEOUT = exports.ERROR = exports.SYSTEM_JS_COLLECTION = exports.SYSTEM_COMMAND_COLLECTION = exports.SYSTEM_USER_COLLECTION = exports.SYSTEM_PROFILE_COLLECTION = exports.SYSTEM_INDEX_COLLECTION = exports.SYSTEM_NAMESPACE_COLLECTION = void 0;\nexports.LEGACY_HELLO_COMMAND_CAMEL_CASE = exports.LEGACY_HELLO_COMMAND = exports.MONGO_CLIENT_EVENTS = exports.LOCAL_SERVER_EVENTS = exports.SERVER_RELAY_EVENTS = exports.APM_EVENTS = exports.TOPOLOGY_EVENTS = exports.CMAP_EVENTS = exports.HEARTBEAT_EVENTS = exports.RESUME_TOKEN_CHANGED = void 0;\nexports.SYSTEM_NAMESPACE_COLLECTION = 'system.namespaces';\nexports.SYSTEM_INDEX_COLLECTION = 'system.indexes';\nexports.SYSTEM_PROFILE_COLLECTION = 'system.profile';\nexports.SYSTEM_USER_COLLECTION = 'system.users';\nexports.SYSTEM_COMMAND_COLLECTION = '$cmd';\nexports.SYSTEM_JS_COLLECTION = 'system.js';\n// events\nexports.ERROR = 'error';\nexports.TIMEOUT = 'timeout';\nexports.CLOSE = 'close';\nexports.OPEN = 'open';\nexports.CONNECT = 'connect';\nexports.CLOSED = 'closed';\nexports.ENDED = 'ended';\nexports.MESSAGE = 'message';\nexports.PINNED = 'pinned';\nexports.UNPINNED = 'unpinned';\nexports.DESCRIPTION_RECEIVED = 'descriptionReceived';\n/** @internal */\nexports.SERVER_OPENING = 'serverOpening';\n/** @internal */\nexports.SERVER_CLOSED = 'serverClosed';\n/** @internal */\nexports.SERVER_DESCRIPTION_CHANGED = 'serverDescriptionChanged';\n/** @internal */\nexports.TOPOLOGY_OPENING = 'topologyOpening';\n/** @internal */\nexports.TOPOLOGY_CLOSED = 'topologyClosed';\n/** @internal */\nexports.TOPOLOGY_DESCRIPTION_CHANGED = 'topologyDescriptionChanged';\n/** @internal */\nexports.SERVER_SELECTION_STARTED = 'serverSelectionStarted';\n/** @internal */\nexports.SERVER_SELECTION_FAILED = 'serverSelectionFailed';\n/** @internal */\nexports.SERVER_SELECTION_SUCCEEDED = 'serverSelectionSucceeded';\n/** @internal */\nexports.WAITING_FOR_SUITABLE_SERVER = 'waitingForSuitableServer';\n/** @internal */\nexports.CONNECTION_POOL_CREATED = 'connectionPoolCreated';\n/** @internal */\nexports.CONNECTION_POOL_CLOSED = 'connectionPoolClosed';\n/** @internal */\nexports.CONNECTION_POOL_CLEARED = 'connectionPoolCleared';\n/** @internal */\nexports.CONNECTION_POOL_READY = 'connectionPoolReady';\n/** @internal */\nexports.CONNECTION_CREATED = 'connectionCreated';\n/** @internal */\nexports.CONNECTION_READY = 'connectionReady';\n/** @internal */\nexports.CONNECTION_CLOSED = 'connectionClosed';\n/** @internal */\nexports.CONNECTION_CHECK_OUT_STARTED = 'connectionCheckOutStarted';\n/** @internal */\nexports.CONNECTION_CHECK_OUT_FAILED = 'connectionCheckOutFailed';\n/** @internal */\nexports.CONNECTION_CHECKED_OUT = 'connectionCheckedOut';\n/** @internal */\nexports.CONNECTION_CHECKED_IN = 'connectionCheckedIn';\nexports.CLUSTER_TIME_RECEIVED = 'clusterTimeReceived';\n/** @internal */\nexports.COMMAND_STARTED = 'commandStarted';\n/** @internal */\nexports.COMMAND_SUCCEEDED = 'commandSucceeded';\n/** @internal */\nexports.COMMAND_FAILED = 'commandFailed';\n/** @internal */\nexports.SERVER_HEARTBEAT_STARTED = 'serverHeartbeatStarted';\n/** @internal */\nexports.SERVER_HEARTBEAT_SUCCEEDED = 'serverHeartbeatSucceeded';\n/** @internal */\nexports.SERVER_HEARTBEAT_FAILED = 'serverHeartbeatFailed';\nexports.RESPONSE = 'response';\nexports.MORE = 'more';\nexports.INIT = 'init';\nexports.CHANGE = 'change';\nexports.END = 'end';\nexports.RESUME_TOKEN_CHANGED = 'resumeTokenChanged';\n/** @public */\nexports.HEARTBEAT_EVENTS = Object.freeze([\n    exports.SERVER_HEARTBEAT_STARTED,\n    exports.SERVER_HEARTBEAT_SUCCEEDED,\n    exports.SERVER_HEARTBEAT_FAILED\n]);\n/** @public */\nexports.CMAP_EVENTS = Object.freeze([\n    exports.CONNECTION_POOL_CREATED,\n    exports.CONNECTION_POOL_READY,\n    exports.CONNECTION_POOL_CLEARED,\n    exports.CONNECTION_POOL_CLOSED,\n    exports.CONNECTION_CREATED,\n    exports.CONNECTION_READY,\n    exports.CONNECTION_CLOSED,\n    exports.CONNECTION_CHECK_OUT_STARTED,\n    exports.CONNECTION_CHECK_OUT_FAILED,\n    exports.CONNECTION_CHECKED_OUT,\n    exports.CONNECTION_CHECKED_IN\n]);\n/** @public */\nexports.TOPOLOGY_EVENTS = Object.freeze([\n    exports.SERVER_OPENING,\n    exports.SERVER_CLOSED,\n    exports.SERVER_DESCRIPTION_CHANGED,\n    exports.TOPOLOGY_OPENING,\n    exports.TOPOLOGY_CLOSED,\n    exports.TOPOLOGY_DESCRIPTION_CHANGED,\n    exports.ERROR,\n    exports.TIMEOUT,\n    exports.CLOSE\n]);\n/** @public */\nexports.APM_EVENTS = Object.freeze([\n    exports.COMMAND_STARTED,\n    exports.COMMAND_SUCCEEDED,\n    exports.COMMAND_FAILED\n]);\n/**\n * All events that we relay to the `Topology`\n * @internal\n */\nexports.SERVER_RELAY_EVENTS = Object.freeze([\n    exports.SERVER_HEARTBEAT_STARTED,\n    exports.SERVER_HEARTBEAT_SUCCEEDED,\n    exports.SERVER_HEARTBEAT_FAILED,\n    exports.COMMAND_STARTED,\n    exports.COMMAND_SUCCEEDED,\n    exports.COMMAND_FAILED,\n    ...exports.CMAP_EVENTS\n]);\n/**\n * All events we listen to from `Server` instances, but do not forward to the client\n * @internal\n */\nexports.LOCAL_SERVER_EVENTS = Object.freeze([\n    exports.CONNECT,\n    exports.DESCRIPTION_RECEIVED,\n    exports.CLOSED,\n    exports.ENDED\n]);\n/** @public */\nexports.MONGO_CLIENT_EVENTS = Object.freeze([\n    ...exports.CMAP_EVENTS,\n    ...exports.APM_EVENTS,\n    ...exports.TOPOLOGY_EVENTS,\n    ...exports.HEARTBEAT_EVENTS\n]);\n/**\n * @internal\n * The legacy hello command that was deprecated in MongoDB 5.0.\n */\nexports.LEGACY_HELLO_COMMAND = 'ismaster';\n/**\n * @internal\n * The legacy hello command that was deprecated in MongoDB 5.0.\n */\nexports.LEGACY_HELLO_COMMAND_CAMEL_CASE = 'isMaster';\n//# sourceMappingURL=constants.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/constants.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cursor/abstract_cursor.js":
/*!************************************************************!*\
  !*** ./node_modules/mongodb/lib/cursor/abstract_cursor.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.assertUninitialized = exports.AbstractCursor = exports.CURSOR_FLAGS = void 0;\nconst stream_1 = __webpack_require__(/*! stream */ \"stream\");\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst responses_1 = __webpack_require__(/*! ../cmap/wire_protocol/responses */ \"./node_modules/mongodb/lib/cmap/wire_protocol/responses.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_types_1 = __webpack_require__(/*! ../mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst execute_operation_1 = __webpack_require__(/*! ../operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst get_more_1 = __webpack_require__(/*! ../operations/get_more */ \"./node_modules/mongodb/lib/operations/get_more.js\");\nconst kill_cursors_1 = __webpack_require__(/*! ../operations/kill_cursors */ \"./node_modules/mongodb/lib/operations/kill_cursors.js\");\nconst read_concern_1 = __webpack_require__(/*! ../read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst read_preference_1 = __webpack_require__(/*! ../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst sessions_1 = __webpack_require__(/*! ../sessions */ \"./node_modules/mongodb/lib/sessions.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\n/** @internal */\nconst kId = Symbol('id');\n/** @internal */\nconst kDocuments = Symbol('documents');\n/** @internal */\nconst kServer = Symbol('server');\n/** @internal */\nconst kNamespace = Symbol('namespace');\n/** @internal */\nconst kClient = Symbol('client');\n/** @internal */\nconst kSession = Symbol('session');\n/** @internal */\nconst kOptions = Symbol('options');\n/** @internal */\nconst kTransform = Symbol('transform');\n/** @internal */\nconst kInitialized = Symbol('initialized');\n/** @internal */\nconst kClosed = Symbol('closed');\n/** @internal */\nconst kKilled = Symbol('killed');\n/** @internal */\nconst kInit = Symbol('kInit');\n/** @public */\nexports.CURSOR_FLAGS = [\n    'tailable',\n    'oplogReplay',\n    'noCursorTimeout',\n    'awaitData',\n    'exhaust',\n    'partial'\n];\n/** @public */\nclass AbstractCursor extends mongo_types_1.TypedEventEmitter {\n    /** @internal */\n    constructor(client, namespace, options = {}) {\n        super();\n        if (!client.s.isMongoClient) {\n            throw new error_1.MongoRuntimeError('Cursor must be constructed with MongoClient');\n        }\n        this[kClient] = client;\n        this[kNamespace] = namespace;\n        this[kId] = null;\n        this[kDocuments] = new utils_1.List();\n        this[kInitialized] = false;\n        this[kClosed] = false;\n        this[kKilled] = false;\n        this[kOptions] = {\n            readPreference: options.readPreference && options.readPreference instanceof read_preference_1.ReadPreference\n                ? options.readPreference\n                : read_preference_1.ReadPreference.primary,\n            ...(0, bson_1.pluckBSONSerializeOptions)(options)\n        };\n        this[kOptions].timeoutMS = options.timeoutMS;\n        const readConcern = read_concern_1.ReadConcern.fromOptions(options);\n        if (readConcern) {\n            this[kOptions].readConcern = readConcern;\n        }\n        if (typeof options.batchSize === 'number') {\n            this[kOptions].batchSize = options.batchSize;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (options.comment !== undefined) {\n            this[kOptions].comment = options.comment;\n        }\n        if (typeof options.maxTimeMS === 'number') {\n            this[kOptions].maxTimeMS = options.maxTimeMS;\n        }\n        if (typeof options.maxAwaitTimeMS === 'number') {\n            this[kOptions].maxAwaitTimeMS = options.maxAwaitTimeMS;\n        }\n        if (options.session instanceof sessions_1.ClientSession) {\n            this[kSession] = options.session;\n        }\n        else {\n            this[kSession] = this[kClient].startSession({ owner: this, explicit: false });\n        }\n    }\n    get id() {\n        return this[kId] ?? undefined;\n    }\n    /** @internal */\n    get isDead() {\n        return (this[kId]?.isZero() ?? false) || this[kClosed] || this[kKilled];\n    }\n    /** @internal */\n    get client() {\n        return this[kClient];\n    }\n    /** @internal */\n    get server() {\n        return this[kServer];\n    }\n    get namespace() {\n        return this[kNamespace];\n    }\n    get readPreference() {\n        return this[kOptions].readPreference;\n    }\n    get readConcern() {\n        return this[kOptions].readConcern;\n    }\n    /** @internal */\n    get session() {\n        return this[kSession];\n    }\n    set session(clientSession) {\n        this[kSession] = clientSession;\n    }\n    /** @internal */\n    get cursorOptions() {\n        return this[kOptions];\n    }\n    get closed() {\n        return this[kClosed];\n    }\n    get killed() {\n        return this[kKilled];\n    }\n    get loadBalanced() {\n        return !!this[kClient].topology?.loadBalanced;\n    }\n    /** Returns current buffered documents length */\n    bufferedCount() {\n        return this[kDocuments].length;\n    }\n    /** Returns current buffered documents */\n    readBufferedDocuments(number) {\n        const bufferedDocs = [];\n        const documentsToRead = Math.min(number ?? this[kDocuments].length, this[kDocuments].length);\n        for (let count = 0; count < documentsToRead; count++) {\n            const document = this[kDocuments].shift(this[kOptions]);\n            if (document != null) {\n                bufferedDocs.push(document);\n            }\n        }\n        return bufferedDocs;\n    }\n    async *[Symbol.asyncIterator]() {\n        if (this.closed) {\n            return;\n        }\n        try {\n            while (true) {\n                const document = await this.next();\n                // Intentional strict null check, because users can map cursors to falsey values.\n                // We allow mapping to all values except for null.\n                // eslint-disable-next-line no-restricted-syntax\n                if (document === null) {\n                    if (!this.closed) {\n                        const message = 'Cursor returned a `null` document, but the cursor is not exhausted.  Mapping documents to `null` is not supported in the cursor transform.';\n                        try {\n                            await cleanupCursor(this, { needsToEmitClosed: true });\n                        }\n                        catch (error) {\n                            (0, utils_1.squashError)(error);\n                        }\n                        throw new error_1.MongoAPIError(message);\n                    }\n                    break;\n                }\n                yield document;\n                if (this[kId] === bson_1.Long.ZERO) {\n                    // Cursor exhausted\n                    break;\n                }\n            }\n        }\n        finally {\n            // Only close the cursor if it has not already been closed. This finally clause handles\n            // the case when a user would break out of a for await of loop early.\n            if (!this.closed) {\n                try {\n                    await this.close();\n                }\n                catch (error) {\n                    (0, utils_1.squashError)(error);\n                }\n            }\n        }\n    }\n    stream(options) {\n        if (options?.transform) {\n            const transform = options.transform;\n            const readable = new ReadableCursorStream(this);\n            const transformedStream = readable.pipe(new stream_1.Transform({\n                objectMode: true,\n                highWaterMark: 1,\n                transform(chunk, _, callback) {\n                    try {\n                        const transformed = transform(chunk);\n                        callback(undefined, transformed);\n                    }\n                    catch (err) {\n                        callback(err);\n                    }\n                }\n            }));\n            // Bubble errors to transformed stream, because otherwise no way\n            // to handle this error.\n            readable.on('error', err => transformedStream.emit('error', err));\n            return transformedStream;\n        }\n        return new ReadableCursorStream(this);\n    }\n    async hasNext() {\n        if (this[kId] === bson_1.Long.ZERO) {\n            return false;\n        }\n        if (this[kDocuments].length !== 0) {\n            return true;\n        }\n        return await next(this, { blocking: true, transform: false, shift: false });\n    }\n    /** Get the next available document from the cursor, returns null if no more documents are available. */\n    async next() {\n        if (this[kId] === bson_1.Long.ZERO) {\n            throw new error_1.MongoCursorExhaustedError();\n        }\n        return await next(this, { blocking: true, transform: true, shift: true });\n    }\n    /**\n     * Try to get the next available document from the cursor or `null` if an empty batch is returned\n     */\n    async tryNext() {\n        if (this[kId] === bson_1.Long.ZERO) {\n            throw new error_1.MongoCursorExhaustedError();\n        }\n        return await next(this, { blocking: false, transform: true, shift: true });\n    }\n    /**\n     * Iterates over all the documents for this cursor using the iterator, callback pattern.\n     *\n     * If the iterator returns `false`, iteration will stop.\n     *\n     * @param iterator - The iteration callback.\n     * @deprecated - Will be removed in a future release. Use for await...of instead.\n     */\n    async forEach(iterator) {\n        if (typeof iterator !== 'function') {\n            throw new error_1.MongoInvalidArgumentError('Argument \"iterator\" must be a function');\n        }\n        for await (const document of this) {\n            const result = iterator(document);\n            if (result === false) {\n                break;\n            }\n        }\n    }\n    async close() {\n        const needsToEmitClosed = !this[kClosed];\n        this[kClosed] = true;\n        await cleanupCursor(this, { needsToEmitClosed });\n    }\n    /**\n     * Returns an array of documents. The caller is responsible for making sure that there\n     * is enough memory to store the results. Note that the array only contains partial\n     * results when this cursor had been previously accessed. In that case,\n     * cursor.rewind() can be used to reset the cursor.\n     */\n    async toArray() {\n        const array = [];\n        for await (const document of this) {\n            array.push(document);\n        }\n        return array;\n    }\n    /**\n     * Add a cursor flag to the cursor\n     *\n     * @param flag - The flag to set, must be one of following ['tailable', 'oplogReplay', 'noCursorTimeout', 'awaitData', 'partial' -.\n     * @param value - The flag boolean value.\n     */\n    addCursorFlag(flag, value) {\n        assertUninitialized(this);\n        if (!exports.CURSOR_FLAGS.includes(flag)) {\n            throw new error_1.MongoInvalidArgumentError(`Flag ${flag} is not one of ${exports.CURSOR_FLAGS}`);\n        }\n        if (typeof value !== 'boolean') {\n            throw new error_1.MongoInvalidArgumentError(`Flag ${flag} must be a boolean value`);\n        }\n        this[kOptions][flag] = value;\n        return this;\n    }\n    /**\n     * Map all documents using the provided function\n     * If there is a transform set on the cursor, that will be called first and the result passed to\n     * this function's transform.\n     *\n     * @remarks\n     *\n     * **Note** Cursors use `null` internally to indicate that there are no more documents in the cursor. Providing a mapping\n     * function that maps values to `null` will result in the cursor closing itself before it has finished iterating\n     * all documents.  This will **not** result in a memory leak, just surprising behavior.  For example:\n     *\n     * ```typescript\n     * const cursor = collection.find({});\n     * cursor.map(() => null);\n     *\n     * const documents = await cursor.toArray();\n     * // documents is always [], regardless of how many documents are in the collection.\n     * ```\n     *\n     * Other falsey values are allowed:\n     *\n     * ```typescript\n     * const cursor = collection.find({});\n     * cursor.map(() => '');\n     *\n     * const documents = await cursor.toArray();\n     * // documents is now an array of empty strings\n     * ```\n     *\n     * **Note for Typescript Users:** adding a transform changes the return type of the iteration of this cursor,\n     * it **does not** return a new instance of a cursor. This means when calling map,\n     * you should always assign the result to a new variable in order to get a correctly typed cursor variable.\n     * Take note of the following example:\n     *\n     * @example\n     * ```typescript\n     * const cursor: FindCursor<Document> = coll.find();\n     * const mappedCursor: FindCursor<number> = cursor.map(doc => Object.keys(doc).length);\n     * const keyCounts: number[] = await mappedCursor.toArray(); // cursor.toArray() still returns Document[]\n     * ```\n     * @param transform - The mapping transformation method.\n     */\n    map(transform) {\n        assertUninitialized(this);\n        const oldTransform = this[kTransform]; // TODO(NODE-3283): Improve transform typing\n        if (oldTransform) {\n            this[kTransform] = doc => {\n                return transform(oldTransform(doc));\n            };\n        }\n        else {\n            this[kTransform] = transform;\n        }\n        return this;\n    }\n    /**\n     * Set the ReadPreference for the cursor.\n     *\n     * @param readPreference - The new read preference for the cursor.\n     */\n    withReadPreference(readPreference) {\n        assertUninitialized(this);\n        if (readPreference instanceof read_preference_1.ReadPreference) {\n            this[kOptions].readPreference = readPreference;\n        }\n        else if (typeof readPreference === 'string') {\n            this[kOptions].readPreference = read_preference_1.ReadPreference.fromString(readPreference);\n        }\n        else {\n            throw new error_1.MongoInvalidArgumentError(`Invalid read preference: ${readPreference}`);\n        }\n        return this;\n    }\n    /**\n     * Set the ReadPreference for the cursor.\n     *\n     * @param readPreference - The new read preference for the cursor.\n     */\n    withReadConcern(readConcern) {\n        assertUninitialized(this);\n        const resolvedReadConcern = read_concern_1.ReadConcern.fromOptions({ readConcern });\n        if (resolvedReadConcern) {\n            this[kOptions].readConcern = resolvedReadConcern;\n        }\n        return this;\n    }\n    /**\n     * Set a maxTimeMS on the cursor query, allowing for hard timeout limits on queries (Only supported on MongoDB 2.6 or higher)\n     *\n     * @param value - Number of milliseconds to wait before aborting the query.\n     */\n    maxTimeMS(value) {\n        assertUninitialized(this);\n        if (typeof value !== 'number') {\n            throw new error_1.MongoInvalidArgumentError('Argument for maxTimeMS must be a number');\n        }\n        this[kOptions].maxTimeMS = value;\n        return this;\n    }\n    /**\n     * Set the batch size for the cursor.\n     *\n     * @param value - The number of documents to return per batch. See {@link https://www.mongodb.com/docs/manual/reference/command/find/|find command documentation}.\n     */\n    batchSize(value) {\n        assertUninitialized(this);\n        if (this[kOptions].tailable) {\n            throw new error_1.MongoTailableCursorError('Tailable cursor does not support batchSize');\n        }\n        if (typeof value !== 'number') {\n            throw new error_1.MongoInvalidArgumentError('Operation \"batchSize\" requires an integer');\n        }\n        this[kOptions].batchSize = value;\n        return this;\n    }\n    /**\n     * Rewind this cursor to its uninitialized state. Any options that are present on the cursor will\n     * remain in effect. Iterating this cursor will cause new queries to be sent to the server, even\n     * if the resultant data has already been retrieved by this cursor.\n     */\n    rewind() {\n        if (!this[kInitialized]) {\n            return;\n        }\n        this[kId] = null;\n        this[kDocuments].clear();\n        this[kClosed] = false;\n        this[kKilled] = false;\n        this[kInitialized] = false;\n        const session = this[kSession];\n        if (session) {\n            // We only want to end this session if we created it, and it hasn't ended yet\n            if (session.explicit === false) {\n                if (!session.hasEnded) {\n                    // eslint-disable-next-line github/no-then\n                    session.endSession().then(undefined, utils_1.squashError);\n                }\n                this[kSession] = this.client.startSession({ owner: this, explicit: false });\n            }\n        }\n    }\n    /** @internal */\n    async getMore(batchSize, useCursorResponse = false) {\n        // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n        const getMoreOperation = new get_more_1.GetMoreOperation(this[kNamespace], this[kId], this[kServer], {\n            ...this[kOptions],\n            session: this[kSession],\n            batchSize,\n            useCursorResponse\n        });\n        return await (0, execute_operation_1.executeOperation)(this[kClient], getMoreOperation);\n    }\n    /**\n     * @internal\n     *\n     * This function is exposed for the unified test runner's createChangeStream\n     * operation.  We cannot refactor to use the abstract _initialize method without\n     * a significant refactor.\n     */\n    async [kInit]() {\n        try {\n            const state = await this._initialize(this[kSession]);\n            const response = state.response;\n            this[kServer] = state.server;\n            if (responses_1.CursorResponse.is(response)) {\n                this[kId] = response.id;\n                if (response.ns)\n                    this[kNamespace] = response.ns;\n                this[kDocuments] = response;\n            }\n            else if (response.cursor) {\n                // TODO(NODE-2674): Preserve int64 sent from MongoDB\n                this[kId] =\n                    typeof response.cursor.id === 'number'\n                        ? bson_1.Long.fromNumber(response.cursor.id)\n                        : typeof response.cursor.id === 'bigint'\n                            ? bson_1.Long.fromBigInt(response.cursor.id)\n                            : response.cursor.id;\n                if (response.cursor.ns) {\n                    this[kNamespace] = (0, utils_1.ns)(response.cursor.ns);\n                }\n                this[kDocuments].pushMany(response.cursor.firstBatch);\n            }\n            // When server responses return without a cursor document, we close this cursor\n            // and return the raw server response. This is often the case for explain commands\n            // for example\n            if (this[kId] == null) {\n                this[kId] = bson_1.Long.ZERO;\n                // TODO(NODE-3286): ExecutionResult needs to accept a generic parameter\n                this[kDocuments].push(state.response);\n            }\n            // the cursor is now initialized, even if it is dead\n            this[kInitialized] = true;\n        }\n        catch (error) {\n            // the cursor is now initialized, even if an error occurred\n            this[kInitialized] = true;\n            await cleanupCursor(this, { error });\n            throw error;\n        }\n        if (this.isDead) {\n            await cleanupCursor(this, undefined);\n        }\n        return;\n    }\n}\n/** @event */\nAbstractCursor.CLOSE = 'close';\nexports.AbstractCursor = AbstractCursor;\nasync function next(cursor, { blocking, transform, shift }) {\n    if (cursor.closed) {\n        if (!shift)\n            return false;\n        return null;\n    }\n    do {\n        if (cursor[kId] == null) {\n            // All cursors must operate within a session, one must be made implicitly if not explicitly provided\n            await cursor[kInit]();\n        }\n        if (cursor[kDocuments].length !== 0) {\n            if (!shift)\n                return true;\n            const doc = cursor[kDocuments].shift(cursor[kOptions]);\n            if (doc != null && transform && cursor[kTransform]) {\n                try {\n                    return cursor[kTransform](doc);\n                }\n                catch (error) {\n                    try {\n                        await cleanupCursor(cursor, { error, needsToEmitClosed: true });\n                    }\n                    catch (error) {\n                        // `cleanupCursor` should never throw, squash and throw the original error\n                        (0, utils_1.squashError)(error);\n                    }\n                    throw error;\n                }\n            }\n            return doc;\n        }\n        if (cursor.isDead) {\n            // if the cursor is dead, we clean it up\n            // cleanupCursor should never throw, but if it does it indicates a bug in the driver\n            // and we should surface the error\n            await cleanupCursor(cursor, {});\n            if (!shift)\n                return false;\n            return null;\n        }\n        // otherwise need to call getMore\n        const batchSize = cursor[kOptions].batchSize || 1000;\n        try {\n            const response = await cursor.getMore(batchSize);\n            if (responses_1.CursorResponse.is(response)) {\n                cursor[kId] = response.id;\n                cursor[kDocuments] = response;\n            }\n            else if (response) {\n                const cursorId = typeof response.cursor.id === 'number'\n                    ? bson_1.Long.fromNumber(response.cursor.id)\n                    : typeof response.cursor.id === 'bigint'\n                        ? bson_1.Long.fromBigInt(response.cursor.id)\n                        : response.cursor.id;\n                cursor[kDocuments].pushMany(response.cursor.nextBatch);\n                cursor[kId] = cursorId;\n            }\n        }\n        catch (error) {\n            try {\n                await cleanupCursor(cursor, { error, needsToEmitClosed: true });\n            }\n            catch (error) {\n                // `cleanupCursor` should never throw, squash and throw the original error\n                (0, utils_1.squashError)(error);\n            }\n            throw error;\n        }\n        if (cursor.isDead) {\n            // If we successfully received a response from a cursor BUT the cursor indicates that it is exhausted,\n            // we intentionally clean up the cursor to release its session back into the pool before the cursor\n            // is iterated.  This prevents a cursor that is exhausted on the server from holding\n            // onto a session indefinitely until the AbstractCursor is iterated.\n            //\n            // cleanupCursorAsync should never throw, but if it does it indicates a bug in the driver\n            // and we should surface the error\n            await cleanupCursor(cursor, {});\n        }\n        if (cursor[kDocuments].length === 0 && blocking === false) {\n            if (!shift)\n                return false;\n            return null;\n        }\n    } while (!cursor.isDead || cursor[kDocuments].length !== 0);\n    if (!shift)\n        return false;\n    return null;\n}\nasync function cleanupCursor(cursor, options) {\n    const cursorId = cursor[kId];\n    const cursorNs = cursor[kNamespace];\n    const server = cursor[kServer];\n    const session = cursor[kSession];\n    const error = options?.error;\n    // Cursors only emit closed events once the client-side cursor has been exhausted fully or there\n    // was an error.  Notably, when the server returns a cursor id of 0 and a non-empty batch, we\n    // cleanup the cursor but don't emit a `close` event.\n    const needsToEmitClosed = options?.needsToEmitClosed ?? cursor[kDocuments].length === 0;\n    if (error) {\n        if (cursor.loadBalanced && error instanceof error_1.MongoNetworkError) {\n            return await completeCleanup();\n        }\n    }\n    if (cursorId == null || server == null || cursorId.isZero() || cursorNs == null) {\n        if (needsToEmitClosed) {\n            cursor[kClosed] = true;\n            cursor[kId] = bson_1.Long.ZERO;\n            cursor.emit(AbstractCursor.CLOSE);\n        }\n        if (session) {\n            if (session.owner === cursor) {\n                await session.endSession({ error });\n                return;\n            }\n            if (!session.inTransaction()) {\n                (0, sessions_1.maybeClearPinnedConnection)(session, { error });\n            }\n        }\n        return;\n    }\n    async function completeCleanup() {\n        if (session) {\n            if (session.owner === cursor) {\n                try {\n                    await session.endSession({ error });\n                }\n                finally {\n                    cursor.emit(AbstractCursor.CLOSE);\n                }\n                return;\n            }\n            if (!session.inTransaction()) {\n                (0, sessions_1.maybeClearPinnedConnection)(session, { error });\n            }\n        }\n        cursor.emit(AbstractCursor.CLOSE);\n        return;\n    }\n    cursor[kKilled] = true;\n    if (session.hasEnded) {\n        return await completeCleanup();\n    }\n    try {\n        await (0, execute_operation_1.executeOperation)(cursor[kClient], new kill_cursors_1.KillCursorsOperation(cursorId, cursorNs, server, { session }));\n    }\n    catch (error) {\n        (0, utils_1.squashError)(error);\n    }\n    finally {\n        await completeCleanup();\n    }\n}\n/** @internal */\nfunction assertUninitialized(cursor) {\n    if (cursor[kInitialized]) {\n        throw new error_1.MongoCursorInUseError();\n    }\n}\nexports.assertUninitialized = assertUninitialized;\nclass ReadableCursorStream extends stream_1.Readable {\n    constructor(cursor) {\n        super({\n            objectMode: true,\n            autoDestroy: false,\n            highWaterMark: 1\n        });\n        this._readInProgress = false;\n        this._cursor = cursor;\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    _read(size) {\n        if (!this._readInProgress) {\n            this._readInProgress = true;\n            this._readNext();\n        }\n    }\n    _destroy(error, callback) {\n        // eslint-disable-next-line github/no-then\n        this._cursor.close().then(() => callback(error), closeError => callback(closeError));\n    }\n    _readNext() {\n        // eslint-disable-next-line github/no-then\n        next(this._cursor, { blocking: true, transform: true, shift: true }).then(result => {\n            if (result == null) {\n                this.push(null);\n            }\n            else if (this.destroyed) {\n                // eslint-disable-next-line github/no-then\n                this._cursor.close().then(undefined, utils_1.squashError);\n            }\n            else {\n                if (this.push(result)) {\n                    return this._readNext();\n                }\n                this._readInProgress = false;\n            }\n        }, err => {\n            // NOTE: This is questionable, but we have a test backing the behavior. It seems the\n            //       desired behavior is that a stream ends cleanly when a user explicitly closes\n            //       a client during iteration. Alternatively, we could do the \"right\" thing and\n            //       propagate the error message by removing this special case.\n            if (err.message.match(/server is closed/)) {\n                // eslint-disable-next-line github/no-then\n                this._cursor.close().then(undefined, utils_1.squashError);\n                return this.push(null);\n            }\n            // NOTE: This is also perhaps questionable. The rationale here is that these errors tend\n            //       to be \"operation was interrupted\", where a cursor has been closed but there is an\n            //       active getMore in-flight. This used to check if the cursor was killed but once\n            //       that changed to happen in cleanup legitimate errors would not destroy the\n            //       stream. There are change streams test specifically test these cases.\n            if (err.message.match(/operation was interrupted/)) {\n                return this.push(null);\n            }\n            // NOTE: The two above checks on the message of the error will cause a null to be pushed\n            //       to the stream, thus closing the stream before the destroy call happens. This means\n            //       that either of those error messages on a change stream will not get a proper\n            //       'error' event to be emitted (the error passed to destroy). Change stream resumability\n            //       relies on that error event to be emitted to create its new cursor and thus was not\n            //       working on 4.4 servers because the error emitted on failover was \"interrupted at\n            //       shutdown\" while on 5.0+ it is \"The server is in quiesce mode and will shut down\".\n            //       See NODE-4475.\n            return this.destroy(err);\n        });\n    }\n}\n//# sourceMappingURL=abstract_cursor.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cursor/abstract_cursor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cursor/aggregation_cursor.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongodb/lib/cursor/aggregation_cursor.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AggregationCursor = void 0;\nconst aggregate_1 = __webpack_require__(/*! ../operations/aggregate */ \"./node_modules/mongodb/lib/operations/aggregate.js\");\nconst execute_operation_1 = __webpack_require__(/*! ../operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst abstract_cursor_1 = __webpack_require__(/*! ./abstract_cursor */ \"./node_modules/mongodb/lib/cursor/abstract_cursor.js\");\n/** @internal */\nconst kPipeline = Symbol('pipeline');\n/** @internal */\nconst kOptions = Symbol('options');\n/**\n * The **AggregationCursor** class is an internal class that embodies an aggregation cursor on MongoDB\n * allowing for iteration over the results returned from the underlying query. It supports\n * one by one document iteration, conversion to an array or can be iterated as a Node 4.X\n * or higher stream\n * @public\n */\nclass AggregationCursor extends abstract_cursor_1.AbstractCursor {\n    /** @internal */\n    constructor(client, namespace, pipeline = [], options = {}) {\n        super(client, namespace, options);\n        this[kPipeline] = pipeline;\n        this[kOptions] = options;\n    }\n    get pipeline() {\n        return this[kPipeline];\n    }\n    clone() {\n        const clonedOptions = (0, utils_1.mergeOptions)({}, this[kOptions]);\n        delete clonedOptions.session;\n        return new AggregationCursor(this.client, this.namespace, this[kPipeline], {\n            ...clonedOptions\n        });\n    }\n    map(transform) {\n        return super.map(transform);\n    }\n    /** @internal */\n    async _initialize(session) {\n        const aggregateOperation = new aggregate_1.AggregateOperation(this.namespace, this[kPipeline], {\n            ...this[kOptions],\n            ...this.cursorOptions,\n            session\n        });\n        const response = await (0, execute_operation_1.executeOperation)(this.client, aggregateOperation);\n        // TODO: NODE-2882\n        return { server: aggregateOperation.server, session, response };\n    }\n    /** Execute the explain for the cursor */\n    async explain(verbosity) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new aggregate_1.AggregateOperation(this.namespace, this[kPipeline], {\n            ...this[kOptions],\n            ...this.cursorOptions,\n            explain: verbosity ?? true\n        }));\n    }\n    addStage(stage) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kPipeline].push(stage);\n        return this;\n    }\n    group($group) {\n        return this.addStage({ $group });\n    }\n    /** Add a limit stage to the aggregation pipeline */\n    limit($limit) {\n        return this.addStage({ $limit });\n    }\n    /** Add a match stage to the aggregation pipeline */\n    match($match) {\n        return this.addStage({ $match });\n    }\n    /** Add an out stage to the aggregation pipeline */\n    out($out) {\n        return this.addStage({ $out });\n    }\n    /**\n     * Add a project stage to the aggregation pipeline\n     *\n     * @remarks\n     * In order to strictly type this function you must provide an interface\n     * that represents the effect of your projection on the result documents.\n     *\n     * By default chaining a projection to your cursor changes the returned type to the generic {@link Document} type.\n     * You should specify a parameterized type to have assertions on your final results.\n     *\n     * @example\n     * ```typescript\n     * // Best way\n     * const docs: AggregationCursor<{ a: number }> = cursor.project<{ a: number }>({ _id: 0, a: true });\n     * // Flexible way\n     * const docs: AggregationCursor<Document> = cursor.project({ _id: 0, a: true });\n     * ```\n     *\n     * @remarks\n     * In order to strictly type this function you must provide an interface\n     * that represents the effect of your projection on the result documents.\n     *\n     * **Note for Typescript Users:** adding a transform changes the return type of the iteration of this cursor,\n     * it **does not** return a new instance of a cursor. This means when calling project,\n     * you should always assign the result to a new variable in order to get a correctly typed cursor variable.\n     * Take note of the following example:\n     *\n     * @example\n     * ```typescript\n     * const cursor: AggregationCursor<{ a: number; b: string }> = coll.aggregate([]);\n     * const projectCursor = cursor.project<{ a: number }>({ _id: 0, a: true });\n     * const aPropOnlyArray: {a: number}[] = await projectCursor.toArray();\n     *\n     * // or always use chaining and save the final cursor\n     *\n     * const cursor = coll.aggregate().project<{ a: string }>({\n     *   _id: 0,\n     *   a: { $convert: { input: '$a', to: 'string' }\n     * }});\n     * ```\n     */\n    project($project) {\n        return this.addStage({ $project });\n    }\n    /** Add a lookup stage to the aggregation pipeline */\n    lookup($lookup) {\n        return this.addStage({ $lookup });\n    }\n    /** Add a redact stage to the aggregation pipeline */\n    redact($redact) {\n        return this.addStage({ $redact });\n    }\n    /** Add a skip stage to the aggregation pipeline */\n    skip($skip) {\n        return this.addStage({ $skip });\n    }\n    /** Add a sort stage to the aggregation pipeline */\n    sort($sort) {\n        return this.addStage({ $sort });\n    }\n    /** Add a unwind stage to the aggregation pipeline */\n    unwind($unwind) {\n        return this.addStage({ $unwind });\n    }\n    /** Add a geoNear stage to the aggregation pipeline */\n    geoNear($geoNear) {\n        return this.addStage({ $geoNear });\n    }\n}\nexports.AggregationCursor = AggregationCursor;\n//# sourceMappingURL=aggregation_cursor.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cursor/aggregation_cursor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cursor/change_stream_cursor.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mongodb/lib/cursor/change_stream_cursor.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ChangeStreamCursor = void 0;\nconst change_stream_1 = __webpack_require__(/*! ../change_stream */ \"./node_modules/mongodb/lib/change_stream.js\");\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst aggregate_1 = __webpack_require__(/*! ../operations/aggregate */ \"./node_modules/mongodb/lib/operations/aggregate.js\");\nconst execute_operation_1 = __webpack_require__(/*! ../operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst abstract_cursor_1 = __webpack_require__(/*! ./abstract_cursor */ \"./node_modules/mongodb/lib/cursor/abstract_cursor.js\");\n/** @internal */\nclass ChangeStreamCursor extends abstract_cursor_1.AbstractCursor {\n    constructor(client, namespace, pipeline = [], options = {}) {\n        super(client, namespace, options);\n        this.pipeline = pipeline;\n        this.options = options;\n        this._resumeToken = null;\n        this.startAtOperationTime = options.startAtOperationTime;\n        if (options.startAfter) {\n            this.resumeToken = options.startAfter;\n        }\n        else if (options.resumeAfter) {\n            this.resumeToken = options.resumeAfter;\n        }\n    }\n    set resumeToken(token) {\n        this._resumeToken = token;\n        this.emit(change_stream_1.ChangeStream.RESUME_TOKEN_CHANGED, token);\n    }\n    get resumeToken() {\n        return this._resumeToken;\n    }\n    get resumeOptions() {\n        const options = {\n            ...this.options\n        };\n        for (const key of ['resumeAfter', 'startAfter', 'startAtOperationTime']) {\n            delete options[key];\n        }\n        if (this.resumeToken != null) {\n            if (this.options.startAfter && !this.hasReceived) {\n                options.startAfter = this.resumeToken;\n            }\n            else {\n                options.resumeAfter = this.resumeToken;\n            }\n        }\n        else if (this.startAtOperationTime != null && (0, utils_1.maxWireVersion)(this.server) >= 7) {\n            options.startAtOperationTime = this.startAtOperationTime;\n        }\n        return options;\n    }\n    cacheResumeToken(resumeToken) {\n        if (this.bufferedCount() === 0 && this.postBatchResumeToken) {\n            this.resumeToken = this.postBatchResumeToken;\n        }\n        else {\n            this.resumeToken = resumeToken;\n        }\n        this.hasReceived = true;\n    }\n    _processBatch(response) {\n        const cursor = response.cursor;\n        if (cursor.postBatchResumeToken) {\n            this.postBatchResumeToken = response.cursor.postBatchResumeToken;\n            const batch = 'firstBatch' in response.cursor ? response.cursor.firstBatch : response.cursor.nextBatch;\n            if (batch.length === 0) {\n                this.resumeToken = cursor.postBatchResumeToken;\n            }\n        }\n    }\n    clone() {\n        return new ChangeStreamCursor(this.client, this.namespace, this.pipeline, {\n            ...this.cursorOptions\n        });\n    }\n    async _initialize(session) {\n        const aggregateOperation = new aggregate_1.AggregateOperation(this.namespace, this.pipeline, {\n            ...this.cursorOptions,\n            ...this.options,\n            session\n        });\n        const response = await (0, execute_operation_1.executeOperation)(session.client, aggregateOperation);\n        const server = aggregateOperation.server;\n        this.maxWireVersion = (0, utils_1.maxWireVersion)(server);\n        if (this.startAtOperationTime == null &&\n            this.resumeAfter == null &&\n            this.startAfter == null &&\n            this.maxWireVersion >= 7) {\n            this.startAtOperationTime = response.operationTime;\n        }\n        this._processBatch(response);\n        this.emit(constants_1.INIT, response);\n        this.emit(constants_1.RESPONSE);\n        // TODO: NODE-2882\n        return { server, session, response };\n    }\n    async getMore(batchSize) {\n        const response = await super.getMore(batchSize);\n        this.maxWireVersion = (0, utils_1.maxWireVersion)(this.server);\n        this._processBatch(response);\n        this.emit(change_stream_1.ChangeStream.MORE, response);\n        this.emit(change_stream_1.ChangeStream.RESPONSE);\n        return response;\n    }\n}\nexports.ChangeStreamCursor = ChangeStreamCursor;\n//# sourceMappingURL=change_stream_cursor.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cursor/change_stream_cursor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cursor/find_cursor.js":
/*!********************************************************!*\
  !*** ./node_modules/mongodb/lib/cursor/find_cursor.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nvar _a;\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.FindCursor = exports.FLAGS = void 0;\nconst responses_1 = __webpack_require__(/*! ../cmap/wire_protocol/responses */ \"./node_modules/mongodb/lib/cmap/wire_protocol/responses.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst count_1 = __webpack_require__(/*! ../operations/count */ \"./node_modules/mongodb/lib/operations/count.js\");\nconst execute_operation_1 = __webpack_require__(/*! ../operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst find_1 = __webpack_require__(/*! ../operations/find */ \"./node_modules/mongodb/lib/operations/find.js\");\nconst sort_1 = __webpack_require__(/*! ../sort */ \"./node_modules/mongodb/lib/sort.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst abstract_cursor_1 = __webpack_require__(/*! ./abstract_cursor */ \"./node_modules/mongodb/lib/cursor/abstract_cursor.js\");\n/** @internal */\nconst kFilter = Symbol('filter');\n/** @internal */\nconst kNumReturned = Symbol('numReturned');\n/** @internal */\nconst kBuiltOptions = Symbol('builtOptions');\n/** @public Flags allowed for cursor */\nexports.FLAGS = [\n    'tailable',\n    'oplogReplay',\n    'noCursorTimeout',\n    'awaitData',\n    'exhaust',\n    'partial'\n];\n/** @public */\nclass FindCursor extends abstract_cursor_1.AbstractCursor {\n    /** @internal */\n    constructor(client, namespace, filter = {}, options = {}) {\n        super(client, namespace, options);\n        /** @internal */\n        this[_a] = 0;\n        this[kFilter] = filter;\n        this[kBuiltOptions] = options;\n        if (options.sort != null) {\n            this[kBuiltOptions].sort = (0, sort_1.formatSort)(options.sort);\n        }\n    }\n    clone() {\n        const clonedOptions = (0, utils_1.mergeOptions)({}, this[kBuiltOptions]);\n        delete clonedOptions.session;\n        return new FindCursor(this.client, this.namespace, this[kFilter], {\n            ...clonedOptions\n        });\n    }\n    map(transform) {\n        return super.map(transform);\n    }\n    /** @internal */\n    async _initialize(session) {\n        const findOperation = new find_1.FindOperation(this.namespace, this[kFilter], {\n            ...this[kBuiltOptions],\n            ...this.cursorOptions,\n            session\n        });\n        const response = await (0, execute_operation_1.executeOperation)(this.client, findOperation);\n        // the response is not a cursor when `explain` is enabled\n        if (responses_1.CursorResponse.is(response)) {\n            this[kNumReturned] = response.batchSize;\n        }\n        else {\n            // Can be an explain response, hence the ?. on everything\n            this[kNumReturned] = this[kNumReturned] + (response?.cursor?.firstBatch?.length ?? 0);\n        }\n        // TODO: NODE-2882\n        return { server: findOperation.server, session, response };\n    }\n    /** @internal */\n    async getMore(batchSize) {\n        const numReturned = this[kNumReturned];\n        if (numReturned) {\n            // TODO(DRIVERS-1448): Remove logic to enforce `limit` in the driver\n            const limit = this[kBuiltOptions].limit;\n            batchSize =\n                limit && limit > 0 && numReturned + batchSize > limit ? limit - numReturned : batchSize;\n            if (batchSize <= 0) {\n                try {\n                    await this.close();\n                }\n                catch (error) {\n                    (0, utils_1.squashError)(error);\n                    // this is an optimization for the special case of a limit for a find command to avoid an\n                    // extra getMore when the limit has been reached and the limit is a multiple of the batchSize.\n                    // This is a consequence of the new query engine in 5.0 having no knowledge of the limit as it\n                    // produces results for the find command.  Once a batch is filled up, it is returned and only\n                    // on the subsequent getMore will the query framework consider the limit, determine the cursor\n                    // is exhausted and return a cursorId of zero.\n                    // instead, if we determine there are no more documents to request from the server, we preemptively\n                    // close the cursor\n                }\n                return responses_1.CursorResponse.emptyGetMore;\n            }\n        }\n        const response = await super.getMore(batchSize, false);\n        // TODO: wrap this in some logic to prevent it from happening if we don't need this support\n        if (responses_1.CursorResponse.is(response)) {\n            this[kNumReturned] = this[kNumReturned] + response.batchSize;\n        }\n        else {\n            this[kNumReturned] = this[kNumReturned] + (response?.cursor?.nextBatch?.length ?? 0);\n        }\n        return response;\n    }\n    /**\n     * Get the count of documents for this cursor\n     * @deprecated Use `collection.estimatedDocumentCount` or `collection.countDocuments` instead\n     */\n    async count(options) {\n        (0, utils_1.emitWarningOnce)('cursor.count is deprecated and will be removed in the next major version, please use `collection.estimatedDocumentCount` or `collection.countDocuments` instead ');\n        if (typeof options === 'boolean') {\n            throw new error_1.MongoInvalidArgumentError('Invalid first parameter to count');\n        }\n        return await (0, execute_operation_1.executeOperation)(this.client, new count_1.CountOperation(this.namespace, this[kFilter], {\n            ...this[kBuiltOptions],\n            ...this.cursorOptions,\n            ...options\n        }));\n    }\n    /** Execute the explain for the cursor */\n    async explain(verbosity) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new find_1.FindOperation(this.namespace, this[kFilter], {\n            ...this[kBuiltOptions],\n            ...this.cursorOptions,\n            explain: verbosity ?? true\n        }));\n    }\n    /** Set the cursor query */\n    filter(filter) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kFilter] = filter;\n        return this;\n    }\n    /**\n     * Set the cursor hint\n     *\n     * @param hint - If specified, then the query system will only consider plans using the hinted index.\n     */\n    hint(hint) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kBuiltOptions].hint = hint;\n        return this;\n    }\n    /**\n     * Set the cursor min\n     *\n     * @param min - Specify a $min value to specify the inclusive lower bound for a specific index in order to constrain the results of find(). The $min specifies the lower bound for all keys of a specific index in order.\n     */\n    min(min) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kBuiltOptions].min = min;\n        return this;\n    }\n    /**\n     * Set the cursor max\n     *\n     * @param max - Specify a $max value to specify the exclusive upper bound for a specific index in order to constrain the results of find(). The $max specifies the upper bound for all keys of a specific index in order.\n     */\n    max(max) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kBuiltOptions].max = max;\n        return this;\n    }\n    /**\n     * Set the cursor returnKey.\n     * If set to true, modifies the cursor to only return the index field or fields for the results of the query, rather than documents.\n     * If set to true and the query does not use an index to perform the read operation, the returned documents will not contain any fields.\n     *\n     * @param value - the returnKey value.\n     */\n    returnKey(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kBuiltOptions].returnKey = value;\n        return this;\n    }\n    /**\n     * Modifies the output of a query by adding a field $recordId to matching documents. $recordId is the internal key which uniquely identifies a document in a collection.\n     *\n     * @param value - The $showDiskLoc option has now been deprecated and replaced with the showRecordId field. $showDiskLoc will still be accepted for OP_QUERY stye find.\n     */\n    showRecordId(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kBuiltOptions].showRecordId = value;\n        return this;\n    }\n    /**\n     * Add a query modifier to the cursor query\n     *\n     * @param name - The query modifier (must start with $, such as $orderby etc)\n     * @param value - The modifier value.\n     */\n    addQueryModifier(name, value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        if (name[0] !== '$') {\n            throw new error_1.MongoInvalidArgumentError(`${name} is not a valid query modifier`);\n        }\n        // Strip of the $\n        const field = name.substr(1);\n        // NOTE: consider some TS magic for this\n        switch (field) {\n            case 'comment':\n                this[kBuiltOptions].comment = value;\n                break;\n            case 'explain':\n                this[kBuiltOptions].explain = value;\n                break;\n            case 'hint':\n                this[kBuiltOptions].hint = value;\n                break;\n            case 'max':\n                this[kBuiltOptions].max = value;\n                break;\n            case 'maxTimeMS':\n                this[kBuiltOptions].maxTimeMS = value;\n                break;\n            case 'min':\n                this[kBuiltOptions].min = value;\n                break;\n            case 'orderby':\n                this[kBuiltOptions].sort = (0, sort_1.formatSort)(value);\n                break;\n            case 'query':\n                this[kFilter] = value;\n                break;\n            case 'returnKey':\n                this[kBuiltOptions].returnKey = value;\n                break;\n            case 'showDiskLoc':\n                this[kBuiltOptions].showRecordId = value;\n                break;\n            default:\n                throw new error_1.MongoInvalidArgumentError(`Invalid query modifier: ${name}`);\n        }\n        return this;\n    }\n    /**\n     * Add a comment to the cursor query allowing for tracking the comment in the log.\n     *\n     * @param value - The comment attached to this query.\n     */\n    comment(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kBuiltOptions].comment = value;\n        return this;\n    }\n    /**\n     * Set a maxAwaitTimeMS on a tailing cursor query to allow to customize the timeout value for the option awaitData (Only supported on MongoDB 3.2 or higher, ignored otherwise)\n     *\n     * @param value - Number of milliseconds to wait before aborting the tailed query.\n     */\n    maxAwaitTimeMS(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        if (typeof value !== 'number') {\n            throw new error_1.MongoInvalidArgumentError('Argument for maxAwaitTimeMS must be a number');\n        }\n        this[kBuiltOptions].maxAwaitTimeMS = value;\n        return this;\n    }\n    /**\n     * Set a maxTimeMS on the cursor query, allowing for hard timeout limits on queries (Only supported on MongoDB 2.6 or higher)\n     *\n     * @param value - Number of milliseconds to wait before aborting the query.\n     */\n    maxTimeMS(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        if (typeof value !== 'number') {\n            throw new error_1.MongoInvalidArgumentError('Argument for maxTimeMS must be a number');\n        }\n        this[kBuiltOptions].maxTimeMS = value;\n        return this;\n    }\n    /**\n     * Add a project stage to the aggregation pipeline\n     *\n     * @remarks\n     * In order to strictly type this function you must provide an interface\n     * that represents the effect of your projection on the result documents.\n     *\n     * By default chaining a projection to your cursor changes the returned type to the generic\n     * {@link Document} type.\n     * You should specify a parameterized type to have assertions on your final results.\n     *\n     * @example\n     * ```typescript\n     * // Best way\n     * const docs: FindCursor<{ a: number }> = cursor.project<{ a: number }>({ _id: 0, a: true });\n     * // Flexible way\n     * const docs: FindCursor<Document> = cursor.project({ _id: 0, a: true });\n     * ```\n     *\n     * @remarks\n     *\n     * **Note for Typescript Users:** adding a transform changes the return type of the iteration of this cursor,\n     * it **does not** return a new instance of a cursor. This means when calling project,\n     * you should always assign the result to a new variable in order to get a correctly typed cursor variable.\n     * Take note of the following example:\n     *\n     * @example\n     * ```typescript\n     * const cursor: FindCursor<{ a: number; b: string }> = coll.find();\n     * const projectCursor = cursor.project<{ a: number }>({ _id: 0, a: true });\n     * const aPropOnlyArray: {a: number}[] = await projectCursor.toArray();\n     *\n     * // or always use chaining and save the final cursor\n     *\n     * const cursor = coll.find().project<{ a: string }>({\n     *   _id: 0,\n     *   a: { $convert: { input: '$a', to: 'string' }\n     * }});\n     * ```\n     */\n    project(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kBuiltOptions].projection = value;\n        return this;\n    }\n    /**\n     * Sets the sort order of the cursor query.\n     *\n     * @param sort - The key or keys set for the sort.\n     * @param direction - The direction of the sorting (1 or -1).\n     */\n    sort(sort, direction) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        if (this[kBuiltOptions].tailable) {\n            throw new error_1.MongoTailableCursorError('Tailable cursor does not support sorting');\n        }\n        this[kBuiltOptions].sort = (0, sort_1.formatSort)(sort, direction);\n        return this;\n    }\n    /**\n     * Allows disk use for blocking sort operations exceeding 100MB memory. (MongoDB 3.2 or higher)\n     *\n     * @remarks\n     * {@link https://www.mongodb.com/docs/manual/reference/command/find/#find-cmd-allowdiskuse | find command allowDiskUse documentation}\n     */\n    allowDiskUse(allow = true) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        if (!this[kBuiltOptions].sort) {\n            throw new error_1.MongoInvalidArgumentError('Option \"allowDiskUse\" requires a sort specification');\n        }\n        // As of 6.0 the default is true. This allows users to get back to the old behavior.\n        if (!allow) {\n            this[kBuiltOptions].allowDiskUse = false;\n            return this;\n        }\n        this[kBuiltOptions].allowDiskUse = true;\n        return this;\n    }\n    /**\n     * Set the collation options for the cursor.\n     *\n     * @param value - The cursor collation options (MongoDB 3.4 or higher) settings for update operation (see 3.4 documentation for available fields).\n     */\n    collation(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kBuiltOptions].collation = value;\n        return this;\n    }\n    /**\n     * Set the limit for the cursor.\n     *\n     * @param value - The limit for the cursor query.\n     */\n    limit(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        if (this[kBuiltOptions].tailable) {\n            throw new error_1.MongoTailableCursorError('Tailable cursor does not support limit');\n        }\n        if (typeof value !== 'number') {\n            throw new error_1.MongoInvalidArgumentError('Operation \"limit\" requires an integer');\n        }\n        this[kBuiltOptions].limit = value;\n        return this;\n    }\n    /**\n     * Set the skip for the cursor.\n     *\n     * @param value - The skip for the cursor query.\n     */\n    skip(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        if (this[kBuiltOptions].tailable) {\n            throw new error_1.MongoTailableCursorError('Tailable cursor does not support skip');\n        }\n        if (typeof value !== 'number') {\n            throw new error_1.MongoInvalidArgumentError('Operation \"skip\" requires an integer');\n        }\n        this[kBuiltOptions].skip = value;\n        return this;\n    }\n}\nexports.FindCursor = FindCursor;\n_a = kNumReturned;\n//# sourceMappingURL=find_cursor.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cursor/find_cursor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cursor/list_collections_cursor.js":
/*!********************************************************************!*\
  !*** ./node_modules/mongodb/lib/cursor/list_collections_cursor.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ListCollectionsCursor = void 0;\nconst execute_operation_1 = __webpack_require__(/*! ../operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst list_collections_1 = __webpack_require__(/*! ../operations/list_collections */ \"./node_modules/mongodb/lib/operations/list_collections.js\");\nconst abstract_cursor_1 = __webpack_require__(/*! ./abstract_cursor */ \"./node_modules/mongodb/lib/cursor/abstract_cursor.js\");\n/** @public */\nclass ListCollectionsCursor extends abstract_cursor_1.AbstractCursor {\n    constructor(db, filter, options) {\n        super(db.client, db.s.namespace, options);\n        this.parent = db;\n        this.filter = filter;\n        this.options = options;\n    }\n    clone() {\n        return new ListCollectionsCursor(this.parent, this.filter, {\n            ...this.options,\n            ...this.cursorOptions\n        });\n    }\n    /** @internal */\n    async _initialize(session) {\n        const operation = new list_collections_1.ListCollectionsOperation(this.parent, this.filter, {\n            ...this.cursorOptions,\n            ...this.options,\n            session\n        });\n        const response = await (0, execute_operation_1.executeOperation)(this.parent.client, operation);\n        // TODO: NODE-2882\n        return { server: operation.server, session, response };\n    }\n}\nexports.ListCollectionsCursor = ListCollectionsCursor;\n//# sourceMappingURL=list_collections_cursor.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cursor/list_collections_cursor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cursor/list_indexes_cursor.js":
/*!****************************************************************!*\
  !*** ./node_modules/mongodb/lib/cursor/list_indexes_cursor.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ListIndexesCursor = void 0;\nconst execute_operation_1 = __webpack_require__(/*! ../operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst indexes_1 = __webpack_require__(/*! ../operations/indexes */ \"./node_modules/mongodb/lib/operations/indexes.js\");\nconst abstract_cursor_1 = __webpack_require__(/*! ./abstract_cursor */ \"./node_modules/mongodb/lib/cursor/abstract_cursor.js\");\n/** @public */\nclass ListIndexesCursor extends abstract_cursor_1.AbstractCursor {\n    constructor(collection, options) {\n        super(collection.client, collection.s.namespace, options);\n        this.parent = collection;\n        this.options = options;\n    }\n    clone() {\n        return new ListIndexesCursor(this.parent, {\n            ...this.options,\n            ...this.cursorOptions\n        });\n    }\n    /** @internal */\n    async _initialize(session) {\n        const operation = new indexes_1.ListIndexesOperation(this.parent, {\n            ...this.cursorOptions,\n            ...this.options,\n            session\n        });\n        const response = await (0, execute_operation_1.executeOperation)(this.parent.client, operation);\n        // TODO: NODE-2882\n        return { server: operation.server, session, response };\n    }\n}\nexports.ListIndexesCursor = ListIndexesCursor;\n//# sourceMappingURL=list_indexes_cursor.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cursor/list_indexes_cursor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cursor/list_search_indexes_cursor.js":
/*!***********************************************************************!*\
  !*** ./node_modules/mongodb/lib/cursor/list_search_indexes_cursor.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ListSearchIndexesCursor = void 0;\nconst aggregation_cursor_1 = __webpack_require__(/*! ./aggregation_cursor */ \"./node_modules/mongodb/lib/cursor/aggregation_cursor.js\");\n/** @public */\nclass ListSearchIndexesCursor extends aggregation_cursor_1.AggregationCursor {\n    /** @internal */\n    constructor({ fullNamespace: ns, client }, name, options = {}) {\n        const pipeline = name == null ? [{ $listSearchIndexes: {} }] : [{ $listSearchIndexes: { name } }];\n        super(client, ns, pipeline, options);\n    }\n}\nexports.ListSearchIndexesCursor = ListSearchIndexesCursor;\n//# sourceMappingURL=list_search_indexes_cursor.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cursor/list_search_indexes_cursor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cursor/run_command_cursor.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongodb/lib/cursor/run_command_cursor.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RunCommandCursor = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst execute_operation_1 = __webpack_require__(/*! ../operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst get_more_1 = __webpack_require__(/*! ../operations/get_more */ \"./node_modules/mongodb/lib/operations/get_more.js\");\nconst run_command_1 = __webpack_require__(/*! ../operations/run_command */ \"./node_modules/mongodb/lib/operations/run_command.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst abstract_cursor_1 = __webpack_require__(/*! ./abstract_cursor */ \"./node_modules/mongodb/lib/cursor/abstract_cursor.js\");\n/** @public */\nclass RunCommandCursor extends abstract_cursor_1.AbstractCursor {\n    /**\n     * Controls the `getMore.comment` field\n     * @param comment - any BSON value\n     */\n    setComment(comment) {\n        this.getMoreOptions.comment = comment;\n        return this;\n    }\n    /**\n     * Controls the `getMore.maxTimeMS` field. Only valid when cursor is tailable await\n     * @param maxTimeMS - the number of milliseconds to wait for new data\n     */\n    setMaxTimeMS(maxTimeMS) {\n        this.getMoreOptions.maxAwaitTimeMS = maxTimeMS;\n        return this;\n    }\n    /**\n     * Controls the `getMore.batchSize` field\n     * @param maxTimeMS - the number documents to return in the `nextBatch`\n     */\n    setBatchSize(batchSize) {\n        this.getMoreOptions.batchSize = batchSize;\n        return this;\n    }\n    /** Unsupported for RunCommandCursor */\n    clone() {\n        throw new error_1.MongoAPIError('Clone not supported, create a new cursor with db.runCursorCommand');\n    }\n    /** Unsupported for RunCommandCursor: readConcern must be configured directly on command document */\n    withReadConcern(_) {\n        throw new error_1.MongoAPIError('RunCommandCursor does not support readConcern it must be attached to the command being run');\n    }\n    /** Unsupported for RunCommandCursor: various cursor flags must be configured directly on command document */\n    addCursorFlag(_, __) {\n        throw new error_1.MongoAPIError('RunCommandCursor does not support cursor flags, they must be attached to the command being run');\n    }\n    /** Unsupported for RunCommandCursor: maxTimeMS must be configured directly on command document */\n    maxTimeMS(_) {\n        throw new error_1.MongoAPIError('maxTimeMS must be configured on the command document directly, to configure getMore.maxTimeMS use cursor.setMaxTimeMS()');\n    }\n    /** Unsupported for RunCommandCursor: batchSize must be configured directly on command document */\n    batchSize(_) {\n        throw new error_1.MongoAPIError('batchSize must be configured on the command document directly, to configure getMore.batchSize use cursor.setBatchSize()');\n    }\n    /** @internal */\n    constructor(db, command, options = {}) {\n        super(db.client, (0, utils_1.ns)(db.namespace), options);\n        this.getMoreOptions = {};\n        this.db = db;\n        this.command = Object.freeze({ ...command });\n    }\n    /** @internal */\n    async _initialize(session) {\n        const operation = new run_command_1.RunCommandOperation(this.db, this.command, {\n            ...this.cursorOptions,\n            session: session,\n            readPreference: this.cursorOptions.readPreference\n        });\n        const response = await (0, execute_operation_1.executeOperation)(this.client, operation);\n        if (response.cursor == null) {\n            throw new error_1.MongoUnexpectedServerResponseError('Expected server to respond with cursor');\n        }\n        return {\n            server: operation.server,\n            session,\n            response\n        };\n    }\n    /** @internal */\n    async getMore(_batchSize) {\n        // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n        const getMoreOperation = new get_more_1.GetMoreOperation(this.namespace, this.id, this.server, {\n            ...this.cursorOptions,\n            session: this.session,\n            ...this.getMoreOptions,\n            useCursorResponse: false\n        });\n        return await (0, execute_operation_1.executeOperation)(this.client, getMoreOperation);\n    }\n}\nexports.RunCommandCursor = RunCommandCursor;\n//# sourceMappingURL=run_command_cursor.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/cursor/run_command_cursor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/db.js":
/*!****************************************!*\
  !*** ./node_modules/mongodb/lib/db.js ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Db = void 0;\nconst admin_1 = __webpack_require__(/*! ./admin */ \"./node_modules/mongodb/lib/admin.js\");\nconst bson_1 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst change_stream_1 = __webpack_require__(/*! ./change_stream */ \"./node_modules/mongodb/lib/change_stream.js\");\nconst collection_1 = __webpack_require__(/*! ./collection */ \"./node_modules/mongodb/lib/collection.js\");\nconst CONSTANTS = __webpack_require__(/*! ./constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst aggregation_cursor_1 = __webpack_require__(/*! ./cursor/aggregation_cursor */ \"./node_modules/mongodb/lib/cursor/aggregation_cursor.js\");\nconst list_collections_cursor_1 = __webpack_require__(/*! ./cursor/list_collections_cursor */ \"./node_modules/mongodb/lib/cursor/list_collections_cursor.js\");\nconst run_command_cursor_1 = __webpack_require__(/*! ./cursor/run_command_cursor */ \"./node_modules/mongodb/lib/cursor/run_command_cursor.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst collections_1 = __webpack_require__(/*! ./operations/collections */ \"./node_modules/mongodb/lib/operations/collections.js\");\nconst create_collection_1 = __webpack_require__(/*! ./operations/create_collection */ \"./node_modules/mongodb/lib/operations/create_collection.js\");\nconst drop_1 = __webpack_require__(/*! ./operations/drop */ \"./node_modules/mongodb/lib/operations/drop.js\");\nconst execute_operation_1 = __webpack_require__(/*! ./operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst indexes_1 = __webpack_require__(/*! ./operations/indexes */ \"./node_modules/mongodb/lib/operations/indexes.js\");\nconst profiling_level_1 = __webpack_require__(/*! ./operations/profiling_level */ \"./node_modules/mongodb/lib/operations/profiling_level.js\");\nconst remove_user_1 = __webpack_require__(/*! ./operations/remove_user */ \"./node_modules/mongodb/lib/operations/remove_user.js\");\nconst rename_1 = __webpack_require__(/*! ./operations/rename */ \"./node_modules/mongodb/lib/operations/rename.js\");\nconst run_command_1 = __webpack_require__(/*! ./operations/run_command */ \"./node_modules/mongodb/lib/operations/run_command.js\");\nconst set_profiling_level_1 = __webpack_require__(/*! ./operations/set_profiling_level */ \"./node_modules/mongodb/lib/operations/set_profiling_level.js\");\nconst stats_1 = __webpack_require__(/*! ./operations/stats */ \"./node_modules/mongodb/lib/operations/stats.js\");\nconst read_concern_1 = __webpack_require__(/*! ./read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst read_preference_1 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst write_concern_1 = __webpack_require__(/*! ./write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\n// Allowed parameters\nconst DB_OPTIONS_ALLOW_LIST = [\n    'writeConcern',\n    'readPreference',\n    'readPreferenceTags',\n    'native_parser',\n    'forceServerObjectId',\n    'pkFactory',\n    'serializeFunctions',\n    'raw',\n    'authSource',\n    'ignoreUndefined',\n    'readConcern',\n    'retryMiliSeconds',\n    'numberOfRetries',\n    'useBigInt64',\n    'promoteBuffers',\n    'promoteLongs',\n    'bsonRegExp',\n    'enableUtf8Validation',\n    'promoteValues',\n    'compression',\n    'retryWrites',\n    'timeoutMS'\n];\n/**\n * The **Db** class is a class that represents a MongoDB Database.\n * @public\n *\n * @example\n * ```ts\n * import { MongoClient } from 'mongodb';\n *\n * interface Pet {\n *   name: string;\n *   kind: 'dog' | 'cat' | 'fish';\n * }\n *\n * const client = new MongoClient('mongodb://localhost:27017');\n * const db = client.db();\n *\n * // Create a collection that validates our union\n * await db.createCollection<Pet>('pets', {\n *   validator: { $expr: { $in: ['$kind', ['dog', 'cat', 'fish']] } }\n * })\n * ```\n */\nclass Db {\n    /**\n     * Creates a new Db instance.\n     *\n     * Db name cannot contain a dot, the server may apply more restrictions when an operation is run.\n     *\n     * @param client - The MongoClient for the database.\n     * @param databaseName - The name of the database this instance represents.\n     * @param options - Optional settings for Db construction.\n     */\n    constructor(client, databaseName, options) {\n        options = options ?? {};\n        // Filter the options\n        options = (0, utils_1.filterOptions)(options, DB_OPTIONS_ALLOW_LIST);\n        // Ensure there are no dots in database name\n        if (typeof databaseName === 'string' && databaseName.includes('.')) {\n            throw new error_1.MongoInvalidArgumentError(`Database names cannot contain the character '.'`);\n        }\n        // Internal state of the db object\n        this.s = {\n            // Options\n            options,\n            // Unpack read preference\n            readPreference: read_preference_1.ReadPreference.fromOptions(options),\n            // Merge bson options\n            bsonOptions: (0, bson_1.resolveBSONOptions)(options, client),\n            // Set up the primary key factory or fallback to ObjectId\n            pkFactory: options?.pkFactory ?? utils_1.DEFAULT_PK_FACTORY,\n            // ReadConcern\n            readConcern: read_concern_1.ReadConcern.fromOptions(options),\n            writeConcern: write_concern_1.WriteConcern.fromOptions(options),\n            // Namespace\n            namespace: new utils_1.MongoDBNamespace(databaseName)\n        };\n        this.client = client;\n    }\n    get databaseName() {\n        return this.s.namespace.db;\n    }\n    // Options\n    get options() {\n        return this.s.options;\n    }\n    /**\n     * Check if a secondary can be used (because the read preference is *not* set to primary)\n     */\n    get secondaryOk() {\n        return this.s.readPreference?.preference !== 'primary' || false;\n    }\n    get readConcern() {\n        return this.s.readConcern;\n    }\n    /**\n     * The current readPreference of the Db. If not explicitly defined for\n     * this Db, will be inherited from the parent MongoClient\n     */\n    get readPreference() {\n        if (this.s.readPreference == null) {\n            return this.client.readPreference;\n        }\n        return this.s.readPreference;\n    }\n    get bsonOptions() {\n        return this.s.bsonOptions;\n    }\n    // get the write Concern\n    get writeConcern() {\n        return this.s.writeConcern;\n    }\n    get namespace() {\n        return this.s.namespace.toString();\n    }\n    /**\n     * Create a new collection on a server with the specified options. Use this to create capped collections.\n     * More information about command options available at https://www.mongodb.com/docs/manual/reference/command/create/\n     *\n     * Collection namespace validation is performed server-side.\n     *\n     * @param name - The name of the collection to create\n     * @param options - Optional settings for the command\n     */\n    async createCollection(name, options) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new create_collection_1.CreateCollectionOperation(this, name, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Execute a command\n     *\n     * @remarks\n     * This command does not inherit options from the MongoClient.\n     *\n     * The driver will ensure the following fields are attached to the command sent to the server:\n     * - `lsid` - sourced from an implicit session or options.session\n     * - `$readPreference` - defaults to primary or can be configured by options.readPreference\n     * - `$db` - sourced from the name of this database\n     *\n     * If the client has a serverApi setting:\n     * - `apiVersion`\n     * - `apiStrict`\n     * - `apiDeprecationErrors`\n     *\n     * When in a transaction:\n     * - `readConcern` - sourced from readConcern set on the TransactionOptions\n     * - `writeConcern` - sourced from writeConcern set on the TransactionOptions\n     *\n     * Attaching any of the above fields to the command will have no effect as the driver will overwrite the value.\n     *\n     * @param command - The command to run\n     * @param options - Optional settings for the command\n     */\n    async command(command, options) {\n        // Intentionally, we do not inherit options from parent for this operation.\n        return await (0, execute_operation_1.executeOperation)(this.client, new run_command_1.RunCommandOperation(this, command, {\n            ...(0, bson_1.resolveBSONOptions)(options),\n            session: options?.session,\n            readPreference: options?.readPreference\n        }));\n    }\n    /**\n     * Execute an aggregation framework pipeline against the database, needs MongoDB \\>= 3.6\n     *\n     * @param pipeline - An array of aggregation stages to be executed\n     * @param options - Optional settings for the command\n     */\n    aggregate(pipeline = [], options) {\n        return new aggregation_cursor_1.AggregationCursor(this.client, this.s.namespace, pipeline, (0, utils_1.resolveOptions)(this, options));\n    }\n    /** Return the Admin db instance */\n    admin() {\n        return new admin_1.Admin(this);\n    }\n    /**\n     * Returns a reference to a MongoDB Collection. If it does not exist it will be created implicitly.\n     *\n     * Collection namespace validation is performed server-side.\n     *\n     * @param name - the collection name we wish to access.\n     * @returns return the new Collection instance\n     */\n    collection(name, options = {}) {\n        if (typeof options === 'function') {\n            throw new error_1.MongoInvalidArgumentError('The callback form of this helper has been removed.');\n        }\n        return new collection_1.Collection(this, name, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * Get all the db statistics.\n     *\n     * @param options - Optional settings for the command\n     */\n    async stats(options) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new stats_1.DbStatsOperation(this, (0, utils_1.resolveOptions)(this, options)));\n    }\n    listCollections(filter = {}, options = {}) {\n        return new list_collections_cursor_1.ListCollectionsCursor(this, filter, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * Rename a collection.\n     *\n     * @remarks\n     * This operation does not inherit options from the MongoClient.\n     *\n     * @param fromCollection - Name of current collection to rename\n     * @param toCollection - New name of of the collection\n     * @param options - Optional settings for the command\n     */\n    async renameCollection(fromCollection, toCollection, options) {\n        // Intentionally, we do not inherit options from parent for this operation.\n        return await (0, execute_operation_1.executeOperation)(this.client, new rename_1.RenameOperation(this.collection(fromCollection), toCollection, { ...options, new_collection: true, readPreference: read_preference_1.ReadPreference.primary }));\n    }\n    /**\n     * Drop a collection from the database, removing it permanently. New accesses will create a new collection.\n     *\n     * @param name - Name of collection to drop\n     * @param options - Optional settings for the command\n     */\n    async dropCollection(name, options) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new drop_1.DropCollectionOperation(this, name, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Drop a database, removing it permanently from the server.\n     *\n     * @param options - Optional settings for the command\n     */\n    async dropDatabase(options) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new drop_1.DropDatabaseOperation(this, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Fetch all collections for the current db.\n     *\n     * @param options - Optional settings for the command\n     */\n    async collections(options) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new collections_1.CollectionsOperation(this, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Creates an index on the db and collection.\n     *\n     * @param name - Name of the collection to create the index on.\n     * @param indexSpec - Specify the field to index, or an index specification\n     * @param options - Optional settings for the command\n     */\n    async createIndex(name, indexSpec, options) {\n        const indexes = await (0, execute_operation_1.executeOperation)(this.client, indexes_1.CreateIndexesOperation.fromIndexSpecification(this, name, indexSpec, options));\n        return indexes[0];\n    }\n    /**\n     * Remove a user from a database\n     *\n     * @param username - The username to remove\n     * @param options - Optional settings for the command\n     */\n    async removeUser(username, options) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new remove_user_1.RemoveUserOperation(this, username, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Set the current profiling level of MongoDB\n     *\n     * @param level - The new profiling level (off, slow_only, all).\n     * @param options - Optional settings for the command\n     */\n    async setProfilingLevel(level, options) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new set_profiling_level_1.SetProfilingLevelOperation(this, level, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Retrieve the current profiling Level for MongoDB\n     *\n     * @param options - Optional settings for the command\n     */\n    async profilingLevel(options) {\n        return await (0, execute_operation_1.executeOperation)(this.client, new profiling_level_1.ProfilingLevelOperation(this, (0, utils_1.resolveOptions)(this, options)));\n    }\n    async indexInformation(name, options) {\n        return await this.collection(name).indexInformation((0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * Create a new Change Stream, watching for new changes (insertions, updates,\n     * replacements, deletions, and invalidations) in this database. Will ignore all\n     * changes to system collections.\n     *\n     * @remarks\n     * watch() accepts two generic arguments for distinct use cases:\n     * - The first is to provide the schema that may be defined for all the collections within this database\n     * - The second is to override the shape of the change stream document entirely, if it is not provided the type will default to ChangeStreamDocument of the first argument\n     *\n     * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents. This allows for filtering (using $match) and manipulating the change stream documents.\n     * @param options - Optional settings for the command\n     * @typeParam TSchema - Type of the data being detected by the change stream\n     * @typeParam TChange - Type of the whole change stream document emitted\n     */\n    watch(pipeline = [], options = {}) {\n        // Allow optionally not specifying a pipeline\n        if (!Array.isArray(pipeline)) {\n            options = pipeline;\n            pipeline = [];\n        }\n        return new change_stream_1.ChangeStream(this, pipeline, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * A low level cursor API providing basic driver functionality:\n     * - ClientSession management\n     * - ReadPreference for server selection\n     * - Running getMores automatically when a local batch is exhausted\n     *\n     * @param command - The command that will start a cursor on the server.\n     * @param options - Configurations for running the command, bson options will apply to getMores\n     */\n    runCursorCommand(command, options) {\n        return new run_command_cursor_1.RunCommandCursor(this, command, options);\n    }\n}\nDb.SYSTEM_NAMESPACE_COLLECTION = CONSTANTS.SYSTEM_NAMESPACE_COLLECTION;\nDb.SYSTEM_INDEX_COLLECTION = CONSTANTS.SYSTEM_INDEX_COLLECTION;\nDb.SYSTEM_PROFILE_COLLECTION = CONSTANTS.SYSTEM_PROFILE_COLLECTION;\nDb.SYSTEM_USER_COLLECTION = CONSTANTS.SYSTEM_USER_COLLECTION;\nDb.SYSTEM_COMMAND_COLLECTION = CONSTANTS.SYSTEM_COMMAND_COLLECTION;\nDb.SYSTEM_JS_COLLECTION = CONSTANTS.SYSTEM_JS_COLLECTION;\nexports.Db = Db;\n//# sourceMappingURL=db.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/db.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/deps.js":
/*!******************************************!*\
  !*** ./node_modules/mongodb/lib/deps.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.getMongoDBClientEncryption = exports.aws4 = exports.getSocks = exports.getSnappy = exports.getGcpMetadata = exports.getAwsCredentialProvider = exports.getZstdLibrary = exports.getKerberos = void 0;\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nfunction makeErrorModule(error) {\n    const props = error ? { kModuleError: error } : {};\n    return new Proxy(props, {\n        get: (_, key) => {\n            if (key === 'kModuleError') {\n                return error;\n            }\n            throw error;\n        },\n        set: () => {\n            throw error;\n        }\n    });\n}\nfunction getKerberos() {\n    let kerberos;\n    try {\n        // Ensure you always wrap an optional require in the try block NODE-3199\n        kerberos = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'kerberos'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n    }\n    catch (error) {\n        kerberos = makeErrorModule(new error_1.MongoMissingDependencyError('Optional module `kerberos` not found. Please install it to enable kerberos authentication', { cause: error, dependencyName: 'kerberos' }));\n    }\n    return kerberos;\n}\nexports.getKerberos = getKerberos;\nfunction getZstdLibrary() {\n    let ZStandard;\n    try {\n        ZStandard = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@mongodb-js/zstd'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n    }\n    catch (error) {\n        ZStandard = makeErrorModule(new error_1.MongoMissingDependencyError('Optional module `@mongodb-js/zstd` not found. Please install it to enable zstd compression', { cause: error, dependencyName: 'zstd' }));\n    }\n    return ZStandard;\n}\nexports.getZstdLibrary = getZstdLibrary;\nfunction getAwsCredentialProvider() {\n    try {\n        // Ensure you always wrap an optional require in the try block NODE-3199\n        const credentialProvider = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@aws-sdk/credential-providers'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n        return credentialProvider;\n    }\n    catch (error) {\n        return makeErrorModule(new error_1.MongoMissingDependencyError('Optional module `@aws-sdk/credential-providers` not found.' +\n            ' Please install it to enable getting aws credentials via the official sdk.', { cause: error, dependencyName: '@aws-sdk/credential-providers' }));\n    }\n}\nexports.getAwsCredentialProvider = getAwsCredentialProvider;\nfunction getGcpMetadata() {\n    try {\n        // Ensure you always wrap an optional require in the try block NODE-3199\n        const credentialProvider = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'gcp-metadata'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n        return credentialProvider;\n    }\n    catch (error) {\n        return makeErrorModule(new error_1.MongoMissingDependencyError('Optional module `gcp-metadata` not found.' +\n            ' Please install it to enable getting gcp credentials via the official sdk.', { cause: error, dependencyName: 'gcp-metadata' }));\n    }\n}\nexports.getGcpMetadata = getGcpMetadata;\nfunction getSnappy() {\n    try {\n        // Ensure you always wrap an optional require in the try block NODE-3199\n        const value = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'snappy'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n        return value;\n    }\n    catch (error) {\n        const kModuleError = new error_1.MongoMissingDependencyError('Optional module `snappy` not found. Please install it to enable snappy compression', { cause: error, dependencyName: 'snappy' });\n        return { kModuleError };\n    }\n}\nexports.getSnappy = getSnappy;\nfunction getSocks() {\n    try {\n        // Ensure you always wrap an optional require in the try block NODE-3199\n        const value = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'socks'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n        return value;\n    }\n    catch (error) {\n        const kModuleError = new error_1.MongoMissingDependencyError('Optional module `socks` not found. Please install it to connections over a SOCKS5 proxy', { cause: error, dependencyName: 'socks' });\n        return { kModuleError };\n    }\n}\nexports.getSocks = getSocks;\nexports.aws4 = loadAws4();\nfunction loadAws4() {\n    let aws4;\n    try {\n        aws4 = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'aws4'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n    }\n    catch (error) {\n        aws4 = makeErrorModule(new error_1.MongoMissingDependencyError('Optional module `aws4` not found. Please install it to enable AWS authentication', { cause: error, dependencyName: 'aws4' }));\n    }\n    return aws4;\n}\n/** A utility function to get the instance of mongodb-client-encryption, if it exists. */\nfunction getMongoDBClientEncryption() {\n    let mongodbClientEncryption = null;\n    try {\n        // NOTE(NODE-3199): Ensure you always wrap an optional require literally in the try block\n        // Cannot be moved to helper utility function, bundlers search and replace the actual require call\n        // in a way that makes this line throw at bundle time, not runtime, catching here will make bundling succeed\n        mongodbClientEncryption = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'mongodb-client-encryption'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n    }\n    catch (error) {\n        const kModuleError = new error_1.MongoMissingDependencyError('Optional module `mongodb-client-encryption` not found. Please install it to use auto encryption or ClientEncryption.', { cause: error, dependencyName: 'mongodb-client-encryption' });\n        return { kModuleError };\n    }\n    return mongodbClientEncryption;\n}\nexports.getMongoDBClientEncryption = getMongoDBClientEncryption;\n//# sourceMappingURL=deps.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/deps.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/encrypter.js":
/*!***********************************************!*\
  !*** ./node_modules/mongodb/lib/encrypter.js ***!
  \***********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Encrypter = void 0;\nconst util_1 = __webpack_require__(/*! util */ \"util\");\nconst auto_encrypter_1 = __webpack_require__(/*! ./client-side-encryption/auto_encrypter */ \"./node_modules/mongodb/lib/client-side-encryption/auto_encrypter.js\");\nconst constants_1 = __webpack_require__(/*! ./constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst deps_1 = __webpack_require__(/*! ./deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_client_1 = __webpack_require__(/*! ./mongo_client */ \"./node_modules/mongodb/lib/mongo_client.js\");\n/** @internal */\nconst kInternalClient = Symbol('internalClient');\n/** @internal */\nclass Encrypter {\n    constructor(client, uri, options) {\n        if (typeof options.autoEncryption !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('Option \"autoEncryption\" must be specified');\n        }\n        // initialize to null, if we call getInternalClient, we may set this it is important to not overwrite those function calls.\n        this[kInternalClient] = null;\n        this.bypassAutoEncryption = !!options.autoEncryption.bypassAutoEncryption;\n        this.needsConnecting = false;\n        if (options.maxPoolSize === 0 && options.autoEncryption.keyVaultClient == null) {\n            options.autoEncryption.keyVaultClient = client;\n        }\n        else if (options.autoEncryption.keyVaultClient == null) {\n            options.autoEncryption.keyVaultClient = this.getInternalClient(client, uri, options);\n        }\n        if (this.bypassAutoEncryption) {\n            options.autoEncryption.metadataClient = undefined;\n        }\n        else if (options.maxPoolSize === 0) {\n            options.autoEncryption.metadataClient = client;\n        }\n        else {\n            options.autoEncryption.metadataClient = this.getInternalClient(client, uri, options);\n        }\n        if (options.proxyHost) {\n            options.autoEncryption.proxyOptions = {\n                proxyHost: options.proxyHost,\n                proxyPort: options.proxyPort,\n                proxyUsername: options.proxyUsername,\n                proxyPassword: options.proxyPassword\n            };\n        }\n        this.autoEncrypter = new auto_encrypter_1.AutoEncrypter(client, options.autoEncryption);\n    }\n    getInternalClient(client, uri, options) {\n        // TODO(NODE-4144): Remove new variable for type narrowing\n        let internalClient = this[kInternalClient];\n        if (internalClient == null) {\n            const clonedOptions = {};\n            for (const key of [\n                ...Object.getOwnPropertyNames(options),\n                ...Object.getOwnPropertySymbols(options)\n            ]) {\n                if (['autoEncryption', 'minPoolSize', 'servers', 'caseTranslate', 'dbName'].includes(key))\n                    continue;\n                Reflect.set(clonedOptions, key, Reflect.get(options, key));\n            }\n            clonedOptions.minPoolSize = 0;\n            internalClient = new mongo_client_1.MongoClient(uri, clonedOptions);\n            this[kInternalClient] = internalClient;\n            for (const eventName of constants_1.MONGO_CLIENT_EVENTS) {\n                for (const listener of client.listeners(eventName)) {\n                    internalClient.on(eventName, listener);\n                }\n            }\n            client.on('newListener', (eventName, listener) => {\n                internalClient?.on(eventName, listener);\n            });\n            this.needsConnecting = true;\n        }\n        return internalClient;\n    }\n    async connectInternalClient() {\n        // TODO(NODE-4144): Remove new variable for type narrowing\n        const internalClient = this[kInternalClient];\n        if (this.needsConnecting && internalClient != null) {\n            this.needsConnecting = false;\n            await internalClient.connect();\n        }\n    }\n    closeCallback(client, force, callback) {\n        (0, util_1.callbackify)(this.close.bind(this))(client, force, callback);\n    }\n    async close(client, force) {\n        let error;\n        try {\n            await this.autoEncrypter.teardown(force);\n        }\n        catch (autoEncrypterError) {\n            error = autoEncrypterError;\n        }\n        const internalClient = this[kInternalClient];\n        if (internalClient != null && client !== internalClient) {\n            return await internalClient.close(force);\n        }\n        if (error != null) {\n            throw error;\n        }\n    }\n    static checkForMongoCrypt() {\n        const mongodbClientEncryption = (0, deps_1.getMongoDBClientEncryption)();\n        if ('kModuleError' in mongodbClientEncryption) {\n            throw new error_1.MongoMissingDependencyError('Auto-encryption requested, but the module is not installed. ' +\n                'Please add `mongodb-client-encryption` as a dependency of your project', {\n                cause: mongodbClientEncryption['kModuleError'],\n                dependencyName: 'mongodb-client-encryption'\n            });\n        }\n    }\n}\nexports.Encrypter = Encrypter;\n//# sourceMappingURL=encrypter.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/encrypter.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/error.js":
/*!*******************************************!*\
  !*** ./node_modules/mongodb/lib/error.js ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.isResumableError = exports.isNetworkTimeoutError = exports.isSDAMUnrecoverableError = exports.isNodeShuttingDownError = exports.isRetryableReadError = exports.isRetryableWriteError = exports.needsRetryableWriteLabel = exports.MongoWriteConcernError = exports.MongoServerSelectionError = exports.MongoSystemError = exports.MongoMissingDependencyError = exports.MongoMissingCredentialsError = exports.MongoCompatibilityError = exports.MongoInvalidArgumentError = exports.MongoParseError = exports.MongoNetworkTimeoutError = exports.MongoNetworkError = exports.isNetworkErrorBeforeHandshake = exports.MongoTopologyClosedError = exports.MongoCursorExhaustedError = exports.MongoServerClosedError = exports.MongoCursorInUseError = exports.MongoUnexpectedServerResponseError = exports.MongoGridFSChunkError = exports.MongoGridFSStreamError = exports.MongoTailableCursorError = exports.MongoChangeStreamError = exports.MongoGCPError = exports.MongoAzureError = exports.MongoOIDCError = exports.MongoAWSError = exports.MongoKerberosError = exports.MongoExpiredSessionError = exports.MongoTransactionError = exports.MongoNotConnectedError = exports.MongoDecompressionError = exports.MongoBatchReExecutionError = exports.MongoRuntimeError = exports.MongoAPIError = exports.MongoDriverError = exports.MongoServerError = exports.MongoError = exports.MongoErrorLabel = exports.GET_MORE_RESUMABLE_CODES = exports.MONGODB_ERROR_CODES = exports.NODE_IS_RECOVERING_ERROR_MESSAGE = exports.LEGACY_NOT_PRIMARY_OR_SECONDARY_ERROR_MESSAGE = exports.LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE = void 0;\n/** @internal */\nconst kErrorLabels = Symbol('errorLabels');\n/**\n * @internal\n * The legacy error message from the server that indicates the node is not a writable primary\n * https://github.com/mongodb/specifications/blob/b07c26dc40d04ac20349f989db531c9845fdd755/source/server-discovery-and-monitoring/server-discovery-and-monitoring.rst#not-writable-primary-and-node-is-recovering\n */\nexports.LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE = new RegExp('not master', 'i');\n/**\n * @internal\n * The legacy error message from the server that indicates the node is not a primary or secondary\n * https://github.com/mongodb/specifications/blob/b07c26dc40d04ac20349f989db531c9845fdd755/source/server-discovery-and-monitoring/server-discovery-and-monitoring.rst#not-writable-primary-and-node-is-recovering\n */\nexports.LEGACY_NOT_PRIMARY_OR_SECONDARY_ERROR_MESSAGE = new RegExp('not master or secondary', 'i');\n/**\n * @internal\n * The error message from the server that indicates the node is recovering\n * https://github.com/mongodb/specifications/blob/b07c26dc40d04ac20349f989db531c9845fdd755/source/server-discovery-and-monitoring/server-discovery-and-monitoring.rst#not-writable-primary-and-node-is-recovering\n */\nexports.NODE_IS_RECOVERING_ERROR_MESSAGE = new RegExp('node is recovering', 'i');\n/** @internal MongoDB Error Codes */\nexports.MONGODB_ERROR_CODES = Object.freeze({\n    HostUnreachable: 6,\n    HostNotFound: 7,\n    AuthenticationFailed: 18,\n    NetworkTimeout: 89,\n    ShutdownInProgress: 91,\n    PrimarySteppedDown: 189,\n    ExceededTimeLimit: 262,\n    SocketException: 9001,\n    NotWritablePrimary: 10107,\n    InterruptedAtShutdown: 11600,\n    InterruptedDueToReplStateChange: 11602,\n    NotPrimaryNoSecondaryOk: 13435,\n    NotPrimaryOrSecondary: 13436,\n    StaleShardVersion: 63,\n    StaleEpoch: 150,\n    StaleConfig: 13388,\n    RetryChangeStream: 234,\n    FailedToSatisfyReadPreference: 133,\n    CursorNotFound: 43,\n    LegacyNotPrimary: 10058,\n    WriteConcernFailed: 64,\n    NamespaceNotFound: 26,\n    IllegalOperation: 20,\n    MaxTimeMSExpired: 50,\n    UnknownReplWriteConcern: 79,\n    UnsatisfiableWriteConcern: 100,\n    Reauthenticate: 391\n});\n// From spec@https://github.com/mongodb/specifications/blob/f93d78191f3db2898a59013a7ed5650352ef6da8/source/change-streams/change-streams.rst#resumable-error\nexports.GET_MORE_RESUMABLE_CODES = new Set([\n    exports.MONGODB_ERROR_CODES.HostUnreachable,\n    exports.MONGODB_ERROR_CODES.HostNotFound,\n    exports.MONGODB_ERROR_CODES.NetworkTimeout,\n    exports.MONGODB_ERROR_CODES.ShutdownInProgress,\n    exports.MONGODB_ERROR_CODES.PrimarySteppedDown,\n    exports.MONGODB_ERROR_CODES.ExceededTimeLimit,\n    exports.MONGODB_ERROR_CODES.SocketException,\n    exports.MONGODB_ERROR_CODES.NotWritablePrimary,\n    exports.MONGODB_ERROR_CODES.InterruptedAtShutdown,\n    exports.MONGODB_ERROR_CODES.InterruptedDueToReplStateChange,\n    exports.MONGODB_ERROR_CODES.NotPrimaryNoSecondaryOk,\n    exports.MONGODB_ERROR_CODES.NotPrimaryOrSecondary,\n    exports.MONGODB_ERROR_CODES.StaleShardVersion,\n    exports.MONGODB_ERROR_CODES.StaleEpoch,\n    exports.MONGODB_ERROR_CODES.StaleConfig,\n    exports.MONGODB_ERROR_CODES.RetryChangeStream,\n    exports.MONGODB_ERROR_CODES.FailedToSatisfyReadPreference,\n    exports.MONGODB_ERROR_CODES.CursorNotFound\n]);\n/** @public */\nexports.MongoErrorLabel = Object.freeze({\n    RetryableWriteError: 'RetryableWriteError',\n    TransientTransactionError: 'TransientTransactionError',\n    UnknownTransactionCommitResult: 'UnknownTransactionCommitResult',\n    ResumableChangeStreamError: 'ResumableChangeStreamError',\n    HandshakeError: 'HandshakeError',\n    ResetPool: 'ResetPool',\n    PoolRequstedRetry: 'PoolRequstedRetry',\n    InterruptInUseConnections: 'InterruptInUseConnections',\n    NoWritesPerformed: 'NoWritesPerformed'\n});\nfunction isAggregateError(e) {\n    return e != null && typeof e === 'object' && 'errors' in e && Array.isArray(e.errors);\n}\n/**\n * @public\n * @category Error\n *\n * @privateRemarks\n * mongodb-client-encryption has a dependency on this error, it uses the constructor with a string argument\n */\nclass MongoError extends Error {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options) {\n        super(message, options);\n        this[kErrorLabels] = new Set();\n    }\n    /** @internal */\n    static buildErrorMessage(e) {\n        if (typeof e === 'string') {\n            return e;\n        }\n        if (isAggregateError(e) && e.message.length === 0) {\n            return e.errors.length === 0\n                ? 'AggregateError has an empty errors array. Please check the `cause` property for more information.'\n                : e.errors.map(({ message }) => message).join(', ');\n        }\n        return e != null && typeof e === 'object' && 'message' in e && typeof e.message === 'string'\n            ? e.message\n            : 'empty error message';\n    }\n    get name() {\n        return 'MongoError';\n    }\n    /** Legacy name for server error responses */\n    get errmsg() {\n        return this.message;\n    }\n    /**\n     * Checks the error to see if it has an error label\n     *\n     * @param label - The error label to check for\n     * @returns returns true if the error has the provided error label\n     */\n    hasErrorLabel(label) {\n        return this[kErrorLabels].has(label);\n    }\n    addErrorLabel(label) {\n        this[kErrorLabels].add(label);\n    }\n    get errorLabels() {\n        return Array.from(this[kErrorLabels]);\n    }\n}\nexports.MongoError = MongoError;\n/**\n * An error coming from the mongo server\n *\n * @public\n * @category Error\n */\nclass MongoServerError extends MongoError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message.message || message.errmsg || message.$err || 'n/a');\n        if (message.errorLabels) {\n            this[kErrorLabels] = new Set(message.errorLabels);\n        }\n        this.errorResponse = message;\n        for (const name in message) {\n            if (name !== 'errorLabels' &&\n                name !== 'errmsg' &&\n                name !== 'message' &&\n                name !== 'errorResponse') {\n                this[name] = message[name];\n            }\n        }\n    }\n    get name() {\n        return 'MongoServerError';\n    }\n}\nexports.MongoServerError = MongoServerError;\n/**\n * An error generated by the driver\n *\n * @public\n * @category Error\n */\nclass MongoDriverError extends MongoError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options) {\n        super(message, options);\n    }\n    get name() {\n        return 'MongoDriverError';\n    }\n}\nexports.MongoDriverError = MongoDriverError;\n/**\n * An error generated when the driver API is used incorrectly\n *\n * @privateRemarks\n * Should **never** be directly instantiated\n *\n * @public\n * @category Error\n */\nclass MongoAPIError extends MongoDriverError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options) {\n        super(message, options);\n    }\n    get name() {\n        return 'MongoAPIError';\n    }\n}\nexports.MongoAPIError = MongoAPIError;\n/**\n * An error generated when the driver encounters unexpected input\n * or reaches an unexpected/invalid internal state\n *\n * @privateRemarks\n * Should **never** be directly instantiated.\n *\n * @public\n * @category Error\n */\nclass MongoRuntimeError extends MongoDriverError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options) {\n        super(message, options);\n    }\n    get name() {\n        return 'MongoRuntimeError';\n    }\n}\nexports.MongoRuntimeError = MongoRuntimeError;\n/**\n * An error generated when a batch command is re-executed after one of the commands in the batch\n * has failed\n *\n * @public\n * @category Error\n */\nclass MongoBatchReExecutionError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message = 'This batch has already been executed, create new batch to execute') {\n        super(message);\n    }\n    get name() {\n        return 'MongoBatchReExecutionError';\n    }\n}\nexports.MongoBatchReExecutionError = MongoBatchReExecutionError;\n/**\n * An error generated when the driver fails to decompress\n * data received from the server.\n *\n * @public\n * @category Error\n */\nclass MongoDecompressionError extends MongoRuntimeError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoDecompressionError';\n    }\n}\nexports.MongoDecompressionError = MongoDecompressionError;\n/**\n * An error thrown when the user attempts to operate on a database or collection through a MongoClient\n * that has not yet successfully called the \"connect\" method\n *\n * @public\n * @category Error\n */\nclass MongoNotConnectedError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoNotConnectedError';\n    }\n}\nexports.MongoNotConnectedError = MongoNotConnectedError;\n/**\n * An error generated when the user makes a mistake in the usage of transactions.\n * (e.g. attempting to commit a transaction with a readPreference other than primary)\n *\n * @public\n * @category Error\n */\nclass MongoTransactionError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoTransactionError';\n    }\n}\nexports.MongoTransactionError = MongoTransactionError;\n/**\n * An error generated when the user attempts to operate\n * on a session that has expired or has been closed.\n *\n * @public\n * @category Error\n */\nclass MongoExpiredSessionError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message = 'Cannot use a session that has ended') {\n        super(message);\n    }\n    get name() {\n        return 'MongoExpiredSessionError';\n    }\n}\nexports.MongoExpiredSessionError = MongoExpiredSessionError;\n/**\n * A error generated when the user attempts to authenticate\n * via Kerberos, but fails to connect to the Kerberos client.\n *\n * @public\n * @category Error\n */\nclass MongoKerberosError extends MongoRuntimeError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoKerberosError';\n    }\n}\nexports.MongoKerberosError = MongoKerberosError;\n/**\n * A error generated when the user attempts to authenticate\n * via AWS, but fails\n *\n * @public\n * @category Error\n */\nclass MongoAWSError extends MongoRuntimeError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options) {\n        super(message, options);\n    }\n    get name() {\n        return 'MongoAWSError';\n    }\n}\nexports.MongoAWSError = MongoAWSError;\n/**\n * A error generated when the user attempts to authenticate\n * via OIDC callbacks, but fails.\n *\n * @public\n * @category Error\n */\nclass MongoOIDCError extends MongoRuntimeError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoOIDCError';\n    }\n}\nexports.MongoOIDCError = MongoOIDCError;\n/**\n * A error generated when the user attempts to authenticate\n * via Azure, but fails.\n *\n * @public\n * @category Error\n */\nclass MongoAzureError extends MongoOIDCError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoAzureError';\n    }\n}\nexports.MongoAzureError = MongoAzureError;\n/**\n * A error generated when the user attempts to authenticate\n * via GCP, but fails.\n *\n * @public\n * @category Error\n */\nclass MongoGCPError extends MongoOIDCError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoGCPError';\n    }\n}\nexports.MongoGCPError = MongoGCPError;\n/**\n * An error generated when a ChangeStream operation fails to execute.\n *\n * @public\n * @category Error\n */\nclass MongoChangeStreamError extends MongoRuntimeError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoChangeStreamError';\n    }\n}\nexports.MongoChangeStreamError = MongoChangeStreamError;\n/**\n * An error thrown when the user calls a function or method not supported on a tailable cursor\n *\n * @public\n * @category Error\n */\nclass MongoTailableCursorError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message = 'Tailable cursor does not support this operation') {\n        super(message);\n    }\n    get name() {\n        return 'MongoTailableCursorError';\n    }\n}\nexports.MongoTailableCursorError = MongoTailableCursorError;\n/** An error generated when a GridFSStream operation fails to execute.\n *\n * @public\n * @category Error\n */\nclass MongoGridFSStreamError extends MongoRuntimeError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoGridFSStreamError';\n    }\n}\nexports.MongoGridFSStreamError = MongoGridFSStreamError;\n/**\n * An error generated when a malformed or invalid chunk is\n * encountered when reading from a GridFSStream.\n *\n * @public\n * @category Error\n */\nclass MongoGridFSChunkError extends MongoRuntimeError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoGridFSChunkError';\n    }\n}\nexports.MongoGridFSChunkError = MongoGridFSChunkError;\n/**\n * An error generated when a **parsable** unexpected response comes from the server.\n * This is generally an error where the driver in a state expecting a certain behavior to occur in\n * the next message from MongoDB but it receives something else.\n * This error **does not** represent an issue with wire message formatting.\n *\n * #### Example\n * When an operation fails, it is the driver's job to retry it. It must perform serverSelection\n * again to make sure that it attempts the operation against a server in a good state. If server\n * selection returns a server that does not support retryable operations, this error is used.\n * This scenario is unlikely as retryable support would also have been determined on the first attempt\n * but it is possible the state change could report a selectable server that does not support retries.\n *\n * @public\n * @category Error\n */\nclass MongoUnexpectedServerResponseError extends MongoRuntimeError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoUnexpectedServerResponseError';\n    }\n}\nexports.MongoUnexpectedServerResponseError = MongoUnexpectedServerResponseError;\n/**\n * An error thrown when the user attempts to add options to a cursor that has already been\n * initialized\n *\n * @public\n * @category Error\n */\nclass MongoCursorInUseError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message = 'Cursor is already initialized') {\n        super(message);\n    }\n    get name() {\n        return 'MongoCursorInUseError';\n    }\n}\nexports.MongoCursorInUseError = MongoCursorInUseError;\n/**\n * An error generated when an attempt is made to operate\n * on a closed/closing server.\n *\n * @public\n * @category Error\n */\nclass MongoServerClosedError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message = 'Server is closed') {\n        super(message);\n    }\n    get name() {\n        return 'MongoServerClosedError';\n    }\n}\nexports.MongoServerClosedError = MongoServerClosedError;\n/**\n * An error thrown when an attempt is made to read from a cursor that has been exhausted\n *\n * @public\n * @category Error\n */\nclass MongoCursorExhaustedError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message || 'Cursor is exhausted');\n    }\n    get name() {\n        return 'MongoCursorExhaustedError';\n    }\n}\nexports.MongoCursorExhaustedError = MongoCursorExhaustedError;\n/**\n * An error generated when an attempt is made to operate on a\n * dropped, or otherwise unavailable, database.\n *\n * @public\n * @category Error\n */\nclass MongoTopologyClosedError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message = 'Topology is closed') {\n        super(message);\n    }\n    get name() {\n        return 'MongoTopologyClosedError';\n    }\n}\nexports.MongoTopologyClosedError = MongoTopologyClosedError;\n/** @internal */\nconst kBeforeHandshake = Symbol('beforeHandshake');\nfunction isNetworkErrorBeforeHandshake(err) {\n    return err[kBeforeHandshake] === true;\n}\nexports.isNetworkErrorBeforeHandshake = isNetworkErrorBeforeHandshake;\n/**\n * An error indicating an issue with the network, including TCP errors and timeouts.\n * @public\n * @category Error\n */\nclass MongoNetworkError extends MongoError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options) {\n        super(message, { cause: options?.cause });\n        if (options && typeof options.beforeHandshake === 'boolean') {\n            this[kBeforeHandshake] = options.beforeHandshake;\n        }\n    }\n    get name() {\n        return 'MongoNetworkError';\n    }\n}\nexports.MongoNetworkError = MongoNetworkError;\n/**\n * An error indicating a network timeout occurred\n * @public\n * @category Error\n *\n * @privateRemarks\n * mongodb-client-encryption has a dependency on this error with an instanceof check\n */\nclass MongoNetworkTimeoutError extends MongoNetworkError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options) {\n        super(message, options);\n    }\n    get name() {\n        return 'MongoNetworkTimeoutError';\n    }\n}\nexports.MongoNetworkTimeoutError = MongoNetworkTimeoutError;\n/**\n * An error used when attempting to parse a value (like a connection string)\n * @public\n * @category Error\n */\nclass MongoParseError extends MongoDriverError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoParseError';\n    }\n}\nexports.MongoParseError = MongoParseError;\n/**\n * An error generated when the user supplies malformed or unexpected arguments\n * or when a required argument or field is not provided.\n *\n *\n * @public\n * @category Error\n */\nclass MongoInvalidArgumentError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoInvalidArgumentError';\n    }\n}\nexports.MongoInvalidArgumentError = MongoInvalidArgumentError;\n/**\n * An error generated when a feature that is not enabled or allowed for the current server\n * configuration is used\n *\n *\n * @public\n * @category Error\n */\nclass MongoCompatibilityError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoCompatibilityError';\n    }\n}\nexports.MongoCompatibilityError = MongoCompatibilityError;\n/**\n * An error generated when the user fails to provide authentication credentials before attempting\n * to connect to a mongo server instance.\n *\n *\n * @public\n * @category Error\n */\nclass MongoMissingCredentialsError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoMissingCredentialsError';\n    }\n}\nexports.MongoMissingCredentialsError = MongoMissingCredentialsError;\n/**\n * An error generated when a required module or dependency is not present in the local environment\n *\n * @public\n * @category Error\n */\nclass MongoMissingDependencyError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options) {\n        super(message, options);\n        this.dependencyName = options.dependencyName;\n    }\n    get name() {\n        return 'MongoMissingDependencyError';\n    }\n}\nexports.MongoMissingDependencyError = MongoMissingDependencyError;\n/**\n * An error signifying a general system issue\n * @public\n * @category Error\n */\nclass MongoSystemError extends MongoError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, reason) {\n        if (reason && reason.error) {\n            super(MongoError.buildErrorMessage(reason.error.message || reason.error), {\n                cause: reason.error\n            });\n        }\n        else {\n            super(message);\n        }\n        if (reason) {\n            this.reason = reason;\n        }\n        this.code = reason.error?.code;\n    }\n    get name() {\n        return 'MongoSystemError';\n    }\n}\nexports.MongoSystemError = MongoSystemError;\n/**\n * An error signifying a client-side server selection error\n * @public\n * @category Error\n */\nclass MongoServerSelectionError extends MongoSystemError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, reason) {\n        super(message, reason);\n    }\n    get name() {\n        return 'MongoServerSelectionError';\n    }\n}\nexports.MongoServerSelectionError = MongoServerSelectionError;\nfunction makeWriteConcernResultObject(input) {\n    const output = Object.assign({}, input);\n    if (output.ok === 0) {\n        output.ok = 1;\n        delete output.errmsg;\n        delete output.code;\n        delete output.codeName;\n    }\n    return output;\n}\n/**\n * An error thrown when the server reports a writeConcernError\n * @public\n * @category Error\n */\nclass MongoWriteConcernError extends MongoServerError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, result) {\n        if (result && Array.isArray(result.errorLabels)) {\n            message.errorLabels = result.errorLabels;\n        }\n        super(message);\n        this.errInfo = message.errInfo;\n        if (result != null) {\n            this.result = makeWriteConcernResultObject(result);\n        }\n    }\n    get name() {\n        return 'MongoWriteConcernError';\n    }\n}\nexports.MongoWriteConcernError = MongoWriteConcernError;\n// https://github.com/mongodb/specifications/blob/master/source/retryable-reads/retryable-reads.rst#retryable-error\nconst RETRYABLE_READ_ERROR_CODES = new Set([\n    exports.MONGODB_ERROR_CODES.HostUnreachable,\n    exports.MONGODB_ERROR_CODES.HostNotFound,\n    exports.MONGODB_ERROR_CODES.NetworkTimeout,\n    exports.MONGODB_ERROR_CODES.ShutdownInProgress,\n    exports.MONGODB_ERROR_CODES.PrimarySteppedDown,\n    exports.MONGODB_ERROR_CODES.SocketException,\n    exports.MONGODB_ERROR_CODES.NotWritablePrimary,\n    exports.MONGODB_ERROR_CODES.InterruptedAtShutdown,\n    exports.MONGODB_ERROR_CODES.InterruptedDueToReplStateChange,\n    exports.MONGODB_ERROR_CODES.NotPrimaryNoSecondaryOk,\n    exports.MONGODB_ERROR_CODES.NotPrimaryOrSecondary,\n    exports.MONGODB_ERROR_CODES.ExceededTimeLimit\n]);\n// see: https://github.com/mongodb/specifications/blob/master/source/retryable-writes/retryable-writes.rst#terms\nconst RETRYABLE_WRITE_ERROR_CODES = RETRYABLE_READ_ERROR_CODES;\nfunction needsRetryableWriteLabel(error, maxWireVersion) {\n    // pre-4.4 server, then the driver adds an error label for every valid case\n    // execute operation will only inspect the label, code/message logic is handled here\n    if (error instanceof MongoNetworkError) {\n        return true;\n    }\n    if (error instanceof MongoError) {\n        if ((maxWireVersion >= 9 || isRetryableWriteError(error)) &&\n            !error.hasErrorLabel(exports.MongoErrorLabel.HandshakeError)) {\n            // If we already have the error label no need to add it again. 4.4+ servers add the label.\n            // In the case where we have a handshake error, need to fall down to the logic checking\n            // the codes.\n            return false;\n        }\n    }\n    if (error instanceof MongoWriteConcernError) {\n        return RETRYABLE_WRITE_ERROR_CODES.has(error.result?.code ?? error.code ?? 0);\n    }\n    if (error instanceof MongoError && typeof error.code === 'number') {\n        return RETRYABLE_WRITE_ERROR_CODES.has(error.code);\n    }\n    const isNotWritablePrimaryError = exports.LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE.test(error.message);\n    if (isNotWritablePrimaryError) {\n        return true;\n    }\n    const isNodeIsRecoveringError = exports.NODE_IS_RECOVERING_ERROR_MESSAGE.test(error.message);\n    if (isNodeIsRecoveringError) {\n        return true;\n    }\n    return false;\n}\nexports.needsRetryableWriteLabel = needsRetryableWriteLabel;\nfunction isRetryableWriteError(error) {\n    return (error.hasErrorLabel(exports.MongoErrorLabel.RetryableWriteError) ||\n        error.hasErrorLabel(exports.MongoErrorLabel.PoolRequstedRetry));\n}\nexports.isRetryableWriteError = isRetryableWriteError;\n/** Determines whether an error is something the driver should attempt to retry */\nfunction isRetryableReadError(error) {\n    const hasRetryableErrorCode = typeof error.code === 'number' ? RETRYABLE_READ_ERROR_CODES.has(error.code) : false;\n    if (hasRetryableErrorCode) {\n        return true;\n    }\n    if (error instanceof MongoNetworkError) {\n        return true;\n    }\n    const isNotWritablePrimaryError = exports.LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE.test(error.message);\n    if (isNotWritablePrimaryError) {\n        return true;\n    }\n    const isNodeIsRecoveringError = exports.NODE_IS_RECOVERING_ERROR_MESSAGE.test(error.message);\n    if (isNodeIsRecoveringError) {\n        return true;\n    }\n    return false;\n}\nexports.isRetryableReadError = isRetryableReadError;\nconst SDAM_RECOVERING_CODES = new Set([\n    exports.MONGODB_ERROR_CODES.ShutdownInProgress,\n    exports.MONGODB_ERROR_CODES.PrimarySteppedDown,\n    exports.MONGODB_ERROR_CODES.InterruptedAtShutdown,\n    exports.MONGODB_ERROR_CODES.InterruptedDueToReplStateChange,\n    exports.MONGODB_ERROR_CODES.NotPrimaryOrSecondary\n]);\nconst SDAM_NOT_PRIMARY_CODES = new Set([\n    exports.MONGODB_ERROR_CODES.NotWritablePrimary,\n    exports.MONGODB_ERROR_CODES.NotPrimaryNoSecondaryOk,\n    exports.MONGODB_ERROR_CODES.LegacyNotPrimary\n]);\nconst SDAM_NODE_SHUTTING_DOWN_ERROR_CODES = new Set([\n    exports.MONGODB_ERROR_CODES.InterruptedAtShutdown,\n    exports.MONGODB_ERROR_CODES.ShutdownInProgress\n]);\nfunction isRecoveringError(err) {\n    if (typeof err.code === 'number') {\n        // If any error code exists, we ignore the error.message\n        return SDAM_RECOVERING_CODES.has(err.code);\n    }\n    return (exports.LEGACY_NOT_PRIMARY_OR_SECONDARY_ERROR_MESSAGE.test(err.message) ||\n        exports.NODE_IS_RECOVERING_ERROR_MESSAGE.test(err.message));\n}\nfunction isNotWritablePrimaryError(err) {\n    if (typeof err.code === 'number') {\n        // If any error code exists, we ignore the error.message\n        return SDAM_NOT_PRIMARY_CODES.has(err.code);\n    }\n    if (isRecoveringError(err)) {\n        return false;\n    }\n    return exports.LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE.test(err.message);\n}\nfunction isNodeShuttingDownError(err) {\n    return !!(typeof err.code === 'number' && SDAM_NODE_SHUTTING_DOWN_ERROR_CODES.has(err.code));\n}\nexports.isNodeShuttingDownError = isNodeShuttingDownError;\n/**\n * Determines whether SDAM can recover from a given error. If it cannot\n * then the pool will be cleared, and server state will completely reset\n * locally.\n *\n * @see https://github.com/mongodb/specifications/blob/master/source/server-discovery-and-monitoring/server-discovery-and-monitoring.rst#not-master-and-node-is-recovering\n */\nfunction isSDAMUnrecoverableError(error) {\n    // NOTE: null check is here for a strictly pre-CMAP world, a timeout or\n    //       close event are considered unrecoverable\n    if (error instanceof MongoParseError || error == null) {\n        return true;\n    }\n    return isRecoveringError(error) || isNotWritablePrimaryError(error);\n}\nexports.isSDAMUnrecoverableError = isSDAMUnrecoverableError;\nfunction isNetworkTimeoutError(err) {\n    return !!(err instanceof MongoNetworkError && err.message.match(/timed out/));\n}\nexports.isNetworkTimeoutError = isNetworkTimeoutError;\nfunction isResumableError(error, wireVersion) {\n    if (error == null || !(error instanceof MongoError)) {\n        return false;\n    }\n    if (error instanceof MongoNetworkError) {\n        return true;\n    }\n    if (wireVersion != null && wireVersion >= 9) {\n        // DRIVERS-1308: For 4.4 drivers running against 4.4 servers, drivers will add a special case to treat the CursorNotFound error code as resumable\n        if (error.code === exports.MONGODB_ERROR_CODES.CursorNotFound) {\n            return true;\n        }\n        return error.hasErrorLabel(exports.MongoErrorLabel.ResumableChangeStreamError);\n    }\n    if (typeof error.code === 'number') {\n        return exports.GET_MORE_RESUMABLE_CODES.has(error.code);\n    }\n    return false;\n}\nexports.isResumableError = isResumableError;\n//# sourceMappingURL=error.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/error.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/explain.js":
/*!*********************************************!*\
  !*** ./node_modules/mongodb/lib/explain.js ***!
  \*********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Explain = exports.ExplainVerbosity = void 0;\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\n/** @public */\nexports.ExplainVerbosity = Object.freeze({\n    queryPlanner: 'queryPlanner',\n    queryPlannerExtended: 'queryPlannerExtended',\n    executionStats: 'executionStats',\n    allPlansExecution: 'allPlansExecution'\n});\n/** @internal */\nclass Explain {\n    constructor(verbosity) {\n        if (typeof verbosity === 'boolean') {\n            this.verbosity = verbosity\n                ? exports.ExplainVerbosity.allPlansExecution\n                : exports.ExplainVerbosity.queryPlanner;\n        }\n        else {\n            this.verbosity = verbosity;\n        }\n    }\n    static fromOptions(options) {\n        if (options?.explain == null)\n            return;\n        const explain = options.explain;\n        if (typeof explain === 'boolean' || typeof explain === 'string') {\n            return new Explain(explain);\n        }\n        throw new error_1.MongoInvalidArgumentError('Field \"explain\" must be a string or a boolean');\n    }\n}\nexports.Explain = Explain;\n//# sourceMappingURL=explain.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/explain.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/gridfs/download.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongodb/lib/gridfs/download.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.GridFSBucketReadStream = void 0;\nconst stream_1 = __webpack_require__(/*! stream */ \"stream\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\n/**\n * A readable stream that enables you to read buffers from GridFS.\n *\n * Do not instantiate this class directly. Use `openDownloadStream()` instead.\n * @public\n */\nclass GridFSBucketReadStream extends stream_1.Readable {\n    /**\n     * @param chunks - Handle for chunks collection\n     * @param files - Handle for files collection\n     * @param readPreference - The read preference to use\n     * @param filter - The filter to use to find the file document\n     * @internal\n     */\n    constructor(chunks, files, readPreference, filter, options) {\n        super({ emitClose: true });\n        this.s = {\n            bytesToTrim: 0,\n            bytesToSkip: 0,\n            bytesRead: 0,\n            chunks,\n            expected: 0,\n            files,\n            filter,\n            init: false,\n            expectedEnd: 0,\n            options: {\n                start: 0,\n                end: 0,\n                ...options\n            },\n            readPreference\n        };\n    }\n    /**\n     * Reads from the cursor and pushes to the stream.\n     * Private Impl, do not call directly\n     * @internal\n     */\n    _read() {\n        if (this.destroyed)\n            return;\n        waitForFile(this, () => doRead(this));\n    }\n    /**\n     * Sets the 0-based offset in bytes to start streaming from. Throws\n     * an error if this stream has entered flowing mode\n     * (e.g. if you've already called `on('data')`)\n     *\n     * @param start - 0-based offset in bytes to start streaming from\n     */\n    start(start = 0) {\n        throwIfInitialized(this);\n        this.s.options.start = start;\n        return this;\n    }\n    /**\n     * Sets the 0-based offset in bytes to start streaming from. Throws\n     * an error if this stream has entered flowing mode\n     * (e.g. if you've already called `on('data')`)\n     *\n     * @param end - Offset in bytes to stop reading at\n     */\n    end(end = 0) {\n        throwIfInitialized(this);\n        this.s.options.end = end;\n        return this;\n    }\n    /**\n     * Marks this stream as aborted (will never push another `data` event)\n     * and kills the underlying cursor. Will emit the 'end' event, and then\n     * the 'close' event once the cursor is successfully killed.\n     */\n    async abort() {\n        this.push(null);\n        this.destroy();\n        await this.s.cursor?.close();\n    }\n}\n/**\n * Fires when the stream loaded the file document corresponding to the provided id.\n * @event\n */\nGridFSBucketReadStream.FILE = 'file';\nexports.GridFSBucketReadStream = GridFSBucketReadStream;\nfunction throwIfInitialized(stream) {\n    if (stream.s.init) {\n        throw new error_1.MongoGridFSStreamError('Options cannot be changed after the stream is initialized');\n    }\n}\nfunction doRead(stream) {\n    if (stream.destroyed)\n        return;\n    if (!stream.s.cursor)\n        return;\n    if (!stream.s.file)\n        return;\n    const handleReadResult = (doc) => {\n        if (stream.destroyed)\n            return;\n        if (!doc) {\n            stream.push(null);\n            // eslint-disable-next-line github/no-then\n            stream.s.cursor?.close().then(undefined, error => stream.destroy(error));\n            return;\n        }\n        if (!stream.s.file)\n            return;\n        const bytesRemaining = stream.s.file.length - stream.s.bytesRead;\n        const expectedN = stream.s.expected++;\n        const expectedLength = Math.min(stream.s.file.chunkSize, bytesRemaining);\n        if (doc.n > expectedN) {\n            return stream.destroy(new error_1.MongoGridFSChunkError(`ChunkIsMissing: Got unexpected n: ${doc.n}, expected: ${expectedN}`));\n        }\n        if (doc.n < expectedN) {\n            return stream.destroy(new error_1.MongoGridFSChunkError(`ExtraChunk: Got unexpected n: ${doc.n}, expected: ${expectedN}`));\n        }\n        let buf = Buffer.isBuffer(doc.data) ? doc.data : doc.data.buffer;\n        if (buf.byteLength !== expectedLength) {\n            if (bytesRemaining <= 0) {\n                return stream.destroy(new error_1.MongoGridFSChunkError(`ExtraChunk: Got unexpected n: ${doc.n}, expected file length ${stream.s.file.length} bytes but already read ${stream.s.bytesRead} bytes`));\n            }\n            return stream.destroy(new error_1.MongoGridFSChunkError(`ChunkIsWrongSize: Got unexpected length: ${buf.byteLength}, expected: ${expectedLength}`));\n        }\n        stream.s.bytesRead += buf.byteLength;\n        if (buf.byteLength === 0) {\n            return stream.push(null);\n        }\n        let sliceStart = null;\n        let sliceEnd = null;\n        if (stream.s.bytesToSkip != null) {\n            sliceStart = stream.s.bytesToSkip;\n            stream.s.bytesToSkip = 0;\n        }\n        const atEndOfStream = expectedN === stream.s.expectedEnd - 1;\n        const bytesLeftToRead = stream.s.options.end - stream.s.bytesToSkip;\n        if (atEndOfStream && stream.s.bytesToTrim != null) {\n            sliceEnd = stream.s.file.chunkSize - stream.s.bytesToTrim;\n        }\n        else if (stream.s.options.end && bytesLeftToRead < doc.data.byteLength) {\n            sliceEnd = bytesLeftToRead;\n        }\n        if (sliceStart != null || sliceEnd != null) {\n            buf = buf.slice(sliceStart || 0, sliceEnd || buf.byteLength);\n        }\n        stream.push(buf);\n        return;\n    };\n    // eslint-disable-next-line github/no-then\n    stream.s.cursor.next().then(handleReadResult, error => {\n        if (stream.destroyed)\n            return;\n        stream.destroy(error);\n    });\n}\nfunction init(stream) {\n    const findOneOptions = {};\n    if (stream.s.readPreference) {\n        findOneOptions.readPreference = stream.s.readPreference;\n    }\n    if (stream.s.options && stream.s.options.sort) {\n        findOneOptions.sort = stream.s.options.sort;\n    }\n    if (stream.s.options && stream.s.options.skip) {\n        findOneOptions.skip = stream.s.options.skip;\n    }\n    const handleReadResult = (doc) => {\n        if (stream.destroyed)\n            return;\n        if (!doc) {\n            const identifier = stream.s.filter._id\n                ? stream.s.filter._id.toString()\n                : stream.s.filter.filename;\n            const errmsg = `FileNotFound: file ${identifier} was not found`;\n            // TODO(NODE-3483)\n            const err = new error_1.MongoRuntimeError(errmsg);\n            err.code = 'ENOENT'; // TODO: NODE-3338 set property as part of constructor\n            return stream.destroy(err);\n        }\n        // If document is empty, kill the stream immediately and don't\n        // execute any reads\n        if (doc.length <= 0) {\n            stream.push(null);\n            return;\n        }\n        if (stream.destroyed) {\n            // If user destroys the stream before we have a cursor, wait\n            // until the query is done to say we're 'closed' because we can't\n            // cancel a query.\n            stream.destroy();\n            return;\n        }\n        try {\n            stream.s.bytesToSkip = handleStartOption(stream, doc, stream.s.options);\n        }\n        catch (error) {\n            return stream.destroy(error);\n        }\n        const filter = { files_id: doc._id };\n        // Currently (MongoDB 3.4.4) skip function does not support the index,\n        // it needs to retrieve all the documents first and then skip them. (CS-25811)\n        // As work around we use $gte on the \"n\" field.\n        if (stream.s.options && stream.s.options.start != null) {\n            const skip = Math.floor(stream.s.options.start / doc.chunkSize);\n            if (skip > 0) {\n                filter['n'] = { $gte: skip };\n            }\n        }\n        stream.s.cursor = stream.s.chunks.find(filter).sort({ n: 1 });\n        if (stream.s.readPreference) {\n            stream.s.cursor.withReadPreference(stream.s.readPreference);\n        }\n        stream.s.expectedEnd = Math.ceil(doc.length / doc.chunkSize);\n        stream.s.file = doc;\n        try {\n            stream.s.bytesToTrim = handleEndOption(stream, doc, stream.s.cursor, stream.s.options);\n        }\n        catch (error) {\n            return stream.destroy(error);\n        }\n        stream.emit(GridFSBucketReadStream.FILE, doc);\n        return;\n    };\n    // eslint-disable-next-line github/no-then\n    stream.s.files.findOne(stream.s.filter, findOneOptions).then(handleReadResult, error => {\n        if (stream.destroyed)\n            return;\n        stream.destroy(error);\n    });\n}\nfunction waitForFile(stream, callback) {\n    if (stream.s.file) {\n        return callback();\n    }\n    if (!stream.s.init) {\n        init(stream);\n        stream.s.init = true;\n    }\n    stream.once('file', () => {\n        callback();\n    });\n}\nfunction handleStartOption(stream, doc, options) {\n    if (options && options.start != null) {\n        if (options.start > doc.length) {\n            throw new error_1.MongoInvalidArgumentError(`Stream start (${options.start}) must not be more than the length of the file (${doc.length})`);\n        }\n        if (options.start < 0) {\n            throw new error_1.MongoInvalidArgumentError(`Stream start (${options.start}) must not be negative`);\n        }\n        if (options.end != null && options.end < options.start) {\n            throw new error_1.MongoInvalidArgumentError(`Stream start (${options.start}) must not be greater than stream end (${options.end})`);\n        }\n        stream.s.bytesRead = Math.floor(options.start / doc.chunkSize) * doc.chunkSize;\n        stream.s.expected = Math.floor(options.start / doc.chunkSize);\n        return options.start - stream.s.bytesRead;\n    }\n    throw new error_1.MongoInvalidArgumentError('Start option must be defined');\n}\nfunction handleEndOption(stream, doc, cursor, options) {\n    if (options && options.end != null) {\n        if (options.end > doc.length) {\n            throw new error_1.MongoInvalidArgumentError(`Stream end (${options.end}) must not be more than the length of the file (${doc.length})`);\n        }\n        if (options.start == null || options.start < 0) {\n            throw new error_1.MongoInvalidArgumentError(`Stream end (${options.end}) must not be negative`);\n        }\n        const start = options.start != null ? Math.floor(options.start / doc.chunkSize) : 0;\n        cursor.limit(Math.ceil(options.end / doc.chunkSize) - start);\n        stream.s.expectedEnd = Math.ceil(options.end / doc.chunkSize);\n        return Math.ceil(options.end / doc.chunkSize) * doc.chunkSize - options.end;\n    }\n    throw new error_1.MongoInvalidArgumentError('End option must be defined');\n}\n//# sourceMappingURL=download.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/gridfs/download.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/gridfs/index.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/gridfs/index.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.GridFSBucket = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_types_1 = __webpack_require__(/*! ../mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst write_concern_1 = __webpack_require__(/*! ../write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\nconst download_1 = __webpack_require__(/*! ./download */ \"./node_modules/mongodb/lib/gridfs/download.js\");\nconst upload_1 = __webpack_require__(/*! ./upload */ \"./node_modules/mongodb/lib/gridfs/upload.js\");\nconst DEFAULT_GRIDFS_BUCKET_OPTIONS = {\n    bucketName: 'fs',\n    chunkSizeBytes: 255 * 1024\n};\n/**\n * Constructor for a streaming GridFS interface\n * @public\n */\nclass GridFSBucket extends mongo_types_1.TypedEventEmitter {\n    constructor(db, options) {\n        super();\n        this.setMaxListeners(0);\n        const privateOptions = {\n            ...DEFAULT_GRIDFS_BUCKET_OPTIONS,\n            ...options,\n            writeConcern: write_concern_1.WriteConcern.fromOptions(options)\n        };\n        this.s = {\n            db,\n            options: privateOptions,\n            _chunksCollection: db.collection(privateOptions.bucketName + '.chunks'),\n            _filesCollection: db.collection(privateOptions.bucketName + '.files'),\n            checkedIndexes: false,\n            calledOpenUploadStream: false\n        };\n    }\n    /**\n     * Returns a writable stream (GridFSBucketWriteStream) for writing\n     * buffers to GridFS. The stream's 'id' property contains the resulting\n     * file's id.\n     *\n     * @param filename - The value of the 'filename' key in the files doc\n     * @param options - Optional settings.\n     */\n    openUploadStream(filename, options) {\n        return new upload_1.GridFSBucketWriteStream(this, filename, options);\n    }\n    /**\n     * Returns a writable stream (GridFSBucketWriteStream) for writing\n     * buffers to GridFS for a custom file id. The stream's 'id' property contains the resulting\n     * file's id.\n     */\n    openUploadStreamWithId(id, filename, options) {\n        return new upload_1.GridFSBucketWriteStream(this, filename, { ...options, id });\n    }\n    /** Returns a readable stream (GridFSBucketReadStream) for streaming file data from GridFS. */\n    openDownloadStream(id, options) {\n        return new download_1.GridFSBucketReadStream(this.s._chunksCollection, this.s._filesCollection, this.s.options.readPreference, { _id: id }, options);\n    }\n    /**\n     * Deletes a file with the given id\n     *\n     * @param id - The id of the file doc\n     */\n    async delete(id) {\n        const { deletedCount } = await this.s._filesCollection.deleteOne({ _id: id });\n        // Delete orphaned chunks before returning FileNotFound\n        await this.s._chunksCollection.deleteMany({ files_id: id });\n        if (deletedCount === 0) {\n            // TODO(NODE-3483): Replace with more appropriate error\n            // Consider creating new error MongoGridFSFileNotFoundError\n            throw new error_1.MongoRuntimeError(`File not found for id ${id}`);\n        }\n    }\n    /** Convenience wrapper around find on the files collection */\n    find(filter = {}, options = {}) {\n        return this.s._filesCollection.find(filter, options);\n    }\n    /**\n     * Returns a readable stream (GridFSBucketReadStream) for streaming the\n     * file with the given name from GridFS. If there are multiple files with\n     * the same name, this will stream the most recent file with the given name\n     * (as determined by the `uploadDate` field). You can set the `revision`\n     * option to change this behavior.\n     */\n    openDownloadStreamByName(filename, options) {\n        let sort = { uploadDate: -1 };\n        let skip = undefined;\n        if (options && options.revision != null) {\n            if (options.revision >= 0) {\n                sort = { uploadDate: 1 };\n                skip = options.revision;\n            }\n            else {\n                skip = -options.revision - 1;\n            }\n        }\n        return new download_1.GridFSBucketReadStream(this.s._chunksCollection, this.s._filesCollection, this.s.options.readPreference, { filename }, { ...options, sort, skip });\n    }\n    /**\n     * Renames the file with the given _id to the given string\n     *\n     * @param id - the id of the file to rename\n     * @param filename - new name for the file\n     */\n    async rename(id, filename) {\n        const filter = { _id: id };\n        const update = { $set: { filename } };\n        const { matchedCount } = await this.s._filesCollection.updateOne(filter, update);\n        if (matchedCount === 0) {\n            throw new error_1.MongoRuntimeError(`File with id ${id} not found`);\n        }\n    }\n    /** Removes this bucket's files collection, followed by its chunks collection. */\n    async drop() {\n        await this.s._filesCollection.drop();\n        await this.s._chunksCollection.drop();\n    }\n}\n/**\n * When the first call to openUploadStream is made, the upload stream will\n * check to see if it needs to create the proper indexes on the chunks and\n * files collections. This event is fired either when 1) it determines that\n * no index creation is necessary, 2) when it successfully creates the\n * necessary indexes.\n * @event\n */\nGridFSBucket.INDEX = 'index';\nexports.GridFSBucket = GridFSBucket;\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/gridfs/index.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/gridfs/upload.js":
/*!***************************************************!*\
  !*** ./node_modules/mongodb/lib/gridfs/upload.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.GridFSBucketWriteStream = void 0;\nconst stream_1 = __webpack_require__(/*! stream */ \"stream\");\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst write_concern_1 = __webpack_require__(/*! ./../write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\n/**\n * A writable stream that enables you to write buffers to GridFS.\n *\n * Do not instantiate this class directly. Use `openUploadStream()` instead.\n * @public\n */\nclass GridFSBucketWriteStream extends stream_1.Writable {\n    /**\n     * @param bucket - Handle for this stream's corresponding bucket\n     * @param filename - The value of the 'filename' key in the files doc\n     * @param options - Optional settings.\n     * @internal\n     */\n    constructor(bucket, filename, options) {\n        super();\n        /**\n         * The document containing information about the inserted file.\n         * This property is defined _after_ the finish event has been emitted.\n         * It will remain `null` if an error occurs.\n         *\n         * @example\n         * ```ts\n         * fs.createReadStream('file.txt')\n         *   .pipe(bucket.openUploadStream('file.txt'))\n         *   .on('finish', function () {\n         *     console.log(this.gridFSFile)\n         *   })\n         * ```\n         */\n        this.gridFSFile = null;\n        options = options ?? {};\n        this.bucket = bucket;\n        this.chunks = bucket.s._chunksCollection;\n        this.filename = filename;\n        this.files = bucket.s._filesCollection;\n        this.options = options;\n        this.writeConcern = write_concern_1.WriteConcern.fromOptions(options) || bucket.s.options.writeConcern;\n        // Signals the write is all done\n        this.done = false;\n        this.id = options.id ? options.id : new bson_1.ObjectId();\n        // properly inherit the default chunksize from parent\n        this.chunkSizeBytes = options.chunkSizeBytes || this.bucket.s.options.chunkSizeBytes;\n        this.bufToStore = Buffer.alloc(this.chunkSizeBytes);\n        this.length = 0;\n        this.n = 0;\n        this.pos = 0;\n        this.state = {\n            streamEnd: false,\n            outstandingRequests: 0,\n            errored: false,\n            aborted: false\n        };\n        if (!this.bucket.s.calledOpenUploadStream) {\n            this.bucket.s.calledOpenUploadStream = true;\n            // eslint-disable-next-line github/no-then\n            checkIndexes(this).then(() => {\n                this.bucket.s.checkedIndexes = true;\n                this.bucket.emit('index');\n            }, utils_1.squashError);\n        }\n    }\n    /**\n     * @internal\n     *\n     * The stream is considered constructed when the indexes are done being created\n     */\n    _construct(callback) {\n        if (this.bucket.s.checkedIndexes) {\n            return process.nextTick(callback);\n        }\n        this.bucket.once('index', callback);\n    }\n    /**\n     * @internal\n     * Write a buffer to the stream.\n     *\n     * @param chunk - Buffer to write\n     * @param encoding - Optional encoding for the buffer\n     * @param callback - Function to call when the chunk was added to the buffer, or if the entire chunk was persisted to MongoDB if this chunk caused a flush.\n     */\n    _write(chunk, encoding, callback) {\n        doWrite(this, chunk, encoding, callback);\n    }\n    /** @internal */\n    _final(callback) {\n        if (this.state.streamEnd) {\n            return process.nextTick(callback);\n        }\n        this.state.streamEnd = true;\n        writeRemnant(this, callback);\n    }\n    /**\n     * Places this write stream into an aborted state (all future writes fail)\n     * and deletes all chunks that have already been written.\n     */\n    async abort() {\n        if (this.state.streamEnd) {\n            // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n            throw new error_1.MongoAPIError('Cannot abort a stream that has already completed');\n        }\n        if (this.state.aborted) {\n            // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n            throw new error_1.MongoAPIError('Cannot call abort() on a stream twice');\n        }\n        this.state.aborted = true;\n        await this.chunks.deleteMany({ files_id: this.id });\n    }\n}\nexports.GridFSBucketWriteStream = GridFSBucketWriteStream;\nfunction handleError(stream, error, callback) {\n    if (stream.state.errored) {\n        process.nextTick(callback);\n        return;\n    }\n    stream.state.errored = true;\n    process.nextTick(callback, error);\n}\nfunction createChunkDoc(filesId, n, data) {\n    return {\n        _id: new bson_1.ObjectId(),\n        files_id: filesId,\n        n,\n        data\n    };\n}\nasync function checkChunksIndex(stream) {\n    const index = { files_id: 1, n: 1 };\n    let indexes;\n    try {\n        indexes = await stream.chunks.listIndexes().toArray();\n    }\n    catch (error) {\n        if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n            indexes = [];\n        }\n        else {\n            throw error;\n        }\n    }\n    const hasChunksIndex = !!indexes.find(index => {\n        const keys = Object.keys(index.key);\n        if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {\n            return true;\n        }\n        return false;\n    });\n    if (!hasChunksIndex) {\n        await stream.chunks.createIndex(index, {\n            ...stream.writeConcern,\n            background: true,\n            unique: true\n        });\n    }\n}\nfunction checkDone(stream, callback) {\n    if (stream.done) {\n        return process.nextTick(callback);\n    }\n    if (stream.state.streamEnd && stream.state.outstandingRequests === 0 && !stream.state.errored) {\n        // Set done so we do not trigger duplicate createFilesDoc\n        stream.done = true;\n        // Create a new files doc\n        const gridFSFile = createFilesDoc(stream.id, stream.length, stream.chunkSizeBytes, stream.filename, stream.options.contentType, stream.options.aliases, stream.options.metadata);\n        if (isAborted(stream, callback)) {\n            return;\n        }\n        // eslint-disable-next-line github/no-then\n        stream.files.insertOne(gridFSFile, { writeConcern: stream.writeConcern }).then(() => {\n            stream.gridFSFile = gridFSFile;\n            callback();\n        }, error => handleError(stream, error, callback));\n        return;\n    }\n    process.nextTick(callback);\n}\nasync function checkIndexes(stream) {\n    const doc = await stream.files.findOne({}, { projection: { _id: 1 } });\n    if (doc != null) {\n        // If at least one document exists assume the collection has the required index\n        return;\n    }\n    const index = { filename: 1, uploadDate: 1 };\n    let indexes;\n    try {\n        indexes = await stream.files.listIndexes().toArray();\n    }\n    catch (error) {\n        if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n            indexes = [];\n        }\n        else {\n            throw error;\n        }\n    }\n    const hasFileIndex = !!indexes.find(index => {\n        const keys = Object.keys(index.key);\n        if (keys.length === 2 && index.key.filename === 1 && index.key.uploadDate === 1) {\n            return true;\n        }\n        return false;\n    });\n    if (!hasFileIndex) {\n        await stream.files.createIndex(index, { background: false });\n    }\n    await checkChunksIndex(stream);\n}\nfunction createFilesDoc(_id, length, chunkSize, filename, contentType, aliases, metadata) {\n    const ret = {\n        _id,\n        length,\n        chunkSize,\n        uploadDate: new Date(),\n        filename\n    };\n    if (contentType) {\n        ret.contentType = contentType;\n    }\n    if (aliases) {\n        ret.aliases = aliases;\n    }\n    if (metadata) {\n        ret.metadata = metadata;\n    }\n    return ret;\n}\nfunction doWrite(stream, chunk, encoding, callback) {\n    if (isAborted(stream, callback)) {\n        return;\n    }\n    const inputBuf = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);\n    stream.length += inputBuf.length;\n    // Input is small enough to fit in our buffer\n    if (stream.pos + inputBuf.length < stream.chunkSizeBytes) {\n        inputBuf.copy(stream.bufToStore, stream.pos);\n        stream.pos += inputBuf.length;\n        process.nextTick(callback);\n        return;\n    }\n    // Otherwise, buffer is too big for current chunk, so we need to flush\n    // to MongoDB.\n    let inputBufRemaining = inputBuf.length;\n    let spaceRemaining = stream.chunkSizeBytes - stream.pos;\n    let numToCopy = Math.min(spaceRemaining, inputBuf.length);\n    let outstandingRequests = 0;\n    while (inputBufRemaining > 0) {\n        const inputBufPos = inputBuf.length - inputBufRemaining;\n        inputBuf.copy(stream.bufToStore, stream.pos, inputBufPos, inputBufPos + numToCopy);\n        stream.pos += numToCopy;\n        spaceRemaining -= numToCopy;\n        let doc;\n        if (spaceRemaining === 0) {\n            doc = createChunkDoc(stream.id, stream.n, Buffer.from(stream.bufToStore));\n            ++stream.state.outstandingRequests;\n            ++outstandingRequests;\n            if (isAborted(stream, callback)) {\n                return;\n            }\n            // eslint-disable-next-line github/no-then\n            stream.chunks.insertOne(doc, { writeConcern: stream.writeConcern }).then(() => {\n                --stream.state.outstandingRequests;\n                --outstandingRequests;\n                if (!outstandingRequests) {\n                    checkDone(stream, callback);\n                }\n            }, error => handleError(stream, error, callback));\n            spaceRemaining = stream.chunkSizeBytes;\n            stream.pos = 0;\n            ++stream.n;\n        }\n        inputBufRemaining -= numToCopy;\n        numToCopy = Math.min(spaceRemaining, inputBufRemaining);\n    }\n}\nfunction writeRemnant(stream, callback) {\n    // Buffer is empty, so don't bother to insert\n    if (stream.pos === 0) {\n        return checkDone(stream, callback);\n    }\n    ++stream.state.outstandingRequests;\n    // Create a new buffer to make sure the buffer isn't bigger than it needs\n    // to be.\n    const remnant = Buffer.alloc(stream.pos);\n    stream.bufToStore.copy(remnant, 0, 0, stream.pos);\n    const doc = createChunkDoc(stream.id, stream.n, remnant);\n    // If the stream was aborted, do not write remnant\n    if (isAborted(stream, callback)) {\n        return;\n    }\n    // eslint-disable-next-line github/no-then\n    stream.chunks.insertOne(doc, { writeConcern: stream.writeConcern }).then(() => {\n        --stream.state.outstandingRequests;\n        checkDone(stream, callback);\n    }, error => handleError(stream, error, callback));\n}\nfunction isAborted(stream, callback) {\n    if (stream.state.aborted) {\n        process.nextTick(callback, new error_1.MongoAPIError('Stream has been aborted'));\n        return true;\n    }\n    return false;\n}\n//# sourceMappingURL=upload.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/gridfs/upload.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/index.js":
/*!*******************************************!*\
  !*** ./node_modules/mongodb/lib/index.js ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoTopologyClosedError = exports.MongoTailableCursorError = exports.MongoSystemError = exports.MongoServerSelectionError = exports.MongoServerError = exports.MongoServerClosedError = exports.MongoRuntimeError = exports.MongoParseError = exports.MongoOIDCError = exports.MongoNotConnectedError = exports.MongoNetworkTimeoutError = exports.MongoNetworkError = exports.MongoMissingDependencyError = exports.MongoMissingCredentialsError = exports.MongoKerberosError = exports.MongoInvalidArgumentError = exports.MongoGridFSStreamError = exports.MongoGridFSChunkError = exports.MongoGCPError = exports.MongoExpiredSessionError = exports.MongoError = exports.MongoDriverError = exports.MongoDecompressionError = exports.MongoCursorInUseError = exports.MongoCursorExhaustedError = exports.MongoCompatibilityError = exports.MongoChangeStreamError = exports.MongoBatchReExecutionError = exports.MongoAzureError = exports.MongoAWSError = exports.MongoAPIError = exports.ChangeStreamCursor = exports.ClientEncryption = exports.MongoBulkWriteError = exports.UUID = exports.Timestamp = exports.ObjectId = exports.MinKey = exports.MaxKey = exports.Long = exports.Int32 = exports.Double = exports.Decimal128 = exports.DBRef = exports.Code = exports.BSONType = exports.BSONSymbol = exports.BSONRegExp = exports.Binary = exports.BSON = void 0;\nexports.ConnectionPoolCreatedEvent = exports.ConnectionPoolClosedEvent = exports.ConnectionPoolClearedEvent = exports.ConnectionCreatedEvent = exports.ConnectionClosedEvent = exports.ConnectionCheckOutStartedEvent = exports.ConnectionCheckOutFailedEvent = exports.ConnectionCheckedOutEvent = exports.ConnectionCheckedInEvent = exports.CommandSucceededEvent = exports.CommandStartedEvent = exports.CommandFailedEvent = exports.WriteConcern = exports.ReadPreference = exports.ReadConcern = exports.TopologyType = exports.ServerType = exports.ReadPreferenceMode = exports.ReadConcernLevel = exports.ProfilingLevel = exports.ReturnDocument = exports.ServerApiVersion = exports.ExplainVerbosity = exports.MongoErrorLabel = exports.CURSOR_FLAGS = exports.Compressor = exports.AuthMechanism = exports.GSSAPICanonicalizationValue = exports.AutoEncryptionLoggerLevel = exports.BatchType = exports.UnorderedBulkOperation = exports.OrderedBulkOperation = exports.MongoClient = exports.ListIndexesCursor = exports.ListCollectionsCursor = exports.GridFSBucketWriteStream = exports.GridFSBucketReadStream = exports.GridFSBucket = exports.FindCursor = exports.Db = exports.Collection = exports.ClientSession = exports.ChangeStream = exports.CancellationToken = exports.AggregationCursor = exports.Admin = exports.AbstractCursor = exports.MongoWriteConcernError = exports.MongoUnexpectedServerResponseError = exports.MongoTransactionError = void 0;\nexports.MongoClientAuthProviders = exports.MongoCryptKMSRequestNetworkTimeoutError = exports.MongoCryptInvalidArgumentError = exports.MongoCryptError = exports.MongoCryptCreateEncryptedCollectionError = exports.MongoCryptCreateDataKeyError = exports.MongoCryptAzureKMSRequestError = exports.SrvPollingEvent = exports.WaitingForSuitableServerEvent = exports.ServerSelectionSucceededEvent = exports.ServerSelectionStartedEvent = exports.ServerSelectionFailedEvent = exports.ServerSelectionEvent = exports.TopologyOpeningEvent = exports.TopologyDescriptionChangedEvent = exports.TopologyClosedEvent = exports.ServerOpeningEvent = exports.ServerHeartbeatSucceededEvent = exports.ServerHeartbeatStartedEvent = exports.ServerHeartbeatFailedEvent = exports.ServerDescriptionChangedEvent = exports.ServerClosedEvent = exports.ConnectionReadyEvent = exports.ConnectionPoolReadyEvent = exports.ConnectionPoolMonitoringEvent = void 0;\nconst admin_1 = __webpack_require__(/*! ./admin */ \"./node_modules/mongodb/lib/admin.js\");\nObject.defineProperty(exports, \"Admin\", ({ enumerable: true, get: function () { return admin_1.Admin; } }));\nconst ordered_1 = __webpack_require__(/*! ./bulk/ordered */ \"./node_modules/mongodb/lib/bulk/ordered.js\");\nObject.defineProperty(exports, \"OrderedBulkOperation\", ({ enumerable: true, get: function () { return ordered_1.OrderedBulkOperation; } }));\nconst unordered_1 = __webpack_require__(/*! ./bulk/unordered */ \"./node_modules/mongodb/lib/bulk/unordered.js\");\nObject.defineProperty(exports, \"UnorderedBulkOperation\", ({ enumerable: true, get: function () { return unordered_1.UnorderedBulkOperation; } }));\nconst change_stream_1 = __webpack_require__(/*! ./change_stream */ \"./node_modules/mongodb/lib/change_stream.js\");\nObject.defineProperty(exports, \"ChangeStream\", ({ enumerable: true, get: function () { return change_stream_1.ChangeStream; } }));\nconst collection_1 = __webpack_require__(/*! ./collection */ \"./node_modules/mongodb/lib/collection.js\");\nObject.defineProperty(exports, \"Collection\", ({ enumerable: true, get: function () { return collection_1.Collection; } }));\nconst abstract_cursor_1 = __webpack_require__(/*! ./cursor/abstract_cursor */ \"./node_modules/mongodb/lib/cursor/abstract_cursor.js\");\nObject.defineProperty(exports, \"AbstractCursor\", ({ enumerable: true, get: function () { return abstract_cursor_1.AbstractCursor; } }));\nconst aggregation_cursor_1 = __webpack_require__(/*! ./cursor/aggregation_cursor */ \"./node_modules/mongodb/lib/cursor/aggregation_cursor.js\");\nObject.defineProperty(exports, \"AggregationCursor\", ({ enumerable: true, get: function () { return aggregation_cursor_1.AggregationCursor; } }));\nconst find_cursor_1 = __webpack_require__(/*! ./cursor/find_cursor */ \"./node_modules/mongodb/lib/cursor/find_cursor.js\");\nObject.defineProperty(exports, \"FindCursor\", ({ enumerable: true, get: function () { return find_cursor_1.FindCursor; } }));\nconst list_collections_cursor_1 = __webpack_require__(/*! ./cursor/list_collections_cursor */ \"./node_modules/mongodb/lib/cursor/list_collections_cursor.js\");\nObject.defineProperty(exports, \"ListCollectionsCursor\", ({ enumerable: true, get: function () { return list_collections_cursor_1.ListCollectionsCursor; } }));\nconst list_indexes_cursor_1 = __webpack_require__(/*! ./cursor/list_indexes_cursor */ \"./node_modules/mongodb/lib/cursor/list_indexes_cursor.js\");\nObject.defineProperty(exports, \"ListIndexesCursor\", ({ enumerable: true, get: function () { return list_indexes_cursor_1.ListIndexesCursor; } }));\nconst db_1 = __webpack_require__(/*! ./db */ \"./node_modules/mongodb/lib/db.js\");\nObject.defineProperty(exports, \"Db\", ({ enumerable: true, get: function () { return db_1.Db; } }));\nconst gridfs_1 = __webpack_require__(/*! ./gridfs */ \"./node_modules/mongodb/lib/gridfs/index.js\");\nObject.defineProperty(exports, \"GridFSBucket\", ({ enumerable: true, get: function () { return gridfs_1.GridFSBucket; } }));\nconst download_1 = __webpack_require__(/*! ./gridfs/download */ \"./node_modules/mongodb/lib/gridfs/download.js\");\nObject.defineProperty(exports, \"GridFSBucketReadStream\", ({ enumerable: true, get: function () { return download_1.GridFSBucketReadStream; } }));\nconst upload_1 = __webpack_require__(/*! ./gridfs/upload */ \"./node_modules/mongodb/lib/gridfs/upload.js\");\nObject.defineProperty(exports, \"GridFSBucketWriteStream\", ({ enumerable: true, get: function () { return upload_1.GridFSBucketWriteStream; } }));\nconst mongo_client_1 = __webpack_require__(/*! ./mongo_client */ \"./node_modules/mongodb/lib/mongo_client.js\");\nObject.defineProperty(exports, \"MongoClient\", ({ enumerable: true, get: function () { return mongo_client_1.MongoClient; } }));\nconst mongo_types_1 = __webpack_require__(/*! ./mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nObject.defineProperty(exports, \"CancellationToken\", ({ enumerable: true, get: function () { return mongo_types_1.CancellationToken; } }));\nconst sessions_1 = __webpack_require__(/*! ./sessions */ \"./node_modules/mongodb/lib/sessions.js\");\nObject.defineProperty(exports, \"ClientSession\", ({ enumerable: true, get: function () { return sessions_1.ClientSession; } }));\n/** @public */\nvar bson_1 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nObject.defineProperty(exports, \"BSON\", ({ enumerable: true, get: function () { return bson_1.BSON; } }));\nvar bson_2 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nObject.defineProperty(exports, \"Binary\", ({ enumerable: true, get: function () { return bson_2.Binary; } }));\nObject.defineProperty(exports, \"BSONRegExp\", ({ enumerable: true, get: function () { return bson_2.BSONRegExp; } }));\nObject.defineProperty(exports, \"BSONSymbol\", ({ enumerable: true, get: function () { return bson_2.BSONSymbol; } }));\nObject.defineProperty(exports, \"BSONType\", ({ enumerable: true, get: function () { return bson_2.BSONType; } }));\nObject.defineProperty(exports, \"Code\", ({ enumerable: true, get: function () { return bson_2.Code; } }));\nObject.defineProperty(exports, \"DBRef\", ({ enumerable: true, get: function () { return bson_2.DBRef; } }));\nObject.defineProperty(exports, \"Decimal128\", ({ enumerable: true, get: function () { return bson_2.Decimal128; } }));\nObject.defineProperty(exports, \"Double\", ({ enumerable: true, get: function () { return bson_2.Double; } }));\nObject.defineProperty(exports, \"Int32\", ({ enumerable: true, get: function () { return bson_2.Int32; } }));\nObject.defineProperty(exports, \"Long\", ({ enumerable: true, get: function () { return bson_2.Long; } }));\nObject.defineProperty(exports, \"MaxKey\", ({ enumerable: true, get: function () { return bson_2.MaxKey; } }));\nObject.defineProperty(exports, \"MinKey\", ({ enumerable: true, get: function () { return bson_2.MinKey; } }));\nObject.defineProperty(exports, \"ObjectId\", ({ enumerable: true, get: function () { return bson_2.ObjectId; } }));\nObject.defineProperty(exports, \"Timestamp\", ({ enumerable: true, get: function () { return bson_2.Timestamp; } }));\nObject.defineProperty(exports, \"UUID\", ({ enumerable: true, get: function () { return bson_2.UUID; } }));\nvar common_1 = __webpack_require__(/*! ./bulk/common */ \"./node_modules/mongodb/lib/bulk/common.js\");\nObject.defineProperty(exports, \"MongoBulkWriteError\", ({ enumerable: true, get: function () { return common_1.MongoBulkWriteError; } }));\nvar client_encryption_1 = __webpack_require__(/*! ./client-side-encryption/client_encryption */ \"./node_modules/mongodb/lib/client-side-encryption/client_encryption.js\");\nObject.defineProperty(exports, \"ClientEncryption\", ({ enumerable: true, get: function () { return client_encryption_1.ClientEncryption; } }));\nvar change_stream_cursor_1 = __webpack_require__(/*! ./cursor/change_stream_cursor */ \"./node_modules/mongodb/lib/cursor/change_stream_cursor.js\");\nObject.defineProperty(exports, \"ChangeStreamCursor\", ({ enumerable: true, get: function () { return change_stream_cursor_1.ChangeStreamCursor; } }));\nvar error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nObject.defineProperty(exports, \"MongoAPIError\", ({ enumerable: true, get: function () { return error_1.MongoAPIError; } }));\nObject.defineProperty(exports, \"MongoAWSError\", ({ enumerable: true, get: function () { return error_1.MongoAWSError; } }));\nObject.defineProperty(exports, \"MongoAzureError\", ({ enumerable: true, get: function () { return error_1.MongoAzureError; } }));\nObject.defineProperty(exports, \"MongoBatchReExecutionError\", ({ enumerable: true, get: function () { return error_1.MongoBatchReExecutionError; } }));\nObject.defineProperty(exports, \"MongoChangeStreamError\", ({ enumerable: true, get: function () { return error_1.MongoChangeStreamError; } }));\nObject.defineProperty(exports, \"MongoCompatibilityError\", ({ enumerable: true, get: function () { return error_1.MongoCompatibilityError; } }));\nObject.defineProperty(exports, \"MongoCursorExhaustedError\", ({ enumerable: true, get: function () { return error_1.MongoCursorExhaustedError; } }));\nObject.defineProperty(exports, \"MongoCursorInUseError\", ({ enumerable: true, get: function () { return error_1.MongoCursorInUseError; } }));\nObject.defineProperty(exports, \"MongoDecompressionError\", ({ enumerable: true, get: function () { return error_1.MongoDecompressionError; } }));\nObject.defineProperty(exports, \"MongoDriverError\", ({ enumerable: true, get: function () { return error_1.MongoDriverError; } }));\nObject.defineProperty(exports, \"MongoError\", ({ enumerable: true, get: function () { return error_1.MongoError; } }));\nObject.defineProperty(exports, \"MongoExpiredSessionError\", ({ enumerable: true, get: function () { return error_1.MongoExpiredSessionError; } }));\nObject.defineProperty(exports, \"MongoGCPError\", ({ enumerable: true, get: function () { return error_1.MongoGCPError; } }));\nObject.defineProperty(exports, \"MongoGridFSChunkError\", ({ enumerable: true, get: function () { return error_1.MongoGridFSChunkError; } }));\nObject.defineProperty(exports, \"MongoGridFSStreamError\", ({ enumerable: true, get: function () { return error_1.MongoGridFSStreamError; } }));\nObject.defineProperty(exports, \"MongoInvalidArgumentError\", ({ enumerable: true, get: function () { return error_1.MongoInvalidArgumentError; } }));\nObject.defineProperty(exports, \"MongoKerberosError\", ({ enumerable: true, get: function () { return error_1.MongoKerberosError; } }));\nObject.defineProperty(exports, \"MongoMissingCredentialsError\", ({ enumerable: true, get: function () { return error_1.MongoMissingCredentialsError; } }));\nObject.defineProperty(exports, \"MongoMissingDependencyError\", ({ enumerable: true, get: function () { return error_1.MongoMissingDependencyError; } }));\nObject.defineProperty(exports, \"MongoNetworkError\", ({ enumerable: true, get: function () { return error_1.MongoNetworkError; } }));\nObject.defineProperty(exports, \"MongoNetworkTimeoutError\", ({ enumerable: true, get: function () { return error_1.MongoNetworkTimeoutError; } }));\nObject.defineProperty(exports, \"MongoNotConnectedError\", ({ enumerable: true, get: function () { return error_1.MongoNotConnectedError; } }));\nObject.defineProperty(exports, \"MongoOIDCError\", ({ enumerable: true, get: function () { return error_1.MongoOIDCError; } }));\nObject.defineProperty(exports, \"MongoParseError\", ({ enumerable: true, get: function () { return error_1.MongoParseError; } }));\nObject.defineProperty(exports, \"MongoRuntimeError\", ({ enumerable: true, get: function () { return error_1.MongoRuntimeError; } }));\nObject.defineProperty(exports, \"MongoServerClosedError\", ({ enumerable: true, get: function () { return error_1.MongoServerClosedError; } }));\nObject.defineProperty(exports, \"MongoServerError\", ({ enumerable: true, get: function () { return error_1.MongoServerError; } }));\nObject.defineProperty(exports, \"MongoServerSelectionError\", ({ enumerable: true, get: function () { return error_1.MongoServerSelectionError; } }));\nObject.defineProperty(exports, \"MongoSystemError\", ({ enumerable: true, get: function () { return error_1.MongoSystemError; } }));\nObject.defineProperty(exports, \"MongoTailableCursorError\", ({ enumerable: true, get: function () { return error_1.MongoTailableCursorError; } }));\nObject.defineProperty(exports, \"MongoTopologyClosedError\", ({ enumerable: true, get: function () { return error_1.MongoTopologyClosedError; } }));\nObject.defineProperty(exports, \"MongoTransactionError\", ({ enumerable: true, get: function () { return error_1.MongoTransactionError; } }));\nObject.defineProperty(exports, \"MongoUnexpectedServerResponseError\", ({ enumerable: true, get: function () { return error_1.MongoUnexpectedServerResponseError; } }));\nObject.defineProperty(exports, \"MongoWriteConcernError\", ({ enumerable: true, get: function () { return error_1.MongoWriteConcernError; } }));\n// enums\nvar common_2 = __webpack_require__(/*! ./bulk/common */ \"./node_modules/mongodb/lib/bulk/common.js\");\nObject.defineProperty(exports, \"BatchType\", ({ enumerable: true, get: function () { return common_2.BatchType; } }));\nvar auto_encrypter_1 = __webpack_require__(/*! ./client-side-encryption/auto_encrypter */ \"./node_modules/mongodb/lib/client-side-encryption/auto_encrypter.js\");\nObject.defineProperty(exports, \"AutoEncryptionLoggerLevel\", ({ enumerable: true, get: function () { return auto_encrypter_1.AutoEncryptionLoggerLevel; } }));\nvar gssapi_1 = __webpack_require__(/*! ./cmap/auth/gssapi */ \"./node_modules/mongodb/lib/cmap/auth/gssapi.js\");\nObject.defineProperty(exports, \"GSSAPICanonicalizationValue\", ({ enumerable: true, get: function () { return gssapi_1.GSSAPICanonicalizationValue; } }));\nvar providers_1 = __webpack_require__(/*! ./cmap/auth/providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\nObject.defineProperty(exports, \"AuthMechanism\", ({ enumerable: true, get: function () { return providers_1.AuthMechanism; } }));\nvar compression_1 = __webpack_require__(/*! ./cmap/wire_protocol/compression */ \"./node_modules/mongodb/lib/cmap/wire_protocol/compression.js\");\nObject.defineProperty(exports, \"Compressor\", ({ enumerable: true, get: function () { return compression_1.Compressor; } }));\nvar abstract_cursor_2 = __webpack_require__(/*! ./cursor/abstract_cursor */ \"./node_modules/mongodb/lib/cursor/abstract_cursor.js\");\nObject.defineProperty(exports, \"CURSOR_FLAGS\", ({ enumerable: true, get: function () { return abstract_cursor_2.CURSOR_FLAGS; } }));\nvar error_2 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nObject.defineProperty(exports, \"MongoErrorLabel\", ({ enumerable: true, get: function () { return error_2.MongoErrorLabel; } }));\nvar explain_1 = __webpack_require__(/*! ./explain */ \"./node_modules/mongodb/lib/explain.js\");\nObject.defineProperty(exports, \"ExplainVerbosity\", ({ enumerable: true, get: function () { return explain_1.ExplainVerbosity; } }));\nvar mongo_client_2 = __webpack_require__(/*! ./mongo_client */ \"./node_modules/mongodb/lib/mongo_client.js\");\nObject.defineProperty(exports, \"ServerApiVersion\", ({ enumerable: true, get: function () { return mongo_client_2.ServerApiVersion; } }));\nvar find_and_modify_1 = __webpack_require__(/*! ./operations/find_and_modify */ \"./node_modules/mongodb/lib/operations/find_and_modify.js\");\nObject.defineProperty(exports, \"ReturnDocument\", ({ enumerable: true, get: function () { return find_and_modify_1.ReturnDocument; } }));\nvar set_profiling_level_1 = __webpack_require__(/*! ./operations/set_profiling_level */ \"./node_modules/mongodb/lib/operations/set_profiling_level.js\");\nObject.defineProperty(exports, \"ProfilingLevel\", ({ enumerable: true, get: function () { return set_profiling_level_1.ProfilingLevel; } }));\nvar read_concern_1 = __webpack_require__(/*! ./read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nObject.defineProperty(exports, \"ReadConcernLevel\", ({ enumerable: true, get: function () { return read_concern_1.ReadConcernLevel; } }));\nvar read_preference_1 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nObject.defineProperty(exports, \"ReadPreferenceMode\", ({ enumerable: true, get: function () { return read_preference_1.ReadPreferenceMode; } }));\nvar common_3 = __webpack_require__(/*! ./sdam/common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nObject.defineProperty(exports, \"ServerType\", ({ enumerable: true, get: function () { return common_3.ServerType; } }));\nObject.defineProperty(exports, \"TopologyType\", ({ enumerable: true, get: function () { return common_3.TopologyType; } }));\n// Helper classes\nvar read_concern_2 = __webpack_require__(/*! ./read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nObject.defineProperty(exports, \"ReadConcern\", ({ enumerable: true, get: function () { return read_concern_2.ReadConcern; } }));\nvar read_preference_2 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nObject.defineProperty(exports, \"ReadPreference\", ({ enumerable: true, get: function () { return read_preference_2.ReadPreference; } }));\nvar write_concern_1 = __webpack_require__(/*! ./write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\nObject.defineProperty(exports, \"WriteConcern\", ({ enumerable: true, get: function () { return write_concern_1.WriteConcern; } }));\n// events\nvar command_monitoring_events_1 = __webpack_require__(/*! ./cmap/command_monitoring_events */ \"./node_modules/mongodb/lib/cmap/command_monitoring_events.js\");\nObject.defineProperty(exports, \"CommandFailedEvent\", ({ enumerable: true, get: function () { return command_monitoring_events_1.CommandFailedEvent; } }));\nObject.defineProperty(exports, \"CommandStartedEvent\", ({ enumerable: true, get: function () { return command_monitoring_events_1.CommandStartedEvent; } }));\nObject.defineProperty(exports, \"CommandSucceededEvent\", ({ enumerable: true, get: function () { return command_monitoring_events_1.CommandSucceededEvent; } }));\nvar connection_pool_events_1 = __webpack_require__(/*! ./cmap/connection_pool_events */ \"./node_modules/mongodb/lib/cmap/connection_pool_events.js\");\nObject.defineProperty(exports, \"ConnectionCheckedInEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionCheckedInEvent; } }));\nObject.defineProperty(exports, \"ConnectionCheckedOutEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionCheckedOutEvent; } }));\nObject.defineProperty(exports, \"ConnectionCheckOutFailedEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionCheckOutFailedEvent; } }));\nObject.defineProperty(exports, \"ConnectionCheckOutStartedEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionCheckOutStartedEvent; } }));\nObject.defineProperty(exports, \"ConnectionClosedEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionClosedEvent; } }));\nObject.defineProperty(exports, \"ConnectionCreatedEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionCreatedEvent; } }));\nObject.defineProperty(exports, \"ConnectionPoolClearedEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionPoolClearedEvent; } }));\nObject.defineProperty(exports, \"ConnectionPoolClosedEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionPoolClosedEvent; } }));\nObject.defineProperty(exports, \"ConnectionPoolCreatedEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionPoolCreatedEvent; } }));\nObject.defineProperty(exports, \"ConnectionPoolMonitoringEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionPoolMonitoringEvent; } }));\nObject.defineProperty(exports, \"ConnectionPoolReadyEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionPoolReadyEvent; } }));\nObject.defineProperty(exports, \"ConnectionReadyEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionReadyEvent; } }));\nvar events_1 = __webpack_require__(/*! ./sdam/events */ \"./node_modules/mongodb/lib/sdam/events.js\");\nObject.defineProperty(exports, \"ServerClosedEvent\", ({ enumerable: true, get: function () { return events_1.ServerClosedEvent; } }));\nObject.defineProperty(exports, \"ServerDescriptionChangedEvent\", ({ enumerable: true, get: function () { return events_1.ServerDescriptionChangedEvent; } }));\nObject.defineProperty(exports, \"ServerHeartbeatFailedEvent\", ({ enumerable: true, get: function () { return events_1.ServerHeartbeatFailedEvent; } }));\nObject.defineProperty(exports, \"ServerHeartbeatStartedEvent\", ({ enumerable: true, get: function () { return events_1.ServerHeartbeatStartedEvent; } }));\nObject.defineProperty(exports, \"ServerHeartbeatSucceededEvent\", ({ enumerable: true, get: function () { return events_1.ServerHeartbeatSucceededEvent; } }));\nObject.defineProperty(exports, \"ServerOpeningEvent\", ({ enumerable: true, get: function () { return events_1.ServerOpeningEvent; } }));\nObject.defineProperty(exports, \"TopologyClosedEvent\", ({ enumerable: true, get: function () { return events_1.TopologyClosedEvent; } }));\nObject.defineProperty(exports, \"TopologyDescriptionChangedEvent\", ({ enumerable: true, get: function () { return events_1.TopologyDescriptionChangedEvent; } }));\nObject.defineProperty(exports, \"TopologyOpeningEvent\", ({ enumerable: true, get: function () { return events_1.TopologyOpeningEvent; } }));\nvar server_selection_events_1 = __webpack_require__(/*! ./sdam/server_selection_events */ \"./node_modules/mongodb/lib/sdam/server_selection_events.js\");\nObject.defineProperty(exports, \"ServerSelectionEvent\", ({ enumerable: true, get: function () { return server_selection_events_1.ServerSelectionEvent; } }));\nObject.defineProperty(exports, \"ServerSelectionFailedEvent\", ({ enumerable: true, get: function () { return server_selection_events_1.ServerSelectionFailedEvent; } }));\nObject.defineProperty(exports, \"ServerSelectionStartedEvent\", ({ enumerable: true, get: function () { return server_selection_events_1.ServerSelectionStartedEvent; } }));\nObject.defineProperty(exports, \"ServerSelectionSucceededEvent\", ({ enumerable: true, get: function () { return server_selection_events_1.ServerSelectionSucceededEvent; } }));\nObject.defineProperty(exports, \"WaitingForSuitableServerEvent\", ({ enumerable: true, get: function () { return server_selection_events_1.WaitingForSuitableServerEvent; } }));\nvar srv_polling_1 = __webpack_require__(/*! ./sdam/srv_polling */ \"./node_modules/mongodb/lib/sdam/srv_polling.js\");\nObject.defineProperty(exports, \"SrvPollingEvent\", ({ enumerable: true, get: function () { return srv_polling_1.SrvPollingEvent; } }));\nvar errors_1 = __webpack_require__(/*! ./client-side-encryption/errors */ \"./node_modules/mongodb/lib/client-side-encryption/errors.js\");\nObject.defineProperty(exports, \"MongoCryptAzureKMSRequestError\", ({ enumerable: true, get: function () { return errors_1.MongoCryptAzureKMSRequestError; } }));\nObject.defineProperty(exports, \"MongoCryptCreateDataKeyError\", ({ enumerable: true, get: function () { return errors_1.MongoCryptCreateDataKeyError; } }));\nObject.defineProperty(exports, \"MongoCryptCreateEncryptedCollectionError\", ({ enumerable: true, get: function () { return errors_1.MongoCryptCreateEncryptedCollectionError; } }));\nObject.defineProperty(exports, \"MongoCryptError\", ({ enumerable: true, get: function () { return errors_1.MongoCryptError; } }));\nObject.defineProperty(exports, \"MongoCryptInvalidArgumentError\", ({ enumerable: true, get: function () { return errors_1.MongoCryptInvalidArgumentError; } }));\nObject.defineProperty(exports, \"MongoCryptKMSRequestNetworkTimeoutError\", ({ enumerable: true, get: function () { return errors_1.MongoCryptKMSRequestNetworkTimeoutError; } }));\nvar mongo_client_auth_providers_1 = __webpack_require__(/*! ./mongo_client_auth_providers */ \"./node_modules/mongodb/lib/mongo_client_auth_providers.js\");\nObject.defineProperty(exports, \"MongoClientAuthProviders\", ({ enumerable: true, get: function () { return mongo_client_auth_providers_1.MongoClientAuthProviders; } }));\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/index.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/mongo_client.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/mongo_client.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoClient = exports.ServerApiVersion = void 0;\nconst fs_1 = __webpack_require__(/*! fs */ \"fs\");\nconst bson_1 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst change_stream_1 = __webpack_require__(/*! ./change_stream */ \"./node_modules/mongodb/lib/change_stream.js\");\nconst mongo_credentials_1 = __webpack_require__(/*! ./cmap/auth/mongo_credentials */ \"./node_modules/mongodb/lib/cmap/auth/mongo_credentials.js\");\nconst providers_1 = __webpack_require__(/*! ./cmap/auth/providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\nconst connection_string_1 = __webpack_require__(/*! ./connection_string */ \"./node_modules/mongodb/lib/connection_string.js\");\nconst constants_1 = __webpack_require__(/*! ./constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst db_1 = __webpack_require__(/*! ./db */ \"./node_modules/mongodb/lib/db.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_client_auth_providers_1 = __webpack_require__(/*! ./mongo_client_auth_providers */ \"./node_modules/mongodb/lib/mongo_client_auth_providers.js\");\nconst mongo_logger_1 = __webpack_require__(/*! ./mongo_logger */ \"./node_modules/mongodb/lib/mongo_logger.js\");\nconst mongo_types_1 = __webpack_require__(/*! ./mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst execute_operation_1 = __webpack_require__(/*! ./operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst run_command_1 = __webpack_require__(/*! ./operations/run_command */ \"./node_modules/mongodb/lib/operations/run_command.js\");\nconst read_preference_1 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst server_selection_1 = __webpack_require__(/*! ./sdam/server_selection */ \"./node_modules/mongodb/lib/sdam/server_selection.js\");\nconst topology_1 = __webpack_require__(/*! ./sdam/topology */ \"./node_modules/mongodb/lib/sdam/topology.js\");\nconst sessions_1 = __webpack_require__(/*! ./sessions */ \"./node_modules/mongodb/lib/sessions.js\");\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/mongodb/lib/utils.js\");\n/** @public */\nexports.ServerApiVersion = Object.freeze({\n    v1: '1'\n});\n/** @internal */\nconst kOptions = Symbol('options');\n/**\n * The **MongoClient** class is a class that allows for making Connections to MongoDB.\n * @public\n *\n * @remarks\n * The programmatically provided options take precedence over the URI options.\n *\n * @example\n * ```ts\n * import { MongoClient } from 'mongodb';\n *\n * // Enable command monitoring for debugging\n * const client = new MongoClient('mongodb://localhost:27017', { monitorCommands: true });\n *\n * client.on('commandStarted', started => console.log(started));\n * client.db().collection('pets');\n * await client.insertOne({ name: 'spot', kind: 'dog' });\n * ```\n */\nclass MongoClient extends mongo_types_1.TypedEventEmitter {\n    constructor(url, options) {\n        super();\n        this[kOptions] = (0, connection_string_1.parseOptions)(url, this, options);\n        const shouldSetLogger = Object.values(this[kOptions].mongoLoggerOptions.componentSeverities).some(value => value !== mongo_logger_1.SeverityLevel.OFF);\n        this.mongoLogger = shouldSetLogger\n            ? new mongo_logger_1.MongoLogger(this[kOptions].mongoLoggerOptions)\n            : undefined;\n        // eslint-disable-next-line @typescript-eslint/no-this-alias\n        const client = this;\n        // The internal state\n        this.s = {\n            url,\n            bsonOptions: (0, bson_1.resolveBSONOptions)(this[kOptions]),\n            namespace: (0, utils_1.ns)('admin'),\n            hasBeenClosed: false,\n            sessionPool: new sessions_1.ServerSessionPool(this),\n            activeSessions: new Set(),\n            authProviders: new mongo_client_auth_providers_1.MongoClientAuthProviders(),\n            get options() {\n                return client[kOptions];\n            },\n            get readConcern() {\n                return client[kOptions].readConcern;\n            },\n            get writeConcern() {\n                return client[kOptions].writeConcern;\n            },\n            get readPreference() {\n                return client[kOptions].readPreference;\n            },\n            get isMongoClient() {\n                return true;\n            }\n        };\n        this.checkForNonGenuineHosts();\n    }\n    /** @internal */\n    checkForNonGenuineHosts() {\n        const documentDBHostnames = this[kOptions].hosts.filter((hostAddress) => (0, utils_1.isHostMatch)(utils_1.DOCUMENT_DB_CHECK, hostAddress.host));\n        const srvHostIsDocumentDB = (0, utils_1.isHostMatch)(utils_1.DOCUMENT_DB_CHECK, this[kOptions].srvHost);\n        const cosmosDBHostnames = this[kOptions].hosts.filter((hostAddress) => (0, utils_1.isHostMatch)(utils_1.COSMOS_DB_CHECK, hostAddress.host));\n        const srvHostIsCosmosDB = (0, utils_1.isHostMatch)(utils_1.COSMOS_DB_CHECK, this[kOptions].srvHost);\n        if (documentDBHostnames.length !== 0 || srvHostIsDocumentDB) {\n            this.mongoLogger?.info('client', utils_1.DOCUMENT_DB_MSG);\n        }\n        else if (cosmosDBHostnames.length !== 0 || srvHostIsCosmosDB) {\n            this.mongoLogger?.info('client', utils_1.COSMOS_DB_MSG);\n        }\n    }\n    /** @see MongoOptions */\n    get options() {\n        return Object.freeze({ ...this[kOptions] });\n    }\n    get serverApi() {\n        return this[kOptions].serverApi && Object.freeze({ ...this[kOptions].serverApi });\n    }\n    /**\n     * Intended for APM use only\n     * @internal\n     */\n    get monitorCommands() {\n        return this[kOptions].monitorCommands;\n    }\n    set monitorCommands(value) {\n        this[kOptions].monitorCommands = value;\n    }\n    /** @internal */\n    get autoEncrypter() {\n        return this[kOptions].autoEncrypter;\n    }\n    get readConcern() {\n        return this.s.readConcern;\n    }\n    get writeConcern() {\n        return this.s.writeConcern;\n    }\n    get readPreference() {\n        return this.s.readPreference;\n    }\n    get bsonOptions() {\n        return this.s.bsonOptions;\n    }\n    /**\n     * Connect to MongoDB using a url\n     *\n     * @see docs.mongodb.org/manual/reference/connection-string/\n     */\n    async connect() {\n        if (this.connectionLock) {\n            return await this.connectionLock;\n        }\n        try {\n            this.connectionLock = this._connect();\n            await this.connectionLock;\n        }\n        finally {\n            // release\n            this.connectionLock = undefined;\n        }\n        return this;\n    }\n    /**\n     * Create a topology to open the connection, must be locked to avoid topology leaks in concurrency scenario.\n     * Locking is enforced by the connect method.\n     *\n     * @internal\n     */\n    async _connect() {\n        if (this.topology && this.topology.isConnected()) {\n            return this;\n        }\n        const options = this[kOptions];\n        if (options.tls) {\n            if (typeof options.tlsCAFile === 'string') {\n                options.ca ??= await fs_1.promises.readFile(options.tlsCAFile);\n            }\n            if (typeof options.tlsCRLFile === 'string') {\n                options.crl ??= await fs_1.promises.readFile(options.tlsCRLFile);\n            }\n            if (typeof options.tlsCertificateKeyFile === 'string') {\n                if (!options.key || !options.cert) {\n                    const contents = await fs_1.promises.readFile(options.tlsCertificateKeyFile);\n                    options.key ??= contents;\n                    options.cert ??= contents;\n                }\n            }\n        }\n        if (typeof options.srvHost === 'string') {\n            const hosts = await (0, connection_string_1.resolveSRVRecord)(options);\n            for (const [index, host] of hosts.entries()) {\n                options.hosts[index] = host;\n            }\n        }\n        // It is important to perform validation of hosts AFTER SRV resolution, to check the real hostname,\n        // but BEFORE we even attempt connecting with a potentially not allowed hostname\n        if (options.credentials?.mechanism === providers_1.AuthMechanism.MONGODB_OIDC) {\n            const allowedHosts = options.credentials?.mechanismProperties?.ALLOWED_HOSTS || mongo_credentials_1.DEFAULT_ALLOWED_HOSTS;\n            const isServiceAuth = !!options.credentials?.mechanismProperties?.ENVIRONMENT;\n            if (!isServiceAuth) {\n                for (const host of options.hosts) {\n                    if (!(0, utils_1.hostMatchesWildcards)(host.toHostPort().host, allowedHosts)) {\n                        throw new error_1.MongoInvalidArgumentError(`Host '${host}' is not valid for OIDC authentication with ALLOWED_HOSTS of '${allowedHosts.join(',')}'`);\n                    }\n                }\n            }\n        }\n        this.topology = new topology_1.Topology(this, options.hosts, options);\n        // Events can be emitted before initialization is complete so we have to\n        // save the reference to the topology on the client ASAP if the event handlers need to access it\n        this.topology.once(topology_1.Topology.OPEN, () => this.emit('open', this));\n        for (const event of constants_1.MONGO_CLIENT_EVENTS) {\n            this.topology.on(event, (...args) => this.emit(event, ...args));\n        }\n        const topologyConnect = async () => {\n            try {\n                await this.topology?.connect(options);\n            }\n            catch (error) {\n                this.topology?.close();\n                throw error;\n            }\n        };\n        if (this.autoEncrypter) {\n            await this.autoEncrypter?.init();\n            await topologyConnect();\n            await options.encrypter.connectInternalClient();\n        }\n        else {\n            await topologyConnect();\n        }\n        return this;\n    }\n    /**\n     * Close the client and its underlying connections\n     *\n     * @param force - Force close, emitting no events\n     */\n    async close(force = false) {\n        // There's no way to set hasBeenClosed back to false\n        Object.defineProperty(this.s, 'hasBeenClosed', {\n            value: true,\n            enumerable: true,\n            configurable: false,\n            writable: false\n        });\n        const activeSessionEnds = Array.from(this.s.activeSessions, session => session.endSession());\n        this.s.activeSessions.clear();\n        await Promise.all(activeSessionEnds);\n        if (this.topology == null) {\n            return;\n        }\n        // If we would attempt to select a server and get nothing back we short circuit\n        // to avoid the server selection timeout.\n        const selector = (0, server_selection_1.readPreferenceServerSelector)(read_preference_1.ReadPreference.primaryPreferred);\n        const topologyDescription = this.topology.description;\n        const serverDescriptions = Array.from(topologyDescription.servers.values());\n        const servers = selector(topologyDescription, serverDescriptions);\n        if (servers.length !== 0) {\n            const endSessions = Array.from(this.s.sessionPool.sessions, ({ id }) => id);\n            if (endSessions.length !== 0) {\n                try {\n                    await (0, execute_operation_1.executeOperation)(this, new run_command_1.RunAdminCommandOperation({ endSessions }, { readPreference: read_preference_1.ReadPreference.primaryPreferred, noResponse: true }));\n                }\n                catch (error) {\n                    (0, utils_1.squashError)(error);\n                }\n            }\n        }\n        // clear out references to old topology\n        const topology = this.topology;\n        this.topology = undefined;\n        topology.close();\n        const { encrypter } = this[kOptions];\n        if (encrypter) {\n            await encrypter.close(this, force);\n        }\n    }\n    /**\n     * Create a new Db instance sharing the current socket connections.\n     *\n     * @param dbName - The name of the database we want to use. If not provided, use database name from connection string.\n     * @param options - Optional settings for Db construction\n     */\n    db(dbName, options) {\n        options = options ?? {};\n        // Default to db from connection string if not provided\n        if (!dbName) {\n            dbName = this.options.dbName;\n        }\n        // Copy the options and add out internal override of the not shared flag\n        const finalOptions = Object.assign({}, this[kOptions], options);\n        // Return the db object\n        const db = new db_1.Db(this, dbName, finalOptions);\n        // Return the database\n        return db;\n    }\n    /**\n     * Connect to MongoDB using a url\n     *\n     * @remarks\n     * The programmatically provided options take precedence over the URI options.\n     *\n     * @see https://www.mongodb.com/docs/manual/reference/connection-string/\n     */\n    static async connect(url, options) {\n        const client = new this(url, options);\n        return await client.connect();\n    }\n    /**\n     * Creates a new ClientSession. When using the returned session in an operation\n     * a corresponding ServerSession will be created.\n     *\n     * @remarks\n     * A ClientSession instance may only be passed to operations being performed on the same\n     * MongoClient it was started from.\n     */\n    startSession(options) {\n        const session = new sessions_1.ClientSession(this, this.s.sessionPool, { explicit: true, ...options }, this[kOptions]);\n        this.s.activeSessions.add(session);\n        session.once('ended', () => {\n            this.s.activeSessions.delete(session);\n        });\n        return session;\n    }\n    async withSession(optionsOrExecutor, executor) {\n        const options = {\n            // Always define an owner\n            owner: Symbol(),\n            // If it's an object inherit the options\n            ...(typeof optionsOrExecutor === 'object' ? optionsOrExecutor : {})\n        };\n        const withSessionCallback = typeof optionsOrExecutor === 'function' ? optionsOrExecutor : executor;\n        if (withSessionCallback == null) {\n            throw new error_1.MongoInvalidArgumentError('Missing required callback parameter');\n        }\n        const session = this.startSession(options);\n        try {\n            return await withSessionCallback(session);\n        }\n        finally {\n            try {\n                await session.endSession();\n            }\n            catch (error) {\n                (0, utils_1.squashError)(error);\n            }\n        }\n    }\n    /**\n     * Create a new Change Stream, watching for new changes (insertions, updates,\n     * replacements, deletions, and invalidations) in this cluster. Will ignore all\n     * changes to system collections, as well as the local, admin, and config databases.\n     *\n     * @remarks\n     * watch() accepts two generic arguments for distinct use cases:\n     * - The first is to provide the schema that may be defined for all the data within the current cluster\n     * - The second is to override the shape of the change stream document entirely, if it is not provided the type will default to ChangeStreamDocument of the first argument\n     *\n     * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents. This allows for filtering (using $match) and manipulating the change stream documents.\n     * @param options - Optional settings for the command\n     * @typeParam TSchema - Type of the data being detected by the change stream\n     * @typeParam TChange - Type of the whole change stream document emitted\n     */\n    watch(pipeline = [], options = {}) {\n        // Allow optionally not specifying a pipeline\n        if (!Array.isArray(pipeline)) {\n            options = pipeline;\n            pipeline = [];\n        }\n        return new change_stream_1.ChangeStream(this, pipeline, (0, utils_1.resolveOptions)(this, options));\n    }\n}\nexports.MongoClient = MongoClient;\n//# sourceMappingURL=mongo_client.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/mongo_client.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/mongo_client_auth_providers.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mongodb/lib/mongo_client_auth_providers.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoClientAuthProviders = void 0;\nconst gssapi_1 = __webpack_require__(/*! ./cmap/auth/gssapi */ \"./node_modules/mongodb/lib/cmap/auth/gssapi.js\");\nconst mongocr_1 = __webpack_require__(/*! ./cmap/auth/mongocr */ \"./node_modules/mongodb/lib/cmap/auth/mongocr.js\");\nconst mongodb_aws_1 = __webpack_require__(/*! ./cmap/auth/mongodb_aws */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_aws.js\");\nconst mongodb_oidc_1 = __webpack_require__(/*! ./cmap/auth/mongodb_oidc */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc.js\");\nconst automated_callback_workflow_1 = __webpack_require__(/*! ./cmap/auth/mongodb_oidc/automated_callback_workflow */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/automated_callback_workflow.js\");\nconst human_callback_workflow_1 = __webpack_require__(/*! ./cmap/auth/mongodb_oidc/human_callback_workflow */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/human_callback_workflow.js\");\nconst token_cache_1 = __webpack_require__(/*! ./cmap/auth/mongodb_oidc/token_cache */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/token_cache.js\");\nconst plain_1 = __webpack_require__(/*! ./cmap/auth/plain */ \"./node_modules/mongodb/lib/cmap/auth/plain.js\");\nconst providers_1 = __webpack_require__(/*! ./cmap/auth/providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\nconst scram_1 = __webpack_require__(/*! ./cmap/auth/scram */ \"./node_modules/mongodb/lib/cmap/auth/scram.js\");\nconst x509_1 = __webpack_require__(/*! ./cmap/auth/x509 */ \"./node_modules/mongodb/lib/cmap/auth/x509.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\n/** @internal */\nconst AUTH_PROVIDERS = new Map([\n    [providers_1.AuthMechanism.MONGODB_AWS, () => new mongodb_aws_1.MongoDBAWS()],\n    [providers_1.AuthMechanism.MONGODB_CR, () => new mongocr_1.MongoCR()],\n    [providers_1.AuthMechanism.MONGODB_GSSAPI, () => new gssapi_1.GSSAPI()],\n    [providers_1.AuthMechanism.MONGODB_OIDC, (workflow) => new mongodb_oidc_1.MongoDBOIDC(workflow)],\n    [providers_1.AuthMechanism.MONGODB_PLAIN, () => new plain_1.Plain()],\n    [providers_1.AuthMechanism.MONGODB_SCRAM_SHA1, () => new scram_1.ScramSHA1()],\n    [providers_1.AuthMechanism.MONGODB_SCRAM_SHA256, () => new scram_1.ScramSHA256()],\n    [providers_1.AuthMechanism.MONGODB_X509, () => new x509_1.X509()]\n]);\n/**\n * Create a set of providers per client\n * to avoid sharing the provider's cache between different clients.\n * @internal\n */\nclass MongoClientAuthProviders {\n    constructor() {\n        this.existingProviders = new Map();\n    }\n    /**\n     * Get or create an authentication provider based on the provided mechanism.\n     * We don't want to create all providers at once, as some providers may not be used.\n     * @param name - The name of the provider to get or create.\n     * @param credentials - The credentials.\n     * @returns The provider.\n     * @throws MongoInvalidArgumentError if the mechanism is not supported.\n     * @internal\n     */\n    getOrCreateProvider(name, authMechanismProperties) {\n        const authProvider = this.existingProviders.get(name);\n        if (authProvider) {\n            return authProvider;\n        }\n        const providerFunction = AUTH_PROVIDERS.get(name);\n        if (!providerFunction) {\n            throw new error_1.MongoInvalidArgumentError(`authMechanism ${name} not supported`);\n        }\n        let provider;\n        if (name === providers_1.AuthMechanism.MONGODB_OIDC) {\n            provider = providerFunction(this.getWorkflow(authMechanismProperties));\n        }\n        else {\n            provider = providerFunction();\n        }\n        this.existingProviders.set(name, provider);\n        return provider;\n    }\n    /**\n     * Gets either a device workflow or callback workflow.\n     */\n    getWorkflow(authMechanismProperties) {\n        if (authMechanismProperties.OIDC_HUMAN_CALLBACK) {\n            return new human_callback_workflow_1.HumanCallbackWorkflow(new token_cache_1.TokenCache(), authMechanismProperties.OIDC_HUMAN_CALLBACK);\n        }\n        else if (authMechanismProperties.OIDC_CALLBACK) {\n            return new automated_callback_workflow_1.AutomatedCallbackWorkflow(new token_cache_1.TokenCache(), authMechanismProperties.OIDC_CALLBACK);\n        }\n        else {\n            const environment = authMechanismProperties.ENVIRONMENT;\n            const workflow = mongodb_oidc_1.OIDC_WORKFLOWS.get(environment)?.();\n            if (!workflow) {\n                throw new error_1.MongoInvalidArgumentError(`Could not load workflow for environment ${authMechanismProperties.ENVIRONMENT}`);\n            }\n            return workflow;\n        }\n    }\n}\nexports.MongoClientAuthProviders = MongoClientAuthProviders;\n//# sourceMappingURL=mongo_client_auth_providers.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/mongo_client_auth_providers.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/mongo_logger.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/mongo_logger.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoLogger = exports.defaultLogTransform = exports.stringifyWithMaxLen = exports.createStdioLogger = exports.parseSeverityFromString = exports.MongoLoggableComponent = exports.SEVERITY_LEVEL_MAP = exports.DEFAULT_MAX_DOCUMENT_LENGTH = exports.SeverityLevel = void 0;\nconst util_1 = __webpack_require__(/*! util */ \"util\");\nconst bson_1 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst constants_1 = __webpack_require__(/*! ./constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/mongodb/lib/utils.js\");\n/** @internal */\nexports.SeverityLevel = Object.freeze({\n    EMERGENCY: 'emergency',\n    ALERT: 'alert',\n    CRITICAL: 'critical',\n    ERROR: 'error',\n    WARNING: 'warn',\n    NOTICE: 'notice',\n    INFORMATIONAL: 'info',\n    DEBUG: 'debug',\n    TRACE: 'trace',\n    OFF: 'off'\n});\n/** @internal */\nexports.DEFAULT_MAX_DOCUMENT_LENGTH = 1000;\n/** @internal */\nclass SeverityLevelMap extends Map {\n    constructor(entries) {\n        const newEntries = [];\n        for (const [level, value] of entries) {\n            newEntries.push([value, level]);\n        }\n        newEntries.push(...entries);\n        super(newEntries);\n    }\n    getNumericSeverityLevel(severity) {\n        return this.get(severity);\n    }\n    getSeverityLevelName(level) {\n        return this.get(level);\n    }\n}\n/** @internal */\nexports.SEVERITY_LEVEL_MAP = new SeverityLevelMap([\n    [exports.SeverityLevel.OFF, -Infinity],\n    [exports.SeverityLevel.EMERGENCY, 0],\n    [exports.SeverityLevel.ALERT, 1],\n    [exports.SeverityLevel.CRITICAL, 2],\n    [exports.SeverityLevel.ERROR, 3],\n    [exports.SeverityLevel.WARNING, 4],\n    [exports.SeverityLevel.NOTICE, 5],\n    [exports.SeverityLevel.INFORMATIONAL, 6],\n    [exports.SeverityLevel.DEBUG, 7],\n    [exports.SeverityLevel.TRACE, 8]\n]);\n/** @internal */\nexports.MongoLoggableComponent = Object.freeze({\n    COMMAND: 'command',\n    TOPOLOGY: 'topology',\n    SERVER_SELECTION: 'serverSelection',\n    CONNECTION: 'connection',\n    CLIENT: 'client'\n});\n/**\n * Parses a string as one of SeverityLevel\n * @internal\n *\n * @param s - the value to be parsed\n * @returns one of SeverityLevel if value can be parsed as such, otherwise null\n */\nfunction parseSeverityFromString(s) {\n    const validSeverities = Object.values(exports.SeverityLevel);\n    const lowerSeverity = s?.toLowerCase();\n    if (lowerSeverity != null && validSeverities.includes(lowerSeverity)) {\n        return lowerSeverity;\n    }\n    return null;\n}\nexports.parseSeverityFromString = parseSeverityFromString;\n/** @internal */\nfunction createStdioLogger(stream) {\n    return {\n        write: (0, util_1.promisify)((log, cb) => {\n            const logLine = (0, util_1.inspect)(log, { compact: true, breakLength: Infinity });\n            stream.write(`${logLine}\\n`, 'utf-8', cb);\n            return;\n        })\n    };\n}\nexports.createStdioLogger = createStdioLogger;\n/**\n * resolves the MONGODB_LOG_PATH and mongodbLogPath options from the environment and the\n * mongo client options respectively. The mongodbLogPath can be either 'stdout', 'stderr', a NodeJS\n * Writable or an object which has a `write` method with the signature:\n * ```ts\n * write(log: Log): void\n * ```\n *\n * @returns the MongoDBLogWritable object to write logs to\n */\nfunction resolveLogPath({ MONGODB_LOG_PATH }, { mongodbLogPath }) {\n    if (typeof mongodbLogPath === 'string' && /^stderr$/i.test(mongodbLogPath)) {\n        return { mongodbLogPath: createStdioLogger(process.stderr), mongodbLogPathIsStdErr: true };\n    }\n    if (typeof mongodbLogPath === 'string' && /^stdout$/i.test(mongodbLogPath)) {\n        return { mongodbLogPath: createStdioLogger(process.stdout), mongodbLogPathIsStdErr: false };\n    }\n    if (typeof mongodbLogPath === 'object' && typeof mongodbLogPath?.write === 'function') {\n        return { mongodbLogPath: mongodbLogPath, mongodbLogPathIsStdErr: false };\n    }\n    if (MONGODB_LOG_PATH && /^stderr$/i.test(MONGODB_LOG_PATH)) {\n        return { mongodbLogPath: createStdioLogger(process.stderr), mongodbLogPathIsStdErr: true };\n    }\n    if (MONGODB_LOG_PATH && /^stdout$/i.test(MONGODB_LOG_PATH)) {\n        return { mongodbLogPath: createStdioLogger(process.stdout), mongodbLogPathIsStdErr: false };\n    }\n    return { mongodbLogPath: createStdioLogger(process.stderr), mongodbLogPathIsStdErr: true };\n}\nfunction resolveSeverityConfiguration(clientOption, environmentOption, defaultSeverity) {\n    return (parseSeverityFromString(clientOption) ??\n        parseSeverityFromString(environmentOption) ??\n        defaultSeverity);\n}\nfunction compareSeverity(s0, s1) {\n    const s0Num = exports.SEVERITY_LEVEL_MAP.getNumericSeverityLevel(s0);\n    const s1Num = exports.SEVERITY_LEVEL_MAP.getNumericSeverityLevel(s1);\n    return s0Num < s1Num ? -1 : s0Num > s1Num ? 1 : 0;\n}\n/** @internal */\nfunction stringifyWithMaxLen(value, maxDocumentLength, options = {}) {\n    let strToTruncate = '';\n    if (typeof value === 'string') {\n        strToTruncate = value;\n    }\n    else if (typeof value === 'function') {\n        strToTruncate = value.name;\n    }\n    else {\n        try {\n            strToTruncate = bson_1.EJSON.stringify(value, options);\n        }\n        catch (e) {\n            strToTruncate = `Extended JSON serialization failed with: ${e.message}`;\n        }\n    }\n    // handle truncation that occurs in the middle of multi-byte codepoints\n    if (maxDocumentLength !== 0 &&\n        strToTruncate.length > maxDocumentLength &&\n        strToTruncate.charCodeAt(maxDocumentLength - 1) !==\n            strToTruncate.codePointAt(maxDocumentLength - 1)) {\n        maxDocumentLength--;\n        if (maxDocumentLength === 0) {\n            return '';\n        }\n    }\n    return maxDocumentLength !== 0 && strToTruncate.length > maxDocumentLength\n        ? `${strToTruncate.slice(0, maxDocumentLength)}...`\n        : strToTruncate;\n}\nexports.stringifyWithMaxLen = stringifyWithMaxLen;\nfunction isLogConvertible(obj) {\n    const objAsLogConvertible = obj;\n    // eslint-disable-next-line no-restricted-syntax\n    return objAsLogConvertible.toLog !== undefined && typeof objAsLogConvertible.toLog === 'function';\n}\nfunction attachServerSelectionFields(log, serverSelectionEvent, maxDocumentLength = exports.DEFAULT_MAX_DOCUMENT_LENGTH) {\n    const { selector, operation, topologyDescription, message } = serverSelectionEvent;\n    log.selector = stringifyWithMaxLen(selector, maxDocumentLength);\n    log.operation = operation;\n    log.topologyDescription = stringifyWithMaxLen(topologyDescription, maxDocumentLength);\n    log.message = message;\n    return log;\n}\nfunction attachCommandFields(log, commandEvent) {\n    log.commandName = commandEvent.commandName;\n    log.requestId = commandEvent.requestId;\n    log.driverConnectionId = commandEvent.connectionId;\n    const { host, port } = utils_1.HostAddress.fromString(commandEvent.address).toHostPort();\n    log.serverHost = host;\n    log.serverPort = port;\n    if (commandEvent?.serviceId) {\n        log.serviceId = commandEvent.serviceId.toHexString();\n    }\n    log.databaseName = commandEvent.databaseName;\n    log.serverConnectionId = commandEvent.serverConnectionId;\n    return log;\n}\nfunction attachConnectionFields(log, event) {\n    const { host, port } = utils_1.HostAddress.fromString(event.address).toHostPort();\n    log.serverHost = host;\n    log.serverPort = port;\n    return log;\n}\nfunction attachSDAMFields(log, sdamEvent) {\n    log.topologyId = sdamEvent.topologyId;\n    return log;\n}\nfunction attachServerHeartbeatFields(log, serverHeartbeatEvent) {\n    const { awaited, connectionId } = serverHeartbeatEvent;\n    log.awaited = awaited;\n    log.driverConnectionId = serverHeartbeatEvent.connectionId;\n    const { host, port } = utils_1.HostAddress.fromString(connectionId).toHostPort();\n    log.serverHost = host;\n    log.serverPort = port;\n    return log;\n}\n/** @internal */\nfunction defaultLogTransform(logObject, maxDocumentLength = exports.DEFAULT_MAX_DOCUMENT_LENGTH) {\n    let log = Object.create(null);\n    switch (logObject.name) {\n        case constants_1.SERVER_SELECTION_STARTED:\n            log = attachServerSelectionFields(log, logObject, maxDocumentLength);\n            return log;\n        case constants_1.SERVER_SELECTION_FAILED:\n            log = attachServerSelectionFields(log, logObject, maxDocumentLength);\n            log.failure = logObject.failure?.message;\n            return log;\n        case constants_1.SERVER_SELECTION_SUCCEEDED:\n            log = attachServerSelectionFields(log, logObject, maxDocumentLength);\n            log.serverHost = logObject.serverHost;\n            log.serverPort = logObject.serverPort;\n            return log;\n        case constants_1.WAITING_FOR_SUITABLE_SERVER:\n            log = attachServerSelectionFields(log, logObject, maxDocumentLength);\n            log.remainingTimeMS = logObject.remainingTimeMS;\n            return log;\n        case constants_1.COMMAND_STARTED:\n            log = attachCommandFields(log, logObject);\n            log.message = 'Command started';\n            log.command = stringifyWithMaxLen(logObject.command, maxDocumentLength, { relaxed: true });\n            log.databaseName = logObject.databaseName;\n            return log;\n        case constants_1.COMMAND_SUCCEEDED:\n            log = attachCommandFields(log, logObject);\n            log.message = 'Command succeeded';\n            log.durationMS = logObject.duration;\n            log.reply = stringifyWithMaxLen(logObject.reply, maxDocumentLength, { relaxed: true });\n            return log;\n        case constants_1.COMMAND_FAILED:\n            log = attachCommandFields(log, logObject);\n            log.message = 'Command failed';\n            log.durationMS = logObject.duration;\n            log.failure = logObject.failure?.message ?? '(redacted)';\n            return log;\n        case constants_1.CONNECTION_POOL_CREATED:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection pool created';\n            if (logObject.options) {\n                const { maxIdleTimeMS, minPoolSize, maxPoolSize, maxConnecting, waitQueueTimeoutMS } = logObject.options;\n                log = {\n                    ...log,\n                    maxIdleTimeMS,\n                    minPoolSize,\n                    maxPoolSize,\n                    maxConnecting,\n                    waitQueueTimeoutMS\n                };\n            }\n            return log;\n        case constants_1.CONNECTION_POOL_READY:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection pool ready';\n            return log;\n        case constants_1.CONNECTION_POOL_CLEARED:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection pool cleared';\n            if (logObject.serviceId?._bsontype === 'ObjectId') {\n                log.serviceId = logObject.serviceId?.toHexString();\n            }\n            return log;\n        case constants_1.CONNECTION_POOL_CLOSED:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection pool closed';\n            return log;\n        case constants_1.CONNECTION_CREATED:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection created';\n            log.driverConnectionId = logObject.connectionId;\n            return log;\n        case constants_1.CONNECTION_READY:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection ready';\n            log.driverConnectionId = logObject.connectionId;\n            return log;\n        case constants_1.CONNECTION_CLOSED:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection closed';\n            log.driverConnectionId = logObject.connectionId;\n            switch (logObject.reason) {\n                case 'stale':\n                    log.reason = 'Connection became stale because the pool was cleared';\n                    break;\n                case 'idle':\n                    log.reason =\n                        'Connection has been available but unused for longer than the configured max idle time';\n                    break;\n                case 'error':\n                    log.reason = 'An error occurred while using the connection';\n                    if (logObject.error) {\n                        log.error = logObject.error;\n                    }\n                    break;\n                case 'poolClosed':\n                    log.reason = 'Connection pool was closed';\n                    break;\n                default:\n                    log.reason = `Unknown close reason: ${logObject.reason}`;\n            }\n            return log;\n        case constants_1.CONNECTION_CHECK_OUT_STARTED:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection checkout started';\n            return log;\n        case constants_1.CONNECTION_CHECK_OUT_FAILED:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection checkout failed';\n            switch (logObject.reason) {\n                case 'poolClosed':\n                    log.reason = 'Connection pool was closed';\n                    break;\n                case 'timeout':\n                    log.reason = 'Wait queue timeout elapsed without a connection becoming available';\n                    break;\n                case 'connectionError':\n                    log.reason = 'An error occurred while trying to establish a new connection';\n                    if (logObject.error) {\n                        log.error = logObject.error;\n                    }\n                    break;\n                default:\n                    log.reason = `Unknown close reason: ${logObject.reason}`;\n            }\n            return log;\n        case constants_1.CONNECTION_CHECKED_OUT:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection checked out';\n            log.driverConnectionId = logObject.connectionId;\n            return log;\n        case constants_1.CONNECTION_CHECKED_IN:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection checked in';\n            log.driverConnectionId = logObject.connectionId;\n            return log;\n        case constants_1.SERVER_OPENING:\n            log = attachSDAMFields(log, logObject);\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Starting server monitoring';\n            return log;\n        case constants_1.SERVER_CLOSED:\n            log = attachSDAMFields(log, logObject);\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Stopped server monitoring';\n            return log;\n        case constants_1.SERVER_HEARTBEAT_STARTED:\n            log = attachSDAMFields(log, logObject);\n            log = attachServerHeartbeatFields(log, logObject);\n            log.message = 'Server heartbeat started';\n            return log;\n        case constants_1.SERVER_HEARTBEAT_SUCCEEDED:\n            log = attachSDAMFields(log, logObject);\n            log = attachServerHeartbeatFields(log, logObject);\n            log.message = 'Server heartbeat succeeded';\n            log.durationMS = logObject.duration;\n            log.serverConnectionId = logObject.serverConnectionId;\n            log.reply = stringifyWithMaxLen(logObject.reply, maxDocumentLength, { relaxed: true });\n            return log;\n        case constants_1.SERVER_HEARTBEAT_FAILED:\n            log = attachSDAMFields(log, logObject);\n            log = attachServerHeartbeatFields(log, logObject);\n            log.message = 'Server heartbeat failed';\n            log.durationMS = logObject.duration;\n            log.failure = logObject.failure?.message;\n            return log;\n        case constants_1.TOPOLOGY_OPENING:\n            log = attachSDAMFields(log, logObject);\n            log.message = 'Starting topology monitoring';\n            return log;\n        case constants_1.TOPOLOGY_CLOSED:\n            log = attachSDAMFields(log, logObject);\n            log.message = 'Stopped topology monitoring';\n            return log;\n        case constants_1.TOPOLOGY_DESCRIPTION_CHANGED:\n            log = attachSDAMFields(log, logObject);\n            log.message = 'Topology description changed';\n            log.previousDescription = log.reply = stringifyWithMaxLen(logObject.previousDescription, maxDocumentLength);\n            log.newDescription = log.reply = stringifyWithMaxLen(logObject.newDescription, maxDocumentLength);\n            return log;\n        default:\n            for (const [key, value] of Object.entries(logObject)) {\n                if (value != null)\n                    log[key] = value;\n            }\n    }\n    return log;\n}\nexports.defaultLogTransform = defaultLogTransform;\n/** @internal */\nclass MongoLogger {\n    constructor(options) {\n        this.pendingLog = null;\n        /**\n         * This method should be used when logging errors that do not have a public driver API for\n         * reporting errors.\n         */\n        this.error = this.log.bind(this, 'error');\n        /**\n         * This method should be used to log situations where undesirable application behaviour might\n         * occur. For example, failing to end sessions on `MongoClient.close`.\n         */\n        this.warn = this.log.bind(this, 'warn');\n        /**\n         * This method should be used to report high-level information about normal driver behaviour.\n         * For example, the creation of a `MongoClient`.\n         */\n        this.info = this.log.bind(this, 'info');\n        /**\n         * This method should be used to report information that would be helpful when debugging an\n         * application. For example, a command starting, succeeding or failing.\n         */\n        this.debug = this.log.bind(this, 'debug');\n        /**\n         * This method should be used to report fine-grained details related to logic flow. For example,\n         * entering and exiting a function body.\n         */\n        this.trace = this.log.bind(this, 'trace');\n        this.componentSeverities = options.componentSeverities;\n        this.maxDocumentLength = options.maxDocumentLength;\n        this.logDestination = options.logDestination;\n        this.logDestinationIsStdErr = options.logDestinationIsStdErr;\n        this.severities = this.createLoggingSeverities();\n    }\n    createLoggingSeverities() {\n        const severities = Object();\n        for (const component of Object.values(exports.MongoLoggableComponent)) {\n            severities[component] = {};\n            for (const severityLevel of Object.values(exports.SeverityLevel)) {\n                severities[component][severityLevel] =\n                    compareSeverity(severityLevel, this.componentSeverities[component]) <= 0;\n            }\n        }\n        return severities;\n    }\n    turnOffSeverities() {\n        for (const component of Object.values(exports.MongoLoggableComponent)) {\n            this.componentSeverities[component] = exports.SeverityLevel.OFF;\n            for (const severityLevel of Object.values(exports.SeverityLevel)) {\n                this.severities[component][severityLevel] = false;\n            }\n        }\n    }\n    logWriteFailureHandler(error) {\n        if (this.logDestinationIsStdErr) {\n            this.turnOffSeverities();\n            this.clearPendingLog();\n            return;\n        }\n        this.logDestination = createStdioLogger(process.stderr);\n        this.logDestinationIsStdErr = true;\n        this.clearPendingLog();\n        this.error(exports.MongoLoggableComponent.CLIENT, {\n            toLog: function () {\n                return {\n                    message: 'User input for mongodbLogPath is now invalid. Logging is halted.',\n                    error: error.message\n                };\n            }\n        });\n        this.turnOffSeverities();\n        this.clearPendingLog();\n    }\n    clearPendingLog() {\n        this.pendingLog = null;\n    }\n    willLog(component, severity) {\n        if (severity === exports.SeverityLevel.OFF)\n            return false;\n        return this.severities[component][severity];\n    }\n    log(severity, component, message) {\n        if (!this.willLog(component, severity))\n            return;\n        let logMessage = { t: new Date(), c: component, s: severity };\n        if (typeof message === 'string') {\n            logMessage.message = message;\n        }\n        else if (typeof message === 'object') {\n            if (isLogConvertible(message)) {\n                logMessage = { ...logMessage, ...message.toLog() };\n            }\n            else {\n                logMessage = { ...logMessage, ...defaultLogTransform(message, this.maxDocumentLength) };\n            }\n        }\n        if ((0, utils_1.isPromiseLike)(this.pendingLog)) {\n            this.pendingLog = this.pendingLog\n                // eslint-disable-next-line github/no-then\n                .then(() => this.logDestination.write(logMessage))\n                // eslint-disable-next-line github/no-then\n                .then(this.clearPendingLog.bind(this), this.logWriteFailureHandler.bind(this));\n            return;\n        }\n        try {\n            const logResult = this.logDestination.write(logMessage);\n            if ((0, utils_1.isPromiseLike)(logResult)) {\n                // eslint-disable-next-line github/no-then\n                this.pendingLog = logResult.then(this.clearPendingLog.bind(this), this.logWriteFailureHandler.bind(this));\n            }\n        }\n        catch (error) {\n            this.logWriteFailureHandler(error);\n        }\n    }\n    /**\n     * Merges options set through environment variables and the MongoClient, preferring environment\n     * variables when both are set, and substituting defaults for values not set. Options set in\n     * constructor take precedence over both environment variables and MongoClient options.\n     *\n     * @remarks\n     * When parsing component severity levels, invalid values are treated as unset and replaced with\n     * the default severity.\n     *\n     * @param envOptions - options set for the logger from the environment\n     * @param clientOptions - options set for the logger in the MongoClient options\n     * @returns a MongoLoggerOptions object to be used when instantiating a new MongoLogger\n     */\n    static resolveOptions(envOptions, clientOptions) {\n        // client options take precedence over env options\n        const resolvedLogPath = resolveLogPath(envOptions, clientOptions);\n        const combinedOptions = {\n            ...envOptions,\n            ...clientOptions,\n            mongodbLogPath: resolvedLogPath.mongodbLogPath,\n            mongodbLogPathIsStdErr: resolvedLogPath.mongodbLogPathIsStdErr\n        };\n        const defaultSeverity = resolveSeverityConfiguration(combinedOptions.mongodbLogComponentSeverities?.default, combinedOptions.MONGODB_LOG_ALL, exports.SeverityLevel.OFF);\n        return {\n            componentSeverities: {\n                command: resolveSeverityConfiguration(combinedOptions.mongodbLogComponentSeverities?.command, combinedOptions.MONGODB_LOG_COMMAND, defaultSeverity),\n                topology: resolveSeverityConfiguration(combinedOptions.mongodbLogComponentSeverities?.topology, combinedOptions.MONGODB_LOG_TOPOLOGY, defaultSeverity),\n                serverSelection: resolveSeverityConfiguration(combinedOptions.mongodbLogComponentSeverities?.serverSelection, combinedOptions.MONGODB_LOG_SERVER_SELECTION, defaultSeverity),\n                connection: resolveSeverityConfiguration(combinedOptions.mongodbLogComponentSeverities?.connection, combinedOptions.MONGODB_LOG_CONNECTION, defaultSeverity),\n                client: resolveSeverityConfiguration(combinedOptions.mongodbLogComponentSeverities?.client, combinedOptions.MONGODB_LOG_CLIENT, defaultSeverity),\n                default: defaultSeverity\n            },\n            maxDocumentLength: combinedOptions.mongodbLogMaxDocumentLength ??\n                (0, utils_1.parseUnsignedInteger)(combinedOptions.MONGODB_LOG_MAX_DOCUMENT_LENGTH) ??\n                1000,\n            logDestination: combinedOptions.mongodbLogPath,\n            logDestinationIsStdErr: combinedOptions.mongodbLogPathIsStdErr\n        };\n    }\n}\nexports.MongoLogger = MongoLogger;\n//# sourceMappingURL=mongo_logger.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/mongo_logger.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/mongo_types.js":
/*!*************************************************!*\
  !*** ./node_modules/mongodb/lib/mongo_types.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CancellationToken = exports.TypedEventEmitter = void 0;\nconst events_1 = __webpack_require__(/*! events */ \"events\");\nconst mongo_logger_1 = __webpack_require__(/*! ./mongo_logger */ \"./node_modules/mongodb/lib/mongo_logger.js\");\n/**\n * Typescript type safe event emitter\n * @public\n */\nclass TypedEventEmitter extends events_1.EventEmitter {\n    /** @internal */\n    emitAndLog(event, ...args) {\n        this.emit(event, ...args);\n        if (this.component)\n            this.mongoLogger?.debug(this.component, args[0]);\n    }\n    /** @internal */\n    emitAndLogHeartbeat(event, topologyId, serverConnectionId, ...args) {\n        this.emit(event, ...args);\n        if (this.component) {\n            const loggableHeartbeatEvent = {\n                topologyId: topologyId,\n                serverConnectionId: serverConnectionId ?? null,\n                ...args[0]\n            };\n            this.mongoLogger?.debug(this.component, loggableHeartbeatEvent);\n        }\n    }\n    /** @internal */\n    emitAndLogCommand(monitorCommands, event, databaseName, connectionEstablished, ...args) {\n        if (monitorCommands) {\n            this.emit(event, ...args);\n        }\n        if (connectionEstablished) {\n            const loggableCommandEvent = {\n                databaseName: databaseName,\n                ...args[0]\n            };\n            this.mongoLogger?.debug(mongo_logger_1.MongoLoggableComponent.COMMAND, loggableCommandEvent);\n        }\n    }\n}\nexports.TypedEventEmitter = TypedEventEmitter;\n/** @public */\nclass CancellationToken extends TypedEventEmitter {\n}\nexports.CancellationToken = CancellationToken;\n//# sourceMappingURL=mongo_types.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/mongo_types.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/aggregate.js":
/*!**********************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/aggregate.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AggregateOperation = exports.DB_AGGREGATE_COLLECTION = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst write_concern_1 = __webpack_require__(/*! ../write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nexports.DB_AGGREGATE_COLLECTION = 1;\nconst MIN_WIRE_VERSION_$OUT_READ_CONCERN_SUPPORT = 8;\n/** @internal */\nclass AggregateOperation extends command_1.CommandOperation {\n    constructor(ns, pipeline, options) {\n        super(undefined, { ...options, dbName: ns.db });\n        this.options = { ...options };\n        // Covers when ns.collection is null, undefined or the empty string, use DB_AGGREGATE_COLLECTION\n        this.target = ns.collection || exports.DB_AGGREGATE_COLLECTION;\n        this.pipeline = pipeline;\n        // determine if we have a write stage, override read preference if so\n        this.hasWriteStage = false;\n        if (typeof options?.out === 'string') {\n            this.pipeline = this.pipeline.concat({ $out: options.out });\n            this.hasWriteStage = true;\n        }\n        else if (pipeline.length > 0) {\n            const finalStage = pipeline[pipeline.length - 1];\n            if (finalStage.$out || finalStage.$merge) {\n                this.hasWriteStage = true;\n            }\n        }\n        if (this.hasWriteStage) {\n            this.trySecondaryWrite = true;\n        }\n        else {\n            delete this.options.writeConcern;\n        }\n        if (this.explain && this.writeConcern) {\n            throw new error_1.MongoInvalidArgumentError('Option \"explain\" cannot be used on an aggregate call with writeConcern');\n        }\n        if (options?.cursor != null && typeof options.cursor !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('Cursor options must be an object');\n        }\n    }\n    get commandName() {\n        return 'aggregate';\n    }\n    get canRetryRead() {\n        return !this.hasWriteStage;\n    }\n    addToPipeline(stage) {\n        this.pipeline.push(stage);\n    }\n    async execute(server, session) {\n        const options = this.options;\n        const serverWireVersion = (0, utils_1.maxWireVersion)(server);\n        const command = { aggregate: this.target, pipeline: this.pipeline };\n        if (this.hasWriteStage && serverWireVersion < MIN_WIRE_VERSION_$OUT_READ_CONCERN_SUPPORT) {\n            this.readConcern = undefined;\n        }\n        if (this.hasWriteStage && this.writeConcern) {\n            write_concern_1.WriteConcern.apply(command, this.writeConcern);\n        }\n        if (options.bypassDocumentValidation === true) {\n            command.bypassDocumentValidation = options.bypassDocumentValidation;\n        }\n        if (typeof options.allowDiskUse === 'boolean') {\n            command.allowDiskUse = options.allowDiskUse;\n        }\n        if (options.hint) {\n            command.hint = options.hint;\n        }\n        if (options.let) {\n            command.let = options.let;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (options.comment !== undefined) {\n            command.comment = options.comment;\n        }\n        command.cursor = options.cursor || {};\n        if (options.batchSize && !this.hasWriteStage) {\n            command.cursor.batchSize = options.batchSize;\n        }\n        const res = await super.executeCommand(server, session, command);\n        return res;\n    }\n}\nexports.AggregateOperation = AggregateOperation;\n(0, operation_1.defineAspects)(AggregateOperation, [\n    operation_1.Aspect.READ_OPERATION,\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.EXPLAINABLE,\n    operation_1.Aspect.CURSOR_CREATING\n]);\n//# sourceMappingURL=aggregate.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/aggregate.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/bulk_write.js":
/*!***********************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/bulk_write.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.BulkWriteOperation = void 0;\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass BulkWriteOperation extends operation_1.AbstractOperation {\n    constructor(collection, operations, options) {\n        super(options);\n        this.options = options;\n        this.collection = collection;\n        this.operations = operations;\n    }\n    get commandName() {\n        return 'bulkWrite';\n    }\n    async execute(server, session) {\n        const coll = this.collection;\n        const operations = this.operations;\n        const options = { ...this.options, ...this.bsonOptions, readPreference: this.readPreference };\n        // Create the bulk operation\n        const bulk = options.ordered === false\n            ? coll.initializeUnorderedBulkOp(options)\n            : coll.initializeOrderedBulkOp(options);\n        // for each op go through and add to the bulk\n        for (let i = 0; i < operations.length; i++) {\n            bulk.raw(operations[i]);\n        }\n        // Execute the bulk\n        const result = await bulk.execute({ ...options, session });\n        return result;\n    }\n}\nexports.BulkWriteOperation = BulkWriteOperation;\n(0, operation_1.defineAspects)(BulkWriteOperation, [operation_1.Aspect.WRITE_OPERATION]);\n//# sourceMappingURL=bulk_write.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/bulk_write.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/collections.js":
/*!************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/collections.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CollectionsOperation = void 0;\nconst collection_1 = __webpack_require__(/*! ../collection */ \"./node_modules/mongodb/lib/collection.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass CollectionsOperation extends operation_1.AbstractOperation {\n    constructor(db, options) {\n        super(options);\n        this.options = options;\n        this.db = db;\n    }\n    get commandName() {\n        return 'listCollections';\n    }\n    async execute(server, session) {\n        // Let's get the collection names\n        const documents = await this.db\n            .listCollections({}, { ...this.options, nameOnly: true, readPreference: this.readPreference, session })\n            .toArray();\n        const collections = [];\n        for (const { name } of documents) {\n            if (!name.includes('$')) {\n                // Filter collections removing any illegal ones\n                collections.push(new collection_1.Collection(this.db, name, this.db.s.options));\n            }\n        }\n        // Return the collection objects\n        return collections;\n    }\n}\nexports.CollectionsOperation = CollectionsOperation;\n//# sourceMappingURL=collections.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/collections.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/command.js":
/*!********************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/command.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CommandOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst explain_1 = __webpack_require__(/*! ../explain */ \"./node_modules/mongodb/lib/explain.js\");\nconst read_concern_1 = __webpack_require__(/*! ../read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst server_selection_1 = __webpack_require__(/*! ../sdam/server_selection */ \"./node_modules/mongodb/lib/sdam/server_selection.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst write_concern_1 = __webpack_require__(/*! ../write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass CommandOperation extends operation_1.AbstractOperation {\n    constructor(parent, options) {\n        super(options);\n        this.options = options ?? {};\n        // NOTE: this was explicitly added for the add/remove user operations, it's likely\n        //       something we'd want to reconsider. Perhaps those commands can use `Admin`\n        //       as a parent?\n        const dbNameOverride = options?.dbName || options?.authdb;\n        if (dbNameOverride) {\n            this.ns = new utils_1.MongoDBNamespace(dbNameOverride, '$cmd');\n        }\n        else {\n            this.ns = parent\n                ? parent.s.namespace.withCollection('$cmd')\n                : new utils_1.MongoDBNamespace('admin', '$cmd');\n        }\n        this.readConcern = read_concern_1.ReadConcern.fromOptions(options);\n        this.writeConcern = write_concern_1.WriteConcern.fromOptions(options);\n        if (this.hasAspect(operation_1.Aspect.EXPLAINABLE)) {\n            this.explain = explain_1.Explain.fromOptions(options);\n        }\n        else if (options?.explain != null) {\n            throw new error_1.MongoInvalidArgumentError(`Option \"explain\" is not supported on this command`);\n        }\n    }\n    get canRetryWrite() {\n        if (this.hasAspect(operation_1.Aspect.EXPLAINABLE)) {\n            return this.explain == null;\n        }\n        return true;\n    }\n    async executeCommand(server, session, cmd) {\n        // TODO: consider making this a non-enumerable property\n        this.server = server;\n        const options = {\n            ...this.options,\n            ...this.bsonOptions,\n            readPreference: this.readPreference,\n            session\n        };\n        const serverWireVersion = (0, utils_1.maxWireVersion)(server);\n        const inTransaction = this.session && this.session.inTransaction();\n        if (this.readConcern && (0, utils_1.commandSupportsReadConcern)(cmd) && !inTransaction) {\n            Object.assign(cmd, { readConcern: this.readConcern });\n        }\n        if (this.trySecondaryWrite && serverWireVersion < server_selection_1.MIN_SECONDARY_WRITE_WIRE_VERSION) {\n            options.omitReadPreference = true;\n        }\n        if (this.writeConcern && this.hasAspect(operation_1.Aspect.WRITE_OPERATION) && !inTransaction) {\n            write_concern_1.WriteConcern.apply(cmd, this.writeConcern);\n        }\n        if (options.collation &&\n            typeof options.collation === 'object' &&\n            !this.hasAspect(operation_1.Aspect.SKIP_COLLATION)) {\n            Object.assign(cmd, { collation: options.collation });\n        }\n        if (typeof options.maxTimeMS === 'number') {\n            cmd.maxTimeMS = options.maxTimeMS;\n        }\n        if (this.hasAspect(operation_1.Aspect.EXPLAINABLE) && this.explain) {\n            cmd = (0, utils_1.decorateWithExplain)(cmd, this.explain);\n        }\n        return await server.command(this.ns, cmd, options);\n    }\n}\nexports.CommandOperation = CommandOperation;\n//# sourceMappingURL=command.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/command.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/count.js":
/*!******************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/count.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CountOperation = void 0;\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass CountOperation extends command_1.CommandOperation {\n    constructor(namespace, filter, options) {\n        super({ s: { namespace: namespace } }, options);\n        this.options = options;\n        this.collectionName = namespace.collection;\n        this.query = filter;\n    }\n    get commandName() {\n        return 'count';\n    }\n    async execute(server, session) {\n        const options = this.options;\n        const cmd = {\n            count: this.collectionName,\n            query: this.query\n        };\n        if (typeof options.limit === 'number') {\n            cmd.limit = options.limit;\n        }\n        if (typeof options.skip === 'number') {\n            cmd.skip = options.skip;\n        }\n        if (options.hint != null) {\n            cmd.hint = options.hint;\n        }\n        if (typeof options.maxTimeMS === 'number') {\n            cmd.maxTimeMS = options.maxTimeMS;\n        }\n        const result = await super.executeCommand(server, session, cmd);\n        return result ? result.n : 0;\n    }\n}\nexports.CountOperation = CountOperation;\n(0, operation_1.defineAspects)(CountOperation, [operation_1.Aspect.READ_OPERATION, operation_1.Aspect.RETRYABLE]);\n//# sourceMappingURL=count.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/count.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/count_documents.js":
/*!****************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/count_documents.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CountDocumentsOperation = void 0;\nconst aggregate_1 = __webpack_require__(/*! ./aggregate */ \"./node_modules/mongodb/lib/operations/aggregate.js\");\n/** @internal */\nclass CountDocumentsOperation extends aggregate_1.AggregateOperation {\n    constructor(collection, query, options) {\n        const pipeline = [];\n        pipeline.push({ $match: query });\n        if (typeof options.skip === 'number') {\n            pipeline.push({ $skip: options.skip });\n        }\n        if (typeof options.limit === 'number') {\n            pipeline.push({ $limit: options.limit });\n        }\n        pipeline.push({ $group: { _id: 1, n: { $sum: 1 } } });\n        super(collection.s.namespace, pipeline, options);\n    }\n    async execute(server, session) {\n        const result = await super.execute(server, session);\n        // NOTE: We're avoiding creating a cursor here to reduce the callstack.\n        const response = result;\n        if (response.cursor == null || response.cursor.firstBatch == null) {\n            return 0;\n        }\n        const docs = response.cursor.firstBatch;\n        return docs.length ? docs[0].n : 0;\n    }\n}\nexports.CountDocumentsOperation = CountDocumentsOperation;\n//# sourceMappingURL=count_documents.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/count_documents.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/create_collection.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/create_collection.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CreateCollectionOperation = void 0;\nconst constants_1 = __webpack_require__(/*! ../cmap/wire_protocol/constants */ \"./node_modules/mongodb/lib/cmap/wire_protocol/constants.js\");\nconst collection_1 = __webpack_require__(/*! ../collection */ \"./node_modules/mongodb/lib/collection.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst indexes_1 = __webpack_require__(/*! ./indexes */ \"./node_modules/mongodb/lib/operations/indexes.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\nconst ILLEGAL_COMMAND_FIELDS = new Set([\n    'w',\n    'wtimeout',\n    'j',\n    'fsync',\n    'autoIndexId',\n    'pkFactory',\n    'raw',\n    'readPreference',\n    'session',\n    'readConcern',\n    'writeConcern',\n    'raw',\n    'fieldsAsRaw',\n    'useBigInt64',\n    'promoteLongs',\n    'promoteValues',\n    'promoteBuffers',\n    'bsonRegExp',\n    'serializeFunctions',\n    'ignoreUndefined',\n    'enableUtf8Validation'\n]);\n/* @internal */\nconst INVALID_QE_VERSION = 'Driver support of Queryable Encryption is incompatible with server. Upgrade server to use Queryable Encryption.';\n/** @internal */\nclass CreateCollectionOperation extends command_1.CommandOperation {\n    constructor(db, name, options = {}) {\n        super(db, options);\n        this.options = options;\n        this.db = db;\n        this.name = name;\n    }\n    get commandName() {\n        return 'create';\n    }\n    async execute(server, session) {\n        const db = this.db;\n        const name = this.name;\n        const options = this.options;\n        const encryptedFields = options.encryptedFields ??\n            db.client.options.autoEncryption?.encryptedFieldsMap?.[`${db.databaseName}.${name}`];\n        if (encryptedFields) {\n            // Creating a QE collection required min server of 7.0.0\n            // TODO(NODE-5353): Get wire version information from connection.\n            if (!server.loadBalanced &&\n                server.description.maxWireVersion < constants_1.MIN_SUPPORTED_QE_WIRE_VERSION) {\n                throw new error_1.MongoCompatibilityError(`${INVALID_QE_VERSION} The minimum server version required is ${constants_1.MIN_SUPPORTED_QE_SERVER_VERSION}`);\n            }\n            // Create auxilliary collections for queryable encryption support.\n            const escCollection = encryptedFields.escCollection ?? `enxcol_.${name}.esc`;\n            const ecocCollection = encryptedFields.ecocCollection ?? `enxcol_.${name}.ecoc`;\n            for (const collectionName of [escCollection, ecocCollection]) {\n                const createOp = new CreateCollectionOperation(db, collectionName, {\n                    clusteredIndex: {\n                        key: { _id: 1 },\n                        unique: true\n                    }\n                });\n                await createOp.executeWithoutEncryptedFieldsCheck(server, session);\n            }\n            if (!options.encryptedFields) {\n                this.options = { ...this.options, encryptedFields };\n            }\n        }\n        const coll = await this.executeWithoutEncryptedFieldsCheck(server, session);\n        if (encryptedFields) {\n            // Create the required index for queryable encryption support.\n            const createIndexOp = indexes_1.CreateIndexesOperation.fromIndexSpecification(db, name, { __safeContent__: 1 }, {});\n            await createIndexOp.execute(server, session);\n        }\n        return coll;\n    }\n    async executeWithoutEncryptedFieldsCheck(server, session) {\n        const db = this.db;\n        const name = this.name;\n        const options = this.options;\n        const cmd = { create: name };\n        for (const n in options) {\n            if (options[n] != null &&\n                typeof options[n] !== 'function' &&\n                !ILLEGAL_COMMAND_FIELDS.has(n)) {\n                cmd[n] = options[n];\n            }\n        }\n        // otherwise just execute the command\n        await super.executeCommand(server, session, cmd);\n        return new collection_1.Collection(db, name, options);\n    }\n}\nexports.CreateCollectionOperation = CreateCollectionOperation;\n(0, operation_1.defineAspects)(CreateCollectionOperation, [operation_1.Aspect.WRITE_OPERATION]);\n//# sourceMappingURL=create_collection.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/create_collection.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/delete.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/delete.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.makeDeleteStatement = exports.DeleteManyOperation = exports.DeleteOneOperation = exports.DeleteOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass DeleteOperation extends command_1.CommandOperation {\n    constructor(ns, statements, options) {\n        super(undefined, options);\n        this.options = options;\n        this.ns = ns;\n        this.statements = statements;\n    }\n    get commandName() {\n        return 'delete';\n    }\n    get canRetryWrite() {\n        if (super.canRetryWrite === false) {\n            return false;\n        }\n        return this.statements.every(op => (op.limit != null ? op.limit > 0 : true));\n    }\n    async execute(server, session) {\n        const options = this.options ?? {};\n        const ordered = typeof options.ordered === 'boolean' ? options.ordered : true;\n        const command = {\n            delete: this.ns.collection,\n            deletes: this.statements,\n            ordered\n        };\n        if (options.let) {\n            command.let = options.let;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (options.comment !== undefined) {\n            command.comment = options.comment;\n        }\n        const unacknowledgedWrite = this.writeConcern && this.writeConcern.w === 0;\n        if (unacknowledgedWrite) {\n            if (this.statements.find((o) => o.hint)) {\n                // TODO(NODE-3541): fix error for hint with unacknowledged writes\n                throw new error_1.MongoCompatibilityError(`hint is not supported with unacknowledged writes`);\n            }\n        }\n        const res = await super.executeCommand(server, session, command);\n        return res;\n    }\n}\nexports.DeleteOperation = DeleteOperation;\nclass DeleteOneOperation extends DeleteOperation {\n    constructor(collection, filter, options) {\n        super(collection.s.namespace, [makeDeleteStatement(filter, { ...options, limit: 1 })], options);\n    }\n    async execute(server, session) {\n        const res = await super.execute(server, session);\n        if (this.explain)\n            return res;\n        if (res.code)\n            throw new error_1.MongoServerError(res);\n        if (res.writeErrors)\n            throw new error_1.MongoServerError(res.writeErrors[0]);\n        return {\n            acknowledged: this.writeConcern?.w !== 0,\n            deletedCount: res.n\n        };\n    }\n}\nexports.DeleteOneOperation = DeleteOneOperation;\nclass DeleteManyOperation extends DeleteOperation {\n    constructor(collection, filter, options) {\n        super(collection.s.namespace, [makeDeleteStatement(filter, options)], options);\n    }\n    async execute(server, session) {\n        const res = await super.execute(server, session);\n        if (this.explain)\n            return res;\n        if (res.code)\n            throw new error_1.MongoServerError(res);\n        if (res.writeErrors)\n            throw new error_1.MongoServerError(res.writeErrors[0]);\n        return {\n            acknowledged: this.writeConcern?.w !== 0,\n            deletedCount: res.n\n        };\n    }\n}\nexports.DeleteManyOperation = DeleteManyOperation;\nfunction makeDeleteStatement(filter, options) {\n    const op = {\n        q: filter,\n        limit: typeof options.limit === 'number' ? options.limit : 0\n    };\n    if (options.collation) {\n        op.collation = options.collation;\n    }\n    if (options.hint) {\n        op.hint = options.hint;\n    }\n    return op;\n}\nexports.makeDeleteStatement = makeDeleteStatement;\n(0, operation_1.defineAspects)(DeleteOperation, [operation_1.Aspect.RETRYABLE, operation_1.Aspect.WRITE_OPERATION]);\n(0, operation_1.defineAspects)(DeleteOneOperation, [\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.WRITE_OPERATION,\n    operation_1.Aspect.EXPLAINABLE,\n    operation_1.Aspect.SKIP_COLLATION\n]);\n(0, operation_1.defineAspects)(DeleteManyOperation, [\n    operation_1.Aspect.WRITE_OPERATION,\n    operation_1.Aspect.EXPLAINABLE,\n    operation_1.Aspect.SKIP_COLLATION\n]);\n//# sourceMappingURL=delete.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/delete.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/distinct.js":
/*!*********************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/distinct.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DistinctOperation = void 0;\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/**\n * Return a list of distinct values for the given key across a collection.\n * @internal\n */\nclass DistinctOperation extends command_1.CommandOperation {\n    /**\n     * Construct a Distinct operation.\n     *\n     * @param collection - Collection instance.\n     * @param key - Field of the document to find distinct values for.\n     * @param query - The query for filtering the set of documents to which we apply the distinct filter.\n     * @param options - Optional settings. See Collection.prototype.distinct for a list of options.\n     */\n    constructor(collection, key, query, options) {\n        super(collection, options);\n        this.options = options ?? {};\n        this.collection = collection;\n        this.key = key;\n        this.query = query;\n    }\n    get commandName() {\n        return 'distinct';\n    }\n    async execute(server, session) {\n        const coll = this.collection;\n        const key = this.key;\n        const query = this.query;\n        const options = this.options;\n        // Distinct command\n        const cmd = {\n            distinct: coll.collectionName,\n            key: key,\n            query: query\n        };\n        // Add maxTimeMS if defined\n        if (typeof options.maxTimeMS === 'number') {\n            cmd.maxTimeMS = options.maxTimeMS;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (typeof options.comment !== 'undefined') {\n            cmd.comment = options.comment;\n        }\n        // Do we have a readConcern specified\n        (0, utils_1.decorateWithReadConcern)(cmd, coll, options);\n        // Have we specified collation\n        (0, utils_1.decorateWithCollation)(cmd, coll, options);\n        const result = await super.executeCommand(server, session, cmd);\n        return this.explain ? result : result.values;\n    }\n}\nexports.DistinctOperation = DistinctOperation;\n(0, operation_1.defineAspects)(DistinctOperation, [operation_1.Aspect.READ_OPERATION, operation_1.Aspect.RETRYABLE, operation_1.Aspect.EXPLAINABLE]);\n//# sourceMappingURL=distinct.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/distinct.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/drop.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/drop.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DropDatabaseOperation = exports.DropCollectionOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass DropCollectionOperation extends command_1.CommandOperation {\n    constructor(db, name, options = {}) {\n        super(db, options);\n        this.db = db;\n        this.options = options;\n        this.name = name;\n    }\n    get commandName() {\n        return 'drop';\n    }\n    async execute(server, session) {\n        const db = this.db;\n        const options = this.options;\n        const name = this.name;\n        const encryptedFieldsMap = db.client.options.autoEncryption?.encryptedFieldsMap;\n        let encryptedFields = options.encryptedFields ?? encryptedFieldsMap?.[`${db.databaseName}.${name}`];\n        if (!encryptedFields && encryptedFieldsMap) {\n            // If the MongoClient was configured with an encryptedFieldsMap,\n            // and no encryptedFields config was available in it or explicitly\n            // passed as an argument, the spec tells us to look one up using\n            // listCollections().\n            const listCollectionsResult = await db\n                .listCollections({ name }, { nameOnly: false })\n                .toArray();\n            encryptedFields = listCollectionsResult?.[0]?.options?.encryptedFields;\n        }\n        if (encryptedFields) {\n            const escCollection = encryptedFields.escCollection || `enxcol_.${name}.esc`;\n            const ecocCollection = encryptedFields.ecocCollection || `enxcol_.${name}.ecoc`;\n            for (const collectionName of [escCollection, ecocCollection]) {\n                // Drop auxilliary collections, ignoring potential NamespaceNotFound errors.\n                const dropOp = new DropCollectionOperation(db, collectionName);\n                try {\n                    await dropOp.executeWithoutEncryptedFieldsCheck(server, session);\n                }\n                catch (err) {\n                    if (!(err instanceof error_1.MongoServerError) ||\n                        err.code !== error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n                        throw err;\n                    }\n                }\n            }\n        }\n        return await this.executeWithoutEncryptedFieldsCheck(server, session);\n    }\n    async executeWithoutEncryptedFieldsCheck(server, session) {\n        await super.executeCommand(server, session, { drop: this.name });\n        return true;\n    }\n}\nexports.DropCollectionOperation = DropCollectionOperation;\n/** @internal */\nclass DropDatabaseOperation extends command_1.CommandOperation {\n    constructor(db, options) {\n        super(db, options);\n        this.options = options;\n    }\n    get commandName() {\n        return 'dropDatabase';\n    }\n    async execute(server, session) {\n        await super.executeCommand(server, session, { dropDatabase: 1 });\n        return true;\n    }\n}\nexports.DropDatabaseOperation = DropDatabaseOperation;\n(0, operation_1.defineAspects)(DropCollectionOperation, [operation_1.Aspect.WRITE_OPERATION]);\n(0, operation_1.defineAspects)(DropDatabaseOperation, [operation_1.Aspect.WRITE_OPERATION]);\n//# sourceMappingURL=drop.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/drop.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/estimated_document_count.js":
/*!*************************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/estimated_document_count.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.EstimatedDocumentCountOperation = void 0;\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass EstimatedDocumentCountOperation extends command_1.CommandOperation {\n    constructor(collection, options = {}) {\n        super(collection, options);\n        this.options = options;\n        this.collectionName = collection.collectionName;\n    }\n    get commandName() {\n        return 'count';\n    }\n    async execute(server, session) {\n        const cmd = { count: this.collectionName };\n        if (typeof this.options.maxTimeMS === 'number') {\n            cmd.maxTimeMS = this.options.maxTimeMS;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (this.options.comment !== undefined) {\n            cmd.comment = this.options.comment;\n        }\n        const response = await super.executeCommand(server, session, cmd);\n        return response?.n || 0;\n    }\n}\nexports.EstimatedDocumentCountOperation = EstimatedDocumentCountOperation;\n(0, operation_1.defineAspects)(EstimatedDocumentCountOperation, [\n    operation_1.Aspect.READ_OPERATION,\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.CURSOR_CREATING\n]);\n//# sourceMappingURL=estimated_document_count.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/estimated_document_count.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/execute_operation.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/execute_operation.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.executeOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_preference_1 = __webpack_require__(/*! ../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst server_selection_1 = __webpack_require__(/*! ../sdam/server_selection */ \"./node_modules/mongodb/lib/sdam/server_selection.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\nconst MMAPv1_RETRY_WRITES_ERROR_CODE = error_1.MONGODB_ERROR_CODES.IllegalOperation;\nconst MMAPv1_RETRY_WRITES_ERROR_MESSAGE = 'This MongoDB deployment does not support retryable writes. Please add retryWrites=false to your connection string.';\n/**\n * Executes the given operation with provided arguments.\n * @internal\n *\n * @remarks\n * Allows for a single point of entry to provide features such as implicit sessions, which\n * are required by the Driver Sessions specification in the event that a ClientSession is\n * not provided.\n *\n * The expectation is that this function:\n * - Connects the MongoClient if it has not already been connected\n * - Creates a session if none is provided and cleans up the session it creates\n * - Selects a server based on readPreference or various factors\n * - Retries an operation if it fails for certain errors, see {@link retryOperation}\n *\n * @typeParam T - The operation's type\n * @typeParam TResult - The type of the operation's result, calculated from T\n *\n * @param client - The MongoClient to execute this operation with\n * @param operation - The operation to execute\n */\nasync function executeOperation(client, operation) {\n    if (!(operation instanceof operation_1.AbstractOperation)) {\n        // TODO(NODE-3483): Extend MongoRuntimeError\n        throw new error_1.MongoRuntimeError('This method requires a valid operation instance');\n    }\n    if (client.topology == null) {\n        // Auto connect on operation\n        if (client.s.hasBeenClosed) {\n            throw new error_1.MongoNotConnectedError('Client must be connected before running operations');\n        }\n        client.s.options[Symbol.for('@@mdb.skipPingOnConnect')] = true;\n        try {\n            await client.connect();\n        }\n        finally {\n            delete client.s.options[Symbol.for('@@mdb.skipPingOnConnect')];\n        }\n    }\n    const { topology } = client;\n    if (topology == null) {\n        throw new error_1.MongoRuntimeError('client.connect did not create a topology but also did not throw');\n    }\n    // The driver sessions spec mandates that we implicitly create sessions for operations\n    // that are not explicitly provided with a session.\n    let session = operation.session;\n    let owner;\n    if (session == null) {\n        owner = Symbol();\n        session = client.startSession({ owner, explicit: false });\n    }\n    else if (session.hasEnded) {\n        throw new error_1.MongoExpiredSessionError('Use of expired sessions is not permitted');\n    }\n    else if (session.snapshotEnabled && !topology.capabilities.supportsSnapshotReads) {\n        throw new error_1.MongoCompatibilityError('Snapshot reads require MongoDB 5.0 or later');\n    }\n    else if (session.client !== client) {\n        throw new error_1.MongoInvalidArgumentError('ClientSession must be from the same MongoClient');\n    }\n    if (session.explicit && session?.timeoutMS != null && operation.options.timeoutMS != null) {\n        throw new error_1.MongoInvalidArgumentError('Do not specify timeoutMS on operation if already specified on an explicit session');\n    }\n    const readPreference = operation.readPreference ?? read_preference_1.ReadPreference.primary;\n    const inTransaction = !!session?.inTransaction();\n    const hasReadAspect = operation.hasAspect(operation_1.Aspect.READ_OPERATION);\n    const hasWriteAspect = operation.hasAspect(operation_1.Aspect.WRITE_OPERATION);\n    if (inTransaction &&\n        !readPreference.equals(read_preference_1.ReadPreference.primary) &&\n        (hasReadAspect || operation.commandName === 'runCommand')) {\n        throw new error_1.MongoTransactionError(`Read preference in a transaction must be primary, not: ${readPreference.mode}`);\n    }\n    if (session?.isPinned && session.transaction.isCommitted && !operation.bypassPinningCheck) {\n        session.unpin();\n    }\n    let selector;\n    if (operation.hasAspect(operation_1.Aspect.MUST_SELECT_SAME_SERVER)) {\n        // GetMore and KillCursor operations must always select the same server, but run through\n        // server selection to potentially force monitor checks if the server is\n        // in an unknown state.\n        selector = (0, server_selection_1.sameServerSelector)(operation.server?.description);\n    }\n    else if (operation.trySecondaryWrite) {\n        // If operation should try to write to secondary use the custom server selector\n        // otherwise provide the read preference.\n        selector = (0, server_selection_1.secondaryWritableServerSelector)(topology.commonWireVersion, readPreference);\n    }\n    else {\n        selector = readPreference;\n    }\n    const server = await topology.selectServer(selector, {\n        session,\n        operationName: operation.commandName\n    });\n    if (session == null) {\n        // No session also means it is not retryable, early exit\n        return await operation.execute(server, undefined);\n    }\n    if (!operation.hasAspect(operation_1.Aspect.RETRYABLE)) {\n        // non-retryable operation, early exit\n        try {\n            return await operation.execute(server, session);\n        }\n        finally {\n            if (session?.owner != null && session.owner === owner) {\n                try {\n                    await session.endSession();\n                }\n                catch (error) {\n                    (0, utils_1.squashError)(error);\n                }\n            }\n        }\n    }\n    const willRetryRead = topology.s.options.retryReads && !inTransaction && operation.canRetryRead;\n    const willRetryWrite = topology.s.options.retryWrites &&\n        !inTransaction &&\n        (0, utils_1.supportsRetryableWrites)(server) &&\n        operation.canRetryWrite;\n    const willRetry = (hasReadAspect && willRetryRead) || (hasWriteAspect && willRetryWrite);\n    if (hasWriteAspect && willRetryWrite) {\n        operation.options.willRetryWrite = true;\n        session.incrementTransactionNumber();\n    }\n    try {\n        return await operation.execute(server, session);\n    }\n    catch (operationError) {\n        if (willRetry && operationError instanceof error_1.MongoError) {\n            return await retryOperation(operation, operationError, {\n                session,\n                topology,\n                selector,\n                previousServer: server.description\n            });\n        }\n        throw operationError;\n    }\n    finally {\n        if (session?.owner != null && session.owner === owner) {\n            try {\n                await session.endSession();\n            }\n            catch (error) {\n                (0, utils_1.squashError)(error);\n            }\n        }\n    }\n}\nexports.executeOperation = executeOperation;\nasync function retryOperation(operation, originalError, { session, topology, selector, previousServer }) {\n    const isWriteOperation = operation.hasAspect(operation_1.Aspect.WRITE_OPERATION);\n    const isReadOperation = operation.hasAspect(operation_1.Aspect.READ_OPERATION);\n    if (isWriteOperation && originalError.code === MMAPv1_RETRY_WRITES_ERROR_CODE) {\n        throw new error_1.MongoServerError({\n            message: MMAPv1_RETRY_WRITES_ERROR_MESSAGE,\n            errmsg: MMAPv1_RETRY_WRITES_ERROR_MESSAGE,\n            originalError\n        });\n    }\n    if (isWriteOperation && !(0, error_1.isRetryableWriteError)(originalError)) {\n        throw originalError;\n    }\n    if (isReadOperation && !(0, error_1.isRetryableReadError)(originalError)) {\n        throw originalError;\n    }\n    if (originalError instanceof error_1.MongoNetworkError &&\n        session.isPinned &&\n        !session.inTransaction() &&\n        operation.hasAspect(operation_1.Aspect.CURSOR_CREATING)) {\n        // If we have a cursor and the initial command fails with a network error,\n        // we can retry it on another connection. So we need to check it back in, clear the\n        // pool for the service id, and retry again.\n        session.unpin({ force: true, forceClear: true });\n    }\n    // select a new server, and attempt to retry the operation\n    const server = await topology.selectServer(selector, {\n        session,\n        operationName: operation.commandName,\n        previousServer\n    });\n    if (isWriteOperation && !(0, utils_1.supportsRetryableWrites)(server)) {\n        throw new error_1.MongoUnexpectedServerResponseError('Selected server does not support retryable writes');\n    }\n    try {\n        return await operation.execute(server, session);\n    }\n    catch (retryError) {\n        if (retryError instanceof error_1.MongoError &&\n            retryError.hasErrorLabel(error_1.MongoErrorLabel.NoWritesPerformed)) {\n            throw originalError;\n        }\n        throw retryError;\n    }\n}\n//# sourceMappingURL=execute_operation.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/execute_operation.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/find.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/find.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.FindOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_concern_1 = __webpack_require__(/*! ../read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst sort_1 = __webpack_require__(/*! ../sort */ \"./node_modules/mongodb/lib/sort.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass FindOperation extends command_1.CommandOperation {\n    constructor(ns, filter = {}, options = {}) {\n        super(undefined, options);\n        this.options = { ...options };\n        delete this.options.writeConcern;\n        this.ns = ns;\n        if (typeof filter !== 'object' || Array.isArray(filter)) {\n            throw new error_1.MongoInvalidArgumentError('Query filter must be a plain object or ObjectId');\n        }\n        // special case passing in an ObjectId as a filter\n        this.filter = filter != null && filter._bsontype === 'ObjectId' ? { _id: filter } : filter;\n    }\n    get commandName() {\n        return 'find';\n    }\n    async execute(server, session) {\n        this.server = server;\n        const options = this.options;\n        let findCommand = makeFindCommand(this.ns, this.filter, options);\n        if (this.explain) {\n            findCommand = (0, utils_1.decorateWithExplain)(findCommand, this.explain);\n        }\n        return await server.command(this.ns, findCommand, {\n            ...this.options,\n            ...this.bsonOptions,\n            documentsReturnedIn: 'firstBatch',\n            session\n        }, undefined);\n    }\n}\nexports.FindOperation = FindOperation;\nfunction makeFindCommand(ns, filter, options) {\n    const findCommand = {\n        find: ns.collection,\n        filter\n    };\n    if (options.sort) {\n        findCommand.sort = (0, sort_1.formatSort)(options.sort);\n    }\n    if (options.projection) {\n        let projection = options.projection;\n        if (projection && Array.isArray(projection)) {\n            projection = projection.length\n                ? projection.reduce((result, field) => {\n                    result[field] = 1;\n                    return result;\n                }, {})\n                : { _id: 1 };\n        }\n        findCommand.projection = projection;\n    }\n    if (options.hint) {\n        findCommand.hint = (0, utils_1.normalizeHintField)(options.hint);\n    }\n    if (typeof options.skip === 'number') {\n        findCommand.skip = options.skip;\n    }\n    if (typeof options.limit === 'number') {\n        if (options.limit < 0) {\n            findCommand.limit = -options.limit;\n            findCommand.singleBatch = true;\n        }\n        else {\n            findCommand.limit = options.limit;\n        }\n    }\n    if (typeof options.batchSize === 'number') {\n        if (options.batchSize < 0) {\n            if (options.limit &&\n                options.limit !== 0 &&\n                Math.abs(options.batchSize) < Math.abs(options.limit)) {\n                findCommand.limit = -options.batchSize;\n            }\n            findCommand.singleBatch = true;\n        }\n        else {\n            findCommand.batchSize = options.batchSize;\n        }\n    }\n    if (typeof options.singleBatch === 'boolean') {\n        findCommand.singleBatch = options.singleBatch;\n    }\n    // we check for undefined specifically here to allow falsy values\n    // eslint-disable-next-line no-restricted-syntax\n    if (options.comment !== undefined) {\n        findCommand.comment = options.comment;\n    }\n    if (typeof options.maxTimeMS === 'number') {\n        findCommand.maxTimeMS = options.maxTimeMS;\n    }\n    const readConcern = read_concern_1.ReadConcern.fromOptions(options);\n    if (readConcern) {\n        findCommand.readConcern = readConcern.toJSON();\n    }\n    if (options.max) {\n        findCommand.max = options.max;\n    }\n    if (options.min) {\n        findCommand.min = options.min;\n    }\n    if (typeof options.returnKey === 'boolean') {\n        findCommand.returnKey = options.returnKey;\n    }\n    if (typeof options.showRecordId === 'boolean') {\n        findCommand.showRecordId = options.showRecordId;\n    }\n    if (typeof options.tailable === 'boolean') {\n        findCommand.tailable = options.tailable;\n    }\n    if (typeof options.oplogReplay === 'boolean') {\n        findCommand.oplogReplay = options.oplogReplay;\n    }\n    if (typeof options.timeout === 'boolean') {\n        findCommand.noCursorTimeout = !options.timeout;\n    }\n    else if (typeof options.noCursorTimeout === 'boolean') {\n        findCommand.noCursorTimeout = options.noCursorTimeout;\n    }\n    if (typeof options.awaitData === 'boolean') {\n        findCommand.awaitData = options.awaitData;\n    }\n    if (typeof options.allowPartialResults === 'boolean') {\n        findCommand.allowPartialResults = options.allowPartialResults;\n    }\n    if (options.collation) {\n        findCommand.collation = options.collation;\n    }\n    if (typeof options.allowDiskUse === 'boolean') {\n        findCommand.allowDiskUse = options.allowDiskUse;\n    }\n    if (options.let) {\n        findCommand.let = options.let;\n    }\n    return findCommand;\n}\n(0, operation_1.defineAspects)(FindOperation, [\n    operation_1.Aspect.READ_OPERATION,\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.EXPLAINABLE,\n    operation_1.Aspect.CURSOR_CREATING\n]);\n//# sourceMappingURL=find.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/find.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/find_and_modify.js":
/*!****************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/find_and_modify.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.FindOneAndUpdateOperation = exports.FindOneAndReplaceOperation = exports.FindOneAndDeleteOperation = exports.FindAndModifyOperation = exports.ReturnDocument = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_preference_1 = __webpack_require__(/*! ../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst sort_1 = __webpack_require__(/*! ../sort */ \"./node_modules/mongodb/lib/sort.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @public */\nexports.ReturnDocument = Object.freeze({\n    BEFORE: 'before',\n    AFTER: 'after'\n});\nfunction configureFindAndModifyCmdBaseUpdateOpts(cmdBase, options) {\n    cmdBase.new = options.returnDocument === exports.ReturnDocument.AFTER;\n    cmdBase.upsert = options.upsert === true;\n    if (options.bypassDocumentValidation === true) {\n        cmdBase.bypassDocumentValidation = options.bypassDocumentValidation;\n    }\n    return cmdBase;\n}\n/** @internal */\nclass FindAndModifyOperation extends command_1.CommandOperation {\n    constructor(collection, query, options) {\n        super(collection, options);\n        this.options = options ?? {};\n        this.cmdBase = {\n            remove: false,\n            new: false,\n            upsert: false\n        };\n        options.includeResultMetadata ??= false;\n        const sort = (0, sort_1.formatSort)(options.sort);\n        if (sort) {\n            this.cmdBase.sort = sort;\n        }\n        if (options.projection) {\n            this.cmdBase.fields = options.projection;\n        }\n        if (options.maxTimeMS) {\n            this.cmdBase.maxTimeMS = options.maxTimeMS;\n        }\n        // Decorate the findAndModify command with the write Concern\n        if (options.writeConcern) {\n            this.cmdBase.writeConcern = options.writeConcern;\n        }\n        if (options.let) {\n            this.cmdBase.let = options.let;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (options.comment !== undefined) {\n            this.cmdBase.comment = options.comment;\n        }\n        // force primary read preference\n        this.readPreference = read_preference_1.ReadPreference.primary;\n        this.collection = collection;\n        this.query = query;\n    }\n    get commandName() {\n        return 'findAndModify';\n    }\n    async execute(server, session) {\n        const coll = this.collection;\n        const query = this.query;\n        const options = { ...this.options, ...this.bsonOptions };\n        // Create findAndModify command object\n        const cmd = {\n            findAndModify: coll.collectionName,\n            query: query,\n            ...this.cmdBase\n        };\n        // Have we specified collation\n        try {\n            (0, utils_1.decorateWithCollation)(cmd, coll, options);\n        }\n        catch (err) {\n            return err;\n        }\n        if (options.hint) {\n            // TODO: once this method becomes a CommandOperation we will have the server\n            // in place to check.\n            const unacknowledgedWrite = this.writeConcern?.w === 0;\n            if (unacknowledgedWrite || (0, utils_1.maxWireVersion)(server) < 8) {\n                throw new error_1.MongoCompatibilityError('The current topology does not support a hint on findAndModify commands');\n            }\n            cmd.hint = options.hint;\n        }\n        // Execute the command\n        const result = await super.executeCommand(server, session, cmd);\n        return options.includeResultMetadata ? result : result.value ?? null;\n    }\n}\nexports.FindAndModifyOperation = FindAndModifyOperation;\n/** @internal */\nclass FindOneAndDeleteOperation extends FindAndModifyOperation {\n    constructor(collection, filter, options) {\n        // Basic validation\n        if (filter == null || typeof filter !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('Argument \"filter\" must be an object');\n        }\n        super(collection, filter, options);\n        this.cmdBase.remove = true;\n    }\n}\nexports.FindOneAndDeleteOperation = FindOneAndDeleteOperation;\n/** @internal */\nclass FindOneAndReplaceOperation extends FindAndModifyOperation {\n    constructor(collection, filter, replacement, options) {\n        if (filter == null || typeof filter !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('Argument \"filter\" must be an object');\n        }\n        if (replacement == null || typeof replacement !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('Argument \"replacement\" must be an object');\n        }\n        if ((0, utils_1.hasAtomicOperators)(replacement)) {\n            throw new error_1.MongoInvalidArgumentError('Replacement document must not contain atomic operators');\n        }\n        super(collection, filter, options);\n        this.cmdBase.update = replacement;\n        configureFindAndModifyCmdBaseUpdateOpts(this.cmdBase, options);\n    }\n}\nexports.FindOneAndReplaceOperation = FindOneAndReplaceOperation;\n/** @internal */\nclass FindOneAndUpdateOperation extends FindAndModifyOperation {\n    constructor(collection, filter, update, options) {\n        if (filter == null || typeof filter !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('Argument \"filter\" must be an object');\n        }\n        if (update == null || typeof update !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('Argument \"update\" must be an object');\n        }\n        if (!(0, utils_1.hasAtomicOperators)(update)) {\n            throw new error_1.MongoInvalidArgumentError('Update document requires atomic operators');\n        }\n        super(collection, filter, options);\n        this.cmdBase.update = update;\n        configureFindAndModifyCmdBaseUpdateOpts(this.cmdBase, options);\n        if (options.arrayFilters) {\n            this.cmdBase.arrayFilters = options.arrayFilters;\n        }\n    }\n}\nexports.FindOneAndUpdateOperation = FindOneAndUpdateOperation;\n(0, operation_1.defineAspects)(FindAndModifyOperation, [\n    operation_1.Aspect.WRITE_OPERATION,\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.EXPLAINABLE\n]);\n//# sourceMappingURL=find_and_modify.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/find_and_modify.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/get_more.js":
/*!*********************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/get_more.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.GetMoreOperation = void 0;\nconst responses_1 = __webpack_require__(/*! ../cmap/wire_protocol/responses */ \"./node_modules/mongodb/lib/cmap/wire_protocol/responses.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass GetMoreOperation extends operation_1.AbstractOperation {\n    constructor(ns, cursorId, server, options) {\n        super(options);\n        this.options = options;\n        this.ns = ns;\n        this.cursorId = cursorId;\n        this.server = server;\n    }\n    get commandName() {\n        return 'getMore';\n    }\n    /**\n     * Although there is a server already associated with the get more operation, the signature\n     * for execute passes a server so we will just use that one.\n     */\n    async execute(server, _session) {\n        if (server !== this.server) {\n            throw new error_1.MongoRuntimeError('Getmore must run on the same server operation began on');\n        }\n        if (this.cursorId == null || this.cursorId.isZero()) {\n            throw new error_1.MongoRuntimeError('Unable to iterate cursor with no id');\n        }\n        const collection = this.ns.collection;\n        if (collection == null) {\n            // Cursors should have adopted the namespace returned by MongoDB\n            // which should always defined a collection name (even a pseudo one, ex. db.aggregate())\n            throw new error_1.MongoRuntimeError('A collection name must be determined before getMore');\n        }\n        const getMoreCmd = {\n            getMore: this.cursorId,\n            collection\n        };\n        if (typeof this.options.batchSize === 'number') {\n            getMoreCmd.batchSize = Math.abs(this.options.batchSize);\n        }\n        if (typeof this.options.maxAwaitTimeMS === 'number') {\n            getMoreCmd.maxTimeMS = this.options.maxAwaitTimeMS;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (this.options.comment !== undefined && (0, utils_1.maxWireVersion)(server) >= 9) {\n            getMoreCmd.comment = this.options.comment;\n        }\n        const commandOptions = {\n            returnFieldSelector: null,\n            documentsReturnedIn: 'nextBatch',\n            ...this.options\n        };\n        return await server.command(this.ns, getMoreCmd, commandOptions, this.options.useCursorResponse ? responses_1.CursorResponse : undefined);\n    }\n}\nexports.GetMoreOperation = GetMoreOperation;\n(0, operation_1.defineAspects)(GetMoreOperation, [operation_1.Aspect.READ_OPERATION, operation_1.Aspect.MUST_SELECT_SAME_SERVER]);\n//# sourceMappingURL=get_more.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/get_more.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/indexes.js":
/*!********************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/indexes.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ListIndexesOperation = exports.DropIndexOperation = exports.CreateIndexesOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\nconst VALID_INDEX_OPTIONS = new Set([\n    'background',\n    'unique',\n    'name',\n    'partialFilterExpression',\n    'sparse',\n    'hidden',\n    'expireAfterSeconds',\n    'storageEngine',\n    'collation',\n    'version',\n    // text indexes\n    'weights',\n    'default_language',\n    'language_override',\n    'textIndexVersion',\n    // 2d-sphere indexes\n    '2dsphereIndexVersion',\n    // 2d indexes\n    'bits',\n    'min',\n    'max',\n    // geoHaystack Indexes\n    'bucketSize',\n    // wildcard indexes\n    'wildcardProjection'\n]);\nfunction isIndexDirection(x) {\n    return (typeof x === 'number' || x === '2d' || x === '2dsphere' || x === 'text' || x === 'geoHaystack');\n}\nfunction isSingleIndexTuple(t) {\n    return Array.isArray(t) && t.length === 2 && isIndexDirection(t[1]);\n}\n/**\n * Converts an `IndexSpecification`, which can be specified in multiple formats, into a\n * valid `key` for the createIndexes command.\n */\nfunction constructIndexDescriptionMap(indexSpec) {\n    const key = new Map();\n    const indexSpecs = !Array.isArray(indexSpec) || isSingleIndexTuple(indexSpec) ? [indexSpec] : indexSpec;\n    // Iterate through array and handle different types\n    for (const spec of indexSpecs) {\n        if (typeof spec === 'string') {\n            key.set(spec, 1);\n        }\n        else if (Array.isArray(spec)) {\n            key.set(spec[0], spec[1] ?? 1);\n        }\n        else if (spec instanceof Map) {\n            for (const [property, value] of spec) {\n                key.set(property, value);\n            }\n        }\n        else if ((0, utils_1.isObject)(spec)) {\n            for (const [property, value] of Object.entries(spec)) {\n                key.set(property, value);\n            }\n        }\n    }\n    return key;\n}\n/**\n * Receives an index description and returns a modified index description which has had invalid options removed\n * from the description and has mapped the `version` option to the `v` option.\n */\nfunction resolveIndexDescription(description) {\n    const validProvidedOptions = Object.entries(description).filter(([optionName]) => VALID_INDEX_OPTIONS.has(optionName));\n    return Object.fromEntries(\n    // we support the `version` option, but the `createIndexes` command expects it to be the `v`\n    validProvidedOptions.map(([name, value]) => (name === 'version' ? ['v', value] : [name, value])));\n}\n/** @internal */\nclass CreateIndexesOperation extends command_1.CommandOperation {\n    constructor(parent, collectionName, indexes, options) {\n        super(parent, options);\n        this.options = options ?? {};\n        this.collectionName = collectionName;\n        this.indexes = indexes.map((userIndex) => {\n            // Ensure the key is a Map to preserve index key ordering\n            const key = userIndex.key instanceof Map ? userIndex.key : new Map(Object.entries(userIndex.key));\n            const name = userIndex.name ?? Array.from(key).flat().join('_');\n            const validIndexOptions = resolveIndexDescription(userIndex);\n            return {\n                ...validIndexOptions,\n                name,\n                key\n            };\n        });\n    }\n    static fromIndexDescriptionArray(parent, collectionName, indexes, options) {\n        return new CreateIndexesOperation(parent, collectionName, indexes, options);\n    }\n    static fromIndexSpecification(parent, collectionName, indexSpec, options = {}) {\n        const key = constructIndexDescriptionMap(indexSpec);\n        const description = { ...options, key };\n        return new CreateIndexesOperation(parent, collectionName, [description], options);\n    }\n    get commandName() {\n        return 'createIndexes';\n    }\n    async execute(server, session) {\n        const options = this.options;\n        const indexes = this.indexes;\n        const serverWireVersion = (0, utils_1.maxWireVersion)(server);\n        const cmd = { createIndexes: this.collectionName, indexes };\n        if (options.commitQuorum != null) {\n            if (serverWireVersion < 9) {\n                throw new error_1.MongoCompatibilityError('Option `commitQuorum` for `createIndexes` not supported on servers < 4.4');\n            }\n            cmd.commitQuorum = options.commitQuorum;\n        }\n        // collation is set on each index, it should not be defined at the root\n        this.options.collation = undefined;\n        await super.executeCommand(server, session, cmd);\n        const indexNames = indexes.map(index => index.name || '');\n        return indexNames;\n    }\n}\nexports.CreateIndexesOperation = CreateIndexesOperation;\n/** @internal */\nclass DropIndexOperation extends command_1.CommandOperation {\n    constructor(collection, indexName, options) {\n        super(collection, options);\n        this.options = options ?? {};\n        this.collection = collection;\n        this.indexName = indexName;\n    }\n    get commandName() {\n        return 'dropIndexes';\n    }\n    async execute(server, session) {\n        const cmd = { dropIndexes: this.collection.collectionName, index: this.indexName };\n        return await super.executeCommand(server, session, cmd);\n    }\n}\nexports.DropIndexOperation = DropIndexOperation;\n/** @internal */\nclass ListIndexesOperation extends command_1.CommandOperation {\n    constructor(collection, options) {\n        super(collection, options);\n        this.options = { ...options };\n        delete this.options.writeConcern;\n        this.collectionNamespace = collection.s.namespace;\n    }\n    get commandName() {\n        return 'listIndexes';\n    }\n    async execute(server, session) {\n        const serverWireVersion = (0, utils_1.maxWireVersion)(server);\n        const cursor = this.options.batchSize ? { batchSize: this.options.batchSize } : {};\n        const command = { listIndexes: this.collectionNamespace.collection, cursor };\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (serverWireVersion >= 9 && this.options.comment !== undefined) {\n            command.comment = this.options.comment;\n        }\n        return await super.executeCommand(server, session, command);\n    }\n}\nexports.ListIndexesOperation = ListIndexesOperation;\n(0, operation_1.defineAspects)(ListIndexesOperation, [\n    operation_1.Aspect.READ_OPERATION,\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.CURSOR_CREATING\n]);\n(0, operation_1.defineAspects)(CreateIndexesOperation, [operation_1.Aspect.WRITE_OPERATION]);\n(0, operation_1.defineAspects)(DropIndexOperation, [operation_1.Aspect.WRITE_OPERATION]);\n//# sourceMappingURL=indexes.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/indexes.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/insert.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/insert.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.InsertManyOperation = exports.InsertOneOperation = exports.InsertOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst write_concern_1 = __webpack_require__(/*! ../write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\nconst bulk_write_1 = __webpack_require__(/*! ./bulk_write */ \"./node_modules/mongodb/lib/operations/bulk_write.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass InsertOperation extends command_1.CommandOperation {\n    constructor(ns, documents, options) {\n        super(undefined, options);\n        this.options = { ...options, checkKeys: options.checkKeys ?? false };\n        this.ns = ns;\n        this.documents = documents;\n    }\n    get commandName() {\n        return 'insert';\n    }\n    async execute(server, session) {\n        const options = this.options ?? {};\n        const ordered = typeof options.ordered === 'boolean' ? options.ordered : true;\n        const command = {\n            insert: this.ns.collection,\n            documents: this.documents,\n            ordered\n        };\n        if (typeof options.bypassDocumentValidation === 'boolean') {\n            command.bypassDocumentValidation = options.bypassDocumentValidation;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (options.comment !== undefined) {\n            command.comment = options.comment;\n        }\n        return await super.executeCommand(server, session, command);\n    }\n}\nexports.InsertOperation = InsertOperation;\nclass InsertOneOperation extends InsertOperation {\n    constructor(collection, doc, options) {\n        super(collection.s.namespace, (0, utils_1.maybeAddIdToDocuments)(collection, [doc], options), options);\n    }\n    async execute(server, session) {\n        const res = await super.execute(server, session);\n        if (res.code)\n            throw new error_1.MongoServerError(res);\n        if (res.writeErrors) {\n            // This should be a WriteError but we can't change it now because of error hierarchy\n            throw new error_1.MongoServerError(res.writeErrors[0]);\n        }\n        return {\n            acknowledged: this.writeConcern?.w !== 0,\n            insertedId: this.documents[0]._id\n        };\n    }\n}\nexports.InsertOneOperation = InsertOneOperation;\n/** @internal */\nclass InsertManyOperation extends operation_1.AbstractOperation {\n    constructor(collection, docs, options) {\n        super(options);\n        if (!Array.isArray(docs)) {\n            throw new error_1.MongoInvalidArgumentError('Argument \"docs\" must be an array of documents');\n        }\n        this.options = options;\n        this.collection = collection;\n        this.docs = docs;\n    }\n    get commandName() {\n        return 'insert';\n    }\n    async execute(server, session) {\n        const coll = this.collection;\n        const options = { ...this.options, ...this.bsonOptions, readPreference: this.readPreference };\n        const writeConcern = write_concern_1.WriteConcern.fromOptions(options);\n        const bulkWriteOperation = new bulk_write_1.BulkWriteOperation(coll, this.docs.map(document => ({\n            insertOne: { document }\n        })), options);\n        try {\n            const res = await bulkWriteOperation.execute(server, session);\n            return {\n                acknowledged: writeConcern?.w !== 0,\n                insertedCount: res.insertedCount,\n                insertedIds: res.insertedIds\n            };\n        }\n        catch (err) {\n            if (err && err.message === 'Operation must be an object with an operation key') {\n                throw new error_1.MongoInvalidArgumentError('Collection.insertMany() cannot be called with an array that has null/undefined values');\n            }\n            throw err;\n        }\n    }\n}\nexports.InsertManyOperation = InsertManyOperation;\n(0, operation_1.defineAspects)(InsertOperation, [operation_1.Aspect.RETRYABLE, operation_1.Aspect.WRITE_OPERATION]);\n(0, operation_1.defineAspects)(InsertOneOperation, [operation_1.Aspect.RETRYABLE, operation_1.Aspect.WRITE_OPERATION]);\n(0, operation_1.defineAspects)(InsertManyOperation, [operation_1.Aspect.WRITE_OPERATION]);\n//# sourceMappingURL=insert.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/insert.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/is_capped.js":
/*!**********************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/is_capped.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.IsCappedOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass IsCappedOperation extends operation_1.AbstractOperation {\n    constructor(collection, options) {\n        super(options);\n        this.options = options;\n        this.collection = collection;\n    }\n    get commandName() {\n        return 'listCollections';\n    }\n    async execute(server, session) {\n        const coll = this.collection;\n        const [collection] = await coll.s.db\n            .listCollections({ name: coll.collectionName }, { ...this.options, nameOnly: false, readPreference: this.readPreference, session })\n            .toArray();\n        if (collection == null || collection.options == null) {\n            throw new error_1.MongoAPIError(`collection ${coll.namespace} not found`);\n        }\n        return !!collection.options?.capped;\n    }\n}\nexports.IsCappedOperation = IsCappedOperation;\n//# sourceMappingURL=is_capped.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/is_capped.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/kill_cursors.js":
/*!*************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/kill_cursors.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.KillCursorsOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\nclass KillCursorsOperation extends operation_1.AbstractOperation {\n    constructor(cursorId, ns, server, options) {\n        super(options);\n        this.ns = ns;\n        this.cursorId = cursorId;\n        this.server = server;\n    }\n    get commandName() {\n        return 'killCursors';\n    }\n    async execute(server, session) {\n        if (server !== this.server) {\n            throw new error_1.MongoRuntimeError('Killcursor must run on the same server operation began on');\n        }\n        const killCursors = this.ns.collection;\n        if (killCursors == null) {\n            // Cursors should have adopted the namespace returned by MongoDB\n            // which should always defined a collection name (even a pseudo one, ex. db.aggregate())\n            throw new error_1.MongoRuntimeError('A collection name must be determined before killCursors');\n        }\n        const killCursorsCommand = {\n            killCursors,\n            cursors: [this.cursorId]\n        };\n        try {\n            await server.command(this.ns, killCursorsCommand, { session });\n        }\n        catch (error) {\n            // The driver should never emit errors from killCursors, this is spec-ed behavior\n            (0, utils_1.squashError)(error);\n        }\n    }\n}\nexports.KillCursorsOperation = KillCursorsOperation;\n(0, operation_1.defineAspects)(KillCursorsOperation, [operation_1.Aspect.MUST_SELECT_SAME_SERVER]);\n//# sourceMappingURL=kill_cursors.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/kill_cursors.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/list_collections.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/list_collections.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ListCollectionsOperation = void 0;\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass ListCollectionsOperation extends command_1.CommandOperation {\n    constructor(db, filter, options) {\n        super(db, options);\n        this.options = { ...options };\n        delete this.options.writeConcern;\n        this.db = db;\n        this.filter = filter;\n        this.nameOnly = !!this.options.nameOnly;\n        this.authorizedCollections = !!this.options.authorizedCollections;\n        if (typeof this.options.batchSize === 'number') {\n            this.batchSize = this.options.batchSize;\n        }\n    }\n    get commandName() {\n        return 'listCollections';\n    }\n    async execute(server, session) {\n        return await super.executeCommand(server, session, this.generateCommand((0, utils_1.maxWireVersion)(server)));\n    }\n    /* This is here for the purpose of unit testing the final command that gets sent. */\n    generateCommand(wireVersion) {\n        const command = {\n            listCollections: 1,\n            filter: this.filter,\n            cursor: this.batchSize ? { batchSize: this.batchSize } : {},\n            nameOnly: this.nameOnly,\n            authorizedCollections: this.authorizedCollections\n        };\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (wireVersion >= 9 && this.options.comment !== undefined) {\n            command.comment = this.options.comment;\n        }\n        return command;\n    }\n}\nexports.ListCollectionsOperation = ListCollectionsOperation;\n(0, operation_1.defineAspects)(ListCollectionsOperation, [\n    operation_1.Aspect.READ_OPERATION,\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.CURSOR_CREATING\n]);\n//# sourceMappingURL=list_collections.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/list_collections.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/list_databases.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/list_databases.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ListDatabasesOperation = void 0;\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass ListDatabasesOperation extends command_1.CommandOperation {\n    constructor(db, options) {\n        super(db, options);\n        this.options = options ?? {};\n        this.ns = new utils_1.MongoDBNamespace('admin', '$cmd');\n    }\n    get commandName() {\n        return 'listDatabases';\n    }\n    async execute(server, session) {\n        const cmd = { listDatabases: 1 };\n        if (typeof this.options.nameOnly === 'boolean') {\n            cmd.nameOnly = this.options.nameOnly;\n        }\n        if (this.options.filter) {\n            cmd.filter = this.options.filter;\n        }\n        if (typeof this.options.authorizedDatabases === 'boolean') {\n            cmd.authorizedDatabases = this.options.authorizedDatabases;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if ((0, utils_1.maxWireVersion)(server) >= 9 && this.options.comment !== undefined) {\n            cmd.comment = this.options.comment;\n        }\n        return await super.executeCommand(server, session, cmd);\n    }\n}\nexports.ListDatabasesOperation = ListDatabasesOperation;\n(0, operation_1.defineAspects)(ListDatabasesOperation, [operation_1.Aspect.READ_OPERATION, operation_1.Aspect.RETRYABLE]);\n//# sourceMappingURL=list_databases.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/list_databases.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/operation.js":
/*!**********************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/operation.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.defineAspects = exports.AbstractOperation = exports.Aspect = void 0;\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst read_preference_1 = __webpack_require__(/*! ../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nexports.Aspect = {\n    READ_OPERATION: Symbol('READ_OPERATION'),\n    WRITE_OPERATION: Symbol('WRITE_OPERATION'),\n    RETRYABLE: Symbol('RETRYABLE'),\n    EXPLAINABLE: Symbol('EXPLAINABLE'),\n    SKIP_COLLATION: Symbol('SKIP_COLLATION'),\n    CURSOR_CREATING: Symbol('CURSOR_CREATING'),\n    MUST_SELECT_SAME_SERVER: Symbol('MUST_SELECT_SAME_SERVER')\n};\n/** @internal */\nconst kSession = Symbol('session');\n/**\n * This class acts as a parent class for any operation and is responsible for setting this.options,\n * as well as setting and getting a session.\n * Additionally, this class implements `hasAspect`, which determines whether an operation has\n * a specific aspect.\n * @internal\n */\nclass AbstractOperation {\n    constructor(options = {}) {\n        this.readPreference = this.hasAspect(exports.Aspect.WRITE_OPERATION)\n            ? read_preference_1.ReadPreference.primary\n            : read_preference_1.ReadPreference.fromOptions(options) ?? read_preference_1.ReadPreference.primary;\n        // Pull the BSON serialize options from the already-resolved options\n        this.bsonOptions = (0, bson_1.resolveBSONOptions)(options);\n        this[kSession] = options.session != null ? options.session : undefined;\n        this.options = options;\n        this.bypassPinningCheck = !!options.bypassPinningCheck;\n        this.trySecondaryWrite = false;\n    }\n    hasAspect(aspect) {\n        const ctor = this.constructor;\n        if (ctor.aspects == null) {\n            return false;\n        }\n        return ctor.aspects.has(aspect);\n    }\n    get session() {\n        return this[kSession];\n    }\n    clearSession() {\n        this[kSession] = undefined;\n    }\n    get canRetryRead() {\n        return true;\n    }\n    get canRetryWrite() {\n        return true;\n    }\n}\nexports.AbstractOperation = AbstractOperation;\nfunction defineAspects(operation, aspects) {\n    if (!Array.isArray(aspects) && !(aspects instanceof Set)) {\n        aspects = [aspects];\n    }\n    aspects = new Set(aspects);\n    Object.defineProperty(operation, 'aspects', {\n        value: aspects,\n        writable: false\n    });\n    return aspects;\n}\nexports.defineAspects = defineAspects;\n//# sourceMappingURL=operation.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/operation.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/options_operation.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/options_operation.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.OptionsOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass OptionsOperation extends operation_1.AbstractOperation {\n    constructor(collection, options) {\n        super(options);\n        this.options = options;\n        this.collection = collection;\n    }\n    get commandName() {\n        return 'listCollections';\n    }\n    async execute(server, session) {\n        const coll = this.collection;\n        const [collection] = await coll.s.db\n            .listCollections({ name: coll.collectionName }, { ...this.options, nameOnly: false, readPreference: this.readPreference, session })\n            .toArray();\n        if (collection == null || collection.options == null) {\n            throw new error_1.MongoAPIError(`collection ${coll.namespace} not found`);\n        }\n        return collection.options;\n    }\n}\nexports.OptionsOperation = OptionsOperation;\n//# sourceMappingURL=options_operation.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/options_operation.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/profiling_level.js":
/*!****************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/profiling_level.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ProfilingLevelOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\n/** @internal */\nclass ProfilingLevelOperation extends command_1.CommandOperation {\n    constructor(db, options) {\n        super(db, options);\n        this.options = options;\n    }\n    get commandName() {\n        return 'profile';\n    }\n    async execute(server, session) {\n        const doc = await super.executeCommand(server, session, { profile: -1 });\n        if (doc.ok === 1) {\n            const was = doc.was;\n            if (was === 0)\n                return 'off';\n            if (was === 1)\n                return 'slow_only';\n            if (was === 2)\n                return 'all';\n            throw new error_1.MongoUnexpectedServerResponseError(`Illegal profiling level value ${was}`);\n        }\n        else {\n            throw new error_1.MongoUnexpectedServerResponseError('Error with profile command');\n        }\n    }\n}\nexports.ProfilingLevelOperation = ProfilingLevelOperation;\n//# sourceMappingURL=profiling_level.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/profiling_level.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/remove_user.js":
/*!************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/remove_user.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RemoveUserOperation = void 0;\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass RemoveUserOperation extends command_1.CommandOperation {\n    constructor(db, username, options) {\n        super(db, options);\n        this.options = options;\n        this.username = username;\n    }\n    get commandName() {\n        return 'dropUser';\n    }\n    async execute(server, session) {\n        await super.executeCommand(server, session, { dropUser: this.username });\n        return true;\n    }\n}\nexports.RemoveUserOperation = RemoveUserOperation;\n(0, operation_1.defineAspects)(RemoveUserOperation, [operation_1.Aspect.WRITE_OPERATION]);\n//# sourceMappingURL=remove_user.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/remove_user.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/rename.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/rename.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RenameOperation = void 0;\nconst collection_1 = __webpack_require__(/*! ../collection */ \"./node_modules/mongodb/lib/collection.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass RenameOperation extends command_1.CommandOperation {\n    constructor(collection, newName, options) {\n        super(collection, options);\n        this.collection = collection;\n        this.newName = newName;\n        this.options = options;\n        this.ns = new utils_1.MongoDBNamespace('admin', '$cmd');\n    }\n    get commandName() {\n        return 'renameCollection';\n    }\n    async execute(server, session) {\n        // Build the command\n        const renameCollection = this.collection.namespace;\n        const toCollection = this.collection.s.namespace.withCollection(this.newName).toString();\n        const dropTarget = typeof this.options.dropTarget === 'boolean' ? this.options.dropTarget : false;\n        const command = {\n            renameCollection: renameCollection,\n            to: toCollection,\n            dropTarget: dropTarget\n        };\n        await super.executeCommand(server, session, command);\n        return new collection_1.Collection(this.collection.s.db, this.newName, this.collection.s.options);\n    }\n}\nexports.RenameOperation = RenameOperation;\n(0, operation_1.defineAspects)(RenameOperation, [operation_1.Aspect.WRITE_OPERATION]);\n//# sourceMappingURL=rename.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/rename.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/run_command.js":
/*!************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/run_command.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RunAdminCommandOperation = exports.RunCommandOperation = void 0;\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass RunCommandOperation extends operation_1.AbstractOperation {\n    constructor(parent, command, options) {\n        super(options);\n        this.command = command;\n        this.options = options;\n        this.ns = parent.s.namespace.withCollection('$cmd');\n    }\n    get commandName() {\n        return 'runCommand';\n    }\n    async execute(server, session) {\n        this.server = server;\n        const res = await server.command(this.ns, this.command, {\n            ...this.options,\n            readPreference: this.readPreference,\n            session\n        });\n        return res;\n    }\n}\nexports.RunCommandOperation = RunCommandOperation;\nclass RunAdminCommandOperation extends operation_1.AbstractOperation {\n    constructor(command, options) {\n        super(options);\n        this.command = command;\n        this.options = options;\n        this.ns = new utils_1.MongoDBNamespace('admin', '$cmd');\n    }\n    get commandName() {\n        return 'runCommand';\n    }\n    async execute(server, session) {\n        this.server = server;\n        const res = await server.command(this.ns, this.command, {\n            ...this.options,\n            readPreference: this.readPreference,\n            session\n        });\n        return res;\n    }\n}\nexports.RunAdminCommandOperation = RunAdminCommandOperation;\n//# sourceMappingURL=run_command.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/run_command.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/search_indexes/create.js":
/*!**********************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/search_indexes/create.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CreateSearchIndexesOperation = void 0;\nconst operation_1 = __webpack_require__(/*! ../operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass CreateSearchIndexesOperation extends operation_1.AbstractOperation {\n    constructor(collection, descriptions) {\n        super();\n        this.collection = collection;\n        this.descriptions = descriptions;\n    }\n    get commandName() {\n        return 'createSearchIndexes';\n    }\n    async execute(server, session) {\n        const namespace = this.collection.fullNamespace;\n        const command = {\n            createSearchIndexes: namespace.collection,\n            indexes: this.descriptions\n        };\n        const res = await server.command(namespace, command, { session });\n        const indexesCreated = res?.indexesCreated ?? [];\n        return indexesCreated.map(({ name }) => name);\n    }\n}\nexports.CreateSearchIndexesOperation = CreateSearchIndexesOperation;\n//# sourceMappingURL=create.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/search_indexes/create.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/search_indexes/drop.js":
/*!********************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/search_indexes/drop.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DropSearchIndexOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst operation_1 = __webpack_require__(/*! ../operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass DropSearchIndexOperation extends operation_1.AbstractOperation {\n    constructor(collection, name) {\n        super();\n        this.collection = collection;\n        this.name = name;\n    }\n    get commandName() {\n        return 'dropSearchIndex';\n    }\n    async execute(server, session) {\n        const namespace = this.collection.fullNamespace;\n        const command = {\n            dropSearchIndex: namespace.collection\n        };\n        if (typeof this.name === 'string') {\n            command.name = this.name;\n        }\n        try {\n            await server.command(namespace, command, { session });\n        }\n        catch (error) {\n            const isNamespaceNotFoundError = error instanceof error_1.MongoServerError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound;\n            if (!isNamespaceNotFoundError) {\n                throw error;\n            }\n        }\n    }\n}\nexports.DropSearchIndexOperation = DropSearchIndexOperation;\n//# sourceMappingURL=drop.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/search_indexes/drop.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/search_indexes/update.js":
/*!**********************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/search_indexes/update.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.UpdateSearchIndexOperation = void 0;\nconst operation_1 = __webpack_require__(/*! ../operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass UpdateSearchIndexOperation extends operation_1.AbstractOperation {\n    constructor(collection, name, definition) {\n        super();\n        this.collection = collection;\n        this.name = name;\n        this.definition = definition;\n    }\n    get commandName() {\n        return 'updateSearchIndex';\n    }\n    async execute(server, session) {\n        const namespace = this.collection.fullNamespace;\n        const command = {\n            updateSearchIndex: namespace.collection,\n            name: this.name,\n            definition: this.definition\n        };\n        await server.command(namespace, command, { session });\n        return;\n    }\n}\nexports.UpdateSearchIndexOperation = UpdateSearchIndexOperation;\n//# sourceMappingURL=update.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/search_indexes/update.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/set_profiling_level.js":
/*!********************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/set_profiling_level.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SetProfilingLevelOperation = exports.ProfilingLevel = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst levelValues = new Set(['off', 'slow_only', 'all']);\n/** @public */\nexports.ProfilingLevel = Object.freeze({\n    off: 'off',\n    slowOnly: 'slow_only',\n    all: 'all'\n});\n/** @internal */\nclass SetProfilingLevelOperation extends command_1.CommandOperation {\n    constructor(db, level, options) {\n        super(db, options);\n        this.options = options;\n        switch (level) {\n            case exports.ProfilingLevel.off:\n                this.profile = 0;\n                break;\n            case exports.ProfilingLevel.slowOnly:\n                this.profile = 1;\n                break;\n            case exports.ProfilingLevel.all:\n                this.profile = 2;\n                break;\n            default:\n                this.profile = 0;\n                break;\n        }\n        this.level = level;\n    }\n    get commandName() {\n        return 'profile';\n    }\n    async execute(server, session) {\n        const level = this.level;\n        if (!levelValues.has(level)) {\n            throw new error_1.MongoInvalidArgumentError(`Profiling level must be one of \"${(0, utils_1.enumToString)(exports.ProfilingLevel)}\"`);\n        }\n        // TODO(NODE-3483): Determine error to put here\n        await super.executeCommand(server, session, { profile: this.profile });\n        return level;\n    }\n}\nexports.SetProfilingLevelOperation = SetProfilingLevelOperation;\n//# sourceMappingURL=set_profiling_level.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/set_profiling_level.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/stats.js":
/*!******************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/stats.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DbStatsOperation = void 0;\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass DbStatsOperation extends command_1.CommandOperation {\n    constructor(db, options) {\n        super(db, options);\n        this.options = options;\n    }\n    get commandName() {\n        return 'dbStats';\n    }\n    async execute(server, session) {\n        const command = { dbStats: true };\n        if (this.options.scale != null) {\n            command.scale = this.options.scale;\n        }\n        return await super.executeCommand(server, session, command);\n    }\n}\nexports.DbStatsOperation = DbStatsOperation;\n(0, operation_1.defineAspects)(DbStatsOperation, [operation_1.Aspect.READ_OPERATION]);\n//# sourceMappingURL=stats.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/stats.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/update.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/update.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.makeUpdateStatement = exports.ReplaceOneOperation = exports.UpdateManyOperation = exports.UpdateOneOperation = exports.UpdateOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/**\n * @internal\n * UpdateOperation is used in bulk write, while UpdateOneOperation and UpdateManyOperation are only used in the collections API\n */\nclass UpdateOperation extends command_1.CommandOperation {\n    constructor(ns, statements, options) {\n        super(undefined, options);\n        this.options = options;\n        this.ns = ns;\n        this.statements = statements;\n    }\n    get commandName() {\n        return 'update';\n    }\n    get canRetryWrite() {\n        if (super.canRetryWrite === false) {\n            return false;\n        }\n        return this.statements.every(op => op.multi == null || op.multi === false);\n    }\n    async execute(server, session) {\n        const options = this.options ?? {};\n        const ordered = typeof options.ordered === 'boolean' ? options.ordered : true;\n        const command = {\n            update: this.ns.collection,\n            updates: this.statements,\n            ordered\n        };\n        if (typeof options.bypassDocumentValidation === 'boolean') {\n            command.bypassDocumentValidation = options.bypassDocumentValidation;\n        }\n        if (options.let) {\n            command.let = options.let;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (options.comment !== undefined) {\n            command.comment = options.comment;\n        }\n        const unacknowledgedWrite = this.writeConcern && this.writeConcern.w === 0;\n        if (unacknowledgedWrite) {\n            if (this.statements.find((o) => o.hint)) {\n                // TODO(NODE-3541): fix error for hint with unacknowledged writes\n                throw new error_1.MongoCompatibilityError(`hint is not supported with unacknowledged writes`);\n            }\n        }\n        return await super.executeCommand(server, session, command);\n    }\n}\nexports.UpdateOperation = UpdateOperation;\n/** @internal */\nclass UpdateOneOperation extends UpdateOperation {\n    constructor(collection, filter, update, options) {\n        super(collection.s.namespace, [makeUpdateStatement(filter, update, { ...options, multi: false })], options);\n        if (!(0, utils_1.hasAtomicOperators)(update)) {\n            throw new error_1.MongoInvalidArgumentError('Update document requires atomic operators');\n        }\n    }\n    async execute(server, session) {\n        const res = await super.execute(server, session);\n        if (this.explain != null)\n            return res;\n        if (res.code)\n            throw new error_1.MongoServerError(res);\n        if (res.writeErrors)\n            throw new error_1.MongoServerError(res.writeErrors[0]);\n        return {\n            acknowledged: this.writeConcern?.w !== 0,\n            modifiedCount: res.nModified ?? res.n,\n            upsertedId: Array.isArray(res.upserted) && res.upserted.length > 0 ? res.upserted[0]._id : null,\n            upsertedCount: Array.isArray(res.upserted) && res.upserted.length ? res.upserted.length : 0,\n            matchedCount: Array.isArray(res.upserted) && res.upserted.length > 0 ? 0 : res.n\n        };\n    }\n}\nexports.UpdateOneOperation = UpdateOneOperation;\n/** @internal */\nclass UpdateManyOperation extends UpdateOperation {\n    constructor(collection, filter, update, options) {\n        super(collection.s.namespace, [makeUpdateStatement(filter, update, { ...options, multi: true })], options);\n        if (!(0, utils_1.hasAtomicOperators)(update)) {\n            throw new error_1.MongoInvalidArgumentError('Update document requires atomic operators');\n        }\n    }\n    async execute(server, session) {\n        const res = await super.execute(server, session);\n        if (this.explain != null)\n            return res;\n        if (res.code)\n            throw new error_1.MongoServerError(res);\n        if (res.writeErrors)\n            throw new error_1.MongoServerError(res.writeErrors[0]);\n        return {\n            acknowledged: this.writeConcern?.w !== 0,\n            modifiedCount: res.nModified ?? res.n,\n            upsertedId: Array.isArray(res.upserted) && res.upserted.length > 0 ? res.upserted[0]._id : null,\n            upsertedCount: Array.isArray(res.upserted) && res.upserted.length ? res.upserted.length : 0,\n            matchedCount: Array.isArray(res.upserted) && res.upserted.length > 0 ? 0 : res.n\n        };\n    }\n}\nexports.UpdateManyOperation = UpdateManyOperation;\n/** @internal */\nclass ReplaceOneOperation extends UpdateOperation {\n    constructor(collection, filter, replacement, options) {\n        super(collection.s.namespace, [makeUpdateStatement(filter, replacement, { ...options, multi: false })], options);\n        if ((0, utils_1.hasAtomicOperators)(replacement)) {\n            throw new error_1.MongoInvalidArgumentError('Replacement document must not contain atomic operators');\n        }\n    }\n    async execute(server, session) {\n        const res = await super.execute(server, session);\n        if (this.explain != null)\n            return res;\n        if (res.code)\n            throw new error_1.MongoServerError(res);\n        if (res.writeErrors)\n            throw new error_1.MongoServerError(res.writeErrors[0]);\n        return {\n            acknowledged: this.writeConcern?.w !== 0,\n            modifiedCount: res.nModified ?? res.n,\n            upsertedId: Array.isArray(res.upserted) && res.upserted.length > 0 ? res.upserted[0]._id : null,\n            upsertedCount: Array.isArray(res.upserted) && res.upserted.length ? res.upserted.length : 0,\n            matchedCount: Array.isArray(res.upserted) && res.upserted.length > 0 ? 0 : res.n\n        };\n    }\n}\nexports.ReplaceOneOperation = ReplaceOneOperation;\nfunction makeUpdateStatement(filter, update, options) {\n    if (filter == null || typeof filter !== 'object') {\n        throw new error_1.MongoInvalidArgumentError('Selector must be a valid JavaScript object');\n    }\n    if (update == null || typeof update !== 'object') {\n        throw new error_1.MongoInvalidArgumentError('Document must be a valid JavaScript object');\n    }\n    const op = { q: filter, u: update };\n    if (typeof options.upsert === 'boolean') {\n        op.upsert = options.upsert;\n    }\n    if (options.multi) {\n        op.multi = options.multi;\n    }\n    if (options.hint) {\n        op.hint = options.hint;\n    }\n    if (options.arrayFilters) {\n        op.arrayFilters = options.arrayFilters;\n    }\n    if (options.collation) {\n        op.collation = options.collation;\n    }\n    return op;\n}\nexports.makeUpdateStatement = makeUpdateStatement;\n(0, operation_1.defineAspects)(UpdateOperation, [operation_1.Aspect.RETRYABLE, operation_1.Aspect.WRITE_OPERATION, operation_1.Aspect.SKIP_COLLATION]);\n(0, operation_1.defineAspects)(UpdateOneOperation, [\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.WRITE_OPERATION,\n    operation_1.Aspect.EXPLAINABLE,\n    operation_1.Aspect.SKIP_COLLATION\n]);\n(0, operation_1.defineAspects)(UpdateManyOperation, [\n    operation_1.Aspect.WRITE_OPERATION,\n    operation_1.Aspect.EXPLAINABLE,\n    operation_1.Aspect.SKIP_COLLATION\n]);\n(0, operation_1.defineAspects)(ReplaceOneOperation, [\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.WRITE_OPERATION,\n    operation_1.Aspect.SKIP_COLLATION\n]);\n//# sourceMappingURL=update.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/update.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/validate_collection.js":
/*!********************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/validate_collection.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ValidateCollectionOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\n/** @internal */\nclass ValidateCollectionOperation extends command_1.CommandOperation {\n    constructor(admin, collectionName, options) {\n        // Decorate command with extra options\n        const command = { validate: collectionName };\n        const keys = Object.keys(options);\n        for (let i = 0; i < keys.length; i++) {\n            if (Object.prototype.hasOwnProperty.call(options, keys[i]) && keys[i] !== 'session') {\n                command[keys[i]] = options[keys[i]];\n            }\n        }\n        super(admin.s.db, options);\n        this.options = options;\n        this.command = command;\n        this.collectionName = collectionName;\n    }\n    get commandName() {\n        return 'validate';\n    }\n    async execute(server, session) {\n        const collectionName = this.collectionName;\n        const doc = await super.executeCommand(server, session, this.command);\n        if (doc.result != null && typeof doc.result !== 'string')\n            throw new error_1.MongoUnexpectedServerResponseError('Error with validation data');\n        if (doc.result != null && doc.result.match(/exception|corrupt/) != null)\n            throw new error_1.MongoUnexpectedServerResponseError(`Invalid collection ${collectionName}`);\n        if (doc.valid != null && !doc.valid)\n            throw new error_1.MongoUnexpectedServerResponseError(`Invalid collection ${collectionName}`);\n        return doc;\n    }\n}\nexports.ValidateCollectionOperation = ValidateCollectionOperation;\n//# sourceMappingURL=validate_collection.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/operations/validate_collection.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/read_concern.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/read_concern.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ReadConcern = exports.ReadConcernLevel = void 0;\n/** @public */\nexports.ReadConcernLevel = Object.freeze({\n    local: 'local',\n    majority: 'majority',\n    linearizable: 'linearizable',\n    available: 'available',\n    snapshot: 'snapshot'\n});\n/**\n * The MongoDB ReadConcern, which allows for control of the consistency and isolation properties\n * of the data read from replica sets and replica set shards.\n * @public\n *\n * @see https://www.mongodb.com/docs/manual/reference/read-concern/index.html\n */\nclass ReadConcern {\n    /** Constructs a ReadConcern from the read concern level.*/\n    constructor(level) {\n        /**\n         * A spec test exists that allows level to be any string.\n         * \"invalid readConcern with out stage\"\n         * @see ./test/spec/crud/v2/aggregate-out-readConcern.json\n         * @see https://github.com/mongodb/specifications/blob/master/source/read-write-concern/read-write-concern.rst#unknown-levels-and-additional-options-for-string-based-readconcerns\n         */\n        this.level = exports.ReadConcernLevel[level] ?? level;\n    }\n    /**\n     * Construct a ReadConcern given an options object.\n     *\n     * @param options - The options object from which to extract the write concern.\n     */\n    static fromOptions(options) {\n        if (options == null) {\n            return;\n        }\n        if (options.readConcern) {\n            const { readConcern } = options;\n            if (readConcern instanceof ReadConcern) {\n                return readConcern;\n            }\n            else if (typeof readConcern === 'string') {\n                return new ReadConcern(readConcern);\n            }\n            else if ('level' in readConcern && readConcern.level) {\n                return new ReadConcern(readConcern.level);\n            }\n        }\n        if (options.level) {\n            return new ReadConcern(options.level);\n        }\n        return;\n    }\n    static get MAJORITY() {\n        return exports.ReadConcernLevel.majority;\n    }\n    static get AVAILABLE() {\n        return exports.ReadConcernLevel.available;\n    }\n    static get LINEARIZABLE() {\n        return exports.ReadConcernLevel.linearizable;\n    }\n    static get SNAPSHOT() {\n        return exports.ReadConcernLevel.snapshot;\n    }\n    toJSON() {\n        return { level: this.level };\n    }\n}\nexports.ReadConcern = ReadConcern;\n//# sourceMappingURL=read_concern.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/read_concern.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/read_preference.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongodb/lib/read_preference.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ReadPreference = exports.ReadPreferenceMode = void 0;\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\n/** @public */\nexports.ReadPreferenceMode = Object.freeze({\n    primary: 'primary',\n    primaryPreferred: 'primaryPreferred',\n    secondary: 'secondary',\n    secondaryPreferred: 'secondaryPreferred',\n    nearest: 'nearest'\n});\n/**\n * The **ReadPreference** class is a class that represents a MongoDB ReadPreference and is\n * used to construct connections.\n * @public\n *\n * @see https://www.mongodb.com/docs/manual/core/read-preference/\n */\nclass ReadPreference {\n    /**\n     * @param mode - A string describing the read preference mode (primary|primaryPreferred|secondary|secondaryPreferred|nearest)\n     * @param tags - A tag set used to target reads to members with the specified tag(s). tagSet is not available if using read preference mode primary.\n     * @param options - Additional read preference options\n     */\n    constructor(mode, tags, options) {\n        if (!ReadPreference.isValid(mode)) {\n            throw new error_1.MongoInvalidArgumentError(`Invalid read preference mode ${JSON.stringify(mode)}`);\n        }\n        if (options == null && typeof tags === 'object' && !Array.isArray(tags)) {\n            options = tags;\n            tags = undefined;\n        }\n        else if (tags && !Array.isArray(tags)) {\n            throw new error_1.MongoInvalidArgumentError('ReadPreference tags must be an array');\n        }\n        this.mode = mode;\n        this.tags = tags;\n        this.hedge = options?.hedge;\n        this.maxStalenessSeconds = undefined;\n        this.minWireVersion = undefined;\n        options = options ?? {};\n        if (options.maxStalenessSeconds != null) {\n            if (options.maxStalenessSeconds <= 0) {\n                throw new error_1.MongoInvalidArgumentError('maxStalenessSeconds must be a positive integer');\n            }\n            this.maxStalenessSeconds = options.maxStalenessSeconds;\n            // NOTE: The minimum required wire version is 5 for this read preference. If the existing\n            //       topology has a lower value then a MongoError will be thrown during server selection.\n            this.minWireVersion = 5;\n        }\n        if (this.mode === ReadPreference.PRIMARY) {\n            if (this.tags && Array.isArray(this.tags) && this.tags.length > 0) {\n                throw new error_1.MongoInvalidArgumentError('Primary read preference cannot be combined with tags');\n            }\n            if (this.maxStalenessSeconds) {\n                throw new error_1.MongoInvalidArgumentError('Primary read preference cannot be combined with maxStalenessSeconds');\n            }\n            if (this.hedge) {\n                throw new error_1.MongoInvalidArgumentError('Primary read preference cannot be combined with hedge');\n            }\n        }\n    }\n    // Support the deprecated `preference` property introduced in the porcelain layer\n    get preference() {\n        return this.mode;\n    }\n    static fromString(mode) {\n        return new ReadPreference(mode);\n    }\n    /**\n     * Construct a ReadPreference given an options object.\n     *\n     * @param options - The options object from which to extract the read preference.\n     */\n    static fromOptions(options) {\n        if (!options)\n            return;\n        const readPreference = options.readPreference ?? options.session?.transaction.options.readPreference;\n        const readPreferenceTags = options.readPreferenceTags;\n        if (readPreference == null) {\n            return;\n        }\n        if (typeof readPreference === 'string') {\n            return new ReadPreference(readPreference, readPreferenceTags, {\n                maxStalenessSeconds: options.maxStalenessSeconds,\n                hedge: options.hedge\n            });\n        }\n        else if (!(readPreference instanceof ReadPreference) && typeof readPreference === 'object') {\n            const mode = readPreference.mode || readPreference.preference;\n            if (mode && typeof mode === 'string') {\n                return new ReadPreference(mode, readPreference.tags ?? readPreferenceTags, {\n                    maxStalenessSeconds: readPreference.maxStalenessSeconds,\n                    hedge: options.hedge\n                });\n            }\n        }\n        if (readPreferenceTags) {\n            readPreference.tags = readPreferenceTags;\n        }\n        return readPreference;\n    }\n    /**\n     * Replaces options.readPreference with a ReadPreference instance\n     */\n    static translate(options) {\n        if (options.readPreference == null)\n            return options;\n        const r = options.readPreference;\n        if (typeof r === 'string') {\n            options.readPreference = new ReadPreference(r);\n        }\n        else if (r && !(r instanceof ReadPreference) && typeof r === 'object') {\n            const mode = r.mode || r.preference;\n            if (mode && typeof mode === 'string') {\n                options.readPreference = new ReadPreference(mode, r.tags, {\n                    maxStalenessSeconds: r.maxStalenessSeconds\n                });\n            }\n        }\n        else if (!(r instanceof ReadPreference)) {\n            throw new error_1.MongoInvalidArgumentError(`Invalid read preference: ${r}`);\n        }\n        return options;\n    }\n    /**\n     * Validate if a mode is legal\n     *\n     * @param mode - The string representing the read preference mode.\n     */\n    static isValid(mode) {\n        const VALID_MODES = new Set([\n            ReadPreference.PRIMARY,\n            ReadPreference.PRIMARY_PREFERRED,\n            ReadPreference.SECONDARY,\n            ReadPreference.SECONDARY_PREFERRED,\n            ReadPreference.NEAREST,\n            null\n        ]);\n        return VALID_MODES.has(mode);\n    }\n    /**\n     * Validate if a mode is legal\n     *\n     * @param mode - The string representing the read preference mode.\n     */\n    isValid(mode) {\n        return ReadPreference.isValid(typeof mode === 'string' ? mode : this.mode);\n    }\n    /**\n     * Indicates that this readPreference needs the \"SecondaryOk\" bit when sent over the wire\n     * @see https://www.mongodb.com/docs/manual/reference/mongodb-wire-protocol/#op-query\n     */\n    secondaryOk() {\n        const NEEDS_SECONDARYOK = new Set([\n            ReadPreference.PRIMARY_PREFERRED,\n            ReadPreference.SECONDARY,\n            ReadPreference.SECONDARY_PREFERRED,\n            ReadPreference.NEAREST\n        ]);\n        return NEEDS_SECONDARYOK.has(this.mode);\n    }\n    /**\n     * Check if the two ReadPreferences are equivalent\n     *\n     * @param readPreference - The read preference with which to check equality\n     */\n    equals(readPreference) {\n        return readPreference.mode === this.mode;\n    }\n    /** Return JSON representation */\n    toJSON() {\n        const readPreference = { mode: this.mode };\n        if (Array.isArray(this.tags))\n            readPreference.tags = this.tags;\n        if (this.maxStalenessSeconds)\n            readPreference.maxStalenessSeconds = this.maxStalenessSeconds;\n        if (this.hedge)\n            readPreference.hedge = this.hedge;\n        return readPreference;\n    }\n}\nReadPreference.PRIMARY = exports.ReadPreferenceMode.primary;\nReadPreference.PRIMARY_PREFERRED = exports.ReadPreferenceMode.primaryPreferred;\nReadPreference.SECONDARY = exports.ReadPreferenceMode.secondary;\nReadPreference.SECONDARY_PREFERRED = exports.ReadPreferenceMode.secondaryPreferred;\nReadPreference.NEAREST = exports.ReadPreferenceMode.nearest;\nReadPreference.primary = new ReadPreference(exports.ReadPreferenceMode.primary);\nReadPreference.primaryPreferred = new ReadPreference(exports.ReadPreferenceMode.primaryPreferred);\nReadPreference.secondary = new ReadPreference(exports.ReadPreferenceMode.secondary);\nReadPreference.secondaryPreferred = new ReadPreference(exports.ReadPreferenceMode.secondaryPreferred);\nReadPreference.nearest = new ReadPreference(exports.ReadPreferenceMode.nearest);\nexports.ReadPreference = ReadPreference;\n//# sourceMappingURL=read_preference.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/read_preference.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/common.js":
/*!*************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/common.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports._advanceClusterTime = exports.drainTimerQueue = exports.ServerType = exports.TopologyType = exports.STATE_CONNECTED = exports.STATE_CONNECTING = exports.STATE_CLOSED = exports.STATE_CLOSING = void 0;\nconst timers_1 = __webpack_require__(/*! timers */ \"timers\");\n// shared state names\nexports.STATE_CLOSING = 'closing';\nexports.STATE_CLOSED = 'closed';\nexports.STATE_CONNECTING = 'connecting';\nexports.STATE_CONNECTED = 'connected';\n/**\n * An enumeration of topology types we know about\n * @public\n */\nexports.TopologyType = Object.freeze({\n    Single: 'Single',\n    ReplicaSetNoPrimary: 'ReplicaSetNoPrimary',\n    ReplicaSetWithPrimary: 'ReplicaSetWithPrimary',\n    Sharded: 'Sharded',\n    Unknown: 'Unknown',\n    LoadBalanced: 'LoadBalanced'\n});\n/**\n * An enumeration of server types we know about\n * @public\n */\nexports.ServerType = Object.freeze({\n    Standalone: 'Standalone',\n    Mongos: 'Mongos',\n    PossiblePrimary: 'PossiblePrimary',\n    RSPrimary: 'RSPrimary',\n    RSSecondary: 'RSSecondary',\n    RSArbiter: 'RSArbiter',\n    RSOther: 'RSOther',\n    RSGhost: 'RSGhost',\n    Unknown: 'Unknown',\n    LoadBalancer: 'LoadBalancer'\n});\n/** @internal */\nfunction drainTimerQueue(queue) {\n    queue.forEach(timers_1.clearTimeout);\n    queue.clear();\n}\nexports.drainTimerQueue = drainTimerQueue;\n/** Shared function to determine clusterTime for a given topology or session */\nfunction _advanceClusterTime(entity, $clusterTime) {\n    if (entity.clusterTime == null) {\n        entity.clusterTime = $clusterTime;\n    }\n    else {\n        if ($clusterTime.clusterTime.greaterThan(entity.clusterTime.clusterTime)) {\n            entity.clusterTime = $clusterTime;\n        }\n    }\n}\nexports._advanceClusterTime = _advanceClusterTime;\n//# sourceMappingURL=common.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/sdam/common.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/events.js":
/*!*************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/events.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ServerHeartbeatFailedEvent = exports.ServerHeartbeatSucceededEvent = exports.ServerHeartbeatStartedEvent = exports.TopologyClosedEvent = exports.TopologyOpeningEvent = exports.TopologyDescriptionChangedEvent = exports.ServerClosedEvent = exports.ServerOpeningEvent = exports.ServerDescriptionChangedEvent = void 0;\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\n/**\n * Emitted when server description changes, but does NOT include changes to the RTT.\n * @public\n * @category Event\n */\nclass ServerDescriptionChangedEvent {\n    /** @internal */\n    constructor(topologyId, address, previousDescription, newDescription) {\n        this.name = constants_1.SERVER_DESCRIPTION_CHANGED;\n        this.topologyId = topologyId;\n        this.address = address;\n        this.previousDescription = previousDescription;\n        this.newDescription = newDescription;\n    }\n}\nexports.ServerDescriptionChangedEvent = ServerDescriptionChangedEvent;\n/**\n * Emitted when server is initialized.\n * @public\n * @category Event\n */\nclass ServerOpeningEvent {\n    /** @internal */\n    constructor(topologyId, address) {\n        /** @internal */\n        this.name = constants_1.SERVER_OPENING;\n        this.topologyId = topologyId;\n        this.address = address;\n    }\n}\nexports.ServerOpeningEvent = ServerOpeningEvent;\n/**\n * Emitted when server is closed.\n * @public\n * @category Event\n */\nclass ServerClosedEvent {\n    /** @internal */\n    constructor(topologyId, address) {\n        /** @internal */\n        this.name = constants_1.SERVER_CLOSED;\n        this.topologyId = topologyId;\n        this.address = address;\n    }\n}\nexports.ServerClosedEvent = ServerClosedEvent;\n/**\n * Emitted when topology description changes.\n * @public\n * @category Event\n */\nclass TopologyDescriptionChangedEvent {\n    /** @internal */\n    constructor(topologyId, previousDescription, newDescription) {\n        /** @internal */\n        this.name = constants_1.TOPOLOGY_DESCRIPTION_CHANGED;\n        this.topologyId = topologyId;\n        this.previousDescription = previousDescription;\n        this.newDescription = newDescription;\n    }\n}\nexports.TopologyDescriptionChangedEvent = TopologyDescriptionChangedEvent;\n/**\n * Emitted when topology is initialized.\n * @public\n * @category Event\n */\nclass TopologyOpeningEvent {\n    /** @internal */\n    constructor(topologyId) {\n        /** @internal */\n        this.name = constants_1.TOPOLOGY_OPENING;\n        this.topologyId = topologyId;\n    }\n}\nexports.TopologyOpeningEvent = TopologyOpeningEvent;\n/**\n * Emitted when topology is closed.\n * @public\n * @category Event\n */\nclass TopologyClosedEvent {\n    /** @internal */\n    constructor(topologyId) {\n        /** @internal */\n        this.name = constants_1.TOPOLOGY_CLOSED;\n        this.topologyId = topologyId;\n    }\n}\nexports.TopologyClosedEvent = TopologyClosedEvent;\n/**\n * Emitted when the server monitors hello command is started - immediately before\n * the hello command is serialized into raw BSON and written to the socket.\n *\n * @public\n * @category Event\n */\nclass ServerHeartbeatStartedEvent {\n    /** @internal */\n    constructor(connectionId, awaited) {\n        /** @internal */\n        this.name = constants_1.SERVER_HEARTBEAT_STARTED;\n        this.connectionId = connectionId;\n        this.awaited = awaited;\n    }\n}\nexports.ServerHeartbeatStartedEvent = ServerHeartbeatStartedEvent;\n/**\n * Emitted when the server monitors hello succeeds.\n * @public\n * @category Event\n */\nclass ServerHeartbeatSucceededEvent {\n    /** @internal */\n    constructor(connectionId, duration, reply, awaited) {\n        /** @internal */\n        this.name = constants_1.SERVER_HEARTBEAT_SUCCEEDED;\n        this.connectionId = connectionId;\n        this.duration = duration;\n        this.reply = reply ?? {};\n        this.awaited = awaited;\n    }\n}\nexports.ServerHeartbeatSucceededEvent = ServerHeartbeatSucceededEvent;\n/**\n * Emitted when the server monitors hello fails, either with an ok: 0 or a socket exception.\n * @public\n * @category Event\n */\nclass ServerHeartbeatFailedEvent {\n    /** @internal */\n    constructor(connectionId, duration, failure, awaited) {\n        /** @internal */\n        this.name = constants_1.SERVER_HEARTBEAT_FAILED;\n        this.connectionId = connectionId;\n        this.duration = duration;\n        this.failure = failure;\n        this.awaited = awaited;\n    }\n}\nexports.ServerHeartbeatFailedEvent = ServerHeartbeatFailedEvent;\n//# sourceMappingURL=events.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/sdam/events.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/monitor.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/monitor.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RTTSampler = exports.MonitorInterval = exports.RTTPinger = exports.Monitor = exports.ServerMonitoringMode = void 0;\nconst timers_1 = __webpack_require__(/*! timers */ \"timers\");\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst connect_1 = __webpack_require__(/*! ../cmap/connect */ \"./node_modules/mongodb/lib/cmap/connect.js\");\nconst client_metadata_1 = __webpack_require__(/*! ../cmap/handshake/client_metadata */ \"./node_modules/mongodb/lib/cmap/handshake/client_metadata.js\");\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_logger_1 = __webpack_require__(/*! ../mongo_logger */ \"./node_modules/mongodb/lib/mongo_logger.js\");\nconst mongo_types_1 = __webpack_require__(/*! ../mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst common_1 = __webpack_require__(/*! ./common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst events_1 = __webpack_require__(/*! ./events */ \"./node_modules/mongodb/lib/sdam/events.js\");\nconst server_1 = __webpack_require__(/*! ./server */ \"./node_modules/mongodb/lib/sdam/server.js\");\n/** @internal */\nconst kServer = Symbol('server');\n/** @internal */\nconst kMonitorId = Symbol('monitorId');\n/** @internal */\nconst kCancellationToken = Symbol('cancellationToken');\nconst STATE_IDLE = 'idle';\nconst STATE_MONITORING = 'monitoring';\nconst stateTransition = (0, utils_1.makeStateMachine)({\n    [common_1.STATE_CLOSING]: [common_1.STATE_CLOSING, STATE_IDLE, common_1.STATE_CLOSED],\n    [common_1.STATE_CLOSED]: [common_1.STATE_CLOSED, STATE_MONITORING],\n    [STATE_IDLE]: [STATE_IDLE, STATE_MONITORING, common_1.STATE_CLOSING],\n    [STATE_MONITORING]: [STATE_MONITORING, STATE_IDLE, common_1.STATE_CLOSING]\n});\nconst INVALID_REQUEST_CHECK_STATES = new Set([common_1.STATE_CLOSING, common_1.STATE_CLOSED, STATE_MONITORING]);\nfunction isInCloseState(monitor) {\n    return monitor.s.state === common_1.STATE_CLOSED || monitor.s.state === common_1.STATE_CLOSING;\n}\n/** @public */\nexports.ServerMonitoringMode = Object.freeze({\n    auto: 'auto',\n    poll: 'poll',\n    stream: 'stream'\n});\n/** @internal */\nclass Monitor extends mongo_types_1.TypedEventEmitter {\n    constructor(server, options) {\n        super();\n        /** @internal */\n        this.component = mongo_logger_1.MongoLoggableComponent.TOPOLOGY;\n        this[kServer] = server;\n        this.connection = null;\n        this[kCancellationToken] = new mongo_types_1.CancellationToken();\n        this[kCancellationToken].setMaxListeners(Infinity);\n        this[kMonitorId] = undefined;\n        this.s = {\n            state: common_1.STATE_CLOSED\n        };\n        this.address = server.description.address;\n        this.options = Object.freeze({\n            connectTimeoutMS: options.connectTimeoutMS ?? 10000,\n            heartbeatFrequencyMS: options.heartbeatFrequencyMS ?? 10000,\n            minHeartbeatFrequencyMS: options.minHeartbeatFrequencyMS ?? 500,\n            serverMonitoringMode: options.serverMonitoringMode\n        });\n        this.isRunningInFaasEnv = (0, client_metadata_1.getFAASEnv)() != null;\n        this.mongoLogger = this[kServer].topology.client?.mongoLogger;\n        this.rttSampler = new RTTSampler(10);\n        const cancellationToken = this[kCancellationToken];\n        // TODO: refactor this to pull it directly from the pool, requires new ConnectionPool integration\n        const connectOptions = {\n            id: '<monitor>',\n            generation: server.pool.generation,\n            cancellationToken,\n            hostAddress: server.description.hostAddress,\n            ...options,\n            // force BSON serialization options\n            raw: false,\n            useBigInt64: false,\n            promoteLongs: true,\n            promoteValues: true,\n            promoteBuffers: true\n        };\n        // ensure no authentication is used for monitoring\n        delete connectOptions.credentials;\n        if (connectOptions.autoEncrypter) {\n            delete connectOptions.autoEncrypter;\n        }\n        this.connectOptions = Object.freeze(connectOptions);\n    }\n    connect() {\n        if (this.s.state !== common_1.STATE_CLOSED) {\n            return;\n        }\n        // start\n        const heartbeatFrequencyMS = this.options.heartbeatFrequencyMS;\n        const minHeartbeatFrequencyMS = this.options.minHeartbeatFrequencyMS;\n        this[kMonitorId] = new MonitorInterval(monitorServer(this), {\n            heartbeatFrequencyMS: heartbeatFrequencyMS,\n            minHeartbeatFrequencyMS: minHeartbeatFrequencyMS,\n            immediate: true\n        });\n    }\n    requestCheck() {\n        if (INVALID_REQUEST_CHECK_STATES.has(this.s.state)) {\n            return;\n        }\n        this[kMonitorId]?.wake();\n    }\n    reset() {\n        const topologyVersion = this[kServer].description.topologyVersion;\n        if (isInCloseState(this) || topologyVersion == null) {\n            return;\n        }\n        stateTransition(this, common_1.STATE_CLOSING);\n        resetMonitorState(this);\n        // restart monitor\n        stateTransition(this, STATE_IDLE);\n        // restart monitoring\n        const heartbeatFrequencyMS = this.options.heartbeatFrequencyMS;\n        const minHeartbeatFrequencyMS = this.options.minHeartbeatFrequencyMS;\n        this[kMonitorId] = new MonitorInterval(monitorServer(this), {\n            heartbeatFrequencyMS: heartbeatFrequencyMS,\n            minHeartbeatFrequencyMS: minHeartbeatFrequencyMS\n        });\n    }\n    close() {\n        if (isInCloseState(this)) {\n            return;\n        }\n        stateTransition(this, common_1.STATE_CLOSING);\n        resetMonitorState(this);\n        // close monitor\n        this.emit('close');\n        stateTransition(this, common_1.STATE_CLOSED);\n    }\n    get roundTripTime() {\n        return this.rttSampler.average();\n    }\n    get minRoundTripTime() {\n        return this.rttSampler.min();\n    }\n    get latestRtt() {\n        return this.rttSampler.last;\n    }\n    addRttSample(rtt) {\n        this.rttSampler.addSample(rtt);\n    }\n    clearRttSamples() {\n        this.rttSampler.clear();\n    }\n}\nexports.Monitor = Monitor;\nfunction resetMonitorState(monitor) {\n    monitor[kMonitorId]?.stop();\n    monitor[kMonitorId] = undefined;\n    monitor.rttPinger?.close();\n    monitor.rttPinger = undefined;\n    monitor[kCancellationToken].emit('cancel');\n    monitor.connection?.destroy();\n    monitor.connection = null;\n    monitor.clearRttSamples();\n}\nfunction useStreamingProtocol(monitor, topologyVersion) {\n    // If we have no topology version we always poll no matter\n    // what the user provided, since the server does not support\n    // the streaming protocol.\n    if (topologyVersion == null)\n        return false;\n    const serverMonitoringMode = monitor.options.serverMonitoringMode;\n    if (serverMonitoringMode === exports.ServerMonitoringMode.poll)\n        return false;\n    if (serverMonitoringMode === exports.ServerMonitoringMode.stream)\n        return true;\n    // If we are in auto mode, we need to figure out if we're in a FaaS\n    // environment or not and choose the appropriate mode.\n    if (monitor.isRunningInFaasEnv)\n        return false;\n    return true;\n}\nfunction checkServer(monitor, callback) {\n    let start;\n    let awaited;\n    const topologyVersion = monitor[kServer].description.topologyVersion;\n    const isAwaitable = useStreamingProtocol(monitor, topologyVersion);\n    monitor.emitAndLogHeartbeat(server_1.Server.SERVER_HEARTBEAT_STARTED, monitor[kServer].topology.s.id, undefined, new events_1.ServerHeartbeatStartedEvent(monitor.address, isAwaitable));\n    function onHeartbeatFailed(err) {\n        monitor.connection?.destroy();\n        monitor.connection = null;\n        monitor.emitAndLogHeartbeat(server_1.Server.SERVER_HEARTBEAT_FAILED, monitor[kServer].topology.s.id, undefined, new events_1.ServerHeartbeatFailedEvent(monitor.address, (0, utils_1.calculateDurationInMs)(start), err, awaited));\n        const error = !(err instanceof error_1.MongoError)\n            ? new error_1.MongoError(error_1.MongoError.buildErrorMessage(err), { cause: err })\n            : err;\n        error.addErrorLabel(error_1.MongoErrorLabel.ResetPool);\n        if (error instanceof error_1.MongoNetworkTimeoutError) {\n            error.addErrorLabel(error_1.MongoErrorLabel.InterruptInUseConnections);\n        }\n        monitor.emit('resetServer', error);\n        callback(err);\n    }\n    function onHeartbeatSucceeded(hello) {\n        if (!('isWritablePrimary' in hello)) {\n            // Provide hello-style response document.\n            hello.isWritablePrimary = hello[constants_1.LEGACY_HELLO_COMMAND];\n        }\n        // NOTE: here we use the latestRtt as this measurement corresponds with the value\n        // obtained for this successful heartbeat, if there is no latestRtt, then we calculate the\n        // duration\n        const duration = isAwaitable && monitor.rttPinger\n            ? monitor.rttPinger.latestRtt ?? (0, utils_1.calculateDurationInMs)(start)\n            : (0, utils_1.calculateDurationInMs)(start);\n        monitor.addRttSample(duration);\n        monitor.emitAndLogHeartbeat(server_1.Server.SERVER_HEARTBEAT_SUCCEEDED, monitor[kServer].topology.s.id, hello.connectionId, new events_1.ServerHeartbeatSucceededEvent(monitor.address, duration, hello, isAwaitable));\n        if (isAwaitable) {\n            // If we are using the streaming protocol then we immediately issue another 'started'\n            // event, otherwise the \"check\" is complete and return to the main monitor loop\n            monitor.emitAndLogHeartbeat(server_1.Server.SERVER_HEARTBEAT_STARTED, monitor[kServer].topology.s.id, undefined, new events_1.ServerHeartbeatStartedEvent(monitor.address, true));\n            // We have not actually sent an outgoing handshake, but when we get the next response we\n            // want the duration to reflect the time since we last heard from the server\n            start = (0, utils_1.now)();\n        }\n        else {\n            monitor.rttPinger?.close();\n            monitor.rttPinger = undefined;\n            callback(undefined, hello);\n        }\n    }\n    const { connection } = monitor;\n    if (connection && !connection.closed) {\n        const { serverApi, helloOk } = connection;\n        const connectTimeoutMS = monitor.options.connectTimeoutMS;\n        const maxAwaitTimeMS = monitor.options.heartbeatFrequencyMS;\n        const cmd = {\n            [serverApi?.version || helloOk ? 'hello' : constants_1.LEGACY_HELLO_COMMAND]: 1,\n            ...(isAwaitable && topologyVersion\n                ? { maxAwaitTimeMS, topologyVersion: makeTopologyVersion(topologyVersion) }\n                : {})\n        };\n        const options = isAwaitable\n            ? {\n                socketTimeoutMS: connectTimeoutMS ? connectTimeoutMS + maxAwaitTimeMS : 0,\n                exhaustAllowed: true\n            }\n            : { socketTimeoutMS: connectTimeoutMS };\n        if (isAwaitable && monitor.rttPinger == null) {\n            monitor.rttPinger = new RTTPinger(monitor);\n        }\n        // Record new start time before sending handshake\n        start = (0, utils_1.now)();\n        if (isAwaitable) {\n            awaited = true;\n            return connection.exhaustCommand((0, utils_1.ns)('admin.$cmd'), cmd, options, (error, hello) => {\n                if (error)\n                    return onHeartbeatFailed(error);\n                return onHeartbeatSucceeded(hello);\n            });\n        }\n        awaited = false;\n        connection\n            .command((0, utils_1.ns)('admin.$cmd'), cmd, options)\n            // eslint-disable-next-line github/no-then\n            .then(onHeartbeatSucceeded, onHeartbeatFailed);\n        return;\n    }\n    // connecting does an implicit `hello`\n    (async () => {\n        const socket = await (0, connect_1.makeSocket)(monitor.connectOptions);\n        const connection = (0, connect_1.makeConnection)(monitor.connectOptions, socket);\n        // The start time is after socket creation but before the handshake\n        start = (0, utils_1.now)();\n        try {\n            await (0, connect_1.performInitialHandshake)(connection, monitor.connectOptions);\n            return connection;\n        }\n        catch (error) {\n            connection.destroy();\n            throw error;\n        }\n        // eslint-disable-next-line github/no-then\n    })().then(connection => {\n        if (isInCloseState(monitor)) {\n            connection.destroy();\n            return;\n        }\n        const duration = (0, utils_1.calculateDurationInMs)(start);\n        monitor.addRttSample(duration);\n        monitor.connection = connection;\n        monitor.emitAndLogHeartbeat(server_1.Server.SERVER_HEARTBEAT_SUCCEEDED, monitor[kServer].topology.s.id, connection.hello?.connectionId, new events_1.ServerHeartbeatSucceededEvent(monitor.address, duration, connection.hello, useStreamingProtocol(monitor, connection.hello?.topologyVersion)));\n        callback(undefined, connection.hello);\n    }, error => {\n        monitor.connection = null;\n        awaited = false;\n        onHeartbeatFailed(error);\n    });\n}\nfunction monitorServer(monitor) {\n    return (callback) => {\n        if (monitor.s.state === STATE_MONITORING) {\n            process.nextTick(callback);\n            return;\n        }\n        stateTransition(monitor, STATE_MONITORING);\n        function done() {\n            if (!isInCloseState(monitor)) {\n                stateTransition(monitor, STATE_IDLE);\n            }\n            callback();\n        }\n        checkServer(monitor, (err, hello) => {\n            if (err) {\n                // otherwise an error occurred on initial discovery, also bail\n                if (monitor[kServer].description.type === common_1.ServerType.Unknown) {\n                    return done();\n                }\n            }\n            // if the check indicates streaming is supported, immediately reschedule monitoring\n            if (useStreamingProtocol(monitor, hello?.topologyVersion)) {\n                (0, timers_1.setTimeout)(() => {\n                    if (!isInCloseState(monitor)) {\n                        monitor[kMonitorId]?.wake();\n                    }\n                }, 0);\n            }\n            done();\n        });\n    };\n}\nfunction makeTopologyVersion(tv) {\n    return {\n        processId: tv.processId,\n        // tests mock counter as just number, but in a real situation counter should always be a Long\n        // TODO(NODE-2674): Preserve int64 sent from MongoDB\n        counter: bson_1.Long.isLong(tv.counter) ? tv.counter : bson_1.Long.fromNumber(tv.counter)\n    };\n}\n/** @internal */\nclass RTTPinger {\n    constructor(monitor) {\n        this.connection = undefined;\n        this[kCancellationToken] = monitor[kCancellationToken];\n        this.closed = false;\n        this.monitor = monitor;\n        this.latestRtt = monitor.latestRtt ?? undefined;\n        const heartbeatFrequencyMS = monitor.options.heartbeatFrequencyMS;\n        this[kMonitorId] = (0, timers_1.setTimeout)(() => this.measureRoundTripTime(), heartbeatFrequencyMS);\n    }\n    get roundTripTime() {\n        return this.monitor.roundTripTime;\n    }\n    get minRoundTripTime() {\n        return this.monitor.minRoundTripTime;\n    }\n    close() {\n        this.closed = true;\n        (0, timers_1.clearTimeout)(this[kMonitorId]);\n        this.connection?.destroy();\n        this.connection = undefined;\n    }\n    measureAndReschedule(start, conn) {\n        if (this.closed) {\n            conn?.destroy();\n            return;\n        }\n        if (this.connection == null) {\n            this.connection = conn;\n        }\n        this.latestRtt = (0, utils_1.calculateDurationInMs)(start);\n        this[kMonitorId] = (0, timers_1.setTimeout)(() => this.measureRoundTripTime(), this.monitor.options.heartbeatFrequencyMS);\n    }\n    measureRoundTripTime() {\n        const start = (0, utils_1.now)();\n        if (this.closed) {\n            return;\n        }\n        const connection = this.connection;\n        if (connection == null) {\n            // eslint-disable-next-line github/no-then\n            (0, connect_1.connect)(this.monitor.connectOptions).then(connection => {\n                this.measureAndReschedule(start, connection);\n            }, () => {\n                this.connection = undefined;\n            });\n            return;\n        }\n        const commandName = connection.serverApi?.version || connection.helloOk ? 'hello' : constants_1.LEGACY_HELLO_COMMAND;\n        // eslint-disable-next-line github/no-then\n        connection.command((0, utils_1.ns)('admin.$cmd'), { [commandName]: 1 }, undefined).then(() => this.measureAndReschedule(start), () => {\n            this.connection?.destroy();\n            this.connection = undefined;\n            return;\n        });\n    }\n}\nexports.RTTPinger = RTTPinger;\n/**\n * @internal\n */\nclass MonitorInterval {\n    constructor(fn, options = {}) {\n        this.isExpeditedCallToFnScheduled = false;\n        this.stopped = false;\n        this.isExecutionInProgress = false;\n        this.hasExecutedOnce = false;\n        this._executeAndReschedule = () => {\n            if (this.stopped)\n                return;\n            if (this.timerId) {\n                (0, timers_1.clearTimeout)(this.timerId);\n            }\n            this.isExpeditedCallToFnScheduled = false;\n            this.isExecutionInProgress = true;\n            this.fn(() => {\n                this.lastExecutionEnded = (0, utils_1.now)();\n                this.isExecutionInProgress = false;\n                this._reschedule(this.heartbeatFrequencyMS);\n            });\n        };\n        this.fn = fn;\n        this.lastExecutionEnded = -Infinity;\n        this.heartbeatFrequencyMS = options.heartbeatFrequencyMS ?? 1000;\n        this.minHeartbeatFrequencyMS = options.minHeartbeatFrequencyMS ?? 500;\n        if (options.immediate) {\n            this._executeAndReschedule();\n        }\n        else {\n            this._reschedule(undefined);\n        }\n    }\n    wake() {\n        const currentTime = (0, utils_1.now)();\n        const timeSinceLastCall = currentTime - this.lastExecutionEnded;\n        // TODO(NODE-4674): Add error handling and logging to the monitor\n        if (timeSinceLastCall < 0) {\n            return this._executeAndReschedule();\n        }\n        if (this.isExecutionInProgress) {\n            return;\n        }\n        // debounce multiple calls to wake within the `minInterval`\n        if (this.isExpeditedCallToFnScheduled) {\n            return;\n        }\n        // reschedule a call as soon as possible, ensuring the call never happens\n        // faster than the `minInterval`\n        if (timeSinceLastCall < this.minHeartbeatFrequencyMS) {\n            this.isExpeditedCallToFnScheduled = true;\n            this._reschedule(this.minHeartbeatFrequencyMS - timeSinceLastCall);\n            return;\n        }\n        this._executeAndReschedule();\n    }\n    stop() {\n        this.stopped = true;\n        if (this.timerId) {\n            (0, timers_1.clearTimeout)(this.timerId);\n            this.timerId = undefined;\n        }\n        this.lastExecutionEnded = -Infinity;\n        this.isExpeditedCallToFnScheduled = false;\n    }\n    toString() {\n        return JSON.stringify(this);\n    }\n    toJSON() {\n        const currentTime = (0, utils_1.now)();\n        const timeSinceLastCall = currentTime - this.lastExecutionEnded;\n        return {\n            timerId: this.timerId != null ? 'set' : 'cleared',\n            lastCallTime: this.lastExecutionEnded,\n            isExpeditedCheckScheduled: this.isExpeditedCallToFnScheduled,\n            stopped: this.stopped,\n            heartbeatFrequencyMS: this.heartbeatFrequencyMS,\n            minHeartbeatFrequencyMS: this.minHeartbeatFrequencyMS,\n            currentTime,\n            timeSinceLastCall\n        };\n    }\n    _reschedule(ms) {\n        if (this.stopped)\n            return;\n        if (this.timerId) {\n            (0, timers_1.clearTimeout)(this.timerId);\n        }\n        this.timerId = (0, timers_1.setTimeout)(this._executeAndReschedule, ms || this.heartbeatFrequencyMS);\n    }\n}\nexports.MonitorInterval = MonitorInterval;\n/** @internal\n * This class implements the RTT sampling logic specified for [CSOT](https://github.com/mongodb/specifications/blob/bbb335e60cd7ea1e0f7cd9a9443cb95fc9d3b64d/source/client-side-operations-timeout/client-side-operations-timeout.md#drivers-use-minimum-rtt-to-short-circuit-operations)\n *\n * This is implemented as a [circular buffer](https://en.wikipedia.org/wiki/Circular_buffer) keeping\n * the most recent `windowSize` samples\n * */\nclass RTTSampler {\n    constructor(windowSize = 10) {\n        this.rttSamples = new Float64Array(windowSize);\n        this.length = 0;\n        this.writeIndex = 0;\n    }\n    /**\n     * Adds an rtt sample to the end of the circular buffer\n     * When `windowSize` samples have been collected, `addSample` overwrites the least recently added\n     * sample\n     */\n    addSample(sample) {\n        this.rttSamples[this.writeIndex++] = sample;\n        if (this.length < this.rttSamples.length) {\n            this.length++;\n        }\n        this.writeIndex %= this.rttSamples.length;\n    }\n    /**\n     * When \\< 2 samples have been collected, returns 0\n     * Otherwise computes the minimum value samples contained in the buffer\n     */\n    min() {\n        if (this.length < 2)\n            return 0;\n        let min = this.rttSamples[0];\n        for (let i = 1; i < this.length; i++) {\n            if (this.rttSamples[i] < min)\n                min = this.rttSamples[i];\n        }\n        return min;\n    }\n    /**\n     * Returns mean of samples contained in the buffer\n     */\n    average() {\n        if (this.length === 0)\n            return 0;\n        let sum = 0;\n        for (let i = 0; i < this.length; i++) {\n            sum += this.rttSamples[i];\n        }\n        return sum / this.length;\n    }\n    /**\n     * Returns most recently inserted element in the buffer\n     * Returns null if the buffer is empty\n     * */\n    get last() {\n        if (this.length === 0)\n            return null;\n        return this.rttSamples[this.writeIndex === 0 ? this.length - 1 : this.writeIndex - 1];\n    }\n    /**\n     * Clear the buffer\n     * NOTE: this does not overwrite the data held in the internal array, just the pointers into\n     * this array\n     */\n    clear() {\n        this.length = 0;\n        this.writeIndex = 0;\n    }\n}\nexports.RTTSampler = RTTSampler;\n//# sourceMappingURL=monitor.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/sdam/monitor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/server.js":
/*!*************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/server.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Server = void 0;\nconst connection_1 = __webpack_require__(/*! ../cmap/connection */ \"./node_modules/mongodb/lib/cmap/connection.js\");\nconst connection_pool_1 = __webpack_require__(/*! ../cmap/connection_pool */ \"./node_modules/mongodb/lib/cmap/connection_pool.js\");\nconst errors_1 = __webpack_require__(/*! ../cmap/errors */ \"./node_modules/mongodb/lib/cmap/errors.js\");\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_types_1 = __webpack_require__(/*! ../mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst transactions_1 = __webpack_require__(/*! ../transactions */ \"./node_modules/mongodb/lib/transactions.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst common_1 = __webpack_require__(/*! ./common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst monitor_1 = __webpack_require__(/*! ./monitor */ \"./node_modules/mongodb/lib/sdam/monitor.js\");\nconst server_description_1 = __webpack_require__(/*! ./server_description */ \"./node_modules/mongodb/lib/sdam/server_description.js\");\nconst stateTransition = (0, utils_1.makeStateMachine)({\n    [common_1.STATE_CLOSED]: [common_1.STATE_CLOSED, common_1.STATE_CONNECTING],\n    [common_1.STATE_CONNECTING]: [common_1.STATE_CONNECTING, common_1.STATE_CLOSING, common_1.STATE_CONNECTED, common_1.STATE_CLOSED],\n    [common_1.STATE_CONNECTED]: [common_1.STATE_CONNECTED, common_1.STATE_CLOSING, common_1.STATE_CLOSED],\n    [common_1.STATE_CLOSING]: [common_1.STATE_CLOSING, common_1.STATE_CLOSED]\n});\n/** @internal */\nclass Server extends mongo_types_1.TypedEventEmitter {\n    /**\n     * Create a server\n     */\n    constructor(topology, description, options) {\n        super();\n        this.serverApi = options.serverApi;\n        const poolOptions = { hostAddress: description.hostAddress, ...options };\n        this.topology = topology;\n        this.pool = new connection_pool_1.ConnectionPool(this, poolOptions);\n        this.s = {\n            description,\n            options,\n            state: common_1.STATE_CLOSED,\n            operationCount: 0\n        };\n        for (const event of [...constants_1.CMAP_EVENTS, ...constants_1.APM_EVENTS]) {\n            this.pool.on(event, (e) => this.emit(event, e));\n        }\n        this.pool.on(connection_1.Connection.CLUSTER_TIME_RECEIVED, (clusterTime) => {\n            this.clusterTime = clusterTime;\n        });\n        if (this.loadBalanced) {\n            this.monitor = null;\n            // monitoring is disabled in load balancing mode\n            return;\n        }\n        // create the monitor\n        this.monitor = new monitor_1.Monitor(this, this.s.options);\n        for (const event of constants_1.HEARTBEAT_EVENTS) {\n            this.monitor.on(event, (e) => this.emit(event, e));\n        }\n        this.monitor.on('resetServer', (error) => markServerUnknown(this, error));\n        this.monitor.on(Server.SERVER_HEARTBEAT_SUCCEEDED, (event) => {\n            this.emit(Server.DESCRIPTION_RECEIVED, new server_description_1.ServerDescription(this.description.hostAddress, event.reply, {\n                roundTripTime: this.monitor?.roundTripTime,\n                minRoundTripTime: this.monitor?.minRoundTripTime\n            }));\n            if (this.s.state === common_1.STATE_CONNECTING) {\n                stateTransition(this, common_1.STATE_CONNECTED);\n                this.emit(Server.CONNECT, this);\n            }\n        });\n    }\n    get clusterTime() {\n        return this.topology.clusterTime;\n    }\n    set clusterTime(clusterTime) {\n        this.topology.clusterTime = clusterTime;\n    }\n    get description() {\n        return this.s.description;\n    }\n    get name() {\n        return this.s.description.address;\n    }\n    get autoEncrypter() {\n        if (this.s.options && this.s.options.autoEncrypter) {\n            return this.s.options.autoEncrypter;\n        }\n        return;\n    }\n    get loadBalanced() {\n        return this.topology.description.type === common_1.TopologyType.LoadBalanced;\n    }\n    /**\n     * Initiate server connect\n     */\n    connect() {\n        if (this.s.state !== common_1.STATE_CLOSED) {\n            return;\n        }\n        stateTransition(this, common_1.STATE_CONNECTING);\n        // If in load balancer mode we automatically set the server to\n        // a load balancer. It never transitions out of this state and\n        // has no monitor.\n        if (!this.loadBalanced) {\n            this.monitor?.connect();\n        }\n        else {\n            stateTransition(this, common_1.STATE_CONNECTED);\n            this.emit(Server.CONNECT, this);\n        }\n    }\n    /** Destroy the server connection */\n    destroy() {\n        if (this.s.state === common_1.STATE_CLOSED) {\n            return;\n        }\n        stateTransition(this, common_1.STATE_CLOSING);\n        if (!this.loadBalanced) {\n            this.monitor?.close();\n        }\n        this.pool.close();\n        stateTransition(this, common_1.STATE_CLOSED);\n        this.emit('closed');\n    }\n    /**\n     * Immediately schedule monitoring of this server. If there already an attempt being made\n     * this will be a no-op.\n     */\n    requestCheck() {\n        if (!this.loadBalanced) {\n            this.monitor?.requestCheck();\n        }\n    }\n    async command(ns, cmd, options, responseType) {\n        if (ns.db == null || typeof ns === 'string') {\n            throw new error_1.MongoInvalidArgumentError('Namespace must not be a string');\n        }\n        if (this.s.state === common_1.STATE_CLOSING || this.s.state === common_1.STATE_CLOSED) {\n            throw new error_1.MongoServerClosedError();\n        }\n        // Clone the options\n        const finalOptions = Object.assign({}, options, {\n            wireProtocolCommand: false,\n            directConnection: this.topology.s.options.directConnection\n        });\n        // There are cases where we need to flag the read preference not to get sent in\n        // the command, such as pre-5.0 servers attempting to perform an aggregate write\n        // with a non-primary read preference. In this case the effective read preference\n        // (primary) is not the same as the provided and must be removed completely.\n        if (finalOptions.omitReadPreference) {\n            delete finalOptions.readPreference;\n        }\n        const session = finalOptions.session;\n        let conn = session?.pinnedConnection;\n        this.incrementOperationCount();\n        if (conn == null) {\n            try {\n                conn = await this.pool.checkOut();\n                if (this.loadBalanced && isPinnableCommand(cmd, session)) {\n                    session?.pin(conn);\n                }\n            }\n            catch (checkoutError) {\n                this.decrementOperationCount();\n                if (!(checkoutError instanceof errors_1.PoolClearedError))\n                    this.handleError(checkoutError);\n                throw checkoutError;\n            }\n        }\n        try {\n            try {\n                return await conn.command(ns, cmd, finalOptions, responseType);\n            }\n            catch (commandError) {\n                throw this.decorateCommandError(conn, cmd, finalOptions, commandError);\n            }\n        }\n        catch (operationError) {\n            if (operationError instanceof error_1.MongoError &&\n                operationError.code === error_1.MONGODB_ERROR_CODES.Reauthenticate) {\n                await this.pool.reauthenticate(conn);\n                try {\n                    return await conn.command(ns, cmd, finalOptions, responseType);\n                }\n                catch (commandError) {\n                    throw this.decorateCommandError(conn, cmd, finalOptions, commandError);\n                }\n            }\n            else {\n                throw operationError;\n            }\n        }\n        finally {\n            this.decrementOperationCount();\n            if (session?.pinnedConnection !== conn) {\n                this.pool.checkIn(conn);\n            }\n        }\n    }\n    /**\n     * Handle SDAM error\n     * @internal\n     */\n    handleError(error, connection) {\n        if (!(error instanceof error_1.MongoError)) {\n            return;\n        }\n        const isStaleError = error.connectionGeneration && error.connectionGeneration < this.pool.generation;\n        if (isStaleError) {\n            return;\n        }\n        const isNetworkNonTimeoutError = error instanceof error_1.MongoNetworkError && !(error instanceof error_1.MongoNetworkTimeoutError);\n        const isNetworkTimeoutBeforeHandshakeError = (0, error_1.isNetworkErrorBeforeHandshake)(error);\n        const isAuthHandshakeError = error.hasErrorLabel(error_1.MongoErrorLabel.HandshakeError);\n        if (isNetworkNonTimeoutError || isNetworkTimeoutBeforeHandshakeError || isAuthHandshakeError) {\n            // In load balanced mode we never mark the server as unknown and always\n            // clear for the specific service id.\n            if (!this.loadBalanced) {\n                error.addErrorLabel(error_1.MongoErrorLabel.ResetPool);\n                markServerUnknown(this, error);\n            }\n            else if (connection) {\n                this.pool.clear({ serviceId: connection.serviceId });\n            }\n        }\n        else {\n            if ((0, error_1.isSDAMUnrecoverableError)(error)) {\n                if (shouldHandleStateChangeError(this, error)) {\n                    const shouldClearPool = (0, utils_1.maxWireVersion)(this) <= 7 || (0, error_1.isNodeShuttingDownError)(error);\n                    if (this.loadBalanced && connection && shouldClearPool) {\n                        this.pool.clear({ serviceId: connection.serviceId });\n                    }\n                    if (!this.loadBalanced) {\n                        if (shouldClearPool) {\n                            error.addErrorLabel(error_1.MongoErrorLabel.ResetPool);\n                        }\n                        markServerUnknown(this, error);\n                        process.nextTick(() => this.requestCheck());\n                    }\n                }\n            }\n        }\n    }\n    /**\n     * Ensure that error is properly decorated and internal state is updated before throwing\n     * @internal\n     */\n    decorateCommandError(connection, cmd, options, error) {\n        if (typeof error !== 'object' || error == null || !('name' in error)) {\n            throw new error_1.MongoRuntimeError('An unexpected error type: ' + typeof error);\n        }\n        if (error.name === 'AbortError' && 'cause' in error && error.cause instanceof error_1.MongoError) {\n            error = error.cause;\n        }\n        if (!(error instanceof error_1.MongoError)) {\n            // Node.js or some other error we have not special handling for\n            return error;\n        }\n        if (connectionIsStale(this.pool, connection)) {\n            return error;\n        }\n        const session = options?.session;\n        if (error instanceof error_1.MongoNetworkError) {\n            if (session && !session.hasEnded && session.serverSession) {\n                session.serverSession.isDirty = true;\n            }\n            // inActiveTransaction check handles commit and abort.\n            if (inActiveTransaction(session, cmd) &&\n                !error.hasErrorLabel(error_1.MongoErrorLabel.TransientTransactionError)) {\n                error.addErrorLabel(error_1.MongoErrorLabel.TransientTransactionError);\n            }\n            if ((isRetryableWritesEnabled(this.topology) || (0, transactions_1.isTransactionCommand)(cmd)) &&\n                (0, utils_1.supportsRetryableWrites)(this) &&\n                !inActiveTransaction(session, cmd)) {\n                error.addErrorLabel(error_1.MongoErrorLabel.RetryableWriteError);\n            }\n        }\n        else {\n            if ((isRetryableWritesEnabled(this.topology) || (0, transactions_1.isTransactionCommand)(cmd)) &&\n                (0, error_1.needsRetryableWriteLabel)(error, (0, utils_1.maxWireVersion)(this)) &&\n                !inActiveTransaction(session, cmd)) {\n                error.addErrorLabel(error_1.MongoErrorLabel.RetryableWriteError);\n            }\n        }\n        if (session &&\n            session.isPinned &&\n            error.hasErrorLabel(error_1.MongoErrorLabel.TransientTransactionError)) {\n            session.unpin({ force: true });\n        }\n        this.handleError(error, connection);\n        return error;\n    }\n    /**\n     * Decrement the operation count, returning the new count.\n     */\n    decrementOperationCount() {\n        return (this.s.operationCount -= 1);\n    }\n    /**\n     * Increment the operation count, returning the new count.\n     */\n    incrementOperationCount() {\n        return (this.s.operationCount += 1);\n    }\n}\n/** @event */\nServer.SERVER_HEARTBEAT_STARTED = constants_1.SERVER_HEARTBEAT_STARTED;\n/** @event */\nServer.SERVER_HEARTBEAT_SUCCEEDED = constants_1.SERVER_HEARTBEAT_SUCCEEDED;\n/** @event */\nServer.SERVER_HEARTBEAT_FAILED = constants_1.SERVER_HEARTBEAT_FAILED;\n/** @event */\nServer.CONNECT = constants_1.CONNECT;\n/** @event */\nServer.DESCRIPTION_RECEIVED = constants_1.DESCRIPTION_RECEIVED;\n/** @event */\nServer.CLOSED = constants_1.CLOSED;\n/** @event */\nServer.ENDED = constants_1.ENDED;\nexports.Server = Server;\nfunction markServerUnknown(server, error) {\n    // Load balancer servers can never be marked unknown.\n    if (server.loadBalanced) {\n        return;\n    }\n    if (error instanceof error_1.MongoNetworkError && !(error instanceof error_1.MongoNetworkTimeoutError)) {\n        server.monitor?.reset();\n    }\n    server.emit(Server.DESCRIPTION_RECEIVED, new server_description_1.ServerDescription(server.description.hostAddress, undefined, { error }));\n}\nfunction isPinnableCommand(cmd, session) {\n    if (session) {\n        return (session.inTransaction() ||\n            (session.transaction.isCommitted && 'commitTransaction' in cmd) ||\n            'aggregate' in cmd ||\n            'find' in cmd ||\n            'getMore' in cmd ||\n            'listCollections' in cmd ||\n            'listIndexes' in cmd);\n    }\n    return false;\n}\nfunction connectionIsStale(pool, connection) {\n    if (connection.serviceId) {\n        return (connection.generation !== pool.serviceGenerations.get(connection.serviceId.toHexString()));\n    }\n    return connection.generation !== pool.generation;\n}\nfunction shouldHandleStateChangeError(server, err) {\n    const etv = err.topologyVersion;\n    const stv = server.description.topologyVersion;\n    return (0, server_description_1.compareTopologyVersion)(stv, etv) < 0;\n}\nfunction inActiveTransaction(session, cmd) {\n    return session && session.inTransaction() && !(0, transactions_1.isTransactionCommand)(cmd);\n}\n/** this checks the retryWrites option passed down from the client options, it\n * does not check if the server supports retryable writes */\nfunction isRetryableWritesEnabled(topology) {\n    return topology.s.options.retryWrites !== false;\n}\n//# sourceMappingURL=server.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/sdam/server.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/server_description.js":
/*!*************************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/server_description.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.compareTopologyVersion = exports.parseServerType = exports.ServerDescription = void 0;\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst common_1 = __webpack_require__(/*! ./common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst WRITABLE_SERVER_TYPES = new Set([\n    common_1.ServerType.RSPrimary,\n    common_1.ServerType.Standalone,\n    common_1.ServerType.Mongos,\n    common_1.ServerType.LoadBalancer\n]);\nconst DATA_BEARING_SERVER_TYPES = new Set([\n    common_1.ServerType.RSPrimary,\n    common_1.ServerType.RSSecondary,\n    common_1.ServerType.Mongos,\n    common_1.ServerType.Standalone,\n    common_1.ServerType.LoadBalancer\n]);\n/**\n * The client's view of a single server, based on the most recent hello outcome.\n *\n * Internal type, not meant to be directly instantiated\n * @public\n */\nclass ServerDescription {\n    /**\n     * Create a ServerDescription\n     * @internal\n     *\n     * @param address - The address of the server\n     * @param hello - An optional hello response for this server\n     */\n    constructor(address, hello, options = {}) {\n        if (address == null || address === '') {\n            throw new error_1.MongoRuntimeError('ServerDescription must be provided with a non-empty address');\n        }\n        this.address =\n            typeof address === 'string'\n                ? utils_1.HostAddress.fromString(address).toString() // Use HostAddress to normalize\n                : address.toString();\n        this.type = parseServerType(hello, options);\n        this.hosts = hello?.hosts?.map((host) => host.toLowerCase()) ?? [];\n        this.passives = hello?.passives?.map((host) => host.toLowerCase()) ?? [];\n        this.arbiters = hello?.arbiters?.map((host) => host.toLowerCase()) ?? [];\n        this.tags = hello?.tags ?? {};\n        this.minWireVersion = hello?.minWireVersion ?? 0;\n        this.maxWireVersion = hello?.maxWireVersion ?? 0;\n        this.roundTripTime = options?.roundTripTime ?? -1;\n        this.minRoundTripTime = options?.minRoundTripTime ?? 0;\n        this.lastUpdateTime = (0, utils_1.now)();\n        this.lastWriteDate = hello?.lastWrite?.lastWriteDate ?? 0;\n        this.error = options.error ?? null;\n        // TODO(NODE-2674): Preserve int64 sent from MongoDB\n        this.topologyVersion = this.error?.topologyVersion ?? hello?.topologyVersion ?? null;\n        this.setName = hello?.setName ?? null;\n        this.setVersion = hello?.setVersion ?? null;\n        this.electionId = hello?.electionId ?? null;\n        this.logicalSessionTimeoutMinutes = hello?.logicalSessionTimeoutMinutes ?? null;\n        this.primary = hello?.primary ?? null;\n        this.me = hello?.me?.toLowerCase() ?? null;\n        this.$clusterTime = hello?.$clusterTime ?? null;\n    }\n    get hostAddress() {\n        return utils_1.HostAddress.fromString(this.address);\n    }\n    get allHosts() {\n        return this.hosts.concat(this.arbiters).concat(this.passives);\n    }\n    /** Is this server available for reads*/\n    get isReadable() {\n        return this.type === common_1.ServerType.RSSecondary || this.isWritable;\n    }\n    /** Is this server data bearing */\n    get isDataBearing() {\n        return DATA_BEARING_SERVER_TYPES.has(this.type);\n    }\n    /** Is this server available for writes */\n    get isWritable() {\n        return WRITABLE_SERVER_TYPES.has(this.type);\n    }\n    get host() {\n        const chopLength = `:${this.port}`.length;\n        return this.address.slice(0, -chopLength);\n    }\n    get port() {\n        const port = this.address.split(':').pop();\n        return port ? Number.parseInt(port, 10) : 27017;\n    }\n    /**\n     * Determines if another `ServerDescription` is equal to this one per the rules defined\n     * in the {@link https://github.com/mongodb/specifications/blob/master/source/server-discovery-and-monitoring/server-discovery-and-monitoring.rst#serverdescription|SDAM spec}\n     */\n    equals(other) {\n        // Despite using the comparator that would determine a nullish topologyVersion as greater than\n        // for equality we should only always perform direct equality comparison\n        const topologyVersionsEqual = this.topologyVersion === other?.topologyVersion ||\n            compareTopologyVersion(this.topologyVersion, other?.topologyVersion) === 0;\n        const electionIdsEqual = this.electionId != null && other?.electionId != null\n            ? (0, utils_1.compareObjectId)(this.electionId, other.electionId) === 0\n            : this.electionId === other?.electionId;\n        return (other != null &&\n            (0, utils_1.errorStrictEqual)(this.error, other.error) &&\n            this.type === other.type &&\n            this.minWireVersion === other.minWireVersion &&\n            (0, utils_1.arrayStrictEqual)(this.hosts, other.hosts) &&\n            tagsStrictEqual(this.tags, other.tags) &&\n            this.setName === other.setName &&\n            this.setVersion === other.setVersion &&\n            electionIdsEqual &&\n            this.primary === other.primary &&\n            this.logicalSessionTimeoutMinutes === other.logicalSessionTimeoutMinutes &&\n            topologyVersionsEqual);\n    }\n}\nexports.ServerDescription = ServerDescription;\n// Parses a `hello` message and determines the server type\nfunction parseServerType(hello, options) {\n    if (options?.loadBalanced) {\n        return common_1.ServerType.LoadBalancer;\n    }\n    if (!hello || !hello.ok) {\n        return common_1.ServerType.Unknown;\n    }\n    if (hello.isreplicaset) {\n        return common_1.ServerType.RSGhost;\n    }\n    if (hello.msg && hello.msg === 'isdbgrid') {\n        return common_1.ServerType.Mongos;\n    }\n    if (hello.setName) {\n        if (hello.hidden) {\n            return common_1.ServerType.RSOther;\n        }\n        else if (hello.isWritablePrimary) {\n            return common_1.ServerType.RSPrimary;\n        }\n        else if (hello.secondary) {\n            return common_1.ServerType.RSSecondary;\n        }\n        else if (hello.arbiterOnly) {\n            return common_1.ServerType.RSArbiter;\n        }\n        else {\n            return common_1.ServerType.RSOther;\n        }\n    }\n    return common_1.ServerType.Standalone;\n}\nexports.parseServerType = parseServerType;\nfunction tagsStrictEqual(tags, tags2) {\n    const tagsKeys = Object.keys(tags);\n    const tags2Keys = Object.keys(tags2);\n    return (tagsKeys.length === tags2Keys.length &&\n        tagsKeys.every((key) => tags2[key] === tags[key]));\n}\n/**\n * Compares two topology versions.\n *\n * 1. If the response topologyVersion is unset or the ServerDescription's\n *    topologyVersion is null, the client MUST assume the response is more recent.\n * 1. If the response's topologyVersion.processId is not equal to the\n *    ServerDescription's, the client MUST assume the response is more recent.\n * 1. If the response's topologyVersion.processId is equal to the\n *    ServerDescription's, the client MUST use the counter field to determine\n *    which topologyVersion is more recent.\n *\n * ```ts\n * currentTv <   newTv === -1\n * currentTv === newTv === 0\n * currentTv >   newTv === 1\n * ```\n */\nfunction compareTopologyVersion(currentTv, newTv) {\n    if (currentTv == null || newTv == null) {\n        return -1;\n    }\n    if (!currentTv.processId.equals(newTv.processId)) {\n        return -1;\n    }\n    // TODO(NODE-2674): Preserve int64 sent from MongoDB\n    const currentCounter = typeof currentTv.counter === 'bigint'\n        ? bson_1.Long.fromBigInt(currentTv.counter)\n        : bson_1.Long.isLong(currentTv.counter)\n            ? currentTv.counter\n            : bson_1.Long.fromNumber(currentTv.counter);\n    const newCounter = typeof newTv.counter === 'bigint'\n        ? bson_1.Long.fromBigInt(newTv.counter)\n        : bson_1.Long.isLong(newTv.counter)\n            ? newTv.counter\n            : bson_1.Long.fromNumber(newTv.counter);\n    return currentCounter.compare(newCounter);\n}\nexports.compareTopologyVersion = compareTopologyVersion;\n//# sourceMappingURL=server_description.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/sdam/server_description.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/server_selection.js":
/*!***********************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/server_selection.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.readPreferenceServerSelector = exports.secondaryWritableServerSelector = exports.sameServerSelector = exports.writableServerSelector = exports.MIN_SECONDARY_WRITE_WIRE_VERSION = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_preference_1 = __webpack_require__(/*! ../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst common_1 = __webpack_require__(/*! ./common */ \"./node_modules/mongodb/lib/sdam/common.js\");\n// max staleness constants\nconst IDLE_WRITE_PERIOD = 10000;\nconst SMALLEST_MAX_STALENESS_SECONDS = 90;\n//  Minimum version to try writes on secondaries.\nexports.MIN_SECONDARY_WRITE_WIRE_VERSION = 13;\n/**\n * Returns a server selector that selects for writable servers\n */\nfunction writableServerSelector() {\n    return function writableServer(topologyDescription, servers) {\n        return latencyWindowReducer(topologyDescription, servers.filter((s) => s.isWritable));\n    };\n}\nexports.writableServerSelector = writableServerSelector;\n/**\n * The purpose of this selector is to select the same server, only\n * if it is in a state that it can have commands sent to it.\n */\nfunction sameServerSelector(description) {\n    return function sameServerSelector(topologyDescription, servers) {\n        if (!description)\n            return [];\n        // Filter the servers to match the provided description only if\n        // the type is not unknown.\n        return servers.filter(sd => {\n            return sd.address === description.address && sd.type !== common_1.ServerType.Unknown;\n        });\n    };\n}\nexports.sameServerSelector = sameServerSelector;\n/**\n * Returns a server selector that uses a read preference to select a\n * server potentially for a write on a secondary.\n */\nfunction secondaryWritableServerSelector(wireVersion, readPreference) {\n    // If server version < 5.0, read preference always primary.\n    // If server version >= 5.0...\n    // - If read preference is supplied, use that.\n    // - If no read preference is supplied, use primary.\n    if (!readPreference ||\n        !wireVersion ||\n        (wireVersion && wireVersion < exports.MIN_SECONDARY_WRITE_WIRE_VERSION)) {\n        return readPreferenceServerSelector(read_preference_1.ReadPreference.primary);\n    }\n    return readPreferenceServerSelector(readPreference);\n}\nexports.secondaryWritableServerSelector = secondaryWritableServerSelector;\n/**\n * Reduces the passed in array of servers by the rules of the \"Max Staleness\" specification\n * found here: https://github.com/mongodb/specifications/blob/master/source/max-staleness/max-staleness.rst\n *\n * @param readPreference - The read preference providing max staleness guidance\n * @param topologyDescription - The topology description\n * @param servers - The list of server descriptions to be reduced\n * @returns The list of servers that satisfy the requirements of max staleness\n */\nfunction maxStalenessReducer(readPreference, topologyDescription, servers) {\n    if (readPreference.maxStalenessSeconds == null || readPreference.maxStalenessSeconds < 0) {\n        return servers;\n    }\n    const maxStaleness = readPreference.maxStalenessSeconds;\n    const maxStalenessVariance = (topologyDescription.heartbeatFrequencyMS + IDLE_WRITE_PERIOD) / 1000;\n    if (maxStaleness < maxStalenessVariance) {\n        throw new error_1.MongoInvalidArgumentError(`Option \"maxStalenessSeconds\" must be at least ${maxStalenessVariance} seconds`);\n    }\n    if (maxStaleness < SMALLEST_MAX_STALENESS_SECONDS) {\n        throw new error_1.MongoInvalidArgumentError(`Option \"maxStalenessSeconds\" must be at least ${SMALLEST_MAX_STALENESS_SECONDS} seconds`);\n    }\n    if (topologyDescription.type === common_1.TopologyType.ReplicaSetWithPrimary) {\n        const primary = Array.from(topologyDescription.servers.values()).filter(primaryFilter)[0];\n        return servers.reduce((result, server) => {\n            const stalenessMS = server.lastUpdateTime -\n                server.lastWriteDate -\n                (primary.lastUpdateTime - primary.lastWriteDate) +\n                topologyDescription.heartbeatFrequencyMS;\n            const staleness = stalenessMS / 1000;\n            const maxStalenessSeconds = readPreference.maxStalenessSeconds ?? 0;\n            if (staleness <= maxStalenessSeconds) {\n                result.push(server);\n            }\n            return result;\n        }, []);\n    }\n    if (topologyDescription.type === common_1.TopologyType.ReplicaSetNoPrimary) {\n        if (servers.length === 0) {\n            return servers;\n        }\n        const sMax = servers.reduce((max, s) => s.lastWriteDate > max.lastWriteDate ? s : max);\n        return servers.reduce((result, server) => {\n            const stalenessMS = sMax.lastWriteDate - server.lastWriteDate + topologyDescription.heartbeatFrequencyMS;\n            const staleness = stalenessMS / 1000;\n            const maxStalenessSeconds = readPreference.maxStalenessSeconds ?? 0;\n            if (staleness <= maxStalenessSeconds) {\n                result.push(server);\n            }\n            return result;\n        }, []);\n    }\n    return servers;\n}\n/**\n * Determines whether a server's tags match a given set of tags\n *\n * @param tagSet - The requested tag set to match\n * @param serverTags - The server's tags\n */\nfunction tagSetMatch(tagSet, serverTags) {\n    const keys = Object.keys(tagSet);\n    const serverTagKeys = Object.keys(serverTags);\n    for (let i = 0; i < keys.length; ++i) {\n        const key = keys[i];\n        if (serverTagKeys.indexOf(key) === -1 || serverTags[key] !== tagSet[key]) {\n            return false;\n        }\n    }\n    return true;\n}\n/**\n * Reduces a set of server descriptions based on tags requested by the read preference\n *\n * @param readPreference - The read preference providing the requested tags\n * @param servers - The list of server descriptions to reduce\n * @returns The list of servers matching the requested tags\n */\nfunction tagSetReducer(readPreference, servers) {\n    if (readPreference.tags == null ||\n        (Array.isArray(readPreference.tags) && readPreference.tags.length === 0)) {\n        return servers;\n    }\n    for (let i = 0; i < readPreference.tags.length; ++i) {\n        const tagSet = readPreference.tags[i];\n        const serversMatchingTagset = servers.reduce((matched, server) => {\n            if (tagSetMatch(tagSet, server.tags))\n                matched.push(server);\n            return matched;\n        }, []);\n        if (serversMatchingTagset.length) {\n            return serversMatchingTagset;\n        }\n    }\n    return [];\n}\n/**\n * Reduces a list of servers to ensure they fall within an acceptable latency window. This is\n * further specified in the \"Server Selection\" specification, found here:\n * https://github.com/mongodb/specifications/blob/master/source/server-selection/server-selection.rst\n *\n * @param topologyDescription - The topology description\n * @param servers - The list of servers to reduce\n * @returns The servers which fall within an acceptable latency window\n */\nfunction latencyWindowReducer(topologyDescription, servers) {\n    const low = servers.reduce((min, server) => Math.min(server.roundTripTime, min), Infinity);\n    const high = low + topologyDescription.localThresholdMS;\n    return servers.reduce((result, server) => {\n        if (server.roundTripTime <= high && server.roundTripTime >= low)\n            result.push(server);\n        return result;\n    }, []);\n}\n// filters\nfunction primaryFilter(server) {\n    return server.type === common_1.ServerType.RSPrimary;\n}\nfunction secondaryFilter(server) {\n    return server.type === common_1.ServerType.RSSecondary;\n}\nfunction nearestFilter(server) {\n    return server.type === common_1.ServerType.RSSecondary || server.type === common_1.ServerType.RSPrimary;\n}\nfunction knownFilter(server) {\n    return server.type !== common_1.ServerType.Unknown;\n}\nfunction loadBalancerFilter(server) {\n    return server.type === common_1.ServerType.LoadBalancer;\n}\n/**\n * Returns a function which selects servers based on a provided read preference\n *\n * @param readPreference - The read preference to select with\n */\nfunction readPreferenceServerSelector(readPreference) {\n    if (!readPreference.isValid()) {\n        throw new error_1.MongoInvalidArgumentError('Invalid read preference specified');\n    }\n    return function readPreferenceServers(topologyDescription, servers, deprioritized = []) {\n        const commonWireVersion = topologyDescription.commonWireVersion;\n        if (commonWireVersion &&\n            readPreference.minWireVersion &&\n            readPreference.minWireVersion > commonWireVersion) {\n            throw new error_1.MongoCompatibilityError(`Minimum wire version '${readPreference.minWireVersion}' required, but found '${commonWireVersion}'`);\n        }\n        if (topologyDescription.type === common_1.TopologyType.LoadBalanced) {\n            return servers.filter(loadBalancerFilter);\n        }\n        if (topologyDescription.type === common_1.TopologyType.Unknown) {\n            return [];\n        }\n        if (topologyDescription.type === common_1.TopologyType.Single) {\n            return latencyWindowReducer(topologyDescription, servers.filter(knownFilter));\n        }\n        if (topologyDescription.type === common_1.TopologyType.Sharded) {\n            const filtered = servers.filter(server => {\n                return !deprioritized.includes(server);\n            });\n            const selectable = filtered.length > 0 ? filtered : deprioritized;\n            return latencyWindowReducer(topologyDescription, selectable.filter(knownFilter));\n        }\n        const mode = readPreference.mode;\n        if (mode === read_preference_1.ReadPreference.PRIMARY) {\n            return servers.filter(primaryFilter);\n        }\n        if (mode === read_preference_1.ReadPreference.PRIMARY_PREFERRED) {\n            const result = servers.filter(primaryFilter);\n            if (result.length) {\n                return result;\n            }\n        }\n        const filter = mode === read_preference_1.ReadPreference.NEAREST ? nearestFilter : secondaryFilter;\n        const selectedServers = latencyWindowReducer(topologyDescription, tagSetReducer(readPreference, maxStalenessReducer(readPreference, topologyDescription, servers.filter(filter))));\n        if (mode === read_preference_1.ReadPreference.SECONDARY_PREFERRED && selectedServers.length === 0) {\n            return servers.filter(primaryFilter);\n        }\n        return selectedServers;\n    };\n}\nexports.readPreferenceServerSelector = readPreferenceServerSelector;\n//# sourceMappingURL=server_selection.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/sdam/server_selection.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/server_selection_events.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/server_selection_events.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.WaitingForSuitableServerEvent = exports.ServerSelectionSucceededEvent = exports.ServerSelectionFailedEvent = exports.ServerSelectionStartedEvent = exports.ServerSelectionEvent = void 0;\nconst utils_1 = __webpack_require__(/*! .././utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\n/**\n * The base export class for all logs published from server selection\n * @internal\n * @category Log Type\n */\nclass ServerSelectionEvent {\n    /** @internal */\n    constructor(selector, topologyDescription, operation) {\n        this.selector = selector;\n        this.operation = operation;\n        this.topologyDescription = topologyDescription;\n    }\n}\nexports.ServerSelectionEvent = ServerSelectionEvent;\n/**\n * An event published when server selection starts\n * @internal\n * @category Event\n */\nclass ServerSelectionStartedEvent extends ServerSelectionEvent {\n    /** @internal */\n    constructor(selector, topologyDescription, operation) {\n        super(selector, topologyDescription, operation);\n        /** @internal */\n        this.name = constants_1.SERVER_SELECTION_STARTED;\n        this.message = 'Server selection started';\n    }\n}\nexports.ServerSelectionStartedEvent = ServerSelectionStartedEvent;\n/**\n * An event published when a server selection fails\n * @internal\n * @category Event\n */\nclass ServerSelectionFailedEvent extends ServerSelectionEvent {\n    /** @internal */\n    constructor(selector, topologyDescription, error, operation) {\n        super(selector, topologyDescription, operation);\n        /** @internal */\n        this.name = constants_1.SERVER_SELECTION_FAILED;\n        this.message = 'Server selection failed';\n        this.failure = error;\n    }\n}\nexports.ServerSelectionFailedEvent = ServerSelectionFailedEvent;\n/**\n * An event published when server selection succeeds\n * @internal\n * @category Event\n */\nclass ServerSelectionSucceededEvent extends ServerSelectionEvent {\n    /** @internal */\n    constructor(selector, topologyDescription, address, operation) {\n        super(selector, topologyDescription, operation);\n        /** @internal */\n        this.name = constants_1.SERVER_SELECTION_SUCCEEDED;\n        this.message = 'Server selection succeeded';\n        const { host, port } = utils_1.HostAddress.fromString(address).toHostPort();\n        this.serverHost = host;\n        this.serverPort = port;\n    }\n}\nexports.ServerSelectionSucceededEvent = ServerSelectionSucceededEvent;\n/**\n * An event published when server selection is waiting for a suitable server to become available\n * @internal\n * @category Event\n */\nclass WaitingForSuitableServerEvent extends ServerSelectionEvent {\n    /** @internal */\n    constructor(selector, topologyDescription, remainingTimeMS, operation) {\n        super(selector, topologyDescription, operation);\n        /** @internal */\n        this.name = constants_1.WAITING_FOR_SUITABLE_SERVER;\n        this.message = 'Waiting for suitable server to become available';\n        this.remainingTimeMS = remainingTimeMS;\n    }\n}\nexports.WaitingForSuitableServerEvent = WaitingForSuitableServerEvent;\n//# sourceMappingURL=server_selection_events.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/sdam/server_selection_events.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/srv_polling.js":
/*!******************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/srv_polling.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SrvPoller = exports.SrvPollingEvent = void 0;\nconst dns = __webpack_require__(/*! dns */ \"dns\");\nconst timers_1 = __webpack_require__(/*! timers */ \"timers\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_types_1 = __webpack_require__(/*! ../mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\n/**\n * @internal\n * @category Event\n */\nclass SrvPollingEvent {\n    constructor(srvRecords) {\n        this.srvRecords = srvRecords;\n    }\n    hostnames() {\n        return new Set(this.srvRecords.map(r => utils_1.HostAddress.fromSrvRecord(r).toString()));\n    }\n}\nexports.SrvPollingEvent = SrvPollingEvent;\n/** @internal */\nclass SrvPoller extends mongo_types_1.TypedEventEmitter {\n    constructor(options) {\n        super();\n        if (!options || !options.srvHost) {\n            throw new error_1.MongoRuntimeError('Options for SrvPoller must exist and include srvHost');\n        }\n        this.srvHost = options.srvHost;\n        this.srvMaxHosts = options.srvMaxHosts ?? 0;\n        this.srvServiceName = options.srvServiceName ?? 'mongodb';\n        this.rescanSrvIntervalMS = 60000;\n        this.heartbeatFrequencyMS = options.heartbeatFrequencyMS ?? 10000;\n        this.haMode = false;\n        this.generation = 0;\n        this._timeout = undefined;\n    }\n    get srvAddress() {\n        return `_${this.srvServiceName}._tcp.${this.srvHost}`;\n    }\n    get intervalMS() {\n        return this.haMode ? this.heartbeatFrequencyMS : this.rescanSrvIntervalMS;\n    }\n    start() {\n        if (!this._timeout) {\n            this.schedule();\n        }\n    }\n    stop() {\n        if (this._timeout) {\n            (0, timers_1.clearTimeout)(this._timeout);\n            this.generation += 1;\n            this._timeout = undefined;\n        }\n    }\n    // TODO(NODE-4994): implement new logging logic for SrvPoller failures\n    schedule() {\n        if (this._timeout) {\n            (0, timers_1.clearTimeout)(this._timeout);\n        }\n        this._timeout = (0, timers_1.setTimeout)(() => {\n            // eslint-disable-next-line github/no-then\n            this._poll().then(undefined, utils_1.squashError);\n        }, this.intervalMS);\n    }\n    success(srvRecords) {\n        this.haMode = false;\n        this.schedule();\n        this.emit(SrvPoller.SRV_RECORD_DISCOVERY, new SrvPollingEvent(srvRecords));\n    }\n    failure() {\n        this.haMode = true;\n        this.schedule();\n    }\n    async _poll() {\n        const generation = this.generation;\n        let srvRecords;\n        try {\n            srvRecords = await dns.promises.resolveSrv(this.srvAddress);\n        }\n        catch (dnsError) {\n            this.failure();\n            return;\n        }\n        if (generation !== this.generation) {\n            return;\n        }\n        const finalAddresses = [];\n        for (const record of srvRecords) {\n            if ((0, utils_1.matchesParentDomain)(record.name, this.srvHost)) {\n                finalAddresses.push(record);\n            }\n        }\n        if (!finalAddresses.length) {\n            this.failure();\n            return;\n        }\n        this.success(finalAddresses);\n    }\n}\n/** @event */\nSrvPoller.SRV_RECORD_DISCOVERY = 'srvRecordDiscovery';\nexports.SrvPoller = SrvPoller;\n//# sourceMappingURL=srv_polling.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/sdam/srv_polling.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/topology.js":
/*!***************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/topology.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ServerCapabilities = exports.Topology = void 0;\nconst connection_string_1 = __webpack_require__(/*! ../connection_string */ \"./node_modules/mongodb/lib/connection_string.js\");\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_logger_1 = __webpack_require__(/*! ../mongo_logger */ \"./node_modules/mongodb/lib/mongo_logger.js\");\nconst mongo_types_1 = __webpack_require__(/*! ../mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst read_preference_1 = __webpack_require__(/*! ../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst timeout_1 = __webpack_require__(/*! ../timeout */ \"./node_modules/mongodb/lib/timeout.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst common_1 = __webpack_require__(/*! ./common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst events_1 = __webpack_require__(/*! ./events */ \"./node_modules/mongodb/lib/sdam/events.js\");\nconst server_1 = __webpack_require__(/*! ./server */ \"./node_modules/mongodb/lib/sdam/server.js\");\nconst server_description_1 = __webpack_require__(/*! ./server_description */ \"./node_modules/mongodb/lib/sdam/server_description.js\");\nconst server_selection_1 = __webpack_require__(/*! ./server_selection */ \"./node_modules/mongodb/lib/sdam/server_selection.js\");\nconst server_selection_events_1 = __webpack_require__(/*! ./server_selection_events */ \"./node_modules/mongodb/lib/sdam/server_selection_events.js\");\nconst srv_polling_1 = __webpack_require__(/*! ./srv_polling */ \"./node_modules/mongodb/lib/sdam/srv_polling.js\");\nconst topology_description_1 = __webpack_require__(/*! ./topology_description */ \"./node_modules/mongodb/lib/sdam/topology_description.js\");\n// Global state\nlet globalTopologyCounter = 0;\nconst stateTransition = (0, utils_1.makeStateMachine)({\n    [common_1.STATE_CLOSED]: [common_1.STATE_CLOSED, common_1.STATE_CONNECTING],\n    [common_1.STATE_CONNECTING]: [common_1.STATE_CONNECTING, common_1.STATE_CLOSING, common_1.STATE_CONNECTED, common_1.STATE_CLOSED],\n    [common_1.STATE_CONNECTED]: [common_1.STATE_CONNECTED, common_1.STATE_CLOSING, common_1.STATE_CLOSED],\n    [common_1.STATE_CLOSING]: [common_1.STATE_CLOSING, common_1.STATE_CLOSED]\n});\n/** @internal */\nconst kCancelled = Symbol('cancelled');\n/** @internal */\nconst kWaitQueue = Symbol('waitQueue');\n/**\n * A container of server instances representing a connection to a MongoDB topology.\n * @internal\n */\nclass Topology extends mongo_types_1.TypedEventEmitter {\n    /**\n     * @param seedlist - a list of HostAddress instances to connect to\n     */\n    constructor(client, seeds, options) {\n        super();\n        this.client = client;\n        // Options should only be undefined in tests, MongoClient will always have defined options\n        options = options ?? {\n            hosts: [utils_1.HostAddress.fromString('localhost:27017')],\n            ...Object.fromEntries(connection_string_1.DEFAULT_OPTIONS.entries()),\n            ...Object.fromEntries(connection_string_1.FEATURE_FLAGS.entries())\n        };\n        if (typeof seeds === 'string') {\n            seeds = [utils_1.HostAddress.fromString(seeds)];\n        }\n        else if (!Array.isArray(seeds)) {\n            seeds = [seeds];\n        }\n        const seedlist = [];\n        for (const seed of seeds) {\n            if (typeof seed === 'string') {\n                seedlist.push(utils_1.HostAddress.fromString(seed));\n            }\n            else if (seed instanceof utils_1.HostAddress) {\n                seedlist.push(seed);\n            }\n            else {\n                // FIXME(NODE-3483): May need to be a MongoParseError\n                throw new error_1.MongoRuntimeError(`Topology cannot be constructed from ${JSON.stringify(seed)}`);\n            }\n        }\n        const topologyType = topologyTypeFromOptions(options);\n        const topologyId = globalTopologyCounter++;\n        const selectedHosts = options.srvMaxHosts == null ||\n            options.srvMaxHosts === 0 ||\n            options.srvMaxHosts >= seedlist.length\n            ? seedlist\n            : (0, utils_1.shuffle)(seedlist, options.srvMaxHosts);\n        const serverDescriptions = new Map();\n        for (const hostAddress of selectedHosts) {\n            serverDescriptions.set(hostAddress.toString(), new server_description_1.ServerDescription(hostAddress));\n        }\n        this[kWaitQueue] = new utils_1.List();\n        this.s = {\n            // the id of this topology\n            id: topologyId,\n            // passed in options\n            options,\n            // initial seedlist of servers to connect to\n            seedlist,\n            // initial state\n            state: common_1.STATE_CLOSED,\n            // the topology description\n            description: new topology_description_1.TopologyDescription(topologyType, serverDescriptions, options.replicaSet, undefined, undefined, undefined, options),\n            serverSelectionTimeoutMS: options.serverSelectionTimeoutMS,\n            heartbeatFrequencyMS: options.heartbeatFrequencyMS,\n            minHeartbeatFrequencyMS: options.minHeartbeatFrequencyMS,\n            // a map of server instances to normalized addresses\n            servers: new Map(),\n            credentials: options?.credentials,\n            clusterTime: undefined,\n            // timer management\n            connectionTimers: new Set(),\n            detectShardedTopology: ev => this.detectShardedTopology(ev),\n            detectSrvRecords: ev => this.detectSrvRecords(ev)\n        };\n        this.mongoLogger = client.mongoLogger;\n        this.component = 'topology';\n        if (options.srvHost && !options.loadBalanced) {\n            this.s.srvPoller =\n                options.srvPoller ??\n                    new srv_polling_1.SrvPoller({\n                        heartbeatFrequencyMS: this.s.heartbeatFrequencyMS,\n                        srvHost: options.srvHost,\n                        srvMaxHosts: options.srvMaxHosts,\n                        srvServiceName: options.srvServiceName\n                    });\n            this.on(Topology.TOPOLOGY_DESCRIPTION_CHANGED, this.s.detectShardedTopology);\n        }\n        this.connectionLock = undefined;\n    }\n    detectShardedTopology(event) {\n        const previousType = event.previousDescription.type;\n        const newType = event.newDescription.type;\n        const transitionToSharded = previousType !== common_1.TopologyType.Sharded && newType === common_1.TopologyType.Sharded;\n        const srvListeners = this.s.srvPoller?.listeners(srv_polling_1.SrvPoller.SRV_RECORD_DISCOVERY);\n        const listeningToSrvPolling = !!srvListeners?.includes(this.s.detectSrvRecords);\n        if (transitionToSharded && !listeningToSrvPolling) {\n            this.s.srvPoller?.on(srv_polling_1.SrvPoller.SRV_RECORD_DISCOVERY, this.s.detectSrvRecords);\n            this.s.srvPoller?.start();\n        }\n    }\n    detectSrvRecords(ev) {\n        const previousTopologyDescription = this.s.description;\n        this.s.description = this.s.description.updateFromSrvPollingEvent(ev, this.s.options.srvMaxHosts);\n        if (this.s.description === previousTopologyDescription) {\n            // Nothing changed, so return\n            return;\n        }\n        updateServers(this);\n        this.emitAndLog(Topology.TOPOLOGY_DESCRIPTION_CHANGED, new events_1.TopologyDescriptionChangedEvent(this.s.id, previousTopologyDescription, this.s.description));\n    }\n    /**\n     * @returns A `TopologyDescription` for this topology\n     */\n    get description() {\n        return this.s.description;\n    }\n    get loadBalanced() {\n        return this.s.options.loadBalanced;\n    }\n    get serverApi() {\n        return this.s.options.serverApi;\n    }\n    get capabilities() {\n        return new ServerCapabilities(this.lastHello());\n    }\n    /** Initiate server connect */\n    async connect(options) {\n        this.connectionLock ??= this._connect(options);\n        try {\n            await this.connectionLock;\n            return this;\n        }\n        finally {\n            this.connectionLock = undefined;\n        }\n        return this;\n    }\n    async _connect(options) {\n        options = options ?? {};\n        if (this.s.state === common_1.STATE_CONNECTED) {\n            return this;\n        }\n        stateTransition(this, common_1.STATE_CONNECTING);\n        // emit SDAM monitoring events\n        this.emitAndLog(Topology.TOPOLOGY_OPENING, new events_1.TopologyOpeningEvent(this.s.id));\n        // emit an event for the topology change\n        this.emitAndLog(Topology.TOPOLOGY_DESCRIPTION_CHANGED, new events_1.TopologyDescriptionChangedEvent(this.s.id, new topology_description_1.TopologyDescription(common_1.TopologyType.Unknown), // initial is always Unknown\n        this.s.description));\n        // connect all known servers, then attempt server selection to connect\n        const serverDescriptions = Array.from(this.s.description.servers.values());\n        this.s.servers = new Map(serverDescriptions.map(serverDescription => [\n            serverDescription.address,\n            createAndConnectServer(this, serverDescription)\n        ]));\n        // In load balancer mode we need to fake a server description getting\n        // emitted from the monitor, since the monitor doesn't exist.\n        if (this.s.options.loadBalanced) {\n            for (const description of serverDescriptions) {\n                const newDescription = new server_description_1.ServerDescription(description.hostAddress, undefined, {\n                    loadBalanced: this.s.options.loadBalanced\n                });\n                this.serverUpdateHandler(newDescription);\n            }\n        }\n        const readPreference = options.readPreference ?? read_preference_1.ReadPreference.primary;\n        const selectServerOptions = { operationName: 'ping', ...options };\n        try {\n            const server = await this.selectServer((0, server_selection_1.readPreferenceServerSelector)(readPreference), selectServerOptions);\n            const skipPingOnConnect = this.s.options[Symbol.for('@@mdb.skipPingOnConnect')] === true;\n            if (!skipPingOnConnect && server && this.s.credentials) {\n                await server.command((0, utils_1.ns)('admin.$cmd'), { ping: 1 }, {});\n                stateTransition(this, common_1.STATE_CONNECTED);\n                this.emit(Topology.OPEN, this);\n                this.emit(Topology.CONNECT, this);\n                return this;\n            }\n            stateTransition(this, common_1.STATE_CONNECTED);\n            this.emit(Topology.OPEN, this);\n            this.emit(Topology.CONNECT, this);\n            return this;\n        }\n        catch (error) {\n            this.close();\n            throw error;\n        }\n    }\n    /** Close this topology */\n    close() {\n        if (this.s.state === common_1.STATE_CLOSED || this.s.state === common_1.STATE_CLOSING) {\n            return;\n        }\n        for (const server of this.s.servers.values()) {\n            destroyServer(server, this);\n        }\n        this.s.servers.clear();\n        stateTransition(this, common_1.STATE_CLOSING);\n        drainWaitQueue(this[kWaitQueue], new error_1.MongoTopologyClosedError());\n        (0, common_1.drainTimerQueue)(this.s.connectionTimers);\n        if (this.s.srvPoller) {\n            this.s.srvPoller.stop();\n            this.s.srvPoller.removeListener(srv_polling_1.SrvPoller.SRV_RECORD_DISCOVERY, this.s.detectSrvRecords);\n        }\n        this.removeListener(Topology.TOPOLOGY_DESCRIPTION_CHANGED, this.s.detectShardedTopology);\n        stateTransition(this, common_1.STATE_CLOSED);\n        // emit an event for close\n        this.emitAndLog(Topology.TOPOLOGY_CLOSED, new events_1.TopologyClosedEvent(this.s.id));\n    }\n    /**\n     * Selects a server according to the selection predicate provided\n     *\n     * @param selector - An optional selector to select servers by, defaults to a random selection within a latency window\n     * @param options - Optional settings related to server selection\n     * @param callback - The callback used to indicate success or failure\n     * @returns An instance of a `Server` meeting the criteria of the predicate provided\n     */\n    async selectServer(selector, options) {\n        let serverSelector;\n        if (typeof selector !== 'function') {\n            if (typeof selector === 'string') {\n                serverSelector = (0, server_selection_1.readPreferenceServerSelector)(read_preference_1.ReadPreference.fromString(selector));\n            }\n            else {\n                let readPreference;\n                if (selector instanceof read_preference_1.ReadPreference) {\n                    readPreference = selector;\n                }\n                else {\n                    read_preference_1.ReadPreference.translate(options);\n                    readPreference = options.readPreference || read_preference_1.ReadPreference.primary;\n                }\n                serverSelector = (0, server_selection_1.readPreferenceServerSelector)(readPreference);\n            }\n        }\n        else {\n            serverSelector = selector;\n        }\n        options = { serverSelectionTimeoutMS: this.s.serverSelectionTimeoutMS, ...options };\n        if (this.client.mongoLogger?.willLog(mongo_logger_1.MongoLoggableComponent.SERVER_SELECTION, mongo_logger_1.SeverityLevel.DEBUG)) {\n            this.client.mongoLogger?.debug(mongo_logger_1.MongoLoggableComponent.SERVER_SELECTION, new server_selection_events_1.ServerSelectionStartedEvent(selector, this.description, options.operationName));\n        }\n        const isSharded = this.description.type === common_1.TopologyType.Sharded;\n        const session = options.session;\n        const transaction = session && session.transaction;\n        if (isSharded && transaction && transaction.server) {\n            if (this.client.mongoLogger?.willLog(mongo_logger_1.MongoLoggableComponent.SERVER_SELECTION, mongo_logger_1.SeverityLevel.DEBUG)) {\n                this.client.mongoLogger?.debug(mongo_logger_1.MongoLoggableComponent.SERVER_SELECTION, new server_selection_events_1.ServerSelectionSucceededEvent(selector, this.description, transaction.server.pool.address, options.operationName));\n            }\n            return transaction.server;\n        }\n        const { promise: serverPromise, resolve, reject } = (0, utils_1.promiseWithResolvers)();\n        const timeout = timeout_1.Timeout.expires(options.serverSelectionTimeoutMS ?? 0);\n        const waitQueueMember = {\n            serverSelector,\n            topologyDescription: this.description,\n            mongoLogger: this.client.mongoLogger,\n            transaction,\n            resolve,\n            reject,\n            timeout,\n            startTime: (0, utils_1.now)(),\n            operationName: options.operationName,\n            waitingLogged: false,\n            previousServer: options.previousServer\n        };\n        this[kWaitQueue].push(waitQueueMember);\n        processWaitQueue(this);\n        try {\n            return await Promise.race([serverPromise, waitQueueMember.timeout]);\n        }\n        catch (error) {\n            if (timeout_1.TimeoutError.is(error)) {\n                // Timeout\n                waitQueueMember[kCancelled] = true;\n                timeout.clear();\n                const timeoutError = new error_1.MongoServerSelectionError(`Server selection timed out after ${options.serverSelectionTimeoutMS} ms`, this.description);\n                if (this.client.mongoLogger?.willLog(mongo_logger_1.MongoLoggableComponent.SERVER_SELECTION, mongo_logger_1.SeverityLevel.DEBUG)) {\n                    this.client.mongoLogger?.debug(mongo_logger_1.MongoLoggableComponent.SERVER_SELECTION, new server_selection_events_1.ServerSelectionFailedEvent(selector, this.description, timeoutError, options.operationName));\n                }\n                throw timeoutError;\n            }\n            // Other server selection error\n            throw error;\n        }\n    }\n    /**\n     * Update the internal TopologyDescription with a ServerDescription\n     *\n     * @param serverDescription - The server to update in the internal list of server descriptions\n     */\n    serverUpdateHandler(serverDescription) {\n        if (!this.s.description.hasServer(serverDescription.address)) {\n            return;\n        }\n        // ignore this server update if its from an outdated topologyVersion\n        if (isStaleServerDescription(this.s.description, serverDescription)) {\n            return;\n        }\n        // these will be used for monitoring events later\n        const previousTopologyDescription = this.s.description;\n        const previousServerDescription = this.s.description.servers.get(serverDescription.address);\n        if (!previousServerDescription) {\n            return;\n        }\n        // Driver Sessions Spec: \"Whenever a driver receives a cluster time from\n        // a server it MUST compare it to the current highest seen cluster time\n        // for the deployment. If the new cluster time is higher than the\n        // highest seen cluster time it MUST become the new highest seen cluster\n        // time. Two cluster times are compared using only the BsonTimestamp\n        // value of the clusterTime embedded field.\"\n        const clusterTime = serverDescription.$clusterTime;\n        if (clusterTime) {\n            (0, common_1._advanceClusterTime)(this, clusterTime);\n        }\n        // If we already know all the information contained in this updated description, then\n        // we don't need to emit SDAM events, but still need to update the description, in order\n        // to keep client-tracked attributes like last update time and round trip time up to date\n        const equalDescriptions = previousServerDescription && previousServerDescription.equals(serverDescription);\n        // first update the TopologyDescription\n        this.s.description = this.s.description.update(serverDescription);\n        if (this.s.description.compatibilityError) {\n            this.emit(Topology.ERROR, new error_1.MongoCompatibilityError(this.s.description.compatibilityError));\n            return;\n        }\n        // emit monitoring events for this change\n        if (!equalDescriptions) {\n            const newDescription = this.s.description.servers.get(serverDescription.address);\n            if (newDescription) {\n                this.emit(Topology.SERVER_DESCRIPTION_CHANGED, new events_1.ServerDescriptionChangedEvent(this.s.id, serverDescription.address, previousServerDescription, newDescription));\n            }\n        }\n        // update server list from updated descriptions\n        updateServers(this, serverDescription);\n        // attempt to resolve any outstanding server selection attempts\n        if (this[kWaitQueue].length > 0) {\n            processWaitQueue(this);\n        }\n        if (!equalDescriptions) {\n            this.emitAndLog(Topology.TOPOLOGY_DESCRIPTION_CHANGED, new events_1.TopologyDescriptionChangedEvent(this.s.id, previousTopologyDescription, this.s.description));\n        }\n    }\n    auth(credentials, callback) {\n        if (typeof credentials === 'function')\n            (callback = credentials), (credentials = undefined);\n        if (typeof callback === 'function')\n            callback(undefined, true);\n    }\n    get clientMetadata() {\n        return this.s.options.metadata;\n    }\n    isConnected() {\n        return this.s.state === common_1.STATE_CONNECTED;\n    }\n    isDestroyed() {\n        return this.s.state === common_1.STATE_CLOSED;\n    }\n    // NOTE: There are many places in code where we explicitly check the last hello\n    //       to do feature support detection. This should be done any other way, but for\n    //       now we will just return the first hello seen, which should suffice.\n    lastHello() {\n        const serverDescriptions = Array.from(this.description.servers.values());\n        if (serverDescriptions.length === 0)\n            return {};\n        const sd = serverDescriptions.filter((sd) => sd.type !== common_1.ServerType.Unknown)[0];\n        const result = sd || { maxWireVersion: this.description.commonWireVersion };\n        return result;\n    }\n    get commonWireVersion() {\n        return this.description.commonWireVersion;\n    }\n    get logicalSessionTimeoutMinutes() {\n        return this.description.logicalSessionTimeoutMinutes;\n    }\n    get clusterTime() {\n        return this.s.clusterTime;\n    }\n    set clusterTime(clusterTime) {\n        this.s.clusterTime = clusterTime;\n    }\n}\n/** @event */\nTopology.SERVER_OPENING = constants_1.SERVER_OPENING;\n/** @event */\nTopology.SERVER_CLOSED = constants_1.SERVER_CLOSED;\n/** @event */\nTopology.SERVER_DESCRIPTION_CHANGED = constants_1.SERVER_DESCRIPTION_CHANGED;\n/** @event */\nTopology.TOPOLOGY_OPENING = constants_1.TOPOLOGY_OPENING;\n/** @event */\nTopology.TOPOLOGY_CLOSED = constants_1.TOPOLOGY_CLOSED;\n/** @event */\nTopology.TOPOLOGY_DESCRIPTION_CHANGED = constants_1.TOPOLOGY_DESCRIPTION_CHANGED;\n/** @event */\nTopology.ERROR = constants_1.ERROR;\n/** @event */\nTopology.OPEN = constants_1.OPEN;\n/** @event */\nTopology.CONNECT = constants_1.CONNECT;\n/** @event */\nTopology.CLOSE = constants_1.CLOSE;\n/** @event */\nTopology.TIMEOUT = constants_1.TIMEOUT;\nexports.Topology = Topology;\n/** Destroys a server, and removes all event listeners from the instance */\nfunction destroyServer(server, topology) {\n    for (const event of constants_1.LOCAL_SERVER_EVENTS) {\n        server.removeAllListeners(event);\n    }\n    server.destroy();\n    topology.emitAndLog(Topology.SERVER_CLOSED, new events_1.ServerClosedEvent(topology.s.id, server.description.address));\n    for (const event of constants_1.SERVER_RELAY_EVENTS) {\n        server.removeAllListeners(event);\n    }\n}\n/** Predicts the TopologyType from options */\nfunction topologyTypeFromOptions(options) {\n    if (options?.directConnection) {\n        return common_1.TopologyType.Single;\n    }\n    if (options?.replicaSet) {\n        return common_1.TopologyType.ReplicaSetNoPrimary;\n    }\n    if (options?.loadBalanced) {\n        return common_1.TopologyType.LoadBalanced;\n    }\n    return common_1.TopologyType.Unknown;\n}\n/**\n * Creates new server instances and attempts to connect them\n *\n * @param topology - The topology that this server belongs to\n * @param serverDescription - The description for the server to initialize and connect to\n */\nfunction createAndConnectServer(topology, serverDescription) {\n    topology.emitAndLog(Topology.SERVER_OPENING, new events_1.ServerOpeningEvent(topology.s.id, serverDescription.address));\n    const server = new server_1.Server(topology, serverDescription, topology.s.options);\n    for (const event of constants_1.SERVER_RELAY_EVENTS) {\n        server.on(event, (e) => topology.emit(event, e));\n    }\n    server.on(server_1.Server.DESCRIPTION_RECEIVED, description => topology.serverUpdateHandler(description));\n    server.connect();\n    return server;\n}\n/**\n * @param topology - Topology to update.\n * @param incomingServerDescription - New server description.\n */\nfunction updateServers(topology, incomingServerDescription) {\n    // update the internal server's description\n    if (incomingServerDescription && topology.s.servers.has(incomingServerDescription.address)) {\n        const server = topology.s.servers.get(incomingServerDescription.address);\n        if (server) {\n            server.s.description = incomingServerDescription;\n            if (incomingServerDescription.error instanceof error_1.MongoError &&\n                incomingServerDescription.error.hasErrorLabel(error_1.MongoErrorLabel.ResetPool)) {\n                const interruptInUseConnections = incomingServerDescription.error.hasErrorLabel(error_1.MongoErrorLabel.InterruptInUseConnections);\n                server.pool.clear({ interruptInUseConnections });\n            }\n            else if (incomingServerDescription.error == null) {\n                const newTopologyType = topology.s.description.type;\n                const shouldMarkPoolReady = incomingServerDescription.isDataBearing ||\n                    (incomingServerDescription.type !== common_1.ServerType.Unknown &&\n                        newTopologyType === common_1.TopologyType.Single);\n                if (shouldMarkPoolReady) {\n                    server.pool.ready();\n                }\n            }\n        }\n    }\n    // add new servers for all descriptions we currently don't know about locally\n    for (const serverDescription of topology.description.servers.values()) {\n        if (!topology.s.servers.has(serverDescription.address)) {\n            const server = createAndConnectServer(topology, serverDescription);\n            topology.s.servers.set(serverDescription.address, server);\n        }\n    }\n    // for all servers no longer known, remove their descriptions and destroy their instances\n    for (const entry of topology.s.servers) {\n        const serverAddress = entry[0];\n        if (topology.description.hasServer(serverAddress)) {\n            continue;\n        }\n        if (!topology.s.servers.has(serverAddress)) {\n            continue;\n        }\n        const server = topology.s.servers.get(serverAddress);\n        topology.s.servers.delete(serverAddress);\n        // prepare server for garbage collection\n        if (server) {\n            destroyServer(server, topology);\n        }\n    }\n}\nfunction drainWaitQueue(queue, drainError) {\n    while (queue.length) {\n        const waitQueueMember = queue.shift();\n        if (!waitQueueMember) {\n            continue;\n        }\n        waitQueueMember.timeout.clear();\n        if (!waitQueueMember[kCancelled]) {\n            if (waitQueueMember.mongoLogger?.willLog(mongo_logger_1.MongoLoggableComponent.SERVER_SELECTION, mongo_logger_1.SeverityLevel.DEBUG)) {\n                waitQueueMember.mongoLogger?.debug(mongo_logger_1.MongoLoggableComponent.SERVER_SELECTION, new server_selection_events_1.ServerSelectionFailedEvent(waitQueueMember.serverSelector, waitQueueMember.topologyDescription, drainError, waitQueueMember.operationName));\n            }\n            waitQueueMember.reject(drainError);\n        }\n    }\n}\nfunction processWaitQueue(topology) {\n    if (topology.s.state === common_1.STATE_CLOSED) {\n        drainWaitQueue(topology[kWaitQueue], new error_1.MongoTopologyClosedError());\n        return;\n    }\n    const isSharded = topology.description.type === common_1.TopologyType.Sharded;\n    const serverDescriptions = Array.from(topology.description.servers.values());\n    const membersToProcess = topology[kWaitQueue].length;\n    for (let i = 0; i < membersToProcess; ++i) {\n        const waitQueueMember = topology[kWaitQueue].shift();\n        if (!waitQueueMember) {\n            continue;\n        }\n        if (waitQueueMember[kCancelled]) {\n            continue;\n        }\n        let selectedDescriptions;\n        try {\n            const serverSelector = waitQueueMember.serverSelector;\n            const previousServer = waitQueueMember.previousServer;\n            selectedDescriptions = serverSelector\n                ? serverSelector(topology.description, serverDescriptions, previousServer ? [previousServer] : [])\n                : serverDescriptions;\n        }\n        catch (selectorError) {\n            waitQueueMember.timeout.clear();\n            if (topology.client.mongoLogger?.willLog(mongo_logger_1.MongoLoggableComponent.SERVER_SELECTION, mongo_logger_1.SeverityLevel.DEBUG)) {\n                topology.client.mongoLogger?.debug(mongo_logger_1.MongoLoggableComponent.SERVER_SELECTION, new server_selection_events_1.ServerSelectionFailedEvent(waitQueueMember.serverSelector, topology.description, selectorError, waitQueueMember.operationName));\n            }\n            waitQueueMember.reject(selectorError);\n            continue;\n        }\n        let selectedServer;\n        if (selectedDescriptions.length === 0) {\n            if (!waitQueueMember.waitingLogged) {\n                if (topology.client.mongoLogger?.willLog(mongo_logger_1.MongoLoggableComponent.SERVER_SELECTION, mongo_logger_1.SeverityLevel.INFORMATIONAL)) {\n                    topology.client.mongoLogger?.info(mongo_logger_1.MongoLoggableComponent.SERVER_SELECTION, new server_selection_events_1.WaitingForSuitableServerEvent(waitQueueMember.serverSelector, topology.description, topology.s.serverSelectionTimeoutMS !== 0\n                        ? topology.s.serverSelectionTimeoutMS - ((0, utils_1.now)() - waitQueueMember.startTime)\n                        : -1, waitQueueMember.operationName));\n                }\n                waitQueueMember.waitingLogged = true;\n            }\n            topology[kWaitQueue].push(waitQueueMember);\n            continue;\n        }\n        else if (selectedDescriptions.length === 1) {\n            selectedServer = topology.s.servers.get(selectedDescriptions[0].address);\n        }\n        else {\n            const descriptions = (0, utils_1.shuffle)(selectedDescriptions, 2);\n            const server1 = topology.s.servers.get(descriptions[0].address);\n            const server2 = topology.s.servers.get(descriptions[1].address);\n            selectedServer =\n                server1 && server2 && server1.s.operationCount < server2.s.operationCount\n                    ? server1\n                    : server2;\n        }\n        if (!selectedServer) {\n            const serverSelectionError = new error_1.MongoServerSelectionError('server selection returned a server description but the server was not found in the topology', topology.description);\n            if (topology.client.mongoLogger?.willLog(mongo_logger_1.MongoLoggableComponent.SERVER_SELECTION, mongo_logger_1.SeverityLevel.DEBUG)) {\n                topology.client.mongoLogger?.debug(mongo_logger_1.MongoLoggableComponent.SERVER_SELECTION, new server_selection_events_1.ServerSelectionFailedEvent(waitQueueMember.serverSelector, topology.description, serverSelectionError, waitQueueMember.operationName));\n            }\n            waitQueueMember.reject(serverSelectionError);\n            return;\n        }\n        const transaction = waitQueueMember.transaction;\n        if (isSharded && transaction && transaction.isActive && selectedServer) {\n            transaction.pinServer(selectedServer);\n        }\n        waitQueueMember.timeout.clear();\n        if (topology.client.mongoLogger?.willLog(mongo_logger_1.MongoLoggableComponent.SERVER_SELECTION, mongo_logger_1.SeverityLevel.DEBUG)) {\n            topology.client.mongoLogger?.debug(mongo_logger_1.MongoLoggableComponent.SERVER_SELECTION, new server_selection_events_1.ServerSelectionSucceededEvent(waitQueueMember.serverSelector, waitQueueMember.topologyDescription, selectedServer.pool.address, waitQueueMember.operationName));\n        }\n        waitQueueMember.resolve(selectedServer);\n    }\n    if (topology[kWaitQueue].length > 0) {\n        // ensure all server monitors attempt monitoring soon\n        for (const [, server] of topology.s.servers) {\n            process.nextTick(function scheduleServerCheck() {\n                return server.requestCheck();\n            });\n        }\n    }\n}\nfunction isStaleServerDescription(topologyDescription, incomingServerDescription) {\n    const currentServerDescription = topologyDescription.servers.get(incomingServerDescription.address);\n    const currentTopologyVersion = currentServerDescription?.topologyVersion;\n    return ((0, server_description_1.compareTopologyVersion)(currentTopologyVersion, incomingServerDescription.topologyVersion) > 0);\n}\n/** @public */\nclass ServerCapabilities {\n    constructor(hello) {\n        this.minWireVersion = hello.minWireVersion || 0;\n        this.maxWireVersion = hello.maxWireVersion || 0;\n    }\n    get hasAggregationCursor() {\n        return this.maxWireVersion >= 1;\n    }\n    get hasWriteCommands() {\n        return this.maxWireVersion >= 2;\n    }\n    get hasTextSearch() {\n        return this.minWireVersion >= 0;\n    }\n    get hasAuthCommands() {\n        return this.maxWireVersion >= 1;\n    }\n    get hasListCollectionsCommand() {\n        return this.maxWireVersion >= 3;\n    }\n    get hasListIndexesCommand() {\n        return this.maxWireVersion >= 3;\n    }\n    get supportsSnapshotReads() {\n        return this.maxWireVersion >= 13;\n    }\n    get commandsTakeWriteConcern() {\n        return this.maxWireVersion >= 5;\n    }\n    get commandsTakeCollation() {\n        return this.maxWireVersion >= 5;\n    }\n}\nexports.ServerCapabilities = ServerCapabilities;\n//# sourceMappingURL=topology.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/sdam/topology.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/topology_description.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/topology_description.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TopologyDescription = void 0;\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst WIRE_CONSTANTS = __webpack_require__(/*! ../cmap/wire_protocol/constants */ \"./node_modules/mongodb/lib/cmap/wire_protocol/constants.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst common_1 = __webpack_require__(/*! ./common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst server_description_1 = __webpack_require__(/*! ./server_description */ \"./node_modules/mongodb/lib/sdam/server_description.js\");\n// constants related to compatibility checks\nconst MIN_SUPPORTED_SERVER_VERSION = WIRE_CONSTANTS.MIN_SUPPORTED_SERVER_VERSION;\nconst MAX_SUPPORTED_SERVER_VERSION = WIRE_CONSTANTS.MAX_SUPPORTED_SERVER_VERSION;\nconst MIN_SUPPORTED_WIRE_VERSION = WIRE_CONSTANTS.MIN_SUPPORTED_WIRE_VERSION;\nconst MAX_SUPPORTED_WIRE_VERSION = WIRE_CONSTANTS.MAX_SUPPORTED_WIRE_VERSION;\nconst MONGOS_OR_UNKNOWN = new Set([common_1.ServerType.Mongos, common_1.ServerType.Unknown]);\nconst MONGOS_OR_STANDALONE = new Set([common_1.ServerType.Mongos, common_1.ServerType.Standalone]);\nconst NON_PRIMARY_RS_MEMBERS = new Set([\n    common_1.ServerType.RSSecondary,\n    common_1.ServerType.RSArbiter,\n    common_1.ServerType.RSOther\n]);\n/**\n * Representation of a deployment of servers\n * @public\n */\nclass TopologyDescription {\n    /**\n     * Create a TopologyDescription\n     */\n    constructor(topologyType, serverDescriptions = null, setName = null, maxSetVersion = null, maxElectionId = null, commonWireVersion = null, options = null) {\n        options = options ?? {};\n        this.type = topologyType ?? common_1.TopologyType.Unknown;\n        this.servers = serverDescriptions ?? new Map();\n        this.stale = false;\n        this.compatible = true;\n        this.heartbeatFrequencyMS = options.heartbeatFrequencyMS ?? 0;\n        this.localThresholdMS = options.localThresholdMS ?? 15;\n        this.setName = setName ?? null;\n        this.maxElectionId = maxElectionId ?? null;\n        this.maxSetVersion = maxSetVersion ?? null;\n        this.commonWireVersion = commonWireVersion ?? 0;\n        // determine server compatibility\n        for (const serverDescription of this.servers.values()) {\n            // Load balancer mode is always compatible.\n            if (serverDescription.type === common_1.ServerType.Unknown ||\n                serverDescription.type === common_1.ServerType.LoadBalancer) {\n                continue;\n            }\n            if (serverDescription.minWireVersion > MAX_SUPPORTED_WIRE_VERSION) {\n                this.compatible = false;\n                this.compatibilityError = `Server at ${serverDescription.address} requires wire version ${serverDescription.minWireVersion}, but this version of the driver only supports up to ${MAX_SUPPORTED_WIRE_VERSION} (MongoDB ${MAX_SUPPORTED_SERVER_VERSION})`;\n            }\n            if (serverDescription.maxWireVersion < MIN_SUPPORTED_WIRE_VERSION) {\n                this.compatible = false;\n                this.compatibilityError = `Server at ${serverDescription.address} reports wire version ${serverDescription.maxWireVersion}, but this version of the driver requires at least ${MIN_SUPPORTED_WIRE_VERSION} (MongoDB ${MIN_SUPPORTED_SERVER_VERSION}).`;\n                break;\n            }\n        }\n        // Whenever a client updates the TopologyDescription from a hello response, it MUST set\n        // TopologyDescription.logicalSessionTimeoutMinutes to the smallest logicalSessionTimeoutMinutes\n        // value among ServerDescriptions of all data-bearing server types. If any have a null\n        // logicalSessionTimeoutMinutes, then TopologyDescription.logicalSessionTimeoutMinutes MUST be\n        // set to null.\n        this.logicalSessionTimeoutMinutes = null;\n        for (const [, server] of this.servers) {\n            if (server.isReadable) {\n                if (server.logicalSessionTimeoutMinutes == null) {\n                    // If any of the servers have a null logicalSessionsTimeout, then the whole topology does\n                    this.logicalSessionTimeoutMinutes = null;\n                    break;\n                }\n                if (this.logicalSessionTimeoutMinutes == null) {\n                    // First server with a non null logicalSessionsTimeout\n                    this.logicalSessionTimeoutMinutes = server.logicalSessionTimeoutMinutes;\n                    continue;\n                }\n                // Always select the smaller of the:\n                // current server logicalSessionsTimeout and the topologies logicalSessionsTimeout\n                this.logicalSessionTimeoutMinutes = Math.min(this.logicalSessionTimeoutMinutes, server.logicalSessionTimeoutMinutes);\n            }\n        }\n    }\n    /**\n     * Returns a new TopologyDescription based on the SrvPollingEvent\n     * @internal\n     */\n    updateFromSrvPollingEvent(ev, srvMaxHosts = 0) {\n        /** The SRV addresses defines the set of addresses we should be using */\n        const incomingHostnames = ev.hostnames();\n        const currentHostnames = new Set(this.servers.keys());\n        const hostnamesToAdd = new Set(incomingHostnames);\n        const hostnamesToRemove = new Set();\n        for (const hostname of currentHostnames) {\n            // filter hostnamesToAdd (made from incomingHostnames) down to what is *not* present in currentHostnames\n            hostnamesToAdd.delete(hostname);\n            if (!incomingHostnames.has(hostname)) {\n                // If the SRV Records no longer include this hostname\n                // we have to stop using it\n                hostnamesToRemove.add(hostname);\n            }\n        }\n        if (hostnamesToAdd.size === 0 && hostnamesToRemove.size === 0) {\n            // No new hosts to add and none to remove\n            return this;\n        }\n        const serverDescriptions = new Map(this.servers);\n        for (const removedHost of hostnamesToRemove) {\n            serverDescriptions.delete(removedHost);\n        }\n        if (hostnamesToAdd.size > 0) {\n            if (srvMaxHosts === 0) {\n                // Add all!\n                for (const hostToAdd of hostnamesToAdd) {\n                    serverDescriptions.set(hostToAdd, new server_description_1.ServerDescription(hostToAdd));\n                }\n            }\n            else if (serverDescriptions.size < srvMaxHosts) {\n                // Add only the amount needed to get us back to srvMaxHosts\n                const selectedHosts = (0, utils_1.shuffle)(hostnamesToAdd, srvMaxHosts - serverDescriptions.size);\n                for (const selectedHostToAdd of selectedHosts) {\n                    serverDescriptions.set(selectedHostToAdd, new server_description_1.ServerDescription(selectedHostToAdd));\n                }\n            }\n        }\n        return new TopologyDescription(this.type, serverDescriptions, this.setName, this.maxSetVersion, this.maxElectionId, this.commonWireVersion, { heartbeatFrequencyMS: this.heartbeatFrequencyMS, localThresholdMS: this.localThresholdMS });\n    }\n    /**\n     * Returns a copy of this description updated with a given ServerDescription\n     * @internal\n     */\n    update(serverDescription) {\n        const address = serverDescription.address;\n        // potentially mutated values\n        let { type: topologyType, setName, maxSetVersion, maxElectionId, commonWireVersion } = this;\n        const serverType = serverDescription.type;\n        const serverDescriptions = new Map(this.servers);\n        // update common wire version\n        if (serverDescription.maxWireVersion !== 0) {\n            if (commonWireVersion == null) {\n                commonWireVersion = serverDescription.maxWireVersion;\n            }\n            else {\n                commonWireVersion = Math.min(commonWireVersion, serverDescription.maxWireVersion);\n            }\n        }\n        if (typeof serverDescription.setName === 'string' &&\n            typeof setName === 'string' &&\n            serverDescription.setName !== setName) {\n            if (topologyType === common_1.TopologyType.Single) {\n                // \"Single\" Topology with setName mismatch is direct connection usage, mark unknown do not remove\n                serverDescription = new server_description_1.ServerDescription(address);\n            }\n            else {\n                serverDescriptions.delete(address);\n            }\n        }\n        // update the actual server description\n        serverDescriptions.set(address, serverDescription);\n        if (topologyType === common_1.TopologyType.Single) {\n            // once we are defined as single, that never changes\n            return new TopologyDescription(common_1.TopologyType.Single, serverDescriptions, setName, maxSetVersion, maxElectionId, commonWireVersion, { heartbeatFrequencyMS: this.heartbeatFrequencyMS, localThresholdMS: this.localThresholdMS });\n        }\n        if (topologyType === common_1.TopologyType.Unknown) {\n            if (serverType === common_1.ServerType.Standalone && this.servers.size !== 1) {\n                serverDescriptions.delete(address);\n            }\n            else {\n                topologyType = topologyTypeForServerType(serverType);\n            }\n        }\n        if (topologyType === common_1.TopologyType.Sharded) {\n            if (!MONGOS_OR_UNKNOWN.has(serverType)) {\n                serverDescriptions.delete(address);\n            }\n        }\n        if (topologyType === common_1.TopologyType.ReplicaSetNoPrimary) {\n            if (MONGOS_OR_STANDALONE.has(serverType)) {\n                serverDescriptions.delete(address);\n            }\n            if (serverType === common_1.ServerType.RSPrimary) {\n                const result = updateRsFromPrimary(serverDescriptions, serverDescription, setName, maxSetVersion, maxElectionId);\n                topologyType = result[0];\n                setName = result[1];\n                maxSetVersion = result[2];\n                maxElectionId = result[3];\n            }\n            else if (NON_PRIMARY_RS_MEMBERS.has(serverType)) {\n                const result = updateRsNoPrimaryFromMember(serverDescriptions, serverDescription, setName);\n                topologyType = result[0];\n                setName = result[1];\n            }\n        }\n        if (topologyType === common_1.TopologyType.ReplicaSetWithPrimary) {\n            if (MONGOS_OR_STANDALONE.has(serverType)) {\n                serverDescriptions.delete(address);\n                topologyType = checkHasPrimary(serverDescriptions);\n            }\n            else if (serverType === common_1.ServerType.RSPrimary) {\n                const result = updateRsFromPrimary(serverDescriptions, serverDescription, setName, maxSetVersion, maxElectionId);\n                topologyType = result[0];\n                setName = result[1];\n                maxSetVersion = result[2];\n                maxElectionId = result[3];\n            }\n            else if (NON_PRIMARY_RS_MEMBERS.has(serverType)) {\n                topologyType = updateRsWithPrimaryFromMember(serverDescriptions, serverDescription, setName);\n            }\n            else {\n                topologyType = checkHasPrimary(serverDescriptions);\n            }\n        }\n        return new TopologyDescription(topologyType, serverDescriptions, setName, maxSetVersion, maxElectionId, commonWireVersion, { heartbeatFrequencyMS: this.heartbeatFrequencyMS, localThresholdMS: this.localThresholdMS });\n    }\n    get error() {\n        const descriptionsWithError = Array.from(this.servers.values()).filter((sd) => sd.error);\n        if (descriptionsWithError.length > 0) {\n            return descriptionsWithError[0].error;\n        }\n        return null;\n    }\n    /**\n     * Determines if the topology description has any known servers\n     */\n    get hasKnownServers() {\n        return Array.from(this.servers.values()).some((sd) => sd.type !== common_1.ServerType.Unknown);\n    }\n    /**\n     * Determines if this topology description has a data-bearing server available.\n     */\n    get hasDataBearingServers() {\n        return Array.from(this.servers.values()).some((sd) => sd.isDataBearing);\n    }\n    /**\n     * Determines if the topology has a definition for the provided address\n     * @internal\n     */\n    hasServer(address) {\n        return this.servers.has(address);\n    }\n    /**\n     * Returns a JSON-serializable representation of the TopologyDescription.  This is primarily\n     * intended for use with JSON.stringify().\n     *\n     * This method will not throw.\n     */\n    toJSON() {\n        return bson_1.EJSON.serialize(this);\n    }\n}\nexports.TopologyDescription = TopologyDescription;\nfunction topologyTypeForServerType(serverType) {\n    switch (serverType) {\n        case common_1.ServerType.Standalone:\n            return common_1.TopologyType.Single;\n        case common_1.ServerType.Mongos:\n            return common_1.TopologyType.Sharded;\n        case common_1.ServerType.RSPrimary:\n            return common_1.TopologyType.ReplicaSetWithPrimary;\n        case common_1.ServerType.RSOther:\n        case common_1.ServerType.RSSecondary:\n            return common_1.TopologyType.ReplicaSetNoPrimary;\n        default:\n            return common_1.TopologyType.Unknown;\n    }\n}\nfunction updateRsFromPrimary(serverDescriptions, serverDescription, setName = null, maxSetVersion = null, maxElectionId = null) {\n    setName = setName || serverDescription.setName;\n    if (setName !== serverDescription.setName) {\n        serverDescriptions.delete(serverDescription.address);\n        return [checkHasPrimary(serverDescriptions), setName, maxSetVersion, maxElectionId];\n    }\n    if (serverDescription.maxWireVersion >= 17) {\n        const electionIdComparison = (0, utils_1.compareObjectId)(maxElectionId, serverDescription.electionId);\n        const maxElectionIdIsEqual = electionIdComparison === 0;\n        const maxElectionIdIsLess = electionIdComparison === -1;\n        const maxSetVersionIsLessOrEqual = (maxSetVersion ?? -1) <= (serverDescription.setVersion ?? -1);\n        if (maxElectionIdIsLess || (maxElectionIdIsEqual && maxSetVersionIsLessOrEqual)) {\n            // The reported electionId was greater\n            // or the electionId was equal and reported setVersion was greater\n            // Always update both values, they are a tuple\n            maxElectionId = serverDescription.electionId;\n            maxSetVersion = serverDescription.setVersion;\n        }\n        else {\n            // Stale primary\n            // replace serverDescription with a default ServerDescription of type \"Unknown\"\n            serverDescriptions.set(serverDescription.address, new server_description_1.ServerDescription(serverDescription.address));\n            return [checkHasPrimary(serverDescriptions), setName, maxSetVersion, maxElectionId];\n        }\n    }\n    else {\n        const electionId = serverDescription.electionId ? serverDescription.electionId : null;\n        if (serverDescription.setVersion && electionId) {\n            if (maxSetVersion && maxElectionId) {\n                if (maxSetVersion > serverDescription.setVersion ||\n                    (0, utils_1.compareObjectId)(maxElectionId, electionId) > 0) {\n                    // this primary is stale, we must remove it\n                    serverDescriptions.set(serverDescription.address, new server_description_1.ServerDescription(serverDescription.address));\n                    return [checkHasPrimary(serverDescriptions), setName, maxSetVersion, maxElectionId];\n                }\n            }\n            maxElectionId = serverDescription.electionId;\n        }\n        if (serverDescription.setVersion != null &&\n            (maxSetVersion == null || serverDescription.setVersion > maxSetVersion)) {\n            maxSetVersion = serverDescription.setVersion;\n        }\n    }\n    // We've heard from the primary. Is it the same primary as before?\n    for (const [address, server] of serverDescriptions) {\n        if (server.type === common_1.ServerType.RSPrimary && server.address !== serverDescription.address) {\n            // Reset old primary's type to Unknown.\n            serverDescriptions.set(address, new server_description_1.ServerDescription(server.address));\n            // There can only be one primary\n            break;\n        }\n    }\n    // Discover new hosts from this primary's response.\n    serverDescription.allHosts.forEach((address) => {\n        if (!serverDescriptions.has(address)) {\n            serverDescriptions.set(address, new server_description_1.ServerDescription(address));\n        }\n    });\n    // Remove hosts not in the response.\n    const currentAddresses = Array.from(serverDescriptions.keys());\n    const responseAddresses = serverDescription.allHosts;\n    currentAddresses\n        .filter((addr) => responseAddresses.indexOf(addr) === -1)\n        .forEach((address) => {\n        serverDescriptions.delete(address);\n    });\n    return [checkHasPrimary(serverDescriptions), setName, maxSetVersion, maxElectionId];\n}\nfunction updateRsWithPrimaryFromMember(serverDescriptions, serverDescription, setName = null) {\n    if (setName == null) {\n        // TODO(NODE-3483): should be an appropriate runtime error\n        throw new error_1.MongoRuntimeError('Argument \"setName\" is required if connected to a replica set');\n    }\n    if (setName !== serverDescription.setName ||\n        (serverDescription.me && serverDescription.address !== serverDescription.me)) {\n        serverDescriptions.delete(serverDescription.address);\n    }\n    return checkHasPrimary(serverDescriptions);\n}\nfunction updateRsNoPrimaryFromMember(serverDescriptions, serverDescription, setName = null) {\n    const topologyType = common_1.TopologyType.ReplicaSetNoPrimary;\n    setName = setName ?? serverDescription.setName;\n    if (setName !== serverDescription.setName) {\n        serverDescriptions.delete(serverDescription.address);\n        return [topologyType, setName];\n    }\n    serverDescription.allHosts.forEach((address) => {\n        if (!serverDescriptions.has(address)) {\n            serverDescriptions.set(address, new server_description_1.ServerDescription(address));\n        }\n    });\n    if (serverDescription.me && serverDescription.address !== serverDescription.me) {\n        serverDescriptions.delete(serverDescription.address);\n    }\n    return [topologyType, setName];\n}\nfunction checkHasPrimary(serverDescriptions) {\n    for (const serverDescription of serverDescriptions.values()) {\n        if (serverDescription.type === common_1.ServerType.RSPrimary) {\n            return common_1.TopologyType.ReplicaSetWithPrimary;\n        }\n    }\n    return common_1.TopologyType.ReplicaSetNoPrimary;\n}\n//# sourceMappingURL=topology_description.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/sdam/topology_description.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sessions.js":
/*!**********************************************!*\
  !*** ./node_modules/mongodb/lib/sessions.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nvar _a;\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.updateSessionFromResponse = exports.applySession = exports.ServerSessionPool = exports.ServerSession = exports.maybeClearPinnedConnection = exports.ClientSession = void 0;\nconst bson_1 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst metrics_1 = __webpack_require__(/*! ./cmap/metrics */ \"./node_modules/mongodb/lib/cmap/metrics.js\");\nconst shared_1 = __webpack_require__(/*! ./cmap/wire_protocol/shared */ \"./node_modules/mongodb/lib/cmap/wire_protocol/shared.js\");\nconst constants_1 = __webpack_require__(/*! ./constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_types_1 = __webpack_require__(/*! ./mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst execute_operation_1 = __webpack_require__(/*! ./operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst run_command_1 = __webpack_require__(/*! ./operations/run_command */ \"./node_modules/mongodb/lib/operations/run_command.js\");\nconst read_concern_1 = __webpack_require__(/*! ./read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst read_preference_1 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst common_1 = __webpack_require__(/*! ./sdam/common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst transactions_1 = __webpack_require__(/*! ./transactions */ \"./node_modules/mongodb/lib/transactions.js\");\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst write_concern_1 = __webpack_require__(/*! ./write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\nconst minWireVersionForShardedTransactions = 8;\n/** @internal */\nconst kServerSession = Symbol('serverSession');\n/** @internal */\nconst kSnapshotTime = Symbol('snapshotTime');\n/** @internal */\nconst kSnapshotEnabled = Symbol('snapshotEnabled');\n/** @internal */\nconst kPinnedConnection = Symbol('pinnedConnection');\n/** @internal Accumulates total number of increments to add to txnNumber when applying session to command */\nconst kTxnNumberIncrement = Symbol('txnNumberIncrement');\n/**\n * A class representing a client session on the server\n *\n * NOTE: not meant to be instantiated directly.\n * @public\n */\nclass ClientSession extends mongo_types_1.TypedEventEmitter {\n    /**\n     * Create a client session.\n     * @internal\n     * @param client - The current client\n     * @param sessionPool - The server session pool (Internal Class)\n     * @param options - Optional settings\n     * @param clientOptions - Optional settings provided when creating a MongoClient\n     */\n    constructor(client, sessionPool, options, clientOptions) {\n        super();\n        /** @internal */\n        this[_a] = false;\n        if (client == null) {\n            // TODO(NODE-3483)\n            throw new error_1.MongoRuntimeError('ClientSession requires a MongoClient');\n        }\n        if (sessionPool == null || !(sessionPool instanceof ServerSessionPool)) {\n            // TODO(NODE-3483)\n            throw new error_1.MongoRuntimeError('ClientSession requires a ServerSessionPool');\n        }\n        options = options ?? {};\n        if (options.snapshot === true) {\n            this[kSnapshotEnabled] = true;\n            if (options.causalConsistency === true) {\n                throw new error_1.MongoInvalidArgumentError('Properties \"causalConsistency\" and \"snapshot\" are mutually exclusive');\n            }\n        }\n        this.client = client;\n        this.sessionPool = sessionPool;\n        this.hasEnded = false;\n        this.clientOptions = clientOptions;\n        this.timeoutMS = options.defaultTimeoutMS ?? client.options?.timeoutMS;\n        this.explicit = !!options.explicit;\n        this[kServerSession] = this.explicit ? this.sessionPool.acquire() : null;\n        this[kTxnNumberIncrement] = 0;\n        const defaultCausalConsistencyValue = this.explicit && options.snapshot !== true;\n        this.supports = {\n            // if we can enable causal consistency, do so by default\n            causalConsistency: options.causalConsistency ?? defaultCausalConsistencyValue\n        };\n        this.clusterTime = options.initialClusterTime;\n        this.operationTime = undefined;\n        this.owner = options.owner;\n        this.defaultTransactionOptions = { ...options.defaultTransactionOptions };\n        this.transaction = new transactions_1.Transaction();\n    }\n    /** The server id associated with this session */\n    get id() {\n        return this[kServerSession]?.id;\n    }\n    get serverSession() {\n        let serverSession = this[kServerSession];\n        if (serverSession == null) {\n            if (this.explicit) {\n                throw new error_1.MongoRuntimeError('Unexpected null serverSession for an explicit session');\n            }\n            if (this.hasEnded) {\n                throw new error_1.MongoRuntimeError('Unexpected null serverSession for an ended implicit session');\n            }\n            serverSession = this.sessionPool.acquire();\n            this[kServerSession] = serverSession;\n        }\n        return serverSession;\n    }\n    /** Whether or not this session is configured for snapshot reads */\n    get snapshotEnabled() {\n        return this[kSnapshotEnabled];\n    }\n    get loadBalanced() {\n        return this.client.topology?.description.type === common_1.TopologyType.LoadBalanced;\n    }\n    /** @internal */\n    get pinnedConnection() {\n        return this[kPinnedConnection];\n    }\n    /** @internal */\n    pin(conn) {\n        if (this[kPinnedConnection]) {\n            throw TypeError('Cannot pin multiple connections to the same session');\n        }\n        this[kPinnedConnection] = conn;\n        conn.emit(constants_1.PINNED, this.inTransaction() ? metrics_1.ConnectionPoolMetrics.TXN : metrics_1.ConnectionPoolMetrics.CURSOR);\n    }\n    /** @internal */\n    unpin(options) {\n        if (this.loadBalanced) {\n            return maybeClearPinnedConnection(this, options);\n        }\n        this.transaction.unpinServer();\n    }\n    get isPinned() {\n        return this.loadBalanced ? !!this[kPinnedConnection] : this.transaction.isPinned;\n    }\n    /**\n     * Ends this session on the server\n     *\n     * @param options - Optional settings. Currently reserved for future use\n     */\n    async endSession(options) {\n        try {\n            if (this.inTransaction()) {\n                await this.abortTransaction();\n            }\n            if (!this.hasEnded) {\n                const serverSession = this[kServerSession];\n                if (serverSession != null) {\n                    // release the server session back to the pool\n                    this.sessionPool.release(serverSession);\n                    // Make sure a new serverSession never makes it onto this ClientSession\n                    Object.defineProperty(this, kServerSession, {\n                        value: ServerSession.clone(serverSession),\n                        writable: false\n                    });\n                }\n                // mark the session as ended, and emit a signal\n                this.hasEnded = true;\n                this.emit('ended', this);\n            }\n        }\n        catch (error) {\n            // spec indicates that we should ignore all errors for `endSessions`\n            (0, utils_1.squashError)(error);\n        }\n        finally {\n            maybeClearPinnedConnection(this, { force: true, ...options });\n        }\n    }\n    /**\n     * Advances the operationTime for a ClientSession.\n     *\n     * @param operationTime - the `BSON.Timestamp` of the operation type it is desired to advance to\n     */\n    advanceOperationTime(operationTime) {\n        if (this.operationTime == null) {\n            this.operationTime = operationTime;\n            return;\n        }\n        if (operationTime.greaterThan(this.operationTime)) {\n            this.operationTime = operationTime;\n        }\n    }\n    /**\n     * Advances the clusterTime for a ClientSession to the provided clusterTime of another ClientSession\n     *\n     * @param clusterTime - the $clusterTime returned by the server from another session in the form of a document containing the `BSON.Timestamp` clusterTime and signature\n     */\n    advanceClusterTime(clusterTime) {\n        if (!clusterTime || typeof clusterTime !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('input cluster time must be an object');\n        }\n        if (!clusterTime.clusterTime || clusterTime.clusterTime._bsontype !== 'Timestamp') {\n            throw new error_1.MongoInvalidArgumentError('input cluster time \"clusterTime\" property must be a valid BSON Timestamp');\n        }\n        if (!clusterTime.signature ||\n            clusterTime.signature.hash?._bsontype !== 'Binary' ||\n            (typeof clusterTime.signature.keyId !== 'bigint' &&\n                typeof clusterTime.signature.keyId !== 'number' &&\n                clusterTime.signature.keyId?._bsontype !== 'Long') // apparently we decode the key to number?\n        ) {\n            throw new error_1.MongoInvalidArgumentError('input cluster time must have a valid \"signature\" property with BSON Binary hash and BSON Long keyId');\n        }\n        (0, common_1._advanceClusterTime)(this, clusterTime);\n    }\n    /**\n     * Used to determine if this session equals another\n     *\n     * @param session - The session to compare to\n     */\n    equals(session) {\n        if (!(session instanceof ClientSession)) {\n            return false;\n        }\n        if (this.id == null || session.id == null) {\n            return false;\n        }\n        return utils_1.ByteUtils.equals(this.id.id.buffer, session.id.id.buffer);\n    }\n    /**\n     * Increment the transaction number on the internal ServerSession\n     *\n     * @privateRemarks\n     * This helper increments a value stored on the client session that will be\n     * added to the serverSession's txnNumber upon applying it to a command.\n     * This is because the serverSession is lazily acquired after a connection is obtained\n     */\n    incrementTransactionNumber() {\n        this[kTxnNumberIncrement] += 1;\n    }\n    /** @returns whether this session is currently in a transaction or not */\n    inTransaction() {\n        return this.transaction.isActive;\n    }\n    /**\n     * Starts a new transaction with the given options.\n     *\n     * @remarks\n     * **IMPORTANT**: Running operations in parallel is not supported during a transaction. The use of `Promise.all`,\n     * `Promise.allSettled`, `Promise.race`, etc to parallelize operations inside a transaction is\n     * undefined behaviour.\n     *\n     * @param options - Options for the transaction\n     */\n    startTransaction(options) {\n        if (this[kSnapshotEnabled]) {\n            throw new error_1.MongoCompatibilityError('Transactions are not supported in snapshot sessions');\n        }\n        if (this.inTransaction()) {\n            throw new error_1.MongoTransactionError('Transaction already in progress');\n        }\n        if (this.isPinned && this.transaction.isCommitted) {\n            this.unpin();\n        }\n        const topologyMaxWireVersion = (0, utils_1.maxWireVersion)(this.client.topology);\n        if ((0, shared_1.isSharded)(this.client.topology) &&\n            topologyMaxWireVersion != null &&\n            topologyMaxWireVersion < minWireVersionForShardedTransactions) {\n            throw new error_1.MongoCompatibilityError('Transactions are not supported on sharded clusters in MongoDB < 4.2.');\n        }\n        // increment txnNumber\n        this.incrementTransactionNumber();\n        // create transaction state\n        this.transaction = new transactions_1.Transaction({\n            readConcern: options?.readConcern ??\n                this.defaultTransactionOptions.readConcern ??\n                this.clientOptions?.readConcern,\n            writeConcern: options?.writeConcern ??\n                this.defaultTransactionOptions.writeConcern ??\n                this.clientOptions?.writeConcern,\n            readPreference: options?.readPreference ??\n                this.defaultTransactionOptions.readPreference ??\n                this.clientOptions?.readPreference,\n            maxCommitTimeMS: options?.maxCommitTimeMS ?? this.defaultTransactionOptions.maxCommitTimeMS\n        });\n        this.transaction.transition(transactions_1.TxnState.STARTING_TRANSACTION);\n    }\n    /**\n     * Commits the currently active transaction in this session.\n     */\n    async commitTransaction() {\n        return await endTransaction(this, 'commitTransaction');\n    }\n    /**\n     * Aborts the currently active transaction in this session.\n     */\n    async abortTransaction() {\n        return await endTransaction(this, 'abortTransaction');\n    }\n    /**\n     * This is here to ensure that ClientSession is never serialized to BSON.\n     */\n    toBSON() {\n        throw new error_1.MongoRuntimeError('ClientSession cannot be serialized to BSON.');\n    }\n    /**\n     * Starts a transaction and runs a provided function, ensuring the commitTransaction is always attempted when all operations run in the function have completed.\n     *\n     * **IMPORTANT:** This method requires the function passed in to return a Promise. That promise must be made by `await`-ing all operations in such a way that rejections are propagated to the returned promise.\n     *\n     * **IMPORTANT:** Running operations in parallel is not supported during a transaction. The use of `Promise.all`,\n     * `Promise.allSettled`, `Promise.race`, etc to parallelize operations inside a transaction is\n     * undefined behaviour.\n     *\n     *\n     * @remarks\n     * - If all operations successfully complete and the `commitTransaction` operation is successful, then the provided function will return the result of the provided function.\n     * - If the transaction is unable to complete or an error is thrown from within the provided function, then the provided function will throw an error.\n     *   - If the transaction is manually aborted within the provided function it will not throw.\n     * - If the driver needs to attempt to retry the operations, the provided function may be called multiple times.\n     *\n     * Checkout a descriptive example here:\n     * @see https://www.mongodb.com/blog/post/quick-start-nodejs--mongodb--how-to-implement-transactions\n     *\n     * If a command inside withTransaction fails:\n     * - It may cause the transaction on the server to be aborted.\n     * - This situation is normally handled transparently by the driver.\n     * - However, if the application catches such an error and does not rethrow it, the driver will not be able to determine whether the transaction was aborted or not.\n     * - The driver will then retry the transaction indefinitely.\n     *\n     * To avoid this situation, the application must not silently handle errors within the provided function.\n     * If the application needs to handle errors within, it must await all operations such that if an operation is rejected it becomes the rejection of the callback function passed into withTransaction.\n     *\n     * @param fn - callback to run within a transaction\n     * @param options - optional settings for the transaction\n     * @returns A raw command response or undefined\n     */\n    async withTransaction(fn, options) {\n        const startTime = (0, utils_1.now)();\n        return await attemptTransaction(this, startTime, fn, options);\n    }\n}\nexports.ClientSession = ClientSession;\n_a = kSnapshotEnabled;\nconst MAX_WITH_TRANSACTION_TIMEOUT = 120000;\nconst NON_DETERMINISTIC_WRITE_CONCERN_ERRORS = new Set([\n    'CannotSatisfyWriteConcern',\n    'UnknownReplWriteConcern',\n    'UnsatisfiableWriteConcern'\n]);\nfunction hasNotTimedOut(startTime, max) {\n    return (0, utils_1.calculateDurationInMs)(startTime) < max;\n}\nfunction isUnknownTransactionCommitResult(err) {\n    const isNonDeterministicWriteConcernError = err instanceof error_1.MongoServerError &&\n        err.codeName &&\n        NON_DETERMINISTIC_WRITE_CONCERN_ERRORS.has(err.codeName);\n    return (isMaxTimeMSExpiredError(err) ||\n        (!isNonDeterministicWriteConcernError &&\n            err.code !== error_1.MONGODB_ERROR_CODES.UnsatisfiableWriteConcern &&\n            err.code !== error_1.MONGODB_ERROR_CODES.UnknownReplWriteConcern));\n}\nfunction maybeClearPinnedConnection(session, options) {\n    // unpin a connection if it has been pinned\n    const conn = session[kPinnedConnection];\n    const error = options?.error;\n    if (session.inTransaction() &&\n        error &&\n        error instanceof error_1.MongoError &&\n        error.hasErrorLabel(error_1.MongoErrorLabel.TransientTransactionError)) {\n        return;\n    }\n    const topology = session.client.topology;\n    // NOTE: the spec talks about what to do on a network error only, but the tests seem to\n    //       to validate that we don't unpin on _all_ errors?\n    if (conn && topology != null) {\n        const servers = Array.from(topology.s.servers.values());\n        const loadBalancer = servers[0];\n        if (options?.error == null || options?.force) {\n            loadBalancer.pool.checkIn(conn);\n            session[kPinnedConnection] = undefined;\n            conn.emit(constants_1.UNPINNED, session.transaction.state !== transactions_1.TxnState.NO_TRANSACTION\n                ? metrics_1.ConnectionPoolMetrics.TXN\n                : metrics_1.ConnectionPoolMetrics.CURSOR);\n            if (options?.forceClear) {\n                loadBalancer.pool.clear({ serviceId: conn.serviceId });\n            }\n        }\n    }\n}\nexports.maybeClearPinnedConnection = maybeClearPinnedConnection;\nfunction isMaxTimeMSExpiredError(err) {\n    if (err == null || !(err instanceof error_1.MongoServerError)) {\n        return false;\n    }\n    return (err.code === error_1.MONGODB_ERROR_CODES.MaxTimeMSExpired ||\n        (err.writeConcernError && err.writeConcernError.code === error_1.MONGODB_ERROR_CODES.MaxTimeMSExpired));\n}\nasync function attemptTransactionCommit(session, startTime, fn, result, options) {\n    try {\n        await session.commitTransaction();\n        return result;\n    }\n    catch (commitErr) {\n        if (commitErr instanceof error_1.MongoError &&\n            hasNotTimedOut(startTime, MAX_WITH_TRANSACTION_TIMEOUT) &&\n            !isMaxTimeMSExpiredError(commitErr)) {\n            if (commitErr.hasErrorLabel(error_1.MongoErrorLabel.UnknownTransactionCommitResult)) {\n                return await attemptTransactionCommit(session, startTime, fn, result, options);\n            }\n            if (commitErr.hasErrorLabel(error_1.MongoErrorLabel.TransientTransactionError)) {\n                return await attemptTransaction(session, startTime, fn, options);\n            }\n        }\n        throw commitErr;\n    }\n}\nconst USER_EXPLICIT_TXN_END_STATES = new Set([\n    transactions_1.TxnState.NO_TRANSACTION,\n    transactions_1.TxnState.TRANSACTION_COMMITTED,\n    transactions_1.TxnState.TRANSACTION_ABORTED\n]);\nfunction userExplicitlyEndedTransaction(session) {\n    return USER_EXPLICIT_TXN_END_STATES.has(session.transaction.state);\n}\nasync function attemptTransaction(session, startTime, fn, options = {}) {\n    session.startTransaction(options);\n    let promise;\n    try {\n        promise = fn(session);\n    }\n    catch (err) {\n        promise = Promise.reject(err);\n    }\n    if (!(0, utils_1.isPromiseLike)(promise)) {\n        try {\n            await session.abortTransaction();\n        }\n        catch (error) {\n            (0, utils_1.squashError)(error);\n        }\n        throw new error_1.MongoInvalidArgumentError('Function provided to `withTransaction` must return a Promise');\n    }\n    try {\n        const result = await promise;\n        if (userExplicitlyEndedTransaction(session)) {\n            return result;\n        }\n        return await attemptTransactionCommit(session, startTime, fn, result, options);\n    }\n    catch (err) {\n        if (session.inTransaction()) {\n            await session.abortTransaction();\n        }\n        if (err instanceof error_1.MongoError &&\n            err.hasErrorLabel(error_1.MongoErrorLabel.TransientTransactionError) &&\n            hasNotTimedOut(startTime, MAX_WITH_TRANSACTION_TIMEOUT)) {\n            return await attemptTransaction(session, startTime, fn, options);\n        }\n        if (isMaxTimeMSExpiredError(err)) {\n            err.addErrorLabel(error_1.MongoErrorLabel.UnknownTransactionCommitResult);\n        }\n        throw err;\n    }\n}\nasync function endTransaction(session, commandName) {\n    // handle any initial problematic cases\n    const txnState = session.transaction.state;\n    if (txnState === transactions_1.TxnState.NO_TRANSACTION) {\n        throw new error_1.MongoTransactionError('No transaction started');\n    }\n    if (commandName === 'commitTransaction') {\n        if (txnState === transactions_1.TxnState.STARTING_TRANSACTION ||\n            txnState === transactions_1.TxnState.TRANSACTION_COMMITTED_EMPTY) {\n            // the transaction was never started, we can safely exit here\n            session.transaction.transition(transactions_1.TxnState.TRANSACTION_COMMITTED_EMPTY);\n            return;\n        }\n        if (txnState === transactions_1.TxnState.TRANSACTION_ABORTED) {\n            throw new error_1.MongoTransactionError('Cannot call commitTransaction after calling abortTransaction');\n        }\n    }\n    else {\n        if (txnState === transactions_1.TxnState.STARTING_TRANSACTION) {\n            // the transaction was never started, we can safely exit here\n            session.transaction.transition(transactions_1.TxnState.TRANSACTION_ABORTED);\n            return;\n        }\n        if (txnState === transactions_1.TxnState.TRANSACTION_ABORTED) {\n            throw new error_1.MongoTransactionError('Cannot call abortTransaction twice');\n        }\n        if (txnState === transactions_1.TxnState.TRANSACTION_COMMITTED ||\n            txnState === transactions_1.TxnState.TRANSACTION_COMMITTED_EMPTY) {\n            throw new error_1.MongoTransactionError('Cannot call abortTransaction after calling commitTransaction');\n        }\n    }\n    // construct and send the command\n    const command = { [commandName]: 1 };\n    // apply a writeConcern if specified\n    let writeConcern;\n    if (session.transaction.options.writeConcern) {\n        writeConcern = Object.assign({}, session.transaction.options.writeConcern);\n    }\n    else if (session.clientOptions && session.clientOptions.writeConcern) {\n        writeConcern = { w: session.clientOptions.writeConcern.w };\n    }\n    if (txnState === transactions_1.TxnState.TRANSACTION_COMMITTED) {\n        writeConcern = Object.assign({ wtimeoutMS: 10000 }, writeConcern, { w: 'majority' });\n    }\n    if (writeConcern) {\n        write_concern_1.WriteConcern.apply(command, writeConcern);\n    }\n    if (commandName === 'commitTransaction' && session.transaction.options.maxTimeMS) {\n        Object.assign(command, { maxTimeMS: session.transaction.options.maxTimeMS });\n    }\n    if (session.transaction.recoveryToken) {\n        command.recoveryToken = session.transaction.recoveryToken;\n    }\n    try {\n        // send the command\n        await (0, execute_operation_1.executeOperation)(session.client, new run_command_1.RunAdminCommandOperation(command, {\n            session,\n            readPreference: read_preference_1.ReadPreference.primary,\n            bypassPinningCheck: true\n        }));\n        if (command.abortTransaction) {\n            // always unpin on abort regardless of command outcome\n            session.unpin();\n        }\n        if (commandName !== 'commitTransaction') {\n            session.transaction.transition(transactions_1.TxnState.TRANSACTION_ABORTED);\n            if (session.loadBalanced) {\n                maybeClearPinnedConnection(session, { force: false });\n            }\n        }\n        else {\n            session.transaction.transition(transactions_1.TxnState.TRANSACTION_COMMITTED);\n        }\n    }\n    catch (firstAttemptErr) {\n        if (command.abortTransaction) {\n            // always unpin on abort regardless of command outcome\n            session.unpin();\n        }\n        if (firstAttemptErr instanceof error_1.MongoError && (0, error_1.isRetryableWriteError)(firstAttemptErr)) {\n            // SPEC-1185: apply majority write concern when retrying commitTransaction\n            if (command.commitTransaction) {\n                // per txns spec, must unpin session in this case\n                session.unpin({ force: true });\n                command.writeConcern = Object.assign({ wtimeout: 10000 }, command.writeConcern, {\n                    w: 'majority'\n                });\n            }\n            try {\n                await (0, execute_operation_1.executeOperation)(session.client, new run_command_1.RunAdminCommandOperation(command, {\n                    session,\n                    readPreference: read_preference_1.ReadPreference.primary,\n                    bypassPinningCheck: true\n                }));\n                if (commandName !== 'commitTransaction') {\n                    session.transaction.transition(transactions_1.TxnState.TRANSACTION_ABORTED);\n                    if (session.loadBalanced) {\n                        maybeClearPinnedConnection(session, { force: false });\n                    }\n                }\n                else {\n                    session.transaction.transition(transactions_1.TxnState.TRANSACTION_COMMITTED);\n                }\n            }\n            catch (secondAttemptErr) {\n                handleEndTransactionError(session, commandName, secondAttemptErr);\n            }\n        }\n        else {\n            handleEndTransactionError(session, commandName, firstAttemptErr);\n        }\n    }\n}\nfunction handleEndTransactionError(session, commandName, error) {\n    if (commandName !== 'commitTransaction') {\n        session.transaction.transition(transactions_1.TxnState.TRANSACTION_ABORTED);\n        if (session.loadBalanced) {\n            maybeClearPinnedConnection(session, { force: false });\n        }\n        // The spec indicates that if the operation times out or fails with a non-retryable error, we should ignore all errors on `abortTransaction`\n        return;\n    }\n    session.transaction.transition(transactions_1.TxnState.TRANSACTION_COMMITTED);\n    if (error instanceof error_1.MongoError) {\n        if ((0, error_1.isRetryableWriteError)(error) ||\n            error instanceof error_1.MongoWriteConcernError ||\n            isMaxTimeMSExpiredError(error)) {\n            if (isUnknownTransactionCommitResult(error)) {\n                error.addErrorLabel(error_1.MongoErrorLabel.UnknownTransactionCommitResult);\n                // per txns spec, must unpin session in this case\n                session.unpin({ error });\n            }\n        }\n        else if (error.hasErrorLabel(error_1.MongoErrorLabel.TransientTransactionError)) {\n            session.unpin({ error });\n        }\n    }\n    throw error;\n}\n/**\n * Reflects the existence of a session on the server. Can be reused by the session pool.\n * WARNING: not meant to be instantiated directly. For internal use only.\n * @public\n */\nclass ServerSession {\n    /** @internal */\n    constructor() {\n        this.id = { id: new bson_1.Binary((0, utils_1.uuidV4)(), bson_1.Binary.SUBTYPE_UUID) };\n        this.lastUse = (0, utils_1.now)();\n        this.txnNumber = 0;\n        this.isDirty = false;\n    }\n    /**\n     * Determines if the server session has timed out.\n     *\n     * @param sessionTimeoutMinutes - The server's \"logicalSessionTimeoutMinutes\"\n     */\n    hasTimedOut(sessionTimeoutMinutes) {\n        // Take the difference of the lastUse timestamp and now, which will result in a value in\n        // milliseconds, and then convert milliseconds to minutes to compare to `sessionTimeoutMinutes`\n        const idleTimeMinutes = Math.round((((0, utils_1.calculateDurationInMs)(this.lastUse) % 86400000) % 3600000) / 60000);\n        return idleTimeMinutes > sessionTimeoutMinutes - 1;\n    }\n    /**\n     * @internal\n     * Cloning meant to keep a readable reference to the server session data\n     * after ClientSession has ended\n     */\n    static clone(serverSession) {\n        const arrayBuffer = new ArrayBuffer(16);\n        const idBytes = Buffer.from(arrayBuffer);\n        idBytes.set(serverSession.id.id.buffer);\n        const id = new bson_1.Binary(idBytes, serverSession.id.id.sub_type);\n        // Manual prototype construction to avoid modifying the constructor of this class\n        return Object.setPrototypeOf({\n            id: { id },\n            lastUse: serverSession.lastUse,\n            txnNumber: serverSession.txnNumber,\n            isDirty: serverSession.isDirty\n        }, ServerSession.prototype);\n    }\n}\nexports.ServerSession = ServerSession;\n/**\n * Maintains a pool of Server Sessions.\n * For internal use only\n * @internal\n */\nclass ServerSessionPool {\n    constructor(client) {\n        if (client == null) {\n            throw new error_1.MongoRuntimeError('ServerSessionPool requires a MongoClient');\n        }\n        this.client = client;\n        this.sessions = new utils_1.List();\n    }\n    /**\n     * Acquire a Server Session from the pool.\n     * Iterates through each session in the pool, removing any stale sessions\n     * along the way. The first non-stale session found is removed from the\n     * pool and returned. If no non-stale session is found, a new ServerSession is created.\n     */\n    acquire() {\n        const sessionTimeoutMinutes = this.client.topology?.logicalSessionTimeoutMinutes ?? 10;\n        let session = null;\n        // Try to obtain from session pool\n        while (this.sessions.length > 0) {\n            const potentialSession = this.sessions.shift();\n            if (potentialSession != null &&\n                (!!this.client.topology?.loadBalanced ||\n                    !potentialSession.hasTimedOut(sessionTimeoutMinutes))) {\n                session = potentialSession;\n                break;\n            }\n        }\n        // If nothing valid came from the pool make a new one\n        if (session == null) {\n            session = new ServerSession();\n        }\n        return session;\n    }\n    /**\n     * Release a session to the session pool\n     * Adds the session back to the session pool if the session has not timed out yet.\n     * This method also removes any stale sessions from the pool.\n     *\n     * @param session - The session to release to the pool\n     */\n    release(session) {\n        const sessionTimeoutMinutes = this.client.topology?.logicalSessionTimeoutMinutes ?? 10;\n        if (this.client.topology?.loadBalanced && !sessionTimeoutMinutes) {\n            this.sessions.unshift(session);\n        }\n        if (!sessionTimeoutMinutes) {\n            return;\n        }\n        this.sessions.prune(session => session.hasTimedOut(sessionTimeoutMinutes));\n        if (!session.hasTimedOut(sessionTimeoutMinutes)) {\n            if (session.isDirty) {\n                return;\n            }\n            // otherwise, readd this session to the session pool\n            this.sessions.unshift(session);\n        }\n    }\n}\nexports.ServerSessionPool = ServerSessionPool;\n/**\n * Optionally decorate a command with sessions specific keys\n *\n * @param session - the session tracking transaction state\n * @param command - the command to decorate\n * @param options - Optional settings passed to calling operation\n *\n * @internal\n */\nfunction applySession(session, command, options) {\n    if (session.hasEnded) {\n        return new error_1.MongoExpiredSessionError();\n    }\n    // May acquire serverSession here\n    const serverSession = session.serverSession;\n    if (serverSession == null) {\n        return new error_1.MongoRuntimeError('Unable to acquire server session');\n    }\n    if (options.writeConcern?.w === 0) {\n        if (session && session.explicit) {\n            // Error if user provided an explicit session to an unacknowledged write (SPEC-1019)\n            return new error_1.MongoAPIError('Cannot have explicit session with unacknowledged writes');\n        }\n        return;\n    }\n    // mark the last use of this session, and apply the `lsid`\n    serverSession.lastUse = (0, utils_1.now)();\n    command.lsid = serverSession.id;\n    const inTxnOrTxnCommand = session.inTransaction() || (0, transactions_1.isTransactionCommand)(command);\n    const isRetryableWrite = !!options.willRetryWrite;\n    if (isRetryableWrite || inTxnOrTxnCommand) {\n        serverSession.txnNumber += session[kTxnNumberIncrement];\n        session[kTxnNumberIncrement] = 0;\n        // TODO(NODE-2674): Preserve int64 sent from MongoDB\n        command.txnNumber = bson_1.Long.fromNumber(serverSession.txnNumber);\n    }\n    if (!inTxnOrTxnCommand) {\n        if (session.transaction.state !== transactions_1.TxnState.NO_TRANSACTION) {\n            session.transaction.transition(transactions_1.TxnState.NO_TRANSACTION);\n        }\n        if (session.supports.causalConsistency &&\n            session.operationTime &&\n            (0, utils_1.commandSupportsReadConcern)(command)) {\n            command.readConcern = command.readConcern || {};\n            Object.assign(command.readConcern, { afterClusterTime: session.operationTime });\n        }\n        else if (session[kSnapshotEnabled]) {\n            command.readConcern = command.readConcern || { level: read_concern_1.ReadConcernLevel.snapshot };\n            if (session[kSnapshotTime] != null) {\n                Object.assign(command.readConcern, { atClusterTime: session[kSnapshotTime] });\n            }\n        }\n        return;\n    }\n    // now attempt to apply transaction-specific sessions data\n    // `autocommit` must always be false to differentiate from retryable writes\n    command.autocommit = false;\n    if (session.transaction.state === transactions_1.TxnState.STARTING_TRANSACTION) {\n        session.transaction.transition(transactions_1.TxnState.TRANSACTION_IN_PROGRESS);\n        command.startTransaction = true;\n        const readConcern = session.transaction.options.readConcern || session?.clientOptions?.readConcern;\n        if (readConcern) {\n            command.readConcern = readConcern;\n        }\n        if (session.supports.causalConsistency && session.operationTime) {\n            command.readConcern = command.readConcern || {};\n            Object.assign(command.readConcern, { afterClusterTime: session.operationTime });\n        }\n    }\n    return;\n}\nexports.applySession = applySession;\nfunction updateSessionFromResponse(session, document) {\n    if (document.$clusterTime) {\n        (0, common_1._advanceClusterTime)(session, document.$clusterTime);\n    }\n    if (document.operationTime && session && session.supports.causalConsistency) {\n        session.advanceOperationTime(document.operationTime);\n    }\n    if (document.recoveryToken && session && session.inTransaction()) {\n        session.transaction._recoveryToken = document.recoveryToken;\n    }\n    if (session?.[kSnapshotEnabled] && session[kSnapshotTime] == null) {\n        // find and aggregate commands return atClusterTime on the cursor\n        // distinct includes it in the response body\n        const atClusterTime = document.atClusterTime;\n        if (atClusterTime) {\n            session[kSnapshotTime] = atClusterTime;\n        }\n    }\n}\nexports.updateSessionFromResponse = updateSessionFromResponse;\n//# sourceMappingURL=sessions.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/sessions.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sort.js":
/*!******************************************!*\
  !*** ./node_modules/mongodb/lib/sort.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.formatSort = void 0;\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\n/** @internal */\nfunction prepareDirection(direction = 1) {\n    const value = `${direction}`.toLowerCase();\n    if (isMeta(direction))\n        return direction;\n    switch (value) {\n        case 'ascending':\n        case 'asc':\n        case '1':\n            return 1;\n        case 'descending':\n        case 'desc':\n        case '-1':\n            return -1;\n        default:\n            throw new error_1.MongoInvalidArgumentError(`Invalid sort direction: ${JSON.stringify(direction)}`);\n    }\n}\n/** @internal */\nfunction isMeta(t) {\n    return typeof t === 'object' && t != null && '$meta' in t && typeof t.$meta === 'string';\n}\n/** @internal */\nfunction isPair(t) {\n    if (Array.isArray(t) && t.length === 2) {\n        try {\n            prepareDirection(t[1]);\n            return true;\n        }\n        catch (e) {\n            return false;\n        }\n    }\n    return false;\n}\nfunction isDeep(t) {\n    return Array.isArray(t) && Array.isArray(t[0]);\n}\nfunction isMap(t) {\n    return t instanceof Map && t.size > 0;\n}\n/** @internal */\nfunction pairToMap(v) {\n    return new Map([[`${v[0]}`, prepareDirection([v[1]])]]);\n}\n/** @internal */\nfunction deepToMap(t) {\n    const sortEntries = t.map(([k, v]) => [`${k}`, prepareDirection(v)]);\n    return new Map(sortEntries);\n}\n/** @internal */\nfunction stringsToMap(t) {\n    const sortEntries = t.map(key => [`${key}`, 1]);\n    return new Map(sortEntries);\n}\n/** @internal */\nfunction objectToMap(t) {\n    const sortEntries = Object.entries(t).map(([k, v]) => [\n        `${k}`,\n        prepareDirection(v)\n    ]);\n    return new Map(sortEntries);\n}\n/** @internal */\nfunction mapToMap(t) {\n    const sortEntries = Array.from(t).map(([k, v]) => [\n        `${k}`,\n        prepareDirection(v)\n    ]);\n    return new Map(sortEntries);\n}\n/** converts a Sort type into a type that is valid for the server (SortForCmd) */\nfunction formatSort(sort, direction) {\n    if (sort == null)\n        return undefined;\n    if (typeof sort === 'string')\n        return new Map([[sort, prepareDirection(direction)]]);\n    if (typeof sort !== 'object') {\n        throw new error_1.MongoInvalidArgumentError(`Invalid sort format: ${JSON.stringify(sort)} Sort must be a valid object`);\n    }\n    if (!Array.isArray(sort)) {\n        return isMap(sort) ? mapToMap(sort) : Object.keys(sort).length ? objectToMap(sort) : undefined;\n    }\n    if (!sort.length)\n        return undefined;\n    if (isDeep(sort))\n        return deepToMap(sort);\n    if (isPair(sort))\n        return pairToMap(sort);\n    return stringsToMap(sort);\n}\nexports.formatSort = formatSort;\n//# sourceMappingURL=sort.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/sort.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/timeout.js":
/*!*********************************************!*\
  !*** ./node_modules/mongodb/lib/timeout.js ***!
  \*********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Timeout = exports.TimeoutError = void 0;\nconst timers_1 = __webpack_require__(/*! timers */ \"timers\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/mongodb/lib/utils.js\");\n/** @internal */\nclass TimeoutError extends Error {\n    get name() {\n        return 'TimeoutError';\n    }\n    constructor(message, options) {\n        super(message, options);\n    }\n    static is(error) {\n        return (error != null && typeof error === 'object' && 'name' in error && error.name === 'TimeoutError');\n    }\n}\nexports.TimeoutError = TimeoutError;\n/**\n * @internal\n * This class is an abstraction over timeouts\n * The Timeout class can only be in the pending or rejected states. It is guaranteed not to resolve\n * if interacted with exclusively through its public API\n * */\nclass Timeout extends Promise {\n    get [Symbol.toStringTag]() {\n        return 'MongoDBTimeout';\n    }\n    /** Create a new timeout that expires in `duration` ms */\n    constructor(executor = () => null, duration, unref = false) {\n        let reject;\n        if (duration < 0) {\n            throw new error_1.MongoInvalidArgumentError('Cannot create a Timeout with a negative duration');\n        }\n        super((_, promiseReject) => {\n            reject = promiseReject;\n            executor(utils_1.noop, promiseReject);\n        });\n        this.ended = null;\n        this.timedOut = false;\n        this.duration = duration;\n        this.start = Math.trunc(performance.now());\n        if (this.duration > 0) {\n            this.id = (0, timers_1.setTimeout)(() => {\n                this.ended = Math.trunc(performance.now());\n                this.timedOut = true;\n                reject(new TimeoutError(`Expired after ${duration}ms`));\n            }, this.duration);\n            if (typeof this.id.unref === 'function' && unref) {\n                // Ensure we do not keep the Node.js event loop running\n                this.id.unref();\n            }\n        }\n    }\n    /**\n     * Clears the underlying timeout. This method is idempotent\n     */\n    clear() {\n        (0, timers_1.clearTimeout)(this.id);\n        this.id = undefined;\n    }\n    static expires(durationMS, unref) {\n        return new Timeout(undefined, durationMS, unref);\n    }\n    static is(timeout) {\n        return (typeof timeout === 'object' &&\n            timeout != null &&\n            Symbol.toStringTag in timeout &&\n            timeout[Symbol.toStringTag] === 'MongoDBTimeout' &&\n            'then' in timeout &&\n            // eslint-disable-next-line github/no-then\n            typeof timeout.then === 'function');\n    }\n}\nexports.Timeout = Timeout;\n//# sourceMappingURL=timeout.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/timeout.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/transactions.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/transactions.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.isTransactionCommand = exports.Transaction = exports.TxnState = void 0;\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_concern_1 = __webpack_require__(/*! ./read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst read_preference_1 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst write_concern_1 = __webpack_require__(/*! ./write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\n/** @internal */\nexports.TxnState = Object.freeze({\n    NO_TRANSACTION: 'NO_TRANSACTION',\n    STARTING_TRANSACTION: 'STARTING_TRANSACTION',\n    TRANSACTION_IN_PROGRESS: 'TRANSACTION_IN_PROGRESS',\n    TRANSACTION_COMMITTED: 'TRANSACTION_COMMITTED',\n    TRANSACTION_COMMITTED_EMPTY: 'TRANSACTION_COMMITTED_EMPTY',\n    TRANSACTION_ABORTED: 'TRANSACTION_ABORTED'\n});\nconst stateMachine = {\n    [exports.TxnState.NO_TRANSACTION]: [exports.TxnState.NO_TRANSACTION, exports.TxnState.STARTING_TRANSACTION],\n    [exports.TxnState.STARTING_TRANSACTION]: [\n        exports.TxnState.TRANSACTION_IN_PROGRESS,\n        exports.TxnState.TRANSACTION_COMMITTED,\n        exports.TxnState.TRANSACTION_COMMITTED_EMPTY,\n        exports.TxnState.TRANSACTION_ABORTED\n    ],\n    [exports.TxnState.TRANSACTION_IN_PROGRESS]: [\n        exports.TxnState.TRANSACTION_IN_PROGRESS,\n        exports.TxnState.TRANSACTION_COMMITTED,\n        exports.TxnState.TRANSACTION_ABORTED\n    ],\n    [exports.TxnState.TRANSACTION_COMMITTED]: [\n        exports.TxnState.TRANSACTION_COMMITTED,\n        exports.TxnState.TRANSACTION_COMMITTED_EMPTY,\n        exports.TxnState.STARTING_TRANSACTION,\n        exports.TxnState.NO_TRANSACTION\n    ],\n    [exports.TxnState.TRANSACTION_ABORTED]: [exports.TxnState.STARTING_TRANSACTION, exports.TxnState.NO_TRANSACTION],\n    [exports.TxnState.TRANSACTION_COMMITTED_EMPTY]: [\n        exports.TxnState.TRANSACTION_COMMITTED_EMPTY,\n        exports.TxnState.NO_TRANSACTION\n    ]\n};\nconst ACTIVE_STATES = new Set([\n    exports.TxnState.STARTING_TRANSACTION,\n    exports.TxnState.TRANSACTION_IN_PROGRESS\n]);\nconst COMMITTED_STATES = new Set([\n    exports.TxnState.TRANSACTION_COMMITTED,\n    exports.TxnState.TRANSACTION_COMMITTED_EMPTY,\n    exports.TxnState.TRANSACTION_ABORTED\n]);\n/**\n * @public\n * A class maintaining state related to a server transaction. Internal Only\n */\nclass Transaction {\n    /** Create a transaction @internal */\n    constructor(options) {\n        options = options ?? {};\n        this.state = exports.TxnState.NO_TRANSACTION;\n        this.options = {};\n        const writeConcern = write_concern_1.WriteConcern.fromOptions(options);\n        if (writeConcern) {\n            if (writeConcern.w === 0) {\n                throw new error_1.MongoTransactionError('Transactions do not support unacknowledged write concern');\n            }\n            this.options.writeConcern = writeConcern;\n        }\n        if (options.readConcern) {\n            this.options.readConcern = read_concern_1.ReadConcern.fromOptions(options);\n        }\n        if (options.readPreference) {\n            this.options.readPreference = read_preference_1.ReadPreference.fromOptions(options);\n        }\n        if (options.maxCommitTimeMS) {\n            this.options.maxTimeMS = options.maxCommitTimeMS;\n        }\n        // TODO: This isn't technically necessary\n        this._pinnedServer = undefined;\n        this._recoveryToken = undefined;\n    }\n    /** @internal */\n    get server() {\n        return this._pinnedServer;\n    }\n    get recoveryToken() {\n        return this._recoveryToken;\n    }\n    get isPinned() {\n        return !!this.server;\n    }\n    /** @returns Whether the transaction has started */\n    get isStarting() {\n        return this.state === exports.TxnState.STARTING_TRANSACTION;\n    }\n    /**\n     * @returns Whether this session is presently in a transaction\n     */\n    get isActive() {\n        return ACTIVE_STATES.has(this.state);\n    }\n    get isCommitted() {\n        return COMMITTED_STATES.has(this.state);\n    }\n    /**\n     * Transition the transaction in the state machine\n     * @internal\n     * @param nextState - The new state to transition to\n     */\n    transition(nextState) {\n        const nextStates = stateMachine[this.state];\n        if (nextStates && nextStates.includes(nextState)) {\n            this.state = nextState;\n            if (this.state === exports.TxnState.NO_TRANSACTION ||\n                this.state === exports.TxnState.STARTING_TRANSACTION ||\n                this.state === exports.TxnState.TRANSACTION_ABORTED) {\n                this.unpinServer();\n            }\n            return;\n        }\n        throw new error_1.MongoRuntimeError(`Attempted illegal state transition from [${this.state}] to [${nextState}]`);\n    }\n    /** @internal */\n    pinServer(server) {\n        if (this.isActive) {\n            this._pinnedServer = server;\n        }\n    }\n    /** @internal */\n    unpinServer() {\n        this._pinnedServer = undefined;\n    }\n}\nexports.Transaction = Transaction;\nfunction isTransactionCommand(command) {\n    return !!(command.commitTransaction || command.abortTransaction);\n}\nexports.isTransactionCommand = isTransactionCommand;\n//# sourceMappingURL=transactions.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/transactions.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/utils.js":
/*!*******************************************!*\
  !*** ./node_modules/mongodb/lib/utils.js ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.COSMOS_DB_CHECK = exports.DOCUMENT_DB_CHECK = exports.request = exports.get = exports.matchesParentDomain = exports.parseUnsignedInteger = exports.parseInteger = exports.compareObjectId = exports.commandSupportsReadConcern = exports.shuffle = exports.supportsRetryableWrites = exports.enumToString = exports.emitWarningOnce = exports.emitWarning = exports.MONGODB_WARNING_CODE = exports.DEFAULT_PK_FACTORY = exports.HostAddress = exports.BufferPool = exports.List = exports.deepCopy = exports.isRecord = exports.setDifference = exports.isHello = exports.isSuperset = exports.resolveOptions = exports.hasAtomicOperators = exports.calculateDurationInMs = exports.now = exports.makeStateMachine = exports.errorStrictEqual = exports.arrayStrictEqual = exports.maxWireVersion = exports.uuidV4 = exports.makeCounter = exports.MongoDBCollectionNamespace = exports.MongoDBNamespace = exports.ns = exports.getTopology = exports.decorateWithExplain = exports.decorateWithReadConcern = exports.decorateWithCollation = exports.isPromiseLike = exports.applyRetryableWrites = exports.filterOptions = exports.mergeOptions = exports.isObject = exports.normalizeHintField = exports.hostMatchesWildcards = exports.isUint8Array = exports.ByteUtils = void 0;\nexports.noop = exports.fileIsAccessible = exports.maybeAddIdToDocuments = exports.once = exports.randomBytes = exports.squashError = exports.promiseWithResolvers = exports.isHostMatch = exports.COSMOS_DB_MSG = exports.DOCUMENT_DB_MSG = void 0;\nconst crypto = __webpack_require__(/*! crypto */ \"crypto\");\nconst fs_1 = __webpack_require__(/*! fs */ \"fs\");\nconst http = __webpack_require__(/*! http */ \"http\");\nconst timers_1 = __webpack_require__(/*! timers */ \"timers\");\nconst url = __webpack_require__(/*! url */ \"url\");\nconst url_1 = __webpack_require__(/*! url */ \"url\");\nconst util_1 = __webpack_require__(/*! util */ \"util\");\nconst bson_1 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst constants_1 = __webpack_require__(/*! ./cmap/wire_protocol/constants */ \"./node_modules/mongodb/lib/cmap/wire_protocol/constants.js\");\nconst constants_2 = __webpack_require__(/*! ./constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_concern_1 = __webpack_require__(/*! ./read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst read_preference_1 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst common_1 = __webpack_require__(/*! ./sdam/common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst write_concern_1 = __webpack_require__(/*! ./write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\nexports.ByteUtils = {\n    toLocalBufferType(buffer) {\n        return Buffer.isBuffer(buffer)\n            ? buffer\n            : Buffer.from(buffer.buffer, buffer.byteOffset, buffer.byteLength);\n    },\n    equals(seqA, seqB) {\n        return exports.ByteUtils.toLocalBufferType(seqA).equals(seqB);\n    },\n    compare(seqA, seqB) {\n        return exports.ByteUtils.toLocalBufferType(seqA).compare(seqB);\n    },\n    toBase64(uint8array) {\n        return exports.ByteUtils.toLocalBufferType(uint8array).toString('base64');\n    }\n};\n/**\n * Returns true if value is a Uint8Array or a Buffer\n * @param value - any value that may be a Uint8Array\n */\nfunction isUint8Array(value) {\n    return (value != null &&\n        typeof value === 'object' &&\n        Symbol.toStringTag in value &&\n        value[Symbol.toStringTag] === 'Uint8Array');\n}\nexports.isUint8Array = isUint8Array;\n/**\n * Determines if a connection's address matches a user provided list\n * of domain wildcards.\n */\nfunction hostMatchesWildcards(host, wildcards) {\n    for (const wildcard of wildcards) {\n        if (host === wildcard ||\n            (wildcard.startsWith('*.') && host?.endsWith(wildcard.substring(2, wildcard.length))) ||\n            (wildcard.startsWith('*/') && host?.endsWith(wildcard.substring(2, wildcard.length)))) {\n            return true;\n        }\n    }\n    return false;\n}\nexports.hostMatchesWildcards = hostMatchesWildcards;\n/**\n * Ensure Hint field is in a shape we expect:\n * - object of index names mapping to 1 or -1\n * - just an index name\n * @internal\n */\nfunction normalizeHintField(hint) {\n    let finalHint = undefined;\n    if (typeof hint === 'string') {\n        finalHint = hint;\n    }\n    else if (Array.isArray(hint)) {\n        finalHint = {};\n        hint.forEach(param => {\n            finalHint[param] = 1;\n        });\n    }\n    else if (hint != null && typeof hint === 'object') {\n        finalHint = {};\n        for (const name in hint) {\n            finalHint[name] = hint[name];\n        }\n    }\n    return finalHint;\n}\nexports.normalizeHintField = normalizeHintField;\nconst TO_STRING = (object) => Object.prototype.toString.call(object);\n/**\n * Checks if arg is an Object:\n * - **NOTE**: the check is based on the `[Symbol.toStringTag]() === 'Object'`\n * @internal\n */\nfunction isObject(arg) {\n    return '[object Object]' === TO_STRING(arg);\n}\nexports.isObject = isObject;\n/** @internal */\nfunction mergeOptions(target, source) {\n    return { ...target, ...source };\n}\nexports.mergeOptions = mergeOptions;\n/** @internal */\nfunction filterOptions(options, names) {\n    const filterOptions = {};\n    for (const name in options) {\n        if (names.includes(name)) {\n            filterOptions[name] = options[name];\n        }\n    }\n    // Filtered options\n    return filterOptions;\n}\nexports.filterOptions = filterOptions;\n/**\n * Applies retryWrites: true to a command if retryWrites is set on the command's database.\n * @internal\n *\n * @param target - The target command to which we will apply retryWrites.\n * @param db - The database from which we can inherit a retryWrites value.\n */\nfunction applyRetryableWrites(target, db) {\n    if (db && db.s.options?.retryWrites) {\n        target.retryWrites = true;\n    }\n    return target;\n}\nexports.applyRetryableWrites = applyRetryableWrites;\n/**\n * Applies a write concern to a command based on well defined inheritance rules, optionally\n * detecting support for the write concern in the first place.\n * @internal\n *\n * @param target - the target command we will be applying the write concern to\n * @param sources - sources where we can inherit default write concerns from\n * @param options - optional settings passed into a command for write concern overrides\n */\n/**\n * Checks if a given value is a Promise\n *\n * @typeParam T - The resolution type of the possible promise\n * @param value - An object that could be a promise\n * @returns true if the provided value is a Promise\n */\nfunction isPromiseLike(value) {\n    return (value != null &&\n        typeof value === 'object' &&\n        'then' in value &&\n        // eslint-disable-next-line github/no-then\n        typeof value.then === 'function');\n}\nexports.isPromiseLike = isPromiseLike;\n/**\n * Applies collation to a given command.\n * @internal\n *\n * @param command - the command on which to apply collation\n * @param target - target of command\n * @param options - options containing collation settings\n */\nfunction decorateWithCollation(command, target, options) {\n    const capabilities = getTopology(target).capabilities;\n    if (options.collation && typeof options.collation === 'object') {\n        if (capabilities && capabilities.commandsTakeCollation) {\n            command.collation = options.collation;\n        }\n        else {\n            throw new error_1.MongoCompatibilityError(`Current topology does not support collation`);\n        }\n    }\n}\nexports.decorateWithCollation = decorateWithCollation;\n/**\n * Applies a read concern to a given command.\n * @internal\n *\n * @param command - the command on which to apply the read concern\n * @param coll - the parent collection of the operation calling this method\n */\nfunction decorateWithReadConcern(command, coll, options) {\n    if (options && options.session && options.session.inTransaction()) {\n        return;\n    }\n    const readConcern = Object.assign({}, command.readConcern || {});\n    if (coll.s.readConcern) {\n        Object.assign(readConcern, coll.s.readConcern);\n    }\n    if (Object.keys(readConcern).length > 0) {\n        Object.assign(command, { readConcern: readConcern });\n    }\n}\nexports.decorateWithReadConcern = decorateWithReadConcern;\n/**\n * Applies an explain to a given command.\n * @internal\n *\n * @param command - the command on which to apply the explain\n * @param options - the options containing the explain verbosity\n */\nfunction decorateWithExplain(command, explain) {\n    if (command.explain) {\n        return command;\n    }\n    return { explain: command, verbosity: explain.verbosity };\n}\nexports.decorateWithExplain = decorateWithExplain;\n/**\n * A helper function to get the topology from a given provider. Throws\n * if the topology cannot be found.\n * @throws MongoNotConnectedError\n * @internal\n */\nfunction getTopology(provider) {\n    // MongoClient or ClientSession or AbstractCursor\n    if ('topology' in provider && provider.topology) {\n        return provider.topology;\n    }\n    else if ('client' in provider && provider.client.topology) {\n        return provider.client.topology;\n    }\n    throw new error_1.MongoNotConnectedError('MongoClient must be connected to perform this operation');\n}\nexports.getTopology = getTopology;\n/** @internal */\nfunction ns(ns) {\n    return MongoDBNamespace.fromString(ns);\n}\nexports.ns = ns;\n/** @public */\nclass MongoDBNamespace {\n    /**\n     * Create a namespace object\n     *\n     * @param db - database name\n     * @param collection - collection name\n     */\n    constructor(db, collection) {\n        this.db = db;\n        this.collection = collection;\n        this.collection = collection === '' ? undefined : collection;\n    }\n    toString() {\n        return this.collection ? `${this.db}.${this.collection}` : this.db;\n    }\n    withCollection(collection) {\n        return new MongoDBCollectionNamespace(this.db, collection);\n    }\n    static fromString(namespace) {\n        if (typeof namespace !== 'string' || namespace === '') {\n            // TODO(NODE-3483): Replace with MongoNamespaceError\n            throw new error_1.MongoRuntimeError(`Cannot parse namespace from \"${namespace}\"`);\n        }\n        const [db, ...collectionParts] = namespace.split('.');\n        const collection = collectionParts.join('.');\n        return new MongoDBNamespace(db, collection === '' ? undefined : collection);\n    }\n}\nexports.MongoDBNamespace = MongoDBNamespace;\n/**\n * @public\n *\n * A class representing a collection's namespace.  This class enforces (through Typescript) that\n * the `collection` portion of the namespace is defined and should only be\n * used in scenarios where this can be guaranteed.\n */\nclass MongoDBCollectionNamespace extends MongoDBNamespace {\n    constructor(db, collection) {\n        super(db, collection);\n        this.collection = collection;\n    }\n    static fromString(namespace) {\n        return super.fromString(namespace);\n    }\n}\nexports.MongoDBCollectionNamespace = MongoDBCollectionNamespace;\n/** @internal */\nfunction* makeCounter(seed = 0) {\n    let count = seed;\n    while (true) {\n        const newCount = count;\n        count += 1;\n        yield newCount;\n    }\n}\nexports.makeCounter = makeCounter;\n/**\n * Synchronously Generate a UUIDv4\n * @internal\n */\nfunction uuidV4() {\n    const result = crypto.randomBytes(16);\n    result[6] = (result[6] & 0x0f) | 0x40;\n    result[8] = (result[8] & 0x3f) | 0x80;\n    return result;\n}\nexports.uuidV4 = uuidV4;\n/**\n * A helper function for determining `maxWireVersion` between legacy and new topology instances\n * @internal\n */\nfunction maxWireVersion(topologyOrServer) {\n    if (topologyOrServer) {\n        if (topologyOrServer.loadBalanced || topologyOrServer.serverApi?.version) {\n            // Since we do not have a monitor in the load balanced mode,\n            // we assume the load-balanced server is always pointed at the latest mongodb version.\n            // There is a risk that for on-prem deployments\n            // that don't upgrade immediately that this could alert to the\n            // application that a feature is available that is actually not.\n            // We also return the max supported wire version for serverAPI.\n            return constants_1.MAX_SUPPORTED_WIRE_VERSION;\n        }\n        if (topologyOrServer.hello) {\n            return topologyOrServer.hello.maxWireVersion;\n        }\n        if ('lastHello' in topologyOrServer && typeof topologyOrServer.lastHello === 'function') {\n            const lastHello = topologyOrServer.lastHello();\n            if (lastHello) {\n                return lastHello.maxWireVersion;\n            }\n        }\n        if (topologyOrServer.description &&\n            'maxWireVersion' in topologyOrServer.description &&\n            topologyOrServer.description.maxWireVersion != null) {\n            return topologyOrServer.description.maxWireVersion;\n        }\n    }\n    return 0;\n}\nexports.maxWireVersion = maxWireVersion;\n/** @internal */\nfunction arrayStrictEqual(arr, arr2) {\n    if (!Array.isArray(arr) || !Array.isArray(arr2)) {\n        return false;\n    }\n    return arr.length === arr2.length && arr.every((elt, idx) => elt === arr2[idx]);\n}\nexports.arrayStrictEqual = arrayStrictEqual;\n/** @internal */\nfunction errorStrictEqual(lhs, rhs) {\n    if (lhs === rhs) {\n        return true;\n    }\n    if (!lhs || !rhs) {\n        return lhs === rhs;\n    }\n    if ((lhs == null && rhs != null) || (lhs != null && rhs == null)) {\n        return false;\n    }\n    if (lhs.constructor.name !== rhs.constructor.name) {\n        return false;\n    }\n    if (lhs.message !== rhs.message) {\n        return false;\n    }\n    return true;\n}\nexports.errorStrictEqual = errorStrictEqual;\n/** @internal */\nfunction makeStateMachine(stateTable) {\n    return function stateTransition(target, newState) {\n        const legalStates = stateTable[target.s.state];\n        if (legalStates && legalStates.indexOf(newState) < 0) {\n            throw new error_1.MongoRuntimeError(`illegal state transition from [${target.s.state}] => [${newState}], allowed: [${legalStates}]`);\n        }\n        target.emit('stateChanged', target.s.state, newState);\n        target.s.state = newState;\n    };\n}\nexports.makeStateMachine = makeStateMachine;\n/** @internal */\nfunction now() {\n    const hrtime = process.hrtime();\n    return Math.floor(hrtime[0] * 1000 + hrtime[1] / 1000000);\n}\nexports.now = now;\n/** @internal */\nfunction calculateDurationInMs(started) {\n    if (typeof started !== 'number') {\n        return -1;\n    }\n    const elapsed = now() - started;\n    return elapsed < 0 ? 0 : elapsed;\n}\nexports.calculateDurationInMs = calculateDurationInMs;\n/** @internal */\nfunction hasAtomicOperators(doc) {\n    if (Array.isArray(doc)) {\n        for (const document of doc) {\n            if (hasAtomicOperators(document)) {\n                return true;\n            }\n        }\n        return false;\n    }\n    const keys = Object.keys(doc);\n    return keys.length > 0 && keys[0][0] === '$';\n}\nexports.hasAtomicOperators = hasAtomicOperators;\n/**\n * Merge inherited properties from parent into options, prioritizing values from options,\n * then values from parent.\n * @internal\n */\nfunction resolveOptions(parent, options) {\n    const result = Object.assign({}, options, (0, bson_1.resolveBSONOptions)(options, parent));\n    // Users cannot pass a readConcern/writeConcern to operations in a transaction\n    const session = options?.session;\n    if (!session?.inTransaction()) {\n        const readConcern = read_concern_1.ReadConcern.fromOptions(options) ?? parent?.readConcern;\n        if (readConcern) {\n            result.readConcern = readConcern;\n        }\n        const writeConcern = write_concern_1.WriteConcern.fromOptions(options) ?? parent?.writeConcern;\n        if (writeConcern) {\n            result.writeConcern = writeConcern;\n        }\n    }\n    const readPreference = read_preference_1.ReadPreference.fromOptions(options) ?? parent?.readPreference;\n    if (readPreference) {\n        result.readPreference = readPreference;\n    }\n    return result;\n}\nexports.resolveOptions = resolveOptions;\nfunction isSuperset(set, subset) {\n    set = Array.isArray(set) ? new Set(set) : set;\n    subset = Array.isArray(subset) ? new Set(subset) : subset;\n    for (const elem of subset) {\n        if (!set.has(elem)) {\n            return false;\n        }\n    }\n    return true;\n}\nexports.isSuperset = isSuperset;\n/**\n * Checks if the document is a Hello request\n * @internal\n */\nfunction isHello(doc) {\n    return doc[constants_2.LEGACY_HELLO_COMMAND] || doc.hello ? true : false;\n}\nexports.isHello = isHello;\n/** Returns the items that are uniquely in setA */\nfunction setDifference(setA, setB) {\n    const difference = new Set(setA);\n    for (const elem of setB) {\n        difference.delete(elem);\n    }\n    return difference;\n}\nexports.setDifference = setDifference;\nconst HAS_OWN = (object, prop) => Object.prototype.hasOwnProperty.call(object, prop);\nfunction isRecord(value, requiredKeys = undefined) {\n    if (!isObject(value)) {\n        return false;\n    }\n    const ctor = value.constructor;\n    if (ctor && ctor.prototype) {\n        if (!isObject(ctor.prototype)) {\n            return false;\n        }\n        // Check to see if some method exists from the Object exists\n        if (!HAS_OWN(ctor.prototype, 'isPrototypeOf')) {\n            return false;\n        }\n    }\n    if (requiredKeys) {\n        const keys = Object.keys(value);\n        return isSuperset(keys, requiredKeys);\n    }\n    return true;\n}\nexports.isRecord = isRecord;\n/**\n * Make a deep copy of an object\n *\n * NOTE: This is not meant to be the perfect implementation of a deep copy,\n * but instead something that is good enough for the purposes of\n * command monitoring.\n */\nfunction deepCopy(value) {\n    if (value == null) {\n        return value;\n    }\n    else if (Array.isArray(value)) {\n        return value.map(item => deepCopy(item));\n    }\n    else if (isRecord(value)) {\n        const res = {};\n        for (const key in value) {\n            res[key] = deepCopy(value[key]);\n        }\n        return res;\n    }\n    const ctor = value.constructor;\n    if (ctor) {\n        switch (ctor.name.toLowerCase()) {\n            case 'date':\n                return new ctor(Number(value));\n            case 'map':\n                return new Map(value);\n            case 'set':\n                return new Set(value);\n            case 'buffer':\n                return Buffer.from(value);\n        }\n    }\n    return value;\n}\nexports.deepCopy = deepCopy;\n/**\n * A sequential list of items in a circularly linked list\n * @remarks\n * The head node is special, it is always defined and has a value of null.\n * It is never \"included\" in the list, in that, it is not returned by pop/shift or yielded by the iterator.\n * The circular linkage and always defined head node are to reduce checks for null next/prev references to zero.\n * New nodes are declared as object literals with keys always in the same order: next, prev, value.\n * @internal\n */\nclass List {\n    get length() {\n        return this.count;\n    }\n    get [Symbol.toStringTag]() {\n        return 'List';\n    }\n    constructor() {\n        this.count = 0;\n        // this is carefully crafted:\n        // declaring a complete and consistently key ordered\n        // object is beneficial to the runtime optimizations\n        this.head = {\n            next: null,\n            prev: null,\n            value: null\n        };\n        this.head.next = this.head;\n        this.head.prev = this.head;\n    }\n    toArray() {\n        return Array.from(this);\n    }\n    toString() {\n        return `head <=> ${this.toArray().join(' <=> ')} <=> head`;\n    }\n    *[Symbol.iterator]() {\n        for (const node of this.nodes()) {\n            yield node.value;\n        }\n    }\n    *nodes() {\n        let ptr = this.head.next;\n        while (ptr !== this.head) {\n            // Save next before yielding so that we make removing within iteration safe\n            const { next } = ptr;\n            yield ptr;\n            ptr = next;\n        }\n    }\n    /** Insert at end of list */\n    push(value) {\n        this.count += 1;\n        const newNode = {\n            next: this.head,\n            prev: this.head.prev,\n            value\n        };\n        this.head.prev.next = newNode;\n        this.head.prev = newNode;\n    }\n    /** Inserts every item inside an iterable instead of the iterable itself */\n    pushMany(iterable) {\n        for (const value of iterable) {\n            this.push(value);\n        }\n    }\n    /** Insert at front of list */\n    unshift(value) {\n        this.count += 1;\n        const newNode = {\n            next: this.head.next,\n            prev: this.head,\n            value\n        };\n        this.head.next.prev = newNode;\n        this.head.next = newNode;\n    }\n    remove(node) {\n        if (node === this.head || this.length === 0) {\n            return null;\n        }\n        this.count -= 1;\n        const prevNode = node.prev;\n        const nextNode = node.next;\n        prevNode.next = nextNode;\n        nextNode.prev = prevNode;\n        return node.value;\n    }\n    /** Removes the first node at the front of the list */\n    shift() {\n        return this.remove(this.head.next);\n    }\n    /** Removes the last node at the end of the list */\n    pop() {\n        return this.remove(this.head.prev);\n    }\n    /** Iterates through the list and removes nodes where filter returns true */\n    prune(filter) {\n        for (const node of this.nodes()) {\n            if (filter(node.value)) {\n                this.remove(node);\n            }\n        }\n    }\n    clear() {\n        this.count = 0;\n        this.head.next = this.head;\n        this.head.prev = this.head;\n    }\n    /** Returns the first item in the list, does not remove */\n    first() {\n        // If the list is empty, value will be the head's null\n        return this.head.next.value;\n    }\n    /** Returns the last item in the list, does not remove */\n    last() {\n        // If the list is empty, value will be the head's null\n        return this.head.prev.value;\n    }\n}\nexports.List = List;\n/**\n * A pool of Buffers which allow you to read them as if they were one\n * @internal\n */\nclass BufferPool {\n    constructor() {\n        this.buffers = new List();\n        this.totalByteLength = 0;\n    }\n    get length() {\n        return this.totalByteLength;\n    }\n    /** Adds a buffer to the internal buffer pool list */\n    append(buffer) {\n        this.buffers.push(buffer);\n        this.totalByteLength += buffer.length;\n    }\n    /**\n     * If BufferPool contains 4 bytes or more construct an int32 from the leading bytes,\n     * otherwise return null. Size can be negative, caller should error check.\n     */\n    getInt32() {\n        if (this.totalByteLength < 4) {\n            return null;\n        }\n        const firstBuffer = this.buffers.first();\n        if (firstBuffer != null && firstBuffer.byteLength >= 4) {\n            return firstBuffer.readInt32LE(0);\n        }\n        // Unlikely case: an int32 is split across buffers.\n        // Use read and put the returned buffer back on top\n        const top4Bytes = this.read(4);\n        const value = top4Bytes.readInt32LE(0);\n        // Put it back.\n        this.totalByteLength += 4;\n        this.buffers.unshift(top4Bytes);\n        return value;\n    }\n    /** Reads the requested number of bytes, optionally consuming them */\n    read(size) {\n        if (typeof size !== 'number' || size < 0) {\n            throw new error_1.MongoInvalidArgumentError('Argument \"size\" must be a non-negative number');\n        }\n        // oversized request returns empty buffer\n        if (size > this.totalByteLength) {\n            return Buffer.alloc(0);\n        }\n        // We know we have enough, we just don't know how it is spread across chunks\n        // TODO(NODE-4732): alloc API should change based on raw option\n        const result = Buffer.allocUnsafe(size);\n        for (let bytesRead = 0; bytesRead < size;) {\n            const buffer = this.buffers.shift();\n            if (buffer == null) {\n                break;\n            }\n            const bytesRemaining = size - bytesRead;\n            const bytesReadable = Math.min(bytesRemaining, buffer.byteLength);\n            const bytes = buffer.subarray(0, bytesReadable);\n            result.set(bytes, bytesRead);\n            bytesRead += bytesReadable;\n            this.totalByteLength -= bytesReadable;\n            if (bytesReadable < buffer.byteLength) {\n                this.buffers.unshift(buffer.subarray(bytesReadable));\n            }\n        }\n        return result;\n    }\n}\nexports.BufferPool = BufferPool;\n/** @public */\nclass HostAddress {\n    constructor(hostString) {\n        this.host = undefined;\n        this.port = undefined;\n        this.socketPath = undefined;\n        this.isIPv6 = false;\n        const escapedHost = hostString.split(' ').join('%20'); // escape spaces, for socket path hosts\n        if (escapedHost.endsWith('.sock')) {\n            // heuristically determine if we're working with a domain socket\n            this.socketPath = decodeURIComponent(escapedHost);\n            return;\n        }\n        const urlString = `iLoveJS://${escapedHost}`;\n        let url;\n        try {\n            url = new url_1.URL(urlString);\n        }\n        catch (urlError) {\n            const runtimeError = new error_1.MongoRuntimeError(`Unable to parse ${escapedHost} with URL`);\n            runtimeError.cause = urlError;\n            throw runtimeError;\n        }\n        const hostname = url.hostname;\n        const port = url.port;\n        let normalized = decodeURIComponent(hostname).toLowerCase();\n        if (normalized.startsWith('[') && normalized.endsWith(']')) {\n            this.isIPv6 = true;\n            normalized = normalized.substring(1, hostname.length - 1);\n        }\n        this.host = normalized.toLowerCase();\n        if (typeof port === 'number') {\n            this.port = port;\n        }\n        else if (typeof port === 'string' && port !== '') {\n            this.port = Number.parseInt(port, 10);\n        }\n        else {\n            this.port = 27017;\n        }\n        if (this.port === 0) {\n            throw new error_1.MongoParseError('Invalid port (zero) with hostname');\n        }\n        Object.freeze(this);\n    }\n    [Symbol.for('nodejs.util.inspect.custom')]() {\n        return this.inspect();\n    }\n    inspect() {\n        return `new HostAddress('${this.toString()}')`;\n    }\n    toString() {\n        if (typeof this.host === 'string') {\n            if (this.isIPv6) {\n                return `[${this.host}]:${this.port}`;\n            }\n            return `${this.host}:${this.port}`;\n        }\n        return `${this.socketPath}`;\n    }\n    static fromString(s) {\n        return new HostAddress(s);\n    }\n    static fromHostPort(host, port) {\n        if (host.includes(':')) {\n            host = `[${host}]`; // IPv6 address\n        }\n        return HostAddress.fromString(`${host}:${port}`);\n    }\n    static fromSrvRecord({ name, port }) {\n        return HostAddress.fromHostPort(name, port);\n    }\n    toHostPort() {\n        if (this.socketPath) {\n            return { host: this.socketPath, port: 0 };\n        }\n        const host = this.host ?? '';\n        const port = this.port ?? 0;\n        return { host, port };\n    }\n}\nexports.HostAddress = HostAddress;\nexports.DEFAULT_PK_FACTORY = {\n    // We prefer not to rely on ObjectId having a createPk method\n    createPk() {\n        return new bson_1.ObjectId();\n    }\n};\n/**\n * When the driver used emitWarning the code will be equal to this.\n * @public\n *\n * @example\n * ```ts\n * process.on('warning', (warning) => {\n *  if (warning.code === MONGODB_WARNING_CODE) console.error('Ah an important warning! :)')\n * })\n * ```\n */\nexports.MONGODB_WARNING_CODE = 'MONGODB DRIVER';\n/** @internal */\nfunction emitWarning(message) {\n    return process.emitWarning(message, { code: exports.MONGODB_WARNING_CODE });\n}\nexports.emitWarning = emitWarning;\nconst emittedWarnings = new Set();\n/**\n * Will emit a warning once for the duration of the application.\n * Uses the message to identify if it has already been emitted\n * so using string interpolation can cause multiple emits\n * @internal\n */\nfunction emitWarningOnce(message) {\n    if (!emittedWarnings.has(message)) {\n        emittedWarnings.add(message);\n        return emitWarning(message);\n    }\n}\nexports.emitWarningOnce = emitWarningOnce;\n/**\n * Takes a JS object and joins the values into a string separated by ', '\n */\nfunction enumToString(en) {\n    return Object.values(en).join(', ');\n}\nexports.enumToString = enumToString;\n/**\n * Determine if a server supports retryable writes.\n *\n * @internal\n */\nfunction supportsRetryableWrites(server) {\n    if (!server) {\n        return false;\n    }\n    if (server.loadBalanced) {\n        // Loadbalanced topologies will always support retry writes\n        return true;\n    }\n    if (server.description.logicalSessionTimeoutMinutes != null) {\n        // that supports sessions\n        if (server.description.type !== common_1.ServerType.Standalone) {\n            // and that is not a standalone\n            return true;\n        }\n    }\n    return false;\n}\nexports.supportsRetryableWrites = supportsRetryableWrites;\n/**\n * FisherYates Shuffle\n *\n * Reference: https://bost.ocks.org/mike/shuffle/\n * @param sequence - items to be shuffled\n * @param limit - Defaults to `0`. If nonzero shuffle will slice the randomized array e.g, `.slice(0, limit)` otherwise will return the entire randomized array.\n */\nfunction shuffle(sequence, limit = 0) {\n    const items = Array.from(sequence); // shallow copy in order to never shuffle the input\n    if (limit > items.length) {\n        throw new error_1.MongoRuntimeError('Limit must be less than the number of items');\n    }\n    let remainingItemsToShuffle = items.length;\n    const lowerBound = limit % items.length === 0 ? 1 : items.length - limit;\n    while (remainingItemsToShuffle > lowerBound) {\n        // Pick a remaining element\n        const randomIndex = Math.floor(Math.random() * remainingItemsToShuffle);\n        remainingItemsToShuffle -= 1;\n        // And swap it with the current element\n        const swapHold = items[remainingItemsToShuffle];\n        items[remainingItemsToShuffle] = items[randomIndex];\n        items[randomIndex] = swapHold;\n    }\n    return limit % items.length === 0 ? items : items.slice(lowerBound);\n}\nexports.shuffle = shuffle;\n// TODO(NODE-4936): read concern eligibility for commands should be codified in command construction\n// @see https://github.com/mongodb/specifications/blob/master/source/read-write-concern/read-write-concern.rst#read-concern\nfunction commandSupportsReadConcern(command) {\n    if (command.aggregate || command.count || command.distinct || command.find || command.geoNear) {\n        return true;\n    }\n    return false;\n}\nexports.commandSupportsReadConcern = commandSupportsReadConcern;\n/**\n * Compare objectIds. `null` is always less\n * - `+1 = oid1 is greater than oid2`\n * - `-1 = oid1 is less than oid2`\n * - `+0 = oid1 is equal oid2`\n */\nfunction compareObjectId(oid1, oid2) {\n    if (oid1 == null && oid2 == null) {\n        return 0;\n    }\n    if (oid1 == null) {\n        return -1;\n    }\n    if (oid2 == null) {\n        return 1;\n    }\n    return exports.ByteUtils.compare(oid1.id, oid2.id);\n}\nexports.compareObjectId = compareObjectId;\nfunction parseInteger(value) {\n    if (typeof value === 'number')\n        return Math.trunc(value);\n    const parsedValue = Number.parseInt(String(value), 10);\n    return Number.isNaN(parsedValue) ? null : parsedValue;\n}\nexports.parseInteger = parseInteger;\nfunction parseUnsignedInteger(value) {\n    const parsedInt = parseInteger(value);\n    return parsedInt != null && parsedInt >= 0 ? parsedInt : null;\n}\nexports.parseUnsignedInteger = parseUnsignedInteger;\n/**\n * Determines whether a provided address matches the provided parent domain.\n *\n * If a DNS server were to become compromised SRV records would still need to\n * advertise addresses that are under the same domain as the srvHost.\n *\n * @param address - The address to check against a domain\n * @param srvHost - The domain to check the provided address against\n * @returns Whether the provided address matches the parent domain\n */\nfunction matchesParentDomain(address, srvHost) {\n    // Remove trailing dot if exists on either the resolved address or the srv hostname\n    const normalizedAddress = address.endsWith('.') ? address.slice(0, address.length - 1) : address;\n    const normalizedSrvHost = srvHost.endsWith('.') ? srvHost.slice(0, srvHost.length - 1) : srvHost;\n    const allCharacterBeforeFirstDot = /^.*?\\./;\n    // Remove all characters before first dot\n    // Add leading dot back to string so\n    //   an srvHostDomain = '.trusted.site'\n    //   will not satisfy an addressDomain that endsWith '.fake-trusted.site'\n    const addressDomain = `.${normalizedAddress.replace(allCharacterBeforeFirstDot, '')}`;\n    const srvHostDomain = `.${normalizedSrvHost.replace(allCharacterBeforeFirstDot, '')}`;\n    return addressDomain.endsWith(srvHostDomain);\n}\nexports.matchesParentDomain = matchesParentDomain;\n/**\n * Perform a get request that returns status and body.\n * @internal\n */\nfunction get(url, options = {}) {\n    return new Promise((resolve, reject) => {\n        /* eslint-disable prefer-const */\n        let timeoutId;\n        const request = http\n            .get(url, options, response => {\n            response.setEncoding('utf8');\n            let body = '';\n            response.on('data', chunk => (body += chunk));\n            response.on('end', () => {\n                (0, timers_1.clearTimeout)(timeoutId);\n                resolve({ status: response.statusCode, body });\n            });\n        })\n            .on('error', error => {\n            (0, timers_1.clearTimeout)(timeoutId);\n            reject(error);\n        })\n            .end();\n        timeoutId = (0, timers_1.setTimeout)(() => {\n            request.destroy(new error_1.MongoNetworkTimeoutError(`request timed out after 10 seconds`));\n        }, 10000);\n    });\n}\nexports.get = get;\nasync function request(uri, options = {}) {\n    return await new Promise((resolve, reject) => {\n        const requestOptions = {\n            method: 'GET',\n            timeout: 10000,\n            json: true,\n            ...url.parse(uri),\n            ...options\n        };\n        const req = http.request(requestOptions, res => {\n            res.setEncoding('utf8');\n            let data = '';\n            res.on('data', d => {\n                data += d;\n            });\n            res.once('end', () => {\n                if (options.json === false) {\n                    resolve(data);\n                    return;\n                }\n                try {\n                    const parsed = JSON.parse(data);\n                    resolve(parsed);\n                }\n                catch {\n                    // TODO(NODE-3483)\n                    reject(new error_1.MongoRuntimeError(`Invalid JSON response: \"${data}\"`));\n                }\n            });\n        });\n        req.once('timeout', () => req.destroy(new error_1.MongoNetworkTimeoutError(`Network request to ${uri} timed out after ${options.timeout} ms`)));\n        req.once('error', error => reject(error));\n        req.end();\n    });\n}\nexports.request = request;\n/** @internal */\nexports.DOCUMENT_DB_CHECK = /(\\.docdb\\.amazonaws\\.com$)|(\\.docdb-elastic\\.amazonaws\\.com$)/;\n/** @internal */\nexports.COSMOS_DB_CHECK = /\\.cosmos\\.azure\\.com$/;\n/** @internal */\nexports.DOCUMENT_DB_MSG = 'You appear to be connected to a DocumentDB cluster. For more information regarding feature compatibility and support please visit https://www.mongodb.com/supportability/documentdb';\n/** @internal */\nexports.COSMOS_DB_MSG = 'You appear to be connected to a CosmosDB cluster. For more information regarding feature compatibility and support please visit https://www.mongodb.com/supportability/cosmosdb';\n/** @internal */\nfunction isHostMatch(match, host) {\n    return host && match.test(host.toLowerCase()) ? true : false;\n}\nexports.isHostMatch = isHostMatch;\nfunction promiseWithResolvers() {\n    let resolve;\n    let reject;\n    const promise = new Promise(function withResolversExecutor(promiseResolve, promiseReject) {\n        resolve = promiseResolve;\n        reject = promiseReject;\n    });\n    return { promise, resolve, reject };\n}\nexports.promiseWithResolvers = promiseWithResolvers;\n/**\n * A noop function intended for use in preventing unhandled rejections.\n *\n * @example\n * ```js\n * const promise = myAsyncTask();\n * // eslint-disable-next-line github/no-then\n * promise.then(undefined, squashError);\n * ```\n */\nfunction squashError(_error) {\n    return;\n}\nexports.squashError = squashError;\nexports.randomBytes = (0, util_1.promisify)(crypto.randomBytes);\n/**\n * Replicates the events.once helper.\n *\n * Removes unused signal logic and It **only** supports 0 or 1 argument events.\n *\n * @param ee - An event emitter that may emit `ev`\n * @param name - An event name to wait for\n */\nasync function once(ee, name) {\n    const { promise, resolve, reject } = promiseWithResolvers();\n    const onEvent = (data) => resolve(data);\n    const onError = (error) => reject(error);\n    ee.once(name, onEvent).once('error', onError);\n    try {\n        const res = await promise;\n        ee.off('error', onError);\n        return res;\n    }\n    catch (error) {\n        ee.off(name, onEvent);\n        throw error;\n    }\n}\nexports.once = once;\nfunction maybeAddIdToDocuments(coll, docOrDocs, options) {\n    const forceServerObjectId = typeof options.forceServerObjectId === 'boolean'\n        ? options.forceServerObjectId\n        : coll.s.db.options?.forceServerObjectId;\n    // no need to modify the docs if server sets the ObjectId\n    if (forceServerObjectId === true) {\n        return docOrDocs;\n    }\n    const transform = (doc) => {\n        if (doc._id == null) {\n            doc._id = coll.s.pkFactory.createPk();\n        }\n        return doc;\n    };\n    return Array.isArray(docOrDocs) ? docOrDocs.map(transform) : transform(docOrDocs);\n}\nexports.maybeAddIdToDocuments = maybeAddIdToDocuments;\nasync function fileIsAccessible(fileName, mode) {\n    try {\n        await fs_1.promises.access(fileName, mode);\n        return true;\n    }\n    catch {\n        return false;\n    }\n}\nexports.fileIsAccessible = fileIsAccessible;\nfunction noop() {\n    return;\n}\nexports.noop = noop;\n//# sourceMappingURL=utils.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/utils.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/write_concern.js":
/*!***************************************************!*\
  !*** ./node_modules/mongodb/lib/write_concern.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.WriteConcern = exports.WRITE_CONCERN_KEYS = void 0;\nexports.WRITE_CONCERN_KEYS = ['w', 'wtimeout', 'j', 'journal', 'fsync'];\n/**\n * A MongoDB WriteConcern, which describes the level of acknowledgement\n * requested from MongoDB for write operations.\n * @public\n *\n * @see https://www.mongodb.com/docs/manual/reference/write-concern/\n */\nclass WriteConcern {\n    /**\n     * Constructs a WriteConcern from the write concern properties.\n     * @param w - request acknowledgment that the write operation has propagated to a specified number of mongod instances or to mongod instances with specified tags.\n     * @param wtimeoutMS - specify a time limit to prevent write operations from blocking indefinitely\n     * @param journal - request acknowledgment that the write operation has been written to the on-disk journal\n     * @param fsync - equivalent to the j option. Is deprecated and will be removed in the next major version.\n     */\n    constructor(w, wtimeoutMS, journal, fsync) {\n        if (w != null) {\n            if (!Number.isNaN(Number(w))) {\n                this.w = Number(w);\n            }\n            else {\n                this.w = w;\n            }\n        }\n        if (wtimeoutMS != null) {\n            this.wtimeoutMS = this.wtimeout = wtimeoutMS;\n        }\n        if (journal != null) {\n            this.journal = this.j = journal;\n        }\n        if (fsync != null) {\n            this.journal = this.j = fsync ? true : false;\n        }\n    }\n    /**\n     * Apply a write concern to a command document. Will modify and return the command.\n     */\n    static apply(command, writeConcern) {\n        const wc = {};\n        // The write concern document sent to the server has w/wtimeout/j fields.\n        if (writeConcern.w != null)\n            wc.w = writeConcern.w;\n        if (writeConcern.wtimeoutMS != null)\n            wc.wtimeout = writeConcern.wtimeoutMS;\n        if (writeConcern.journal != null)\n            wc.j = writeConcern.j;\n        command.writeConcern = wc;\n        return command;\n    }\n    /** Construct a WriteConcern given an options object. */\n    static fromOptions(options, inherit) {\n        if (options == null)\n            return undefined;\n        inherit = inherit ?? {};\n        let opts;\n        if (typeof options === 'string' || typeof options === 'number') {\n            opts = { w: options };\n        }\n        else if (options instanceof WriteConcern) {\n            opts = options;\n        }\n        else {\n            opts = options.writeConcern;\n        }\n        const parentOpts = inherit instanceof WriteConcern ? inherit : inherit.writeConcern;\n        const { w = undefined, wtimeout = undefined, j = undefined, fsync = undefined, journal = undefined, wtimeoutMS = undefined } = {\n            ...parentOpts,\n            ...opts\n        };\n        if (w != null ||\n            wtimeout != null ||\n            wtimeoutMS != null ||\n            j != null ||\n            journal != null ||\n            fsync != null) {\n            return new WriteConcern(w, wtimeout ?? wtimeoutMS, j ?? journal, fsync);\n        }\n        return undefined;\n    }\n}\nexports.WriteConcern = WriteConcern;\n//# sourceMappingURL=write_concern.js.map\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/lib/write_concern.js?");

/***/ }),

/***/ "./node_modules/mongoose/index.js":
/*!****************************************!*\
  !*** ./node_modules/mongoose/index.js ***!
  \****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/**\n * Export lib/mongoose\n *\n */\n\n\n\nconst mongoose = __webpack_require__(/*! ./lib/ */ \"./node_modules/mongoose/lib/index.js\");\n\nmodule.exports = mongoose;\nmodule.exports[\"default\"] = mongoose;\nmodule.exports.mongoose = mongoose;\n\n// Re-export for ESM support\nmodule.exports.cast = mongoose.cast;\nmodule.exports.STATES = mongoose.STATES;\nmodule.exports.setDriver = mongoose.setDriver;\nmodule.exports.set = mongoose.set;\nmodule.exports.get = mongoose.get;\nmodule.exports.createConnection = mongoose.createConnection;\nmodule.exports.connect = mongoose.connect;\nmodule.exports.disconnect = mongoose.disconnect;\nmodule.exports.startSession = mongoose.startSession;\nmodule.exports.pluralize = mongoose.pluralize;\nmodule.exports.model = mongoose.model;\nmodule.exports.deleteModel = mongoose.deleteModel;\nmodule.exports.modelNames = mongoose.modelNames;\nmodule.exports.plugin = mongoose.plugin;\nmodule.exports.connections = mongoose.connections;\nmodule.exports.version = mongoose.version;\nmodule.exports.Mongoose = mongoose.Mongoose;\nmodule.exports.Schema = mongoose.Schema;\nmodule.exports.SchemaType = mongoose.SchemaType;\nmodule.exports.SchemaTypes = mongoose.SchemaTypes;\nmodule.exports.VirtualType = mongoose.VirtualType;\nmodule.exports.Types = mongoose.Types;\nmodule.exports.Query = mongoose.Query;\nmodule.exports.Model = mongoose.Model;\nmodule.exports.Document = mongoose.Document;\nmodule.exports.ObjectId = mongoose.ObjectId;\nmodule.exports.isValidObjectId = mongoose.isValidObjectId;\nmodule.exports.isObjectIdOrHexString = mongoose.isObjectIdOrHexString;\nmodule.exports.syncIndexes = mongoose.syncIndexes;\nmodule.exports.Decimal128 = mongoose.Decimal128;\nmodule.exports.Mixed = mongoose.Mixed;\nmodule.exports.Date = mongoose.Date;\nmodule.exports.Number = mongoose.Number;\nmodule.exports.Error = mongoose.Error;\nmodule.exports.MongooseError = mongoose.MongooseError;\nmodule.exports.now = mongoose.now;\nmodule.exports.CastError = mongoose.CastError;\nmodule.exports.SchemaTypeOptions = mongoose.SchemaTypeOptions;\nmodule.exports.mongo = mongoose.mongo;\nmodule.exports.mquery = mongoose.mquery;\nmodule.exports.sanitizeFilter = mongoose.sanitizeFilter;\nmodule.exports.trusted = mongoose.trusted;\nmodule.exports.skipMiddlewareFunction = mongoose.skipMiddlewareFunction;\nmodule.exports.overwriteMiddlewareResult = mongoose.overwriteMiddlewareResult;\n\n// The following properties are not exported using ESM because `setDriver()` can mutate these\n// module.exports.connection = mongoose.connection;\n// module.exports.Collection = mongoose.Collection;\n// module.exports.Connection = mongoose.Connection;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/index.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/aggregate.js":
/*!************************************************!*\
  !*** ./node_modules/mongoose/lib/aggregate.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies\n */\n\nconst AggregationCursor = __webpack_require__(/*! ./cursor/aggregationCursor */ \"./node_modules/mongoose/lib/cursor/aggregationCursor.js\");\nconst MongooseError = __webpack_require__(/*! ./error/mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\nconst Query = __webpack_require__(/*! ./query */ \"./node_modules/mongoose/lib/query.js\");\nconst { applyGlobalMaxTimeMS, applyGlobalDiskUse } = __webpack_require__(/*! ./helpers/query/applyGlobalOption */ \"./node_modules/mongoose/lib/helpers/query/applyGlobalOption.js\");\nconst clone = __webpack_require__(/*! ./helpers/clone */ \"./node_modules/mongoose/lib/helpers/clone.js\");\nconst getConstructorName = __webpack_require__(/*! ./helpers/getConstructorName */ \"./node_modules/mongoose/lib/helpers/getConstructorName.js\");\nconst prepareDiscriminatorPipeline = __webpack_require__(/*! ./helpers/aggregate/prepareDiscriminatorPipeline */ \"./node_modules/mongoose/lib/helpers/aggregate/prepareDiscriminatorPipeline.js\");\nconst stringifyFunctionOperators = __webpack_require__(/*! ./helpers/aggregate/stringifyFunctionOperators */ \"./node_modules/mongoose/lib/helpers/aggregate/stringifyFunctionOperators.js\");\nconst utils = __webpack_require__(/*! ./utils */ \"./node_modules/mongoose/lib/utils.js\");\nconst read = Query.prototype.read;\nconst readConcern = Query.prototype.readConcern;\n\nconst validRedactStringValues = new Set(['$$DESCEND', '$$PRUNE', '$$KEEP']);\n\n/**\n * Aggregate constructor used for building aggregation pipelines. Do not\n * instantiate this class directly, use [Model.aggregate()](https://mongoosejs.com/docs/api/model.html#Model.aggregate()) instead.\n *\n * #### Example:\n *\n *     const aggregate = Model.aggregate([\n *       { $project: { a: 1, b: 1 } },\n *       { $skip: 5 }\n *     ]);\n *\n *     Model.\n *       aggregate([{ $match: { age: { $gte: 21 }}}]).\n *       unwind('tags').\n *       exec();\n *\n * #### Note:\n *\n * - The documents returned are plain javascript objects, not mongoose documents (since any shape of document can be returned).\n * - Mongoose does **not** cast pipeline stages. The below will **not** work unless `_id` is a string in the database\n *\n *     new Aggregate([{ $match: { _id: '00000000000000000000000a' } }]);\n *     // Do this instead to cast to an ObjectId\n *     new Aggregate([{ $match: { _id: new mongoose.Types.ObjectId('00000000000000000000000a') } }]);\n *\n * @see MongoDB https://www.mongodb.com/docs/manual/applications/aggregation/\n * @see driver https://mongodb.github.io/node-mongodb-native/4.9/classes/Collection.html#aggregate\n * @param {Array} [pipeline] aggregation pipeline as an array of objects\n * @param {Model} [model] the model to use with this aggregate.\n * @api public\n */\n\nfunction Aggregate(pipeline, model) {\n  this._pipeline = [];\n  this._model = model;\n  this.options = {};\n\n  if (arguments.length === 1 && Array.isArray(pipeline)) {\n    this.append.apply(this, pipeline);\n  }\n}\n\n/**\n * Contains options passed down to the [aggregate command](https://www.mongodb.com/docs/manual/reference/command/aggregate/).\n * Supported options are:\n *\n * - [`allowDiskUse`](https://mongoosejs.com/docs/api/aggregate.html#Aggregate.prototype.allowDiskUse())\n * - `bypassDocumentValidation`\n * - [`collation`](https://mongoosejs.com/docs/api/aggregate.html#Aggregate.prototype.collation())\n * - `comment`\n * - [`cursor`](https://mongoosejs.com/docs/api/aggregate.html#Aggregate.prototype.cursor())\n * - [`explain`](https://mongoosejs.com/docs/api/aggregate.html#Aggregate.prototype.explain())\n * - `fieldsAsRaw`\n * - [`hint`](https://mongoosejs.com/docs/api/aggregate.html#Aggregate.prototype.hint())\n * - `let`\n * - `maxTimeMS`\n * - `raw`\n * - [`readConcern`](https://mongoosejs.com/docs/api/aggregate.html#Aggregate.prototype.readConcern())\n * - `readPreference`\n * - [`session`](https://mongoosejs.com/docs/api/aggregate.html#Aggregate.prototype.session())\n * - `writeConcern`\n *\n * @property options\n * @memberOf Aggregate\n * @api public\n */\n\nAggregate.prototype.options;\n\n/**\n * Get/set the model that this aggregation will execute on.\n *\n * #### Example:\n *\n *     const aggregate = MyModel.aggregate([{ $match: { answer: 42 } }]);\n *     aggregate.model() === MyModel; // true\n *\n *     // Change the model. There's rarely any reason to do this.\n *     aggregate.model(SomeOtherModel);\n *     aggregate.model() === SomeOtherModel; // true\n *\n * @param {Model} [model] Set the model associated with this aggregate. If not provided, returns the already stored model.\n * @return {Model}\n * @api public\n */\n\nAggregate.prototype.model = function(model) {\n  if (arguments.length === 0) {\n    return this._model;\n  }\n\n  this._model = model;\n  if (model.schema != null) {\n    if (this.options.readPreference == null &&\n      model.schema.options.read != null) {\n      this.options.readPreference = model.schema.options.read;\n    }\n    if (this.options.collation == null &&\n      model.schema.options.collation != null) {\n      this.options.collation = model.schema.options.collation;\n    }\n  }\n\n  return model;\n};\n\n/**\n * Appends new operators to this aggregate pipeline\n *\n * #### Example:\n *\n *     aggregate.append({ $project: { field: 1 }}, { $limit: 2 });\n *\n *     // or pass an array\n *     const pipeline = [{ $match: { daw: 'Logic Audio X' }} ];\n *     aggregate.append(pipeline);\n *\n * @param {...Object|Object[]} ops operator(s) to append. Can either be a spread of objects or a single parameter of a object array.\n * @return {Aggregate}\n * @api public\n */\n\nAggregate.prototype.append = function() {\n  const args = (arguments.length === 1 && Array.isArray(arguments[0]))\n    ? arguments[0]\n    : [...arguments];\n\n  if (!args.every(isOperator)) {\n    throw new Error('Arguments must be aggregate pipeline operators');\n  }\n\n  this._pipeline = this._pipeline.concat(args);\n\n  return this;\n};\n\n/**\n * Appends a new $addFields operator to this aggregate pipeline.\n * Requires MongoDB v3.4+ to work\n *\n * #### Example:\n *\n *     // adding new fields based on existing fields\n *     aggregate.addFields({\n *         newField: '$b.nested'\n *       , plusTen: { $add: ['$val', 10]}\n *       , sub: {\n *            name: '$a'\n *         }\n *     })\n *\n *     // etc\n *     aggregate.addFields({ salary_k: { $divide: [ \"$salary\", 1000 ] } });\n *\n * @param {Object} arg field specification\n * @see $addFields https://www.mongodb.com/docs/manual/reference/operator/aggregation/addFields/\n * @return {Aggregate}\n * @api public\n */\nAggregate.prototype.addFields = function(arg) {\n  if (typeof arg !== 'object' || arg === null || Array.isArray(arg)) {\n    throw new Error('Invalid addFields() argument. Must be an object');\n  }\n  return this.append({ $addFields: Object.assign({}, arg) });\n};\n\n/**\n * Appends a new $project operator to this aggregate pipeline.\n *\n * Mongoose query [selection syntax](https://mongoosejs.com/docs/api/query.html#Query.prototype.select()) is also supported.\n *\n * #### Example:\n *\n *     // include a, include b, exclude _id\n *     aggregate.project(\"a b -_id\");\n *\n *     // or you may use object notation, useful when\n *     // you have keys already prefixed with a \"-\"\n *     aggregate.project({a: 1, b: 1, _id: 0});\n *\n *     // reshaping documents\n *     aggregate.project({\n *         newField: '$b.nested'\n *       , plusTen: { $add: ['$val', 10]}\n *       , sub: {\n *            name: '$a'\n *         }\n *     })\n *\n *     // etc\n *     aggregate.project({ salary_k: { $divide: [ \"$salary\", 1000 ] } });\n *\n * @param {Object|String} arg field specification\n * @see projection https://www.mongodb.com/docs/manual/reference/aggregation/project/\n * @return {Aggregate}\n * @api public\n */\n\nAggregate.prototype.project = function(arg) {\n  const fields = {};\n\n  if (typeof arg === 'object' && !Array.isArray(arg)) {\n    Object.keys(arg).forEach(function(field) {\n      fields[field] = arg[field];\n    });\n  } else if (arguments.length === 1 && typeof arg === 'string') {\n    arg.split(/\\s+/).forEach(function(field) {\n      if (!field) {\n        return;\n      }\n      const include = field[0] === '-' ? 0 : 1;\n      if (include === 0) {\n        field = field.substring(1);\n      }\n      fields[field] = include;\n    });\n  } else {\n    throw new Error('Invalid project() argument. Must be string or object');\n  }\n\n  return this.append({ $project: fields });\n};\n\n/**\n * Appends a new custom $group operator to this aggregate pipeline.\n *\n * #### Example:\n *\n *     aggregate.group({ _id: \"$department\" });\n *\n * @see $group https://www.mongodb.com/docs/manual/reference/aggregation/group/\n * @method group\n * @memberOf Aggregate\n * @instance\n * @param {Object} arg $group operator contents\n * @return {Aggregate}\n * @api public\n */\n\n/**\n * Appends a new custom $match operator to this aggregate pipeline.\n *\n * #### Example:\n *\n *     aggregate.match({ department: { $in: [ \"sales\", \"engineering\" ] } });\n *\n * @see $match https://www.mongodb.com/docs/manual/reference/aggregation/match/\n * @method match\n * @memberOf Aggregate\n * @instance\n * @param {Object} arg $match operator contents\n * @return {Aggregate}\n * @api public\n */\n\n/**\n * Appends a new $skip operator to this aggregate pipeline.\n *\n * #### Example:\n *\n *     aggregate.skip(10);\n *\n * @see $skip https://www.mongodb.com/docs/manual/reference/aggregation/skip/\n * @method skip\n * @memberOf Aggregate\n * @instance\n * @param {Number} num number of records to skip before next stage\n * @return {Aggregate}\n * @api public\n */\n\n/**\n * Appends a new $limit operator to this aggregate pipeline.\n *\n * #### Example:\n *\n *     aggregate.limit(10);\n *\n * @see $limit https://www.mongodb.com/docs/manual/reference/aggregation/limit/\n * @method limit\n * @memberOf Aggregate\n * @instance\n * @param {Number} num maximum number of records to pass to the next stage\n * @return {Aggregate}\n * @api public\n */\n\n\n/**\n * Appends a new $densify operator to this aggregate pipeline.\n *\n * #### Example:\n *\n *      aggregate.densify({\n *        field: 'timestamp',\n *        range: {\n *          step: 1,\n *          unit: 'hour',\n *          bounds: [new Date('2021-05-18T00:00:00.000Z'), new Date('2021-05-18T08:00:00.000Z')]\n *        }\n *      });\n *\n * @see $densify https://www.mongodb.com/docs/manual/reference/operator/aggregation/densify/\n * @method densify\n * @memberOf Aggregate\n * @instance\n * @param {Object} arg $densify operator contents\n * @return {Aggregate}\n * @api public\n */\n\n/**\n * Appends a new $fill operator to this aggregate pipeline.\n *\n * #### Example:\n *\n *      aggregate.fill({\n *        output: {\n *          bootsSold: { value: 0 },\n *          sandalsSold: { value: 0 },\n *          sneakersSold: { value: 0 }\n *        }\n *      });\n *\n * @see $fill https://www.mongodb.com/docs/manual/reference/operator/aggregation/fill/\n * @method fill\n * @memberOf Aggregate\n * @instance\n * @param {Object} arg $fill operator contents\n * @return {Aggregate}\n * @api public\n */\n\n/**\n * Appends a new $geoNear operator to this aggregate pipeline.\n *\n * #### Note:\n *\n * **MUST** be used as the first operator in the pipeline.\n *\n * #### Example:\n *\n *     aggregate.near({\n *       near: { type: 'Point', coordinates: [40.724, -73.997] },\n *       distanceField: \"dist.calculated\", // required\n *       maxDistance: 0.008,\n *       query: { type: \"public\" },\n *       includeLocs: \"dist.location\",\n *       spherical: true,\n *     });\n *\n * @see $geoNear https://www.mongodb.com/docs/manual/reference/aggregation/geoNear/\n * @method near\n * @memberOf Aggregate\n * @instance\n * @param {Object} arg\n * @return {Aggregate}\n * @api public\n */\n\nAggregate.prototype.near = function(arg) {\n  const op = {};\n  op.$geoNear = arg;\n  return this.append(op);\n};\n\n/*!\n * define methods\n */\n\n'group match skip limit out densify fill'.split(' ').forEach(function($operator) {\n  Aggregate.prototype[$operator] = function(arg) {\n    const op = {};\n    op['$' + $operator] = arg;\n    return this.append(op);\n  };\n});\n\n/**\n * Appends new custom $unwind operator(s) to this aggregate pipeline.\n *\n * Note that the `$unwind` operator requires the path name to start with '$'.\n * Mongoose will prepend '$' if the specified field doesn't start '$'.\n *\n * #### Example:\n *\n *     aggregate.unwind(\"tags\");\n *     aggregate.unwind(\"a\", \"b\", \"c\");\n *     aggregate.unwind({ path: '$tags', preserveNullAndEmptyArrays: true });\n *\n * @see $unwind https://www.mongodb.com/docs/manual/reference/aggregation/unwind/\n * @param {String|Object|String[]|Object[]} fields the field(s) to unwind, either as field names or as [objects with options](https://www.mongodb.com/docs/manual/reference/operator/aggregation/unwind/#document-operand-with-options). If passing a string, prefixing the field name with '$' is optional. If passing an object, `path` must start with '$'.\n * @return {Aggregate}\n * @api public\n */\n\nAggregate.prototype.unwind = function() {\n  const args = [...arguments];\n\n  const res = [];\n  for (const arg of args) {\n    if (arg && typeof arg === 'object') {\n      res.push({ $unwind: arg });\n    } else if (typeof arg === 'string') {\n      res.push({\n        $unwind: (arg[0] === '$') ? arg : '$' + arg\n      });\n    } else {\n      throw new Error('Invalid arg \"' + arg + '\" to unwind(), ' +\n        'must be string or object');\n    }\n  }\n\n  return this.append.apply(this, res);\n};\n\n/**\n * Appends a new $replaceRoot operator to this aggregate pipeline.\n *\n * Note that the `$replaceRoot` operator requires field strings to start with '$'.\n * If you are passing in a string Mongoose will prepend '$' if the specified field doesn't start '$'.\n * If you are passing in an object the strings in your expression will not be altered.\n *\n * #### Example:\n *\n *     aggregate.replaceRoot(\"user\");\n *\n *     aggregate.replaceRoot({ x: { $concat: ['$this', '$that'] } });\n *\n * @see $replaceRoot https://www.mongodb.com/docs/manual/reference/operator/aggregation/replaceRoot\n * @param {String|Object} newRoot the field or document which will become the new root document\n * @return {Aggregate}\n * @api public\n */\n\nAggregate.prototype.replaceRoot = function(newRoot) {\n  let ret;\n\n  if (typeof newRoot === 'string') {\n    ret = newRoot.startsWith('$') ? newRoot : '$' + newRoot;\n  } else {\n    ret = newRoot;\n  }\n\n  return this.append({\n    $replaceRoot: {\n      newRoot: ret\n    }\n  });\n};\n\n/**\n * Appends a new $count operator to this aggregate pipeline.\n *\n * #### Example:\n *\n *     aggregate.count(\"userCount\");\n *\n * @see $count https://www.mongodb.com/docs/manual/reference/operator/aggregation/count\n * @param {String} fieldName The name of the output field which has the count as its value. It must be a non-empty string, must not start with $ and must not contain the . character.\n * @return {Aggregate}\n * @api public\n */\n\nAggregate.prototype.count = function(fieldName) {\n  return this.append({ $count: fieldName });\n};\n\n/**\n * Appends a new $sortByCount operator to this aggregate pipeline. Accepts either a string field name\n * or a pipeline object.\n *\n * Note that the `$sortByCount` operator requires the new root to start with '$'.\n * Mongoose will prepend '$' if the specified field name doesn't start with '$'.\n *\n * #### Example:\n *\n *     aggregate.sortByCount('users');\n *     aggregate.sortByCount({ $mergeObjects: [ \"$employee\", \"$business\" ] })\n *\n * @see $sortByCount https://www.mongodb.com/docs/manual/reference/operator/aggregation/sortByCount/\n * @param {Object|String} arg\n * @return {Aggregate} this\n * @api public\n */\n\nAggregate.prototype.sortByCount = function(arg) {\n  if (arg && typeof arg === 'object') {\n    return this.append({ $sortByCount: arg });\n  } else if (typeof arg === 'string') {\n    return this.append({\n      $sortByCount: (arg[0] === '$') ? arg : '$' + arg\n    });\n  } else {\n    throw new TypeError('Invalid arg \"' + arg + '\" to sortByCount(), ' +\n      'must be string or object');\n  }\n};\n\n/**\n * Appends new custom $lookup operator to this aggregate pipeline.\n *\n * #### Example:\n *\n *     aggregate.lookup({ from: 'users', localField: 'userId', foreignField: '_id', as: 'users' });\n *\n * @see $lookup https://www.mongodb.com/docs/manual/reference/operator/aggregation/lookup/#pipe._S_lookup\n * @param {Object} options to $lookup as described in the above link\n * @return {Aggregate}\n * @api public\n */\n\nAggregate.prototype.lookup = function(options) {\n  return this.append({ $lookup: options });\n};\n\n/**\n * Appends new custom $graphLookup operator(s) to this aggregate pipeline, performing a recursive search on a collection.\n *\n * Note that graphLookup can only consume at most 100MB of memory, and does not allow disk use even if `{ allowDiskUse: true }` is specified.\n *\n * #### Example:\n *\n *      // Suppose we have a collection of courses, where a document might look like `{ _id: 0, name: 'Calculus', prerequisite: 'Trigonometry'}` and `{ _id: 0, name: 'Trigonometry', prerequisite: 'Algebra' }`\n *      aggregate.graphLookup({ from: 'courses', startWith: '$prerequisite', connectFromField: 'prerequisite', connectToField: 'name', as: 'prerequisites', maxDepth: 3 }) // this will recursively search the 'courses' collection up to 3 prerequisites\n *\n * @see $graphLookup https://www.mongodb.com/docs/manual/reference/operator/aggregation/graphLookup/#pipe._S_graphLookup\n * @param {Object} options to $graphLookup as described in the above link\n * @return {Aggregate}\n * @api public\n */\n\nAggregate.prototype.graphLookup = function(options) {\n  const cloneOptions = {};\n  if (options) {\n    if (!utils.isObject(options)) {\n      throw new TypeError('Invalid graphLookup() argument. Must be an object.');\n    }\n\n    utils.mergeClone(cloneOptions, options);\n    const startWith = cloneOptions.startWith;\n\n    if (startWith && typeof startWith === 'string') {\n      cloneOptions.startWith = cloneOptions.startWith.startsWith('$') ?\n        cloneOptions.startWith :\n        '$' + cloneOptions.startWith;\n    }\n\n  }\n  return this.append({ $graphLookup: cloneOptions });\n};\n\n/**\n * Appends new custom $sample operator to this aggregate pipeline.\n *\n * #### Example:\n *\n *     aggregate.sample(3); // Add a pipeline that picks 3 random documents\n *\n * @see $sample https://www.mongodb.com/docs/manual/reference/operator/aggregation/sample/#pipe._S_sample\n * @param {Number} size number of random documents to pick\n * @return {Aggregate}\n * @api public\n */\n\nAggregate.prototype.sample = function(size) {\n  return this.append({ $sample: { size: size } });\n};\n\n/**\n * Appends a new $sort operator to this aggregate pipeline.\n *\n * If an object is passed, values allowed are `asc`, `desc`, `ascending`, `descending`, `1`, and `-1`.\n *\n * If a string is passed, it must be a space delimited list of path names. The sort order of each path is ascending unless the path name is prefixed with `-` which will be treated as descending.\n *\n * #### Example:\n *\n *     // these are equivalent\n *     aggregate.sort({ field: 'asc', test: -1 });\n *     aggregate.sort('field -test');\n *\n * @see $sort https://www.mongodb.com/docs/manual/reference/aggregation/sort/\n * @param {Object|String} arg\n * @return {Aggregate} this\n * @api public\n */\n\nAggregate.prototype.sort = function(arg) {\n  // TODO refactor to reuse the query builder logic\n\n  const sort = {};\n\n  if (getConstructorName(arg) === 'Object') {\n    const desc = ['desc', 'descending', -1];\n    Object.keys(arg).forEach(function(field) {\n      // If sorting by text score, skip coercing into 1/-1\n      if (arg[field] instanceof Object && arg[field].$meta) {\n        sort[field] = arg[field];\n        return;\n      }\n      sort[field] = desc.indexOf(arg[field]) === -1 ? 1 : -1;\n    });\n  } else if (arguments.length === 1 && typeof arg === 'string') {\n    arg.split(/\\s+/).forEach(function(field) {\n      if (!field) {\n        return;\n      }\n      const ascend = field[0] === '-' ? -1 : 1;\n      if (ascend === -1) {\n        field = field.substring(1);\n      }\n      sort[field] = ascend;\n    });\n  } else {\n    throw new TypeError('Invalid sort() argument. Must be a string or object.');\n  }\n\n  return this.append({ $sort: sort });\n};\n\n/**\n * Appends new $unionWith operator to this aggregate pipeline.\n *\n * #### Example:\n *\n *     aggregate.unionWith({ coll: 'users', pipeline: [ { $match: { _id: 1 } } ] });\n *\n * @see $unionWith https://www.mongodb.com/docs/manual/reference/operator/aggregation/unionWith\n * @param {Object} options to $unionWith query as described in the above link\n * @return {Aggregate}\n * @api public\n */\n\nAggregate.prototype.unionWith = function(options) {\n  return this.append({ $unionWith: options });\n};\n\n\n/**\n * Sets the readPreference option for the aggregation query.\n *\n * #### Example:\n *\n *     await Model.aggregate(pipeline).read('primaryPreferred');\n *\n * @param {String|ReadPreference} pref one of the listed preference options or their aliases\n * @param {Array} [tags] optional tags for this query.\n * @return {Aggregate} this\n * @api public\n * @see mongodb https://www.mongodb.com/docs/manual/applications/replication/#read-preference\n */\n\nAggregate.prototype.read = function(pref, tags) {\n  read.call(this, pref, tags);\n  return this;\n};\n\n/**\n * Sets the readConcern level for the aggregation query.\n *\n * #### Example:\n *\n *     await Model.aggregate(pipeline).readConcern('majority');\n *\n * @param {String} level one of the listed read concern level or their aliases\n * @see mongodb https://www.mongodb.com/docs/manual/reference/read-concern/\n * @return {Aggregate} this\n * @api public\n */\n\nAggregate.prototype.readConcern = function(level) {\n  readConcern.call(this, level);\n  return this;\n};\n\n/**\n * Appends a new $redact operator to this aggregate pipeline.\n *\n * If 3 arguments are supplied, Mongoose will wrap them with if-then-else of $cond operator respectively\n * If `thenExpr` or `elseExpr` is string, make sure it starts with $$, like `$$DESCEND`, `$$PRUNE` or `$$KEEP`.\n *\n * #### Example:\n *\n *     await Model.aggregate(pipeline).redact({\n *       $cond: {\n *         if: { $eq: [ '$level', 5 ] },\n *         then: '$$PRUNE',\n *         else: '$$DESCEND'\n *       }\n *     });\n *\n *     // $redact often comes with $cond operator, you can also use the following syntax provided by mongoose\n *     await Model.aggregate(pipeline).redact({ $eq: [ '$level', 5 ] }, '$$PRUNE', '$$DESCEND');\n *\n * @param {Object} expression redact options or conditional expression\n * @param {String|Object} [thenExpr] true case for the condition\n * @param {String|Object} [elseExpr] false case for the condition\n * @return {Aggregate} this\n * @see $redact https://www.mongodb.com/docs/manual/reference/operator/aggregation/redact/\n * @api public\n */\n\nAggregate.prototype.redact = function(expression, thenExpr, elseExpr) {\n  if (arguments.length === 3) {\n    if ((typeof thenExpr === 'string' && !validRedactStringValues.has(thenExpr)) ||\n      (typeof elseExpr === 'string' && !validRedactStringValues.has(elseExpr))) {\n      throw new Error('If thenExpr or elseExpr is string, it must be either $$DESCEND, $$PRUNE or $$KEEP');\n    }\n\n    expression = {\n      $cond: {\n        if: expression,\n        then: thenExpr,\n        else: elseExpr\n      }\n    };\n  } else if (arguments.length !== 1) {\n    throw new TypeError('Invalid arguments');\n  }\n\n  return this.append({ $redact: expression });\n};\n\n/**\n * Execute the aggregation with explain\n *\n * #### Example:\n *\n *     Model.aggregate(..).explain()\n *\n * @param {String} [verbosity]\n * @return {Promise}\n */\n\nAggregate.prototype.explain = async function explain(verbosity) {\n  if (typeof verbosity === 'function' || typeof arguments[1] === 'function') {\n    throw new MongooseError('Aggregate.prototype.explain() no longer accepts a callback');\n  }\n  const model = this._model;\n\n  if (!this._pipeline.length) {\n    throw new Error('Aggregate has empty pipeline');\n  }\n\n  prepareDiscriminatorPipeline(this._pipeline, this._model.schema);\n\n  await new Promise((resolve, reject) => {\n    model.hooks.execPre('aggregate', this, error => {\n      if (error) {\n        const _opts = { error: error };\n        return model.hooks.execPost('aggregate', this, [null], _opts, error => {\n          reject(error);\n        });\n      } else {\n        resolve();\n      }\n    });\n  });\n\n  const cursor = model.collection.aggregate(this._pipeline, this.options);\n\n  if (verbosity == null) {\n    verbosity = true;\n  }\n\n  let result = null;\n  try {\n    result = await cursor.explain(verbosity);\n  } catch (error) {\n    await new Promise((resolve, reject) => {\n      const _opts = { error: error };\n      model.hooks.execPost('aggregate', this, [null], _opts, error => {\n        if (error) {\n          return reject(error);\n        }\n        return resolve();\n      });\n    });\n  }\n\n  const _opts = { error: null };\n  await new Promise((resolve, reject) => {\n    model.hooks.execPost('aggregate', this, [result], _opts, error => {\n      if (error) {\n        return reject(error);\n      }\n      return resolve();\n    });\n  });\n\n  return result;\n};\n\n/**\n * Sets the allowDiskUse option for the aggregation query\n *\n * #### Example:\n *\n *     await Model.aggregate([{ $match: { foo: 'bar' } }]).allowDiskUse(true);\n *\n * @param {Boolean} value Should tell server it can use hard drive to store data during aggregation.\n * @return {Aggregate} this\n * @see mongodb https://www.mongodb.com/docs/manual/reference/command/aggregate/\n */\n\nAggregate.prototype.allowDiskUse = function(value) {\n  this.options.allowDiskUse = value;\n  return this;\n};\n\n/**\n * Sets the hint option for the aggregation query\n *\n * #### Example:\n *\n *     Model.aggregate(..).hint({ qty: 1, category: 1 }).exec();\n *\n * @param {Object|String} value a hint object or the index name\n * @return {Aggregate} this\n * @see mongodb https://www.mongodb.com/docs/manual/reference/command/aggregate/\n */\n\nAggregate.prototype.hint = function(value) {\n  this.options.hint = value;\n  return this;\n};\n\n/**\n * Sets the session for this aggregation. Useful for [transactions](https://mongoosejs.com/docs/transactions.html).\n *\n * #### Example:\n *\n *     const session = await Model.startSession();\n *     await Model.aggregate(..).session(session);\n *\n * @param {ClientSession} session\n * @return {Aggregate} this\n * @see mongodb https://www.mongodb.com/docs/manual/reference/command/aggregate/\n */\n\nAggregate.prototype.session = function(session) {\n  if (session == null) {\n    delete this.options.session;\n  } else {\n    this.options.session = session;\n  }\n  return this;\n};\n\n/**\n * Lets you set arbitrary options, for middleware or plugins.\n *\n * #### Example:\n *\n *     const agg = Model.aggregate(..).option({ allowDiskUse: true }); // Set the `allowDiskUse` option\n *     agg.options; // `{ allowDiskUse: true }`\n *\n * @param {Object} options keys to merge into current options\n * @param {Number} [options.maxTimeMS] number limits the time this aggregation will run, see [MongoDB docs on `maxTimeMS`](https://www.mongodb.com/docs/manual/reference/operator/meta/maxTimeMS/)\n * @param {Boolean} [options.allowDiskUse] boolean if true, the MongoDB server will use the hard drive to store data during this aggregation\n * @param {Object} [options.collation] object see [`Aggregate.prototype.collation()`](https://mongoosejs.com/docs/api/aggregate.html#Aggregate.prototype.collation())\n * @param {ClientSession} [options.session] ClientSession see [`Aggregate.prototype.session()`](https://mongoosejs.com/docs/api/aggregate.html#Aggregate.prototype.session())\n * @see mongodb https://www.mongodb.com/docs/manual/reference/command/aggregate/\n * @return {Aggregate} this\n * @api public\n */\n\nAggregate.prototype.option = function(value) {\n  for (const key in value) {\n    this.options[key] = value[key];\n  }\n  return this;\n};\n\n/**\n * Sets the `cursor` option and executes this aggregation, returning an aggregation cursor.\n * Cursors are useful if you want to process the results of the aggregation one-at-a-time\n * because the aggregation result is too big to fit into memory.\n *\n * #### Example:\n *\n *     const cursor = Model.aggregate(..).cursor({ batchSize: 1000 });\n *     cursor.eachAsync(function(doc, i) {\n *       // use doc\n *     });\n *\n * @param {Object} options\n * @param {Number} [options.batchSize] set the cursor batch size\n * @param {Boolean} [options.useMongooseAggCursor] use experimental mongoose-specific aggregation cursor (for `eachAsync()` and other query cursor semantics)\n * @return {AggregationCursor} cursor representing this aggregation\n * @api public\n * @see mongodb https://mongodb.github.io/node-mongodb-native/4.9/classes/AggregationCursor.html\n */\n\nAggregate.prototype.cursor = function(options) {\n  this.options.cursor = options || {};\n  return new AggregationCursor(this); // return this;\n};\n\n/**\n * Adds a collation\n *\n * #### Example:\n *\n *     const res = await Model.aggregate(pipeline).collation({ locale: 'en_US', strength: 1 });\n *\n * @param {Object} collation options\n * @return {Aggregate} this\n * @api public\n * @see mongodb https://mongodb.github.io/node-mongodb-native/4.9/interfaces/CollationOptions.html\n */\n\nAggregate.prototype.collation = function(collation) {\n  this.options.collation = collation;\n  return this;\n};\n\n/**\n * Combines multiple aggregation pipelines.\n *\n * #### Example:\n *\n *     const res = await Model.aggregate().facet({\n *       books: [{ groupBy: '$author' }],\n *       price: [{ $bucketAuto: { groupBy: '$price', buckets: 2 } }]\n *     });\n *\n *     // Output: { books: [...], price: [{...}, {...}] }\n *\n * @param {Object} facet options\n * @return {Aggregate} this\n * @see $facet https://www.mongodb.com/docs/manual/reference/operator/aggregation/facet/\n * @api public\n */\n\nAggregate.prototype.facet = function(options) {\n  return this.append({ $facet: options });\n};\n\n/**\n * Helper for [Atlas Text Search](https://www.mongodb.com/docs/atlas/atlas-search/tutorial/)'s\n * `$search` stage.\n *\n * #### Example:\n *\n *     const res = await Model.aggregate().\n *      search({\n *        text: {\n *          query: 'baseball',\n *          path: 'plot'\n *        }\n *      });\n *\n *     // Output: [{ plot: '...', title: '...' }]\n *\n * @param {Object} $search options\n * @return {Aggregate} this\n * @see $search https://www.mongodb.com/docs/atlas/atlas-search/tutorial/\n * @api public\n */\n\nAggregate.prototype.search = function(options) {\n  return this.append({ $search: options });\n};\n\n/**\n * Returns the current pipeline\n *\n * #### Example:\n *\n *     MyModel.aggregate().match({ test: 1 }).pipeline(); // [{ $match: { test: 1 } }]\n *\n * @return {Array} The current pipeline similar to the operation that will be executed\n * @api public\n */\n\nAggregate.prototype.pipeline = function() {\n  return this._pipeline;\n};\n\n/**\n * Executes the aggregate pipeline on the currently bound Model.\n *\n * #### Example:\n *     const result = await aggregate.exec();\n *\n * @return {Promise}\n * @api public\n */\n\nAggregate.prototype.exec = async function exec() {\n  if (!this._model) {\n    throw new Error('Aggregate not bound to any Model');\n  }\n  if (typeof arguments[0] === 'function') {\n    throw new MongooseError('Aggregate.prototype.exec() no longer accepts a callback');\n  }\n  const model = this._model;\n  const collection = this._model.collection;\n\n  applyGlobalMaxTimeMS(this.options, model.db.options, model.base.options);\n  applyGlobalDiskUse(this.options, model.db.options, model.base.options);\n\n  const asyncLocalStorage = this.model()?.db?.base.transactionAsyncLocalStorage?.getStore();\n  if (!this.options.hasOwnProperty('session') && asyncLocalStorage?.session != null) {\n    this.options.session = asyncLocalStorage.session;\n  }\n\n  if (this.options && this.options.cursor) {\n    return new AggregationCursor(this);\n  }\n\n  prepareDiscriminatorPipeline(this._pipeline, this._model.schema);\n  stringifyFunctionOperators(this._pipeline);\n\n  await new Promise((resolve, reject) => {\n    model.hooks.execPre('aggregate', this, error => {\n      if (error) {\n        const _opts = { error: error };\n        return model.hooks.execPost('aggregate', this, [null], _opts, error => {\n          reject(error);\n        });\n      } else {\n        resolve();\n      }\n    });\n  });\n\n  if (!this._pipeline.length) {\n    throw new MongooseError('Aggregate has empty pipeline');\n  }\n\n  const options = clone(this.options || {});\n  let result;\n  try {\n    const cursor = await collection.aggregate(this._pipeline, options);\n    result = await cursor.toArray();\n  } catch (error) {\n    await new Promise((resolve, reject) => {\n      const _opts = { error: error };\n      model.hooks.execPost('aggregate', this, [null], _opts, (error) => {\n        if (error) {\n          return reject(error);\n        }\n\n        resolve();\n      });\n    });\n  }\n\n  const _opts = { error: null };\n  await new Promise((resolve, reject) => {\n    model.hooks.execPost('aggregate', this, [result], _opts, error => {\n      if (error) {\n        return reject(error);\n      }\n      return resolve();\n    });\n  });\n\n  return result;\n};\n\n/**\n * Provides a Promise-like `then` function, which will call `.exec` without a callback\n * Compatible with `await`.\n *\n * #### Example:\n *\n *     Model.aggregate(..).then(successCallback, errorCallback);\n *\n * @param {Function} [resolve] successCallback\n * @param {Function} [reject]  errorCallback\n * @return {Promise}\n */\nAggregate.prototype.then = function(resolve, reject) {\n  return this.exec().then(resolve, reject);\n};\n\n/**\n * Executes the aggregation returning a `Promise` which will be\n * resolved with either the doc(s) or rejected with the error.\n * Like [`.then()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.then), but only takes a rejection handler.\n * Compatible with `await`.\n *\n * @param {Function} [reject]\n * @return {Promise}\n * @api public\n */\n\nAggregate.prototype.catch = function(reject) {\n  return this.exec().then(null, reject);\n};\n\n/**\n * Executes the aggregate returning a `Promise` which will be\n * resolved with `.finally()` chained.\n *\n * More about [Promise `finally()` in JavaScript](https://thecodebarbarian.com/using-promise-finally-in-node-js.html).\n *\n * @param {Function} [onFinally]\n * @return {Promise}\n * @api public\n */\n\nAggregate.prototype.finally = function(onFinally) {\n  return this.exec().finally(onFinally);\n};\n\n/**\n * Returns an asyncIterator for use with [`for/await/of` loops](https://thecodebarbarian.com/getting-started-with-async-iterators-in-node-js)\n * You do not need to call this function explicitly, the JavaScript runtime\n * will call it for you.\n *\n * #### Example:\n *\n *     const agg = Model.aggregate([{ $match: { age: { $gte: 25 } } }]);\n *     for await (const doc of agg) {\n *       console.log(doc.name);\n *     }\n *\n * Node.js 10.x supports async iterators natively without any flags. You can\n * enable async iterators in Node.js 8.x using the [`--harmony_async_iteration` flag](https://github.com/tc39/proposal-async-iteration/issues/117#issuecomment-346695187).\n *\n * **Note:** This function is not set if `Symbol.asyncIterator` is undefined. If\n * `Symbol.asyncIterator` is undefined, that means your Node.js version does not\n * support async iterators.\n *\n * @method [Symbol.asyncIterator]\n * @memberOf Aggregate\n * @instance\n * @api public\n */\n\nif (Symbol.asyncIterator != null) {\n  Aggregate.prototype[Symbol.asyncIterator] = function() {\n    return this.cursor({ useMongooseAggCursor: true }).transformNull()._transformForAsyncIterator();\n  };\n}\n\n/*!\n * Helpers\n */\n\n/**\n * Checks whether an object is likely a pipeline operator\n *\n * @param {Object} obj object to check\n * @return {Boolean}\n * @api private\n */\n\nfunction isOperator(obj) {\n  if (typeof obj !== 'object' || obj === null) {\n    return false;\n  }\n\n  const k = Object.keys(obj);\n\n  return k.length === 1 && k[0][0] === '$';\n}\n\n/**\n * Adds the appropriate `$match` pipeline step to the top of an aggregate's\n * pipeline, should it's model is a non-root discriminator type. This is\n * analogous to the `prepareDiscriminatorCriteria` function in `lib/query.js`.\n *\n * @param {Aggregate} aggregate Aggregate to prepare\n * @api private\n */\n\nAggregate._prepareDiscriminatorPipeline = prepareDiscriminatorPipeline;\n\n/*!\n * Exports\n */\n\nmodule.exports = Aggregate;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/aggregate.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/browserDocument.js":
/*!******************************************************!*\
  !*** ./node_modules/mongoose/lib/browserDocument.js ***!
  \******************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module dependencies.\n */\n\n\n\nconst NodeJSDocument = __webpack_require__(/*! ./document */ \"./node_modules/mongoose/lib/document.js\");\nconst EventEmitter = (__webpack_require__(/*! events */ \"events\").EventEmitter);\nconst MongooseError = __webpack_require__(/*! ./error/index */ \"./node_modules/mongoose/lib/error/index.js\");\nconst Schema = __webpack_require__(/*! ./schema */ \"./node_modules/mongoose/lib/schema.js\");\nconst ObjectId = __webpack_require__(/*! ./types/objectid */ \"./node_modules/mongoose/lib/types/objectid.js\");\nconst ValidationError = MongooseError.ValidationError;\nconst applyHooks = __webpack_require__(/*! ./helpers/model/applyHooks */ \"./node_modules/mongoose/lib/helpers/model/applyHooks.js\");\nconst isObject = __webpack_require__(/*! ./helpers/isObject */ \"./node_modules/mongoose/lib/helpers/isObject.js\");\n\n/**\n * Document constructor.\n *\n * @param {Object} obj the values to set\n * @param {Object} schema\n * @param {Object} [fields] optional object containing the fields which were selected in the query returning this document and any populated paths data\n * @param {Boolean} [skipId] bool, should we auto create an ObjectId _id\n * @inherits NodeJS EventEmitter https://nodejs.org/api/events.html#class-eventemitter\n * @event `init`: Emitted on a document after it has was retrieved from the db and fully hydrated by Mongoose.\n * @event `save`: Emitted when the document is successfully saved\n * @api private\n */\n\nfunction Document(obj, schema, fields, skipId, skipInit) {\n  if (!(this instanceof Document)) {\n    return new Document(obj, schema, fields, skipId, skipInit);\n  }\n\n  if (isObject(schema) && !schema.instanceOfSchema) {\n    schema = new Schema(schema);\n  }\n\n  // When creating EmbeddedDocument, it already has the schema and he doesn't need the _id\n  schema = this.schema || schema;\n\n  // Generate ObjectId if it is missing, but it requires a scheme\n  if (!this.schema && schema.options._id) {\n    obj = obj || {};\n\n    if (obj._id === undefined) {\n      obj._id = new ObjectId();\n    }\n  }\n\n  if (!schema) {\n    throw new MongooseError.MissingSchemaError();\n  }\n\n  this.$__setSchema(schema);\n\n  NodeJSDocument.call(this, obj, fields, skipId, skipInit);\n\n  applyHooks(this, schema, { decorateDoc: true });\n\n  // apply methods\n  for (const m in schema.methods) {\n    this[m] = schema.methods[m];\n  }\n  // apply statics\n  for (const s in schema.statics) {\n    this[s] = schema.statics[s];\n  }\n}\n\n/*!\n * Inherit from the NodeJS document\n */\n\nDocument.prototype = Object.create(NodeJSDocument.prototype);\nDocument.prototype.constructor = Document;\n\n/*!\n * ignore\n */\n\nDocument.events = new EventEmitter();\n\n/*!\n * Browser doc exposes the event emitter API\n */\n\nDocument.$emitter = new EventEmitter();\n\n['on', 'once', 'emit', 'listeners', 'removeListener', 'setMaxListeners',\n  'removeAllListeners', 'addListener'].forEach(function(emitterFn) {\n  Document[emitterFn] = function() {\n    return Document.$emitter[emitterFn].apply(Document.$emitter, arguments);\n  };\n});\n\n/*!\n * Module exports.\n */\n\nDocument.ValidationError = ValidationError;\nmodule.exports = exports = Document;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/browserDocument.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/cast.js":
/*!*******************************************!*\
  !*** ./node_modules/mongoose/lib/cast.js ***!
  \*******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst CastError = __webpack_require__(/*! ./error/cast */ \"./node_modules/mongoose/lib/error/cast.js\");\nconst StrictModeError = __webpack_require__(/*! ./error/strict */ \"./node_modules/mongoose/lib/error/strict.js\");\nconst Types = __webpack_require__(/*! ./schema/index */ \"./node_modules/mongoose/lib/schema/index.js\");\nconst cast$expr = __webpack_require__(/*! ./helpers/query/cast$expr */ \"./node_modules/mongoose/lib/helpers/query/cast$expr.js\");\nconst castTextSearch = __webpack_require__(/*! ./schema/operators/text */ \"./node_modules/mongoose/lib/schema/operators/text.js\");\nconst get = __webpack_require__(/*! ./helpers/get */ \"./node_modules/mongoose/lib/helpers/get.js\");\nconst getSchemaDiscriminatorByValue = __webpack_require__(/*! ./helpers/discriminator/getSchemaDiscriminatorByValue */ \"./node_modules/mongoose/lib/helpers/discriminator/getSchemaDiscriminatorByValue.js\");\nconst isOperator = __webpack_require__(/*! ./helpers/query/isOperator */ \"./node_modules/mongoose/lib/helpers/query/isOperator.js\");\nconst util = __webpack_require__(/*! util */ \"util\");\nconst isObject = __webpack_require__(/*! ./helpers/isObject */ \"./node_modules/mongoose/lib/helpers/isObject.js\");\nconst isMongooseObject = __webpack_require__(/*! ./helpers/isMongooseObject */ \"./node_modules/mongoose/lib/helpers/isMongooseObject.js\");\nconst utils = __webpack_require__(/*! ./utils */ \"./node_modules/mongoose/lib/utils.js\");\n\nconst ALLOWED_GEOWITHIN_GEOJSON_TYPES = ['Polygon', 'MultiPolygon'];\n\n/**\n * Handles internal casting for query filters.\n *\n * @param {Schema} schema\n * @param {Object} obj Object to cast\n * @param {Object} [options] the query options\n * @param {Boolean|\"throw\"} [options.strict] Wheter to enable all strict options\n * @param {Boolean|\"throw\"} [options.strictQuery] Enable strict Queries\n * @param {Boolean} [options.upsert]\n * @param {Query} [context] passed to setters\n * @api private\n */\nmodule.exports = function cast(schema, obj, options, context) {\n  if (Array.isArray(obj)) {\n    throw new Error('Query filter must be an object, got an array ', util.inspect(obj));\n  }\n\n  if (obj == null) {\n    return obj;\n  }\n\n  if (schema != null && schema.discriminators != null && obj[schema.options.discriminatorKey] != null) {\n    schema = getSchemaDiscriminatorByValue(schema, obj[schema.options.discriminatorKey]) || schema;\n  }\n\n  const paths = Object.keys(obj);\n  let i = paths.length;\n  let _keys;\n  let any$conditionals;\n  let schematype;\n  let nested;\n  let path;\n  let type;\n  let val;\n\n  options = options || {};\n\n  while (i--) {\n    path = paths[i];\n    val = obj[path];\n\n    if (path === '$or' || path === '$nor' || path === '$and') {\n      if (!Array.isArray(val)) {\n        throw new CastError('Array', val, path);\n      }\n      for (let k = 0; k < val.length; ++k) {\n        if (val[k] == null || typeof val[k] !== 'object') {\n          throw new CastError('Object', val[k], path + '.' + k);\n        }\n        const discriminatorValue = val[k][schema.options.discriminatorKey];\n        if (discriminatorValue == null) {\n          val[k] = cast(schema, val[k], options, context);\n        } else {\n          const discriminatorSchema = getSchemaDiscriminatorByValue(context.schema, discriminatorValue);\n          val[k] = cast(discriminatorSchema ? discriminatorSchema : schema, val[k], options, context);\n        }\n      }\n    } else if (path === '$where') {\n      type = typeof val;\n\n      if (type !== 'string' && type !== 'function') {\n        throw new Error('Must have a string or function for $where');\n      }\n\n      if (type === 'function') {\n        obj[path] = val.toString();\n      }\n\n      continue;\n    } else if (path === '$expr') {\n      val = cast$expr(val, schema);\n      continue;\n    } else if (path === '$elemMatch') {\n      val = cast(schema, val, options, context);\n    } else if (path === '$text') {\n      val = castTextSearch(val, path);\n    } else {\n      if (!schema) {\n        // no casting for Mixed types\n        continue;\n      }\n\n      schematype = schema.path(path);\n\n      // Check for embedded discriminator paths\n      if (!schematype) {\n        const split = path.split('.');\n        let j = split.length;\n        while (j--) {\n          const pathFirstHalf = split.slice(0, j).join('.');\n          const pathLastHalf = split.slice(j).join('.');\n          const _schematype = schema.path(pathFirstHalf);\n          const discriminatorKey = _schematype &&\n            _schematype.schema &&\n            _schematype.schema.options &&\n            _schematype.schema.options.discriminatorKey;\n\n          // gh-6027: if we haven't found the schematype but this path is\n          // underneath an embedded discriminator and the embedded discriminator\n          // key is in the query, use the embedded discriminator schema\n          if (_schematype != null &&\n            (_schematype.schema && _schematype.schema.discriminators) != null &&\n            discriminatorKey != null &&\n            pathLastHalf !== discriminatorKey) {\n            const discriminatorVal = get(obj, pathFirstHalf + '.' + discriminatorKey);\n            const discriminators = _schematype.schema.discriminators;\n            if (typeof discriminatorVal === 'string' && discriminators[discriminatorVal] != null) {\n\n              schematype = discriminators[discriminatorVal].path(pathLastHalf);\n            } else if (discriminatorVal != null &&\n              Object.keys(discriminatorVal).length === 1 &&\n              Array.isArray(discriminatorVal.$in) &&\n              discriminatorVal.$in.length === 1 &&\n              typeof discriminatorVal.$in[0] === 'string' &&\n              discriminators[discriminatorVal.$in[0]] != null) {\n              schematype = discriminators[discriminatorVal.$in[0]].path(pathLastHalf);\n            }\n          }\n        }\n      }\n\n      if (!schematype) {\n        // Handle potential embedded array queries\n        const split = path.split('.');\n        let j = split.length;\n        let pathFirstHalf;\n        let pathLastHalf;\n        let remainingConds;\n\n        // Find the part of the var path that is a path of the Schema\n        while (j--) {\n          pathFirstHalf = split.slice(0, j).join('.');\n          schematype = schema.path(pathFirstHalf);\n          if (schematype) {\n            break;\n          }\n        }\n\n        // If a substring of the input path resolves to an actual real path...\n        if (schematype) {\n          // Apply the casting; similar code for $elemMatch in schema/array.js\n          if (schematype.caster && schematype.caster.schema) {\n            remainingConds = {};\n            pathLastHalf = split.slice(j).join('.');\n            remainingConds[pathLastHalf] = val;\n\n            const ret = cast(schematype.caster.schema, remainingConds, options, context)[pathLastHalf];\n            if (ret === void 0) {\n              delete obj[path];\n            } else {\n              obj[path] = ret;\n            }\n          } else {\n            obj[path] = val;\n          }\n          continue;\n        }\n\n        if (isObject(val)) {\n          // handle geo schemas that use object notation\n          // { loc: { long: Number, lat: Number }\n\n          let geo = '';\n          if (val.$near) {\n            geo = '$near';\n          } else if (val.$nearSphere) {\n            geo = '$nearSphere';\n          } else if (val.$within) {\n            geo = '$within';\n          } else if (val.$geoIntersects) {\n            geo = '$geoIntersects';\n          } else if (val.$geoWithin) {\n            geo = '$geoWithin';\n          }\n\n          if (geo) {\n            const numbertype = new Types.Number('__QueryCasting__');\n            let value = val[geo];\n\n            if (val.$maxDistance != null) {\n              val.$maxDistance = numbertype.castForQuery(\n                null,\n                val.$maxDistance,\n                context\n              );\n            }\n            if (val.$minDistance != null) {\n              val.$minDistance = numbertype.castForQuery(\n                null,\n                val.$minDistance,\n                context\n              );\n            }\n\n            if (geo === '$within') {\n              const withinType = value.$center\n                  || value.$centerSphere\n                  || value.$box\n                  || value.$polygon;\n\n              if (!withinType) {\n                throw new Error('Bad $within parameter: ' + JSON.stringify(val));\n              }\n\n              value = withinType;\n            } else if (geo === '$near' &&\n                typeof value.type === 'string' && Array.isArray(value.coordinates)) {\n              // geojson; cast the coordinates\n              value = value.coordinates;\n            } else if ((geo === '$near' || geo === '$nearSphere' || geo === '$geoIntersects') &&\n                value.$geometry && typeof value.$geometry.type === 'string' &&\n                Array.isArray(value.$geometry.coordinates)) {\n              if (value.$maxDistance != null) {\n                value.$maxDistance = numbertype.castForQuery(\n                  null,\n                  value.$maxDistance,\n                  context\n                );\n              }\n              if (value.$minDistance != null) {\n                value.$minDistance = numbertype.castForQuery(\n                  null,\n                  value.$minDistance,\n                  context\n                );\n              }\n              if (isMongooseObject(value.$geometry)) {\n                value.$geometry = value.$geometry.toObject({\n                  transform: false,\n                  virtuals: false\n                });\n              }\n              value = value.$geometry.coordinates;\n            } else if (geo === '$geoWithin') {\n              if (value.$geometry) {\n                if (isMongooseObject(value.$geometry)) {\n                  value.$geometry = value.$geometry.toObject({ virtuals: false });\n                }\n                const geoWithinType = value.$geometry.type;\n                if (ALLOWED_GEOWITHIN_GEOJSON_TYPES.indexOf(geoWithinType) === -1) {\n                  throw new Error('Invalid geoJSON type for $geoWithin \"' +\n                    geoWithinType + '\", must be \"Polygon\" or \"MultiPolygon\"');\n                }\n                value = value.$geometry.coordinates;\n              } else {\n                value = value.$box || value.$polygon || value.$center ||\n                  value.$centerSphere;\n                if (isMongooseObject(value)) {\n                  value = value.toObject({ virtuals: false });\n                }\n              }\n            }\n\n            _cast(value, numbertype, context);\n            continue;\n          }\n        }\n\n        if (schema.nested[path]) {\n          continue;\n        }\n\n        const strict = 'strict' in options ? options.strict : schema.options.strict;\n        const strictQuery = getStrictQuery(options, schema._userProvidedOptions, schema.options, context);\n        if (options.upsert && strict) {\n          if (strict === 'throw') {\n            throw new StrictModeError(path);\n          }\n          throw new StrictModeError(path, 'Path \"' + path + '\" is not in ' +\n            'schema, strict mode is `true`, and upsert is `true`.');\n        } if (strictQuery === 'throw') {\n          throw new StrictModeError(path, 'Path \"' + path + '\" is not in ' +\n            'schema and strictQuery is \\'throw\\'.');\n        } else if (strictQuery) {\n          delete obj[path];\n        }\n      } else if (val == null) {\n        continue;\n      } else if (utils.isPOJO(val)) {\n        any$conditionals = Object.keys(val).some(isOperator);\n\n        if (!any$conditionals) {\n          obj[path] = schematype.castForQuery(\n            null,\n            val,\n            context\n          );\n        } else {\n          const ks = Object.keys(val);\n          let $cond;\n          let k = ks.length;\n\n          while (k--) {\n            $cond = ks[k];\n            nested = val[$cond];\n            if ($cond === '$elemMatch') {\n              if (nested && schematype != null && schematype.schema != null) {\n                cast(schematype.schema, nested, options, context);\n              } else if (nested && schematype != null && schematype.$isMongooseArray) {\n                if (utils.isPOJO(nested) && nested.$not != null) {\n                  cast(schema, nested, options, context);\n                } else {\n                  val[$cond] = schematype.castForQuery(\n                    $cond,\n                    nested,\n                    context\n                  );\n                }\n              }\n            } else if ($cond === '$not') {\n              if (nested && schematype) {\n                _keys = Object.keys(nested);\n                if (_keys.length && isOperator(_keys[0])) {\n                  for (const key in nested) {\n                    nested[key] = schematype.castForQuery(\n                      key,\n                      nested[key],\n                      context\n                    );\n                  }\n                } else {\n                  val[$cond] = schematype.castForQuery(\n                    $cond,\n                    nested,\n                    context\n                  );\n                }\n                continue;\n              }\n            } else {\n              val[$cond] = schematype.castForQuery(\n                $cond,\n                nested,\n                context\n              );\n            }\n\n          }\n        }\n      } else if (Array.isArray(val) && ['Buffer', 'Array'].indexOf(schematype.instance) === -1) {\n        const casted = [];\n        const valuesArray = val;\n\n        for (const _val of valuesArray) {\n          casted.push(schematype.castForQuery(\n            null,\n            _val,\n            context\n          ));\n        }\n\n        obj[path] = { $in: casted };\n      } else {\n        obj[path] = schematype.castForQuery(\n          null,\n          val,\n          context\n        );\n      }\n    }\n  }\n\n  return obj;\n};\n\nfunction _cast(val, numbertype, context) {\n  if (Array.isArray(val)) {\n    val.forEach(function(item, i) {\n      if (Array.isArray(item) || isObject(item)) {\n        return _cast(item, numbertype, context);\n      }\n      val[i] = numbertype.castForQuery(null, item, context);\n    });\n  } else {\n    const nearKeys = Object.keys(val);\n    let nearLen = nearKeys.length;\n    while (nearLen--) {\n      const nkey = nearKeys[nearLen];\n      const item = val[nkey];\n      if (Array.isArray(item) || isObject(item)) {\n        _cast(item, numbertype, context);\n        val[nkey] = item;\n      } else {\n        val[nkey] = numbertype.castForQuery({ val: item, context: context });\n      }\n    }\n  }\n}\n\nfunction getStrictQuery(queryOptions, schemaUserProvidedOptions, schemaOptions, context) {\n  if ('strictQuery' in queryOptions) {\n    return queryOptions.strictQuery;\n  }\n  if ('strictQuery' in schemaUserProvidedOptions) {\n    return schemaUserProvidedOptions.strictQuery;\n  }\n  const mongooseOptions = context &&\n    context.mongooseCollection &&\n    context.mongooseCollection.conn &&\n    context.mongooseCollection.conn.base &&\n    context.mongooseCollection.conn.base.options;\n  if (mongooseOptions) {\n    if ('strictQuery' in mongooseOptions) {\n      return mongooseOptions.strictQuery;\n    }\n  }\n  return schemaOptions.strictQuery;\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/cast.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/cast/bigint.js":
/*!**************************************************!*\
  !*** ./node_modules/mongoose/lib/cast/bigint.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst assert = __webpack_require__(/*! assert */ \"assert\");\nconst { Long } = __webpack_require__(/*! bson */ \"./node_modules/bson/lib/bson.cjs\");\n\n/**\n * Given a value, cast it to a BigInt, or throw an `Error` if the value\n * cannot be casted. `null` and `undefined` are considered valid.\n *\n * @param {Any} value\n * @return {Number}\n * @throws {Error} if `value` is not one of the allowed values\n * @api private\n */\n\nmodule.exports = function castBigInt(val) {\n  if (val == null) {\n    return val;\n  }\n  if (val === '') {\n    return null;\n  }\n  if (typeof val === 'bigint') {\n    return val;\n  }\n\n  if (val instanceof Long) {\n    return val.toBigInt();\n  }\n\n  if (typeof val === 'string' || typeof val === 'number') {\n    return BigInt(val);\n  }\n\n  assert.ok(false);\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/cast/bigint.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/cast/boolean.js":
/*!***************************************************!*\
  !*** ./node_modules/mongoose/lib/cast/boolean.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst CastError = __webpack_require__(/*! ../error/cast */ \"./node_modules/mongoose/lib/error/cast.js\");\n\n/**\n * Given a value, cast it to a boolean, or throw a `CastError` if the value\n * cannot be casted. `null` and `undefined` are considered valid.\n *\n * @param {Any} value\n * @param {String} [path] optional the path to set on the CastError\n * @return {Boolean|null|undefined}\n * @throws {CastError} if `value` is not one of the allowed values\n * @api private\n */\n\nmodule.exports = function castBoolean(value, path) {\n  if (module.exports.convertToTrue.has(value)) {\n    return true;\n  }\n  if (module.exports.convertToFalse.has(value)) {\n    return false;\n  }\n\n  if (value == null) {\n    return value;\n  }\n\n  throw new CastError('boolean', value, path);\n};\n\nmodule.exports.convertToTrue = new Set([true, 'true', 1, '1', 'yes']);\nmodule.exports.convertToFalse = new Set([false, 'false', 0, '0', 'no']);\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/cast/boolean.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/cast/date.js":
/*!************************************************!*\
  !*** ./node_modules/mongoose/lib/cast/date.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst assert = __webpack_require__(/*! assert */ \"assert\");\n\nmodule.exports = function castDate(value) {\n  // Support empty string because of empty form values. Originally introduced\n  // in https://github.com/Automattic/mongoose/commit/efc72a1898fc3c33a319d915b8c5463a22938dfe\n  if (value == null || value === '') {\n    return null;\n  }\n\n  if (value instanceof Date) {\n    assert.ok(!isNaN(value.valueOf()));\n\n    return value;\n  }\n\n  let date;\n\n  assert.ok(typeof value !== 'boolean');\n\n  if (value instanceof Number || typeof value === 'number') {\n    date = new Date(value);\n  } else if (typeof value === 'string' && !isNaN(Number(value)) && (Number(value) >= 275761 || Number(value) < -271820)) {\n    // string representation of milliseconds take this path\n    date = new Date(Number(value));\n  } else if (typeof value.valueOf === 'function') {\n    // support for moment.js. This is also the path strings will take because\n    // strings have a `valueOf()`\n    date = new Date(value.valueOf());\n  } else {\n    // fallback\n    date = new Date(value);\n  }\n\n  if (!isNaN(date.valueOf())) {\n    return date;\n  }\n\n  assert.ok(false);\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/cast/date.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/cast/decimal128.js":
/*!******************************************************!*\
  !*** ./node_modules/mongoose/lib/cast/decimal128.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst Decimal128Type = __webpack_require__(/*! ../types/decimal128 */ \"./node_modules/mongoose/lib/types/decimal128.js\");\nconst assert = __webpack_require__(/*! assert */ \"assert\");\n\nmodule.exports = function castDecimal128(value) {\n  if (value == null) {\n    return value;\n  }\n\n  if (typeof value === 'object' && typeof value.$numberDecimal === 'string') {\n    return Decimal128Type.fromString(value.$numberDecimal);\n  }\n\n  if (value instanceof Decimal128Type) {\n    return value;\n  }\n\n  if (typeof value === 'string') {\n    return Decimal128Type.fromString(value);\n  }\n\n  if (typeof Buffer === 'function' && Buffer.isBuffer(value)) {\n    return new Decimal128Type(value);\n  }\n  if (typeof Uint8Array === 'function' && value instanceof Uint8Array) {\n    return new Decimal128Type(value);\n  }\n\n  if (typeof value === 'number') {\n    return Decimal128Type.fromString(String(value));\n  }\n\n  if (typeof value.valueOf === 'function' && typeof value.valueOf() === 'string') {\n    return Decimal128Type.fromString(value.valueOf());\n  }\n\n  assert.ok(false);\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/cast/decimal128.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/cast/number.js":
/*!**************************************************!*\
  !*** ./node_modules/mongoose/lib/cast/number.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst assert = __webpack_require__(/*! assert */ \"assert\");\n\n/**\n * Given a value, cast it to a number, or throw an `Error` if the value\n * cannot be casted. `null` and `undefined` are considered valid.\n *\n * @param {Any} value\n * @return {Number}\n * @throws {Error} if `value` is not one of the allowed values\n * @api private\n */\n\nmodule.exports = function castNumber(val) {\n  if (val == null) {\n    return val;\n  }\n  if (val === '') {\n    return null;\n  }\n\n  if (typeof val === 'string' || typeof val === 'boolean') {\n    val = Number(val);\n  }\n\n  assert.ok(!isNaN(val));\n  if (val instanceof Number) {\n    return val.valueOf();\n  }\n  if (typeof val === 'number') {\n    return val;\n  }\n  if (!Array.isArray(val) && typeof val.valueOf === 'function') {\n    return Number(val.valueOf());\n  }\n  if (val.toString && !Array.isArray(val) && val.toString() == Number(val)) {\n    return Number(val);\n  }\n\n  assert.ok(false);\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/cast/number.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/cast/objectid.js":
/*!****************************************************!*\
  !*** ./node_modules/mongoose/lib/cast/objectid.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst isBsonType = __webpack_require__(/*! ../helpers/isBsonType */ \"./node_modules/mongoose/lib/helpers/isBsonType.js\");\nconst ObjectId = __webpack_require__(/*! ../types/objectid */ \"./node_modules/mongoose/lib/types/objectid.js\");\n\nmodule.exports = function castObjectId(value) {\n  if (value == null) {\n    return value;\n  }\n\n  if (isBsonType(value, 'ObjectId')) {\n    return value;\n  }\n\n  if (value._id) {\n    if (isBsonType(value._id, 'ObjectId')) {\n      return value._id;\n    }\n    if (value._id.toString instanceof Function) {\n      return new ObjectId(value._id.toString());\n    }\n  }\n\n  if (value.toString instanceof Function) {\n    return new ObjectId(value.toString());\n  }\n\n  return new ObjectId(value);\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/cast/objectid.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/cast/string.js":
/*!**************************************************!*\
  !*** ./node_modules/mongoose/lib/cast/string.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst CastError = __webpack_require__(/*! ../error/cast */ \"./node_modules/mongoose/lib/error/cast.js\");\n\n/**\n * Given a value, cast it to a string, or throw a `CastError` if the value\n * cannot be casted. `null` and `undefined` are considered valid.\n *\n * @param {Any} value\n * @param {String} [path] optional the path to set on the CastError\n * @return {string|null|undefined}\n * @throws {CastError}\n * @api private\n */\n\nmodule.exports = function castString(value, path) {\n  // If null or undefined\n  if (value == null) {\n    return value;\n  }\n\n  // handle documents being passed\n  if (value._id && typeof value._id === 'string') {\n    return value._id;\n  }\n\n  // Re: gh-647 and gh-3030, we're ok with casting using `toString()`\n  // **unless** its the default Object.toString, because \"[object Object]\"\n  // doesn't really qualify as useful data\n  if (value.toString &&\n      value.toString !== Object.prototype.toString &&\n      !Array.isArray(value)) {\n    return value.toString();\n  }\n\n  throw new CastError('string', value, path);\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/cast/string.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/collection.js":
/*!*************************************************!*\
  !*** ./node_modules/mongoose/lib/collection.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst EventEmitter = (__webpack_require__(/*! events */ \"events\").EventEmitter);\nconst STATES = __webpack_require__(/*! ./connectionState */ \"./node_modules/mongoose/lib/connectionState.js\");\nconst immediate = __webpack_require__(/*! ./helpers/immediate */ \"./node_modules/mongoose/lib/helpers/immediate.js\");\n\n/**\n * Abstract Collection constructor\n *\n * This is the base class that drivers inherit from and implement.\n *\n * @param {String} name name of the collection\n * @param {Connection} conn A MongooseConnection instance\n * @param {Object} [opts] optional collection options\n * @api public\n */\n\nfunction Collection(name, conn, opts) {\n  if (opts === void 0) {\n    opts = {};\n  }\n\n  this.opts = opts;\n  this.name = name;\n  this.collectionName = name;\n  this.conn = conn;\n  this.queue = [];\n  this.buffer = true;\n  this.emitter = new EventEmitter();\n\n  if (STATES.connected === this.conn.readyState) {\n    this.onOpen();\n  }\n}\n\n/**\n * The collection name\n *\n * @api public\n * @property name\n */\n\nCollection.prototype.name;\n\n/**\n * The collection name\n *\n * @api public\n * @property collectionName\n */\n\nCollection.prototype.collectionName;\n\n/**\n * The Connection instance\n *\n * @api public\n * @property conn\n */\n\nCollection.prototype.conn;\n\n/**\n * Called when the database connects\n *\n * @api private\n */\n\nCollection.prototype.onOpen = function() {\n  this.buffer = false;\n  immediate(() => this.doQueue());\n};\n\n/**\n * Called when the database disconnects\n *\n * @api private\n */\n\nCollection.prototype.onClose = function() {};\n\n/**\n * Queues a method for later execution when its\n * database connection opens.\n *\n * @param {String} name name of the method to queue\n * @param {Array} args arguments to pass to the method when executed\n * @api private\n */\n\nCollection.prototype.addQueue = function(name, args) {\n  this.queue.push([name, args]);\n  return this;\n};\n\n/**\n * Removes a queued method\n *\n * @param {String} name name of the method to queue\n * @param {Array} args arguments to pass to the method when executed\n * @api private\n */\n\nCollection.prototype.removeQueue = function(name, args) {\n  const index = this.queue.findIndex(v => v[0] === name && v[1] === args);\n  if (index === -1) {\n    return false;\n  }\n  this.queue.splice(index, 1);\n  return true;\n};\n\n/**\n * Executes all queued methods and clears the queue.\n *\n * @api private\n */\n\nCollection.prototype.doQueue = function() {\n  for (const method of this.queue) {\n    if (typeof method[0] === 'function') {\n      method[0].apply(this, method[1]);\n    } else {\n      this[method[0]].apply(this, method[1]);\n    }\n  }\n  this.queue = [];\n  const _this = this;\n  immediate(function() {\n    _this.emitter.emit('queue');\n  });\n  return this;\n};\n\n/**\n * Abstract method that drivers must implement.\n */\n\nCollection.prototype.ensureIndex = function() {\n  throw new Error('Collection#ensureIndex unimplemented by driver');\n};\n\n/**\n * Abstract method that drivers must implement.\n */\n\nCollection.prototype.createIndex = function() {\n  throw new Error('Collection#createIndex unimplemented by driver');\n};\n\n/**\n * Abstract method that drivers must implement.\n */\n\nCollection.prototype.findAndModify = function() {\n  throw new Error('Collection#findAndModify unimplemented by driver');\n};\n\n/**\n * Abstract method that drivers must implement.\n */\n\nCollection.prototype.findOneAndUpdate = function() {\n  throw new Error('Collection#findOneAndUpdate unimplemented by driver');\n};\n\n/**\n * Abstract method that drivers must implement.\n */\n\nCollection.prototype.findOneAndDelete = function() {\n  throw new Error('Collection#findOneAndDelete unimplemented by driver');\n};\n\n/**\n * Abstract method that drivers must implement.\n */\n\nCollection.prototype.findOneAndReplace = function() {\n  throw new Error('Collection#findOneAndReplace unimplemented by driver');\n};\n\n/**\n * Abstract method that drivers must implement.\n */\n\nCollection.prototype.findOne = function() {\n  throw new Error('Collection#findOne unimplemented by driver');\n};\n\n/**\n * Abstract method that drivers must implement.\n */\n\nCollection.prototype.find = function() {\n  throw new Error('Collection#find unimplemented by driver');\n};\n\n/**\n * Abstract method that drivers must implement.\n */\n\nCollection.prototype.insert = function() {\n  throw new Error('Collection#insert unimplemented by driver');\n};\n\n/**\n * Abstract method that drivers must implement.\n */\n\nCollection.prototype.insertOne = function() {\n  throw new Error('Collection#insertOne unimplemented by driver');\n};\n\n/**\n * Abstract method that drivers must implement.\n */\n\nCollection.prototype.insertMany = function() {\n  throw new Error('Collection#insertMany unimplemented by driver');\n};\n\n/**\n * Abstract method that drivers must implement.\n */\n\nCollection.prototype.save = function() {\n  throw new Error('Collection#save unimplemented by driver');\n};\n\n/**\n * Abstract method that drivers must implement.\n */\n\nCollection.prototype.updateOne = function() {\n  throw new Error('Collection#updateOne unimplemented by driver');\n};\n\n/**\n * Abstract method that drivers must implement.\n */\n\nCollection.prototype.updateMany = function() {\n  throw new Error('Collection#updateMany unimplemented by driver');\n};\n\n/**\n * Abstract method that drivers must implement.\n */\n\nCollection.prototype.deleteOne = function() {\n  throw new Error('Collection#deleteOne unimplemented by driver');\n};\n\n/**\n * Abstract method that drivers must implement.\n */\n\nCollection.prototype.deleteMany = function() {\n  throw new Error('Collection#deleteMany unimplemented by driver');\n};\n\n/**\n * Abstract method that drivers must implement.\n */\n\nCollection.prototype.getIndexes = function() {\n  throw new Error('Collection#getIndexes unimplemented by driver');\n};\n\n/**\n * Abstract method that drivers must implement.\n */\n\nCollection.prototype.watch = function() {\n  throw new Error('Collection#watch unimplemented by driver');\n};\n\n/*!\n * ignore\n */\n\nCollection.prototype._shouldBufferCommands = function _shouldBufferCommands() {\n  const opts = this.opts;\n\n  if (opts.bufferCommands != null) {\n    return opts.bufferCommands;\n  }\n  if (opts && opts.schemaUserProvidedOptions != null && opts.schemaUserProvidedOptions.bufferCommands != null) {\n    return opts.schemaUserProvidedOptions.bufferCommands;\n  }\n\n  return this.conn._shouldBufferCommands();\n};\n\n/*!\n * ignore\n */\n\nCollection.prototype._getBufferTimeoutMS = function _getBufferTimeoutMS() {\n  const conn = this.conn;\n  const opts = this.opts;\n\n  if (opts.bufferTimeoutMS != null) {\n    return opts.bufferTimeoutMS;\n  }\n  if (opts && opts.schemaUserProvidedOptions != null && opts.schemaUserProvidedOptions.bufferTimeoutMS != null) {\n    return opts.schemaUserProvidedOptions.bufferTimeoutMS;\n  }\n  if (conn.config.bufferTimeoutMS != null) {\n    return conn.config.bufferTimeoutMS;\n  }\n  if (conn.base != null && conn.base.get('bufferTimeoutMS') != null) {\n    return conn.base.get('bufferTimeoutMS');\n  }\n  return 10000;\n};\n\n/*!\n * Module exports.\n */\n\nmodule.exports = Collection;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/collection.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/connection.js":
/*!*************************************************!*\
  !*** ./node_modules/mongoose/lib/connection.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst ChangeStream = __webpack_require__(/*! ./cursor/changeStream */ \"./node_modules/mongoose/lib/cursor/changeStream.js\");\nconst EventEmitter = (__webpack_require__(/*! events */ \"events\").EventEmitter);\nconst Schema = __webpack_require__(/*! ./schema */ \"./node_modules/mongoose/lib/schema.js\");\nconst STATES = __webpack_require__(/*! ./connectionState */ \"./node_modules/mongoose/lib/connectionState.js\");\nconst MongooseError = __webpack_require__(/*! ./error/index */ \"./node_modules/mongoose/lib/error/index.js\");\nconst ServerSelectionError = __webpack_require__(/*! ./error/serverSelection */ \"./node_modules/mongoose/lib/error/serverSelection.js\");\nconst SyncIndexesError = __webpack_require__(/*! ./error/syncIndexes */ \"./node_modules/mongoose/lib/error/syncIndexes.js\");\nconst applyPlugins = __webpack_require__(/*! ./helpers/schema/applyPlugins */ \"./node_modules/mongoose/lib/helpers/schema/applyPlugins.js\");\nconst clone = __webpack_require__(/*! ./helpers/clone */ \"./node_modules/mongoose/lib/helpers/clone.js\");\nconst driver = __webpack_require__(/*! ./driver */ \"./node_modules/mongoose/lib/driver.js\");\nconst get = __webpack_require__(/*! ./helpers/get */ \"./node_modules/mongoose/lib/helpers/get.js\");\nconst immediate = __webpack_require__(/*! ./helpers/immediate */ \"./node_modules/mongoose/lib/helpers/immediate.js\");\nconst utils = __webpack_require__(/*! ./utils */ \"./node_modules/mongoose/lib/utils.js\");\nconst CreateCollectionsError = __webpack_require__(/*! ./error/createCollectionsError */ \"./node_modules/mongoose/lib/error/createCollectionsError.js\");\n\nconst arrayAtomicsSymbol = (__webpack_require__(/*! ./helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").arrayAtomicsSymbol);\nconst sessionNewDocuments = (__webpack_require__(/*! ./helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").sessionNewDocuments);\n\n/**\n * A list of authentication mechanisms that don't require a password for authentication.\n * This is used by the authMechanismDoesNotRequirePassword method.\n *\n * @api private\n */\nconst noPasswordAuthMechanisms = [\n  'MONGODB-X509'\n];\n\n/**\n * Connection constructor\n *\n * For practical reasons, a Connection equals a Db.\n *\n * @param {Mongoose} base a mongoose instance\n * @inherits NodeJS EventEmitter https://nodejs.org/api/events.html#class-eventemitter\n * @event `connecting`: Emitted when `connection.openUri()` is executed on this connection.\n * @event `connected`: Emitted when this connection successfully connects to the db. May be emitted _multiple_ times in `reconnected` scenarios.\n * @event `open`: Emitted after we `connected` and `onOpen` is executed on all of this connection's models.\n * @event `disconnecting`: Emitted when `connection.close()` was executed.\n * @event `disconnected`: Emitted after getting disconnected from the db.\n * @event `close`: Emitted after we `disconnected` and `onClose` executed on all of this connection's models.\n * @event `reconnected`: Emitted after we `connected` and subsequently `disconnected`, followed by successfully another successful connection.\n * @event `error`: Emitted when an error occurs on this connection.\n * @event `operation-start`: Emitted when a call to the MongoDB Node.js driver, like a `find()` or `insertOne()`, happens on any collection tied to this connection.\n * @event `operation-end`: Emitted when a call to the MongoDB Node.js driver, like a `find()` or `insertOne()`, either succeeds or errors.\n * @api public\n */\n\nfunction Connection(base) {\n  this.base = base;\n  this.collections = {};\n  this.models = {};\n  this.config = {};\n  this.replica = false;\n  this.options = null;\n  this.otherDbs = []; // FIXME: To be replaced with relatedDbs\n  this.relatedDbs = {}; // Hashmap of other dbs that share underlying connection\n  this.states = STATES;\n  this._readyState = STATES.disconnected;\n  this._closeCalled = false;\n  this._hasOpened = false;\n  this.plugins = [];\n  if (typeof base === 'undefined' || !base.connections.length) {\n    this.id = 0;\n  } else {\n    this.id = base.nextConnectionId;\n  }\n  this._queue = [];\n}\n\n/*!\n * Inherit from EventEmitter\n */\n\nObject.setPrototypeOf(Connection.prototype, EventEmitter.prototype);\n\n/**\n * Connection ready state\n *\n * - 0 = disconnected\n * - 1 = connected\n * - 2 = connecting\n * - 3 = disconnecting\n *\n * Each state change emits its associated event name.\n *\n * #### Example:\n *\n *     conn.on('connected', callback);\n *     conn.on('disconnected', callback);\n *\n * @property readyState\n * @memberOf Connection\n * @instance\n * @api public\n */\n\nObject.defineProperty(Connection.prototype, 'readyState', {\n  get: function() {\n    return this._readyState;\n  },\n  set: function(val) {\n    if (!(val in STATES)) {\n      throw new Error('Invalid connection state: ' + val);\n    }\n\n    if (this._readyState !== val) {\n      this._readyState = val;\n      // [legacy] loop over the otherDbs on this connection and change their state\n      for (const db of this.otherDbs) {\n        db.readyState = val;\n      }\n\n      if (STATES.connected === val) {\n        this._hasOpened = true;\n      }\n\n      this.emit(STATES[val]);\n    }\n  }\n});\n\n/**\n * Gets the value of the option `key`. Equivalent to `conn.options[key]`\n *\n * #### Example:\n *\n *     conn.get('test'); // returns the 'test' value\n *\n * @param {String} key\n * @method get\n * @api public\n */\n\nConnection.prototype.get = function(key) {\n  if (this.config.hasOwnProperty(key)) {\n    return this.config[key];\n  }\n\n  return get(this.options, key);\n};\n\n/**\n * Sets the value of the option `key`. Equivalent to `conn.options[key] = val`\n *\n * Supported options include:\n *\n * - `maxTimeMS`: Set [`maxTimeMS`](https://mongoosejs.com/docs/api/query.html#Query.prototype.maxTimeMS()) for all queries on this connection.\n * - 'debug': If `true`, prints the operations mongoose sends to MongoDB to the console. If a writable stream is passed, it will log to that stream, without colorization. If a callback function is passed, it will receive the collection name, the method name, then all arugments passed to the method. For example, if you wanted to replicate the default logging, you could output from the callback `Mongoose: ${collectionName}.${methodName}(${methodArgs.join(', ')})`.\n *\n * #### Example:\n *\n *     conn.set('test', 'foo');\n *     conn.get('test'); // 'foo'\n *     conn.options.test; // 'foo'\n *\n * @param {String} key\n * @param {Any} val\n * @method set\n * @api public\n */\n\nConnection.prototype.set = function(key, val) {\n  if (this.config.hasOwnProperty(key)) {\n    this.config[key] = val;\n    return val;\n  }\n\n  this.options = this.options || {};\n  this.options[key] = val;\n  return val;\n};\n\n/**\n * A hash of the collections associated with this connection\n *\n * @property collections\n * @memberOf Connection\n * @instance\n * @api public\n */\n\nConnection.prototype.collections;\n\n/**\n * The name of the database this connection points to.\n *\n * #### Example:\n *\n *     mongoose.createConnection('mongodb://127.0.0.1:27017/mydb').name; // \"mydb\"\n *\n * @property name\n * @memberOf Connection\n * @instance\n * @api public\n */\n\nConnection.prototype.name;\n\n/**\n * A [POJO](https://masteringjs.io/tutorials/fundamentals/pojo) containing\n * a map from model names to models. Contains all models that have been\n * added to this connection using [`Connection#model()`](https://mongoosejs.com/docs/api/connection.html#Connection.prototype.model()).\n *\n * #### Example:\n *\n *     const conn = mongoose.createConnection();\n *     const Test = conn.model('Test', mongoose.Schema({ name: String }));\n *\n *     Object.keys(conn.models).length; // 1\n *     conn.models.Test === Test; // true\n *\n * @property models\n * @memberOf Connection\n * @instance\n * @api public\n */\n\nConnection.prototype.models;\n\n/**\n * A number identifier for this connection. Used for debugging when\n * you have [multiple connections](https://mongoosejs.com/docs/connections.html#multiple_connections).\n *\n * #### Example:\n *\n *     // The default connection has `id = 0`\n *     mongoose.connection.id; // 0\n *\n *     // If you create a new connection, Mongoose increments id\n *     const conn = mongoose.createConnection();\n *     conn.id; // 1\n *\n * @property id\n * @memberOf Connection\n * @instance\n * @api public\n */\n\nConnection.prototype.id;\n\n/**\n * The plugins that will be applied to all models created on this connection.\n *\n * #### Example:\n *\n *     const db = mongoose.createConnection('mongodb://127.0.0.1:27017/mydb');\n *     db.plugin(() => console.log('Applied'));\n *     db.plugins.length; // 1\n *\n *     db.model('Test', new Schema({})); // Prints \"Applied\"\n *\n * @property plugins\n * @memberOf Connection\n * @instance\n * @api public\n */\n\nObject.defineProperty(Connection.prototype, 'plugins', {\n  configurable: false,\n  enumerable: true,\n  writable: true\n});\n\n/**\n * The host name portion of the URI. If multiple hosts, such as a replica set,\n * this will contain the first host name in the URI\n *\n * #### Example:\n *\n *     mongoose.createConnection('mongodb://127.0.0.1:27017/mydb').host; // \"127.0.0.1\"\n *\n * @property host\n * @memberOf Connection\n * @instance\n * @api public\n */\n\nObject.defineProperty(Connection.prototype, 'host', {\n  configurable: true,\n  enumerable: true,\n  writable: true\n});\n\n/**\n * The port portion of the URI. If multiple hosts, such as a replica set,\n * this will contain the port from the first host name in the URI.\n *\n * #### Example:\n *\n *     mongoose.createConnection('mongodb://127.0.0.1:27017/mydb').port; // 27017\n *\n * @property port\n * @memberOf Connection\n * @instance\n * @api public\n */\n\nObject.defineProperty(Connection.prototype, 'port', {\n  configurable: true,\n  enumerable: true,\n  writable: true\n});\n\n/**\n * The username specified in the URI\n *\n * #### Example:\n *\n *     mongoose.createConnection('mongodb://val:psw@127.0.0.1:27017/mydb').user; // \"val\"\n *\n * @property user\n * @memberOf Connection\n * @instance\n * @api public\n */\n\nObject.defineProperty(Connection.prototype, 'user', {\n  configurable: true,\n  enumerable: true,\n  writable: true\n});\n\n/**\n * The password specified in the URI\n *\n * #### Example:\n *\n *     mongoose.createConnection('mongodb://val:psw@127.0.0.1:27017/mydb').pass; // \"psw\"\n *\n * @property pass\n * @memberOf Connection\n * @instance\n * @api public\n */\n\nObject.defineProperty(Connection.prototype, 'pass', {\n  configurable: true,\n  enumerable: true,\n  writable: true\n});\n\n/**\n * The mongodb.Db instance, set when the connection is opened\n *\n * @property db\n * @memberOf Connection\n * @instance\n * @api public\n */\n\nConnection.prototype.db;\n\n/**\n * The MongoClient instance this connection uses to talk to MongoDB. Mongoose automatically sets this property\n * when the connection is opened.\n *\n * @property client\n * @memberOf Connection\n * @instance\n * @api public\n */\n\nConnection.prototype.client;\n\n/**\n * A hash of the global options that are associated with this connection\n *\n * @property config\n * @memberOf Connection\n * @instance\n * @api public\n */\n\nConnection.prototype.config;\n\n/**\n * Helper for `createCollection()`. Will explicitly create the given collection\n * with specified options. Used to create [capped collections](https://www.mongodb.com/docs/manual/core/capped-collections/)\n * and [views](https://www.mongodb.com/docs/manual/core/views/) from mongoose.\n *\n * Options are passed down without modification to the [MongoDB driver's `createCollection()` function](https://mongodb.github.io/node-mongodb-native/4.9/classes/Db.html#createCollection)\n *\n * @method createCollection\n * @param {string} collection The collection to create\n * @param {Object} [options] see [MongoDB driver docs](https://mongodb.github.io/node-mongodb-native/4.9/classes/Db.html#createCollection)\n * @return {Promise}\n * @api public\n */\n\nConnection.prototype.createCollection = async function createCollection(collection, options) {\n  if (typeof options === 'function' || (arguments.length >= 3 && typeof arguments[2] === 'function')) {\n    throw new MongooseError('Connection.prototype.createCollection() no longer accepts a callback');\n  }\n\n  await this._waitForConnect();\n\n  return this.db.createCollection(collection, options);\n};\n\n/**\n * Calls `createCollection()` on a models in a series.\n *\n * @method createCollections\n * @param {Boolean} continueOnError When true, will continue to create collections and create a new error class for the collections that errored.\n * @returns {Promise}\n * @api public\n */\n\nConnection.prototype.createCollections = async function createCollections(options = {}) {\n  const result = {};\n  const errorsMap = { };\n\n  const { continueOnError } = options;\n  delete options.continueOnError;\n  for (const model of Object.values(this.models)) {\n    try {\n      result[model.modelName] = await model.createCollection({});\n    } catch (err) {\n      if (!continueOnError) {\n        errorsMap[model.modelName] = err;\n        break;\n      } else {\n        result[model.modelName] = err;\n      }\n    }\n  }\n\n  if (!continueOnError && Object.keys(errorsMap).length) {\n    const message = Object.entries(errorsMap).map(([modelName, err]) => `${modelName}: ${err.message}`).join(', ');\n    const createCollectionsError = new CreateCollectionsError(message, errorsMap);\n    throw createCollectionsError;\n  }\n  return result;\n};\n\n/**\n * A convenience wrapper for `connection.client.withSession()`.\n *\n * #### Example:\n *\n *     await conn.withSession(async session => {\n *       const doc = await TestModel.findOne().session(session);\n *     });\n *\n * @method withSession\n * @param {Function} executor called with 1 argument: a `ClientSession` instance\n * @return {Promise} resolves to the return value of the executor function\n * @api public\n */\n\nConnection.prototype.withSession = async function withSession(executor) {\n  if (arguments.length === 0) {\n    throw new Error('Please provide an executor function');\n  }\n  return await this.client.withSession(executor);\n};\n\n/**\n * _Requires MongoDB >= 3.6.0._ Starts a [MongoDB session](https://www.mongodb.com/docs/manual/release-notes/3.6/#client-sessions)\n * for benefits like causal consistency, [retryable writes](https://www.mongodb.com/docs/manual/core/retryable-writes/),\n * and [transactions](https://thecodebarbarian.com/a-node-js-perspective-on-mongodb-4-transactions.html).\n *\n * #### Example:\n *\n *     const session = await conn.startSession();\n *     let doc = await Person.findOne({ name: 'Ned Stark' }, null, { session });\n *     await doc.remove();\n *     // `doc` will always be null, even if reading from a replica set\n *     // secondary. Without causal consistency, it is possible to\n *     // get a doc back from the below query if the query reads from a\n *     // secondary that is experiencing replication lag.\n *     doc = await Person.findOne({ name: 'Ned Stark' }, null, { session, readPreference: 'secondary' });\n *\n *\n * @method startSession\n * @param {Object} [options] see the [mongodb driver options](https://mongodb.github.io/node-mongodb-native/4.9/classes/MongoClient.html#startSession)\n * @param {Boolean} [options.causalConsistency=true] set to false to disable causal consistency\n * @return {Promise<ClientSession>} promise that resolves to a MongoDB driver `ClientSession`\n * @api public\n */\n\nConnection.prototype.startSession = async function startSession(options) {\n  if (arguments.length >= 2 && typeof arguments[1] === 'function') {\n    throw new MongooseError('Connection.prototype.startSession() no longer accepts a callback');\n  }\n\n  await this._waitForConnect();\n\n  const session = this.client.startSession(options);\n  return session;\n};\n\n/**\n * _Requires MongoDB >= 3.6.0._ Executes the wrapped async function\n * in a transaction. Mongoose will commit the transaction if the\n * async function executes successfully and attempt to retry if\n * there was a retriable error.\n *\n * Calls the MongoDB driver's [`session.withTransaction()`](https://mongodb.github.io/node-mongodb-native/4.9/classes/ClientSession.html#withTransaction),\n * but also handles resetting Mongoose document state as shown below.\n *\n * #### Example:\n *\n *     const doc = new Person({ name: 'Will Riker' });\n *     await db.transaction(async function setRank(session) {\n *       doc.rank = 'Captain';\n *       await doc.save({ session });\n *       doc.isNew; // false\n *\n *       // Throw an error to abort the transaction\n *       throw new Error('Oops!');\n *     },{ readPreference: 'primary' }).catch(() => {});\n *\n *     // true, `transaction()` reset the document's state because the\n *     // transaction was aborted.\n *     doc.isNew;\n *\n * @method transaction\n * @param {Function} fn Function to execute in a transaction\n * @param {mongodb.TransactionOptions} [options] Optional settings for the transaction\n * @return {Promise<Any>} promise that is fulfilled if Mongoose successfully committed the transaction, or rejects if the transaction was aborted or if Mongoose failed to commit the transaction. If fulfilled, the promise resolves to a MongoDB command result.\n * @api public\n */\n\nConnection.prototype.transaction = function transaction(fn, options) {\n  return this.startSession().then(session => {\n    session[sessionNewDocuments] = new Map();\n    return session.withTransaction(() => _wrapUserTransaction(fn, session, this.base), options).\n      then(res => {\n        delete session[sessionNewDocuments];\n        return res;\n      }).\n      catch(err => {\n        delete session[sessionNewDocuments];\n        throw err;\n      }).\n      finally(() => {\n        session.endSession().catch(() => {});\n      });\n  });\n};\n\n/*!\n * Reset document state in between transaction retries re: gh-13698\n */\n\nasync function _wrapUserTransaction(fn, session, mongoose) {\n  try {\n    const res = mongoose.transactionAsyncLocalStorage == null\n      ? await fn(session)\n      : await new Promise(resolve => {\n        mongoose.transactionAsyncLocalStorage.run(\n          { session },\n          () => resolve(fn(session))\n        );\n      });\n    return res;\n  } catch (err) {\n    _resetSessionDocuments(session);\n    throw err;\n  }\n}\n\n/*!\n * If transaction was aborted, we need to reset newly inserted documents' `isNew`.\n */\nfunction _resetSessionDocuments(session) {\n  for (const doc of session[sessionNewDocuments].keys()) {\n    const state = session[sessionNewDocuments].get(doc);\n    if (state.hasOwnProperty('isNew')) {\n      doc.$isNew = state.isNew;\n    }\n    if (state.hasOwnProperty('versionKey')) {\n      doc.set(doc.schema.options.versionKey, state.versionKey);\n    }\n\n    if (state.modifiedPaths.length > 0 && doc.$__.activePaths.states.modify == null) {\n      doc.$__.activePaths.states.modify = {};\n    }\n    for (const path of state.modifiedPaths) {\n      const currentState = doc.$__.activePaths.paths[path];\n      if (currentState != null) {\n        delete doc.$__.activePaths[currentState][path];\n      }\n      doc.$__.activePaths.paths[path] = 'modify';\n      doc.$__.activePaths.states.modify[path] = true;\n    }\n\n    for (const path of state.atomics.keys()) {\n      const val = doc.$__getValue(path);\n      if (val == null) {\n        continue;\n      }\n      val[arrayAtomicsSymbol] = state.atomics.get(path);\n    }\n  }\n}\n\n/**\n * Helper for `dropCollection()`. Will delete the given collection, including\n * all documents and indexes.\n *\n * @method dropCollection\n * @param {string} collection The collection to delete\n * @return {Promise}\n * @api public\n */\n\nConnection.prototype.dropCollection = async function dropCollection(collection) {\n  if (arguments.length >= 2 && typeof arguments[1] === 'function') {\n    throw new MongooseError('Connection.prototype.dropCollection() no longer accepts a callback');\n  }\n\n  await this._waitForConnect();\n\n  return this.db.dropCollection(collection);\n};\n\n/**\n * Waits for connection to be established, so the connection has a `client`\n *\n * @return Promise\n * @api private\n */\n\nConnection.prototype._waitForConnect = async function _waitForConnect() {\n  if ((this.readyState === STATES.connecting || this.readyState === STATES.disconnected) && this._shouldBufferCommands()) {\n    await new Promise(resolve => {\n      this._queue.push({ fn: resolve });\n    });\n  }\n};\n\n/**\n * Helper for MongoDB Node driver's `listCollections()`.\n * Returns an array of collection objects.\n *\n * @method listCollections\n * @return {Promise<Collection[]>}\n * @api public\n */\n\nConnection.prototype.listCollections = async function listCollections() {\n  await this._waitForConnect();\n\n  const cursor = this.db.listCollections();\n  return await cursor.toArray();\n};\n\n/**\n * Helper for MongoDB Node driver's `listDatabases()`.\n * Returns an object with a `databases` property that contains an\n * array of database objects.\n *\n * #### Example:\n *     const { databases } = await mongoose.connection.listDatabases();\n *     databases; // [{ name: 'mongoose_test', sizeOnDisk: 0, empty: false }]\n *\n * @method listCollections\n * @return {Promise<{ databases: Array<{ name: string }> }>}\n * @api public\n */\n\nConnection.prototype.listDatabases = async function listDatabases() {\n  // Implemented in `lib/drivers/node-mongodb-native/connection.js`\n  throw new MongooseError('listDatabases() not implemented by driver');\n};\n\n/**\n * Helper for `dropDatabase()`. Deletes the given database, including all\n * collections, documents, and indexes.\n *\n * #### Example:\n *\n *     const conn = mongoose.createConnection('mongodb://127.0.0.1:27017/mydb');\n *     // Deletes the entire 'mydb' database\n *     await conn.dropDatabase();\n *\n * @method dropDatabase\n * @return {Promise}\n * @api public\n */\n\nConnection.prototype.dropDatabase = async function dropDatabase() {\n  if (arguments.length >= 1 && typeof arguments[0] === 'function') {\n    throw new MongooseError('Connection.prototype.dropDatabase() no longer accepts a callback');\n  }\n\n  await this._waitForConnect();\n\n  // If `dropDatabase()` is called, this model's collection will not be\n  // init-ed. It is sufficiently common to call `dropDatabase()` after\n  // `mongoose.connect()` but before creating models that we want to\n  // support this. See gh-6796\n  for (const model of Object.values(this.models)) {\n    delete model.$init;\n  }\n\n  return this.db.dropDatabase();\n};\n\n/*!\n * ignore\n */\n\nConnection.prototype._shouldBufferCommands = function _shouldBufferCommands() {\n  if (this.config.bufferCommands != null) {\n    return this.config.bufferCommands;\n  }\n  if (this.base.get('bufferCommands') != null) {\n    return this.base.get('bufferCommands');\n  }\n  return true;\n};\n\n/**\n * error\n *\n * Graceful error handling, passes error to callback\n * if available, else emits error on the connection.\n *\n * @param {Error} err\n * @param {Function} callback optional\n * @emits \"error\" Emits the `error` event with the given `err`, unless a callback is specified\n * @returns {Promise|null} Returns a rejected Promise if no `callback` is given.\n * @api private\n */\n\nConnection.prototype.error = function(err, callback) {\n  if (callback) {\n    callback(err);\n    return null;\n  }\n  if (this.listeners('error').length > 0) {\n    this.emit('error', err);\n  }\n  return Promise.reject(err);\n};\n\n/**\n * Called when the connection is opened\n *\n * @api private\n */\n\nConnection.prototype.onOpen = function() {\n  this.readyState = STATES.connected;\n\n  for (const d of this._queue) {\n    d.fn.apply(d.ctx, d.args);\n  }\n  this._queue = [];\n\n  // avoid having the collection subscribe to our event emitter\n  // to prevent 0.3 warning\n  for (const i in this.collections) {\n    if (utils.object.hasOwnProperty(this.collections, i)) {\n      this.collections[i].onOpen();\n    }\n  }\n\n  this.emit('open');\n};\n\n/**\n * Opens the connection with a URI using `MongoClient.connect()`.\n *\n * @param {String} uri The URI to connect with.\n * @param {Object} [options] Passed on to [`MongoClient.connect`](https://mongodb.github.io/node-mongodb-native/4.9/classes/MongoClient.html#connect-1)\n * @param {Boolean} [options.bufferCommands=true] Mongoose specific option. Set to false to [disable buffering](https://mongoosejs.com/docs/faq.html#callback_never_executes) on all models associated with this connection.\n * @param {Number} [options.bufferTimeoutMS=10000] Mongoose specific option. If `bufferCommands` is true, Mongoose will throw an error after `bufferTimeoutMS` if the operation is still buffered.\n * @param {String} [options.dbName] The name of the database we want to use. If not provided, use database name from connection string.\n * @param {String} [options.user] username for authentication, equivalent to `options.auth.user`. Maintained for backwards compatibility.\n * @param {String} [options.pass] password for authentication, equivalent to `options.auth.password`. Maintained for backwards compatibility.\n * @param {Number} [options.maxPoolSize=100] The maximum number of sockets the MongoDB driver will keep open for this connection. Keep in mind that MongoDB only allows one operation per socket at a time, so you may want to increase this if you find you have a few slow queries that are blocking faster queries from proceeding. See [Slow Trains in MongoDB and Node.js](https://thecodebarbarian.com/slow-trains-in-mongodb-and-nodejs).\n * @param {Number} [options.minPoolSize=0] The minimum number of sockets the MongoDB driver will keep open for this connection. Keep in mind that MongoDB only allows one operation per socket at a time, so you may want to increase this if you find you have a few slow queries that are blocking faster queries from proceeding. See [Slow Trains in MongoDB and Node.js](https://thecodebarbarian.com/slow-trains-in-mongodb-and-nodejs).\n * @param {Number} [options.serverSelectionTimeoutMS] If `useUnifiedTopology = true`, the MongoDB driver will try to find a server to send any given operation to, and keep retrying for `serverSelectionTimeoutMS` milliseconds before erroring out. If not set, the MongoDB driver defaults to using `30000` (30 seconds).\n * @param {Number} [options.heartbeatFrequencyMS] If `useUnifiedTopology = true`, the MongoDB driver sends a heartbeat every `heartbeatFrequencyMS` to check on the status of the connection. A heartbeat is subject to `serverSelectionTimeoutMS`, so the MongoDB driver will retry failed heartbeats for up to 30 seconds by default. Mongoose only emits a `'disconnected'` event after a heartbeat has failed, so you may want to decrease this setting to reduce the time between when your server goes down and when Mongoose emits `'disconnected'`. We recommend you do **not** set this setting below 1000, too many heartbeats can lead to performance degradation.\n * @param {Boolean} [options.autoIndex=true] Mongoose-specific option. Set to false to disable automatic index creation for all models associated with this connection.\n * @param {Class} [options.promiseLibrary] Sets the [underlying driver's promise library](https://mongodb.github.io/node-mongodb-native/4.9/interfaces/MongoClientOptions.html#promiseLibrary).\n * @param {Number} [options.socketTimeoutMS=0] How long the MongoDB driver will wait before killing a socket due to inactivity _after initial connection_. A socket may be inactive because of either no activity or a long-running operation. `socketTimeoutMS` defaults to 0, which means Node.js will not time out the socket due to inactivity. This option is passed to [Node.js `socket#setTimeout()` function](https://nodejs.org/api/net.html#net_socket_settimeout_timeout_callback) after the MongoDB driver successfully completes.\n * @param {Number} [options.family=0] Passed transparently to [Node.js' `dns.lookup()`](https://nodejs.org/api/dns.html#dns_dns_lookup_hostname_options_callback) function. May be either `0, `4`, or `6`. `4` means use IPv4 only, `6` means use IPv6 only, `0` means try both.\n * @param {Boolean} [options.autoCreate=false] Set to `true` to make Mongoose automatically call `createCollection()` on every model created on this connection.\n * @returns {Promise<Connection>}\n * @api public\n */\n\nConnection.prototype.openUri = async function openUri(uri, options) {\n  if (this.readyState === STATES.connecting || this.readyState === STATES.connected) {\n    if (this._connectionString === uri) {\n      return this;\n    }\n  }\n\n  this._closeCalled = false;\n\n  // Internal option to skip `await this.$initialConnection` in\n  // this function for `createConnection()`. Because otherwise\n  // `createConnection()` would have an uncatchable error.\n  let _fireAndForget = false;\n  if (options && '_fireAndForget' in options) {\n    _fireAndForget = options._fireAndForget;\n    delete options._fireAndForget;\n  }\n\n  try {\n    _validateArgs.apply(arguments);\n  } catch (err) {\n    if (_fireAndForget) {\n      throw err;\n    }\n    this.$initialConnection = Promise.reject(err);\n    throw err;\n  }\n\n  this.$initialConnection = this.createClient(uri, options).\n    then(() => this).\n    catch(err => {\n      this.readyState = STATES.disconnected;\n      if (this.listeners('error').length > 0) {\n        immediate(() => this.emit('error', err));\n      }\n      throw err;\n    });\n\n  for (const model of Object.values(this.models)) {\n    // Errors handled internally, so safe to ignore error\n    model.init().catch(function $modelInitNoop() {});\n  }\n\n  // `createConnection()` calls this `openUri()` function without\n  // awaiting on the result, so we set this option to rely on\n  // `asPromise()` to handle any errors.\n  if (_fireAndForget) {\n    return this;\n  }\n\n  try {\n    await this.$initialConnection;\n  } catch (err) {\n    throw _handleConnectionErrors(err);\n  }\n\n  return this;\n};\n\n/*!\n * Treat `on('error')` handlers as handling the initialConnection promise\n * to avoid uncaught exceptions when using `on('error')`. See gh-14377.\n */\n\nConnection.prototype.on = function on(event, callback) {\n  if (event === 'error' && this.$initialConnection) {\n    this.$initialConnection.catch(() => {});\n  }\n  return EventEmitter.prototype.on.call(this, event, callback);\n};\n\n/*!\n * Treat `once('error')` handlers as handling the initialConnection promise\n * to avoid uncaught exceptions when using `on('error')`. See gh-14377.\n */\n\nConnection.prototype.once = function on(event, callback) {\n  if (event === 'error' && this.$initialConnection) {\n    this.$initialConnection.catch(() => {});\n  }\n  return EventEmitter.prototype.once.call(this, event, callback);\n};\n\n/*!\n * ignore\n */\n\nfunction _validateArgs(uri, options, callback) {\n  if (typeof options === 'function' && callback == null) {\n    throw new MongooseError('Connection.prototype.openUri() no longer accepts a callback');\n  } else if (typeof callback === 'function') {\n    throw new MongooseError('Connection.prototype.openUri() no longer accepts a callback');\n  }\n}\n\n/*!\n * ignore\n */\n\nfunction _handleConnectionErrors(err) {\n  if (err?.name === 'MongoServerSelectionError') {\n    const originalError = err;\n    err = new ServerSelectionError();\n    err.assimilateError(originalError);\n  }\n\n  return err;\n}\n\n/**\n * Destroy the connection. Similar to [`.close`](https://mongoosejs.com/docs/api/connection.html#Connection.prototype.close()),\n * but also removes the connection from Mongoose's `connections` list and prevents the\n * connection from ever being re-opened.\n *\n * @param {Boolean} [force]\n * @returns {Promise}\n */\n\nConnection.prototype.destroy = async function destroy(force) {\n  if (typeof force === 'function' || (arguments.length === 2 && typeof arguments[1] === 'function')) {\n    throw new MongooseError('Connection.prototype.destroy() no longer accepts a callback');\n  }\n\n  if (force != null && typeof force === 'object') {\n    this.$wasForceClosed = !!force.force;\n  } else {\n    this.$wasForceClosed = !!force;\n  }\n\n  return this._close(force, true);\n};\n\n/**\n * Closes the connection\n *\n * @param {Boolean} [force] optional\n * @return {Promise}\n * @api public\n */\n\nConnection.prototype.close = async function close(force) {\n  if (typeof force === 'function' || (arguments.length === 2 && typeof arguments[1] === 'function')) {\n    throw new MongooseError('Connection.prototype.close() no longer accepts a callback');\n  }\n\n  if (force != null && typeof force === 'object') {\n    this.$wasForceClosed = !!force.force;\n  } else {\n    this.$wasForceClosed = !!force;\n  }\n\n  for (const model of Object.values(this.models)) {\n    // If manually disconnecting, make sure to clear each model's `$init`\n    // promise, so Mongoose knows to re-run `init()` in case the\n    // connection is re-opened. See gh-12047.\n    delete model.$init;\n  }\n\n  return this._close(force, false);\n};\n\n/**\n * Handles closing the connection\n *\n * @param {Boolean} force\n * @param {Boolean} destroy\n * @returns {Connection} this\n * @api private\n */\nConnection.prototype._close = async function _close(force, destroy) {\n  const _this = this;\n  const closeCalled = this._closeCalled;\n  this._closeCalled = true;\n  this._destroyCalled = destroy;\n  if (this.client != null) {\n    this.client._closeCalled = true;\n    this.client._destroyCalled = destroy;\n  }\n\n  const conn = this;\n  switch (this.readyState) {\n    case STATES.disconnected:\n      if (destroy && this.base.connections.indexOf(conn) !== -1) {\n        this.base.connections.splice(this.base.connections.indexOf(conn), 1);\n      }\n      if (!closeCalled) {\n        await this.doClose(force);\n        this.onClose(force);\n      }\n      break;\n\n    case STATES.connected:\n      this.readyState = STATES.disconnecting;\n      await this.doClose(force);\n      if (destroy && _this.base.connections.indexOf(conn) !== -1) {\n        this.base.connections.splice(this.base.connections.indexOf(conn), 1);\n      }\n      this.onClose(force);\n\n      break;\n    case STATES.connecting:\n      return new Promise((resolve, reject) => {\n        const _rerunClose = () => {\n          this.removeListener('open', _rerunClose);\n          this.removeListener('error', _rerunClose);\n          if (destroy) {\n            this.destroy(force).then(resolve, reject);\n          } else {\n            this.close(force).then(resolve, reject);\n          }\n        };\n\n        this.once('open', _rerunClose);\n        this.once('error', _rerunClose);\n      });\n\n    case STATES.disconnecting:\n      return new Promise(resolve => {\n        this.once('close', () => {\n          if (destroy && this.base.connections.indexOf(conn) !== -1) {\n            this.base.connections.splice(this.base.connections.indexOf(conn), 1);\n          }\n          resolve();\n        });\n      });\n  }\n\n  return this;\n};\n\n/**\n * Abstract method that drivers must implement.\n *\n * @api private\n */\n\nConnection.prototype.doClose = function() {\n  throw new Error('Connection#doClose unimplemented by driver');\n};\n\n/**\n * Called when the connection closes\n *\n * @api private\n */\n\nConnection.prototype.onClose = function(force) {\n  this.readyState = STATES.disconnected;\n\n  // avoid having the collection subscribe to our event emitter\n  // to prevent 0.3 warning\n  for (const i in this.collections) {\n    if (utils.object.hasOwnProperty(this.collections, i)) {\n      this.collections[i].onClose(force);\n    }\n  }\n\n  this.emit('close', force);\n\n  for (const db of this.otherDbs) {\n    this._destroyCalled ? db.destroy({ force: force, skipCloseClient: true }) : db.close({ force: force, skipCloseClient: true });\n  }\n};\n\n/**\n * Retrieves a raw collection instance, creating it if not cached.\n * This method returns a thin wrapper around a [MongoDB Node.js driver collection]([MongoDB Node.js driver collection](https://mongodb.github.io/node-mongodb-native/Next/classes/Collection.html)).\n * Using a Collection bypasses Mongoose middleware, validation, and casting,\n * letting you use [MongoDB Node.js driver](https://mongodb.github.io/node-mongodb-native/) functionality directly.\n *\n * @param {String} name of the collection\n * @param {Object} [options] optional collection options\n * @return {Collection} collection instance\n * @api public\n */\n\nConnection.prototype.collection = function(name, options) {\n  const defaultOptions = {\n    autoIndex: this.config.autoIndex != null ? this.config.autoIndex : this.base.options.autoIndex,\n    autoCreate: this.config.autoCreate != null ? this.config.autoCreate : this.base.options.autoCreate,\n    autoSearchIndex: this.config.autoSearchIndex != null ? this.config.autoSearchIndex : this.base.options.autoSearchIndex\n  };\n  options = Object.assign({}, defaultOptions, options ? clone(options) : {});\n  options.$wasForceClosed = this.$wasForceClosed;\n  const Collection = this.base && this.base.__driver && this.base.__driver.Collection || driver.get().Collection;\n  if (!(name in this.collections)) {\n    this.collections[name] = new Collection(name, this, options);\n  }\n  return this.collections[name];\n};\n\n/**\n * Declares a plugin executed on all schemas you pass to `conn.model()`\n *\n * Equivalent to calling `.plugin(fn)` on each schema you create.\n *\n * #### Example:\n *\n *     const db = mongoose.createConnection('mongodb://127.0.0.1:27017/mydb');\n *     db.plugin(() => console.log('Applied'));\n *     db.plugins.length; // 1\n *\n *     db.model('Test', new Schema({})); // Prints \"Applied\"\n *\n * @param {Function} fn plugin callback\n * @param {Object} [opts] optional options\n * @return {Connection} this\n * @see plugins https://mongoosejs.com/docs/plugins.html\n * @api public\n */\n\nConnection.prototype.plugin = function(fn, opts) {\n  this.plugins.push([fn, opts]);\n  return this;\n};\n\n/**\n * Defines or retrieves a model.\n *\n *     const mongoose = require('mongoose');\n *     const db = mongoose.createConnection(..);\n *     db.model('Venue', new Schema(..));\n *     const Ticket = db.model('Ticket', new Schema(..));\n *     const Venue = db.model('Venue');\n *\n * _When no `collection` argument is passed, Mongoose produces a collection name by passing the model `name` to the `utils.toCollectionName` method. This method pluralizes the name. If you don't like this behavior, either pass a collection name or set your schemas collection name option._\n *\n * #### Example:\n *\n *     const schema = new Schema({ name: String }, { collection: 'actor' });\n *\n *     // or\n *\n *     schema.set('collection', 'actor');\n *\n *     // or\n *\n *     const collectionName = 'actor'\n *     const M = conn.model('Actor', schema, collectionName)\n *\n * @param {String|Function} name the model name or class extending Model\n * @param {Schema} [schema] a schema. necessary when defining a model\n * @param {String} [collection] name of mongodb collection (optional) if not given it will be induced from model name\n * @param {Object} [options]\n * @param {Boolean} [options.overwriteModels=false] If true, overwrite existing models with the same name to avoid `OverwriteModelError`\n * @see Mongoose#model https://mongoosejs.com/docs/api/mongoose.html#Mongoose.prototype.model()\n * @return {Model} The compiled model\n * @api public\n */\n\nConnection.prototype.model = function(name, schema, collection, options) {\n  if (!(this instanceof Connection)) {\n    throw new MongooseError('`connection.model()` should not be run with ' +\n      '`new`. If you are doing `new db.model(foo)(bar)`, use ' +\n      '`db.model(foo)(bar)` instead');\n  }\n\n  let fn;\n  if (typeof name === 'function') {\n    fn = name;\n    name = fn.name;\n  }\n\n  // collection name discovery\n  if (typeof schema === 'string') {\n    collection = schema;\n    schema = false;\n  }\n\n  if (utils.isObject(schema)) {\n    if (!schema.instanceOfSchema) {\n      schema = new Schema(schema);\n    } else if (!(schema instanceof this.base.Schema)) {\n      schema = schema._clone(this.base.Schema);\n    }\n  }\n  if (schema && !schema.instanceOfSchema) {\n    throw new Error('The 2nd parameter to `mongoose.model()` should be a ' +\n      'schema or a POJO');\n  }\n\n  const defaultOptions = { cache: false, overwriteModels: this.base.options.overwriteModels };\n  const opts = Object.assign(defaultOptions, options, { connection: this });\n  if (this.models[name] && !collection && opts.overwriteModels !== true) {\n    // model exists but we are not subclassing with custom collection\n    if (schema && schema.instanceOfSchema && schema !== this.models[name].schema) {\n      throw new MongooseError.OverwriteModelError(name);\n    }\n    return this.models[name];\n  }\n\n  let model;\n\n  if (schema && schema.instanceOfSchema) {\n    applyPlugins(schema, this.plugins, null, '$connectionPluginsApplied');\n\n    // compile a model\n    model = this.base._model(fn || name, schema, collection, opts);\n\n    // only the first model with this name is cached to allow\n    // for one-offs with custom collection names etc.\n    if (!this.models[name]) {\n      this.models[name] = model;\n    }\n\n    // Errors handled internally, so safe to ignore error\n    model.init().catch(function $modelInitNoop() {});\n\n    return model;\n  }\n\n  if (this.models[name] && collection) {\n    // subclassing current model with alternate collection\n    model = this.models[name];\n    schema = model.prototype.schema;\n    const sub = model.__subclass(this, schema, collection);\n    // do not cache the sub model\n    return sub;\n  }\n\n  if (arguments.length === 1) {\n    model = this.models[name];\n    if (!model) {\n      throw new MongooseError.MissingSchemaError(name);\n    }\n    return model;\n  }\n\n  if (!model) {\n    throw new MongooseError.MissingSchemaError(name);\n  }\n\n  if (this === model.prototype.db\n      && (!collection || collection === model.collection.name)) {\n    // model already uses this connection.\n\n    // only the first model with this name is cached to allow\n    // for one-offs with custom collection names etc.\n    if (!this.models[name]) {\n      this.models[name] = model;\n    }\n\n    return model;\n  }\n  this.models[name] = model.__subclass(this, schema, collection);\n  return this.models[name];\n};\n\n/**\n * Removes the model named `name` from this connection, if it exists. You can\n * use this function to clean up any models you created in your tests to\n * prevent OverwriteModelErrors.\n *\n * #### Example:\n *\n *     conn.model('User', new Schema({ name: String }));\n *     console.log(conn.model('User')); // Model object\n *     conn.deleteModel('User');\n *     console.log(conn.model('User')); // undefined\n *\n *     // Usually useful in a Mocha `afterEach()` hook\n *     afterEach(function() {\n *       conn.deleteModel(/.+/); // Delete every model\n *     });\n *\n * @api public\n * @param {String|RegExp} name if string, the name of the model to remove. If regexp, removes all models whose name matches the regexp.\n * @return {Connection} this\n */\n\nConnection.prototype.deleteModel = function(name) {\n  if (typeof name === 'string') {\n    const model = this.model(name);\n    if (model == null) {\n      return this;\n    }\n    const collectionName = model.collection.name;\n    delete this.models[name];\n    delete this.collections[collectionName];\n\n    this.emit('deleteModel', model);\n  } else if (name instanceof RegExp) {\n    const pattern = name;\n    const names = this.modelNames();\n    for (const name of names) {\n      if (pattern.test(name)) {\n        this.deleteModel(name);\n      }\n    }\n  } else {\n    throw new Error('First parameter to `deleteModel()` must be a string ' +\n      'or regexp, got \"' + name + '\"');\n  }\n\n  return this;\n};\n\n/**\n * Watches the entire underlying database for changes. Similar to\n * [`Model.watch()`](https://mongoosejs.com/docs/api/model.html#Model.watch()).\n *\n * This function does **not** trigger any middleware. In particular, it\n * does **not** trigger aggregate middleware.\n *\n * The ChangeStream object is an event emitter that emits the following events:\n *\n * - 'change': A change occurred, see below example\n * - 'error': An unrecoverable error occurred. In particular, change streams currently error out if they lose connection to the replica set primary. Follow [this GitHub issue](https://github.com/Automattic/mongoose/issues/6799) for updates.\n * - 'end': Emitted if the underlying stream is closed\n * - 'close': Emitted if the underlying stream is closed\n *\n * #### Example:\n *\n *     const User = conn.model('User', new Schema({ name: String }));\n *\n *     const changeStream = conn.watch().on('change', data => console.log(data));\n *\n *     // Triggers a 'change' event on the change stream.\n *     await User.create({ name: 'test' });\n *\n * @api public\n * @param {Array} [pipeline]\n * @param {Object} [options] passed without changes to [the MongoDB driver's `Db#watch()` function](https://mongodb.github.io/node-mongodb-native/4.9/classes/Db.html#watch)\n * @return {ChangeStream} mongoose-specific change stream wrapper, inherits from EventEmitter\n */\n\nConnection.prototype.watch = function(pipeline, options) {\n  const changeStreamThunk = cb => {\n    immediate(() => {\n      if (this.readyState === STATES.connecting) {\n        this.once('open', function() {\n          const driverChangeStream = this.db.watch(pipeline, options);\n          cb(null, driverChangeStream);\n        });\n      } else {\n        const driverChangeStream = this.db.watch(pipeline, options);\n        cb(null, driverChangeStream);\n      }\n    });\n  };\n\n  const changeStream = new ChangeStream(changeStreamThunk, pipeline, options);\n  return changeStream;\n};\n\n/**\n * Returns a promise that resolves when this connection\n * successfully connects to MongoDB, or rejects if this connection failed\n * to connect.\n *\n * #### Example:\n *\n *     const conn = await mongoose.createConnection('mongodb://127.0.0.1:27017/test').\n *       asPromise();\n *     conn.readyState; // 1, means Mongoose is connected\n *\n * @api public\n * @return {Promise}\n */\n\nConnection.prototype.asPromise = async function asPromise() {\n  try {\n    await this.$initialConnection;\n    return this;\n  } catch (err) {\n    throw _handleConnectionErrors(err);\n  }\n};\n\n/**\n * Returns an array of model names created on this connection.\n * @api public\n * @return {String[]}\n */\n\nConnection.prototype.modelNames = function() {\n  return Object.keys(this.models);\n};\n\n/**\n * Returns if the connection requires authentication after it is opened. Generally if a\n * username and password are both provided than authentication is needed, but in some cases a\n * password is not required.\n *\n * @api private\n * @return {Boolean} true if the connection should be authenticated after it is opened, otherwise false.\n */\nConnection.prototype.shouldAuthenticate = function() {\n  return this.user != null &&\n    (this.pass != null || this.authMechanismDoesNotRequirePassword());\n};\n\n/**\n * Returns a boolean value that specifies if the current authentication mechanism needs a\n * password to authenticate according to the auth objects passed into the openUri methods.\n *\n * @api private\n * @return {Boolean} true if the authentication mechanism specified in the options object requires\n *  a password, otherwise false.\n */\nConnection.prototype.authMechanismDoesNotRequirePassword = function() {\n  if (this.options && this.options.auth) {\n    return noPasswordAuthMechanisms.indexOf(this.options.auth.authMechanism) >= 0;\n  }\n  return true;\n};\n\n/**\n * Returns a boolean value that specifies if the provided objects object provides enough\n * data to authenticate with. Generally this is true if the username and password are both specified\n * but in some authentication methods, a password is not required for authentication so only a username\n * is required.\n *\n * @param {Object} [options] the options object passed into the openUri methods.\n * @api private\n * @return {Boolean} true if the provided options object provides enough data to authenticate with,\n *   otherwise false.\n */\nConnection.prototype.optionsProvideAuthenticationData = function(options) {\n  return (options) &&\n      (options.user) &&\n      ((options.pass) || this.authMechanismDoesNotRequirePassword());\n};\n\n/**\n * Returns the [MongoDB driver `MongoClient`](https://mongodb.github.io/node-mongodb-native/4.9/classes/MongoClient.html) instance\n * that this connection uses to talk to MongoDB.\n *\n * #### Example:\n *\n *     const conn = await mongoose.createConnection('mongodb://127.0.0.1:27017/test').\n *       asPromise();\n *\n *     conn.getClient(); // MongoClient { ... }\n *\n * @api public\n * @return {MongoClient}\n */\n\nConnection.prototype.getClient = function getClient() {\n  return this.client;\n};\n\n/**\n * Set the [MongoDB driver `MongoClient`](https://mongodb.github.io/node-mongodb-native/4.9/classes/MongoClient.html) instance\n * that this connection uses to talk to MongoDB. This is useful if you already have a MongoClient instance, and want to\n * reuse it.\n *\n * #### Example:\n *\n *     const client = await mongodb.MongoClient.connect('mongodb://127.0.0.1:27017/test');\n *\n *     const conn = mongoose.createConnection().setClient(client);\n *\n *     conn.getClient(); // MongoClient { ... }\n *     conn.readyState; // 1, means 'CONNECTED'\n *\n * @api public\n * @param {MongClient} client The Client to set to be used.\n * @return {Connection} this\n */\n\nConnection.prototype.setClient = function setClient() {\n  throw new MongooseError('Connection#setClient not implemented by driver');\n};\n\n/*!\n * Called internally by `openUri()` to create a MongoClient instance.\n */\n\nConnection.prototype.createClient = function createClient() {\n  throw new MongooseError('Connection#createClient not implemented by driver');\n};\n\n/**\n * Syncs all the indexes for the models registered with this connection.\n *\n * @param {Object} [options]\n * @param {Boolean} [options.continueOnError] `false` by default. If set to `true`, mongoose will not throw an error if one model syncing failed, and will return an object where the keys are the names of the models, and the values are the results/errors for each model.\n * @return {Promise<Object>} Returns a Promise, when the Promise resolves the value is a list of the dropped indexes.\n */\nConnection.prototype.syncIndexes = async function syncIndexes(options = {}) {\n  const result = {};\n  const errorsMap = { };\n\n  const { continueOnError } = options;\n  delete options.continueOnError;\n\n  for (const model of Object.values(this.models)) {\n    try {\n      result[model.modelName] = await model.syncIndexes(options);\n    } catch (err) {\n      if (!continueOnError) {\n        errorsMap[model.modelName] = err;\n        break;\n      } else {\n        result[model.modelName] = err;\n      }\n    }\n  }\n\n  if (!continueOnError && Object.keys(errorsMap).length) {\n    const message = Object.entries(errorsMap).map(([modelName, err]) => `${modelName}: ${err.message}`).join(', ');\n    const syncIndexesError = new SyncIndexesError(message, errorsMap);\n    throw syncIndexesError;\n  }\n\n  return result;\n};\n\n/**\n * Switches to a different database using the same [connection pool](https://mongoosejs.com/docs/api/connectionshtml#connection_pools).\n *\n * Returns a new connection object, with the new db.\n *\n * #### Example:\n *\n *     // Connect to `initialdb` first\n *     const conn = await mongoose.createConnection('mongodb://127.0.0.1:27017/initialdb').asPromise();\n *\n *     // Creates an un-cached connection to `mydb`\n *     const db = conn.useDb('mydb');\n *     // Creates a cached connection to `mydb2`. All calls to `conn.useDb('mydb2', { useCache: true })` will return the same\n *     // connection instance as opposed to creating a new connection instance\n *     const db2 = conn.useDb('mydb2', { useCache: true });\n *\n * @method useDb\n * @memberOf Connection\n * @param {String} name The database name\n * @param {Object} [options]\n * @param {Boolean} [options.useCache=false] If true, cache results so calling `useDb()` multiple times with the same name only creates 1 connection object.\n * @param {Boolean} [options.noListener=false] If true, the connection object will not make the db listen to events on the original connection. See [issue #9961](https://github.com/Automattic/mongoose/issues/9961).\n * @return {Connection} New Connection Object\n * @api public\n */\n\n/**\n * Removes the database connection with the given name created with with `useDb()`.\n *\n * Throws an error if the database connection was not found.\n *\n * #### Example:\n *\n *     // Connect to `initialdb` first\n *     const conn = await mongoose.createConnection('mongodb://127.0.0.1:27017/initialdb').asPromise();\n *\n *     // Creates an un-cached connection to `mydb`\n *     const db = conn.useDb('mydb');\n *\n *     // Closes `db`, and removes `db` from `conn.relatedDbs` and `conn.otherDbs`\n *     await conn.removeDb('mydb');\n *\n * @method removeDb\n * @memberOf Connection\n * @param {String} name The database name\n * @return {Connection} this\n * @api public\n */\n\n/*!\n * Module exports.\n */\n\nConnection.STATES = STATES;\nmodule.exports = Connection;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/connection.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/connectionState.js":
/*!******************************************************!*\
  !*** ./node_modules/mongoose/lib/connectionState.js ***!
  \******************************************************/
/***/ ((module, exports) => {

"use strict";
eval("\n/*!\n * Connection states\n */\n\n\n\nconst STATES = module.exports = exports = Object.create(null);\n\nconst disconnected = 'disconnected';\nconst connected = 'connected';\nconst connecting = 'connecting';\nconst disconnecting = 'disconnecting';\nconst uninitialized = 'uninitialized';\n\nSTATES[0] = disconnected;\nSTATES[1] = connected;\nSTATES[2] = connecting;\nSTATES[3] = disconnecting;\nSTATES[99] = uninitialized;\n\nSTATES[disconnected] = 0;\nSTATES[connected] = 1;\nSTATES[connecting] = 2;\nSTATES[disconnecting] = 3;\nSTATES[uninitialized] = 99;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/connectionState.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/constants.js":
/*!************************************************!*\
  !*** ./node_modules/mongoose/lib/constants.js ***!
  \************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\n/*!\n * ignore\n */\n\nconst queryOperations = Object.freeze([\n  // Read\n  'countDocuments',\n  'distinct',\n  'estimatedDocumentCount',\n  'find',\n  'findOne',\n  // Update\n  'findOneAndReplace',\n  'findOneAndUpdate',\n  'replaceOne',\n  'updateMany',\n  'updateOne',\n  // Delete\n  'deleteMany',\n  'deleteOne',\n  'findOneAndDelete'\n]);\n\nexports.queryOperations = queryOperations;\n\n/*!\n * ignore\n */\n\nconst queryMiddlewareFunctions = queryOperations.concat([\n  'validate'\n]);\n\nexports.queryMiddlewareFunctions = queryMiddlewareFunctions;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/constants.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/cursor/aggregationCursor.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongoose/lib/cursor/aggregationCursor.js ***!
  \***************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module dependencies.\n */\n\n\n\nconst MongooseError = __webpack_require__(/*! ../error/mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\nconst Readable = (__webpack_require__(/*! stream */ \"stream\").Readable);\nconst eachAsync = __webpack_require__(/*! ../helpers/cursor/eachAsync */ \"./node_modules/mongoose/lib/helpers/cursor/eachAsync.js\");\nconst immediate = __webpack_require__(/*! ../helpers/immediate */ \"./node_modules/mongoose/lib/helpers/immediate.js\");\nconst util = __webpack_require__(/*! util */ \"util\");\n\n/**\n * An AggregationCursor is a concurrency primitive for processing aggregation\n * results one document at a time. It is analogous to QueryCursor.\n *\n * An AggregationCursor fulfills the Node.js streams3 API,\n * in addition to several other mechanisms for loading documents from MongoDB\n * one at a time.\n *\n * Creating an AggregationCursor executes the model's pre aggregate hooks,\n * but **not** the model's post aggregate hooks.\n *\n * Unless you're an advanced user, do **not** instantiate this class directly.\n * Use [`Aggregate#cursor()`](https://mongoosejs.com/docs/api/aggregate.html#Aggregate.prototype.cursor()) instead.\n *\n * @param {Aggregate} agg\n * @inherits Readable https://nodejs.org/api/stream.html#class-streamreadable\n * @event `cursor`: Emitted when the cursor is created\n * @event `error`: Emitted when an error occurred\n * @event `data`: Emitted when the stream is flowing and the next doc is ready\n * @event `end`: Emitted when the stream is exhausted\n * @api public\n */\n\nfunction AggregationCursor(agg) {\n  // set autoDestroy=true because on node 12 it's by default false\n  // gh-10902 need autoDestroy to destroy correctly and emit 'close' event\n  Readable.call(this, { autoDestroy: true, objectMode: true });\n\n  this.cursor = null;\n  this.agg = agg;\n  this._transforms = [];\n  const model = agg._model;\n  delete agg.options.cursor.useMongooseAggCursor;\n  this._mongooseOptions = {};\n\n  _init(model, this, agg);\n}\n\nutil.inherits(AggregationCursor, Readable);\n\n/*!\n * ignore\n */\n\nfunction _init(model, c, agg) {\n  if (!model.collection.buffer) {\n    model.hooks.execPre('aggregate', agg, function() {\n      if (typeof agg.options?.cursor?.transform === 'function') {\n        c._transforms.push(agg.options.cursor.transform);\n      }\n\n      c.cursor = model.collection.aggregate(agg._pipeline, agg.options || {});\n      c.emit('cursor', c.cursor);\n    });\n  } else {\n    model.collection.emitter.once('queue', function() {\n      model.hooks.execPre('aggregate', agg, function() {\n        if (typeof agg.options?.cursor?.transform === 'function') {\n          c._transforms.push(agg.options.cursor.transform);\n        }\n\n        c.cursor = model.collection.aggregate(agg._pipeline, agg.options || {});\n        c.emit('cursor', c.cursor);\n      });\n    });\n  }\n}\n\n/**\n * Necessary to satisfy the Readable API\n * @method _read\n * @memberOf AggregationCursor\n * @instance\n * @api private\n */\n\nAggregationCursor.prototype._read = function() {\n  const _this = this;\n  _next(this, function(error, doc) {\n    if (error) {\n      return _this.emit('error', error);\n    }\n    if (!doc) {\n      _this.push(null);\n      _this.cursor.close(function(error) {\n        if (error) {\n          return _this.emit('error', error);\n        }\n      });\n      return;\n    }\n    _this.push(doc);\n  });\n};\n\nif (Symbol.asyncIterator != null) {\n  const msg = 'Mongoose does not support using async iterators with an ' +\n    'existing aggregation cursor. See https://bit.ly/mongoose-async-iterate-aggregation';\n\n  AggregationCursor.prototype[Symbol.asyncIterator] = function() {\n    throw new MongooseError(msg);\n  };\n}\n\n/**\n * Registers a transform function which subsequently maps documents retrieved\n * via the streams interface or `.next()`\n *\n * #### Example:\n *\n *     // Map documents returned by `data` events\n *     Thing.\n *       find({ name: /^hello/ }).\n *       cursor().\n *       map(function (doc) {\n *        doc.foo = \"bar\";\n *        return doc;\n *       })\n *       on('data', function(doc) { console.log(doc.foo); });\n *\n *     // Or map documents returned by `.next()`\n *     const cursor = Thing.find({ name: /^hello/ }).\n *       cursor().\n *       map(function (doc) {\n *         doc.foo = \"bar\";\n *         return doc;\n *       });\n *     cursor.next(function(error, doc) {\n *       console.log(doc.foo);\n *     });\n *\n * @param {Function} fn\n * @return {AggregationCursor}\n * @memberOf AggregationCursor\n * @api public\n * @method map\n */\n\nObject.defineProperty(AggregationCursor.prototype, 'map', {\n  value: function(fn) {\n    this._transforms.push(fn);\n    return this;\n  },\n  enumerable: true,\n  configurable: true,\n  writable: true\n});\n\n/**\n * Marks this cursor as errored\n * @method _markError\n * @instance\n * @memberOf AggregationCursor\n * @api private\n */\n\nAggregationCursor.prototype._markError = function(error) {\n  this._error = error;\n  return this;\n};\n\n/**\n * Marks this cursor as closed. Will stop streaming and subsequent calls to\n * `next()` will error.\n *\n * @param {Function} callback\n * @return {Promise}\n * @api public\n * @method close\n * @emits close\n * @see AggregationCursor.close https://mongodb.github.io/node-mongodb-native/4.9/classes/AggregationCursor.html#close\n */\n\nAggregationCursor.prototype.close = async function close() {\n  if (typeof arguments[0] === 'function') {\n    throw new MongooseError('AggregationCursor.prototype.close() no longer accepts a callback');\n  }\n  try {\n    await this.cursor.close();\n  } catch (error) {\n    this.listeners('error').length > 0 && this.emit('error', error);\n    throw error;\n  }\n  this.emit('close');\n};\n\n/**\n * Get the next document from this cursor. Will return `null` when there are\n * no documents left.\n *\n * @return {Promise}\n * @api public\n * @method next\n */\n\nAggregationCursor.prototype.next = async function next() {\n  if (typeof arguments[0] === 'function') {\n    throw new MongooseError('AggregationCursor.prototype.next() no longer accepts a callback');\n  }\n  return new Promise((resolve, reject) => {\n    _next(this, (err, res) => {\n      if (err != null) {\n        return reject(err);\n      }\n      resolve(res);\n    });\n  });\n};\n\n/**\n * Execute `fn` for every document in the cursor. If `fn` returns a promise,\n * will wait for the promise to resolve before iterating on to the next one.\n * Returns a promise that resolves when done.\n *\n * @param {Function} fn\n * @param {Object} [options]\n * @param {Number} [options.parallel] the number of promises to execute in parallel. Defaults to 1.\n * @param {Number} [options.batchSize=null] if set, Mongoose will call `fn` with an array of at most `batchSize` documents, instead of a single document\n * @param {Boolean} [options.continueOnError=false] if true, `eachAsync()` iterates through all docs even if `fn` throws an error. If false, `eachAsync()` throws an error immediately if the given function `fn()` throws an error.\n * @return {Promise}\n * @api public\n * @method eachAsync\n */\n\nAggregationCursor.prototype.eachAsync = function(fn, opts) {\n  if (typeof arguments[2] === 'function') {\n    throw new MongooseError('AggregationCursor.prototype.eachAsync() no longer accepts a callback');\n  }\n  const _this = this;\n  if (typeof opts === 'function') {\n    opts = {};\n  }\n  opts = opts || {};\n\n  return eachAsync(function(cb) { return _next(_this, cb); }, fn, opts);\n};\n\n/**\n * Returns an asyncIterator for use with [`for/await/of` loops](https://thecodebarbarian.com/getting-started-with-async-iterators-in-node-js)\n * You do not need to call this function explicitly, the JavaScript runtime\n * will call it for you.\n *\n * #### Example:\n *\n *     // Async iterator without explicitly calling `cursor()`. Mongoose still\n *     // creates an AggregationCursor instance internally.\n *     const agg = Model.aggregate([{ $match: { age: { $gte: 25 } } }]);\n *     for await (const doc of agg) {\n *       console.log(doc.name);\n *     }\n *\n *     // You can also use an AggregationCursor instance for async iteration\n *     const cursor = Model.aggregate([{ $match: { age: { $gte: 25 } } }]).cursor();\n *     for await (const doc of cursor) {\n *       console.log(doc.name);\n *     }\n *\n * Node.js 10.x supports async iterators natively without any flags. You can\n * enable async iterators in Node.js 8.x using the [`--harmony_async_iteration` flag](https://github.com/tc39/proposal-async-iteration/issues/117#issuecomment-346695187).\n *\n * **Note:** This function is not set if `Symbol.asyncIterator` is undefined. If\n * `Symbol.asyncIterator` is undefined, that means your Node.js version does not\n * support async iterators.\n *\n * @method [Symbol.asyncIterator]\n * @memberOf AggregationCursor\n * @instance\n * @api public\n */\n\nif (Symbol.asyncIterator != null) {\n  AggregationCursor.prototype[Symbol.asyncIterator] = function() {\n    return this.transformNull()._transformForAsyncIterator();\n  };\n}\n\n/*!\n * ignore\n */\n\nAggregationCursor.prototype._transformForAsyncIterator = function() {\n  if (this._transforms.indexOf(_transformForAsyncIterator) === -1) {\n    this.map(_transformForAsyncIterator);\n  }\n  return this;\n};\n\n/*!\n * ignore\n */\n\nAggregationCursor.prototype.transformNull = function(val) {\n  if (arguments.length === 0) {\n    val = true;\n  }\n  this._mongooseOptions.transformNull = val;\n  return this;\n};\n\n/*!\n * ignore\n */\n\nfunction _transformForAsyncIterator(doc) {\n  return doc == null ? { done: true } : { value: doc, done: false };\n}\n\n/**\n * Adds a [cursor flag](https://mongodb.github.io/node-mongodb-native/4.9/classes/AggregationCursor.html#addCursorFlag).\n * Useful for setting the `noCursorTimeout` and `tailable` flags.\n *\n * @param {String} flag\n * @param {Boolean} value\n * @return {AggregationCursor} this\n * @api public\n * @method addCursorFlag\n */\n\nAggregationCursor.prototype.addCursorFlag = function(flag, value) {\n  const _this = this;\n  _waitForCursor(this, function() {\n    _this.cursor.addCursorFlag(flag, value);\n  });\n  return this;\n};\n\n/*!\n * ignore\n */\n\nfunction _waitForCursor(ctx, cb) {\n  if (ctx.cursor) {\n    return cb();\n  }\n  ctx.once('cursor', function() {\n    cb();\n  });\n}\n\n/**\n * Get the next doc from the underlying cursor and mongooseify it\n * (populate, etc.)\n * @param {Any} ctx\n * @param {Function} cb\n * @api private\n */\n\nfunction _next(ctx, cb) {\n  let callback = cb;\n  if (ctx._transforms.length) {\n    callback = function(err, doc) {\n      if (err || (doc === null && !ctx._mongooseOptions.transformNull)) {\n        return cb(err, doc);\n      }\n      cb(err, ctx._transforms.reduce(function(doc, fn) {\n        return fn(doc);\n      }, doc));\n    };\n  }\n\n  if (ctx._error) {\n    return immediate(function() {\n      callback(ctx._error);\n    });\n  }\n\n  if (ctx.cursor) {\n    return ctx.cursor.next().then(\n      doc => {\n        if (!doc) {\n          return callback(null, null);\n        }\n\n        callback(null, doc);\n      },\n      err => callback(err)\n    );\n  } else {\n    ctx.once('cursor', function() {\n      _next(ctx, cb);\n    });\n  }\n}\n\nmodule.exports = AggregationCursor;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/cursor/aggregationCursor.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/cursor/changeStream.js":
/*!**********************************************************!*\
  !*** ./node_modules/mongoose/lib/cursor/changeStream.js ***!
  \**********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst EventEmitter = (__webpack_require__(/*! events */ \"events\").EventEmitter);\n\n/*!\n * ignore\n */\n\nconst driverChangeStreamEvents = ['close', 'change', 'end', 'error', 'resumeTokenChanged'];\n\n/*!\n * ignore\n */\n\nclass ChangeStream extends EventEmitter {\n  constructor(changeStreamThunk, pipeline, options) {\n    super();\n\n    this.driverChangeStream = null;\n    this.closed = false;\n    this.bindedEvents = false;\n    this.pipeline = pipeline;\n    this.options = options;\n\n    if (options && options.hydrate && !options.model) {\n      throw new Error(\n        'Cannot create change stream with `hydrate: true` ' +\n        'unless calling `Model.watch()`'\n      );\n    }\n\n    // This wrapper is necessary because of buffering.\n    changeStreamThunk((err, driverChangeStream) => {\n      if (err != null) {\n        this.emit('error', err);\n        return;\n      }\n\n      this.driverChangeStream = driverChangeStream;\n      this.emit('ready');\n    });\n  }\n\n  _bindEvents() {\n    if (this.bindedEvents) {\n      return;\n    }\n\n    this.bindedEvents = true;\n\n    if (this.driverChangeStream == null) {\n      this.once('ready', () => {\n        this.driverChangeStream.on('close', () => {\n          this.closed = true;\n        });\n\n        driverChangeStreamEvents.forEach(ev => {\n          this.driverChangeStream.on(ev, data => {\n            if (data != null && data.fullDocument != null && this.options && this.options.hydrate) {\n              data.fullDocument = this.options.model.hydrate(data.fullDocument);\n            }\n            this.emit(ev, data);\n          });\n        });\n      });\n\n      return;\n    }\n\n    this.driverChangeStream.on('close', () => {\n      this.closed = true;\n    });\n\n    driverChangeStreamEvents.forEach(ev => {\n      this.driverChangeStream.on(ev, data => {\n        if (data != null && data.fullDocument != null && this.options && this.options.hydrate) {\n          data.fullDocument = this.options.model.hydrate(data.fullDocument);\n        }\n        this.emit(ev, data);\n      });\n    });\n  }\n\n  hasNext(cb) {\n    return this.driverChangeStream.hasNext(cb);\n  }\n\n  next(cb) {\n    if (this.options && this.options.hydrate) {\n      if (cb != null) {\n        const originalCb = cb;\n        cb = (err, data) => {\n          if (err != null) {\n            return originalCb(err);\n          }\n          if (data.fullDocument != null) {\n            data.fullDocument = this.options.model.hydrate(data.fullDocument);\n          }\n          return originalCb(null, data);\n        };\n      }\n\n      let maybePromise = this.driverChangeStream.next(cb);\n      if (maybePromise && typeof maybePromise.then === 'function') {\n        maybePromise = maybePromise.then(data => {\n          if (data.fullDocument != null) {\n            data.fullDocument = this.options.model.hydrate(data.fullDocument);\n          }\n          return data;\n        });\n      }\n      return maybePromise;\n    }\n\n    return this.driverChangeStream.next(cb);\n  }\n\n  addListener(event, handler) {\n    this._bindEvents();\n    return super.addListener(event, handler);\n  }\n\n  on(event, handler) {\n    this._bindEvents();\n    return super.on(event, handler);\n  }\n\n  once(event, handler) {\n    this._bindEvents();\n    return super.once(event, handler);\n  }\n\n  _queue(cb) {\n    this.once('ready', () => cb());\n  }\n\n  close() {\n    this.closed = true;\n    if (this.driverChangeStream) {\n      return this.driverChangeStream.close();\n    }\n    return Promise.resolve();\n  }\n}\n\n/*!\n * ignore\n */\n\nmodule.exports = ChangeStream;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/cursor/changeStream.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/cursor/queryCursor.js":
/*!*********************************************************!*\
  !*** ./node_modules/mongoose/lib/cursor/queryCursor.js ***!
  \*********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module dependencies.\n */\n\n\n\nconst MongooseError = __webpack_require__(/*! ../error/mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\nconst Readable = (__webpack_require__(/*! stream */ \"stream\").Readable);\nconst eachAsync = __webpack_require__(/*! ../helpers/cursor/eachAsync */ \"./node_modules/mongoose/lib/helpers/cursor/eachAsync.js\");\nconst helpers = __webpack_require__(/*! ../queryHelpers */ \"./node_modules/mongoose/lib/queryHelpers.js\");\nconst kareem = __webpack_require__(/*! kareem */ \"./node_modules/kareem/index.js\");\nconst immediate = __webpack_require__(/*! ../helpers/immediate */ \"./node_modules/mongoose/lib/helpers/immediate.js\");\nconst util = __webpack_require__(/*! util */ \"util\");\n\n/**\n * A QueryCursor is a concurrency primitive for processing query results\n * one document at a time. A QueryCursor fulfills the Node.js streams3 API,\n * in addition to several other mechanisms for loading documents from MongoDB\n * one at a time.\n *\n * QueryCursors execute the model's pre `find` hooks before loading any documents\n * from MongoDB, and the model's post `find` hooks after loading each document.\n *\n * Unless you're an advanced user, do **not** instantiate this class directly.\n * Use [`Query#cursor()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.cursor()) instead.\n *\n * @param {Query} query\n * @param {Object} options query options passed to `.find()`\n * @inherits Readable https://nodejs.org/api/stream.html#class-streamreadable\n * @event `cursor`: Emitted when the cursor is created\n * @event `error`: Emitted when an error occurred\n * @event `data`: Emitted when the stream is flowing and the next doc is ready\n * @event `end`: Emitted when the stream is exhausted\n * @api public\n */\n\nfunction QueryCursor(query) {\n  // set autoDestroy=true because on node 12 it's by default false\n  // gh-10902 need autoDestroy to destroy correctly and emit 'close' event\n  Readable.call(this, { autoDestroy: true, objectMode: true });\n\n  this.cursor = null;\n  this.skipped = false;\n  this.query = query;\n  const model = query.model;\n  this._mongooseOptions = {};\n  this._transforms = [];\n  this.model = model;\n  this.options = {};\n  model.hooks.execPre('find', query, (err) => {\n    if (err != null) {\n      if (err instanceof kareem.skipWrappedFunction) {\n        const resultValue = err.args[0];\n        if (resultValue != null && (!Array.isArray(resultValue) || resultValue.length)) {\n          const err = new MongooseError(\n            'Cannot `skipMiddlewareFunction()` with a value when using ' +\n            '`.find().cursor()`, value must be nullish or empty array, got \"' +\n            util.inspect(resultValue) +\n            '\".'\n          );\n          this._markError(err);\n          this.listeners('error').length > 0 && this.emit('error', err);\n          return;\n        }\n        this.skipped = true;\n        this.emit('cursor', null);\n        return;\n      }\n      this._markError(err);\n      this.listeners('error').length > 0 && this.emit('error', err);\n      return;\n    }\n    Object.assign(this.options, query._optionsForExec());\n    this._transforms = this._transforms.concat(query._transforms.slice());\n    if (this.options.transform) {\n      this._transforms.push(this.options.transform);\n    }\n    // Re: gh-8039, you need to set the `cursor.batchSize` option, top-level\n    // `batchSize` option doesn't work.\n    if (this.options.batchSize) {\n      // Max out the number of documents we'll populate in parallel at 5000.\n      this.options._populateBatchSize = Math.min(this.options.batchSize, 5000);\n    }\n\n    if (model.collection._shouldBufferCommands() && model.collection.buffer) {\n      model.collection.queue.push([\n        () => _getRawCursor(query, this)\n      ]);\n    } else {\n      _getRawCursor(query, this);\n    }\n  });\n}\n\nutil.inherits(QueryCursor, Readable);\n\n/*!\n * ignore\n */\n\nfunction _getRawCursor(query, queryCursor) {\n  try {\n    const cursor = query.model.collection.find(query._conditions, queryCursor.options);\n    queryCursor.cursor = cursor;\n    queryCursor.emit('cursor', cursor);\n  } catch (err) {\n    queryCursor._markError(err);\n    queryCursor.listeners('error').length > 0 && queryCursor.emit('error', queryCursor._error);\n  }\n}\n\n/**\n * Necessary to satisfy the Readable API\n * @method _read\n * @memberOf QueryCursor\n * @instance\n * @api private\n */\n\nQueryCursor.prototype._read = function() {\n  _next(this, (error, doc) => {\n    if (error) {\n      return this.emit('error', error);\n    }\n    if (!doc) {\n      this.push(null);\n      this.cursor.close(function(error) {\n        if (error) {\n          return this.emit('error', error);\n        }\n      });\n      return;\n    }\n    this.push(doc);\n  });\n};\n\n/**\n * Registers a transform function which subsequently maps documents retrieved\n * via the streams interface or `.next()`\n *\n * #### Example:\n *\n *     // Map documents returned by `data` events\n *     Thing.\n *       find({ name: /^hello/ }).\n *       cursor().\n *       map(function (doc) {\n *        doc.foo = \"bar\";\n *        return doc;\n *       })\n *       on('data', function(doc) { console.log(doc.foo); });\n *\n *     // Or map documents returned by `.next()`\n *     const cursor = Thing.find({ name: /^hello/ }).\n *       cursor().\n *       map(function (doc) {\n *         doc.foo = \"bar\";\n *         return doc;\n *       });\n *     cursor.next(function(error, doc) {\n *       console.log(doc.foo);\n *     });\n *\n * @param {Function} fn\n * @return {QueryCursor}\n * @memberOf QueryCursor\n * @api public\n * @method map\n */\n\nObject.defineProperty(QueryCursor.prototype, 'map', {\n  value: function(fn) {\n    this._transforms.push(fn);\n    return this;\n  },\n  enumerable: true,\n  configurable: true,\n  writable: true\n});\n\n/**\n * Marks this cursor as errored\n * @method _markError\n * @memberOf QueryCursor\n * @instance\n * @api private\n */\n\nQueryCursor.prototype._markError = function(error) {\n  this._error = error;\n  return this;\n};\n\n/**\n * Marks this cursor as closed. Will stop streaming and subsequent calls to\n * `next()` will error.\n *\n * @return {Promise}\n * @api public\n * @method close\n * @emits close\n * @see AggregationCursor.close https://mongodb.github.io/node-mongodb-native/4.9/classes/AggregationCursor.html#close\n */\n\nQueryCursor.prototype.close = async function close() {\n  if (typeof arguments[0] === 'function') {\n    throw new MongooseError('QueryCursor.prototype.close() no longer accepts a callback');\n  }\n  try {\n    await this.cursor.close();\n    this.emit('close');\n  } catch (error) {\n    this.listeners('error').length > 0 && this.emit('error', error);\n    throw error;\n  }\n};\n\n/**\n * Rewind this cursor to its uninitialized state. Any options that are present on the cursor will\n * remain in effect. Iterating this cursor will cause new queries to be sent to the server, even\n * if the resultant data has already been retrieved by this cursor.\n *\n * @return {AggregationCursor} this\n * @api public\n * @method rewind\n */\n\nQueryCursor.prototype.rewind = function() {\n  _waitForCursor(this, () => {\n    this.cursor.rewind();\n  });\n  return this;\n};\n\n/**\n * Get the next document from this cursor. Will return `null` when there are\n * no documents left.\n *\n * @return {Promise}\n * @api public\n * @method next\n */\n\nQueryCursor.prototype.next = async function next() {\n  if (typeof arguments[0] === 'function') {\n    throw new MongooseError('QueryCursor.prototype.next() no longer accepts a callback');\n  }\n  return new Promise((resolve, reject) => {\n    _next(this, function(error, doc) {\n      if (error) {\n        return reject(error);\n      }\n      resolve(doc);\n    });\n  });\n};\n\n/**\n * Execute `fn` for every document in the cursor. If `fn` returns a promise,\n * will wait for the promise to resolve before iterating on to the next one.\n * Returns a promise that resolves when done.\n *\n * #### Example:\n *\n *     // Iterate over documents asynchronously\n *     Thing.\n *       find({ name: /^hello/ }).\n *       cursor().\n *       eachAsync(async function (doc, i) {\n *         doc.foo = doc.bar + i;\n *         await doc.save();\n *       })\n *\n * @param {Function} fn\n * @param {Object} [options]\n * @param {Number} [options.parallel] the number of promises to execute in parallel. Defaults to 1.\n * @param {Number} [options.batchSize] if set, will call `fn()` with arrays of documents with length at most `batchSize`\n * @param {Boolean} [options.continueOnError=false] if true, `eachAsync()` iterates through all docs even if `fn` throws an error. If false, `eachAsync()` throws an error immediately if the given function `fn()` throws an error.\n * @return {Promise}\n * @api public\n * @method eachAsync\n */\n\nQueryCursor.prototype.eachAsync = function(fn, opts) {\n  if (typeof arguments[2] === 'function') {\n    throw new MongooseError('QueryCursor.prototype.eachAsync() no longer accepts a callback');\n  }\n  if (typeof opts === 'function') {\n    opts = {};\n  }\n  opts = opts || {};\n\n  return eachAsync((cb) => _next(this, cb), fn, opts);\n};\n\n/**\n * The `options` passed in to the `QueryCursor` constructor.\n *\n * @api public\n * @property options\n */\n\nQueryCursor.prototype.options;\n\n/**\n * Adds a [cursor flag](https://mongodb.github.io/node-mongodb-native/4.9/classes/FindCursor.html#addCursorFlag).\n * Useful for setting the `noCursorTimeout` and `tailable` flags.\n *\n * @param {String} flag\n * @param {Boolean} value\n * @return {AggregationCursor} this\n * @api public\n * @method addCursorFlag\n */\n\nQueryCursor.prototype.addCursorFlag = function(flag, value) {\n  _waitForCursor(this, () => {\n    this.cursor.addCursorFlag(flag, value);\n  });\n  return this;\n};\n\n/*!\n * ignore\n */\n\nQueryCursor.prototype.transformNull = function(val) {\n  if (arguments.length === 0) {\n    val = true;\n  }\n  this._mongooseOptions.transformNull = val;\n  return this;\n};\n\n/*!\n * ignore\n */\n\nQueryCursor.prototype._transformForAsyncIterator = function() {\n  if (this._transforms.indexOf(_transformForAsyncIterator) === -1) {\n    this.map(_transformForAsyncIterator);\n  }\n  return this;\n};\n\n/**\n * Returns an asyncIterator for use with [`for/await/of` loops](https://thecodebarbarian.com/getting-started-with-async-iterators-in-node-js).\n * You do not need to call this function explicitly, the JavaScript runtime\n * will call it for you.\n *\n * #### Example:\n *\n *     // Works without using `cursor()`\n *     for await (const doc of Model.find([{ $sort: { name: 1 } }])) {\n *       console.log(doc.name);\n *     }\n *\n *     // Can also use `cursor()`\n *     for await (const doc of Model.find([{ $sort: { name: 1 } }]).cursor()) {\n *       console.log(doc.name);\n *     }\n *\n * Node.js 10.x supports async iterators natively without any flags. You can\n * enable async iterators in Node.js 8.x using the [`--harmony_async_iteration` flag](https://github.com/tc39/proposal-async-iteration/issues/117#issuecomment-346695187).\n *\n * **Note:** This function is not if `Symbol.asyncIterator` is undefined. If\n * `Symbol.asyncIterator` is undefined, that means your Node.js version does not\n * support async iterators.\n *\n * @method [Symbol.asyncIterator]\n * @memberOf QueryCursor\n * @instance\n * @api public\n */\n\nif (Symbol.asyncIterator != null) {\n  QueryCursor.prototype[Symbol.asyncIterator] = function() {\n    return this.transformNull()._transformForAsyncIterator();\n  };\n}\n\n/*!\n * ignore\n */\n\nfunction _transformForAsyncIterator(doc) {\n  return doc == null ? { done: true } : { value: doc, done: false };\n}\n\n/**\n * Get the next doc from the underlying cursor and mongooseify it\n * (populate, etc.)\n * @param {Any} ctx\n * @param {Function} cb\n * @api private\n */\n\nfunction _next(ctx, cb) {\n  let callback = cb;\n  if (ctx._transforms.length) {\n    callback = function(err, doc) {\n      if (err || (doc === null && !ctx._mongooseOptions.transformNull)) {\n        return cb(err, doc);\n      }\n      cb(err, ctx._transforms.reduce(function(doc, fn) {\n        return fn.call(ctx, doc);\n      }, doc));\n    };\n  }\n\n  if (ctx._error) {\n    return immediate(function() {\n      callback(ctx._error);\n    });\n  }\n  if (ctx.skipped) {\n    return immediate(() => callback(null, null));\n  }\n\n  if (ctx.cursor) {\n    if (ctx.query._mongooseOptions.populate && !ctx._pop) {\n      ctx._pop = helpers.preparePopulationOptionsMQ(ctx.query,\n        ctx.query._mongooseOptions);\n      ctx._pop.__noPromise = true;\n    }\n    if (ctx.query._mongooseOptions.populate && ctx.options._populateBatchSize > 1) {\n      if (ctx._batchDocs && ctx._batchDocs.length) {\n        // Return a cached populated doc\n        return _nextDoc(ctx, ctx._batchDocs.shift(), ctx._pop, callback);\n      } else if (ctx._batchExhausted) {\n        // Internal cursor reported no more docs. Act the same here\n        return callback(null, null);\n      } else {\n        // Request as many docs as batchSize, to populate them also in batch\n        ctx._batchDocs = [];\n        ctx.cursor.next().then(\n          res => { _onNext.call({ ctx, callback }, null, res); },\n          err => { _onNext.call({ ctx, callback }, err); }\n        );\n        return;\n      }\n    } else {\n      return ctx.cursor.next().then(\n        doc => {\n          if (!doc) {\n            callback(null, null);\n            return;\n          }\n\n          if (!ctx.query._mongooseOptions.populate) {\n            return _nextDoc(ctx, doc, null, callback);\n          }\n\n          ctx.query.model.populate(doc, ctx._pop).then(\n            doc => {\n              _nextDoc(ctx, doc, ctx._pop, callback);\n            },\n            err => {\n              callback(err);\n            }\n          );\n        },\n        error => {\n          callback(error);\n        }\n      );\n    }\n  } else {\n    ctx.once('error', cb);\n\n    ctx.once('cursor', function(cursor) {\n      ctx.removeListener('error', cb);\n      if (cursor == null) {\n        if (ctx.skipped) {\n          return cb(null, null);\n        }\n        return;\n      }\n      _next(ctx, cb);\n    });\n  }\n}\n\n/*!\n * ignore\n */\n\nfunction _onNext(error, doc) {\n  if (error) {\n    return this.callback(error);\n  }\n  if (!doc) {\n    this.ctx._batchExhausted = true;\n    return _populateBatch.call(this);\n  }\n\n  this.ctx._batchDocs.push(doc);\n\n  if (this.ctx._batchDocs.length < this.ctx.options._populateBatchSize) {\n    // If both `batchSize` and `_populateBatchSize` are huge, calling `next()` repeatedly may\n    // cause a stack overflow. So make sure we clear the stack regularly.\n    if (this.ctx._batchDocs.length > 0 && this.ctx._batchDocs.length % 1000 === 0) {\n      return immediate(() => this.ctx.cursor.next().then(\n        res => { _onNext.call(this, null, res); },\n        err => { _onNext.call(this, err); }\n      ));\n    }\n    this.ctx.cursor.next().then(\n      res => { _onNext.call(this, null, res); },\n      err => { _onNext.call(this, err); }\n    );\n  } else {\n    _populateBatch.call(this);\n  }\n}\n\n/*!\n * ignore\n */\n\nfunction _populateBatch() {\n  if (!this.ctx._batchDocs.length) {\n    return this.callback(null, null);\n  }\n  this.ctx.query.model.populate(this.ctx._batchDocs, this.ctx._pop).then(\n    () => {\n      _nextDoc(this.ctx, this.ctx._batchDocs.shift(), this.ctx._pop, this.callback);\n    },\n    err => {\n      this.callback(err);\n    }\n  );\n}\n\n/*!\n * ignore\n */\n\nfunction _nextDoc(ctx, doc, pop, callback) {\n  if (ctx.query._mongooseOptions.lean) {\n    return ctx.model.hooks.execPost('find', ctx.query, [[doc]], err => {\n      if (err != null) {\n        return callback(err);\n      }\n      callback(null, doc);\n    });\n  }\n\n  const { model, _fields, _userProvidedFields, options } = ctx.query;\n  helpers.createModelAndInit(model, doc, _fields, _userProvidedFields, options, pop, (err, doc) => {\n    if (err != null) {\n      return callback(err);\n    }\n    ctx.model.hooks.execPost('find', ctx.query, [[doc]], err => {\n      if (err != null) {\n        return callback(err);\n      }\n      callback(null, doc);\n    });\n  });\n}\n\n/*!\n * ignore\n */\n\nfunction _waitForCursor(ctx, cb) {\n  if (ctx.cursor) {\n    return cb();\n  }\n  ctx.once('cursor', function(cursor) {\n    if (cursor == null) {\n      return;\n    }\n    cb();\n  });\n}\n\nmodule.exports = QueryCursor;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/cursor/queryCursor.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/document.js":
/*!***********************************************!*\
  !*** ./node_modules/mongoose/lib/document.js ***!
  \***********************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst DivergentArrayError = __webpack_require__(/*! ./error/divergentArray */ \"./node_modules/mongoose/lib/error/divergentArray.js\");\nconst EventEmitter = (__webpack_require__(/*! events */ \"events\").EventEmitter);\nconst InternalCache = __webpack_require__(/*! ./internal */ \"./node_modules/mongoose/lib/internal.js\");\nconst MongooseBuffer = __webpack_require__(/*! ./types/buffer */ \"./node_modules/mongoose/lib/types/buffer.js\");\nconst MongooseError = __webpack_require__(/*! ./error/index */ \"./node_modules/mongoose/lib/error/index.js\");\nconst MixedSchema = __webpack_require__(/*! ./schema/mixed */ \"./node_modules/mongoose/lib/schema/mixed.js\");\nconst ModifiedPathsSnapshot = __webpack_require__(/*! ./modifiedPathsSnapshot */ \"./node_modules/mongoose/lib/modifiedPathsSnapshot.js\");\nconst ObjectExpectedError = __webpack_require__(/*! ./error/objectExpected */ \"./node_modules/mongoose/lib/error/objectExpected.js\");\nconst ObjectParameterError = __webpack_require__(/*! ./error/objectParameter */ \"./node_modules/mongoose/lib/error/objectParameter.js\");\nconst ParallelValidateError = __webpack_require__(/*! ./error/parallelValidate */ \"./node_modules/mongoose/lib/error/parallelValidate.js\");\nconst Schema = __webpack_require__(/*! ./schema */ \"./node_modules/mongoose/lib/schema.js\");\nconst StrictModeError = __webpack_require__(/*! ./error/strict */ \"./node_modules/mongoose/lib/error/strict.js\");\nconst ValidationError = __webpack_require__(/*! ./error/validation */ \"./node_modules/mongoose/lib/error/validation.js\");\nconst ValidatorError = __webpack_require__(/*! ./error/validator */ \"./node_modules/mongoose/lib/error/validator.js\");\nconst $__hasIncludedChildren = __webpack_require__(/*! ./helpers/projection/hasIncludedChildren */ \"./node_modules/mongoose/lib/helpers/projection/hasIncludedChildren.js\");\nconst applyDefaults = __webpack_require__(/*! ./helpers/document/applyDefaults */ \"./node_modules/mongoose/lib/helpers/document/applyDefaults.js\");\nconst cleanModifiedSubpaths = __webpack_require__(/*! ./helpers/document/cleanModifiedSubpaths */ \"./node_modules/mongoose/lib/helpers/document/cleanModifiedSubpaths.js\");\nconst clone = __webpack_require__(/*! ./helpers/clone */ \"./node_modules/mongoose/lib/helpers/clone.js\");\nconst compile = (__webpack_require__(/*! ./helpers/document/compile */ \"./node_modules/mongoose/lib/helpers/document/compile.js\").compile);\nconst defineKey = (__webpack_require__(/*! ./helpers/document/compile */ \"./node_modules/mongoose/lib/helpers/document/compile.js\").defineKey);\nconst firstKey = __webpack_require__(/*! ./helpers/firstKey */ \"./node_modules/mongoose/lib/helpers/firstKey.js\");\nconst flatten = (__webpack_require__(/*! ./helpers/common */ \"./node_modules/mongoose/lib/helpers/common.js\").flatten);\nconst getEmbeddedDiscriminatorPath = __webpack_require__(/*! ./helpers/document/getEmbeddedDiscriminatorPath */ \"./node_modules/mongoose/lib/helpers/document/getEmbeddedDiscriminatorPath.js\");\nconst getKeysInSchemaOrder = __webpack_require__(/*! ./helpers/schema/getKeysInSchemaOrder */ \"./node_modules/mongoose/lib/helpers/schema/getKeysInSchemaOrder.js\");\nconst getSubdocumentStrictValue = __webpack_require__(/*! ./helpers/schema/getSubdocumentStrictValue */ \"./node_modules/mongoose/lib/helpers/schema/getSubdocumentStrictValue.js\");\nconst handleSpreadDoc = __webpack_require__(/*! ./helpers/document/handleSpreadDoc */ \"./node_modules/mongoose/lib/helpers/document/handleSpreadDoc.js\");\nconst immediate = __webpack_require__(/*! ./helpers/immediate */ \"./node_modules/mongoose/lib/helpers/immediate.js\");\nconst isBsonType = __webpack_require__(/*! ./helpers/isBsonType */ \"./node_modules/mongoose/lib/helpers/isBsonType.js\");\nconst isDefiningProjection = __webpack_require__(/*! ./helpers/projection/isDefiningProjection */ \"./node_modules/mongoose/lib/helpers/projection/isDefiningProjection.js\");\nconst isExclusive = __webpack_require__(/*! ./helpers/projection/isExclusive */ \"./node_modules/mongoose/lib/helpers/projection/isExclusive.js\");\nconst isPathExcluded = __webpack_require__(/*! ./helpers/projection/isPathExcluded */ \"./node_modules/mongoose/lib/helpers/projection/isPathExcluded.js\");\nconst inspect = (__webpack_require__(/*! util */ \"util\").inspect);\nconst internalToObjectOptions = (__webpack_require__(/*! ./options */ \"./node_modules/mongoose/lib/options.js\").internalToObjectOptions);\nconst markArraySubdocsPopulated = __webpack_require__(/*! ./helpers/populate/markArraySubdocsPopulated */ \"./node_modules/mongoose/lib/helpers/populate/markArraySubdocsPopulated.js\");\nconst minimize = __webpack_require__(/*! ./helpers/minimize */ \"./node_modules/mongoose/lib/helpers/minimize.js\");\nconst mpath = __webpack_require__(/*! mpath */ \"./node_modules/mpath/index.js\");\nconst parentPaths = __webpack_require__(/*! ./helpers/path/parentPaths */ \"./node_modules/mongoose/lib/helpers/path/parentPaths.js\");\nconst queryhelpers = __webpack_require__(/*! ./queryHelpers */ \"./node_modules/mongoose/lib/queryHelpers.js\");\nconst utils = __webpack_require__(/*! ./utils */ \"./node_modules/mongoose/lib/utils.js\");\nconst isPromise = __webpack_require__(/*! ./helpers/isPromise */ \"./node_modules/mongoose/lib/helpers/isPromise.js\");\n\nconst deepEqual = utils.deepEqual;\nconst isMongooseObject = utils.isMongooseObject;\n\nconst arrayAtomicsBackupSymbol = (__webpack_require__(/*! ./helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").arrayAtomicsBackupSymbol);\nconst arrayAtomicsSymbol = (__webpack_require__(/*! ./helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").arrayAtomicsSymbol);\nconst documentArrayParent = (__webpack_require__(/*! ./helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").documentArrayParent);\nconst documentIsModified = (__webpack_require__(/*! ./helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").documentIsModified);\nconst documentModifiedPaths = (__webpack_require__(/*! ./helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").documentModifiedPaths);\nconst documentSchemaSymbol = (__webpack_require__(/*! ./helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").documentSchemaSymbol);\nconst getSymbol = (__webpack_require__(/*! ./helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").getSymbol);\nconst populateModelSymbol = (__webpack_require__(/*! ./helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").populateModelSymbol);\nconst scopeSymbol = (__webpack_require__(/*! ./helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").scopeSymbol);\nconst schemaMixedSymbol = (__webpack_require__(/*! ./schema/symbols */ \"./node_modules/mongoose/lib/schema/symbols.js\").schemaMixedSymbol);\nconst getDeepestSubdocumentForPath = __webpack_require__(/*! ./helpers/document/getDeepestSubdocumentForPath */ \"./node_modules/mongoose/lib/helpers/document/getDeepestSubdocumentForPath.js\");\nconst sessionNewDocuments = (__webpack_require__(/*! ./helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").sessionNewDocuments);\n\nlet DocumentArray;\nlet MongooseArray;\nlet Embedded;\n\nconst specialProperties = utils.specialProperties;\n\nconst VERSION_WHERE = 1;\nconst VERSION_INC = 2;\nconst VERSION_ALL = VERSION_WHERE | VERSION_INC;\n\n/**\n * The core Mongoose document constructor. You should not call this directly,\n * the Mongoose [Model constructor](./api/model.html#Model) calls this for you.\n *\n * @param {Object} obj the values to set\n * @param {Object} [fields] optional object containing the fields which were selected in the query returning this document and any populated paths data\n * @param {Object} [options] various configuration options for the document\n * @param {Boolean} [options.defaults=true] if `false`, skip applying default values to this document.\n * @inherits NodeJS EventEmitter https://nodejs.org/api/events.html#class-eventemitter\n * @event `init`: Emitted on a document after it has been retrieved from the db and fully hydrated by Mongoose.\n * @event `save`: Emitted when the document is successfully saved\n * @api private\n */\n\nfunction Document(obj, fields, skipId, options) {\n  if (typeof skipId === 'object' && skipId != null) {\n    options = skipId;\n    skipId = options.skipId;\n  }\n  options = Object.assign({}, options);\n\n  // Support `browserDocument.js` syntax\n  if (this.$__schema == null) {\n    const _schema = utils.isObject(fields) && !fields.instanceOfSchema ?\n      new Schema(fields) :\n      fields;\n    this.$__setSchema(_schema);\n    fields = skipId;\n    skipId = options;\n    options = arguments[4] || {};\n  }\n\n  this.$__ = new InternalCache();\n\n  // Avoid setting `isNew` to `true`, because it is `true` by default\n  if (options.isNew != null && options.isNew !== true) {\n    this.$isNew = options.isNew;\n  }\n\n  if (options.priorDoc != null) {\n    this.$__.priorDoc = options.priorDoc;\n  }\n\n  if (skipId) {\n    this.$__.skipId = skipId;\n  }\n\n  if (obj != null && typeof obj !== 'object') {\n    throw new ObjectParameterError(obj, 'obj', 'Document');\n  }\n\n  let defaults = true;\n  if (options.defaults !== undefined) {\n    this.$__.defaults = options.defaults;\n    defaults = options.defaults;\n  }\n\n  const schema = this.$__schema;\n\n  if (typeof fields === 'boolean' || fields === 'throw') {\n    if (fields !== true) {\n      this.$__.strictMode = fields;\n    }\n    fields = undefined;\n  } else if (schema.options.strict !== true) {\n    this.$__.strictMode = schema.options.strict;\n  }\n\n  const requiredPaths = schema.requiredPaths(true);\n  for (const path of requiredPaths) {\n    this.$__.activePaths.require(path);\n  }\n\n  let exclude = null;\n\n  // determine if this doc is a result of a query with\n  // excluded fields\n  if (utils.isPOJO(fields) && Object.keys(fields).length > 0) {\n    exclude = isExclusive(fields);\n    this.$__.selected = fields;\n    this.$__.exclude = exclude;\n  }\n\n  const hasIncludedChildren = exclude === false && fields ?\n    $__hasIncludedChildren(fields) :\n    null;\n\n  if (this._doc == null) {\n    this.$__buildDoc(obj, fields, skipId, exclude, hasIncludedChildren, false);\n\n    // By default, defaults get applied **before** setting initial values\n    // Re: gh-6155\n    if (defaults) {\n      applyDefaults(this, fields, exclude, hasIncludedChildren, true, null, {\n        skipParentChangeTracking: true\n      });\n    }\n  }\n  if (obj) {\n    // Skip set hooks\n    if (this.$__original_set) {\n      this.$__original_set(obj, undefined, true, options);\n    } else {\n      this.$set(obj, undefined, true, options);\n    }\n\n    if (obj instanceof Document) {\n      this.$isNew = obj.$isNew;\n    }\n  }\n\n  // Function defaults get applied **after** setting initial values so they\n  // see the full doc rather than an empty one, unless they opt out.\n  // Re: gh-3781, gh-6155\n  if (options.willInit && defaults) {\n    if (options.skipDefaults) {\n      this.$__.skipDefaults = options.skipDefaults;\n    }\n  } else if (defaults) {\n    applyDefaults(this, fields, exclude, hasIncludedChildren, false, options.skipDefaults);\n  }\n\n  if (!this.$__.strictMode && obj) {\n    const _this = this;\n    const keys = Object.keys(this._doc);\n\n    keys.forEach(function(key) {\n      // Avoid methods, virtuals, existing fields, and `$` keys. The latter is to avoid overwriting\n      // Mongoose internals.\n      if (!(key in schema.tree) && !(key in schema.methods) && !(key in schema.virtuals) && !key.startsWith('$')) {\n        defineKey({ prop: key, subprops: null, prototype: _this });\n      }\n    });\n  }\n\n  applyQueue(this);\n}\n\nDocument.prototype.$isMongooseDocumentPrototype = true;\n\n/**\n * Boolean flag specifying if the document is new. If you create a document\n * using `new`, this document will be considered \"new\". `$isNew` is how\n * Mongoose determines whether `save()` should use `insertOne()` to create\n * a new document or `updateOne()` to update an existing document.\n *\n * #### Example:\n *\n *     const user = new User({ name: 'John Smith' });\n *     user.$isNew; // true\n *\n *     await user.save(); // Sends an `insertOne` to MongoDB\n *\n * On the other hand, if you load an existing document from the database\n * using `findOne()` or another [query operation](https://mongoosejs.com/docs/queries.html),\n * `$isNew` will be false.\n *\n * #### Example:\n *\n *     const user = await User.findOne({ name: 'John Smith' });\n *     user.$isNew; // false\n *\n * Mongoose sets `$isNew` to `false` immediately after `save()` succeeds.\n * That means Mongoose sets `$isNew` to false **before** `post('save')` hooks run.\n * In `post('save')` hooks, `$isNew` will be `false` if `save()` succeeded.\n *\n * #### Example:\n *\n *     userSchema.post('save', function() {\n *       this.$isNew; // false\n *     });\n *     await User.create({ name: 'John Smith' });\n *\n * For subdocuments, `$isNew` is true if either the parent has `$isNew` set,\n * or if you create a new subdocument.\n *\n * #### Example:\n *\n *     // Assume `Group` has a document array `users`\n *     const group = await Group.findOne();\n *     group.users[0].$isNew; // false\n *\n *     group.users.push({ name: 'John Smith' });\n *     group.users[1].$isNew; // true\n *\n * @api public\n * @property $isNew\n * @memberOf Document\n * @instance\n */\n\nObject.defineProperty(Document.prototype, 'isNew', {\n  get: function() {\n    return this.$isNew;\n  },\n  set: function(value) {\n    this.$isNew = value;\n  }\n});\n\n/**\n * Hash containing current validation errors.\n *\n * @api public\n * @property errors\n * @memberOf Document\n * @instance\n */\n\nObject.defineProperty(Document.prototype, 'errors', {\n  get: function() {\n    return this.$errors;\n  },\n  set: function(value) {\n    this.$errors = value;\n  }\n});\n\n/*!\n * ignore\n */\n\nDocument.prototype.$isNew = true;\n\n/*!\n * Document exposes the NodeJS event emitter API, so you can use\n * `on`, `once`, etc.\n */\nutils.each(\n  ['on', 'once', 'emit', 'listeners', 'removeListener', 'setMaxListeners',\n    'removeAllListeners', 'addListener'],\n  function(emitterFn) {\n    Document.prototype[emitterFn] = function() {\n      // Delay creating emitter until necessary because emitters take up a lot of memory,\n      // especially for subdocuments.\n      if (!this.$__.emitter) {\n        if (emitterFn === 'emit') {\n          return;\n        }\n        this.$__.emitter = new EventEmitter();\n        this.$__.emitter.setMaxListeners(0);\n      }\n      return this.$__.emitter[emitterFn].apply(this.$__.emitter, arguments);\n    };\n    Document.prototype[`$${emitterFn}`] = Document.prototype[emitterFn];\n  });\n\nDocument.prototype.constructor = Document;\n\nfor (const i in EventEmitter.prototype) {\n  Document[i] = EventEmitter.prototype[i];\n}\n\n/**\n * The document's internal schema.\n *\n * @api private\n * @property schema\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.$__schema;\n\n/**\n * The document's schema.\n *\n * @api public\n * @property schema\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.schema;\n\n/**\n * Empty object that you can use for storing properties on the document. This\n * is handy for passing data to middleware without conflicting with Mongoose\n * internals.\n *\n * #### Example:\n *\n *     schema.pre('save', function() {\n *       // Mongoose will set `isNew` to `false` if `save()` succeeds\n *       this.$locals.wasNew = this.isNew;\n *     });\n *\n *     schema.post('save', function() {\n *       // Prints true if `isNew` was set before `save()`\n *       console.log(this.$locals.wasNew);\n *     });\n *\n * @api public\n * @property $locals\n * @memberOf Document\n * @instance\n */\n\nObject.defineProperty(Document.prototype, '$locals', {\n  configurable: false,\n  enumerable: false,\n  get: function() {\n    if (this.$__.locals == null) {\n      this.$__.locals = {};\n    }\n    return this.$__.locals;\n  },\n  set: function(v) {\n    this.$__.locals = v;\n  }\n});\n\n/**\n * Legacy alias for `$isNew`.\n *\n * @api public\n * @property isNew\n * @memberOf Document\n * @see $isNew https://mongoosejs.com/docs/api/document.html#Document.prototype.$isNew\n * @instance\n */\n\nDocument.prototype.isNew;\n\n/**\n * Set this property to add additional query filters when Mongoose saves this document and `isNew` is false.\n *\n * #### Example:\n *\n *     // Make sure `save()` never updates a soft deleted document.\n *     schema.pre('save', function() {\n *       this.$where = { isDeleted: false };\n *     });\n *\n * @api public\n * @property $where\n * @memberOf Document\n * @instance\n */\n\nObject.defineProperty(Document.prototype, '$where', {\n  configurable: false,\n  enumerable: false,\n  writable: true\n});\n\n/**\n * The string version of this documents _id.\n *\n * #### Note:\n *\n * This getter exists on all documents by default. The getter can be disabled by setting the `id` [option](https://mongoosejs.com/docs/guide.html#id) of its `Schema` to false at construction time.\n *\n *     new Schema({ name: String }, { id: false });\n *\n * @api public\n * @see Schema options https://mongoosejs.com/docs/guide.html#options\n * @property id\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.id;\n\n/**\n * Hash containing current validation $errors.\n *\n * @api public\n * @property $errors\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.$errors;\n\n/**\n * A string containing the current operation that Mongoose is executing\n * on this document. May be `null`, `'save'`, `'validate'`, or `'remove'`.\n *\n * #### Example:\n *\n *     const doc = new Model({ name: 'test' });\n *     doc.$op; // null\n *\n *     const promise = doc.save();\n *     doc.$op; // 'save'\n *\n *     await promise;\n *     doc.$op; // null\n *\n * @api public\n * @property $op\n * @memberOf Document\n * @instance\n */\n\nObject.defineProperty(Document.prototype, '$op', {\n  get: function() {\n    return this.$__.op || null;\n  },\n  set: function(value) {\n    this.$__.op = value;\n  }\n});\n\n/*!\n * ignore\n */\n\nfunction $applyDefaultsToNested(val, path, doc) {\n  if (val == null) {\n    return;\n  }\n\n  const paths = Object.keys(doc.$__schema.paths);\n  const plen = paths.length;\n\n  const pathPieces = path.indexOf('.') === -1 ? [path] : path.split('.');\n\n  for (let i = 0; i < plen; ++i) {\n    let curPath = '';\n    const p = paths[i];\n\n    if (!p.startsWith(path + '.')) {\n      continue;\n    }\n\n    const type = doc.$__schema.paths[p];\n    const pieces = type.splitPath().slice(pathPieces.length);\n    const len = pieces.length;\n\n    if (type.defaultValue === void 0) {\n      continue;\n    }\n\n    let cur = val;\n\n    for (let j = 0; j < len; ++j) {\n      if (cur == null) {\n        break;\n      }\n\n      const piece = pieces[j];\n\n      if (j === len - 1) {\n        if (cur[piece] !== void 0) {\n          break;\n        }\n\n        try {\n          const def = type.getDefault(doc, false);\n          if (def !== void 0) {\n            cur[piece] = def;\n          }\n        } catch (err) {\n          doc.invalidate(path + '.' + curPath, err);\n          break;\n        }\n\n        break;\n      }\n\n      curPath += (!curPath.length ? '' : '.') + piece;\n\n      cur[piece] = cur[piece] || {};\n      cur = cur[piece];\n    }\n  }\n}\n\n/**\n * Builds the default doc structure\n *\n * @param {Object} obj\n * @param {Object} [fields]\n * @param {Boolean} [skipId]\n * @param {Boolean} [exclude]\n * @param {Object} [hasIncludedChildren]\n * @api private\n * @method $__buildDoc\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.$__buildDoc = function(obj, fields, skipId, exclude, hasIncludedChildren) {\n  const doc = {};\n\n  const paths = Object.keys(this.$__schema.paths).\n    // Don't build up any paths that are underneath a map, we don't know\n    // what the keys will be\n    filter(p => !p.includes('$*'));\n  const plen = paths.length;\n  let ii = 0;\n\n  for (; ii < plen; ++ii) {\n    const p = paths[ii];\n\n    if (p === '_id') {\n      if (skipId) {\n        continue;\n      }\n      if (obj && '_id' in obj) {\n        continue;\n      }\n    }\n\n    const path = this.$__schema.paths[p].splitPath();\n    const len = path.length;\n    const last = len - 1;\n    let curPath = '';\n    let doc_ = doc;\n    let included = false;\n\n    for (let i = 0; i < len; ++i) {\n      const piece = path[i];\n\n      if (!curPath.length) {\n        curPath = piece;\n      } else {\n        curPath += '.' + piece;\n      }\n\n      // support excluding intermediary levels\n      if (exclude === true) {\n        if (curPath in fields) {\n          break;\n        }\n      } else if (exclude === false && fields && !included) {\n        if (curPath in fields) {\n          included = true;\n        } else if (!hasIncludedChildren[curPath]) {\n          break;\n        }\n      }\n\n      if (i < last) {\n        doc_ = doc_[piece] || (doc_[piece] = {});\n      }\n    }\n  }\n\n  this._doc = doc;\n};\n\n/*!\n * Converts to POJO when you use the document for querying\n */\n\nDocument.prototype.toBSON = function() {\n  return this.toObject(internalToObjectOptions);\n};\n\n/**\n * Initializes the document without setters or marking anything modified.\n *\n * Called internally after a document is returned from mongodb. Normally,\n * you do **not** need to call this function on your own.\n *\n * This function triggers `init` [middleware](https://mongoosejs.com/docs/middleware.html).\n * Note that `init` hooks are [synchronous](https://mongoosejs.com/docs/middleware.html#synchronous).\n *\n * @param {Object} doc document returned by mongo\n * @param {Object} [opts]\n * @param {Function} [fn]\n * @api public\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.init = function(doc, opts, fn) {\n  if (typeof opts === 'function') {\n    fn = opts;\n    opts = null;\n  }\n\n  this.$__init(doc, opts);\n\n  if (fn) {\n    fn(null, this);\n  }\n\n  return this;\n};\n\n/**\n * Alias for [`.init`](https://mongoosejs.com/docs/api/document.html#Document.prototype.init())\n *\n * @api public\n */\n\nDocument.prototype.$init = function() {\n  return this.constructor.prototype.init.apply(this, arguments);\n};\n\n/**\n * Internal \"init\" function\n *\n * @param {Document} doc\n * @param {Object} [opts]\n * @returns {Document} this\n * @api private\n */\n\nDocument.prototype.$__init = function(doc, opts) {\n  this.$isNew = false;\n  opts = opts || {};\n\n  // handle docs with populated paths\n  // If doc._id is not null or undefined\n  if (doc._id != null && opts.populated && opts.populated.length) {\n    const id = String(doc._id);\n    for (const item of opts.populated) {\n      if (item.isVirtual) {\n        this.$populated(item.path, utils.getValue(item.path, doc), item);\n      } else {\n        this.$populated(item.path, item._docs[id], item);\n      }\n\n      if (item._childDocs == null) {\n        continue;\n      }\n      for (const child of item._childDocs) {\n        if (child == null || child.$__ == null) {\n          continue;\n        }\n        child.$__.parent = this;\n      }\n      item._childDocs = [];\n    }\n  }\n\n  init(this, doc, this._doc, opts);\n\n  markArraySubdocsPopulated(this, opts.populated);\n  this.$emit('init', this);\n  this.constructor.emit('init', this);\n\n  const hasIncludedChildren = this.$__.exclude === false && this.$__.selected ?\n    $__hasIncludedChildren(this.$__.selected) :\n    null;\n\n  applyDefaults(this, this.$__.selected, this.$__.exclude, hasIncludedChildren, false, this.$__.skipDefaults);\n  return this;\n};\n\n/**\n * Init helper.\n *\n * @param {Object} self document instance\n * @param {Object} obj raw mongodb doc\n * @param {Object} doc object we are initializing\n * @param {Object} [opts] Optional Options\n * @param {Boolean} [opts.setters] Call `applySetters` instead of `cast`\n * @param {String} [prefix] Prefix to add to each path\n * @api private\n */\n\nfunction init(self, obj, doc, opts, prefix) {\n  prefix = prefix || '';\n\n  if (obj.$__ != null) {\n    obj = obj._doc;\n  }\n  const keys = Object.keys(obj);\n  const len = keys.length;\n  let schemaType;\n  let path;\n  let i;\n  let index = 0;\n  const strict = self.$__.strictMode;\n  const docSchema = self.$__schema;\n\n  while (index < len) {\n    _init(index++);\n  }\n\n  function _init(index) {\n    i = keys[index];\n    // avoid prototype pollution\n    if (i === '__proto__' || i === 'constructor') {\n      return;\n    }\n    path = prefix ? prefix + i : i;\n    schemaType = docSchema.path(path);\n    // Should still work if not a model-level discriminator, but should not be\n    // necessary. This is *only* to catch the case where we queried using the\n    // base model and the discriminated model has a projection\n    if (docSchema.$isRootDiscriminator && !self.$__isSelected(path)) {\n      return;\n    }\n\n    const value = obj[i];\n    if (!schemaType && utils.isPOJO(value)) {\n      // assume nested object\n      if (!doc[i]) {\n        doc[i] = {};\n        if (!strict && !(i in docSchema.tree) && !(i in docSchema.methods) && !(i in docSchema.virtuals)) {\n          self[i] = doc[i];\n        }\n      }\n      init(self, value, doc[i], opts, path + '.');\n    } else if (!schemaType) {\n      doc[i] = value;\n      if (!strict && !prefix) {\n        self[i] = value;\n      }\n    } else {\n      // Retain order when overwriting defaults\n      if (doc.hasOwnProperty(i) && value !== void 0 && !opts.hydratedPopulatedDocs) {\n        delete doc[i];\n      }\n      if (value === null) {\n        doc[i] = schemaType._castNullish(null);\n      } else if (value !== undefined) {\n        const wasPopulated = value.$__ == null ? null : value.$__.wasPopulated;\n\n        if (schemaType && !wasPopulated && !opts.hydratedPopulatedDocs) {\n          try {\n            if (opts && opts.setters) {\n              // Call applySetters with `init = false` because otherwise setters are a noop\n              const overrideInit = false;\n              doc[i] = schemaType.applySetters(value, self, overrideInit);\n            } else {\n              doc[i] = schemaType.cast(value, self, true);\n            }\n          } catch (e) {\n            self.invalidate(e.path, new ValidatorError({\n              path: e.path,\n              message: e.message,\n              type: 'cast',\n              value: e.value,\n              reason: e\n            }));\n          }\n        } else {\n          doc[i] = value;\n        }\n      }\n      // mark as hydrated\n      if (!self.$isModified(path)) {\n        self.$__.activePaths.init(path);\n      }\n    }\n  }\n}\n\n/**\n * Sends an updateOne command with this document `_id` as the query selector.\n *\n * #### Example:\n *\n *     weirdCar.updateOne({$inc: {wheels:1}}, { w: 1 }, callback);\n *\n * #### Valid options:\n *\n *  - same as in [Model.updateOne](https://mongoosejs.com/docs/api/model.html#Model.updateOne)\n *\n * @see Model.updateOne https://mongoosejs.com/docs/api/model.html#Model.updateOne\n * @param {Object} doc\n * @param {Object} [options] optional see [`Query.prototype.setOptions()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.setOptions())\n * @param {Object} [options.lean] if truthy, mongoose will return the document as a plain JavaScript object rather than a mongoose document. See [`Query.lean()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.lean()) and the [Mongoose lean tutorial](https://mongoosejs.com/docs/tutorials/lean.html).\n * @param {Boolean|String} [options.strict] overwrites the schema's [strict mode option](https://mongoosejs.com/docs/guide.html#strict)\n * @param {Boolean} [options.timestamps=null] If set to `false` and [schema-level timestamps](https://mongoosejs.com/docs/guide.html#timestamps) are enabled, skip timestamps for this update. Note that this allows you to overwrite timestamps. Does nothing if schema-level timestamps are not set.\n * @param {Function} [callback]\n * @return {Query}\n * @api public\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.updateOne = function updateOne(doc, options, callback) {\n  const query = this.constructor.updateOne({ _id: this._id }, doc, options);\n  const self = this;\n  query.pre(function queryPreUpdateOne(cb) {\n    self.constructor._middleware.execPre('updateOne', self, [self], cb);\n  });\n  query.post(function queryPostUpdateOne(cb) {\n    self.constructor._middleware.execPost('updateOne', self, [self], {}, cb);\n  });\n\n  if (this.$session() != null) {\n    if (!('session' in query.options)) {\n      query.options.session = this.$session();\n    }\n  }\n\n  if (callback != null) {\n    return query.exec(callback);\n  }\n\n  return query;\n};\n\n/**\n * Sends a replaceOne command with this document `_id` as the query selector.\n *\n * #### Valid options:\n *\n *  - same as in [Model.replaceOne](https://mongoosejs.com/docs/api/model.html#Model.replaceOne())\n *\n * @see Model.replaceOne https://mongoosejs.com/docs/api/model.html#Model.replaceOne()\n * @param {Object} doc\n * @param {Object} [options]\n * @param {Function} [callback]\n * @return {Query}\n * @api public\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.replaceOne = function replaceOne() {\n  const args = [...arguments];\n  args.unshift({ _id: this._id });\n  return this.constructor.replaceOne.apply(this.constructor, args);\n};\n\n/**\n * Getter/setter around the session associated with this document. Used to\n * automatically set `session` if you `save()` a doc that you got from a\n * query with an associated session.\n *\n * #### Example:\n *\n *     const session = MyModel.startSession();\n *     const doc = await MyModel.findOne().session(session);\n *     doc.$session() === session; // true\n *     doc.$session(null);\n *     doc.$session() === null; // true\n *\n * If this is a top-level document, setting the session propagates to all child\n * docs.\n *\n * @param {ClientSession} [session] overwrite the current session\n * @return {ClientSession}\n * @method $session\n * @api public\n * @memberOf Document\n */\n\nDocument.prototype.$session = function $session(session) {\n  if (arguments.length === 0) {\n    if (this.$__.session != null && this.$__.session.hasEnded) {\n      this.$__.session = null;\n      return null;\n    }\n    return this.$__.session;\n  }\n\n  if (session != null && session.hasEnded) {\n    throw new MongooseError('Cannot set a document\\'s session to a session that has ended. Make sure you haven\\'t ' +\n      'called `endSession()` on the session you are passing to `$session()`.');\n  }\n\n  if (session == null && this.$__.session == null) {\n    return;\n  }\n\n  this.$__.session = session;\n\n  if (!this.$isSubdocument) {\n    const subdocs = this.$getAllSubdocs();\n    for (const child of subdocs) {\n      child.$session(session);\n    }\n  }\n\n  return session;\n};\n\n/**\n * Getter/setter around whether this document will apply timestamps by\n * default when using `save()` and `bulkSave()`.\n *\n * #### Example:\n *\n *     const TestModel = mongoose.model('Test', new Schema({ name: String }, { timestamps: true }));\n *     const doc = new TestModel({ name: 'John Smith' });\n *\n *     doc.$timestamps(); // true\n *\n *     doc.$timestamps(false);\n *     await doc.save(); // Does **not** apply timestamps\n *\n * @param {Boolean} [value] overwrite the current session\n * @return {Document|boolean|undefined} When used as a getter (no argument), a boolean will be returned indicating the timestamps option state or if unset \"undefined\" will be used, otherwise will return \"this\"\n * @method $timestamps\n * @api public\n * @memberOf Document\n */\n\nDocument.prototype.$timestamps = function $timestamps(value) {\n  if (arguments.length === 0) {\n    if (this.$__.timestamps != null) {\n      return this.$__.timestamps;\n    }\n\n    if (this.$__schema) {\n      return this.$__schema.options.timestamps;\n    }\n\n    return undefined;\n  }\n\n  const currentValue = this.$timestamps();\n  if (value !== currentValue) {\n    this.$__.timestamps = value;\n  }\n\n  return this;\n};\n\n/**\n * Overwrite all values in this document with the values of `obj`, except\n * for immutable properties. Behaves similarly to `set()`, except for it\n * unsets all properties that aren't in `obj`.\n *\n * @param {Object} obj the object to overwrite this document with\n * @method overwrite\n * @memberOf Document\n * @instance\n * @api public\n * @return {Document} this\n */\n\nDocument.prototype.overwrite = function overwrite(obj) {\n  const keys = Array.from(new Set(Object.keys(this._doc).concat(Object.keys(obj))));\n\n  for (const key of keys) {\n    if (key === '_id') {\n      continue;\n    }\n    // Explicitly skip version key\n    if (this.$__schema.options.versionKey && key === this.$__schema.options.versionKey) {\n      continue;\n    }\n    if (this.$__schema.options.discriminatorKey && key === this.$__schema.options.discriminatorKey) {\n      continue;\n    }\n    this.$set(key, obj[key]);\n  }\n\n  return this;\n};\n\n/**\n * Alias for `set()`, used internally to avoid conflicts\n *\n * @param {String|Object} path path or object of key/vals to set\n * @param {Any} val the value to set\n * @param {Schema|String|Number|Buffer|*} [type] optionally specify a type for \"on-the-fly\" attributes\n * @param {Object} [options] optionally specify options that modify the behavior of the set\n * @param {Boolean} [options.merge=false] if true, setting a [nested path](https://mongoosejs.com/docs/subdocs.html#subdocuments-versus-nested-paths) will merge existing values rather than overwrite the whole object. So `doc.set('nested', { a: 1, b: 2 })` becomes `doc.set('nested.a', 1); doc.set('nested.b', 2);`\n * @return {Document} this\n * @method $set\n * @memberOf Document\n * @instance\n * @api public\n */\n\nDocument.prototype.$set = function $set(path, val, type, options) {\n  if (utils.isPOJO(type)) {\n    options = type;\n    type = undefined;\n  }\n\n  const merge = options && options.merge;\n  const adhoc = type && type !== true;\n  const constructing = type === true;\n  let adhocs;\n  let keys;\n  let i = 0;\n  let pathtype;\n  let key;\n  let prefix;\n\n  const userSpecifiedStrict = options && 'strict' in options;\n  let strict = userSpecifiedStrict\n    ? options.strict\n    : this.$__.strictMode;\n\n  if (adhoc) {\n    adhocs = this.$__.adhocPaths || (this.$__.adhocPaths = {});\n    adhocs[path] = this.$__schema.interpretAsType(path, type, this.$__schema.options);\n  }\n\n  if (path == null) {\n    [path, val] = [val, path];\n  } else if (typeof path !== 'string') {\n    // new Document({ key: val })\n    if (path instanceof Document) {\n      if (path.$__isNested) {\n        path = path.toObject();\n      } else {\n        // This ternary is to support gh-7898 (copying virtuals if same schema)\n        // while not breaking gh-10819, which for some reason breaks if we use toObject()\n        path = path.$__schema === this.$__schema\n          ? applyVirtuals(path, { ...path._doc })\n          : path._doc;\n      }\n    }\n    if (path == null) {\n      [path, val] = [val, path];\n    }\n\n    prefix = val ? val + '.' : '';\n    keys = getKeysInSchemaOrder(this.$__schema, path);\n\n    const len = keys.length;\n\n    // `_skipMinimizeTopLevel` is because we may have deleted the top-level\n    // nested key to ensure key order.\n    const _skipMinimizeTopLevel = options && options._skipMinimizeTopLevel || false;\n    if (len === 0 && _skipMinimizeTopLevel) {\n      delete options._skipMinimizeTopLevel;\n      if (val) {\n        this.$set(val, {});\n      }\n      return this;\n    }\n\n    options = Object.assign({}, options, { _skipMinimizeTopLevel: false });\n\n    for (let i = 0; i < len; ++i) {\n      key = keys[i];\n      const pathName = prefix ? prefix + key : key;\n      pathtype = this.$__schema.pathType(pathName);\n      const valForKey = path[key];\n\n      // On initial set, delete any nested keys if we're going to overwrite\n      // them to ensure we keep the user's key order.\n      if (type === true &&\n          !prefix &&\n          valForKey != null &&\n          pathtype === 'nested' &&\n          this._doc[key] != null) {\n        delete this._doc[key];\n      }\n\n      if (utils.isNonBuiltinObject(valForKey) && pathtype === 'nested') {\n        this.$set(pathName, valForKey, constructing, Object.assign({}, options, { _skipMarkModified: true }));\n        $applyDefaultsToNested(this.$get(pathName), pathName, this);\n        continue;\n      } else if (strict) {\n        // Don't overwrite defaults with undefined keys (gh-3981) (gh-9039)\n        if (constructing && valForKey === void 0 &&\n            this.$get(pathName) !== void 0) {\n          continue;\n        }\n\n        if (pathtype === 'adhocOrUndefined') {\n          pathtype = getEmbeddedDiscriminatorPath(this, pathName, { typeOnly: true });\n        }\n\n        if (pathtype === 'real' || pathtype === 'virtual') {\n          this.$set(pathName, valForKey, constructing, options);\n        } else if (pathtype === 'nested' && valForKey instanceof Document) {\n          this.$set(pathName,\n            valForKey.toObject({ transform: false }), constructing, options);\n        } else if (strict === 'throw') {\n          if (pathtype === 'nested') {\n            throw new ObjectExpectedError(key, valForKey);\n          } else {\n            throw new StrictModeError(key);\n          }\n        } else if (pathtype === 'nested' && valForKey == null) {\n          this.$set(pathName, valForKey, constructing, options);\n        }\n      } else if (valForKey !== void 0) {\n        this.$set(pathName, valForKey, constructing, options);\n      }\n    }\n\n    // Ensure all properties are in correct order\n    const orderedDoc = {};\n    const orderedKeys = Object.keys(this.$__schema.tree);\n    for (let i = 0, len = orderedKeys.length; i < len; ++i) {\n      (key = orderedKeys[i]) &&\n      (this._doc.hasOwnProperty(key)) &&\n      (orderedDoc[key] = undefined);\n    }\n    this._doc = Object.assign(orderedDoc, this._doc);\n\n    return this;\n  }\n\n  let pathType = this.$__schema.pathType(path);\n  let parts = null;\n  if (pathType === 'adhocOrUndefined') {\n    parts = path.indexOf('.') === -1 ? [path] : path.split('.');\n    pathType = getEmbeddedDiscriminatorPath(this, parts, { typeOnly: true });\n  }\n  if (pathType === 'adhocOrUndefined' && !userSpecifiedStrict) {\n    // May be path underneath non-strict schema\n    if (parts == null) {\n      parts = path.indexOf('.') === -1 ? [path] : path.split('.');\n    }\n    const subdocStrict = getSubdocumentStrictValue(this.$__schema, parts);\n    if (subdocStrict !== undefined) {\n      strict = subdocStrict;\n    }\n  }\n\n  // Assume this is a Mongoose document that was copied into a POJO using\n  // `Object.assign()` or `{...doc}`\n  val = handleSpreadDoc(val, true);\n\n  // if this doc is being constructed we should not trigger getters\n  const priorVal = (() => {\n    if (this.$__.priorDoc != null) {\n      return this.$__.priorDoc.$__getValue(path);\n    }\n    if (constructing) {\n      return void 0;\n    }\n    return this.$__getValue(path);\n  })();\n\n  if (pathType === 'nested' && val) {\n    if (typeof val === 'object' && val != null) {\n      if (val.$__ != null) {\n        val = val.toObject(internalToObjectOptions);\n      }\n      if (val == null) {\n        this.invalidate(path, new MongooseError.CastError('Object', val, path));\n        return this;\n      }\n      const wasModified = this.$isModified(path);\n      const hasInitialVal = this.$__.savedState != null && this.$__.savedState.hasOwnProperty(path);\n      if (this.$__.savedState != null && !this.$isNew && !this.$__.savedState.hasOwnProperty(path)) {\n        const initialVal = this.$__getValue(path);\n        this.$__.savedState[path] = initialVal;\n\n        const keys = Object.keys(initialVal || {});\n        for (const key of keys) {\n          this.$__.savedState[path + '.' + key] = initialVal[key];\n        }\n      }\n\n      if (!merge) {\n        this.$__setValue(path, null);\n        cleanModifiedSubpaths(this, path);\n      } else {\n        return this.$set(val, path, constructing);\n      }\n\n      const keys = getKeysInSchemaOrder(this.$__schema, val, path);\n\n      this.$__setValue(path, {});\n      for (const key of keys) {\n        this.$set(path + '.' + key, val[key], constructing, { ...options, _skipMarkModified: true });\n      }\n      if (priorVal != null &&\n          (!wasModified || hasInitialVal) &&\n          utils.deepEqual(hasInitialVal ? this.$__.savedState[path] : priorVal, val)) {\n        this.unmarkModified(path);\n      } else {\n        this.markModified(path);\n      }\n      return this;\n    }\n    this.invalidate(path, new MongooseError.CastError('Object', val, path));\n    return this;\n  }\n\n  let schema;\n  if (parts == null) {\n    parts = path.indexOf('.') === -1 ? [path] : path.split('.');\n  }\n\n  // Might need to change path for top-level alias\n  if (typeof this.$__schema.aliases[parts[0]] === 'string') {\n    parts[0] = this.$__schema.aliases[parts[0]];\n  }\n\n  if (pathType === 'adhocOrUndefined' && strict) {\n    // check for roots that are Mixed types\n    let mixed;\n\n    for (i = 0; i < parts.length; ++i) {\n      const subpath = parts.slice(0, i + 1).join('.');\n\n      // If path is underneath a virtual, bypass everything and just set it.\n      if (i + 1 < parts.length && this.$__schema.pathType(subpath) === 'virtual') {\n        mpath.set(path, val, this);\n        return this;\n      }\n\n      schema = this.$__schema.path(subpath);\n      if (schema == null) {\n        continue;\n      }\n\n      if (schema instanceof MixedSchema) {\n        // allow changes to sub paths of mixed types\n        mixed = true;\n        break;\n      } else if (schema.$isSchemaMap && schema.$__schemaType instanceof MixedSchema && i < parts.length - 1) {\n        // Map of mixed and not the last element in the path resolves to mixed\n        mixed = true;\n        schema = schema.$__schemaType;\n        break;\n      }\n    }\n\n    if (schema == null) {\n      // Check for embedded discriminators\n      schema = getEmbeddedDiscriminatorPath(this, path);\n    }\n\n    if (!mixed && !schema) {\n      if (strict === 'throw') {\n        throw new StrictModeError(path);\n      }\n      return this;\n    }\n  } else if (pathType === 'virtual') {\n    schema = this.$__schema.virtualpath(path);\n    schema.applySetters(val, this);\n    return this;\n  } else {\n    schema = this.$__path(path);\n  }\n\n  // gh-4578, if setting a deeply nested path that doesn't exist yet, create it\n  let cur = this._doc;\n  let curPath = '';\n  for (i = 0; i < parts.length - 1; ++i) {\n    cur = cur[parts[i]];\n    curPath += (curPath.length !== 0 ? '.' : '') + parts[i];\n    if (!cur) {\n      this.$set(curPath, {});\n      // Hack re: gh-5800. If nested field is not selected, it probably exists\n      // so `MongoServerError: cannot use the part (nested of nested.num) to\n      // traverse the element ({nested: null})` is not likely. If user gets\n      // that error, its their fault for now. We should reconsider disallowing\n      // modifying not selected paths for 6.x\n      if (!this.$__isSelected(curPath)) {\n        this.unmarkModified(curPath);\n      }\n      cur = this.$__getValue(curPath);\n    }\n  }\n\n  let pathToMark;\n\n  // When using the $set operator the path to the field must already exist.\n  // Else mongodb throws: \"LEFT_SUBFIELD only supports Object\"\n\n  if (parts.length <= 1) {\n    pathToMark = path;\n  } else {\n    const len = parts.length;\n    for (i = 0; i < len; ++i) {\n      const subpath = parts.slice(0, i + 1).join('.');\n      if (this.$get(subpath, null, { getters: false }) === null) {\n        pathToMark = subpath;\n        break;\n      }\n    }\n\n    if (!pathToMark) {\n      pathToMark = path;\n    }\n  }\n\n  if (!schema) {\n    this.$__set(pathToMark, path, options, constructing, parts, schema, val, priorVal);\n\n    if (pathType === 'nested' && val == null) {\n      cleanModifiedSubpaths(this, path);\n    }\n    return this;\n  }\n\n  // If overwriting a subdocument path, make sure to clear out\n  // any errors _before_ setting, so new errors that happen\n  // get persisted. Re: #9080\n  if (schema.$isSingleNested || schema.$isMongooseArray) {\n    _markValidSubpaths(this, path);\n  }\n\n  if (val != null && merge && schema.$isSingleNested) {\n    if (val instanceof Document) {\n      val = val.toObject({ virtuals: false, transform: false });\n    }\n    const keys = Object.keys(val);\n    for (const key of keys) {\n      this.$set(path + '.' + key, val[key], constructing, options);\n    }\n\n    return this;\n  }\n\n  let shouldSet = true;\n  try {\n    // If the user is trying to set a ref path to a document with\n    // the correct model name, treat it as populated\n    const refMatches = (() => {\n      if (schema.options == null) {\n        return false;\n      }\n      if (!(val instanceof Document)) {\n        return false;\n      }\n      const model = val.constructor;\n\n      // Check ref\n      const ref = schema.options.ref;\n      if (ref != null && (ref === model.modelName || ref === model.baseModelName)) {\n        return true;\n      }\n\n      // Check refPath\n      const refPath = schema.options.refPath;\n      if (refPath == null) {\n        return false;\n      }\n      const modelName = val.get(refPath);\n      return modelName === model.modelName || modelName === model.baseModelName;\n    })();\n\n    let didPopulate = false;\n    if (refMatches && val instanceof Document && (!val.$__.wasPopulated || utils.deepEqual(val.$__.wasPopulated.value, val._doc._id))) {\n      const unpopulatedValue = (schema && schema.$isSingleNested) ? schema.cast(val, this) : val._doc._id;\n      this.$populated(path, unpopulatedValue, { [populateModelSymbol]: val.constructor });\n      val.$__.wasPopulated = { value: unpopulatedValue };\n      didPopulate = true;\n    }\n\n    let popOpts;\n    const typeKey = this.$__schema.options.typeKey;\n    if (schema.options &&\n        Array.isArray(schema.options[typeKey]) &&\n        schema.options[typeKey].length &&\n        schema.options[typeKey][0] &&\n        schema.options[typeKey][0].ref &&\n        _isManuallyPopulatedArray(val, schema.options[typeKey][0].ref)) {\n      popOpts = { [populateModelSymbol]: val[0].constructor };\n      this.$populated(path, val.map(function(v) { return v._doc._id; }), popOpts);\n\n      for (const doc of val) {\n        doc.$__.wasPopulated = { value: doc._doc._id };\n      }\n      didPopulate = true;\n    }\n\n    if (!refMatches || !schema.$isSingleNested || !val.$__) {\n      // If this path is underneath a single nested schema, we'll call the setter\n      // later in `$__set()` because we don't take `_doc` when we iterate through\n      // a single nested doc. That's to make sure we get the correct context.\n      // Otherwise we would double-call the setter, see gh-7196.\n      let setterContext = this;\n      if (this.$__schema.singleNestedPaths[path] != null && parts.length > 1) {\n        setterContext = getDeepestSubdocumentForPath(this, parts, this.schema);\n      }\n      if (options != null && options.overwriteImmutable) {\n        val = schema.applySetters(val, setterContext, false, priorVal, { overwriteImmutable: true });\n      } else {\n        val = schema.applySetters(val, setterContext, false, priorVal);\n      }\n    }\n\n    if (Array.isArray(val) &&\n        !Array.isArray(schema) &&\n        schema.$isMongooseDocumentArray &&\n        val.length !== 0 &&\n        val[0] != null &&\n        val[0].$__ != null &&\n        val[0].$__.populated != null) {\n      const populatedPaths = Object.keys(val[0].$__.populated);\n      for (const populatedPath of populatedPaths) {\n        this.$populated(path + '.' + populatedPath,\n          val.map(v => v.$populated(populatedPath)),\n          val[0].$__.populated[populatedPath].options);\n      }\n      didPopulate = true;\n    }\n\n    if (!didPopulate && this.$__.populated) {\n      // If this array partially contains populated documents, convert them\n      // all to ObjectIds re: #8443\n      if (Array.isArray(val) && this.$__.populated[path]) {\n        for (let i = 0; i < val.length; ++i) {\n          if (val[i] instanceof Document) {\n            val.set(i, val[i]._doc._id, true);\n          }\n        }\n      }\n      delete this.$__.populated[path];\n    }\n\n    if (val != null && schema.$isSingleNested) {\n      _checkImmutableSubpaths(val, schema, priorVal);\n    }\n\n    this.$markValid(path);\n  } catch (e) {\n    if (e instanceof MongooseError.StrictModeError && e.isImmutableError) {\n      this.invalidate(path, e);\n    } else if (e instanceof MongooseError.CastError) {\n      this.invalidate(e.path, e);\n      if (e.$originalErrorPath) {\n        this.invalidate(path,\n          new MongooseError.CastError(schema.instance, val, path, e.$originalErrorPath));\n      }\n    } else {\n      this.invalidate(path,\n        new MongooseError.CastError(schema.instance, val, path, e));\n    }\n    shouldSet = false;\n  }\n\n  if (shouldSet) {\n    let savedState = null;\n    let savedStatePath = null;\n    if (!constructing) {\n      const doc = this.$isSubdocument ? this.ownerDocument() : this;\n      savedState = doc.$__.savedState;\n      savedStatePath = this.$isSubdocument ? this.$__.fullPath + '.' + path : path;\n      doc.$__saveInitialState(savedStatePath);\n    }\n\n    this.$__set(pathToMark, path, options, constructing, parts, schema, val, priorVal);\n\n    const isInTransaction = !!this.$__.session?.transaction;\n    const isModifiedWithinTransaction = this.$__.session &&\n      this.$__.session[sessionNewDocuments] &&\n      this.$__.session[sessionNewDocuments].has(this) &&\n      this.$__.session[sessionNewDocuments].get(this).modifiedPaths &&\n      !this.$__.session[sessionNewDocuments].get(this).modifiedPaths.has(savedStatePath);\n    if (savedState != null &&\n        savedState.hasOwnProperty(savedStatePath) &&\n        (!isInTransaction || isModifiedWithinTransaction) &&\n        utils.deepEqual(val, savedState[savedStatePath])) {\n      this.unmarkModified(path);\n    }\n  }\n\n  if (schema.$isSingleNested && (this.isDirectModified(path) || val == null)) {\n    cleanModifiedSubpaths(this, path);\n  }\n\n  return this;\n};\n\n/*!\n * ignore\n */\n\nfunction _isManuallyPopulatedArray(val, ref) {\n  if (!Array.isArray(val)) {\n    return false;\n  }\n  if (val.length === 0) {\n    return false;\n  }\n\n  for (const el of val) {\n    if (!(el instanceof Document)) {\n      return false;\n    }\n    const modelName = el.constructor.modelName;\n    if (modelName == null) {\n      return false;\n    }\n    if (el.constructor.modelName != ref && el.constructor.baseModelName != ref) {\n      return false;\n    }\n  }\n\n  return true;\n}\n\n/**\n * Sets the value of a path, or many paths.\n * Alias for [`.$set`](https://mongoosejs.com/docs/api/document.html#Document.prototype.$set()).\n *\n * #### Example:\n *\n *     // path, value\n *     doc.set(path, value)\n *\n *     // object\n *     doc.set({\n *         path  : value\n *       , path2 : {\n *            path  : value\n *         }\n *     })\n *\n *     // on-the-fly cast to number\n *     doc.set(path, value, Number)\n *\n *     // on-the-fly cast to string\n *     doc.set(path, value, String)\n *\n *     // changing strict mode behavior\n *     doc.set(path, value, { strict: false });\n *\n * @param {String|Object} path path or object of key/vals to set\n * @param {Any} val the value to set\n * @param {Schema|String|Number|Buffer|*} [type] optionally specify a type for \"on-the-fly\" attributes\n * @param {Object} [options] optionally specify options that modify the behavior of the set\n * @return {Document} this\n * @api public\n * @method set\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.set = Document.prototype.$set;\n\n/**\n * Determine if we should mark this change as modified.\n *\n * @param {never} pathToMark UNUSED\n * @param {String|Symbol} path\n * @param {Object} options\n * @param {Any} constructing\n * @param {never} parts UNUSED\n * @param {Schema} schema\n * @param {Any} val\n * @param {Any} priorVal\n * @return {Boolean}\n * @api private\n * @method $__shouldModify\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.$__shouldModify = function(pathToMark, path, options, constructing, parts, schema, val, priorVal) {\n  if (options && options._skipMarkModified) {\n    return false;\n  }\n  if (this.$isNew) {\n    return true;\n  }\n  // Is path already modified? If so, always modify. We may unmark modified later.\n  if (path in this.$__.activePaths.getStatePaths('modify')) {\n    return true;\n  }\n\n  if (val === void 0 && !this.$__isSelected(path)) {\n    // when a path is not selected in a query, its initial\n    // value will be undefined.\n    return true;\n  }\n\n  if (val === void 0 && path in this.$__.activePaths.getStatePaths('default')) {\n    // we're just unsetting the default value which was never saved\n    return false;\n  }\n\n  // gh-3992: if setting a populated field to a doc, don't mark modified\n  // if they have the same _id\n  if (this.$populated(path) &&\n      val instanceof Document &&\n      deepEqual(val._doc._id, priorVal)) {\n    return false;\n  }\n\n  if (!deepEqual(val, priorVal !== undefined ? priorVal : utils.getValue(path, this))) {\n    return true;\n  }\n\n  if (!constructing &&\n      val !== null &&\n      val !== undefined &&\n      path in this.$__.activePaths.getStatePaths('default') &&\n      deepEqual(val, schema.getDefault(this, constructing))) {\n    // a path with a default was $unset on the server\n    // and the user is setting it to the same value again\n    return true;\n  }\n  return false;\n};\n\n/**\n * Handles the actual setting of the value and marking the path modified if appropriate.\n *\n * @param {String} pathToMark\n * @param {String|Symbol} path\n * @param {Object} options\n * @param {Any} constructing\n * @param {Array} parts\n * @param {Schema} schema\n * @param {Any} val\n * @param {Any} priorVal\n * @api private\n * @method $__set\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.$__set = function(pathToMark, path, options, constructing, parts, schema, val, priorVal) {\n  Embedded = Embedded || __webpack_require__(/*! ./types/arraySubdocument */ \"./node_modules/mongoose/lib/types/arraySubdocument.js\");\n\n  const shouldModify = this.$__shouldModify(pathToMark, path, options, constructing, parts,\n    schema, val, priorVal);\n\n  if (shouldModify) {\n    if (this.$__.primitiveAtomics && this.$__.primitiveAtomics[path]) {\n      delete this.$__.primitiveAtomics[path];\n      if (Object.keys(this.$__.primitiveAtomics).length === 0) {\n        delete this.$__.primitiveAtomics;\n      }\n    }\n    this.markModified(pathToMark);\n\n    // handle directly setting arrays (gh-1126)\n    MongooseArray || (MongooseArray = __webpack_require__(/*! ./types/array */ \"./node_modules/mongoose/lib/types/array/index.js\"));\n    if (val && utils.isMongooseArray(val)) {\n      val._registerAtomic('$set', val);\n\n      // Update embedded document parent references (gh-5189)\n      if (utils.isMongooseDocumentArray(val)) {\n        val.forEach(function(item) {\n          item && item.__parentArray && (item.__parentArray = val);\n        });\n      }\n    }\n  } else if (Array.isArray(val) && Array.isArray(priorVal) && utils.isMongooseArray(val) && utils.isMongooseArray(priorVal)) {\n    val[arrayAtomicsSymbol] = priorVal[arrayAtomicsSymbol];\n    val[arrayAtomicsBackupSymbol] = priorVal[arrayAtomicsBackupSymbol];\n    if (utils.isMongooseDocumentArray(val)) {\n      val.forEach(doc => {\n        if (doc != null) {\n          doc.$isNew = false;\n        }\n      });\n    }\n  }\n\n  let obj = this._doc;\n  let i = 0;\n  const l = parts.length;\n  let cur = '';\n\n  for (; i < l; i++) {\n    const next = i + 1;\n    const last = next === l;\n    cur += (cur ? '.' + parts[i] : parts[i]);\n    if (specialProperties.has(parts[i])) {\n      return;\n    }\n\n    if (last) {\n      if (obj instanceof Map) {\n        obj.set(parts[i], val);\n      } else if (obj.$isSingleNested) {\n        if (!(parts[i] in obj)) {\n          obj[parts[i]] = val;\n          obj._doc[parts[i]] = val;\n        } else {\n          obj._doc[parts[i]] = val;\n        }\n        if (shouldModify) {\n          obj.markModified(parts[i]);\n        }\n      } else {\n        obj[parts[i]] = val;\n      }\n    } else {\n      const isMap = obj instanceof Map;\n      let value = isMap ? obj.get(parts[i]) : obj[parts[i]];\n      if (utils.isPOJO(value)) {\n        obj = value;\n      } else if (value && value instanceof Embedded) {\n        obj = value;\n      } else if (value && !Array.isArray(value) && value.$isSingleNested) {\n        obj = value;\n      } else if (value && Array.isArray(value)) {\n        obj = value;\n      } else if (value == null) {\n        value = {};\n        if (isMap) {\n          obj.set(parts[i], value);\n        } else {\n          obj[parts[i]] = value;\n        }\n        obj = value;\n      } else {\n        obj = value;\n      }\n    }\n  }\n};\n\n/**\n * Gets a raw value from a path (no getters)\n *\n * @param {String} path\n * @return {Any} Returns the value from the given `path`.\n * @api private\n */\n\nDocument.prototype.$__getValue = function(path) {\n  return utils.getValue(path, this._doc);\n};\n\n/**\n * Increments the numeric value at `path` by the given `val`.\n * When you call `save()` on this document, Mongoose will send a\n * [`$inc`](https://www.mongodb.com/docs/manual/reference/operator/update/inc/)\n * as opposed to a `$set`.\n *\n * #### Example:\n *\n *     const schema = new Schema({ counter: Number });\n *     const Test = db.model('Test', schema);\n *\n *     const doc = await Test.create({ counter: 0 });\n *     doc.$inc('counter', 2);\n *     await doc.save(); // Sends a `{ $inc: { counter: 2 } }` to MongoDB\n *     doc.counter; // 2\n *\n *     doc.counter += 2;\n *     await doc.save(); // Sends a `{ $set: { counter: 2 } }` to MongoDB\n *\n * @param {String|Array} path path or paths to update\n * @param {Number} val increment `path` by this value\n * @return {Document} this\n */\n\nDocument.prototype.$inc = function $inc(path, val) {\n  if (val == null) {\n    val = 1;\n  }\n\n  if (Array.isArray(path)) {\n    path.forEach((p) => this.$inc(p, val));\n    return this;\n  }\n\n  const schemaType = this.$__path(path);\n  if (schemaType == null) {\n    if (this.$__.strictMode === 'throw') {\n      throw new StrictModeError(path);\n    } else if (this.$__.strictMode === true) {\n      return this;\n    }\n  } else if (schemaType.instance !== 'Number') {\n    this.invalidate(path, new MongooseError.CastError(schemaType.instance, val, path));\n    return this;\n  }\n\n  const currentValue = this.$__getValue(path) || 0;\n  let shouldSet = false;\n  let valToSet = null;\n  let valToInc = val;\n\n  try {\n    val = schemaType.cast(val);\n    valToSet = schemaType.applySetters(currentValue + val, this);\n    valToInc = valToSet - currentValue;\n    shouldSet = true;\n  } catch (err) {\n    this.invalidate(path, new MongooseError.CastError('number', val, path, err));\n  }\n\n  if (shouldSet) {\n    this.$__.primitiveAtomics = this.$__.primitiveAtomics || {};\n    if (this.$__.primitiveAtomics[path] == null) {\n      this.$__.primitiveAtomics[path] = { $inc: valToInc };\n    } else {\n      this.$__.primitiveAtomics[path].$inc += valToInc;\n    }\n    this.markModified(path);\n    this.$__setValue(path, valToSet);\n  }\n\n  return this;\n};\n\n/**\n * Sets a raw value for a path (no casting, setters, transformations)\n *\n * @param {String} path\n * @param {Object} value\n * @return {Document} this\n * @api private\n */\n\nDocument.prototype.$__setValue = function(path, val) {\n  utils.setValue(path, val, this._doc);\n  return this;\n};\n\n/**\n * Returns the value of a path.\n *\n * #### Example:\n *\n *     // path\n *     doc.get('age') // 47\n *\n *     // dynamic casting to a string\n *     doc.get('age', String) // \"47\"\n *\n * @param {String} path\n * @param {Schema|String|Number|Buffer|*} [type] optionally specify a type for on-the-fly attributes\n * @param {Object} [options]\n * @param {Boolean} [options.virtuals=false] Apply virtuals before getting this path\n * @param {Boolean} [options.getters=true] If false, skip applying getters and just get the raw value\n * @return {Any}\n * @api public\n */\n\nDocument.prototype.get = function(path, type, options) {\n  let adhoc;\n  if (options == null) {\n    options = {};\n  }\n  if (type) {\n    adhoc = this.$__schema.interpretAsType(path, type, this.$__schema.options);\n  }\n  const noDottedPath = options.noDottedPath;\n\n  // Fast path if we know we're just accessing top-level path on the document:\n  // just get the schema path, avoid `$__path()` because that does string manipulation\n  let schema = noDottedPath ? this.$__schema.paths[path] : this.$__path(path);\n  if (schema == null) {\n    schema = this.$__schema.virtualpath(path);\n\n    if (schema != null) {\n      return schema.applyGetters(void 0, this);\n    }\n  }\n\n  if (noDottedPath) {\n    let obj = this._doc[path];\n    if (adhoc) {\n      obj = adhoc.cast(obj);\n    }\n    if (schema != null && options.getters !== false) {\n      return schema.applyGetters(obj, this);\n    }\n    return obj;\n  }\n\n  if (schema != null && schema.instance === 'Mixed') {\n    const virtual = this.$__schema.virtualpath(path);\n    if (virtual != null) {\n      schema = virtual;\n    }\n  }\n\n  const hasDot = path.indexOf('.') !== -1;\n  let obj = this._doc;\n\n  const pieces = hasDot ? path.split('.') : [path];\n  // Might need to change path for top-level alias\n  if (typeof this.$__schema.aliases[pieces[0]] === 'string') {\n    pieces[0] = this.$__schema.aliases[pieces[0]];\n  }\n\n  for (let i = 0, l = pieces.length; i < l; i++) {\n    if (obj && obj._doc) {\n      obj = obj._doc;\n    }\n\n    if (obj == null) {\n      obj = void 0;\n    } else if (obj instanceof Map) {\n      obj = obj.get(pieces[i], { getters: false });\n    } else if (i === l - 1) {\n      obj = utils.getValue(pieces[i], obj);\n    } else {\n      obj = obj[pieces[i]];\n    }\n  }\n\n  if (adhoc) {\n    obj = adhoc.cast(obj);\n  }\n\n  if (schema != null && options.getters !== false) {\n    obj = schema.applyGetters(obj, this);\n  } else if (this.$__schema.nested[path] && options.virtuals) {\n    // Might need to apply virtuals if this is a nested path\n    return applyVirtuals(this, clone(obj) || {}, { path: path });\n  }\n\n  return obj;\n};\n\n/*!\n * ignore\n */\n\nDocument.prototype[getSymbol] = Document.prototype.get;\nDocument.prototype.$get = Document.prototype.get;\n\n/**\n * Returns the schematype for the given `path`.\n *\n * @param {String} path\n * @return {SchemaPath}\n * @api private\n * @method $__path\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.$__path = function(path) {\n  const adhocs = this.$__.adhocPaths;\n  const adhocType = adhocs && adhocs.hasOwnProperty(path) ? adhocs[path] : null;\n\n  if (adhocType) {\n    return adhocType;\n  }\n  return this.$__schema.path(path);\n};\n\n/**\n * Marks the path as having pending changes to write to the db.\n *\n * _Very helpful when using [Mixed](https://mongoosejs.com/docs/schematypes.html#mixed) types._\n *\n * #### Example:\n *\n *     doc.mixed.type = 'changed';\n *     doc.markModified('mixed.type');\n *     doc.save() // changes to mixed.type are now persisted\n *\n * @param {String} path the path to mark modified\n * @param {Document} [scope] the scope to run validators with\n * @api public\n */\n\nDocument.prototype.markModified = function(path, scope) {\n  this.$__saveInitialState(path);\n\n  this.$__.activePaths.modify(path);\n  if (scope != null && !this.$isSubdocument) {\n    this.$__.pathsToScopes = this.$__pathsToScopes || {};\n    this.$__.pathsToScopes[path] = scope;\n  }\n};\n\n/*!\n * ignore\n */\n\nDocument.prototype.$__saveInitialState = function $__saveInitialState(path) {\n  const savedState = this.$__.savedState;\n  const savedStatePath = path;\n  if (savedState != null) {\n    const firstDot = savedStatePath.indexOf('.');\n    const topLevelPath = firstDot === -1 ? savedStatePath : savedStatePath.slice(0, firstDot);\n    if (!savedState.hasOwnProperty(topLevelPath)) {\n      savedState[topLevelPath] = clone(this.$__getValue(topLevelPath));\n    }\n  }\n};\n\n/**\n * Clears the modified state on the specified path.\n *\n * #### Example:\n *\n *     doc.foo = 'bar';\n *     doc.unmarkModified('foo');\n *     doc.save(); // changes to foo will not be persisted\n *\n * @param {String} path the path to unmark modified\n * @api public\n */\n\nDocument.prototype.unmarkModified = function(path) {\n  this.$__.activePaths.init(path);\n  if (this.$__.pathsToScopes != null) {\n    delete this.$__.pathsToScopes[path];\n  }\n};\n\n/**\n * Don't run validation on this path or persist changes to this path.\n *\n * #### Example:\n *\n *     doc.foo = null;\n *     doc.$ignore('foo');\n *     doc.save(); // changes to foo will not be persisted and validators won't be run\n *\n * @memberOf Document\n * @instance\n * @method $ignore\n * @param {String} path the path to ignore\n * @api public\n */\n\nDocument.prototype.$ignore = function(path) {\n  this.$__.activePaths.ignore(path);\n};\n\n/**\n * Returns the list of paths that have been directly modified. A direct\n * modified path is a path that you explicitly set, whether via `doc.foo = 'bar'`,\n * `Object.assign(doc, { foo: 'bar' })`, or `doc.set('foo', 'bar')`.\n *\n * A path `a` may be in `modifiedPaths()` but not in `directModifiedPaths()`\n * because a child of `a` was directly modified.\n *\n * #### Example:\n *\n *     const schema = new Schema({ foo: String, nested: { bar: String } });\n *     const Model = mongoose.model('Test', schema);\n *     await Model.create({ foo: 'original', nested: { bar: 'original' } });\n *\n *     const doc = await Model.findOne();\n *     doc.nested.bar = 'modified';\n *     doc.directModifiedPaths(); // ['nested.bar']\n *     doc.modifiedPaths(); // ['nested', 'nested.bar']\n *\n * @return {String[]}\n * @api public\n */\n\nDocument.prototype.directModifiedPaths = function() {\n  return Object.keys(this.$__.activePaths.getStatePaths('modify'));\n};\n\n/**\n * Returns true if the given path is nullish or only contains empty objects.\n * Useful for determining whether this subdoc will get stripped out by the\n * [minimize option](https://mongoosejs.com/docs/guide.html#minimize).\n *\n * #### Example:\n *\n *     const schema = new Schema({ nested: { foo: String } });\n *     const Model = mongoose.model('Test', schema);\n *     const doc = new Model({});\n *     doc.$isEmpty('nested'); // true\n *     doc.nested.$isEmpty(); // true\n *\n *     doc.nested.foo = 'bar';\n *     doc.$isEmpty('nested'); // false\n *     doc.nested.$isEmpty(); // false\n *\n * @param {String} [path]\n * @memberOf Document\n * @instance\n * @api public\n * @method $isEmpty\n * @return {Boolean}\n */\n\nDocument.prototype.$isEmpty = function(path) {\n  const isEmptyOptions = {\n    minimize: true,\n    virtuals: false,\n    getters: false,\n    transform: false\n  };\n\n  if (arguments.length !== 0) {\n    const v = this.$get(path);\n    if (v == null) {\n      return true;\n    }\n    if (typeof v !== 'object') {\n      return false;\n    }\n    if (utils.isPOJO(v)) {\n      return _isEmpty(v);\n    }\n    return Object.keys(v.toObject(isEmptyOptions)).length === 0;\n  }\n\n  return Object.keys(this.toObject(isEmptyOptions)).length === 0;\n};\n\n/*!\n * ignore\n */\n\nfunction _isEmpty(v) {\n  if (v == null) {\n    return true;\n  }\n  if (typeof v !== 'object' || Array.isArray(v)) {\n    return false;\n  }\n  for (const key of Object.keys(v)) {\n    if (!_isEmpty(v[key])) {\n      return false;\n    }\n  }\n  return true;\n}\n\n/**\n * Returns the list of paths that have been modified.\n *\n * @param {Object} [options]\n * @param {Boolean} [options.includeChildren=false] if true, returns children of modified paths as well. For example, if false, the list of modified paths for `doc.colors = { primary: 'blue' };` will **not** contain `colors.primary`. If true, `modifiedPaths()` will return an array that contains `colors.primary`.\n * @return {String[]}\n * @api public\n */\n\nDocument.prototype.modifiedPaths = function(options) {\n  options = options || {};\n\n  const directModifiedPaths = Object.keys(this.$__.activePaths.getStatePaths('modify'));\n  const result = new Set();\n\n  let i = 0;\n  let j = 0;\n  const len = directModifiedPaths.length;\n\n  for (i = 0; i < len; ++i) {\n    const path = directModifiedPaths[i];\n    const parts = parentPaths(path);\n    const pLen = parts.length;\n\n    for (j = 0; j < pLen; ++j) {\n      result.add(parts[j]);\n    }\n\n    if (!options.includeChildren) {\n      continue;\n    }\n\n    let ii = 0;\n    let cur = this.$get(path);\n    if (typeof cur === 'object' && cur !== null) {\n      if (cur._doc) {\n        cur = cur._doc;\n      }\n      const len = cur.length;\n      if (Array.isArray(cur)) {\n        for (ii = 0; ii < len; ++ii) {\n          const subPath = path + '.' + ii;\n          if (!result.has(subPath)) {\n            result.add(subPath);\n            if (cur[ii] != null && cur[ii].$__) {\n              const modified = cur[ii].modifiedPaths();\n              let iii = 0;\n              const iiiLen = modified.length;\n              for (iii = 0; iii < iiiLen; ++iii) {\n                result.add(subPath + '.' + modified[iii]);\n              }\n            }\n          }\n        }\n      } else {\n        const keys = Object.keys(cur);\n        let ii = 0;\n        const len = keys.length;\n        for (ii = 0; ii < len; ++ii) {\n          result.add(path + '.' + keys[ii]);\n        }\n      }\n    }\n  }\n  return Array.from(result);\n};\n\nDocument.prototype[documentModifiedPaths] = Document.prototype.modifiedPaths;\n\n/**\n * Returns true if any of the given paths is modified, else false. If no arguments, returns `true` if any path\n * in this document is modified.\n *\n * If `path` is given, checks if a path or any full path containing `path` as part of its path chain has been modified.\n *\n * #### Example:\n *\n *     doc.set('documents.0.title', 'changed');\n *     doc.isModified()                      // true\n *     doc.isModified('documents')           // true\n *     doc.isModified('documents.0.title')   // true\n *     doc.isModified('documents otherProp') // true\n *     doc.isDirectModified('documents')     // false\n *\n * @param {String} [path] optional\n * @param {Object} [options]\n * @param {Boolean} [options.ignoreAtomics=false] If true, doesn't return true if path is underneath an array that was modified with atomic operations like `push()`\n * @return {Boolean}\n * @api public\n */\n\nDocument.prototype.isModified = function(paths, options, modifiedPaths) {\n  if (paths) {\n    const ignoreAtomics = options && options.ignoreAtomics;\n    const directModifiedPathsObj = this.$__.activePaths.states.modify;\n    if (directModifiedPathsObj == null) {\n      return false;\n    }\n\n    if (typeof paths === 'string') {\n      paths = paths.indexOf(' ') === -1 ? [paths] : paths.split(' ');\n    }\n\n    for (const path of paths) {\n      if (directModifiedPathsObj[path] != null) {\n        return true;\n      }\n    }\n\n    const modified = modifiedPaths || this[documentModifiedPaths]();\n    const isModifiedChild = paths.some(function(path) {\n      return !!~modified.indexOf(path);\n    });\n\n    let directModifiedPaths = Object.keys(directModifiedPathsObj);\n    if (ignoreAtomics) {\n      directModifiedPaths = directModifiedPaths.filter(path => {\n        const value = this.$__getValue(path);\n        if (value != null && value[arrayAtomicsSymbol] != null && value[arrayAtomicsSymbol].$set === undefined) {\n          return false;\n        }\n        return true;\n      });\n    }\n    return isModifiedChild || paths.some(function(path) {\n      return directModifiedPaths.some(function(mod) {\n        return mod === path || path.startsWith(mod + '.');\n      });\n    });\n  }\n\n  return this.$__.activePaths.some('modify');\n};\n\n/**\n * Alias of [`.isModified`](https://mongoosejs.com/docs/api/document.html#Document.prototype.isModified())\n *\n * @method $isModified\n * @memberOf Document\n * @api public\n */\n\nDocument.prototype.$isModified = Document.prototype.isModified;\n\nDocument.prototype[documentIsModified] = Document.prototype.isModified;\n\n/**\n * Checks if a path is set to its default.\n *\n * #### Example:\n *\n *     MyModel = mongoose.model('test', { name: { type: String, default: 'Val '} });\n *     const m = new MyModel();\n *     m.$isDefault('name'); // true\n *\n * @memberOf Document\n * @instance\n * @method $isDefault\n * @param {String} [path]\n * @return {Boolean}\n * @api public\n */\n\nDocument.prototype.$isDefault = function(path) {\n  if (path == null) {\n    return this.$__.activePaths.some('default');\n  }\n\n  if (typeof path === 'string' && path.indexOf(' ') === -1) {\n    return this.$__.activePaths.getStatePaths('default').hasOwnProperty(path);\n  }\n\n  let paths = path;\n  if (!Array.isArray(paths)) {\n    paths = paths.split(' ');\n  }\n\n  return paths.some(path => this.$__.activePaths.getStatePaths('default').hasOwnProperty(path));\n};\n\n/**\n * Getter/setter, determines whether the document was removed or not.\n *\n * #### Example:\n *\n *     const product = await product.remove();\n *     product.$isDeleted(); // true\n *     product.remove(); // no-op, doesn't send anything to the db\n *\n *     product.$isDeleted(false);\n *     product.$isDeleted(); // false\n *     product.remove(); // will execute a remove against the db\n *\n *\n * @param {Boolean} [val] optional, overrides whether mongoose thinks the doc is deleted\n * @return {Boolean|Document} whether mongoose thinks this doc is deleted.\n * @method $isDeleted\n * @memberOf Document\n * @instance\n * @api public\n */\n\nDocument.prototype.$isDeleted = function(val) {\n  if (arguments.length === 0) {\n    return !!this.$__.isDeleted;\n  }\n\n  this.$__.isDeleted = !!val;\n  return this;\n};\n\n/**\n * Returns true if `path` was directly set and modified, else false.\n *\n * #### Example:\n *\n *     doc.set('documents.0.title', 'changed');\n *     doc.isDirectModified('documents.0.title') // true\n *     doc.isDirectModified('documents') // false\n *\n * @param {String|String[]} [path]\n * @return {Boolean}\n * @api public\n */\n\nDocument.prototype.isDirectModified = function(path) {\n  if (path == null) {\n    return this.$__.activePaths.some('modify');\n  }\n\n  if (typeof path === 'string' && path.indexOf(' ') === -1) {\n    const res = this.$__.activePaths.getStatePaths('modify').hasOwnProperty(path);\n    if (res || path.indexOf('.') === -1) {\n      return res;\n    }\n\n    const pieces = path.split('.');\n    for (let i = 0; i < pieces.length - 1; ++i) {\n      const subpath = pieces.slice(0, i + 1).join('.');\n      const subdoc = this.$get(subpath);\n      if (subdoc != null && subdoc.$__ != null && subdoc.isDirectModified(pieces.slice(i + 1).join('.'))) {\n        return true;\n      }\n    }\n\n    return false;\n  }\n\n  let paths = path;\n  if (typeof paths === 'string') {\n    paths = paths.split(' ');\n  }\n\n  return paths.some(path => this.isDirectModified(path));\n};\n\n/**\n * Checks if `path` is in the `init` state, that is, it was set by `Document#init()` and not modified since.\n *\n * @param {String} [path]\n * @return {Boolean}\n * @api public\n */\n\nDocument.prototype.isInit = function(path) {\n  if (path == null) {\n    return this.$__.activePaths.some('init');\n  }\n\n  if (typeof path === 'string' && path.indexOf(' ') === -1) {\n    return this.$__.activePaths.getStatePaths('init').hasOwnProperty(path);\n  }\n\n  let paths = path;\n  if (!Array.isArray(paths)) {\n    paths = paths.split(' ');\n  }\n\n  return paths.some(path => this.$__.activePaths.getStatePaths('init').hasOwnProperty(path));\n};\n\n/**\n * Checks if `path` was selected in the source query which initialized this document.\n *\n * #### Example:\n *\n *     const doc = await Thing.findOne().select('name');\n *     doc.isSelected('name') // true\n *     doc.isSelected('age')  // false\n *\n * @param {String|String[]} path\n * @return {Boolean}\n * @api public\n */\n\nDocument.prototype.isSelected = function isSelected(path) {\n  if (this.$__.selected == null) {\n    return true;\n  }\n  if (!path) {\n    return false;\n  }\n  if (path === '_id') {\n    return this.$__.selected._id !== 0;\n  }\n\n  if (path.indexOf(' ') !== -1) {\n    path = path.split(' ');\n  }\n  if (Array.isArray(path)) {\n    return path.some(p => this.$__isSelected(p));\n  }\n\n  const paths = Object.keys(this.$__.selected);\n  let inclusive = null;\n\n  if (paths.length === 1 && paths[0] === '_id') {\n    // only _id was selected.\n    return this.$__.selected._id === 0;\n  }\n\n  for (const cur of paths) {\n    if (cur === '_id') {\n      continue;\n    }\n    if (!isDefiningProjection(this.$__.selected[cur])) {\n      continue;\n    }\n    inclusive = !!this.$__.selected[cur];\n    break;\n  }\n\n  if (inclusive === null) {\n    return true;\n  }\n\n  if (path in this.$__.selected) {\n    return inclusive;\n  }\n\n  const pathDot = path + '.';\n\n  for (const cur of paths) {\n    if (cur === '_id') {\n      continue;\n    }\n\n    if (cur.startsWith(pathDot)) {\n      return inclusive || cur !== pathDot;\n    }\n\n    if (pathDot.startsWith(cur + '.')) {\n      return inclusive;\n    }\n  }\n  return !inclusive;\n};\n\nDocument.prototype.$__isSelected = Document.prototype.isSelected;\n\n/**\n * Checks if `path` was explicitly selected. If no projection, always returns\n * true.\n *\n * #### Example:\n *\n *     Thing.findOne().select('nested.name').exec(function (err, doc) {\n *        doc.isDirectSelected('nested.name') // true\n *        doc.isDirectSelected('nested.otherName') // false\n *        doc.isDirectSelected('nested')  // false\n *     })\n *\n * @param {String} path\n * @return {Boolean}\n * @api public\n */\n\nDocument.prototype.isDirectSelected = function isDirectSelected(path) {\n  if (this.$__.selected == null) {\n    return true;\n  }\n\n  if (path === '_id') {\n    return this.$__.selected._id !== 0;\n  }\n\n  if (path.indexOf(' ') !== -1) {\n    path = path.split(' ');\n  }\n  if (Array.isArray(path)) {\n    return path.some(p => this.isDirectSelected(p));\n  }\n\n  const paths = Object.keys(this.$__.selected);\n  let inclusive = null;\n\n  if (paths.length === 1 && paths[0] === '_id') {\n    // only _id was selected.\n    return this.$__.selected._id === 0;\n  }\n\n  for (const cur of paths) {\n    if (cur === '_id') {\n      continue;\n    }\n    if (!isDefiningProjection(this.$__.selected[cur])) {\n      continue;\n    }\n    inclusive = !!this.$__.selected[cur];\n    break;\n  }\n\n  if (inclusive === null) {\n    return true;\n  }\n\n  if (this.$__.selected.hasOwnProperty(path)) {\n    return inclusive;\n  }\n\n  return !inclusive;\n};\n\n/**\n * Executes registered validation rules for this document.\n *\n * #### Note:\n *\n * This method is called `pre` save and if a validation rule is violated, [save](https://mongoosejs.com/docs/api/model.html#Model.prototype.save()) is aborted and the error is thrown.\n *\n * #### Example:\n *\n *     await doc.validate({ validateModifiedOnly: false, pathsToSkip: ['name', 'email']});\n *\n * @param {Array|String} [pathsToValidate] list of paths to validate. If set, Mongoose will validate only the modified paths that are in the given list.\n * @param {Object} [options] internal options\n * @param {Boolean} [options.validateModifiedOnly=false] if `true` mongoose validates only modified paths.\n * @param {Array|string} [options.pathsToSkip] list of paths to skip. If set, Mongoose will validate every modified path that is not in this list.\n * @return {Promise} Returns a Promise.\n * @api public\n */\n\nDocument.prototype.validate = async function validate(pathsToValidate, options) {\n  if (typeof pathsToValidate === 'function' || typeof options === 'function' || typeof arguments[2] === 'function') {\n    throw new MongooseError('Document.prototype.validate() no longer accepts a callback');\n  }\n  let parallelValidate;\n  this.$op = 'validate';\n\n  if (arguments.length === 1) {\n    if (typeof arguments[0] === 'object' && !Array.isArray(arguments[0])) {\n      options = arguments[0];\n      pathsToValidate = null;\n    }\n  }\n  if (options && typeof options.pathsToSkip === 'string') {\n    const isOnePathOnly = options.pathsToSkip.indexOf(' ') === -1;\n    options.pathsToSkip = isOnePathOnly ? [options.pathsToSkip] : options.pathsToSkip.split(' ');\n  }\n  const _skipParallelValidateCheck = options && options._skipParallelValidateCheck;\n\n  if (this.$isSubdocument != null) {\n    // Skip parallel validate check for subdocuments\n  } else if (this.$__.validating && !_skipParallelValidateCheck) {\n    parallelValidate = new ParallelValidateError(this, {\n      parentStack: options && options.parentStack,\n      conflictStack: this.$__.validating.stack\n    });\n  } else if (!_skipParallelValidateCheck) {\n    this.$__.validating = new ParallelValidateError(this, { parentStack: options && options.parentStack });\n  }\n\n  if (parallelValidate != null) {\n    throw parallelValidate;\n  }\n\n  return new Promise((resolve, reject) => {\n    this.$__validate(pathsToValidate, options, (error) => {\n      this.$op = null;\n      this.$__.validating = null;\n      if (error != null) {\n        return reject(error);\n      }\n      resolve();\n    });\n  });\n};\n\n/**\n * Alias of [`.validate`](https://mongoosejs.com/docs/api/document.html#Document.prototype.validate())\n *\n * @method $validate\n * @memberOf Document\n * @api public\n */\n\nDocument.prototype.$validate = Document.prototype.validate;\n\n/*!\n * ignore\n */\n\nfunction _evaluateRequiredFunctions(doc) {\n  const requiredFields = Object.keys(doc.$__.activePaths.getStatePaths('require'));\n  let i = 0;\n  const len = requiredFields.length;\n  for (i = 0; i < len; ++i) {\n    const path = requiredFields[i];\n\n    const p = doc.$__schema.path(path);\n\n    if (p != null && typeof p.originalRequiredValue === 'function') {\n      doc.$__.cachedRequired = doc.$__.cachedRequired || {};\n      try {\n        doc.$__.cachedRequired[path] = p.originalRequiredValue.call(doc, doc);\n      } catch (err) {\n        doc.invalidate(path, err);\n      }\n    }\n  }\n}\n\n/*!\n * ignore\n */\n\nfunction _getPathsToValidate(doc, pathsToValidate, pathsToSkip) {\n  const doValidateOptions = {};\n\n  _evaluateRequiredFunctions(doc);\n  // only validate required fields when necessary\n  let paths = new Set(Object.keys(doc.$__.activePaths.getStatePaths('require')).filter(function(path) {\n    if (!doc.$__isSelected(path) && !doc.$isModified(path)) {\n      return false;\n    }\n    if (doc.$__.cachedRequired != null && path in doc.$__.cachedRequired) {\n      return doc.$__.cachedRequired[path];\n    }\n    return true;\n  }));\n\n  Object.keys(doc.$__.activePaths.getStatePaths('init')).forEach(addToPaths);\n  Object.keys(doc.$__.activePaths.getStatePaths('modify')).forEach(addToPaths);\n  Object.keys(doc.$__.activePaths.getStatePaths('default')).forEach(addToPaths);\n  function addToPaths(p) { paths.add(p); }\n\n  const subdocs = doc.$getAllSubdocs();\n  const modifiedPaths = doc.modifiedPaths();\n  for (const subdoc of subdocs) {\n    if (subdoc.$basePath) {\n      const fullPathToSubdoc = subdoc.$isSingleNested ? subdoc.$__pathRelativeToParent() : subdoc.$__fullPathWithIndexes();\n\n      // Remove child paths for now, because we'll be validating the whole\n      // subdoc.\n      // The following is a faster take on looping through every path in `paths`\n      // and checking if the path starts with `fullPathToSubdoc` re: gh-13191\n      for (const modifiedPath of subdoc.modifiedPaths()) {\n        paths.delete(fullPathToSubdoc + '.' + modifiedPath);\n      }\n\n      if (doc.$isModified(fullPathToSubdoc, null, modifiedPaths) &&\n            !doc.isDirectModified(fullPathToSubdoc) &&\n            !doc.$isDefault(fullPathToSubdoc)) {\n        paths.add(fullPathToSubdoc);\n\n        if (doc.$__.pathsToScopes == null) {\n          doc.$__.pathsToScopes = {};\n        }\n        doc.$__.pathsToScopes[fullPathToSubdoc] = subdoc.$isDocumentArrayElement ?\n          subdoc.__parentArray :\n          subdoc.$parent();\n\n        doValidateOptions[fullPathToSubdoc] = { skipSchemaValidators: true };\n        if (subdoc.$isDocumentArrayElement && subdoc.__index != null) {\n          doValidateOptions[fullPathToSubdoc].index = subdoc.__index;\n        }\n      }\n    }\n  }\n\n  for (const path of paths) {\n    const _pathType = doc.$__schema.path(path);\n    if (!_pathType) {\n      continue;\n    }\n\n    if (_pathType.$isMongooseDocumentArray) {\n      for (const p of paths) {\n        if (p == null || p.startsWith(_pathType.path + '.')) {\n          paths.delete(p);\n        }\n      }\n    }\n\n    // Optimization: if primitive path with no validators, or array of primitives\n    // with no validators, skip validating this path entirely.\n    if (!_pathType.caster && _pathType.validators.length === 0 && !_pathType.$parentSchemaDocArray) {\n      paths.delete(path);\n    } else if (_pathType.$isMongooseArray &&\n      !_pathType.$isMongooseDocumentArray && // Skip document arrays...\n      !_pathType.$embeddedSchemaType.$isMongooseArray && // and arrays of arrays\n      _pathType.validators.length === 0 && // and arrays with top-level validators\n      _pathType.$embeddedSchemaType.validators.length === 0) {\n      paths.delete(path);\n    }\n  }\n\n\n  if (Array.isArray(pathsToValidate)) {\n    paths = _handlePathsToValidate(paths, pathsToValidate);\n  } else if (Array.isArray(pathsToSkip)) {\n    paths = _handlePathsToSkip(paths, pathsToSkip);\n  }\n\n  // from here on we're not removing items from paths\n\n  // gh-661: if a whole array is modified, make sure to run validation on all\n  // the children as well\n  _addArrayPathsToValidate(doc, paths);\n\n  const flattenOptions = { skipArrays: true };\n  for (const pathToCheck of paths) {\n    if (doc.$__schema.nested[pathToCheck]) {\n      let _v = doc.$__getValue(pathToCheck);\n      if (isMongooseObject(_v)) {\n        _v = _v.toObject({ transform: false });\n      }\n      const flat = flatten(_v, pathToCheck, flattenOptions, doc.$__schema);\n      // Single nested paths (paths embedded under single nested subdocs) will\n      // be validated on their own when we call `validate()` on the subdoc itself.\n      // Re: gh-8468\n      Object.keys(flat).filter(path => !doc.$__schema.singleNestedPaths.hasOwnProperty(path)).forEach(addToPaths);\n    }\n  }\n\n  for (const path of paths) {\n    const _pathType = doc.$__schema.path(path);\n\n    if (!_pathType) {\n      continue;\n    }\n\n    // If underneath a document array, may need to re-validate the parent\n    // array re: gh-6818. Do this _after_ adding subpaths, because\n    // we don't want to add every array subpath.\n    if (_pathType.$parentSchemaDocArray && typeof _pathType.$parentSchemaDocArray.path === 'string') {\n      paths.add(_pathType.$parentSchemaDocArray.path);\n    }\n\n    if (!_pathType.$isSchemaMap) {\n      continue;\n    }\n\n    const val = doc.$__getValue(path);\n    if (val == null) {\n      continue;\n    }\n    for (const key of val.keys()) {\n      paths.add(path + '.' + key);\n    }\n  }\n\n  paths = Array.from(paths);\n  return [paths, doValidateOptions];\n}\n\nfunction _addArrayPathsToValidate(doc, paths) {\n  for (const path of paths) {\n    const _pathType = doc.$__schema.path(path);\n    if (!_pathType) {\n      continue;\n    }\n\n    if (!_pathType.$isMongooseArray ||\n        // To avoid potential performance issues, skip doc arrays whose children\n        // are not required. `getPositionalPathType()` may be slow, so avoid\n        // it unless we have a case of #6364\n        (!Array.isArray(_pathType) &&\n          _pathType.$isMongooseDocumentArray &&\n          !(_pathType && _pathType.schemaOptions && _pathType.schemaOptions.required))) {\n      continue;\n    }\n\n    // gh-11380: optimization. If the array isn't a document array and there's no validators\n    // on the array type, there's no need to run validation on the individual array elements.\n    if (_pathType.$isMongooseArray &&\n        !_pathType.$isMongooseDocumentArray && // Skip document arrays...\n        !_pathType.$embeddedSchemaType.$isMongooseArray && // and arrays of arrays\n        _pathType.$embeddedSchemaType.validators.length === 0) {\n      continue;\n    }\n\n    const val = doc.$__getValue(path);\n    _pushNestedArrayPaths(val, paths, path);\n  }\n}\n\nfunction _pushNestedArrayPaths(val, paths, path) {\n  if (val != null) {\n    const numElements = val.length;\n    for (let j = 0; j < numElements; ++j) {\n      if (Array.isArray(val[j])) {\n        _pushNestedArrayPaths(val[j], paths, path + '.' + j);\n      } else {\n        paths.add(path + '.' + j);\n      }\n    }\n  }\n}\n\n/*!\n * ignore\n */\n\nDocument.prototype.$__validate = function(pathsToValidate, options, callback) {\n  if (this.$__.saveOptions && this.$__.saveOptions.pathsToSave && !pathsToValidate) {\n    pathsToValidate = [...this.$__.saveOptions.pathsToSave];\n  } else if (typeof pathsToValidate === 'function') {\n    callback = pathsToValidate;\n    options = null;\n    pathsToValidate = null;\n  } else if (typeof options === 'function') {\n    callback = options;\n    options = null;\n  }\n\n  const hasValidateModifiedOnlyOption = options &&\n      (typeof options === 'object') &&\n      ('validateModifiedOnly' in options);\n\n  const pathsToSkip = (options && options.pathsToSkip) || null;\n\n  let shouldValidateModifiedOnly;\n  if (hasValidateModifiedOnlyOption) {\n    shouldValidateModifiedOnly = !!options.validateModifiedOnly;\n  } else {\n    shouldValidateModifiedOnly = this.$__schema.options.validateModifiedOnly;\n  }\n\n  const validateAllPaths = options && options.validateAllPaths;\n  if (validateAllPaths) {\n    if (pathsToSkip) {\n      throw new TypeError('Cannot set both `validateAllPaths` and `pathsToSkip`');\n    }\n    if (pathsToValidate) {\n      throw new TypeError('Cannot set both `validateAllPaths` and `pathsToValidate`');\n    }\n    if (hasValidateModifiedOnlyOption && shouldValidateModifiedOnly) {\n      throw new TypeError('Cannot set both `validateAllPaths` and `validateModifiedOnly`');\n    }\n  }\n\n  const _this = this;\n  const _complete = () => {\n    let validationError = this.$__.validationError;\n    this.$__.validationError = null;\n    this.$__.validating = null;\n\n    if (shouldValidateModifiedOnly && validationError != null) {\n      // Remove any validation errors that aren't from modified paths\n      const errors = Object.keys(validationError.errors);\n      for (const errPath of errors) {\n        if (!this.$isModified(errPath)) {\n          delete validationError.errors[errPath];\n        }\n      }\n      if (Object.keys(validationError.errors).length === 0) {\n        validationError = void 0;\n      }\n    }\n\n    this.$__.cachedRequired = {};\n    this.$emit('validate', _this);\n    this.constructor.emit('validate', _this);\n\n    if (validationError) {\n      for (const key in validationError.errors) {\n        // Make sure cast errors persist\n        if (!this[documentArrayParent] &&\n            validationError.errors[key] instanceof MongooseError.CastError) {\n          this.invalidate(key, validationError.errors[key]);\n        }\n      }\n\n      return validationError;\n    }\n  };\n\n  // only validate required fields when necessary\n  let paths;\n  let doValidateOptionsByPath;\n  if (validateAllPaths) {\n    paths = new Set(Object.keys(this.$__schema.paths));\n    // gh-661: if a whole array is modified, make sure to run validation on all\n    // the children as well\n    for (const path of paths) {\n      const schemaType = this.$__schema.path(path);\n      if (!schemaType || !schemaType.$isMongooseArray) {\n        continue;\n      }\n      const val = this.$__getValue(path);\n      if (!val) {\n        continue;\n      }\n      _pushNestedArrayPaths(val, paths, path);\n    }\n    paths = [...paths];\n    doValidateOptionsByPath = {};\n  } else {\n    const pathDetails = _getPathsToValidate(this, pathsToValidate, pathsToSkip);\n    paths = shouldValidateModifiedOnly ?\n      pathDetails[0].filter((path) => this.$isModified(path)) :\n      pathDetails[0];\n    doValidateOptionsByPath = pathDetails[1];\n  }\n\n  if (typeof pathsToValidate === 'string') {\n    pathsToValidate = pathsToValidate.split(' ');\n  }\n\n  if (paths.length === 0) {\n    return immediate(function() {\n      const error = _complete();\n      if (error) {\n        return _this.$__schema.s.hooks.execPost('validate:error', _this, [_this], { error: error }, function(error) {\n          callback(error);\n        });\n      }\n      callback(null, _this);\n    });\n  }\n\n  const validated = {};\n  let total = 0;\n\n  let pathsToSave = this.$__.saveOptions?.pathsToSave;\n  if (Array.isArray(pathsToSave)) {\n    pathsToSave = new Set(pathsToSave);\n    for (const path of paths) {\n      if (!pathsToSave.has(path)) {\n        continue;\n      }\n      validatePath(path);\n    }\n  } else {\n    for (const path of paths) {\n      validatePath(path);\n    }\n  }\n\n  function validatePath(path) {\n    if (path == null || validated[path]) {\n      return;\n    }\n\n    validated[path] = true;\n    total++;\n\n    immediate(function() {\n      const schemaType = _this.$__schema.path(path);\n\n      if (!schemaType) {\n        return --total || complete();\n      }\n\n      // If user marked as invalid or there was a cast error, don't validate\n      if (!_this.$isValid(path)) {\n        --total || complete();\n        return;\n      }\n\n      // If setting a path under a mixed path, avoid using the mixed path validator (gh-10141)\n      if (schemaType[schemaMixedSymbol] != null && path !== schemaType.path) {\n        return --total || complete();\n      }\n\n      let val = _this.$__getValue(path);\n\n      // If you `populate()` and get back a null value, required validators\n      // shouldn't fail (gh-8018). We should always fall back to the populated\n      // value.\n      let pop;\n      if ((pop = _this.$populated(path))) {\n        val = pop;\n      } else if (val != null && val.$__ != null && val.$__.wasPopulated) {\n        // Array paths, like `somearray.1`, do not show up as populated with `$populated()`,\n        // so in that case pull out the document's id\n        val = val._id;\n      }\n      const scope = _this.$__.pathsToScopes != null && path in _this.$__.pathsToScopes ?\n        _this.$__.pathsToScopes[path] :\n        _this;\n\n      const doValidateOptions = {\n        ...doValidateOptionsByPath[path],\n        path: path,\n        validateAllPaths\n      };\n\n      schemaType.doValidate(val, function(err) {\n        if (err) {\n          const isSubdoc = schemaType.$isSingleNested ||\n              schemaType.$isArraySubdocument ||\n              schemaType.$isMongooseDocumentArray;\n          if (isSubdoc && err instanceof ValidationError) {\n            return --total || complete();\n          }\n          _this.invalidate(path, err, undefined, true);\n        }\n        --total || complete();\n      }, scope, doValidateOptions);\n    });\n  }\n\n  function complete() {\n    const error = _complete();\n    if (error) {\n      return _this.$__schema.s.hooks.execPost('validate:error', _this, [_this], { error: error }, function(error) {\n        callback(error);\n      });\n    }\n    callback(null, _this);\n  }\n\n};\n\n/*!\n * ignore\n */\n\nfunction _handlePathsToValidate(paths, pathsToValidate) {\n  const _pathsToValidate = new Set(pathsToValidate);\n  const parentPaths = new Map([]);\n  for (const path of pathsToValidate) {\n    if (path.indexOf('.') === -1) {\n      continue;\n    }\n    const pieces = path.split('.');\n    let cur = pieces[0];\n    for (let i = 1; i < pieces.length; ++i) {\n      // Since we skip subpaths under single nested subdocs to\n      // avoid double validation, we need to add back the\n      // single nested subpath if the user asked for it (gh-8626)\n      parentPaths.set(cur, path);\n      cur = cur + '.' + pieces[i];\n    }\n  }\n\n  const ret = new Set();\n  for (const path of paths) {\n    if (_pathsToValidate.has(path)) {\n      ret.add(path);\n    } else if (parentPaths.has(path)) {\n      ret.add(parentPaths.get(path));\n    }\n  }\n  return ret;\n}\n\n/*!\n * ignore\n */\n\nfunction _handlePathsToSkip(paths, pathsToSkip) {\n  pathsToSkip = new Set(pathsToSkip);\n  paths = Array.from(paths).filter(p => !pathsToSkip.has(p));\n  return new Set(paths);\n}\n\n/**\n * Executes registered validation rules (skipping asynchronous validators) for this document.\n *\n * #### Note:\n *\n * This method is useful if you need synchronous validation.\n *\n * #### Example:\n *\n *     const err = doc.validateSync();\n *     if (err) {\n *       handleError(err);\n *     } else {\n *       // validation passed\n *     }\n *\n * @param {Array|string} [pathsToValidate] only validate the given paths\n * @param {Object} [options] options for validation\n * @param {Boolean} [options.validateModifiedOnly=false] If `true`, Mongoose will only validate modified paths, as opposed to modified paths and `required` paths.\n * @param {Array|string} [options.pathsToSkip] list of paths to skip. If set, Mongoose will validate every modified path that is not in this list.\n * @return {ValidationError|undefined} ValidationError if there are errors during validation, or undefined if there is no error.\n * @api public\n */\n\nDocument.prototype.validateSync = function(pathsToValidate, options) {\n  const _this = this;\n\n  if (arguments.length === 1 && typeof arguments[0] === 'object' && !Array.isArray(arguments[0])) {\n    options = arguments[0];\n    pathsToValidate = null;\n  }\n\n  const hasValidateModifiedOnlyOption = options &&\n      (typeof options === 'object') &&\n      ('validateModifiedOnly' in options);\n\n  let shouldValidateModifiedOnly;\n  if (hasValidateModifiedOnlyOption) {\n    shouldValidateModifiedOnly = !!options.validateModifiedOnly;\n  } else {\n    shouldValidateModifiedOnly = this.$__schema.options.validateModifiedOnly;\n  }\n\n  let pathsToSkip = options && options.pathsToSkip;\n\n  const validateAllPaths = options && options.validateAllPaths;\n  if (validateAllPaths) {\n    if (pathsToSkip) {\n      throw new TypeError('Cannot set both `validateAllPaths` and `pathsToSkip`');\n    }\n    if (pathsToValidate) {\n      throw new TypeError('Cannot set both `validateAllPaths` and `pathsToValidate`');\n    }\n  }\n\n  if (typeof pathsToValidate === 'string') {\n    const isOnePathOnly = pathsToValidate.indexOf(' ') === -1;\n    pathsToValidate = isOnePathOnly ? [pathsToValidate] : pathsToValidate.split(' ');\n  } else if (typeof pathsToSkip === 'string' && pathsToSkip.indexOf(' ') !== -1) {\n    pathsToSkip = pathsToSkip.split(' ');\n  }\n\n  // only validate required fields when necessary\n  let paths;\n  let skipSchemaValidators;\n  if (validateAllPaths) {\n    paths = new Set(Object.keys(this.$__schema.paths));\n    // gh-661: if a whole array is modified, make sure to run validation on all\n    // the children as well\n    for (const path of paths) {\n      const schemaType = this.$__schema.path(path);\n      if (!schemaType || !schemaType.$isMongooseArray) {\n        continue;\n      }\n      const val = this.$__getValue(path);\n      if (!val) {\n        continue;\n      }\n      _pushNestedArrayPaths(val, paths, path);\n    }\n    paths = [...paths];\n    skipSchemaValidators = {};\n  } else {\n    const pathDetails = _getPathsToValidate(this, pathsToValidate, pathsToSkip);\n    paths = shouldValidateModifiedOnly ?\n      pathDetails[0].filter((path) => this.$isModified(path)) :\n      pathDetails[0];\n    skipSchemaValidators = pathDetails[1];\n  }\n\n  const validating = {};\n\n  for (let i = 0, len = paths.length; i < len; ++i) {\n    const path = paths[i];\n\n    if (validating[path]) {\n      continue;\n    }\n\n    validating[path] = true;\n\n    const p = _this.$__schema.path(path);\n    if (!p) {\n      continue;\n    }\n    if (!_this.$isValid(path)) {\n      continue;\n    }\n\n    const val = _this.$__getValue(path);\n    const err = p.doValidateSync(val, _this, {\n      skipSchemaValidators: skipSchemaValidators[path],\n      path: path,\n      validateModifiedOnly: shouldValidateModifiedOnly,\n      validateAllPaths\n    });\n    if (err) {\n      const isSubdoc = p.$isSingleNested ||\n        p.$isArraySubdocument ||\n        p.$isMongooseDocumentArray;\n      if (isSubdoc && err instanceof ValidationError) {\n        continue;\n      }\n      _this.invalidate(path, err, undefined, true);\n    }\n  }\n\n  const err = _this.$__.validationError;\n  _this.$__.validationError = undefined;\n  _this.$emit('validate', _this);\n  _this.constructor.emit('validate', _this);\n\n  if (err) {\n    for (const key in err.errors) {\n      // Make sure cast errors persist\n      if (err.errors[key] instanceof MongooseError.CastError) {\n        _this.invalidate(key, err.errors[key]);\n      }\n    }\n  }\n\n  return err;\n};\n\n/**\n * Marks a path as invalid, causing validation to fail.\n *\n * The `errorMsg` argument will become the message of the `ValidationError`.\n *\n * The `value` argument (if passed) will be available through the `ValidationError.value` property.\n *\n *     doc.invalidate('size', 'must be less than 20', 14);\n *\n *     doc.validate(function (err) {\n *       console.log(err)\n *       // prints\n *       { message: 'Validation failed',\n *         name: 'ValidationError',\n *         errors:\n *          { size:\n *             { message: 'must be less than 20',\n *               name: 'ValidatorError',\n *               path: 'size',\n *               type: 'user defined',\n *               value: 14 } } }\n *     })\n *\n * @param {String} path the field to invalidate. For array elements, use the `array.i.field` syntax, where `i` is the 0-based index in the array.\n * @param {String|Error} err the error which states the reason `path` was invalid\n * @param {Object|String|Number|any} val optional invalid value\n * @param {String} [kind] optional `kind` property for the error\n * @return {ValidationError} the current ValidationError, with all currently invalidated paths\n * @api public\n */\n\nDocument.prototype.invalidate = function(path, err, val, kind) {\n  if (!this.$__.validationError) {\n    this.$__.validationError = new ValidationError(this);\n  }\n\n  if (this.$__.validationError.errors[path]) {\n    return;\n  }\n\n  if (!err || typeof err === 'string') {\n    err = new ValidatorError({\n      path: path,\n      message: err,\n      type: kind || 'user defined',\n      value: val\n    });\n  }\n\n  if (this.$__.validationError === err) {\n    return this.$__.validationError;\n  }\n\n  this.$__.validationError.addError(path, err);\n  return this.$__.validationError;\n};\n\n/**\n * Marks a path as valid, removing existing validation errors.\n *\n * @param {String} path the field to mark as valid\n * @api public\n * @memberOf Document\n * @instance\n * @method $markValid\n */\n\nDocument.prototype.$markValid = function(path) {\n  if (!this.$__.validationError || !this.$__.validationError.errors[path]) {\n    return;\n  }\n\n  delete this.$__.validationError.errors[path];\n  if (Object.keys(this.$__.validationError.errors).length === 0) {\n    this.$__.validationError = null;\n  }\n};\n\n/*!\n * ignore\n */\n\nfunction _markValidSubpaths(doc, path) {\n  if (!doc.$__.validationError) {\n    return;\n  }\n\n  const keys = Object.keys(doc.$__.validationError.errors);\n  for (const key of keys) {\n    if (key.startsWith(path + '.')) {\n      delete doc.$__.validationError.errors[key];\n    }\n  }\n  if (Object.keys(doc.$__.validationError.errors).length === 0) {\n    doc.$__.validationError = null;\n  }\n}\n\n/*!\n * ignore\n */\n\nfunction _checkImmutableSubpaths(subdoc, schematype, priorVal) {\n  const schema = schematype.schema;\n  if (schema == null) {\n    return;\n  }\n\n  for (const key of Object.keys(schema.paths)) {\n    const path = schema.paths[key];\n    if (path.$immutableSetter == null) {\n      continue;\n    }\n    const oldVal = priorVal == null ? void 0 : priorVal.$__getValue(key);\n    // Calling immutableSetter with `oldVal` even though it expects `newVal`\n    // is intentional. That's because `$immutableSetter` compares its param\n    // to the current value.\n    path.$immutableSetter.call(subdoc, oldVal);\n  }\n}\n\n/**\n * Saves this document by inserting a new document into the database if [document.isNew](https://mongoosejs.com/docs/api/document.html#Document.prototype.isNew()) is `true`,\n * or sends an [updateOne](https://mongoosejs.com/docs/api/document.html#Document.prototype.updateOne()) operation **only** with the modifications to the database, it does not replace the whole document in the latter case.\n *\n * #### Example:\n *\n *     product.sold = Date.now();\n *     product = await product.save();\n *\n * If save is successful, the returned promise will fulfill with the document\n * saved.\n *\n * #### Example:\n *\n *     const newProduct = await product.save();\n *     newProduct === product; // true\n *\n * @param {Object} [options] options optional options\n * @param {Session} [options.session=null] the [session](https://www.mongodb.com/docs/manual/reference/server-sessions/) associated with this save operation. If not specified, defaults to the [document's associated session](https://mongoosejs.com/docs/api/document.html#Document.prototype.$session()).\n * @param {Object} [options.safe] (DEPRECATED) overrides [schema's safe option](https://mongoosejs.com/docs/guide.html#safe). Use the `w` option instead.\n * @param {Boolean} [options.validateBeforeSave] set to false to save without validating.\n * @param {Boolean} [options.validateModifiedOnly=false] If `true`, Mongoose will only validate modified paths, as opposed to modified paths and `required` paths.\n * @param {Number|String} [options.w] set the [write concern](https://www.mongodb.com/docs/manual/reference/write-concern/#w-option). Overrides the [schema-level `writeConcern` option](https://mongoosejs.com/docs/guide.html#writeConcern)\n * @param {Boolean} [options.j] set to true for MongoDB to wait until this `save()` has been [journaled before resolving the returned promise](https://www.mongodb.com/docs/manual/reference/write-concern/#j-option). Overrides the [schema-level `writeConcern` option](https://mongoosejs.com/docs/guide.html#writeConcern)\n * @param {Number} [options.wtimeout] sets a [timeout for the write concern](https://www.mongodb.com/docs/manual/reference/write-concern/#wtimeout). Overrides the [schema-level `writeConcern` option](https://mongoosejs.com/docs/guide.html#writeConcern).\n * @param {Boolean} [options.checkKeys=true] the MongoDB driver prevents you from saving keys that start with '$' or contain '.' by default. Set this option to `false` to skip that check. See [restrictions on field names](https://www.mongodb.com/docs/manual/reference/limits/#Restrictions-on-Field-Names)\n * @param {Boolean} [options.timestamps=true] if `false` and [timestamps](https://mongoosejs.com/docs/guide.html#timestamps) are enabled, skip timestamps for this `save()`.\n * @param {Function} [fn] optional callback\n * @method save\n * @memberOf Document\n * @instance\n * @throws {DocumentNotFoundError} if this [save updates an existing document](https://mongoosejs.com/docs/api/document.html#Document.prototype.isNew()) but the document doesn't exist in the database. For example, you will get this error if the document is [deleted between when you retrieved the document and when you saved it](documents.html#updating).\n * @return {Promise|undefined} Returns undefined if used with callback or a Promise otherwise.\n * @api public\n * @see middleware https://mongoosejs.com/docs/middleware.html\n */\n\n/**\n * Checks if a path is invalid\n *\n * @param {String|String[]} [path] the field to check. If unset will always return \"false\"\n * @method $isValid\n * @memberOf Document\n * @instance\n * @api private\n */\n\nDocument.prototype.$isValid = function(path) {\n  if (this.$__.validationError == null || Object.keys(this.$__.validationError.errors).length === 0) {\n    return true;\n  }\n  if (path == null) {\n    return false;\n  }\n\n  if (path.indexOf(' ') !== -1) {\n    path = path.split(' ');\n  }\n  if (Array.isArray(path)) {\n    return path.some(p => this.$__.validationError.errors[p] == null);\n  }\n\n  return this.$__.validationError.errors[path] == null;\n};\n\n/**\n * Resets the internal modified state of this document.\n *\n * @api private\n * @return {Document} this\n * @method $__reset\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.$__reset = function reset() {\n  let _this = this;\n\n  // Skip for subdocuments\n  const subdocs = !this.$isSubdocument ? this.$getAllSubdocs() : null;\n  if (subdocs && subdocs.length > 0) {\n    const resetArrays = new Set();\n    for (const subdoc of subdocs) {\n      const fullPathWithIndexes = subdoc.$__fullPathWithIndexes();\n      subdoc.$__reset();\n      if (this.isModified(fullPathWithIndexes) || isParentInit(fullPathWithIndexes)) {\n        if (subdoc.$isDocumentArrayElement) {\n          resetArrays.add(subdoc.parentArray());\n        } else {\n          const parent = subdoc.$parent();\n          if (parent === this) {\n            this.$__.activePaths.clearPath(subdoc.$basePath);\n          } else if (parent != null && parent.$isSubdocument) {\n            // If map path underneath subdocument, may end up with a case where\n            // map path is modified but parent still needs to be reset. See gh-10295\n            parent.$__reset();\n          }\n        }\n      }\n    }\n\n    for (const array of resetArrays) {\n      this.$__.activePaths.clearPath(array.$path());\n      array[arrayAtomicsBackupSymbol] = array[arrayAtomicsSymbol];\n      array[arrayAtomicsSymbol] = {};\n    }\n  }\n\n  function isParentInit(path) {\n    path = path.indexOf('.') === -1 ? [path] : path.split('.');\n    let cur = '';\n    for (let i = 0; i < path.length; ++i) {\n      cur += (cur.length ? '.' : '') + path[i];\n      if (_this.$__.activePaths[cur] === 'init') {\n        return true;\n      }\n    }\n\n    return false;\n  }\n\n  // clear atomics\n  this.$__dirty().forEach(function(dirt) {\n    const type = dirt.value;\n\n    if (type && type[arrayAtomicsSymbol]) {\n      type[arrayAtomicsBackupSymbol] = type[arrayAtomicsSymbol];\n      type[arrayAtomicsSymbol] = {};\n    }\n  });\n\n  this.$__.backup = {};\n  this.$__.backup.activePaths = {\n    modify: Object.assign({}, this.$__.activePaths.getStatePaths('modify')),\n    default: Object.assign({}, this.$__.activePaths.getStatePaths('default'))\n  };\n  this.$__.backup.validationError = this.$__.validationError;\n  this.$__.backup.errors = this.$errors;\n\n  // Clear 'dirty' cache\n  this.$__.activePaths.clear('modify');\n  this.$__.activePaths.clear('default');\n  this.$__.validationError = undefined;\n  this.$errors = undefined;\n  _this = this;\n  this.$__schema.requiredPaths().forEach(function(path) {\n    _this.$__.activePaths.require(path);\n  });\n\n  return this;\n};\n\n/*!\n * ignore\n */\n\nDocument.prototype.$__undoReset = function $__undoReset() {\n  if (this.$__.backup == null || this.$__.backup.activePaths == null) {\n    return;\n  }\n\n  this.$__.activePaths.states.modify = this.$__.backup.activePaths.modify;\n  this.$__.activePaths.states.default = this.$__.backup.activePaths.default;\n\n  this.$__.validationError = this.$__.backup.validationError;\n  this.$errors = this.$__.backup.errors;\n\n  for (const dirt of this.$__dirty()) {\n    const type = dirt.value;\n\n    if (type && type[arrayAtomicsSymbol] && type[arrayAtomicsBackupSymbol]) {\n      type[arrayAtomicsSymbol] = type[arrayAtomicsBackupSymbol];\n    }\n  }\n\n  for (const subdoc of this.$getAllSubdocs()) {\n    subdoc.$__undoReset();\n  }\n};\n\n/**\n * Returns this documents dirty paths / vals.\n *\n * @return {Array}\n * @api private\n * @method $__dirty\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.$__dirty = function() {\n  const _this = this;\n  let all = this.$__.activePaths.map('modify', function(path) {\n    return {\n      path: path,\n      value: _this.$__getValue(path),\n      schema: _this.$__path(path)\n    };\n  });\n\n  // gh-2558: if we had to set a default and the value is not undefined,\n  // we have to save as well\n  all = all.concat(this.$__.activePaths.map('default', function(path) {\n    if (path === '_id' || _this.$__getValue(path) == null) {\n      return;\n    }\n    return {\n      path: path,\n      value: _this.$__getValue(path),\n      schema: _this.$__path(path)\n    };\n  }));\n\n  const allPaths = new Map(all.filter((el) => el != null).map((el) => [el.path, el.value]));\n  // Ignore \"foo.a\" if \"foo\" is dirty already.\n  const minimal = [];\n\n  all.forEach(function(item) {\n    if (!item) {\n      return;\n    }\n\n    let top = null;\n\n    const array = parentPaths(item.path);\n    for (let i = 0; i < array.length - 1; i++) {\n      if (allPaths.has(array[i])) {\n        top = allPaths.get(array[i]);\n        break;\n      }\n    }\n    if (top == null) {\n      minimal.push(item);\n    } else if (top != null &&\n        top[arrayAtomicsSymbol] != null &&\n        top.hasAtomics()) {\n      // special case for top level MongooseArrays\n      // the `top` array itself and a sub path of `top` are being set.\n      // the only way to honor all of both modifications is through a $set\n      // of entire array.\n      top[arrayAtomicsSymbol] = {};\n      top[arrayAtomicsSymbol].$set = top;\n    }\n  });\n  return minimal;\n};\n\n/**\n * Assigns/compiles `schema` into this documents prototype.\n *\n * @param {Schema} schema\n * @api private\n * @method $__setSchema\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.$__setSchema = function(schema) {\n  compile(schema.tree, this, undefined, schema.options);\n\n  // Apply default getters if virtual doesn't have any (gh-6262)\n  for (const key of Object.keys(schema.virtuals)) {\n    schema.virtuals[key]._applyDefaultGetters();\n  }\n  if (schema.path('schema') == null) {\n    this.schema = schema;\n  }\n  this.$__schema = schema;\n  this[documentSchemaSymbol] = schema;\n};\n\n\n/**\n * Get active path that were changed and are arrays\n *\n * @return {Array}\n * @api private\n * @method $__getArrayPathsToValidate\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.$__getArrayPathsToValidate = function() {\n  DocumentArray || (DocumentArray = __webpack_require__(/*! ./types/documentArray */ \"./node_modules/mongoose/lib/types/documentArray/index.js\"));\n\n  // validate all document arrays.\n  return this.$__.activePaths\n    .map('init', 'modify', function(i) {\n      return this.$__getValue(i);\n    }.bind(this))\n    .filter(function(val) {\n      return val && Array.isArray(val) && utils.isMongooseDocumentArray(val) && val.length;\n    }).reduce(function(seed, array) {\n      return seed.concat(array);\n    }, [])\n    .filter(function(doc) {\n      return doc;\n    });\n};\n\n\n/**\n * Get all subdocs (by bfs)\n *\n * @return {Array}\n * @api public\n * @method $getAllSubdocs\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.$getAllSubdocs = function() {\n  DocumentArray || (DocumentArray = __webpack_require__(/*! ./types/documentArray */ \"./node_modules/mongoose/lib/types/documentArray/index.js\"));\n  Embedded = Embedded || __webpack_require__(/*! ./types/arraySubdocument */ \"./node_modules/mongoose/lib/types/arraySubdocument.js\");\n\n  function docReducer(doc, seed, path) {\n    let val = doc;\n    let isNested = false;\n    if (path) {\n      if (doc instanceof Document && doc[documentSchemaSymbol].paths[path]) {\n        val = doc._doc[path];\n      } else if (doc instanceof Document && doc[documentSchemaSymbol].nested[path]) {\n        val = doc._doc[path];\n        isNested = true;\n      } else {\n        val = doc[path];\n      }\n    }\n    if (val instanceof Embedded) {\n      seed.push(val);\n    } else if (val instanceof Map) {\n      seed = Array.from(val.keys()).reduce(function(seed, path) {\n        return docReducer(val.get(path), seed, null);\n      }, seed);\n    } else if (val && !Array.isArray(val) && val.$isSingleNested) {\n      seed = Object.keys(val._doc).reduce(function(seed, path) {\n        return docReducer(val, seed, path);\n      }, seed);\n      seed.push(val);\n    } else if (val && utils.isMongooseDocumentArray(val)) {\n      val.forEach(function _docReduce(doc) {\n        if (!doc || !doc._doc) {\n          return;\n        }\n        seed = Object.keys(doc._doc).reduce(function(seed, path) {\n          return docReducer(doc._doc, seed, path);\n        }, seed);\n        if (doc instanceof Embedded) {\n          seed.push(doc);\n        }\n      });\n    } else if (isNested && val != null) {\n      for (const path of Object.keys(val)) {\n        docReducer(val, seed, path);\n      }\n    }\n    return seed;\n  }\n\n  const subDocs = [];\n  for (const path of Object.keys(this._doc)) {\n    docReducer(this, subDocs, path);\n  }\n\n  return subDocs;\n};\n\n/*!\n * Runs queued functions\n */\n\nfunction applyQueue(doc) {\n  const q = doc.$__schema && doc.$__schema.callQueue;\n  if (!q.length) {\n    return;\n  }\n\n  for (const pair of q) {\n    if (pair[0] !== 'pre' && pair[0] !== 'post' && pair[0] !== 'on') {\n      doc[pair[0]].apply(doc, pair[1]);\n    }\n  }\n}\n\n/*!\n * ignore\n */\n\nDocument.prototype.$__handleReject = function handleReject(err) {\n  // emit on the Model if listening\n  if (this.$listeners('error').length) {\n    this.$emit('error', err);\n  } else if (this.constructor.listeners && this.constructor.listeners('error').length) {\n    this.constructor.emit('error', err);\n  }\n};\n\n/**\n * Internal common logic for toObject() and toJSON()\n *\n * @return {Object}\n * @api private\n * @method $toObject\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.$toObject = function(options, json) {\n  const defaultOptions = this.$__schema._defaultToObjectOptions(json);\n\n  const hasOnlyPrimitiveValues = this.$__hasOnlyPrimitiveValues();\n\n  // If options do not exist or is not an object, set it to empty object\n  options = utils.isPOJO(options) ? { ...options } : {};\n  options._calledWithOptions = options._calledWithOptions || { ...options };\n\n  let _minimize;\n  if (options._calledWithOptions.minimize != null) {\n    _minimize = options.minimize;\n  } else if (defaultOptions != null && defaultOptions.minimize != null) {\n    _minimize = defaultOptions.minimize;\n  } else {\n    _minimize = this.$__schema.options.minimize;\n  }\n\n  options.minimize = _minimize;\n  if (!hasOnlyPrimitiveValues) {\n    options._seen = options._seen || new Map();\n  }\n\n  const depopulate = options._calledWithOptions.depopulate\n    ?? defaultOptions?.depopulate\n    ?? options.depopulate\n    ?? false;\n  // _isNested will only be true if this is not the top level document, we\n  // should never depopulate the top-level document\n  if (depopulate && options._isNested && this.$__.wasPopulated) {\n    return clone(this.$__.wasPopulated.value || this._doc._id, options);\n  }\n  if (depopulate) {\n    options.depopulate = true;\n  }\n\n  // merge default options with input options.\n  if (defaultOptions != null) {\n    for (const key of Object.keys(defaultOptions)) {\n      if (options[key] == null) {\n        options[key] = defaultOptions[key];\n      }\n    }\n  }\n  options._isNested = true;\n  options.json = json;\n  options.minimize = _minimize;\n\n  const parentOptions = options._parentOptions;\n  // Parent options should only bubble down for subdocuments, not populated docs\n  options._parentOptions = this.$isSubdocument ? options : null;\n\n  options._skipSingleNestedGetters = false;\n  // remember the root transform function\n  // to save it from being overwritten by sub-transform functions\n  // const originalTransform = options.transform;\n\n  let ret;\n  if (hasOnlyPrimitiveValues && !options.flattenObjectIds) {\n    // Fast path: if we don't have any nested objects or arrays, we only need a\n    // shallow clone.\n    ret = this.$__toObjectShallow();\n  } else {\n    ret = clone(this._doc, options) || {};\n  }\n\n  options._skipSingleNestedGetters = true;\n  const getters = options._calledWithOptions.getters\n    ?? options.getters\n    ?? defaultOptions.getters\n    ?? false;\n  if (getters) {\n    applyGetters(this, ret, options);\n\n    if (options.minimize) {\n      ret = minimize(ret) || {};\n    }\n  }\n\n  const virtuals = options._calledWithOptions.virtuals\n    ?? defaultOptions.virtuals\n    ?? parentOptions?.virtuals\n    ?? undefined;\n\n  if (virtuals || (getters && virtuals !== false)) {\n    applyVirtuals(this, ret, options, options);\n  }\n\n  if (options.versionKey === false && this.$__schema.options.versionKey) {\n    delete ret[this.$__schema.options.versionKey];\n  }\n\n  const transform = options._calledWithOptions.transform ?? true;\n  let transformFunction = undefined;\n  if (transform === true) {\n    transformFunction = defaultOptions.transform;\n  } else if (typeof transform === 'function') {\n    transformFunction = transform;\n  }\n\n  // In the case where a subdocument has its own transform function, we need to\n  // check and see if the parent has a transform (options.transform) and if the\n  // child schema has a transform (this.schema.options.toObject) In this case,\n  // we need to adjust options.transform to be the child schema's transform and\n  // not the parent schema's\n  if (transform) {\n    applySchemaTypeTransforms(this, ret);\n  }\n\n  if (options.useProjection) {\n    omitDeselectedFields(this, ret);\n  }\n\n  if (typeof transformFunction === 'function') {\n    const xformed = transformFunction(this, ret, options);\n    if (typeof xformed !== 'undefined') {\n      ret = xformed;\n    }\n  }\n\n  return ret;\n};\n\n/*!\n * Internal shallow clone alternative to `$toObject()`: much faster, no options processing\n */\n\nDocument.prototype.$__toObjectShallow = function $__toObjectShallow() {\n  const ret = {};\n  if (this._doc != null) {\n    for (const key of Object.keys(this._doc)) {\n      const value = this._doc[key];\n      if (value instanceof Date) {\n        ret[key] = new Date(value);\n      } else if (value !== undefined) {\n        ret[key] = value;\n      }\n    }\n  }\n\n  return ret;\n};\n\n/**\n * Converts this document into a plain-old JavaScript object ([POJO](https://masteringjs.io/tutorials/fundamentals/pojo)).\n *\n * Buffers are converted to instances of [mongodb.Binary](https://mongodb.github.io/node-mongodb-native/4.9/classes/Binary.html) for proper storage.\n *\n * #### Getters/Virtuals\n *\n * Example of only applying path getters\n *\n *     doc.toObject({ getters: true, virtuals: false })\n *\n * Example of only applying virtual getters\n *\n *     doc.toObject({ virtuals: true })\n *\n * Example of applying both path and virtual getters\n *\n *     doc.toObject({ getters: true })\n *\n * To apply these options to every document of your schema by default, set your [schemas](https://mongoosejs.com/docs/api/schema.html#Schema()) `toObject` option to the same argument.\n *\n *     schema.set('toObject', { virtuals: true })\n *\n * #### Transform:\n *\n * We may need to perform a transformation of the resulting object based on some criteria, say to remove some sensitive information or return a custom object. In this case we set the optional `transform` function.\n *\n * Transform functions receive three arguments\n *\n *     function (doc, ret, options) {}\n *\n * - `doc` The mongoose document which is being converted\n * - `ret` The plain object representation which has been converted\n * - `options` The options in use (either schema options or the options passed inline)\n *\n * #### Example:\n *\n *     // specify the transform schema option\n *     if (!schema.options.toObject) schema.options.toObject = {};\n *     schema.options.toObject.transform = function (doc, ret, options) {\n *       // remove the _id of every document before returning the result\n *       delete ret._id;\n *       return ret;\n *     }\n *\n *     // without the transformation in the schema\n *     doc.toObject(); // { _id: 'anId', name: 'Wreck-it Ralph' }\n *\n *     // with the transformation\n *     doc.toObject(); // { name: 'Wreck-it Ralph' }\n *\n * With transformations we can do a lot more than remove properties. We can even return completely new customized objects:\n *\n *     if (!schema.options.toObject) schema.options.toObject = {};\n *     schema.options.toObject.transform = function (doc, ret, options) {\n *       return { movie: ret.name }\n *     }\n *\n *     // without the transformation in the schema\n *     doc.toObject(); // { _id: 'anId', name: 'Wreck-it Ralph' }\n *\n *     // with the transformation\n *     doc.toObject(); // { movie: 'Wreck-it Ralph' }\n *\n * _Note: if a transform function returns `undefined`, the return value will be ignored._\n *\n * Transformations may also be applied inline, overridding any transform set in the schema options.\n * Any transform function specified in `toObject` options also propagates to any subdocuments.\n *\n *     function deleteId(doc, ret, options) {\n *       delete ret._id;\n *       return ret;\n *     }\n *\n *     const schema = mongoose.Schema({ name: String, docArr: [{ name: String }] });\n *     const TestModel = mongoose.model('Test', schema);\n *\n *     const doc = new TestModel({ name: 'test', docArr: [{ name: 'test' }] });\n *\n *     // pass the transform as an inline option. Deletes `_id` property\n *     // from both the top-level document and the subdocument.\n *     const obj = doc.toObject({ transform: deleteId });\n *     obj._id; // undefined\n *     obj.docArr[0]._id; // undefined\n *\n * If you want to skip transformations, use `transform: false`:\n *\n *     schema.options.toObject.hide = '_id';\n *     schema.options.toObject.transform = function (doc, ret, options) {\n *       if (options.hide) {\n *         options.hide.split(' ').forEach(function (prop) {\n *           delete ret[prop];\n *         });\n *       }\n *       return ret;\n *     }\n *\n *     const doc = new Doc({ _id: 'anId', secret: 47, name: 'Wreck-it Ralph' });\n *     doc.toObject();                                        // { secret: 47, name: 'Wreck-it Ralph' }\n *     doc.toObject({ hide: 'secret _id', transform: false });// { _id: 'anId', secret: 47, name: 'Wreck-it Ralph' }\n *     doc.toObject({ hide: 'secret _id', transform: true }); // { name: 'Wreck-it Ralph' }\n *\n * If you pass a transform in `toObject()` options, Mongoose will apply the transform\n * to [subdocuments](https://mongoosejs.com/docs/subdocs.html) in addition to the top-level document.\n * Similarly, `transform: false` skips transforms for all subdocuments.\n * Note that this behavior is different for transforms defined in the schema:\n * if you define a transform in `schema.options.toObject.transform`, that transform\n * will **not** apply to subdocuments.\n *\n *     const memberSchema = new Schema({ name: String, email: String });\n *     const groupSchema = new Schema({ members: [memberSchema], name: String, email });\n *     const Group = mongoose.model('Group', groupSchema);\n *\n *     const doc = new Group({\n *       name: 'Engineering',\n *       email: 'dev@mongoosejs.io',\n *       members: [{ name: 'Val', email: 'val@mongoosejs.io' }]\n *     });\n *\n *     // Removes `email` from both top-level document **and** array elements\n *     // { name: 'Engineering', members: [{ name: 'Val' }] }\n *     doc.toObject({ transform: (doc, ret) => { delete ret.email; return ret; } });\n *\n * Transforms, like all of these options, are also available for `toJSON`. See [this guide to `JSON.stringify()`](https://thecodebarbarian.com/the-80-20-guide-to-json-stringify-in-javascript.html) to learn why `toJSON()` and `toObject()` are separate functions.\n *\n * See [schema options](https://mongoosejs.com/docs/guide.html#toObject) for some more details.\n *\n * _During save, no custom options are applied to the document before being sent to the database._\n *\n * @param {Object} [options]\n * @param {Boolean} [options.getters=false] if true, apply all getters, including virtuals\n * @param {Boolean|Object} [options.virtuals=false] if true, apply virtuals, including aliases. Use `{ getters: true, virtuals: false }` to just apply getters, not virtuals. An object of the form `{ pathsToSkip: ['someVirtual'] }` may also be used to omit specific virtuals.\n * @param {Boolean} [options.aliases=true] if `options.virtuals = true`, you can set `options.aliases = false` to skip applying aliases. This option is a no-op if `options.virtuals = false`.\n * @param {Boolean} [options.minimize=true] if true, omit any empty objects from the output\n * @param {Function|null} [options.transform=null] if set, mongoose will call this function to allow you to transform the returned object\n * @param {Boolean} [options.depopulate=false] if true, replace any conventionally populated paths with the original id in the output. Has no affect on virtual populated paths.\n * @param {Boolean} [options.versionKey=true] if false, exclude the version key (`__v` by default) from the output\n * @param {Boolean} [options.flattenMaps=false] if true, convert Maps to POJOs. Useful if you want to `JSON.stringify()` the result of `toObject()`.\n * @param {Boolean} [options.flattenObjectIds=false] if true, convert any ObjectIds in the result to 24 character hex strings.\n * @param {Boolean} [options.useProjection=false] - If true, omits fields that are excluded in this document's projection. Unless you specified a projection, this will omit any field that has `select: false` in the schema.\n * @return {Object} js object (not a POJO)\n * @see mongodb.Binary https://mongodb.github.io/node-mongodb-native/4.9/classes/Binary.html\n * @api public\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.toObject = function(options) {\n  return this.$toObject(options);\n};\n\n/*!\n * Applies virtuals properties to `json`.\n */\n\nfunction applyVirtuals(self, json, options, toObjectOptions) {\n  const schema = self.$__schema;\n  const virtuals = schema.virtuals;\n  const paths = Object.keys(virtuals);\n  let i = paths.length;\n  const numPaths = i;\n  let path;\n  let assignPath;\n  let cur = self._doc;\n  let v;\n  const aliases = typeof (toObjectOptions && toObjectOptions.aliases) === 'boolean'\n    ? toObjectOptions.aliases\n    : true;\n\n  options = options || {};\n  let virtualsToApply = null;\n  if (Array.isArray(options.virtuals)) {\n    virtualsToApply = new Set(options.virtuals);\n  } else if (options.virtuals && options.virtuals.pathsToSkip) {\n    virtualsToApply = new Set(paths);\n    for (let i = 0; i < options.virtuals.pathsToSkip.length; i++) {\n      if (virtualsToApply.has(options.virtuals.pathsToSkip[i])) {\n        virtualsToApply.delete(options.virtuals.pathsToSkip[i]);\n      }\n    }\n  }\n\n  if (!cur) {\n    return json;\n  }\n\n  for (i = 0; i < numPaths; ++i) {\n    path = paths[i];\n\n    if (virtualsToApply != null && !virtualsToApply.has(path)) {\n      continue;\n    }\n\n    // Allow skipping aliases with `toObject({ virtuals: true, aliases: false })`\n    if (!aliases && schema.aliases.hasOwnProperty(path)) {\n      continue;\n    }\n\n    // We may be applying virtuals to a nested object, for example if calling\n    // `doc.nestedProp.toJSON()`. If so, the path we assign to, `assignPath`,\n    // will be a trailing substring of the `path`.\n    assignPath = path;\n    if (options.path != null) {\n      if (!path.startsWith(options.path + '.')) {\n        continue;\n      }\n      assignPath = path.substring(options.path.length + 1);\n    }\n    if (assignPath.indexOf('.') === -1 && assignPath === path) {\n      v = virtuals[path].applyGetters(void 0, self);\n      if (v === void 0) {\n        continue;\n      }\n      v = clone(v, options);\n      json[assignPath] = v;\n      continue;\n    }\n    const parts = assignPath.split('.');\n    v = clone(self.get(path), options);\n    if (v === void 0) {\n      continue;\n    }\n    const plen = parts.length;\n    cur = json;\n    for (let j = 0; j < plen - 1; ++j) {\n      cur[parts[j]] = cur[parts[j]] || {};\n      cur = cur[parts[j]];\n    }\n    cur[parts[plen - 1]] = v;\n  }\n\n  return json;\n}\n\n\n/**\n * Applies virtuals properties to `json`.\n *\n * @param {Document} self\n * @param {Object} json\n * @param {Object} [options]\n * @return {Object} `json`\n * @api private\n */\n\nfunction applyGetters(self, json, options) {\n  const schema = self.$__schema;\n  const paths = Object.keys(schema.paths);\n  let i = paths.length;\n  let path;\n  let cur = self._doc;\n  let v;\n\n  if (!cur) {\n    return json;\n  }\n\n  while (i--) {\n    path = paths[i];\n\n    const parts = path.split('.');\n\n    const plen = parts.length;\n    const last = plen - 1;\n    let branch = json;\n    let part;\n    cur = self._doc;\n\n    if (!self.$__isSelected(path)) {\n      continue;\n    }\n\n    for (let ii = 0; ii < plen; ++ii) {\n      part = parts[ii];\n      v = cur[part];\n      // If we've reached a non-object part of the branch, continuing would\n      // cause \"Cannot create property 'foo' on string 'bar'\" error.\n      // Necessary for mongoose-intl plugin re: gh-14446\n      if (branch != null && typeof branch !== 'object') {\n        break;\n      } else if (ii === last) {\n        const val = self.$get(path);\n        branch[part] = clone(val, options);\n        if (Array.isArray(branch[part]) && schema.paths[path].$embeddedSchemaType) {\n          for (let i = 0; i < branch[part].length; ++i) {\n            branch[part][i] = schema.paths[path].$embeddedSchemaType.applyGetters(\n              branch[part][i],\n              self\n            );\n          }\n        }\n      } else if (v == null) {\n        if (part in cur) {\n          branch[part] = v;\n        }\n        break;\n      } else {\n        branch = branch[part] || (branch[part] = {});\n      }\n      cur = v;\n    }\n  }\n\n  return json;\n}\n\n/**\n * Applies schema type transforms to `json`.\n *\n * @param {Document} self\n * @param {Object} json\n * @return {Object} `json`\n * @api private\n */\n\nfunction applySchemaTypeTransforms(self, json) {\n  const schema = self.$__schema;\n  const paths = Object.keys(schema.paths || {});\n  const cur = self._doc;\n\n  if (!cur) {\n    return json;\n  }\n\n  for (const path of paths) {\n    const schematype = schema.paths[path];\n    if (typeof schematype.options.transform === 'function') {\n      const val = self.$get(path);\n      if (val === undefined) {\n        continue;\n      }\n      const transformedValue = schematype.options.transform.call(self, val);\n      throwErrorIfPromise(path, transformedValue);\n      utils.setValue(path, transformedValue, json);\n    } else if (schematype.$embeddedSchemaType != null &&\n        typeof schematype.$embeddedSchemaType.options.transform === 'function') {\n      const val = self.$get(path);\n      if (val === undefined) {\n        continue;\n      }\n      const vals = [].concat(val);\n      const transform = schematype.$embeddedSchemaType.options.transform;\n      for (let i = 0; i < vals.length; ++i) {\n        const transformedValue = transform.call(self, vals[i]);\n        vals[i] = transformedValue;\n        throwErrorIfPromise(path, transformedValue);\n      }\n\n      json[path] = vals;\n    }\n  }\n\n  return json;\n}\n\nfunction throwErrorIfPromise(path, transformedValue) {\n  if (isPromise(transformedValue)) {\n    throw new Error('`transform` function must be synchronous, but the transform on path `' + path + '` returned a promise.');\n  }\n}\n\n/*!\n * ignore\n */\n\nfunction omitDeselectedFields(self, json) {\n  const schema = self.$__schema;\n  const paths = Object.keys(schema.paths || {});\n  const cur = self._doc;\n\n  if (!cur) {\n    return json;\n  }\n\n  let selected = self.$__.selected;\n  if (selected === void 0) {\n    selected = {};\n    queryhelpers.applyPaths(selected, schema);\n  }\n  if (selected == null || Object.keys(selected).length === 0) {\n    return json;\n  }\n\n  for (const path of paths) {\n    if (selected[path] != null && !selected[path]) {\n      delete json[path];\n    }\n  }\n\n  return json;\n}\n\n/**\n * The return value of this method is used in calls to [`JSON.stringify(doc)`](https://thecodebarbarian.com/the-80-20-guide-to-json-stringify-in-javascript#the-tojson-function).\n *\n * This method accepts the same options as [Document#toObject](https://mongoosejs.com/docs/api/document.html#Document.prototype.toObject()). To apply the options to every document of your schema by default, set your [schemas](https://mongoosejs.com/docs/api/schema.html#Schema()) `toJSON` option to the same argument.\n *\n *     schema.set('toJSON', { virtuals: true });\n *\n * There is one difference between `toJSON()` and `toObject()` options.\n * When you call `toJSON()`, the [`flattenMaps` option](https://mongoosejs.com/docs/api/document.html#Document.prototype.toObject()) defaults to `true`, because `JSON.stringify()` doesn't convert maps to objects by default.\n * When you call `toObject()`, the `flattenMaps` option is `false` by default.\n *\n * See [schema options](https://mongoosejs.com/docs/guide.html#toJSON) for more information on setting `toJSON` option defaults.\n *\n * @param {Object} options\n * @param {Boolean} [options.flattenMaps=true] if true, convert Maps to [POJOs](https://masteringjs.io/tutorials/fundamentals/pojo). Useful if you want to `JSON.stringify()` the result.\n * @param {Boolean} [options.flattenObjectIds=false] if true, convert any ObjectIds in the result to 24 character hex strings.\n * @return {Object}\n * @see Document#toObject https://mongoosejs.com/docs/api/document.html#Document.prototype.toObject()\n * @see JSON.stringify() in JavaScript https://thecodebarbarian.com/the-80-20-guide-to-json-stringify-in-javascript.html\n * @api public\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.toJSON = function(options) {\n  return this.$toObject(options, true);\n};\n\n/*!\n * ignore\n */\n\nDocument.prototype.ownerDocument = function() {\n  return this;\n};\n\n\n/**\n * If this document is a subdocument or populated document, returns the document's\n * parent. Returns the original document if there is no parent.\n *\n * @return {Document}\n * @api public\n * @method parent\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.parent = function() {\n  if (this.$isSubdocument || this.$__.wasPopulated) {\n    return this.$__.parent;\n  }\n  return this;\n};\n\n/**\n * Alias for [`parent()`](https://mongoosejs.com/docs/api/document.html#Document.prototype.parent()). If this document is a subdocument or populated\n * document, returns the document's parent. Returns `undefined` otherwise.\n *\n * @return {Document}\n * @api public\n * @method $parent\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.$parent = Document.prototype.parent;\n\n/**\n * Helper for console.log\n *\n * @return {String}\n * @api public\n * @method inspect\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.inspect = function(options) {\n  const isPOJO = utils.isPOJO(options);\n  let opts;\n  if (isPOJO) {\n    opts = options;\n    opts.minimize = false;\n  }\n\n  const ret = arguments.length > 0 ? this.toObject(opts) : this.toObject();\n\n  if (ret == null) {\n    // If `toObject()` returns null, `this` is still an object, so if `inspect()`\n    // prints out null this can cause some serious confusion. See gh-7942.\n    return 'MongooseDocument { ' + ret + ' }';\n  }\n\n  return ret;\n};\n\nif (inspect.custom) {\n  // Avoid Node deprecation warning DEP0079\n  Document.prototype[inspect.custom] = Document.prototype.inspect;\n}\n\n/**\n * Helper for console.log\n *\n * @return {String}\n * @api public\n * @method toString\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.toString = function() {\n  const ret = this.inspect();\n  if (typeof ret === 'string') {\n    return ret;\n  }\n  return inspect(ret);\n};\n\n/**\n * Returns true if this document is equal to another document.\n *\n * Documents are considered equal when they have matching `_id`s, unless neither\n * document has an `_id`, in which case this function falls back to using\n * `deepEqual()`.\n *\n * @param {Document} [doc] a document to compare. If falsy, will always return \"false\".\n * @return {Boolean}\n * @api public\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.equals = function(doc) {\n  if (!doc) {\n    return false;\n  }\n\n  const tid = this.$__getValue('_id');\n  const docid = doc.$__ != null ? doc.$__getValue('_id') : doc;\n  if (!tid && !docid) {\n    return deepEqual(this, doc);\n  }\n  return tid && tid.equals\n    ? tid.equals(docid)\n    : tid === docid;\n};\n\n/**\n * Populates paths on an existing document.\n *\n * #### Example:\n *\n *     // Given a document, `populate()` lets you pull in referenced docs\n *     await doc.populate([\n *       'stories',\n *       { path: 'fans', sort: { name: -1 } }\n *     ]);\n *     doc.populated('stories'); // Array of ObjectIds\n *     doc.stories[0].title; // 'Casino Royale'\n *     doc.populated('fans'); // Array of ObjectIds\n *\n *     // If the referenced doc has been deleted, `populate()` will\n *     // remove that entry from the array.\n *     await Story.delete({ title: 'Casino Royale' });\n *     await doc.populate('stories'); // Empty array\n *\n *     // You can also pass additional query options to `populate()`,\n *     // like projections:\n *     await doc.populate('fans', '-email');\n *     doc.fans[0].email // undefined because of 2nd param `select`\n *\n * @param {String|Object|Array} path either the path to populate or an object specifying all parameters, or either an array of those\n * @param {Object|String} [select] Field selection for the population query\n * @param {Model} [model] The model you wish to use for population. If not specified, populate will look up the model by the name in the Schema's `ref` field.\n * @param {Object} [match] Conditions for the population query\n * @param {Object} [options] Options for the population query (sort, etc)\n * @param {String} [options.path=null] The path to populate.\n * @param {string|PopulateOptions} [options.populate=null] Recursively populate paths in the populated documents. See [deep populate docs](https://mongoosejs.com/docs/populate.html#deep-populate).\n * @param {boolean} [options.retainNullValues=false] by default, Mongoose removes null and undefined values from populated arrays. Use this option to make `populate()` retain `null` and `undefined` array entries.\n * @param {boolean} [options.getters=false] if true, Mongoose will call any getters defined on the `localField`. By default, Mongoose gets the raw value of `localField`. For example, you would need to set this option to `true` if you wanted to [add a `lowercase` getter to your `localField`](https://mongoosejs.com/docs/schematypes.html#schematype-options).\n * @param {boolean} [options.clone=false] When you do `BlogPost.find().populate('author')`, blog posts with the same author will share 1 copy of an `author` doc. Enable this option to make Mongoose clone populated docs before assigning them.\n * @param {Object|Function} [options.match=null] Add an additional filter to the populate query. Can be a filter object containing [MongoDB query syntax](https://www.mongodb.com/docs/manual/tutorial/query-documents/), or a function that returns a filter object.\n * @param {Function} [options.transform=null] Function that Mongoose will call on every populated document that allows you to transform the populated document.\n * @param {Object} [options.options=null] Additional options like `limit` and `lean`.\n * @param {Function} [callback] Callback\n * @see population https://mongoosejs.com/docs/populate.html\n * @see Query#select https://mongoosejs.com/docs/api/query.html#Query.prototype.select()\n * @see Model.populate https://mongoosejs.com/docs/api/model.html#Model.populate()\n * @memberOf Document\n * @instance\n * @return {Promise|null} Returns a Promise if no `callback` is given.\n * @api public\n */\n\nDocument.prototype.populate = async function populate() {\n  const pop = {};\n  const args = [...arguments];\n  if (typeof args[args.length - 1] === 'function') {\n    throw new MongooseError('Document.prototype.populate() no longer accepts a callback');\n  }\n\n  if (args.length !== 0) {\n    // use hash to remove duplicate paths\n    const res = utils.populate.apply(null, args);\n    for (const populateOptions of res) {\n      pop[populateOptions.path] = populateOptions;\n    }\n  }\n\n  const paths = utils.object.vals(pop);\n  let topLevelModel = this.constructor;\n  if (this.$__isNested) {\n    topLevelModel = this.$__[scopeSymbol].constructor;\n    const nestedPath = this.$__.nestedPath;\n    paths.forEach(function(populateOptions) {\n      populateOptions.path = nestedPath + '.' + populateOptions.path;\n    });\n  }\n\n  // Use `$session()` by default if the document has an associated session\n  // See gh-6754\n  if (this.$session() != null) {\n    const session = this.$session();\n    paths.forEach(path => {\n      if (path.options == null) {\n        path.options = { session: session };\n        return;\n      }\n      if (!('session' in path.options)) {\n        path.options.session = session;\n      }\n    });\n  }\n\n  paths.forEach(p => {\n    p._localModel = topLevelModel;\n  });\n\n  return topLevelModel.populate(this, paths);\n};\n\n/**\n * Gets all populated documents associated with this document.\n *\n * @api public\n * @return {Document[]} array of populated documents. Empty array if there are no populated documents associated with this document.\n * @memberOf Document\n * @method $getPopulatedDocs\n * @instance\n */\n\nDocument.prototype.$getPopulatedDocs = function $getPopulatedDocs() {\n  let keys = [];\n  if (this.$__.populated != null) {\n    keys = keys.concat(Object.keys(this.$__.populated));\n  }\n  let result = [];\n  for (const key of keys) {\n    const value = this.$get(key);\n    if (Array.isArray(value)) {\n      result = result.concat(value);\n    } else if (value instanceof Document) {\n      result.push(value);\n    }\n  }\n  return result;\n};\n\n/**\n * Gets _id(s) used during population of the given `path`.\n *\n * #### Example:\n *\n *     const doc = await Model.findOne().populate('author');\n *\n *     console.log(doc.author.name); // Dr.Seuss\n *     console.log(doc.populated('author')); // '5144cf8050f071d979c118a7'\n *\n * If the path was not populated, returns `undefined`.\n *\n * @param {String} path\n * @param {Any} [val]\n * @param {Object} [options]\n * @return {Array|ObjectId|Number|Buffer|String|undefined}\n * @memberOf Document\n * @instance\n * @api public\n */\n\nDocument.prototype.populated = function(path, val, options) {\n  // val and options are internal\n  if (val == null || val === true) {\n    if (!this.$__.populated) {\n      return undefined;\n    }\n    if (typeof path !== 'string') {\n      return undefined;\n    }\n\n    // Map paths can be populated with either `path.$*` or just `path`\n    const _path = path.endsWith('.$*') ? path.replace(/\\.\\$\\*$/, '') : path;\n\n    const v = this.$__.populated[_path];\n    if (v) {\n      return val === true ? v : v.value;\n    }\n    return undefined;\n  }\n\n  this.$__.populated || (this.$__.populated = {});\n  this.$__.populated[path] = { value: val, options: options };\n\n  // If this was a nested populate, make sure each populated doc knows\n  // about its populated children (gh-7685)\n  const pieces = path.split('.');\n  for (let i = 0; i < pieces.length - 1; ++i) {\n    const subpath = pieces.slice(0, i + 1).join('.');\n    const subdoc = this.$get(subpath);\n    if (subdoc != null && subdoc.$__ != null && this.$populated(subpath)) {\n      const rest = pieces.slice(i + 1).join('.');\n      subdoc.$populated(rest, val, options);\n      // No need to continue because the above recursion should take care of\n      // marking the rest of the docs as populated\n      break;\n    }\n  }\n\n  return val;\n};\n\n/**\n * Alias of [`.populated`](https://mongoosejs.com/docs/api/document.html#Document.prototype.populated()).\n *\n * @method $populated\n * @memberOf Document\n * @api public\n */\n\nDocument.prototype.$populated = Document.prototype.populated;\n\n/**\n * Throws an error if a given path is not populated\n *\n * #### Example:\n *\n *     const doc = await Model.findOne().populate('author');\n *\n *     doc.$assertPopulated('author'); // does not throw\n *     doc.$assertPopulated('other path'); // throws an error\n *\n *     // Manually populate and assert in one call. The following does\n *     // `doc.$set({ likes })` before asserting.\n *     doc.$assertPopulated('likes', { likes });\n *\n *\n * @param {String|String[]} path path or array of paths to check. `$assertPopulated` throws if any of the given paths is not populated.\n * @param {Object} [values] optional values to `$set()`. Convenient if you want to manually populate a path and assert that the path was populated in 1 call.\n * @return {Document} this\n * @memberOf Document\n * @method $assertPopulated\n * @instance\n * @api public\n */\n\nDocument.prototype.$assertPopulated = function $assertPopulated(path, values) {\n  if (Array.isArray(path)) {\n    path.forEach(p => this.$assertPopulated(p, values));\n    return this;\n  }\n\n  if (arguments.length > 1) {\n    this.$set(values);\n  }\n\n  if (!this.$populated(path)) {\n    throw new MongooseError(`Expected path \"${path}\" to be populated`);\n  }\n\n  return this;\n};\n\n/**\n * Takes a populated field and returns it to its unpopulated state.\n *\n * #### Example:\n *\n *     Model.findOne().populate('author').exec(function (err, doc) {\n *       console.log(doc.author.name); // Dr.Seuss\n *       console.log(doc.depopulate('author'));\n *       console.log(doc.author); // '5144cf8050f071d979c118a7'\n *     })\n *\n * If the path was not provided, then all populated fields are returned to their unpopulated state.\n *\n * @param {String|String[]} [path] Specific Path to depopulate. If unset, will depopulate all paths on the Document. Or multiple space-delimited paths.\n * @return {Document} this\n * @see Document.populate https://mongoosejs.com/docs/api/document.html#Document.prototype.populate()\n * @api public\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.depopulate = function(path) {\n  if (typeof path === 'string') {\n    path = path.indexOf(' ') === -1 ? [path] : path.split(' ');\n  }\n\n  let populatedIds;\n  const virtualKeys = this.$$populatedVirtuals ? Object.keys(this.$$populatedVirtuals) : [];\n  const populated = this.$__ && this.$__.populated || {};\n\n  if (arguments.length === 0) {\n    // Depopulate all\n    for (const virtualKey of virtualKeys) {\n      delete this.$$populatedVirtuals[virtualKey];\n      delete this._doc[virtualKey];\n      delete populated[virtualKey];\n    }\n\n    const keys = Object.keys(populated);\n\n    for (const key of keys) {\n      populatedIds = this.$populated(key);\n      if (!populatedIds) {\n        continue;\n      }\n      delete populated[key];\n      if (Array.isArray(populatedIds)) {\n        const arr = utils.getValue(key, this._doc);\n        if (arr.isMongooseArray) {\n          const rawArray = arr.__array;\n          for (let i = 0; i < rawArray.length; ++i) {\n            const subdoc = rawArray[i];\n            if (subdoc == null) {\n              continue;\n            }\n            rawArray[i] = subdoc instanceof Document ? subdoc._doc._id : subdoc._id;\n          }\n        } else {\n          utils.setValue(key, populatedIds, this._doc);\n        }\n      } else {\n        utils.setValue(key, populatedIds, this._doc);\n      }\n    }\n    return this;\n  }\n\n  for (const singlePath of path) {\n    populatedIds = this.$populated(singlePath);\n    delete populated[singlePath];\n\n    if (virtualKeys.indexOf(singlePath) !== -1) {\n      delete this.$$populatedVirtuals[singlePath];\n      delete this._doc[singlePath];\n    } else if (populatedIds) {\n      if (Array.isArray(populatedIds)) {\n        const arr = utils.getValue(singlePath, this._doc);\n        if (arr.isMongooseArray) {\n          const rawArray = arr.__array;\n          for (let i = 0; i < rawArray.length; ++i) {\n            const subdoc = rawArray[i];\n            if (subdoc == null) {\n              continue;\n            }\n            rawArray[i] = subdoc instanceof Document ? subdoc._doc._id : subdoc._id;\n          }\n        } else {\n          utils.setValue(singlePath, populatedIds, this._doc);\n        }\n      } else {\n        utils.setValue(singlePath, populatedIds, this._doc);\n      }\n    }\n  }\n  return this;\n};\n\n\n/**\n * Returns the full path to this document.\n *\n * @param {String} [path]\n * @return {String}\n * @api private\n * @method $__fullPath\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.$__fullPath = function(path) {\n  // overridden in SubDocuments\n  return path || '';\n};\n\n/**\n * Returns the changes that happened to the document\n * in the format that will be sent to MongoDB.\n *\n * #### Example:\n *\n *     const userSchema = new Schema({\n *       name: String,\n *       age: Number,\n *       country: String\n *     });\n *     const User = mongoose.model('User', userSchema);\n *     const user = await User.create({\n *       name: 'Hafez',\n *       age: 25,\n *       country: 'Egypt'\n *     });\n *\n *     // returns an empty object, no changes happened yet\n *     user.getChanges(); // { }\n *\n *     user.country = undefined;\n *     user.age = 26;\n *\n *     user.getChanges(); // { $set: { age: 26 }, { $unset: { country: 1 } } }\n *\n *     await user.save();\n *\n *     user.getChanges(); // { }\n *\n * Modifying the object that `getChanges()` returns does not affect the document's\n * change tracking state. Even if you `delete user.getChanges().$set`, Mongoose\n * will still send a `$set` to the server.\n *\n * @return {Object}\n * @api public\n * @method getChanges\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.getChanges = function() {\n  const delta = this.$__delta();\n  const changes = delta ? delta[1] : {};\n  return changes;\n};\n\n/**\n * Produces a special query document of the modified properties used in updates.\n *\n * @api private\n * @method $__delta\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.$__delta = function $__delta() {\n  const dirty = this.$__dirty();\n  const optimisticConcurrency = this.$__schema.options.optimisticConcurrency;\n  if (optimisticConcurrency) {\n    if (Array.isArray(optimisticConcurrency)) {\n      const optCon = new Set(optimisticConcurrency);\n      const modPaths = this.modifiedPaths();\n      if (modPaths.find(path => optCon.has(path))) {\n        this.$__.version = dirty.length ? VERSION_ALL : VERSION_WHERE;\n      }\n    } else {\n      this.$__.version = dirty.length ? VERSION_ALL : VERSION_WHERE;\n    }\n  }\n\n  if (!dirty.length && VERSION_ALL !== this.$__.version) {\n    return;\n  }\n  const where = {};\n  const delta = {};\n  const len = dirty.length;\n  const divergent = [];\n  let d = 0;\n\n  where._id = this._doc._id;\n  // If `_id` is an object, need to depopulate, but also need to be careful\n  // because `_id` can technically be null (see gh-6406)\n  if ((where && where._id && where._id.$__ || null) != null) {\n    where._id = where._id.toObject({ transform: false, depopulate: true });\n  }\n  for (; d < len; ++d) {\n    const data = dirty[d];\n    let value = data.value;\n    const match = checkDivergentArray(this, data.path, value);\n    if (match) {\n      divergent.push(match);\n      continue;\n    }\n\n    const pop = this.$populated(data.path, true);\n    if (!pop && this.$__.selected) {\n      // If any array was selected using an $elemMatch projection, we alter the path and where clause\n      // NOTE: MongoDB only supports projected $elemMatch on top level array.\n      const pathSplit = data.path.split('.');\n      const top = pathSplit[0];\n      if (this.$__.selected[top] && this.$__.selected[top].$elemMatch) {\n        // If the selected array entry was modified\n        if (pathSplit.length > 1 && pathSplit[1] == 0 && typeof where[top] === 'undefined') {\n          where[top] = this.$__.selected[top];\n          pathSplit[1] = '$';\n          data.path = pathSplit.join('.');\n        }\n        // if the selected array was modified in any other way throw an error\n        else {\n          divergent.push(data.path);\n          continue;\n        }\n      }\n    }\n\n    // If this path is set to default, and either this path or one of\n    // its parents is excluded, don't treat this path as dirty.\n    if (this.$isDefault(data.path) && this.$__.selected) {\n      if (data.path.indexOf('.') === -1 && isPathExcluded(this.$__.selected, data.path)) {\n        continue;\n      }\n\n      const pathsToCheck = parentPaths(data.path);\n      if (pathsToCheck.find(path => isPathExcluded(this.$__.isSelected, path))) {\n        continue;\n      }\n    }\n\n    if (divergent.length) continue;\n    if (value === undefined) {\n      operand(this, where, delta, data, 1, '$unset');\n    } else if (value === null) {\n      operand(this, where, delta, data, null);\n    } else if (utils.isMongooseArray(value) && value.$path() && value[arrayAtomicsSymbol]) {\n      // arrays and other custom types (support plugins etc)\n      handleAtomics(this, where, delta, data, value);\n    } else if (value[MongooseBuffer.pathSymbol] && Buffer.isBuffer(value)) {\n      // MongooseBuffer\n      value = value.toObject();\n      operand(this, where, delta, data, value);\n    } else {\n      if (this.$__.primitiveAtomics && this.$__.primitiveAtomics[data.path] != null) {\n        const val = this.$__.primitiveAtomics[data.path];\n        const op = firstKey(val);\n        operand(this, where, delta, data, val[op], op);\n      } else {\n        value = clone(value, {\n          depopulate: true,\n          transform: false,\n          virtuals: false,\n          getters: false,\n          omitUndefined: true,\n          _isNested: true\n        });\n        operand(this, where, delta, data, value);\n      }\n    }\n  }\n\n  if (divergent.length) {\n    return new DivergentArrayError(divergent);\n  }\n\n  if (this.$__.version) {\n    this.$__version(where, delta);\n  }\n\n  if (Object.keys(delta).length === 0) {\n    return [where, null];\n  }\n\n  return [where, delta];\n};\n\n/**\n * Determine if array was populated with some form of filter and is now\n * being updated in a manner which could overwrite data unintentionally.\n *\n * @see https://github.com/Automattic/mongoose/issues/1334\n * @param {Document} doc\n * @param {String} path\n * @param {Any} array\n * @return {String|undefined}\n * @api private\n */\n\nfunction checkDivergentArray(doc, path, array) {\n  // see if we populated this path\n  const pop = doc.$populated(path, true);\n\n  if (!pop && doc.$__.selected) {\n    // If any array was selected using an $elemMatch projection, we deny the update.\n    // NOTE: MongoDB only supports projected $elemMatch on top level array.\n    const top = path.split('.')[0];\n    if (doc.$__.selected[top + '.$']) {\n      return top;\n    }\n  }\n\n  if (!(pop && utils.isMongooseArray(array))) return;\n\n  // If the array was populated using options that prevented all\n  // documents from being returned (match, skip, limit) or they\n  // deselected the _id field, $pop and $set of the array are\n  // not safe operations. If _id was deselected, we do not know\n  // how to remove elements. $pop will pop off the _id from the end\n  // of the array in the db which is not guaranteed to be the\n  // same as the last element we have here. $set of the entire array\n  // would be similarly destructive as we never received all\n  // elements of the array and potentially would overwrite data.\n  const check = pop.options.match ||\n      pop.options.options && utils.object.hasOwnProperty(pop.options.options, 'limit') || // 0 is not permitted\n      pop.options.options && pop.options.options.skip || // 0 is permitted\n      pop.options.select && // deselected _id?\n      (pop.options.select._id === 0 ||\n      /\\s?-_id\\s?/.test(pop.options.select));\n\n  if (check) {\n    const atomics = array[arrayAtomicsSymbol];\n    if (Object.keys(atomics).length === 0 || atomics.$set || atomics.$pop) {\n      return path;\n    }\n  }\n}\n\n/**\n * Apply the operation to the delta (update) clause as\n * well as track versioning for our where clause.\n *\n * @param {Document} self\n * @param {Object} where Unused\n * @param {Object} delta\n * @param {Object} data\n * @param {Mixed} val\n * @param {String} [op]\n * @api private\n */\n\nfunction operand(self, where, delta, data, val, op) {\n  // delta\n  op || (op = '$set');\n  if (!delta[op]) delta[op] = {};\n  delta[op][data.path] = val;\n  // disabled versioning?\n  if (self.$__schema.options.versionKey === false) return;\n\n  // path excluded from versioning?\n  if (shouldSkipVersioning(self, data.path)) return;\n\n  // already marked for versioning?\n  if (VERSION_ALL === (VERSION_ALL & self.$__.version)) return;\n\n  if (self.$__schema.options.optimisticConcurrency) {\n    return;\n  }\n\n  switch (op) {\n    case '$set':\n    case '$unset':\n    case '$pop':\n    case '$pull':\n    case '$pullAll':\n    case '$push':\n    case '$addToSet':\n    case '$inc':\n      break;\n    default:\n      // nothing to do\n      return;\n  }\n\n  // ensure updates sent with positional notation are\n  // editing the correct array element.\n  // only increment the version if an array position changes.\n  // modifying elements of an array is ok if position does not change.\n  if (op === '$push' || op === '$addToSet' || op === '$pullAll' || op === '$pull') {\n    if (/\\.\\d+\\.|\\.\\d+$/.test(data.path)) {\n      self.$__.version = VERSION_ALL;\n    } else {\n      self.$__.version = VERSION_INC;\n    }\n  } else if (/^\\$p/.test(op)) {\n    // potentially changing array positions\n    self.$__.version = VERSION_ALL;\n  } else if (Array.isArray(val)) {\n    // $set an array\n    self.$__.version = VERSION_ALL;\n  } else if (/\\.\\d+\\.|\\.\\d+$/.test(data.path)) {\n    // now handling $set, $unset\n    // subpath of array\n    self.$__.version = VERSION_WHERE;\n  }\n}\n\n/**\n * Compiles an update and where clause for a `val` with _atomics.\n *\n * @param {Document} self\n * @param {Object} where\n * @param {Object} delta\n * @param {Object} data\n * @param {Array} value\n * @api private\n */\n\nfunction handleAtomics(self, where, delta, data, value) {\n  if (delta.$set && delta.$set[data.path]) {\n    // $set has precedence over other atomics\n    return;\n  }\n\n  if (typeof value.$__getAtomics === 'function') {\n    value.$__getAtomics().forEach(function(atomic) {\n      const op = atomic[0];\n      const val = atomic[1];\n      operand(self, where, delta, data, val, op);\n    });\n    return;\n  }\n\n  // legacy support for plugins\n\n  const atomics = value[arrayAtomicsSymbol];\n  const ops = Object.keys(atomics);\n  let i = ops.length;\n  let val;\n  let op;\n\n  if (i === 0) {\n    // $set\n\n    if (utils.isMongooseObject(value)) {\n      value = value.toObject({ depopulate: 1, _isNested: true });\n    } else if (value.valueOf) {\n      value = value.valueOf();\n    }\n\n    return operand(self, where, delta, data, value);\n  }\n\n  function iter(mem) {\n    return utils.isMongooseObject(mem)\n      ? mem.toObject({ depopulate: 1, _isNested: true })\n      : mem;\n  }\n\n  while (i--) {\n    op = ops[i];\n    val = atomics[op];\n\n    if (utils.isMongooseObject(val)) {\n      val = val.toObject({ depopulate: true, transform: false, _isNested: true });\n    } else if (Array.isArray(val)) {\n      val = val.map(iter);\n    } else if (val.valueOf) {\n      val = val.valueOf();\n    }\n\n    if (op === '$addToSet') {\n      val = { $each: val };\n    }\n\n    operand(self, where, delta, data, val, op);\n  }\n}\n\n/**\n * Determines whether versioning should be skipped for the given path\n *\n * @param {Document} self\n * @param {String} path\n * @return {Boolean} true if versioning should be skipped for the given path\n * @api private\n */\nfunction shouldSkipVersioning(self, path) {\n  const skipVersioning = self.$__schema.options.skipVersioning;\n  if (!skipVersioning) return false;\n\n  // Remove any array indexes from the path\n  path = path.replace(/\\.\\d+\\./, '.');\n\n  return skipVersioning[path];\n}\n\n/**\n * Returns a copy of this document with a deep clone of `_doc` and `$__`.\n *\n * @return {Document} a copy of this document\n * @api public\n * @method $clone\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.$clone = function() {\n  const Model = this.constructor;\n  const clonedDoc = new Model();\n  clonedDoc.$isNew = this.$isNew;\n  if (this._doc) {\n    clonedDoc._doc = clone(this._doc, { retainDocuments: true });\n  }\n  if (this.$__) {\n    const Cache = this.$__.constructor;\n    const clonedCache = new Cache();\n    for (const key of Object.getOwnPropertyNames(this.$__)) {\n      if (key === 'activePaths') {\n        continue;\n      }\n      clonedCache[key] = clone(this.$__[key]);\n    }\n    Object.assign(clonedCache.activePaths, clone({ ...this.$__.activePaths }));\n    clonedDoc.$__ = clonedCache;\n  }\n  return clonedDoc;\n};\n\n/**\n * Creates a snapshot of this document's internal change tracking state. You can later\n * reset this document's change tracking state using `$restoreModifiedPathsSnapshot()`.\n *\n * #### Example:\n *\n *     const doc = await TestModel.findOne();\n *     const snapshot = doc.$createModifiedPathsSnapshot();\n *\n * @return {ModifiedPathsSnapshot} a copy of this document's internal change tracking state\n * @api public\n * @method $createModifiedPathsSnapshot\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.$createModifiedPathsSnapshot = function $createModifiedPathsSnapshot() {\n  const subdocSnapshot = new WeakMap();\n  if (!this.$isSubdocument) {\n    const subdocs = this.$getAllSubdocs();\n    for (const child of subdocs) {\n      subdocSnapshot.set(child, child.$__.activePaths.clone());\n    }\n  }\n\n  return new ModifiedPathsSnapshot(\n    subdocSnapshot,\n    this.$__.activePaths.clone(),\n    this.$__.version\n  );\n};\n\n/**\n * Restore this document's change tracking state to the given snapshot.\n * Note that `$restoreModifiedPathsSnapshot()` does **not** modify the document's\n * properties, just resets the change tracking state.\n *\n * This method is especially useful when writing [custom transaction wrappers](https://github.com/Automattic/mongoose/issues/14268#issuecomment-2100505554) that need to restore change tracking when aborting a transaction.\n *\n * #### Example:\n *\n *     const doc = await TestModel.findOne();\n *     const snapshot = doc.$createModifiedPathsSnapshot();\n *\n *     doc.name = 'test';\n *     doc.$restoreModifiedPathsSnapshot(snapshot);\n *     doc.$isModified('name'); // false because `name` was not modified when snapshot was taken\n *     doc.name; // 'test', `$restoreModifiedPathsSnapshot()` does **not** modify the document's data, only change tracking\n *\n * @param {ModifiedPathsSnapshot} snapshot of the document's internal change tracking state snapshot to restore\n * @api public\n * @method $restoreModifiedPathsSnapshot\n * @return {Document} this\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.$restoreModifiedPathsSnapshot = function $restoreModifiedPathsSnapshot(snapshot) {\n  this.$__.activePaths = snapshot.activePaths.clone();\n  this.$__.version = snapshot.version;\n  if (!this.$isSubdocument) {\n    const subdocs = this.$getAllSubdocs();\n    for (const child of subdocs) {\n      if (snapshot.subdocSnapshot.has(child)) {\n        child.$__.activePaths = snapshot.subdocSnapshot.get(child);\n      }\n    }\n  }\n\n  return this;\n};\n\n/**\n * Clear the document's modified paths.\n *\n * #### Example:\n *\n *     const doc = await TestModel.findOne();\n *\n *     doc.name = 'test';\n *     doc.$isModified('name'); // true\n *\n *     doc.$clearModifiedPaths();\n *     doc.name; // 'test', `$clearModifiedPaths()` does **not** modify the document's data, only change tracking\n *\n * @api public\n * @return {Document} this\n * @method $clearModifiedPaths\n * @memberOf Document\n * @instance\n */\n\nDocument.prototype.$clearModifiedPaths = function $clearModifiedPaths() {\n  this.$__.activePaths.clear('modify');\n  this.$__.activePaths.clear('init');\n  this.$__.version = 0;\n  if (!this.$isSubdocument) {\n    const subdocs = this.$getAllSubdocs();\n    for (const child of subdocs) {\n      child.$clearModifiedPaths();\n    }\n  }\n\n  return this;\n};\n\n/*!\n * Check if the given document only has primitive values\n */\n\nDocument.prototype.$__hasOnlyPrimitiveValues = function $__hasOnlyPrimitiveValues() {\n  return !this.$__.populated && !this.$__.wasPopulated && (this._doc == null || Object.values(this._doc).every(v => {\n    return v == null\n      || typeof v !== 'object'\n      || (utils.isNativeObject(v) && !Array.isArray(v))\n      || isBsonType(v, 'ObjectId')\n      || isBsonType(v, 'Decimal128');\n  }));\n};\n\n/*!\n * Module exports.\n */\n\nDocument.VERSION_WHERE = VERSION_WHERE;\nDocument.VERSION_INC = VERSION_INC;\nDocument.VERSION_ALL = VERSION_ALL;\nDocument.ValidationError = ValidationError;\nmodule.exports = exports = Document;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/document.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/documentProvider.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongoose/lib/documentProvider.js ***!
  \*******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/* eslint-env browser */\n\n/*!\n * Module dependencies.\n */\nconst Document = __webpack_require__(/*! ./document.js */ \"./node_modules/mongoose/lib/document.js\");\nconst BrowserDocument = __webpack_require__(/*! ./browserDocument.js */ \"./node_modules/mongoose/lib/browserDocument.js\");\n\nlet isBrowser = false;\n\n/**\n * Returns the Document constructor for the current context\n *\n * @api private\n */\nmodule.exports = function documentProvider() {\n  if (isBrowser) {\n    return BrowserDocument;\n  }\n  return Document;\n};\n\n/*!\n * ignore\n */\nmodule.exports.setBrowser = function(flag) {\n  isBrowser = flag;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/documentProvider.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/driver.js":
/*!*********************************************!*\
  !*** ./node_modules/mongoose/lib/driver.js ***!
  \*********************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/*!\n * ignore\n */\n\nlet driver = null;\n\nmodule.exports.get = function() {\n  return driver;\n};\n\nmodule.exports.set = function(v) {\n  driver = v;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/driver.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/drivers/node-mongodb-native/collection.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/mongoose/lib/drivers/node-mongodb-native/collection.js ***!
  \*****************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst MongooseCollection = __webpack_require__(/*! ../../collection */ \"./node_modules/mongoose/lib/collection.js\");\nconst MongooseError = __webpack_require__(/*! ../../error/mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\nconst Collection = (__webpack_require__(/*! mongodb */ \"./node_modules/mongodb/lib/index.js\").Collection);\nconst ObjectId = __webpack_require__(/*! ../../types/objectid */ \"./node_modules/mongoose/lib/types/objectid.js\");\nconst getConstructorName = __webpack_require__(/*! ../../helpers/getConstructorName */ \"./node_modules/mongoose/lib/helpers/getConstructorName.js\");\nconst internalToObjectOptions = (__webpack_require__(/*! ../../options */ \"./node_modules/mongoose/lib/options.js\").internalToObjectOptions);\nconst stream = __webpack_require__(/*! stream */ \"stream\");\nconst util = __webpack_require__(/*! util */ \"util\");\n\n/**\n * A [node-mongodb-native](https://github.com/mongodb/node-mongodb-native) collection implementation.\n *\n * All methods methods from the [node-mongodb-native](https://github.com/mongodb/node-mongodb-native) driver are copied and wrapped in queue management.\n *\n * @inherits Collection https://mongodb.github.io/node-mongodb-native/4.9/classes/Collection.html\n * @api private\n */\n\nfunction NativeCollection(name, conn, options) {\n  this.collection = null;\n  this.Promise = options.Promise || Promise;\n  this.modelName = options.modelName;\n  delete options.modelName;\n  this._closed = false;\n  MongooseCollection.apply(this, arguments);\n}\n\n/*!\n * Inherit from abstract Collection.\n */\n\nObject.setPrototypeOf(NativeCollection.prototype, MongooseCollection.prototype);\n\n/**\n * Called when the connection opens.\n *\n * @api private\n */\n\nNativeCollection.prototype.onOpen = function() {\n  this.collection = this.conn.db.collection(this.name);\n  MongooseCollection.prototype.onOpen.call(this);\n  return this.collection;\n};\n\n/**\n * Called when the connection closes\n *\n * @api private\n */\n\nNativeCollection.prototype.onClose = function(force) {\n  MongooseCollection.prototype.onClose.call(this, force);\n};\n\n/**\n * Helper to get the collection, in case `this.collection` isn't set yet.\n * May happen if `bufferCommands` is false and created the model when\n * Mongoose was disconnected.\n *\n * @api private\n */\n\nNativeCollection.prototype._getCollection = function _getCollection() {\n  if (this.collection) {\n    return this.collection;\n  }\n  if (this.conn.db != null) {\n    this.collection = this.conn.db.collection(this.name);\n    return this.collection;\n  }\n  return null;\n};\n\n/*!\n * ignore\n */\n\nconst syncCollectionMethods = { watch: true, find: true, aggregate: true };\n\n/**\n * Copy the collection methods and make them subject to queues\n * @param {Number|String} I\n * @api private\n */\n\nfunction iter(i) {\n  NativeCollection.prototype[i] = function() {\n    const collection = this._getCollection();\n    const args = Array.from(arguments);\n    const _this = this;\n    const globalDebug = _this &&\n      _this.conn &&\n      _this.conn.base &&\n      _this.conn.base.options &&\n      _this.conn.base.options.debug;\n    const connectionDebug = _this &&\n      _this.conn &&\n      _this.conn.options &&\n      _this.conn.options.debug;\n    const debug = connectionDebug == null ? globalDebug : connectionDebug;\n    const lastArg = arguments[arguments.length - 1];\n    const opId = new ObjectId();\n\n    // If user force closed, queueing will hang forever. See #5664\n    if (this.conn.$wasForceClosed) {\n      const error = new MongooseError('Connection was force closed');\n      if (args.length > 0 &&\n        typeof args[args.length - 1] === 'function') {\n        args[args.length - 1](error);\n        return;\n      } else {\n        throw error;\n      }\n    }\n\n    let _args = args;\n    let callback = null;\n    if (this._shouldBufferCommands() && this.buffer) {\n      this.conn.emit('buffer', {\n        _id: opId,\n        modelName: _this.modelName,\n        collectionName: _this.name,\n        method: i,\n        args: args\n      });\n\n      let callback;\n      let _args = args;\n      let promise = null;\n      let timeout = null;\n      if (syncCollectionMethods[i] && typeof lastArg === 'function') {\n        this.addQueue(i, _args);\n        callback = lastArg;\n      } else if (syncCollectionMethods[i]) {\n        promise = new this.Promise((resolve, reject) => {\n          callback = function collectionOperationCallback(err, res) {\n            if (timeout != null) {\n              clearTimeout(timeout);\n            }\n            if (err != null) {\n              return reject(err);\n            }\n            resolve(res);\n          };\n          _args = args.concat([callback]);\n          this.addQueue(i, _args);\n        });\n      } else if (typeof lastArg === 'function') {\n        callback = function collectionOperationCallback() {\n          if (timeout != null) {\n            clearTimeout(timeout);\n          }\n          return lastArg.apply(this, arguments);\n        };\n        _args = args.slice(0, args.length - 1).concat([callback]);\n      } else {\n        promise = new Promise((resolve, reject) => {\n          callback = function collectionOperationCallback(err, res) {\n            if (timeout != null) {\n              clearTimeout(timeout);\n            }\n            if (err != null) {\n              return reject(err);\n            }\n            resolve(res);\n          };\n          _args = args.concat([callback]);\n          this.addQueue(i, _args);\n        });\n      }\n\n      const bufferTimeoutMS = this._getBufferTimeoutMS();\n      timeout = setTimeout(() => {\n        const removed = this.removeQueue(i, _args);\n        if (removed) {\n          const message = 'Operation `' + this.name + '.' + i + '()` buffering timed out after ' +\n            bufferTimeoutMS + 'ms';\n          const err = new MongooseError(message);\n          this.conn.emit('buffer-end', { _id: opId, modelName: _this.modelName, collectionName: _this.name, method: i, error: err });\n          callback(err);\n        }\n      }, bufferTimeoutMS);\n\n      if (!syncCollectionMethods[i] && typeof lastArg === 'function') {\n        this.addQueue(i, _args);\n        return;\n      }\n\n      return promise;\n    } else if (!syncCollectionMethods[i] && typeof lastArg === 'function') {\n      callback = function collectionOperationCallback(err, res) {\n        if (err != null) {\n          _this.conn.emit('operation-end', { _id: opId, modelName: _this.modelName, collectionName: _this.name, method: i, error: err });\n        } else {\n          _this.conn.emit('operation-end', { _id: opId, modelName: _this.modelName, collectionName: _this.name, method: i, result: res });\n        }\n        return lastArg.apply(this, arguments);\n      };\n      _args = args.slice(0, args.length - 1).concat([callback]);\n    }\n\n    if (debug) {\n      if (typeof debug === 'function') {\n        let argsToAdd = null;\n        if (typeof args[args.length - 1] == 'function') {\n          argsToAdd = args.slice(0, args.length - 1);\n        } else {\n          argsToAdd = args;\n        }\n        debug.apply(_this,\n          [_this.name, i].concat(argsToAdd));\n      } else if (debug instanceof stream.Writable) {\n        this.$printToStream(_this.name, i, args, debug);\n      } else {\n        const color = debug.color == null ? true : debug.color;\n        const shell = debug.shell == null ? false : debug.shell;\n        this.$print(_this.name, i, args, color, shell);\n      }\n    }\n\n    this.conn.emit('operation-start', { _id: opId, modelName: _this.modelName, collectionName: this.name, method: i, params: _args });\n\n    try {\n      if (collection == null) {\n        const message = 'Cannot call `' + this.name + '.' + i + '()` before initial connection ' +\n          'is complete if `bufferCommands = false`. Make sure you `await mongoose.connect()` if ' +\n          'you have `bufferCommands = false`.';\n        throw new MongooseError(message);\n      }\n\n      if (syncCollectionMethods[i] && typeof lastArg === 'function') {\n        const result = collection[i].apply(collection, _args.slice(0, _args.length - 1));\n        this.conn.emit('operation-end', { _id: opId, modelName: _this.modelName, collectionName: this.name, method: i, result });\n        return lastArg.call(this, null, result);\n      }\n\n      const ret = collection[i].apply(collection, _args);\n      if (ret != null && typeof ret.then === 'function') {\n        return ret.then(\n          result => {\n            if (typeof lastArg === 'function') {\n              lastArg(null, result);\n            } else {\n              this.conn.emit('operation-end', { _id: opId, modelName: _this.modelName, collectionName: this.name, method: i, result });\n            }\n            return result;\n          },\n          error => {\n            if (typeof lastArg === 'function') {\n              lastArg(error);\n              return;\n            } else {\n              this.conn.emit('operation-end', { _id: opId, modelName: _this.modelName, collectionName: this.name, method: i, error });\n            }\n            throw error;\n          }\n        );\n      }\n      return ret;\n    } catch (error) {\n      // Collection operation may throw because of max bson size, catch it here\n      // See gh-3906\n      if (typeof lastArg === 'function') {\n        return lastArg(error);\n      } else {\n        this.conn.emit('operation-end', { _id: opId, modelName: _this.modelName, collectionName: this.name, method: i, error: error });\n\n        throw error;\n      }\n    }\n  };\n}\n\nfor (const key of Object.getOwnPropertyNames(Collection.prototype)) {\n  // Janky hack to work around gh-3005 until we can get rid of the mongoose\n  // collection abstraction\n  const descriptor = Object.getOwnPropertyDescriptor(Collection.prototype, key);\n  // Skip properties with getters because they may throw errors (gh-8528)\n  if (descriptor.get !== undefined) {\n    continue;\n  }\n  if (typeof Collection.prototype[key] !== 'function') {\n    continue;\n  }\n\n  iter(key);\n}\n\n/**\n * Debug print helper\n *\n * @api public\n * @method $print\n */\n\nNativeCollection.prototype.$print = function(name, i, args, color, shell) {\n  const moduleName = color ? '\\x1B[0;36mMongoose:\\x1B[0m ' : 'Mongoose: ';\n  const functionCall = [name, i].join('.');\n  const _args = [];\n  for (let j = args.length - 1; j >= 0; --j) {\n    if (this.$format(args[j]) || _args.length) {\n      _args.unshift(this.$format(args[j], color, shell));\n    }\n  }\n  const params = '(' + _args.join(', ') + ')';\n\n  console.info(moduleName + functionCall + params);\n};\n\n/**\n * Debug print helper\n *\n * @api public\n * @method $print\n */\n\nNativeCollection.prototype.$printToStream = function(name, i, args, stream) {\n  const functionCall = [name, i].join('.');\n  const _args = [];\n  for (let j = args.length - 1; j >= 0; --j) {\n    if (this.$format(args[j]) || _args.length) {\n      _args.unshift(this.$format(args[j]));\n    }\n  }\n  const params = '(' + _args.join(', ') + ')';\n\n  stream.write(functionCall + params, 'utf8');\n};\n\n/**\n * Formatter for debug print args\n *\n * @api public\n * @method $format\n */\n\nNativeCollection.prototype.$format = function(arg, color, shell) {\n  const type = typeof arg;\n  if (type === 'function' || type === 'undefined') return '';\n  return format(arg, false, color, shell);\n};\n\n/**\n * Debug print helper\n * @param {Any} representation\n * @api private\n */\n\nfunction inspectable(representation) {\n  const ret = {\n    inspect: function() { return representation; }\n  };\n  if (util.inspect.custom) {\n    ret[util.inspect.custom] = ret.inspect;\n  }\n  return ret;\n}\nfunction map(o) {\n  return format(o, true);\n}\nfunction formatObjectId(x, key) {\n  x[key] = inspectable('ObjectId(\"' + x[key].toHexString() + '\")');\n}\nfunction formatDate(x, key, shell) {\n  if (shell) {\n    x[key] = inspectable('ISODate(\"' + x[key].toUTCString() + '\")');\n  } else {\n    x[key] = inspectable('new Date(\"' + x[key].toUTCString() + '\")');\n  }\n}\nfunction format(obj, sub, color, shell) {\n  if (obj && typeof obj.toBSON === 'function') {\n    obj = obj.toBSON();\n  }\n  if (obj == null) {\n    return obj;\n  }\n\n  const clone = __webpack_require__(/*! ../../helpers/clone */ \"./node_modules/mongoose/lib/helpers/clone.js\");\n  let x = clone(obj, internalToObjectOptions);\n  const constructorName = getConstructorName(x);\n\n  if (constructorName === 'Binary') {\n    x = 'BinData(' + x.sub_type + ', \"' + x.toString('base64') + '\")';\n  } else if (constructorName === 'ObjectId') {\n    x = inspectable('ObjectId(\"' + x.toHexString() + '\")');\n  } else if (constructorName === 'Date') {\n    x = inspectable('new Date(\"' + x.toUTCString() + '\")');\n  } else if (constructorName === 'Object') {\n    const keys = Object.keys(x);\n    const numKeys = keys.length;\n    let key;\n    for (let i = 0; i < numKeys; ++i) {\n      key = keys[i];\n      if (x[key]) {\n        let error;\n        if (typeof x[key].toBSON === 'function') {\n          try {\n            // `session.toBSON()` throws an error. This means we throw errors\n            // in debug mode when using transactions, see gh-6712. As a\n            // workaround, catch `toBSON()` errors, try to serialize without\n            // `toBSON()`, and rethrow if serialization still fails.\n            x[key] = x[key].toBSON();\n          } catch (_error) {\n            error = _error;\n          }\n        }\n        const _constructorName = getConstructorName(x[key]);\n        if (_constructorName === 'Binary') {\n          x[key] = 'BinData(' + x[key].sub_type + ', \"' +\n            x[key].buffer.toString('base64') + '\")';\n        } else if (_constructorName === 'Object') {\n          x[key] = format(x[key], true);\n        } else if (_constructorName === 'ObjectId') {\n          formatObjectId(x, key);\n        } else if (_constructorName === 'Date') {\n          formatDate(x, key, shell);\n        } else if (_constructorName === 'ClientSession') {\n          x[key] = inspectable('ClientSession(\"' +\n            (\n              x[key] &&\n              x[key].id &&\n              x[key].id.id &&\n              x[key].id.id.buffer || ''\n            ).toString('hex') + '\")');\n        } else if (Array.isArray(x[key])) {\n          x[key] = x[key].map(map);\n        } else if (error != null) {\n          // If there was an error with `toBSON()` and the object wasn't\n          // already converted to a string representation, rethrow it.\n          // Open to better ideas on how to handle this.\n          throw error;\n        }\n      }\n    }\n  }\n  if (sub) {\n    return x;\n  }\n\n  return util.\n    inspect(x, false, 10, color).\n    replace(/\\n/g, '').\n    replace(/\\s{2,}/g, ' ');\n}\n\n/**\n * Retrieves information about this collections indexes.\n *\n * @param {Function} callback\n * @method getIndexes\n * @api public\n */\n\nNativeCollection.prototype.getIndexes = NativeCollection.prototype.indexInformation;\n\n/*!\n * Module exports.\n */\n\nmodule.exports = NativeCollection;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/drivers/node-mongodb-native/collection.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/drivers/node-mongodb-native/connection.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/mongoose/lib/drivers/node-mongodb-native/connection.js ***!
  \*****************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module dependencies.\n */\n\n\n\nconst MongooseConnection = __webpack_require__(/*! ../../connection */ \"./node_modules/mongoose/lib/connection.js\");\nconst MongooseError = __webpack_require__(/*! ../../error/index */ \"./node_modules/mongoose/lib/error/index.js\");\nconst STATES = __webpack_require__(/*! ../../connectionState */ \"./node_modules/mongoose/lib/connectionState.js\");\nconst mongodb = __webpack_require__(/*! mongodb */ \"./node_modules/mongodb/lib/index.js\");\nconst pkg = __webpack_require__(/*! ../../../package.json */ \"./node_modules/mongoose/package.json\");\nconst processConnectionOptions = __webpack_require__(/*! ../../helpers/processConnectionOptions */ \"./node_modules/mongoose/lib/helpers/processConnectionOptions.js\");\nconst setTimeout = (__webpack_require__(/*! ../../helpers/timers */ \"./node_modules/mongoose/lib/helpers/timers.js\").setTimeout);\nconst utils = __webpack_require__(/*! ../../utils */ \"./node_modules/mongoose/lib/utils.js\");\n\n/**\n * A [node-mongodb-native](https://github.com/mongodb/node-mongodb-native) connection implementation.\n *\n * @inherits Connection\n * @api private\n */\n\nfunction NativeConnection() {\n  MongooseConnection.apply(this, arguments);\n  this._listening = false;\n}\n\n/**\n * Expose the possible connection states.\n * @api public\n */\n\nNativeConnection.STATES = STATES;\n\n/*!\n * Inherits from Connection.\n */\n\nObject.setPrototypeOf(NativeConnection.prototype, MongooseConnection.prototype);\n\n/**\n * Switches to a different database using the same connection pool.\n *\n * Returns a new connection object, with the new db. If you set the `useCache`\n * option, `useDb()` will cache connections by `name`.\n *\n * **Note:** Calling `close()` on a `useDb()` connection will close the base connection as well.\n *\n * @param {String} name The database name\n * @param {Object} [options]\n * @param {Boolean} [options.useCache=false] If true, cache results so calling `useDb()` multiple times with the same name only creates 1 connection object.\n * @param {Boolean} [options.noListener=false] If true, the new connection object won't listen to any events on the base connection. This is better for memory usage in cases where you're calling `useDb()` for every request.\n * @return {Connection} New Connection Object\n * @api public\n */\n\nNativeConnection.prototype.useDb = function(name, options) {\n  // Return immediately if cached\n  options = options || {};\n  if (options.useCache && this.relatedDbs[name]) {\n    return this.relatedDbs[name];\n  }\n\n  // we have to manually copy all of the attributes...\n  const newConn = new this.constructor();\n  newConn.name = name;\n  newConn.base = this.base;\n  newConn.collections = {};\n  newConn.models = {};\n  newConn.replica = this.replica;\n  newConn.config = Object.assign({}, this.config, newConn.config);\n  newConn.name = this.name;\n  newConn.options = this.options;\n  newConn._readyState = this._readyState;\n  newConn._closeCalled = this._closeCalled;\n  newConn._hasOpened = this._hasOpened;\n  newConn._listening = false;\n  newConn._parent = this;\n\n  newConn.host = this.host;\n  newConn.port = this.port;\n  newConn.user = this.user;\n  newConn.pass = this.pass;\n\n  // First, when we create another db object, we are not guaranteed to have a\n  // db object to work with. So, in the case where we have a db object and it\n  // is connected, we can just proceed with setting everything up. However, if\n  // we do not have a db or the state is not connected, then we need to wait on\n  // the 'open' event of the connection before doing the rest of the setup\n  // the 'connected' event is the first time we'll have access to the db object\n\n  const _this = this;\n\n  newConn.client = _this.client;\n\n  if (this.db && this._readyState === STATES.connected) {\n    wireup();\n  } else {\n    this.once('connected', wireup);\n  }\n\n  function wireup() {\n    newConn.client = _this.client;\n    const _opts = {};\n    if (options.hasOwnProperty('noListener')) {\n      _opts.noListener = options.noListener;\n    }\n    newConn.db = _this.client.db(name, _opts);\n    newConn.onOpen();\n  }\n\n  newConn.name = name;\n\n  // push onto the otherDbs stack, this is used when state changes\n  if (options.noListener !== true) {\n    this.otherDbs.push(newConn);\n  }\n  newConn.otherDbs.push(this);\n\n  // push onto the relatedDbs cache, this is used when state changes\n  if (options && options.useCache) {\n    this.relatedDbs[newConn.name] = newConn;\n    newConn.relatedDbs = this.relatedDbs;\n  }\n\n  return newConn;\n};\n\n/**\n * Removes the database connection with the given name created with `useDb()`.\n *\n * Throws an error if the database connection was not found.\n *\n * #### Example:\n *\n *     // Connect to `initialdb` first\n *     const conn = await mongoose.createConnection('mongodb://127.0.0.1:27017/initialdb').asPromise();\n *\n *     // Creates an un-cached connection to `mydb`\n *     const db = conn.useDb('mydb');\n *\n *     // Closes `db`, and removes `db` from `conn.relatedDbs` and `conn.otherDbs`\n *     await conn.removeDb('mydb');\n *\n * @method removeDb\n * @memberOf Connection\n * @param {String} name The database name\n * @return {Connection} this\n */\n\nNativeConnection.prototype.removeDb = function removeDb(name) {\n  const dbs = this.otherDbs.filter(db => db.name === name);\n  if (!dbs.length) {\n    throw new MongooseError(`No connections to database \"${name}\" found`);\n  }\n\n  for (const db of dbs) {\n    db._closeCalled = true;\n    db._destroyCalled = true;\n    db._readyState = STATES.disconnected;\n    db.$wasForceClosed = true;\n  }\n  delete this.relatedDbs[name];\n  this.otherDbs = this.otherDbs.filter(db => db.name !== name);\n};\n\n/**\n * Closes the connection\n *\n * @param {Boolean} [force]\n * @return {Connection} this\n * @api private\n */\n\nNativeConnection.prototype.doClose = async function doClose(force) {\n  if (this.client == null) {\n    return this;\n  }\n\n  let skipCloseClient = false;\n  if (force != null && typeof force === 'object') {\n    skipCloseClient = force.skipCloseClient;\n    force = force.force;\n  }\n\n  if (skipCloseClient) {\n    return this;\n  }\n\n  await this.client.close(force);\n  // Defer because the driver will wait at least 1ms before finishing closing\n  // the pool, see https://github.com/mongodb-js/mongodb-core/blob/a8f8e4ce41936babc3b9112bf42d609779f03b39/lib/connection/pool.js#L1026-L1030.\n  // If there's queued operations, you may still get some background work\n  // after the callback is called.\n  await new Promise(resolve => setTimeout(resolve, 1));\n\n  return this;\n};\n\n/**\n * Implementation of `listDatabases()` for MongoDB driver\n *\n * @return Promise\n * @api public\n */\n\nNativeConnection.prototype.listDatabases = async function listDatabases() {\n  await this._waitForConnect();\n\n  return await this.db.admin().listDatabases();\n};\n\n/*!\n * ignore\n */\n\nNativeConnection.prototype.createClient = async function createClient(uri, options) {\n  if (typeof uri !== 'string') {\n    throw new MongooseError('The `uri` parameter to `openUri()` must be a ' +\n      `string, got \"${typeof uri}\". Make sure the first parameter to ` +\n      '`mongoose.connect()` or `mongoose.createConnection()` is a string.');\n  }\n\n  if (this._destroyCalled) {\n    throw new MongooseError(\n      'Connection has been closed and destroyed, and cannot be used for re-opening the connection. ' +\n      'Please create a new connection with `mongoose.createConnection()` or `mongoose.connect()`.'\n    );\n  }\n\n  if (this.readyState === STATES.connecting || this.readyState === STATES.connected) {\n    if (this._connectionString !== uri) {\n      throw new MongooseError('Can\\'t call `openUri()` on an active connection with ' +\n        'different connection strings. Make sure you aren\\'t calling `mongoose.connect()` ' +\n        'multiple times. See: https://mongoosejs.com/docs/connections.html#multiple_connections');\n    }\n  }\n\n  options = processConnectionOptions(uri, options);\n\n  if (options) {\n\n    const autoIndex = options.config && options.config.autoIndex != null ?\n      options.config.autoIndex :\n      options.autoIndex;\n    if (autoIndex != null) {\n      this.config.autoIndex = autoIndex !== false;\n      delete options.config;\n      delete options.autoIndex;\n    }\n\n    if ('autoCreate' in options) {\n      this.config.autoCreate = !!options.autoCreate;\n      delete options.autoCreate;\n    }\n\n    if ('sanitizeFilter' in options) {\n      this.config.sanitizeFilter = options.sanitizeFilter;\n      delete options.sanitizeFilter;\n    }\n\n    if ('autoSearchIndex' in options) {\n      this.config.autoSearchIndex = options.autoSearchIndex;\n      delete options.autoSearchIndex;\n    }\n\n    // Backwards compat\n    if (options.user || options.pass) {\n      options.auth = options.auth || {};\n      options.auth.username = options.user;\n      options.auth.password = options.pass;\n\n      this.user = options.user;\n      this.pass = options.pass;\n    }\n    delete options.user;\n    delete options.pass;\n\n    if (options.bufferCommands != null) {\n      this.config.bufferCommands = options.bufferCommands;\n      delete options.bufferCommands;\n    }\n  } else {\n    options = {};\n  }\n\n  this._connectionOptions = options;\n  const dbName = options.dbName;\n  if (dbName != null) {\n    this.$dbName = dbName;\n  }\n  delete options.dbName;\n\n  if (!utils.hasUserDefinedProperty(options, 'driverInfo')) {\n    options.driverInfo = {\n      name: 'Mongoose',\n      version: pkg.version\n    };\n  }\n\n  this.readyState = STATES.connecting;\n  this._connectionString = uri;\n\n  let client;\n  try {\n    client = new mongodb.MongoClient(uri, options);\n  } catch (error) {\n    this.readyState = STATES.disconnected;\n    throw error;\n  }\n  this.client = client;\n\n  client.setMaxListeners(0);\n  await client.connect();\n\n  _setClient(this, client, options, dbName);\n\n  for (const db of this.otherDbs) {\n    _setClient(db, client, {}, db.name);\n  }\n  return this;\n};\n\n/*!\n * ignore\n */\n\nNativeConnection.prototype.setClient = function setClient(client) {\n  if (!(client instanceof mongodb.MongoClient)) {\n    throw new MongooseError('Must call `setClient()` with an instance of MongoClient');\n  }\n  if (this.readyState !== STATES.disconnected) {\n    throw new MongooseError('Cannot call `setClient()` on a connection that is already connected.');\n  }\n  if (client.topology == null) {\n    throw new MongooseError('Cannot call `setClient()` with a MongoClient that you have not called `connect()` on yet.');\n  }\n\n  this._connectionString = client.s.url;\n  _setClient(this, client, {}, client.s.options.dbName);\n\n  for (const model of Object.values(this.models)) {\n    // Errors handled internally, so safe to ignore error\n    model.init().catch(function $modelInitNoop() {});\n  }\n\n  return this;\n};\n\n/*!\n * ignore\n */\n\nfunction _setClient(conn, client, options, dbName) {\n  const db = dbName != null ? client.db(dbName) : client.db();\n  conn.db = db;\n  conn.client = client;\n  conn.host = client &&\n    client.s &&\n    client.s.options &&\n    client.s.options.hosts &&\n    client.s.options.hosts[0] &&\n    client.s.options.hosts[0].host || void 0;\n  conn.port = client &&\n    client.s &&\n    client.s.options &&\n    client.s.options.hosts &&\n    client.s.options.hosts[0] &&\n    client.s.options.hosts[0].port || void 0;\n  conn.name = dbName != null ? dbName : db.databaseName;\n  conn._closeCalled = client._closeCalled;\n\n  const _handleReconnect = () => {\n    // If we aren't disconnected, we assume this reconnect is due to a\n    // socket timeout. If there's no activity on a socket for\n    // `socketTimeoutMS`, the driver will attempt to reconnect and emit\n    // this event.\n    if (conn.readyState !== STATES.connected) {\n      conn.readyState = STATES.connected;\n      conn.emit('reconnect');\n      conn.emit('reconnected');\n      conn.onOpen();\n    }\n  };\n\n  const type = client &&\n  client.topology &&\n  client.topology.description &&\n  client.topology.description.type || '';\n\n  if (type === 'Single') {\n    client.on('serverDescriptionChanged', ev => {\n      const newDescription = ev.newDescription;\n      if (newDescription.type === 'Unknown') {\n        conn.readyState = STATES.disconnected;\n      } else {\n        _handleReconnect();\n      }\n    });\n  } else if (type.startsWith('ReplicaSet')) {\n    client.on('topologyDescriptionChanged', ev => {\n      // Emit disconnected if we've lost connectivity to the primary\n      const description = ev.newDescription;\n      if (conn.readyState === STATES.connected && description.type !== 'ReplicaSetWithPrimary') {\n        // Implicitly emits 'disconnected'\n        conn.readyState = STATES.disconnected;\n      } else if (conn.readyState === STATES.disconnected && description.type === 'ReplicaSetWithPrimary') {\n        _handleReconnect();\n      }\n    });\n  }\n\n  if (options.monitorCommands) {\n    client.on('commandStarted', (data) => conn.emit('commandStarted', data));\n    client.on('commandFailed', (data) => conn.emit('commandFailed', data));\n    client.on('commandSucceeded', (data) => conn.emit('commandSucceeded', data));\n  }\n\n  conn.onOpen();\n\n  for (const i in conn.collections) {\n    if (utils.object.hasOwnProperty(conn.collections, i)) {\n      conn.collections[i].onOpen();\n    }\n  }\n}\n\n\n/*!\n * Module exports.\n */\n\nmodule.exports = NativeConnection;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/drivers/node-mongodb-native/connection.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/drivers/node-mongodb-native/index.js":
/*!************************************************************************!*\
  !*** ./node_modules/mongoose/lib/drivers/node-mongodb-native/index.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module exports.\n */\n\n\n\nexports.Collection = __webpack_require__(/*! ./collection */ \"./node_modules/mongoose/lib/drivers/node-mongodb-native/collection.js\");\nexports.Connection = __webpack_require__(/*! ./connection */ \"./node_modules/mongoose/lib/drivers/node-mongodb-native/connection.js\");\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/drivers/node-mongodb-native/index.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/error/bulkWriteError.js":
/*!***********************************************************!*\
  !*** ./node_modules/mongoose/lib/error/bulkWriteError.js ***!
  \***********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module dependencies.\n */\n\n\n\nconst MongooseError = __webpack_require__(/*! ./ */ \"./node_modules/mongoose/lib/error/index.js\");\n\n\n/**\n * If `bulkWrite()` or `insertMany()` has validation errors, but\n * all valid operations succeed, and 'throwOnValidationError' is true,\n * Mongoose will throw this error.\n *\n * @api private\n */\n\nclass MongooseBulkWriteError extends MongooseError {\n  constructor(validationErrors, results, rawResult, operation) {\n    let preview = validationErrors.map(e => e.message).join(', ');\n    if (preview.length > 200) {\n      preview = preview.slice(0, 200) + '...';\n    }\n    super(`${operation} failed with ${validationErrors.length} Mongoose validation errors: ${preview}`);\n\n    this.validationErrors = validationErrors;\n    this.results = results;\n    this.rawResult = rawResult;\n    this.operation = operation;\n  }\n}\n\nObject.defineProperty(MongooseBulkWriteError.prototype, 'name', {\n  value: 'MongooseBulkWriteError'\n});\n\n/*!\n * exports\n */\n\nmodule.exports = MongooseBulkWriteError;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/error/bulkWriteError.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/error/cast.js":
/*!*************************************************!*\
  !*** ./node_modules/mongoose/lib/error/cast.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst MongooseError = __webpack_require__(/*! ./mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\nconst util = __webpack_require__(/*! util */ \"util\");\n\n/**\n * Casting Error constructor.\n *\n * @param {String} type\n * @param {String} value\n * @inherits MongooseError\n * @api private\n */\n\nclass CastError extends MongooseError {\n  constructor(type, value, path, reason, schemaType) {\n    // If no args, assume we'll `init()` later.\n    if (arguments.length > 0) {\n      const valueType = getValueType(value);\n      const messageFormat = getMessageFormat(schemaType);\n      const msg = formatMessage(null, type, value, path, messageFormat, valueType, reason);\n      super(msg);\n      this.init(type, value, path, reason, schemaType);\n    } else {\n      super(formatMessage());\n    }\n  }\n\n  toJSON() {\n    return {\n      stringValue: this.stringValue,\n      valueType: this.valueType,\n      kind: this.kind,\n      value: this.value,\n      path: this.path,\n      reason: this.reason,\n      name: this.name,\n      message: this.message\n    };\n  }\n  /*!\n   * ignore\n   */\n  init(type, value, path, reason, schemaType) {\n    this.stringValue = getStringValue(value);\n    this.messageFormat = getMessageFormat(schemaType);\n    this.kind = type;\n    this.value = value;\n    this.path = path;\n    this.reason = reason;\n    this.valueType = getValueType(value);\n  }\n\n  /**\n   * ignore\n   * @param {Readonly<CastError>} other\n   * @api private\n   */\n  copy(other) {\n    this.messageFormat = other.messageFormat;\n    this.stringValue = other.stringValue;\n    this.kind = other.kind;\n    this.value = other.value;\n    this.path = other.path;\n    this.reason = other.reason;\n    this.message = other.message;\n    this.valueType = other.valueType;\n  }\n\n  /*!\n   * ignore\n   */\n  setModel(model) {\n    this.message = formatMessage(model, this.kind, this.value, this.path,\n      this.messageFormat, this.valueType);\n  }\n}\n\nObject.defineProperty(CastError.prototype, 'name', {\n  value: 'CastError'\n});\n\nfunction getStringValue(value) {\n  let stringValue = util.inspect(value);\n  stringValue = stringValue.replace(/^'|'$/g, '\"');\n  if (!stringValue.startsWith('\"')) {\n    stringValue = '\"' + stringValue + '\"';\n  }\n  return stringValue;\n}\n\nfunction getValueType(value) {\n  if (value == null) {\n    return '' + value;\n  }\n\n  const t = typeof value;\n  if (t !== 'object') {\n    return t;\n  }\n  if (typeof value.constructor !== 'function') {\n    return t;\n  }\n  return value.constructor.name;\n}\n\nfunction getMessageFormat(schemaType) {\n  const messageFormat = schemaType && schemaType._castErrorMessage || null;\n  if (typeof messageFormat === 'string' || typeof messageFormat === 'function') {\n    return messageFormat;\n  }\n}\n\n/*!\n * ignore\n */\n\nfunction formatMessage(model, kind, value, path, messageFormat, valueType, reason) {\n  if (typeof messageFormat === 'string') {\n    const stringValue = getStringValue(value);\n    let ret = messageFormat.\n      replace('{KIND}', kind).\n      replace('{VALUE}', stringValue).\n      replace('{PATH}', path);\n    if (model != null) {\n      ret = ret.replace('{MODEL}', model.modelName);\n    }\n\n    return ret;\n  } else if (typeof messageFormat === 'function') {\n    return messageFormat(value, path, model, kind);\n  } else {\n    const stringValue = getStringValue(value);\n    const valueTypeMsg = valueType ? ' (type ' + valueType + ')' : '';\n    let ret = 'Cast to ' + kind + ' failed for value ' +\n      stringValue + valueTypeMsg + ' at path \"' + path + '\"';\n    if (model != null) {\n      ret += ' for model \"' + model.modelName + '\"';\n    }\n    if (reason != null &&\n        typeof reason.constructor === 'function' &&\n        reason.constructor.name !== 'AssertionError' &&\n        reason.constructor.name !== 'Error') {\n      ret += ' because of \"' + reason.constructor.name + '\"';\n    }\n    return ret;\n  }\n}\n\n/*!\n * exports\n */\n\nmodule.exports = CastError;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/error/cast.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/error/createCollectionsError.js":
/*!*******************************************************************!*\
  !*** ./node_modules/mongoose/lib/error/createCollectionsError.js ***!
  \*******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst MongooseError = __webpack_require__(/*! ./mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\n\n/**\n * createCollections Error constructor\n *\n * @param {String} message\n * @param {String} errorsMap\n * @inherits MongooseError\n * @api private\n */\n\nclass CreateCollectionsError extends MongooseError {\n  constructor(message, errorsMap) {\n    super(message);\n    this.errors = errorsMap;\n  }\n}\n\nObject.defineProperty(CreateCollectionsError.prototype, 'name', {\n  value: 'CreateCollectionsError'\n});\n\nmodule.exports = CreateCollectionsError;\n\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/error/createCollectionsError.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/error/divergentArray.js":
/*!***********************************************************!*\
  !*** ./node_modules/mongoose/lib/error/divergentArray.js ***!
  \***********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n/*!\n * Module dependencies.\n */\n\n\n\nconst MongooseError = __webpack_require__(/*! ./mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\n\nclass DivergentArrayError extends MongooseError {\n  /**\n   * DivergentArrayError constructor.\n   * @param {Array<String>} paths\n   * @api private\n   */\n  constructor(paths) {\n    const msg = 'For your own good, using `document.save()` to update an array '\n            + 'which was selected using an $elemMatch projection OR '\n            + 'populated using skip, limit, query conditions, or exclusion of '\n            + 'the _id field when the operation results in a $pop or $set of '\n            + 'the entire array is not supported. The following '\n            + 'path(s) would have been modified unsafely:\\n'\n            + '  ' + paths.join('\\n  ') + '\\n'\n            + 'Use Model.updateOne() to update these arrays instead.';\n    // TODO write up a docs page (FAQ) and link to it\n    super(msg);\n  }\n}\n\nObject.defineProperty(DivergentArrayError.prototype, 'name', {\n  value: 'DivergentArrayError'\n});\n\n/*!\n * exports\n */\n\nmodule.exports = DivergentArrayError;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/error/divergentArray.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/error/eachAsyncMultiError.js":
/*!****************************************************************!*\
  !*** ./node_modules/mongoose/lib/error/eachAsyncMultiError.js ***!
  \****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module dependencies.\n */\n\n\n\nconst MongooseError = __webpack_require__(/*! ./mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\n\n\n/**\n * If `eachAsync()` is called with `continueOnError: true`, there can be\n * multiple errors. This error class contains an `errors` property, which\n * contains an array of all errors that occurred in `eachAsync()`.\n *\n * @api private\n */\n\nclass EachAsyncMultiError extends MongooseError {\n  /**\n   * @param {String} connectionString\n   */\n  constructor(errors) {\n    let preview = errors.map(e => e.message).join(', ');\n    if (preview.length > 50) {\n      preview = preview.slice(0, 50) + '...';\n    }\n    super(`eachAsync() finished with ${errors.length} errors: ${preview}`);\n\n    this.errors = errors;\n  }\n}\n\nObject.defineProperty(EachAsyncMultiError.prototype, 'name', {\n  value: 'EachAsyncMultiError'\n});\n\n/*!\n * exports\n */\n\nmodule.exports = EachAsyncMultiError;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/error/eachAsyncMultiError.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/error/index.js":
/*!**************************************************!*\
  !*** ./node_modules/mongoose/lib/error/index.js ***!
  \**************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\n/**\n * MongooseError constructor. MongooseError is the base class for all\n * Mongoose-specific errors.\n *\n * #### Example:\n *\n *     const Model = mongoose.model('Test', new mongoose.Schema({ answer: Number }));\n *     const doc = new Model({ answer: 'not a number' });\n *     const err = doc.validateSync();\n *\n *     err instanceof mongoose.Error.ValidationError; // true\n *\n * @constructor Error\n * @param {String} msg Error message\n * @inherits Error https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/Error\n */\n\nconst MongooseError = __webpack_require__(/*! ./mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\n\n/**\n * The name of the error. The name uniquely identifies this Mongoose error. The\n * possible values are:\n *\n * - `MongooseError`: general Mongoose error\n * - `CastError`: Mongoose could not convert a value to the type defined in the schema path. May be in a `ValidationError` class' `errors` property.\n * - `DivergentArrayError`: You attempted to `save()` an array that was modified after you loaded it with a `$elemMatch` or similar projection\n * - `MissingSchemaError`: You tried to access a model with [`mongoose.model()`](https://mongoosejs.com/docs/api/mongoose.html#Mongoose.model()) that was not defined\n * - `DocumentNotFoundError`: The document you tried to [`save()`](https://mongoosejs.com/docs/api/document.html#Document.prototype.save()) was not found\n * - `ValidatorError`: error from an individual schema path's validator\n * - `ValidationError`: error returned from [`validate()`](https://mongoosejs.com/docs/api/document.html#Document.prototype.validate()) or [`validateSync()`](https://mongoosejs.com/docs/api/document.html#Document.prototype.validateSync()). Contains zero or more `ValidatorError` instances in `.errors` property.\n * - `MissingSchemaError`: You called `mongoose.Document()` without a schema\n * - `ObjectExpectedError`: Thrown when you set a nested path to a non-object value with [strict mode set](https://mongoosejs.com/docs/guide.html#strict).\n * - `ObjectParameterError`: Thrown when you pass a non-object value to a function which expects an object as a paramter\n * - `OverwriteModelError`: Thrown when you call [`mongoose.model()`](https://mongoosejs.com/docs/api/mongoose.html#Mongoose.model()) to re-define a model that was already defined.\n * - `ParallelSaveError`: Thrown when you call [`save()`](https://mongoosejs.com/docs/api/model.html#Model.prototype.save()) on a document when the same document instance is already saving.\n * - `StrictModeError`: Thrown when you set a path that isn't the schema and [strict mode](https://mongoosejs.com/docs/guide.html#strict) is set to `throw`.\n * - `VersionError`: Thrown when the [document is out of sync](https://mongoosejs.com/docs/guide.html#versionKey)\n *\n * @api public\n * @property {String} name\n * @memberOf Error\n * @instance\n */\n\n/*!\n * Module exports.\n */\n\nmodule.exports = exports = MongooseError;\n\n/**\n * The default built-in validator error messages.\n *\n * @see Error.messages https://mongoosejs.com/docs/api/error.html#Error.messages\n * @api public\n * @memberOf Error\n * @static\n */\n\nMongooseError.messages = __webpack_require__(/*! ./messages */ \"./node_modules/mongoose/lib/error/messages.js\");\n\n// backward compat\nMongooseError.Messages = MongooseError.messages;\n\n/**\n * An instance of this error class will be returned when `save()` fails\n * because the underlying\n * document was not found. The constructor takes one parameter, the\n * conditions that mongoose passed to `updateOne()` when trying to update\n * the document.\n *\n * @api public\n * @memberOf Error\n * @static\n */\n\nMongooseError.DocumentNotFoundError = __webpack_require__(/*! ./notFound */ \"./node_modules/mongoose/lib/error/notFound.js\");\n\n/**\n * An instance of this error class will be returned when mongoose failed to\n * cast a value.\n *\n * @api public\n * @memberOf Error\n * @static\n */\n\nMongooseError.CastError = __webpack_require__(/*! ./cast */ \"./node_modules/mongoose/lib/error/cast.js\");\n\n/**\n * An instance of this error class will be returned when [validation](https://mongoosejs.com/docs/validation.html) failed.\n * The `errors` property contains an object whose keys are the paths that failed and whose values are\n * instances of CastError or ValidationError.\n *\n * @api public\n * @memberOf Error\n * @static\n */\n\nMongooseError.ValidationError = __webpack_require__(/*! ./validation */ \"./node_modules/mongoose/lib/error/validation.js\");\n\n/**\n * A `ValidationError` has a hash of `errors` that contain individual\n * `ValidatorError` instances.\n *\n * #### Example:\n *\n *     const schema = Schema({ name: { type: String, required: true } });\n *     const Model = mongoose.model('Test', schema);\n *     const doc = new Model({});\n *\n *     // Top-level error is a ValidationError, **not** a ValidatorError\n *     const err = doc.validateSync();\n *     err instanceof mongoose.Error.ValidationError; // true\n *\n *     // A ValidationError `err` has 0 or more ValidatorErrors keyed by the\n *     // path in the `err.errors` property.\n *     err.errors['name'] instanceof mongoose.Error.ValidatorError;\n *\n *     err.errors['name'].kind; // 'required'\n *     err.errors['name'].path; // 'name'\n *     err.errors['name'].value; // undefined\n *\n * Instances of `ValidatorError` have the following properties:\n *\n * - `kind`: The validator's `type`, like `'required'` or `'regexp'`\n * - `path`: The path that failed validation\n * - `value`: The value that failed validation\n *\n * @api public\n * @memberOf Error\n * @static\n */\n\nMongooseError.ValidatorError = __webpack_require__(/*! ./validator */ \"./node_modules/mongoose/lib/error/validator.js\");\n\n/**\n * An instance of this error class will be returned when you call `save()` after\n * the document in the database was changed in a potentially unsafe way. See\n * the [`versionKey` option](https://mongoosejs.com/docs/guide.html#versionKey) for more information.\n *\n * @api public\n * @memberOf Error\n * @static\n */\n\nMongooseError.VersionError = __webpack_require__(/*! ./version */ \"./node_modules/mongoose/lib/error/version.js\");\n\n/**\n * An instance of this error class will be returned when you call `save()` multiple\n * times on the same document in parallel. See the [FAQ](https://mongoosejs.com/docs/faq.html) for more\n * information.\n *\n * @api public\n * @memberOf Error\n * @static\n */\n\nMongooseError.ParallelSaveError = __webpack_require__(/*! ./parallelSave */ \"./node_modules/mongoose/lib/error/parallelSave.js\");\n\n/**\n * Thrown when a model with the given name was already registered on the connection.\n * See [the FAQ about `OverwriteModelError`](https://mongoosejs.com/docs/faq.html#overwrite-model-error).\n *\n * @api public\n * @memberOf Error\n * @static\n */\n\nMongooseError.OverwriteModelError = __webpack_require__(/*! ./overwriteModel */ \"./node_modules/mongoose/lib/error/overwriteModel.js\");\n\n/**\n * Thrown when you try to access a model that has not been registered yet\n *\n * @api public\n * @memberOf Error\n * @static\n */\n\nMongooseError.MissingSchemaError = __webpack_require__(/*! ./missingSchema */ \"./node_modules/mongoose/lib/error/missingSchema.js\");\n\n/**\n * Thrown when the MongoDB Node driver can't connect to a valid server\n * to send an operation to.\n *\n * @api public\n * @memberOf Error\n * @static\n */\n\nMongooseError.MongooseServerSelectionError = __webpack_require__(/*! ./serverSelection */ \"./node_modules/mongoose/lib/error/serverSelection.js\");\n\n/**\n * An instance of this error will be returned if you used an array projection\n * and then modified the array in an unsafe way.\n *\n * @api public\n * @memberOf Error\n * @static\n */\n\nMongooseError.DivergentArrayError = __webpack_require__(/*! ./divergentArray */ \"./node_modules/mongoose/lib/error/divergentArray.js\");\n\n/**\n * Thrown when your try to pass values to model constructor that\n * were not specified in schema or change immutable properties when\n * `strict` mode is `\"throw\"`\n *\n * @api public\n * @memberOf Error\n * @static\n */\n\nMongooseError.StrictModeError = __webpack_require__(/*! ./strict */ \"./node_modules/mongoose/lib/error/strict.js\");\n\n/**\n * An instance of this error class will be returned when mongoose failed to\n * populate with a path that is not existing.\n *\n * @api public\n * @memberOf Error\n * @static\n */\n\nMongooseError.StrictPopulateError = __webpack_require__(/*! ./strictPopulate */ \"./node_modules/mongoose/lib/error/strictPopulate.js\");\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/error/index.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/error/invalidSchemaOption.js":
/*!****************************************************************!*\
  !*** ./node_modules/mongoose/lib/error/invalidSchemaOption.js ***!
  \****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n/*!\n * Module dependencies.\n */\n\n\n\nconst MongooseError = __webpack_require__(/*! ./mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\n\nclass InvalidSchemaOptionError extends MongooseError {\n  /**\n   * InvalidSchemaOption Error constructor.\n   * @param {String} name\n   * @api private\n   */\n  constructor(name, option) {\n    const msg = `Cannot create use schema for property \"${name}\" because the schema has the ${option} option enabled.`;\n    super(msg);\n  }\n}\n\nObject.defineProperty(InvalidSchemaOptionError.prototype, 'name', {\n  value: 'InvalidSchemaOptionError'\n});\n\n/*!\n * exports\n */\n\nmodule.exports = InvalidSchemaOptionError;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/error/invalidSchemaOption.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/error/messages.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongoose/lib/error/messages.js ***!
  \*****************************************************/
/***/ ((module, exports) => {

"use strict";
eval("\n/**\n * The default built-in validator error messages. These may be customized.\n *\n *     // customize within each schema or globally like so\n *     const mongoose = require('mongoose');\n *     mongoose.Error.messages.String.enum  = \"Your custom message for {PATH}.\";\n *\n * Error messages support basic templating. Mongoose will replace the following strings with the corresponding value.\n *\n * - `{PATH}` is replaced with the invalid document path\n * - `{VALUE}` is replaced with the invalid value\n * - `{TYPE}` is replaced with the validator type such as \"regexp\", \"min\", or \"user defined\"\n * - `{MIN}` is replaced with the declared min value for the Number.min validator\n * - `{MAX}` is replaced with the declared max value for the Number.max validator\n *\n * Click the \"show code\" link below to see all defaults.\n *\n * @static\n * @memberOf MongooseError\n * @api public\n */\n\n\n\nconst msg = module.exports = exports = {};\n\nmsg.DocumentNotFoundError = null;\n\nmsg.general = {};\nmsg.general.default = 'Validator failed for path `{PATH}` with value `{VALUE}`';\nmsg.general.required = 'Path `{PATH}` is required.';\n\nmsg.Number = {};\nmsg.Number.min = 'Path `{PATH}` ({VALUE}) is less than minimum allowed value ({MIN}).';\nmsg.Number.max = 'Path `{PATH}` ({VALUE}) is more than maximum allowed value ({MAX}).';\nmsg.Number.enum = '`{VALUE}` is not a valid enum value for path `{PATH}`.';\n\nmsg.Date = {};\nmsg.Date.min = 'Path `{PATH}` ({VALUE}) is before minimum allowed value ({MIN}).';\nmsg.Date.max = 'Path `{PATH}` ({VALUE}) is after maximum allowed value ({MAX}).';\n\nmsg.String = {};\nmsg.String.enum = '`{VALUE}` is not a valid enum value for path `{PATH}`.';\nmsg.String.match = 'Path `{PATH}` is invalid ({VALUE}).';\nmsg.String.minlength = 'Path `{PATH}` (`{VALUE}`) is shorter than the minimum allowed length ({MINLENGTH}).';\nmsg.String.maxlength = 'Path `{PATH}` (`{VALUE}`) is longer than the maximum allowed length ({MAXLENGTH}).';\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/error/messages.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/error/missingSchema.js":
/*!**********************************************************!*\
  !*** ./node_modules/mongoose/lib/error/missingSchema.js ***!
  \**********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n/*!\n * Module dependencies.\n */\n\n\n\nconst MongooseError = __webpack_require__(/*! ./mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\n\nclass MissingSchemaError extends MongooseError {\n  /**\n   * MissingSchema Error constructor.\n   * @param {String} name\n   * @api private\n   */\n  constructor(name) {\n    const msg = 'Schema hasn\\'t been registered for model \"' + name + '\".\\n'\n            + 'Use mongoose.model(name, schema)';\n    super(msg);\n  }\n}\n\nObject.defineProperty(MissingSchemaError.prototype, 'name', {\n  value: 'MissingSchemaError'\n});\n\n/*!\n * exports\n */\n\nmodule.exports = MissingSchemaError;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/error/missingSchema.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/error/mongooseError.js":
/*!**********************************************************!*\
  !*** ./node_modules/mongoose/lib/error/mongooseError.js ***!
  \**********************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/*!\n * ignore\n */\n\nclass MongooseError extends Error { }\n\nObject.defineProperty(MongooseError.prototype, 'name', {\n  value: 'MongooseError'\n});\n\nmodule.exports = MongooseError;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/error/mongooseError.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/error/notFound.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongoose/lib/error/notFound.js ***!
  \*****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst MongooseError = __webpack_require__(/*! ./mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\nconst util = __webpack_require__(/*! util */ \"util\");\n\nclass DocumentNotFoundError extends MongooseError {\n  /**\n   * OverwriteModel Error constructor.\n   * @api private\n   */\n  constructor(filter, model, numAffected, result) {\n    let msg;\n    const messages = MongooseError.messages;\n    if (messages.DocumentNotFoundError != null) {\n      msg = typeof messages.DocumentNotFoundError === 'function' ?\n        messages.DocumentNotFoundError(filter, model) :\n        messages.DocumentNotFoundError;\n    } else {\n      msg = 'No document found for query \"' + util.inspect(filter) +\n        '\" on model \"' + model + '\"';\n    }\n\n    super(msg);\n\n    this.result = result;\n    this.numAffected = numAffected;\n    this.filter = filter;\n    // Backwards compat\n    this.query = filter;\n  }\n}\n\nObject.defineProperty(DocumentNotFoundError.prototype, 'name', {\n  value: 'DocumentNotFoundError'\n});\n\n/*!\n * exports\n */\n\nmodule.exports = DocumentNotFoundError;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/error/notFound.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/error/objectExpected.js":
/*!***********************************************************!*\
  !*** ./node_modules/mongoose/lib/error/objectExpected.js ***!
  \***********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module dependencies.\n */\n\n\n\nconst MongooseError = __webpack_require__(/*! ./mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\n\n\nclass ObjectExpectedError extends MongooseError {\n  /**\n   * Strict mode error constructor\n   *\n   * @param {string} type\n   * @param {string} value\n   * @api private\n   */\n  constructor(path, val) {\n    const typeDescription = Array.isArray(val) ? 'array' : 'primitive value';\n    super('Tried to set nested object field `' + path +\n      `\\` to ${typeDescription} \\`` + val + '`');\n    this.path = path;\n  }\n}\n\nObject.defineProperty(ObjectExpectedError.prototype, 'name', {\n  value: 'ObjectExpectedError'\n});\n\nmodule.exports = ObjectExpectedError;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/error/objectExpected.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/error/objectParameter.js":
/*!************************************************************!*\
  !*** ./node_modules/mongoose/lib/error/objectParameter.js ***!
  \************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module dependencies.\n */\n\n\n\nconst MongooseError = __webpack_require__(/*! ./mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\n\nclass ObjectParameterError extends MongooseError {\n  /**\n   * Constructor for errors that happen when a parameter that's expected to be\n   * an object isn't an object\n   *\n   * @param {Any} value\n   * @param {String} paramName\n   * @param {String} fnName\n   * @api private\n   */\n  constructor(value, paramName, fnName) {\n    super('Parameter \"' + paramName + '\" to ' + fnName +\n      '() must be an object, got \"' + value.toString() + '\" (type ' + typeof value + ')');\n  }\n}\n\n\nObject.defineProperty(ObjectParameterError.prototype, 'name', {\n  value: 'ObjectParameterError'\n});\n\nmodule.exports = ObjectParameterError;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/error/objectParameter.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/error/overwriteModel.js":
/*!***********************************************************!*\
  !*** ./node_modules/mongoose/lib/error/overwriteModel.js ***!
  \***********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n/*!\n * Module dependencies.\n */\n\n\n\nconst MongooseError = __webpack_require__(/*! ./mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\n\n\nclass OverwriteModelError extends MongooseError {\n  /**\n   * OverwriteModel Error constructor.\n   * @param {String} name\n   * @api private\n   */\n  constructor(name) {\n    super('Cannot overwrite `' + name + '` model once compiled.');\n  }\n}\n\nObject.defineProperty(OverwriteModelError.prototype, 'name', {\n  value: 'OverwriteModelError'\n});\n\n/*!\n * exports\n */\n\nmodule.exports = OverwriteModelError;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/error/overwriteModel.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/error/parallelSave.js":
/*!*********************************************************!*\
  !*** ./node_modules/mongoose/lib/error/parallelSave.js ***!
  \*********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst MongooseError = __webpack_require__(/*! ./mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\n\nclass ParallelSaveError extends MongooseError {\n  /**\n   * ParallelSave Error constructor.\n   *\n   * @param {Document} doc\n   * @api private\n   */\n  constructor(doc) {\n    const msg = 'Can\\'t save() the same doc multiple times in parallel. Document: ';\n    super(msg + doc._id);\n  }\n}\n\nObject.defineProperty(ParallelSaveError.prototype, 'name', {\n  value: 'ParallelSaveError'\n});\n\n/*!\n * exports\n */\n\nmodule.exports = ParallelSaveError;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/error/parallelSave.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/error/parallelValidate.js":
/*!*************************************************************!*\
  !*** ./node_modules/mongoose/lib/error/parallelValidate.js ***!
  \*************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst MongooseError = __webpack_require__(/*! ./mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\n\n\nclass ParallelValidateError extends MongooseError {\n  /**\n   * ParallelValidate Error constructor.\n   *\n   * @param {Document} doc\n   * @api private\n   */\n  constructor(doc) {\n    const msg = 'Can\\'t validate() the same doc multiple times in parallel. Document: ';\n    super(msg + doc._id);\n  }\n}\n\nObject.defineProperty(ParallelValidateError.prototype, 'name', {\n  value: 'ParallelValidateError'\n});\n\n/*!\n * exports\n */\n\nmodule.exports = ParallelValidateError;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/error/parallelValidate.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/error/serverSelection.js":
/*!************************************************************!*\
  !*** ./node_modules/mongoose/lib/error/serverSelection.js ***!
  \************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module dependencies.\n */\n\n\n\nconst MongooseError = __webpack_require__(/*! ./mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\nconst allServersUnknown = __webpack_require__(/*! ../helpers/topology/allServersUnknown */ \"./node_modules/mongoose/lib/helpers/topology/allServersUnknown.js\");\nconst isAtlas = __webpack_require__(/*! ../helpers/topology/isAtlas */ \"./node_modules/mongoose/lib/helpers/topology/isAtlas.js\");\nconst isSSLError = __webpack_require__(/*! ../helpers/topology/isSSLError */ \"./node_modules/mongoose/lib/helpers/topology/isSSLError.js\");\n\n/*!\n * ignore\n */\n\nconst atlasMessage = 'Could not connect to any servers in your MongoDB Atlas cluster. ' +\n  'One common reason is that you\\'re trying to access the database from ' +\n  'an IP that isn\\'t whitelisted. Make sure your current IP address is on your Atlas ' +\n  'cluster\\'s IP whitelist: https://www.mongodb.com/docs/atlas/security-whitelist/';\n\nconst sslMessage = 'Mongoose is connecting with SSL enabled, but the server is ' +\n  'not accepting SSL connections. Please ensure that the MongoDB server you are ' +\n  'connecting to is configured to accept SSL connections. Learn more: ' +\n  'https://mongoosejs.com/docs/tutorials/ssl.html';\n\nclass MongooseServerSelectionError extends MongooseError {\n  /**\n   * MongooseServerSelectionError constructor\n   *\n   * @api private\n   */\n  assimilateError(err) {\n    const reason = err.reason;\n    // Special message for a case that is likely due to IP whitelisting issues.\n    const isAtlasWhitelistError = isAtlas(reason) &&\n      allServersUnknown(reason) &&\n      err.message.indexOf('bad auth') === -1 &&\n      err.message.indexOf('Authentication failed') === -1;\n\n    if (isAtlasWhitelistError) {\n      this.message = atlasMessage;\n    } else if (isSSLError(reason)) {\n      this.message = sslMessage;\n    } else {\n      this.message = err.message;\n    }\n    for (const key in err) {\n      if (key !== 'name') {\n        this[key] = err[key];\n      }\n    }\n\n    return this;\n  }\n}\n\nObject.defineProperty(MongooseServerSelectionError.prototype, 'name', {\n  value: 'MongooseServerSelectionError'\n});\n\nmodule.exports = MongooseServerSelectionError;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/error/serverSelection.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/error/setOptionError.js":
/*!***********************************************************!*\
  !*** ./node_modules/mongoose/lib/error/setOptionError.js ***!
  \***********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module requirements\n */\n\n\n\nconst MongooseError = __webpack_require__(/*! ./mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\nconst util = __webpack_require__(/*! util */ \"util\");\nconst combinePathErrors = __webpack_require__(/*! ../helpers/error/combinePathErrors */ \"./node_modules/mongoose/lib/helpers/error/combinePathErrors.js\");\n\nclass SetOptionError extends MongooseError {\n  /**\n   * Mongoose.set Error\n   *\n   * @api private\n   * @inherits MongooseError\n   */\n  constructor() {\n    super('');\n\n    this.errors = {};\n  }\n\n  /**\n   * Console.log helper\n   */\n  toString() {\n    return combinePathErrors(this);\n  }\n\n  /**\n   * inspect helper\n   * @api private\n   */\n  inspect() {\n    return Object.assign(new Error(this.message), this);\n  }\n\n  /**\n  * add message\n  * @param {String} key\n  * @param {String|Error} error\n  * @api private\n  */\n  addError(key, error) {\n    if (error instanceof SetOptionError) {\n      const { errors } = error;\n      for (const optionKey of Object.keys(errors)) {\n        this.addError(optionKey, errors[optionKey]);\n      }\n\n      return;\n    }\n\n    this.errors[key] = error;\n    this.message = combinePathErrors(this);\n  }\n}\n\n\nif (util.inspect.custom) {\n  // Avoid Node deprecation warning DEP0079\n  SetOptionError.prototype[util.inspect.custom] = SetOptionError.prototype.inspect;\n}\n\n/**\n * Helper for JSON.stringify\n * Ensure `name` and `message` show up in toJSON output re: gh-9847\n * @api private\n */\nObject.defineProperty(SetOptionError.prototype, 'toJSON', {\n  enumerable: false,\n  writable: false,\n  configurable: true,\n  value: function() {\n    return Object.assign({}, this, { name: this.name, message: this.message });\n  }\n});\n\n\nObject.defineProperty(SetOptionError.prototype, 'name', {\n  value: 'SetOptionError'\n});\n\nclass SetOptionInnerError extends MongooseError {\n  /**\n   * Error for the \"errors\" array in \"SetOptionError\" with consistent message\n   * @param {String} key\n   */\n  constructor(key) {\n    super(`\"${key}\" is not a valid option to set`);\n  }\n}\n\nSetOptionError.SetOptionInnerError = SetOptionInnerError;\n\n/*!\n * Module exports\n */\n\nmodule.exports = SetOptionError;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/error/setOptionError.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/error/strict.js":
/*!***************************************************!*\
  !*** ./node_modules/mongoose/lib/error/strict.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module dependencies.\n */\n\n\n\nconst MongooseError = __webpack_require__(/*! ./mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\n\n\nclass StrictModeError extends MongooseError {\n  /**\n   * Strict mode error constructor\n   *\n   * @param {String} path\n   * @param {String} [msg]\n   * @param {Boolean} [immutable]\n   * @inherits MongooseError\n   * @api private\n   */\n  constructor(path, msg, immutable) {\n    msg = msg || 'Field `' + path + '` is not in schema and strict ' +\n      'mode is set to throw.';\n    super(msg);\n    this.isImmutableError = !!immutable;\n    this.path = path;\n  }\n}\n\nObject.defineProperty(StrictModeError.prototype, 'name', {\n  value: 'StrictModeError'\n});\n\nmodule.exports = StrictModeError;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/error/strict.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/error/strictPopulate.js":
/*!***********************************************************!*\
  !*** ./node_modules/mongoose/lib/error/strictPopulate.js ***!
  \***********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module dependencies.\n */\n\n\n\nconst MongooseError = __webpack_require__(/*! ./mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\n\nclass StrictPopulateError extends MongooseError {\n  /**\n   * Strict mode error constructor\n   *\n   * @param {String} path\n   * @param {String} [msg]\n   * @inherits MongooseError\n   * @api private\n   */\n  constructor(path, msg) {\n    msg = msg || 'Cannot populate path `' + path + '` because it is not in your schema. ' + 'Set the `strictPopulate` option to false to override.';\n    super(msg);\n    this.path = path;\n  }\n}\n\nObject.defineProperty(StrictPopulateError.prototype, 'name', {\n  value: 'StrictPopulateError'\n});\n\nmodule.exports = StrictPopulateError;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/error/strictPopulate.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/error/syncIndexes.js":
/*!********************************************************!*\
  !*** ./node_modules/mongoose/lib/error/syncIndexes.js ***!
  \********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst MongooseError = __webpack_require__(/*! ./mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\n\n/**\n * SyncIndexes Error constructor.\n *\n * @param {String} message\n * @param {String} errorsMap\n * @inherits MongooseError\n * @api private\n */\n\nclass SyncIndexesError extends MongooseError {\n  constructor(message, errorsMap) {\n    super(message);\n    this.errors = errorsMap;\n  }\n}\n\nObject.defineProperty(SyncIndexesError.prototype, 'name', {\n  value: 'SyncIndexesError'\n});\n\n\nmodule.exports = SyncIndexesError;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/error/syncIndexes.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/error/validation.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongoose/lib/error/validation.js ***!
  \*******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module requirements\n */\n\n\n\nconst MongooseError = __webpack_require__(/*! ./mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\nconst getConstructorName = __webpack_require__(/*! ../helpers/getConstructorName */ \"./node_modules/mongoose/lib/helpers/getConstructorName.js\");\nconst util = __webpack_require__(/*! util */ \"util\");\nconst combinePathErrors = __webpack_require__(/*! ../helpers/error/combinePathErrors */ \"./node_modules/mongoose/lib/helpers/error/combinePathErrors.js\");\n\nclass ValidationError extends MongooseError {\n  /**\n   * Document Validation Error\n   *\n   * @api private\n   * @param {Document} [instance]\n   * @inherits MongooseError\n   */\n  constructor(instance) {\n    let _message;\n    if (getConstructorName(instance) === 'model') {\n      _message = instance.constructor.modelName + ' validation failed';\n    } else {\n      _message = 'Validation failed';\n    }\n\n    super(_message);\n\n    this.errors = {};\n    this._message = _message;\n\n    if (instance) {\n      instance.$errors = this.errors;\n    }\n  }\n\n  /**\n   * Console.log helper\n   */\n  toString() {\n    return this.name + ': ' + combinePathErrors(this);\n  }\n\n  /**\n   * inspect helper\n   * @api private\n   */\n  inspect() {\n    return Object.assign(new Error(this.message), this);\n  }\n\n  /**\n  * add message\n  * @param {String} path\n  * @param {String|Error} error\n  * @api private\n  */\n  addError(path, error) {\n    if (error instanceof ValidationError) {\n      const { errors } = error;\n      for (const errorPath of Object.keys(errors)) {\n        this.addError(`${path}.${errorPath}`, errors[errorPath]);\n      }\n\n      return;\n    }\n\n    this.errors[path] = error;\n    this.message = this._message + ': ' + combinePathErrors(this);\n  }\n}\n\n\nif (util.inspect.custom) {\n  // Avoid Node deprecation warning DEP0079\n  ValidationError.prototype[util.inspect.custom] = ValidationError.prototype.inspect;\n}\n\n/**\n * Helper for JSON.stringify\n * Ensure `name` and `message` show up in toJSON output re: gh-9847\n * @api private\n */\nObject.defineProperty(ValidationError.prototype, 'toJSON', {\n  enumerable: false,\n  writable: false,\n  configurable: true,\n  value: function() {\n    return Object.assign({}, this, { name: this.name, message: this.message });\n  }\n});\n\n\nObject.defineProperty(ValidationError.prototype, 'name', {\n  value: 'ValidationError'\n});\n\n/*!\n * Module exports\n */\n\nmodule.exports = ValidationError;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/error/validation.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/error/validator.js":
/*!******************************************************!*\
  !*** ./node_modules/mongoose/lib/error/validator.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module dependencies.\n */\n\n\n\nconst MongooseError = __webpack_require__(/*! ./mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\n\n\nclass ValidatorError extends MongooseError {\n  /**\n   * Schema validator error\n   *\n   * @param {Object} properties\n   * @param {Document} doc\n   * @api private\n   */\n  constructor(properties, doc) {\n    let msg = properties.message;\n    if (!msg) {\n      msg = MongooseError.messages.general.default;\n    }\n\n    const message = formatMessage(msg, properties, doc);\n    super(message);\n\n    properties = Object.assign({}, properties, { message: message });\n    this.properties = properties;\n    this.kind = properties.type;\n    this.path = properties.path;\n    this.value = properties.value;\n    this.reason = properties.reason;\n  }\n\n  /**\n   * toString helper\n   * TODO remove? This defaults to `${this.name}: ${this.message}`\n   * @api private\n   */\n  toString() {\n    return this.message;\n  }\n\n  /**\n   * Ensure `name` and `message` show up in toJSON output re: gh-9296\n   * @api private\n   */\n\n  toJSON() {\n    return Object.assign({ name: this.name, message: this.message }, this);\n  }\n}\n\n\nObject.defineProperty(ValidatorError.prototype, 'name', {\n  value: 'ValidatorError'\n});\n\n/**\n * The object used to define this validator. Not enumerable to hide\n * it from `require('util').inspect()` output re: gh-3925\n * @api private\n */\n\nObject.defineProperty(ValidatorError.prototype, 'properties', {\n  enumerable: false,\n  writable: true,\n  value: null\n});\n\n// Exposed for testing\nValidatorError.prototype.formatMessage = formatMessage;\n\n/**\n * Formats error messages\n * @api private\n */\n\nfunction formatMessage(msg, properties, doc) {\n  if (typeof msg === 'function') {\n    return msg(properties, doc);\n  }\n\n  const propertyNames = Object.keys(properties);\n  for (const propertyName of propertyNames) {\n    if (propertyName === 'message') {\n      continue;\n    }\n    msg = msg.replace('{' + propertyName.toUpperCase() + '}', properties[propertyName]);\n  }\n\n  return msg;\n}\n\n/*!\n * exports\n */\n\nmodule.exports = ValidatorError;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/error/validator.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/error/version.js":
/*!****************************************************!*\
  !*** ./node_modules/mongoose/lib/error/version.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst MongooseError = __webpack_require__(/*! ./mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\n\nclass VersionError extends MongooseError {\n  /**\n   * Version Error constructor.\n   *\n   * @param {Document} doc\n   * @param {Number} currentVersion\n   * @param {Array<String>} modifiedPaths\n   * @api private\n   */\n  constructor(doc, currentVersion, modifiedPaths) {\n    const modifiedPathsStr = modifiedPaths.join(', ');\n    super('No matching document found for id \"' + doc._id +\n      '\" version ' + currentVersion + ' modifiedPaths \"' + modifiedPathsStr + '\"');\n    this.version = currentVersion;\n    this.modifiedPaths = modifiedPaths;\n  }\n}\n\n\nObject.defineProperty(VersionError.prototype, 'name', {\n  value: 'VersionError'\n});\n\n/*!\n * exports\n */\n\nmodule.exports = VersionError;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/error/version.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/aggregate/prepareDiscriminatorPipeline.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/aggregate/prepareDiscriminatorPipeline.js ***!
  \*************************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function prepareDiscriminatorPipeline(pipeline, schema, prefix) {\n  const discriminatorMapping = schema && schema.discriminatorMapping;\n  prefix = prefix || '';\n\n  if (discriminatorMapping && !discriminatorMapping.isRoot) {\n    const originalPipeline = pipeline;\n    const filterKey = (prefix.length > 0 ? prefix + '.' : prefix) + discriminatorMapping.key;\n    const discriminatorValue = discriminatorMapping.value;\n\n    // If the first pipeline stage is a match and it doesn't specify a `__t`\n    // key, add the discriminator key to it. This allows for potential\n    // aggregation query optimizations not to be disturbed by this feature.\n    if (originalPipeline[0] != null &&\n        originalPipeline[0].$match &&\n        (originalPipeline[0].$match[filterKey] === undefined || originalPipeline[0].$match[filterKey] === discriminatorValue)) {\n      originalPipeline[0].$match[filterKey] = discriminatorValue;\n      // `originalPipeline` is a ref, so there's no need for\n      // aggregate._pipeline = originalPipeline\n    } else if (originalPipeline[0] != null && originalPipeline[0].$geoNear) {\n      originalPipeline[0].$geoNear.query =\n          originalPipeline[0].$geoNear.query || {};\n      originalPipeline[0].$geoNear.query[filterKey] = discriminatorValue;\n    } else if (originalPipeline[0] != null && originalPipeline[0].$search) {\n      if (originalPipeline[1] && originalPipeline[1].$match != null) {\n        originalPipeline[1].$match[filterKey] = originalPipeline[1].$match[filterKey] || discriminatorValue;\n      } else {\n        const match = {};\n        match[filterKey] = discriminatorValue;\n        originalPipeline.splice(1, 0, { $match: match });\n      }\n    } else {\n      const match = {};\n      match[filterKey] = discriminatorValue;\n      originalPipeline.unshift({ $match: match });\n    }\n  }\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/aggregate/prepareDiscriminatorPipeline.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/aggregate/stringifyFunctionOperators.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/aggregate/stringifyFunctionOperators.js ***!
  \***********************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function stringifyFunctionOperators(pipeline) {\n  if (!Array.isArray(pipeline)) {\n    return;\n  }\n\n  for (const stage of pipeline) {\n    if (stage == null) {\n      continue;\n    }\n\n    const canHaveAccumulator = stage.$group || stage.$bucket || stage.$bucketAuto;\n    if (canHaveAccumulator != null) {\n      for (const key of Object.keys(canHaveAccumulator)) {\n        handleAccumulator(canHaveAccumulator[key]);\n      }\n    }\n\n    const stageType = Object.keys(stage)[0];\n    if (stageType && typeof stage[stageType] === 'object') {\n      const stageOptions = stage[stageType];\n      for (const key of Object.keys(stageOptions)) {\n        if (stageOptions[key] != null &&\n            stageOptions[key].$function != null &&\n            typeof stageOptions[key].$function.body === 'function') {\n          stageOptions[key].$function.body = stageOptions[key].$function.body.toString();\n        }\n      }\n    }\n\n    if (stage.$facet != null) {\n      for (const key of Object.keys(stage.$facet)) {\n        stringifyFunctionOperators(stage.$facet[key]);\n      }\n    }\n  }\n};\n\nfunction handleAccumulator(operator) {\n  if (operator == null || operator.$accumulator == null) {\n    return;\n  }\n\n  for (const key of ['init', 'accumulate', 'merge', 'finalize']) {\n    if (typeof operator.$accumulator[key] === 'function') {\n      operator.$accumulator[key] = String(operator.$accumulator[key]);\n    }\n  }\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/aggregate/stringifyFunctionOperators.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/arrayDepth.js":
/*!*********************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/arrayDepth.js ***!
  \*********************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = arrayDepth;\n\nfunction arrayDepth(arr) {\n  if (!Array.isArray(arr)) {\n    return { min: 0, max: 0, containsNonArrayItem: true };\n  }\n  if (arr.length === 0) {\n    return { min: 1, max: 1, containsNonArrayItem: false };\n  }\n  if (arr.length === 1 && !Array.isArray(arr[0])) {\n    return { min: 1, max: 1, containsNonArrayItem: false };\n  }\n\n  const res = arrayDepth(arr[0]);\n\n  for (let i = 1; i < arr.length; ++i) {\n    const _res = arrayDepth(arr[i]);\n    if (_res.min < res.min) {\n      res.min = _res.min;\n    }\n    if (_res.max > res.max) {\n      res.max = _res.max;\n    }\n    res.containsNonArrayItem = res.containsNonArrayItem || _res.containsNonArrayItem;\n  }\n\n  res.min = res.min + 1;\n  res.max = res.max + 1;\n\n  return res;\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/arrayDepth.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/clone.js":
/*!****************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/clone.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst Decimal = __webpack_require__(/*! ../types/decimal128 */ \"./node_modules/mongoose/lib/types/decimal128.js\");\nconst ObjectId = __webpack_require__(/*! ../types/objectid */ \"./node_modules/mongoose/lib/types/objectid.js\");\nconst specialProperties = __webpack_require__(/*! ./specialProperties */ \"./node_modules/mongoose/lib/helpers/specialProperties.js\");\nconst isMongooseObject = __webpack_require__(/*! ./isMongooseObject */ \"./node_modules/mongoose/lib/helpers/isMongooseObject.js\");\nconst getFunctionName = __webpack_require__(/*! ./getFunctionName */ \"./node_modules/mongoose/lib/helpers/getFunctionName.js\");\nconst isBsonType = __webpack_require__(/*! ./isBsonType */ \"./node_modules/mongoose/lib/helpers/isBsonType.js\");\nconst isMongooseArray = (__webpack_require__(/*! ../types/array/isMongooseArray */ \"./node_modules/mongoose/lib/types/array/isMongooseArray.js\").isMongooseArray);\nconst isObject = __webpack_require__(/*! ./isObject */ \"./node_modules/mongoose/lib/helpers/isObject.js\");\nconst isPOJO = __webpack_require__(/*! ./isPOJO */ \"./node_modules/mongoose/lib/helpers/isPOJO.js\");\nconst symbols = __webpack_require__(/*! ./symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\");\nconst trustedSymbol = (__webpack_require__(/*! ./query/trusted */ \"./node_modules/mongoose/lib/helpers/query/trusted.js\").trustedSymbol);\n\n/**\n * Object clone with Mongoose natives support.\n *\n * If options.minimize is true, creates a minimal data object. Empty objects and undefined values will not be cloned. This makes the data payload sent to MongoDB as small as possible.\n *\n * Functions and primitives are never cloned.\n *\n * @param {Object} obj the object to clone\n * @param {Object} options\n * @param {Boolean} isArrayChild true if cloning immediately underneath an array. Special case for minimize.\n * @return {Object} the cloned object\n * @api private\n */\n\nfunction clone(obj, options, isArrayChild) {\n  if (obj == null) {\n    return obj;\n  }\n  if (typeof obj === 'number' || typeof obj === 'string' || typeof obj === 'boolean' || typeof obj === 'bigint') {\n    return obj;\n  }\n\n  if (Array.isArray(obj)) {\n    return cloneArray(isMongooseArray(obj) ? obj.__array : obj, options);\n  }\n\n  if (isMongooseObject(obj)) {\n    if (options) {\n      // Single nested subdocs should apply getters later in `applyGetters()`\n      // when calling `toObject()`. See gh-7442, gh-8295\n      if (options._skipSingleNestedGetters && obj.$isSingleNested) {\n        options._calledWithOptions = Object.assign({}, options._calledWithOptions || {}, { getters: false });\n      }\n      if (options.retainDocuments && obj.$__ != null) {\n        const clonedDoc = obj.$clone();\n        if (obj.__index != null) {\n          clonedDoc.__index = obj.__index;\n        }\n        if (obj.__parentArray != null) {\n          clonedDoc.__parentArray = obj.__parentArray;\n        }\n        clonedDoc.$__parent = obj.$__parent;\n        return clonedDoc;\n      }\n    }\n    const isSingleNested = obj.$isSingleNested;\n\n    if (isPOJO(obj) && obj.$__ != null && obj._doc != null) {\n      return obj._doc;\n    }\n\n    let ret;\n    if (options && options.json && typeof obj.toJSON === 'function') {\n      ret = obj.toJSON(options);\n    } else {\n      ret = obj.toObject(options);\n    }\n\n    if (options && options.minimize && !obj.constructor.$__required && isSingleNested && Object.keys(ret).length === 0) {\n      return undefined;\n    }\n\n    return ret;\n  }\n\n  const objConstructor = obj.constructor;\n\n  if (objConstructor) {\n    switch (getFunctionName(objConstructor)) {\n      case 'Object':\n        return cloneObject(obj, options, isArrayChild);\n      case 'Date':\n        return new objConstructor(+obj);\n      case 'RegExp':\n        return cloneRegExp(obj);\n      default:\n        // ignore\n        break;\n    }\n  }\n\n  if (isBsonType(obj, 'ObjectId')) {\n    if (options && options.flattenObjectIds) {\n      return obj.toJSON();\n    }\n    return new ObjectId(obj.id);\n  }\n\n  if (isBsonType(obj, 'Decimal128')) {\n    if (options && options.flattenDecimals) {\n      return obj.toJSON();\n    }\n    return Decimal.fromString(obj.toString());\n  }\n\n  // object created with Object.create(null)\n  if (!objConstructor && isObject(obj)) {\n    return cloneObject(obj, options, isArrayChild);\n  }\n\n  if (typeof obj === 'object' && obj[symbols.schemaTypeSymbol]) {\n    return obj.clone();\n  }\n\n  // If we're cloning this object to go into a MongoDB command,\n  // and there's a `toBSON()` function, assume this object will be\n  // stored as a primitive in MongoDB and doesn't need to be cloned.\n  if (options && options.bson && typeof obj.toBSON === 'function') {\n    return obj;\n  }\n\n  if (typeof obj.valueOf === 'function') {\n    return obj.valueOf();\n  }\n\n  return cloneObject(obj, options, isArrayChild);\n}\nmodule.exports = clone;\n\n/*!\n * ignore\n */\n\nfunction cloneObject(obj, options, isArrayChild) {\n  const minimize = options && options.minimize;\n  const omitUndefined = options && options.omitUndefined;\n  const seen = options && options._seen;\n  const ret = {};\n  let hasKeys;\n\n  if (seen && seen.has(obj)) {\n    return seen.get(obj);\n  } else if (seen) {\n    seen.set(obj, ret);\n  }\n  if (trustedSymbol in obj) {\n    ret[trustedSymbol] = obj[trustedSymbol];\n  }\n\n  const keys = Object.keys(obj);\n  const len = keys.length;\n\n  for (let i = 0; i < len; ++i) {\n    const key = keys[i];\n    if (specialProperties.has(key)) {\n      continue;\n    }\n\n    // Don't pass `isArrayChild` down\n    const val = clone(obj[key], options, false);\n\n    if ((minimize === false || omitUndefined) && typeof val === 'undefined') {\n      delete ret[key];\n    } else if (minimize !== true || (typeof val !== 'undefined')) {\n      hasKeys || (hasKeys = true);\n      ret[key] = val;\n    }\n  }\n\n  return minimize && !isArrayChild ? hasKeys && ret : ret;\n}\n\nfunction cloneArray(arr, options) {\n  let i = 0;\n  const len = arr.length;\n  const ret = new Array(len);\n  for (i = 0; i < len; ++i) {\n    ret[i] = clone(arr[i], options, true);\n  }\n\n  return ret;\n}\n\nfunction cloneRegExp(regexp) {\n  const ret = new RegExp(regexp.source, regexp.flags);\n\n  if (ret.lastIndex !== regexp.lastIndex) {\n    ret.lastIndex = regexp.lastIndex;\n  }\n  return ret;\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/clone.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/common.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/common.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst Binary = (__webpack_require__(/*! bson */ \"./node_modules/bson/lib/bson.cjs\").Binary);\nconst isBsonType = __webpack_require__(/*! ./isBsonType */ \"./node_modules/mongoose/lib/helpers/isBsonType.js\");\nconst isMongooseObject = __webpack_require__(/*! ./isMongooseObject */ \"./node_modules/mongoose/lib/helpers/isMongooseObject.js\");\nconst MongooseError = __webpack_require__(/*! ../error */ \"./node_modules/mongoose/lib/error/index.js\");\nconst util = __webpack_require__(/*! util */ \"util\");\n\nexports.flatten = flatten;\nexports.modifiedPaths = modifiedPaths;\n\n/*!\n * ignore\n */\n\nfunction flatten(update, path, options, schema) {\n  let keys;\n  if (update && isMongooseObject(update) && !Buffer.isBuffer(update)) {\n    keys = Object.keys(update.toObject({ transform: false, virtuals: false }) || {});\n  } else {\n    keys = Object.keys(update || {});\n  }\n\n  const numKeys = keys.length;\n  const result = {};\n  path = path ? path + '.' : '';\n\n  for (let i = 0; i < numKeys; ++i) {\n    const key = keys[i];\n    const val = update[key];\n    result[path + key] = val;\n\n    // Avoid going into mixed paths if schema is specified\n    const keySchema = schema && schema.path && schema.path(path + key);\n    const isNested = schema && schema.nested && schema.nested[path + key];\n    if (keySchema && keySchema.instance === 'Mixed') continue;\n\n    if (shouldFlatten(val)) {\n      if (options && options.skipArrays && Array.isArray(val)) {\n        continue;\n      }\n      const flat = flatten(val, path + key, options, schema);\n      for (const k in flat) {\n        result[k] = flat[k];\n      }\n      if (Array.isArray(val)) {\n        result[path + key] = val;\n      }\n    }\n\n    if (isNested) {\n      const paths = Object.keys(schema.paths);\n      for (const p of paths) {\n        if (p.startsWith(path + key + '.') && !result.hasOwnProperty(p)) {\n          result[p] = void 0;\n        }\n      }\n    }\n  }\n\n  return result;\n}\n\n/*!\n * ignore\n */\n\nfunction modifiedPaths(update, path, result, recursion = null) {\n  if (update == null || typeof update !== 'object') {\n    return;\n  }\n\n  if (recursion == null) {\n    recursion = {\n      raw: { update, path },\n      trace: new WeakSet()\n    };\n  }\n\n  if (recursion.trace.has(update)) {\n    throw new MongooseError(`a circular reference in the update value, updateValue:\n${util.inspect(recursion.raw.update, { showHidden: false, depth: 1 })}\nupdatePath: '${recursion.raw.path}'`);\n  }\n  recursion.trace.add(update);\n\n  const keys = Object.keys(update || {});\n  const numKeys = keys.length;\n  result = result || {};\n  path = path ? path + '.' : '';\n\n  for (let i = 0; i < numKeys; ++i) {\n    const key = keys[i];\n    let val = update[key];\n\n    const _path = path + key;\n    result[_path] = true;\n    if (!Buffer.isBuffer(val) && isMongooseObject(val)) {\n      val = val.toObject({ transform: false, virtuals: false });\n    }\n    if (shouldFlatten(val)) {\n      modifiedPaths(val, path + key, result, recursion);\n    }\n  }\n  recursion.trace.delete(update);\n\n  return result;\n}\n\n/*!\n * ignore\n */\n\nfunction shouldFlatten(val) {\n  return val &&\n      typeof val === 'object' &&\n      !(val instanceof Date) &&\n      !isBsonType(val, 'ObjectId') &&\n      (!Array.isArray(val) || val.length !== 0) &&\n      !(val instanceof Buffer) &&\n      !isBsonType(val, 'Decimal128') &&\n      !(val instanceof Binary);\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/common.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/cursor/eachAsync.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/cursor/eachAsync.js ***!
  \***************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst EachAsyncMultiError = __webpack_require__(/*! ../../error/eachAsyncMultiError */ \"./node_modules/mongoose/lib/error/eachAsyncMultiError.js\");\nconst immediate = __webpack_require__(/*! ../immediate */ \"./node_modules/mongoose/lib/helpers/immediate.js\");\n\n/**\n * Execute `fn` for every document in the cursor. If `fn` returns a promise,\n * will wait for the promise to resolve before iterating on to the next one.\n * Returns a promise that resolves when done.\n *\n * @param {Function} next the thunk to call to get the next document\n * @param {Function} fn\n * @param {Object} options\n * @param {Number} [options.batchSize=null] if set, Mongoose will call `fn` with an array of at most `batchSize` documents, instead of a single document\n * @param {Number} [options.parallel=1] maximum number of `fn` calls that Mongoose will run in parallel\n * @param {AbortSignal} [options.signal] allow cancelling this eachAsync(). Once the abort signal is fired, `eachAsync()` will immediately fulfill the returned promise (or call the callback) and not fetch any more documents.\n * @return {Promise}\n * @api public\n * @method eachAsync\n */\n\nmodule.exports = async function eachAsync(next, fn, options) {\n  const parallel = options.parallel || 1;\n  const batchSize = options.batchSize;\n  const signal = options.signal;\n  const continueOnError = options.continueOnError;\n  const aggregatedErrors = [];\n  const enqueue = asyncQueue();\n\n  let aborted = false;\n\n  return new Promise((resolve, reject) => {\n    if (signal != null) {\n      if (signal.aborted) {\n        return resolve(null);\n      }\n\n      signal.addEventListener('abort', () => {\n        aborted = true;\n        return resolve(null);\n      }, { once: true });\n    }\n\n    if (batchSize != null) {\n      if (typeof batchSize !== 'number') {\n        throw new TypeError('batchSize must be a number');\n      } else if (!Number.isInteger(batchSize)) {\n        throw new TypeError('batchSize must be an integer');\n      } else if (batchSize < 1) {\n        throw new TypeError('batchSize must be at least 1');\n      }\n    }\n\n    iterate((err, res) => {\n      if (err != null) {\n        return reject(err);\n      }\n      resolve(res);\n    });\n  });\n\n  function iterate(finalCallback) {\n    let handleResultsInProgress = 0;\n    let currentDocumentIndex = 0;\n\n    let error = null;\n    for (let i = 0; i < parallel; ++i) {\n      enqueue(createFetch());\n    }\n\n    function createFetch() {\n      let documentsBatch = [];\n      let drained = false;\n\n      return fetch;\n\n      function fetch(done) {\n        if (drained || aborted) {\n          return done();\n        } else if (error) {\n          return done();\n        }\n\n        next(function(err, doc) {\n          if (error != null) {\n            return done();\n          }\n          if (err != null) {\n            if (err.name === 'MongoCursorExhaustedError') {\n              // We may end up calling `next()` multiple times on an exhausted\n              // cursor, which leads to an error. In case cursor is exhausted,\n              // just treat it as if the cursor returned no document, which is\n              // how a cursor indicates it is exhausted.\n              doc = null;\n            } else if (continueOnError) {\n              aggregatedErrors.push(err);\n            } else {\n              error = err;\n              finalCallback(err);\n              return done();\n            }\n          }\n          if (doc == null) {\n            drained = true;\n            if (handleResultsInProgress <= 0) {\n              const finalErr = continueOnError ?\n                createEachAsyncMultiError(aggregatedErrors) :\n                error;\n\n              finalCallback(finalErr);\n            } else if (batchSize && documentsBatch.length) {\n              handleNextResult(documentsBatch, currentDocumentIndex++, handleNextResultCallBack);\n            }\n            return done();\n          }\n\n          ++handleResultsInProgress;\n\n          // Kick off the subsequent `next()` before handling the result, but\n          // make sure we know that we still have a result to handle re: #8422\n          immediate(() => done());\n\n          if (batchSize) {\n            documentsBatch.push(doc);\n          }\n\n          // If the current documents size is less than the provided batch size don't process the documents yet\n          if (batchSize && documentsBatch.length !== batchSize) {\n            immediate(() => enqueue(fetch));\n            return;\n          }\n\n          const docsToProcess = batchSize ? documentsBatch : doc;\n\n          function handleNextResultCallBack(err) {\n            if (batchSize) {\n              handleResultsInProgress -= documentsBatch.length;\n              documentsBatch = [];\n            } else {\n              --handleResultsInProgress;\n            }\n            if (err != null) {\n              if (continueOnError) {\n                aggregatedErrors.push(err);\n              } else {\n                error = err;\n                return finalCallback(err);\n              }\n            }\n            if ((drained || aborted) && handleResultsInProgress <= 0) {\n              const finalErr = continueOnError ?\n                createEachAsyncMultiError(aggregatedErrors) :\n                error;\n              return finalCallback(finalErr);\n            }\n\n            immediate(() => enqueue(fetch));\n          }\n\n          handleNextResult(docsToProcess, currentDocumentIndex++, handleNextResultCallBack);\n        });\n      }\n    }\n  }\n\n  function handleNextResult(doc, i, callback) {\n    let maybePromise;\n    try {\n      maybePromise = fn(doc, i);\n    } catch (err) {\n      return callback(err);\n    }\n    if (maybePromise && typeof maybePromise.then === 'function') {\n      maybePromise.then(\n        function() { callback(null); },\n        function(error) {\n          callback(error || new Error('`eachAsync()` promise rejected without error'));\n        });\n    } else {\n      callback(null);\n    }\n  }\n};\n\n// `next()` can only execute one at a time, so make sure we always execute\n// `next()` in series, while still allowing multiple `fn()` instances to run\n// in parallel.\nfunction asyncQueue() {\n  const _queue = [];\n  let inProgress = null;\n  let id = 0;\n\n  return function enqueue(fn) {\n    if (\n      inProgress === null &&\n      _queue.length === 0\n    ) {\n      inProgress = id++;\n      return fn(_step);\n    }\n    _queue.push(fn);\n  };\n\n  function _step() {\n    if (_queue.length !== 0) {\n      inProgress = id++;\n      const fn = _queue.shift();\n      fn(_step);\n    } else {\n      inProgress = null;\n    }\n  }\n}\n\nfunction createEachAsyncMultiError(aggregatedErrors) {\n  if (aggregatedErrors.length === 0) {\n    return null;\n  }\n\n  return new EachAsyncMultiError(aggregatedErrors);\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/cursor/eachAsync.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/discriminator/applyEmbeddedDiscriminators.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/discriminator/applyEmbeddedDiscriminators.js ***!
  \****************************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = applyEmbeddedDiscriminators;\n\nfunction applyEmbeddedDiscriminators(schema, seen = new WeakSet(), overwriteExisting = false) {\n  if (seen.has(schema)) {\n    return;\n  }\n  seen.add(schema);\n  for (const path of Object.keys(schema.paths)) {\n    const schemaType = schema.paths[path];\n    if (!schemaType.schema) {\n      continue;\n    }\n    applyEmbeddedDiscriminators(schemaType.schema, seen);\n    if (!schemaType.schema._applyDiscriminators) {\n      continue;\n    }\n    if (schemaType._appliedDiscriminators && !overwriteExisting) {\n      continue;\n    }\n    for (const discriminatorKey of schemaType.schema._applyDiscriminators.keys()) {\n      const {\n        schema: discriminatorSchema,\n        options\n      } = schemaType.schema._applyDiscriminators.get(discriminatorKey);\n      applyEmbeddedDiscriminators(discriminatorSchema, seen);\n      schemaType.discriminator(\n        discriminatorKey,\n        discriminatorSchema,\n        overwriteExisting ? { ...options, overwriteExisting: true } : options\n      );\n    }\n    schemaType._appliedDiscriminators = true;\n  }\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/discriminator/applyEmbeddedDiscriminators.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/discriminator/areDiscriminatorValuesEqual.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/discriminator/areDiscriminatorValuesEqual.js ***!
  \****************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst isBsonType = __webpack_require__(/*! ../isBsonType */ \"./node_modules/mongoose/lib/helpers/isBsonType.js\");\n\nmodule.exports = function areDiscriminatorValuesEqual(a, b) {\n  if (typeof a === 'string' && typeof b === 'string') {\n    return a === b;\n  }\n  if (typeof a === 'number' && typeof b === 'number') {\n    return a === b;\n  }\n  if (isBsonType(a, 'ObjectId') && isBsonType(b, 'ObjectId')) {\n    return a.toString() === b.toString();\n  }\n  return false;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/discriminator/areDiscriminatorValuesEqual.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/discriminator/checkEmbeddedDiscriminatorKeyProjection.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/discriminator/checkEmbeddedDiscriminatorKeyProjection.js ***!
  \****************************************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function checkEmbeddedDiscriminatorKeyProjection(userProjection, path, schema, selected, addedPaths) {\n  const userProjectedInPath = Object.keys(userProjection).\n    reduce((cur, key) => cur || key.startsWith(path + '.'), false);\n  const _discriminatorKey = path + '.' + schema.options.discriminatorKey;\n  if (!userProjectedInPath &&\n      addedPaths.length === 1 &&\n      addedPaths[0] === _discriminatorKey) {\n    selected.splice(selected.indexOf(_discriminatorKey), 1);\n  }\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/discriminator/checkEmbeddedDiscriminatorKeyProjection.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/discriminator/getConstructor.js":
/*!***************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/discriminator/getConstructor.js ***!
  \***************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst getDiscriminatorByValue = __webpack_require__(/*! ./getDiscriminatorByValue */ \"./node_modules/mongoose/lib/helpers/discriminator/getDiscriminatorByValue.js\");\n\n/**\n * Find the correct constructor, taking into account discriminators\n * @api private\n */\n\nmodule.exports = function getConstructor(Constructor, value, defaultDiscriminatorValue) {\n  const discriminatorKey = Constructor.schema.options.discriminatorKey;\n  let discriminatorValue = (value != null && value[discriminatorKey]);\n  if (discriminatorValue == null) {\n    discriminatorValue = defaultDiscriminatorValue;\n  }\n  if (Constructor.discriminators &&\n      discriminatorValue != null) {\n    if (Constructor.discriminators[discriminatorValue]) {\n      Constructor = Constructor.discriminators[discriminatorValue];\n    } else {\n      const constructorByValue = getDiscriminatorByValue(Constructor.discriminators, discriminatorValue);\n      if (constructorByValue) {\n        Constructor = constructorByValue;\n      }\n    }\n  }\n\n  return Constructor;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/discriminator/getConstructor.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/discriminator/getDiscriminatorByValue.js":
/*!************************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/discriminator/getDiscriminatorByValue.js ***!
  \************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst areDiscriminatorValuesEqual = __webpack_require__(/*! ./areDiscriminatorValuesEqual */ \"./node_modules/mongoose/lib/helpers/discriminator/areDiscriminatorValuesEqual.js\");\n\n/**\n * returns discriminator by discriminatorMapping.value\n *\n * @param {Object} discriminators\n * @param {string} value\n * @api private\n */\n\nmodule.exports = function getDiscriminatorByValue(discriminators, value) {\n  if (discriminators == null) {\n    return null;\n  }\n  for (const name of Object.keys(discriminators)) {\n    const it = discriminators[name];\n    if (\n      it.schema &&\n      it.schema.discriminatorMapping &&\n      areDiscriminatorValuesEqual(it.schema.discriminatorMapping.value, value)\n    ) {\n      return it;\n    }\n  }\n  return null;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/discriminator/getDiscriminatorByValue.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/discriminator/getSchemaDiscriminatorByValue.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/discriminator/getSchemaDiscriminatorByValue.js ***!
  \******************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst areDiscriminatorValuesEqual = __webpack_require__(/*! ./areDiscriminatorValuesEqual */ \"./node_modules/mongoose/lib/helpers/discriminator/areDiscriminatorValuesEqual.js\");\n\n/**\n * returns discriminator by discriminatorMapping.value\n *\n * @param {Schema} schema\n * @param {string} value\n * @api private\n */\n\nmodule.exports = function getSchemaDiscriminatorByValue(schema, value) {\n  if (schema == null || schema.discriminators == null) {\n    return null;\n  }\n  for (const key of Object.keys(schema.discriminators)) {\n    const discriminatorSchema = schema.discriminators[key];\n    if (discriminatorSchema.discriminatorMapping == null) {\n      continue;\n    }\n    if (areDiscriminatorValuesEqual(discriminatorSchema.discriminatorMapping.value, value)) {\n      return discriminatorSchema;\n    }\n  }\n  return null;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/discriminator/getSchemaDiscriminatorByValue.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/discriminator/mergeDiscriminatorSchema.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/discriminator/mergeDiscriminatorSchema.js ***!
  \*************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst schemaMerge = __webpack_require__(/*! ../schema/merge */ \"./node_modules/mongoose/lib/helpers/schema/merge.js\");\nconst specialProperties = __webpack_require__(/*! ../../helpers/specialProperties */ \"./node_modules/mongoose/lib/helpers/specialProperties.js\");\nconst isBsonType = __webpack_require__(/*! ../../helpers/isBsonType */ \"./node_modules/mongoose/lib/helpers/isBsonType.js\");\nconst ObjectId = __webpack_require__(/*! ../../types/objectid */ \"./node_modules/mongoose/lib/types/objectid.js\");\nconst isObject = __webpack_require__(/*! ../../helpers/isObject */ \"./node_modules/mongoose/lib/helpers/isObject.js\");\n/**\n * Merges `from` into `to` without overwriting existing properties.\n *\n * @param {Object} to\n * @param {Object} from\n * @param {String} [path]\n * @api private\n */\n\nmodule.exports = function mergeDiscriminatorSchema(to, from, path, seen) {\n  const keys = Object.keys(from);\n  let i = 0;\n  const len = keys.length;\n  let key;\n\n  path = path || '';\n  seen = seen || new WeakSet();\n\n  if (seen.has(from)) {\n    return;\n  }\n  seen.add(from);\n\n  while (i < len) {\n    key = keys[i++];\n    if (!path) {\n      if (key === 'discriminators' ||\n        key === 'base' ||\n        key === '_applyDiscriminators' ||\n        key === '_userProvidedOptions' ||\n        key === 'options' ||\n        key === 'tree') {\n        continue;\n      }\n    }\n    if (path === 'tree' && from != null && from.instanceOfSchema) {\n      continue;\n    }\n    if (specialProperties.has(key)) {\n      continue;\n    }\n    if (to[key] == null) {\n      to[key] = from[key];\n    } else if (isObject(from[key])) {\n      if (!isObject(to[key])) {\n        to[key] = {};\n      }\n      if (from[key] != null) {\n        // Skip merging schemas if we're creating a discriminator schema and\n        // base schema has a given path as a single nested but discriminator schema\n        // has the path as a document array, or vice versa (gh-9534)\n        if ((from[key].$isSingleNested && to[key].$isMongooseDocumentArray) ||\n              (from[key].$isMongooseDocumentArray && to[key].$isSingleNested) ||\n              (from[key].$isMongooseDocumentArrayElement && to[key].$isMongooseDocumentArrayElement)) {\n          continue;\n        } else if (from[key].instanceOfSchema) {\n          if (to[key].instanceOfSchema) {\n            schemaMerge(to[key], from[key].clone(), true);\n          } else {\n            to[key] = from[key].clone();\n          }\n          continue;\n        } else if (isBsonType(from[key], 'ObjectId')) {\n          to[key] = new ObjectId(from[key]);\n          continue;\n        }\n      }\n      mergeDiscriminatorSchema(to[key], from[key], path ? path + '.' + key : key, seen);\n    }\n  }\n\n  if (from != null && from.instanceOfSchema) {\n    to.tree = Object.assign({}, from.tree, to.tree);\n  }\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/discriminator/mergeDiscriminatorSchema.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/document/applyDefaults.js":
/*!*********************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/document/applyDefaults.js ***!
  \*********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst isNestedProjection = __webpack_require__(/*! ../projection/isNestedProjection */ \"./node_modules/mongoose/lib/helpers/projection/isNestedProjection.js\");\n\nmodule.exports = function applyDefaults(doc, fields, exclude, hasIncludedChildren, isBeforeSetters, pathsToSkip, options) {\n  const paths = Object.keys(doc.$__schema.paths);\n  const plen = paths.length;\n  const skipParentChangeTracking = options && options.skipParentChangeTracking;\n\n  for (let i = 0; i < plen; ++i) {\n    let def;\n    let curPath = '';\n    const p = paths[i];\n\n    if (p === '_id' && doc.$__.skipId) {\n      continue;\n    }\n\n    const type = doc.$__schema.paths[p];\n    const path = type.splitPath();\n    const len = path.length;\n    let included = false;\n    let doc_ = doc._doc;\n    for (let j = 0; j < len; ++j) {\n      if (doc_ == null) {\n        break;\n      }\n\n      const piece = path[j];\n      curPath += (!curPath.length ? '' : '.') + piece;\n\n      if (exclude === true) {\n        if (curPath in fields) {\n          break;\n        }\n      } else if (exclude === false && fields && !included) {\n        const hasSubpaths = type.$isSingleNested || type.$isMongooseDocumentArray;\n        if ((curPath in fields && !isNestedProjection(fields[curPath])) || (j === len - 1 && hasSubpaths && hasIncludedChildren != null && hasIncludedChildren[curPath])) {\n          included = true;\n        } else if (hasIncludedChildren != null && !hasIncludedChildren[curPath]) {\n          break;\n        }\n      }\n\n      if (j === len - 1) {\n        if (doc_[piece] !== void 0) {\n          break;\n        }\n\n        if (isBeforeSetters != null) {\n          if (typeof type.defaultValue === 'function') {\n            if (!type.defaultValue.$runBeforeSetters && isBeforeSetters) {\n              break;\n            }\n            if (type.defaultValue.$runBeforeSetters && !isBeforeSetters) {\n              break;\n            }\n          } else if (!isBeforeSetters) {\n            // Non-function defaults should always run **before** setters\n            continue;\n          }\n        }\n\n        if (pathsToSkip && pathsToSkip[curPath]) {\n          break;\n        }\n\n        if (fields && exclude !== null) {\n          if (exclude === true) {\n            // apply defaults to all non-excluded fields\n            if (p in fields) {\n              continue;\n            }\n\n            try {\n              def = type.getDefault(doc, false);\n            } catch (err) {\n              doc.invalidate(p, err);\n              break;\n            }\n\n            if (typeof def !== 'undefined') {\n              doc_[piece] = def;\n              applyChangeTracking(doc, p, skipParentChangeTracking);\n            }\n          } else if (included) {\n            // selected field\n            try {\n              def = type.getDefault(doc, false);\n            } catch (err) {\n              doc.invalidate(p, err);\n              break;\n            }\n\n            if (typeof def !== 'undefined') {\n              doc_[piece] = def;\n              applyChangeTracking(doc, p, skipParentChangeTracking);\n            }\n          }\n        } else {\n          try {\n            def = type.getDefault(doc, false);\n          } catch (err) {\n            doc.invalidate(p, err);\n            break;\n          }\n\n          if (typeof def !== 'undefined') {\n            doc_[piece] = def;\n            applyChangeTracking(doc, p, skipParentChangeTracking);\n          }\n        }\n      } else {\n        doc_ = doc_[piece];\n      }\n    }\n  }\n};\n\n/*!\n * ignore\n */\n\nfunction applyChangeTracking(doc, fullPath, skipParentChangeTracking) {\n  doc.$__.activePaths.default(fullPath);\n  if (!skipParentChangeTracking && doc.$isSubdocument && doc.$isSingleNested && doc.$parent() != null) {\n    doc.$parent().$__.activePaths.default(doc.$__pathRelativeToParent(fullPath));\n  }\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/document/applyDefaults.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/document/cleanModifiedSubpaths.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/document/cleanModifiedSubpaths.js ***!
  \*****************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/*!\n * ignore\n */\n\nmodule.exports = function cleanModifiedSubpaths(doc, path, options) {\n  options = options || {};\n  const skipDocArrays = options.skipDocArrays;\n\n  let deleted = 0;\n  if (!doc) {\n    return deleted;\n  }\n\n  for (const modifiedPath of Object.keys(doc.$__.activePaths.getStatePaths('modify'))) {\n    if (skipDocArrays) {\n      const schemaType = doc.$__schema.path(modifiedPath);\n      if (schemaType && schemaType.$isMongooseDocumentArray) {\n        continue;\n      }\n    }\n    if (modifiedPath.startsWith(path + '.')) {\n      doc.$__.activePaths.clearPath(modifiedPath);\n      ++deleted;\n\n      if (doc.$isSubdocument) {\n        const owner = doc.ownerDocument();\n        const fullPath = doc.$__fullPath(modifiedPath);\n        owner.$__.activePaths.clearPath(fullPath);\n      }\n    }\n  }\n  return deleted;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/document/cleanModifiedSubpaths.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/document/compile.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/document/compile.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nconst clone = __webpack_require__(/*! ../../helpers/clone */ \"./node_modules/mongoose/lib/helpers/clone.js\");\nconst documentSchemaSymbol = (__webpack_require__(/*! ../../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").documentSchemaSymbol);\nconst internalToObjectOptions = (__webpack_require__(/*! ../../options */ \"./node_modules/mongoose/lib/options.js\").internalToObjectOptions);\nconst utils = __webpack_require__(/*! ../../utils */ \"./node_modules/mongoose/lib/utils.js\");\n\nlet Document;\nconst getSymbol = (__webpack_require__(/*! ../../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").getSymbol);\nconst scopeSymbol = (__webpack_require__(/*! ../../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").scopeSymbol);\n\nconst isPOJO = utils.isPOJO;\n\n/*!\n * exports\n */\n\nexports.compile = compile;\nexports.defineKey = defineKey;\n\nconst _isEmptyOptions = Object.freeze({\n  minimize: true,\n  virtuals: false,\n  getters: false,\n  transform: false\n});\n\nconst noDottedPathGetOptions = Object.freeze({\n  noDottedPath: true\n});\n\n/**\n * Compiles schemas.\n * @param {Object} tree\n * @param {Any} proto\n * @param {String} prefix\n * @param {Object} options\n * @api private\n */\n\nfunction compile(tree, proto, prefix, options) {\n  Document = Document || __webpack_require__(/*! ../../document */ \"./node_modules/mongoose/lib/document.js\");\n  const typeKey = options.typeKey;\n\n  for (const key of Object.keys(tree)) {\n    const limb = tree[key];\n\n    const hasSubprops = isPOJO(limb) &&\n      Object.keys(limb).length > 0 &&\n      (!limb[typeKey] || (typeKey === 'type' && isPOJO(limb.type) && limb.type.type));\n    const subprops = hasSubprops ? limb : null;\n\n    defineKey({ prop: key, subprops: subprops, prototype: proto, prefix: prefix, options: options });\n  }\n}\n\n/**\n * Defines the accessor named prop on the incoming prototype.\n * @param {Object} options\n * @param {String} options.prop\n * @param {Boolean} options.subprops\n * @param {Any} options.prototype\n * @param {String} [options.prefix]\n * @param {Object} options.options\n * @api private\n */\n\nfunction defineKey({ prop, subprops, prototype, prefix, options }) {\n  Document = Document || __webpack_require__(/*! ../../document */ \"./node_modules/mongoose/lib/document.js\");\n  const path = (prefix ? prefix + '.' : '') + prop;\n  prefix = prefix || '';\n  const useGetOptions = prefix ? Object.freeze({}) : noDottedPathGetOptions;\n\n  if (subprops) {\n    Object.defineProperty(prototype, prop, {\n      enumerable: true,\n      configurable: true,\n      get: function() {\n        const _this = this;\n        if (!this.$__.getters) {\n          this.$__.getters = {};\n        }\n\n        if (!this.$__.getters[path]) {\n          const nested = Object.create(Document.prototype, getOwnPropertyDescriptors(this));\n\n          // save scope for nested getters/setters\n          if (!prefix) {\n            nested.$__[scopeSymbol] = this;\n          }\n          nested.$__.nestedPath = path;\n\n          Object.defineProperty(nested, 'schema', {\n            enumerable: false,\n            configurable: true,\n            writable: false,\n            value: prototype.schema\n          });\n\n          Object.defineProperty(nested, '$__schema', {\n            enumerable: false,\n            configurable: true,\n            writable: false,\n            value: prototype.schema\n          });\n\n          Object.defineProperty(nested, documentSchemaSymbol, {\n            enumerable: false,\n            configurable: true,\n            writable: false,\n            value: prototype.schema\n          });\n\n          Object.defineProperty(nested, 'toObject', {\n            enumerable: false,\n            configurable: true,\n            writable: false,\n            value: function() {\n              return clone(_this.get(path, null, {\n                virtuals: this &&\n                  this.schema &&\n                  this.schema.options &&\n                  this.schema.options.toObject &&\n                  this.schema.options.toObject.virtuals || null\n              }));\n            }\n          });\n\n          Object.defineProperty(nested, '$__get', {\n            enumerable: false,\n            configurable: true,\n            writable: false,\n            value: function() {\n              return _this.get(path, null, {\n                virtuals: this && this.schema && this.schema.options && this.schema.options.toObject && this.schema.options.toObject.virtuals || null\n              });\n            }\n          });\n\n          Object.defineProperty(nested, 'toJSON', {\n            enumerable: false,\n            configurable: true,\n            writable: false,\n            value: function() {\n              return _this.get(path, null, {\n                virtuals: this && this.schema && this.schema.options && this.schema.options.toJSON && this.schema.options.toJSON.virtuals || null\n              });\n            }\n          });\n\n          Object.defineProperty(nested, '$__isNested', {\n            enumerable: false,\n            configurable: true,\n            writable: false,\n            value: true\n          });\n\n          Object.defineProperty(nested, '$isEmpty', {\n            enumerable: false,\n            configurable: true,\n            writable: false,\n            value: function() {\n              return Object.keys(this.get(path, null, _isEmptyOptions) || {}).length === 0;\n            }\n          });\n\n          Object.defineProperty(nested, '$__parent', {\n            enumerable: false,\n            configurable: true,\n            writable: false,\n            value: this\n          });\n\n          compile(subprops, nested, path, options);\n          this.$__.getters[path] = nested;\n        }\n\n        return this.$__.getters[path];\n      },\n      set: function(v) {\n        if (v != null && v.$__isNested) {\n          // Convert top-level to POJO, but leave subdocs hydrated so `$set`\n          // can handle them. See gh-9293.\n          v = v.$__get();\n        } else if (v instanceof Document && !v.$__isNested) {\n          v = v.$toObject(internalToObjectOptions);\n        }\n        const doc = this.$__[scopeSymbol] || this;\n        doc.$set(path, v);\n      }\n    });\n  } else {\n    Object.defineProperty(prototype, prop, {\n      enumerable: true,\n      configurable: true,\n      get: function() {\n        return this[getSymbol].call(\n          this.$__[scopeSymbol] || this,\n          path,\n          null,\n          useGetOptions\n        );\n      },\n      set: function(v) {\n        this.$set.call(this.$__[scopeSymbol] || this, path, v);\n      }\n    });\n  }\n}\n\n// gets descriptors for all properties of `object`\n// makes all properties non-enumerable to match previous behavior to #2211\nfunction getOwnPropertyDescriptors(object) {\n  const result = {};\n\n  Object.getOwnPropertyNames(object).forEach(function(key) {\n    const skip = [\n      'isNew',\n      '$__',\n      '$errors',\n      'errors',\n      '_doc',\n      '$locals',\n      '$op',\n      '__parentArray',\n      '__index',\n      '$isDocumentArrayElement'\n    ].indexOf(key) === -1;\n    if (skip) {\n      return;\n    }\n\n    result[key] = Object.getOwnPropertyDescriptor(object, key);\n    result[key].enumerable = false;\n  });\n\n  return result;\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/document/compile.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/document/getDeepestSubdocumentForPath.js":
/*!************************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/document/getDeepestSubdocumentForPath.js ***!
  \************************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/**\n * Find the deepest subdocument along a given path to ensure setter functions run\n * with the correct subdocument as `this`. If no subdocuments, returns the top-level\n * document.\n *\n * @param {Document} doc\n * @param {String[]} parts\n * @param {Schema} schema\n * @returns Document\n */\n\nmodule.exports = function getDeepestSubdocumentForPath(doc, parts, schema) {\n  let curPath = parts[0];\n  let curSchema = schema;\n  let subdoc = doc;\n  for (let i = 0; i < parts.length - 1; ++i) {\n    const curSchemaType = curSchema.path(curPath);\n    if (curSchemaType && curSchemaType.schema) {\n      let newSubdoc = subdoc.get(curPath);\n      curSchema = curSchemaType.schema;\n      curPath = parts[i + 1];\n      if (Array.isArray(newSubdoc) && !isNaN(curPath)) {\n        newSubdoc = newSubdoc[curPath];\n        curPath = '';\n      }\n      if (newSubdoc == null) {\n        break;\n      }\n      subdoc = newSubdoc;\n    } else {\n      curPath += curPath.length ? '.' + parts[i + 1] : parts[i + 1];\n    }\n  }\n\n  return subdoc;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/document/getDeepestSubdocumentForPath.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/document/getEmbeddedDiscriminatorPath.js":
/*!************************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/document/getEmbeddedDiscriminatorPath.js ***!
  \************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst get = __webpack_require__(/*! ../get */ \"./node_modules/mongoose/lib/helpers/get.js\");\nconst getSchemaDiscriminatorByValue = __webpack_require__(/*! ../discriminator/getSchemaDiscriminatorByValue */ \"./node_modules/mongoose/lib/helpers/discriminator/getSchemaDiscriminatorByValue.js\");\n\n/**\n * Like `schema.path()`, except with a document, because impossible to\n * determine path type without knowing the embedded discriminator key.\n *\n * @param {Document} doc\n * @param {String|String[]} path\n * @param {Object} [options]\n * @api private\n */\n\nmodule.exports = function getEmbeddedDiscriminatorPath(doc, path, options) {\n  options = options || {};\n  const typeOnly = options.typeOnly;\n  const parts = Array.isArray(path) ?\n    path :\n    (path.indexOf('.') === -1 ? [path] : path.split('.'));\n  let schemaType = null;\n  let type = 'adhocOrUndefined';\n\n  const schema = getSchemaDiscriminatorByValue(doc.schema, doc.get(doc.schema.options.discriminatorKey)) || doc.schema;\n\n  for (let i = 0; i < parts.length; ++i) {\n    const subpath = parts.slice(0, i + 1).join('.');\n    schemaType = schema.path(subpath);\n    if (schemaType == null) {\n      type = 'adhocOrUndefined';\n      continue;\n    }\n    if (schemaType.instance === 'Mixed') {\n      return typeOnly ? 'real' : schemaType;\n    }\n    type = schema.pathType(subpath);\n    if ((schemaType.$isSingleNested || schemaType.$isMongooseDocumentArrayElement) &&\n    schemaType.schema.discriminators != null) {\n      const discriminators = schemaType.schema.discriminators;\n      const discriminatorKey = doc.get(subpath + '.' +\n        get(schemaType, 'schema.options.discriminatorKey'));\n      if (discriminatorKey == null || discriminators[discriminatorKey] == null) {\n        continue;\n      }\n      const rest = parts.slice(i + 1).join('.');\n      return getEmbeddedDiscriminatorPath(doc.get(subpath), rest, options);\n    }\n  }\n\n  // Are we getting the whole schema or just the type, 'real', 'nested', etc.\n  return typeOnly ? type : schemaType;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/document/getEmbeddedDiscriminatorPath.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/document/handleSpreadDoc.js":
/*!***********************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/document/handleSpreadDoc.js ***!
  \***********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst utils = __webpack_require__(/*! ../../utils */ \"./node_modules/mongoose/lib/utils.js\");\n\nconst keysToSkip = new Set(['__index', '__parentArray', '_doc']);\n\n/**\n * Using spread operator on a Mongoose document gives you a\n * POJO that has a tendency to cause infinite recursion. So\n * we use this function on `set()` to prevent that.\n */\n\nmodule.exports = function handleSpreadDoc(v, includeExtraKeys) {\n  if (utils.isPOJO(v) && v.$__ != null && v._doc != null) {\n    if (includeExtraKeys) {\n      const extraKeys = {};\n      for (const key of Object.keys(v)) {\n        if (typeof key === 'symbol') {\n          continue;\n        }\n        if (key[0] === '$') {\n          continue;\n        }\n        if (keysToSkip.has(key)) {\n          continue;\n        }\n        extraKeys[key] = v[key];\n      }\n      return { ...v._doc, ...extraKeys };\n    }\n    return v._doc;\n  }\n\n  return v;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/document/handleSpreadDoc.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/each.js":
/*!***************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/each.js ***!
  \***************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function each(arr, cb, done) {\n  if (arr.length === 0) {\n    return done();\n  }\n\n  let remaining = arr.length;\n  let err = null;\n  for (const v of arr) {\n    cb(v, function(_err) {\n      if (err != null) {\n        return;\n      }\n      if (_err != null) {\n        err = _err;\n        return done(err);\n      }\n\n      if (--remaining <= 0) {\n        return done();\n      }\n    });\n  }\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/each.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/error/combinePathErrors.js":
/*!**********************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/error/combinePathErrors.js ***!
  \**********************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/*!\n * ignore\n */\n\nmodule.exports = function combinePathErrors(err) {\n  const keys = Object.keys(err.errors || {});\n  const len = keys.length;\n  const msgs = [];\n  let key;\n\n  for (let i = 0; i < len; ++i) {\n    key = keys[i];\n    if (err === err.errors[key]) {\n      continue;\n    }\n    msgs.push(key + ': ' + err.errors[key].message);\n  }\n\n  return msgs.join(', ');\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/error/combinePathErrors.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/firstKey.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/firstKey.js ***!
  \*******************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function firstKey(obj) {\n  if (obj == null) {\n    return null;\n  }\n  return Object.keys(obj)[0];\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/firstKey.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/get.js":
/*!**************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/get.js ***!
  \**************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/**\n * Simplified lodash.get to work around the annoying null quirk. See:\n * https://github.com/lodash/lodash/issues/3659\n * @api private\n */\n\nmodule.exports = function get(obj, path, def) {\n  let parts;\n  let isPathArray = false;\n  if (typeof path === 'string') {\n    if (path.indexOf('.') === -1) {\n      const _v = getProperty(obj, path);\n      if (_v == null) {\n        return def;\n      }\n      return _v;\n    }\n\n    parts = path.split('.');\n  } else {\n    isPathArray = true;\n    parts = path;\n\n    if (parts.length === 1) {\n      const _v = getProperty(obj, parts[0]);\n      if (_v == null) {\n        return def;\n      }\n      return _v;\n    }\n  }\n  let rest = path;\n  let cur = obj;\n  for (const part of parts) {\n    if (cur == null) {\n      return def;\n    }\n\n    // `lib/cast.js` depends on being able to get dotted paths in updates,\n    // like `{ $set: { 'a.b': 42 } }`\n    if (!isPathArray && cur[rest] != null) {\n      return cur[rest];\n    }\n\n    cur = getProperty(cur, part);\n\n    if (!isPathArray) {\n      rest = rest.substr(part.length + 1);\n    }\n  }\n\n  return cur == null ? def : cur;\n};\n\nfunction getProperty(obj, prop) {\n  if (obj == null) {\n    return obj;\n  }\n  if (obj instanceof Map) {\n    return obj.get(prop);\n  }\n  return obj[prop];\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/get.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/getConstructorName.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/getConstructorName.js ***!
  \*****************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/**\n * If `val` is an object, returns constructor name, if possible. Otherwise returns undefined.\n * @api private\n */\n\nmodule.exports = function getConstructorName(val) {\n  if (val == null) {\n    return void 0;\n  }\n  if (typeof val.constructor !== 'function') {\n    return void 0;\n  }\n  return val.constructor.name;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/getConstructorName.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/getDefaultBulkwriteResult.js":
/*!************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/getDefaultBulkwriteResult.js ***!
  \************************************************************************/
/***/ ((module) => {

"use strict";
eval("\nfunction getDefaultBulkwriteResult() {\n  return {\n    result: {\n      ok: 1,\n      writeErrors: [],\n      writeConcernErrors: [],\n      insertedIds: [],\n      nInserted: 0,\n      nUpserted: 0,\n      nMatched: 0,\n      nModified: 0,\n      nRemoved: 0,\n      upserted: []\n    },\n    insertedCount: 0,\n    matchedCount: 0,\n    modifiedCount: 0,\n    deletedCount: 0,\n    upsertedCount: 0,\n    upsertedIds: {},\n    insertedIds: {},\n    n: 0\n  };\n}\n\nmodule.exports = getDefaultBulkwriteResult;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/getDefaultBulkwriteResult.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/getFunctionName.js":
/*!**************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/getFunctionName.js ***!
  \**************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nconst functionNameRE = /^function\\s*([^\\s(]+)/;\n\nmodule.exports = function(fn) {\n  return (\n    fn.name ||\n    (fn.toString().trim().match(functionNameRE) || [])[1]\n  );\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/getFunctionName.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/immediate.js":
/*!********************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/immediate.js ***!
  \********************************************************/
/***/ ((module) => {

"use strict";
eval("/*!\n * Centralize this so we can more easily work around issues with people\n * stubbing out `process.nextTick()` in tests using sinon:\n * https://github.com/sinonjs/lolex#automatically-incrementing-mocked-time\n * See gh-6074\n */\n\n\n\nconst nextTick = typeof process !== 'undefined' && typeof process.nextTick === 'function' ?\n  process.nextTick.bind(process) :\n  cb => setTimeout(cb, 0); // Fallback for browser build\n\nmodule.exports = function immediate(cb) {\n  return nextTick(cb);\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/immediate.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/indexes/applySchemaCollation.js":
/*!***************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/indexes/applySchemaCollation.js ***!
  \***************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst isTextIndex = __webpack_require__(/*! ./isTextIndex */ \"./node_modules/mongoose/lib/helpers/indexes/isTextIndex.js\");\n\nmodule.exports = function applySchemaCollation(indexKeys, indexOptions, schemaOptions) {\n  if (isTextIndex(indexKeys)) {\n    return;\n  }\n\n  if (schemaOptions.hasOwnProperty('collation') && !indexOptions.hasOwnProperty('collation')) {\n    indexOptions.collation = schemaOptions.collation;\n  }\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/indexes/applySchemaCollation.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/indexes/decorateDiscriminatorIndexOptions.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/indexes/decorateDiscriminatorIndexOptions.js ***!
  \****************************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function decorateDiscriminatorIndexOptions(schema, indexOptions) {\n  // If the model is a discriminator and has an index, add a\n  // partialFilterExpression by default so the index will only apply\n  // to that discriminator.\n  const discriminatorName = schema.discriminatorMapping && schema.discriminatorMapping.value;\n  if (discriminatorName && !('sparse' in indexOptions)) {\n    const discriminatorKey = schema.options.discriminatorKey;\n    indexOptions.partialFilterExpression = indexOptions.partialFilterExpression || {};\n    indexOptions.partialFilterExpression[discriminatorKey] = discriminatorName;\n  }\n  return indexOptions;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/indexes/decorateDiscriminatorIndexOptions.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/indexes/getRelatedIndexes.js":
/*!************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/indexes/getRelatedIndexes.js ***!
  \************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst hasDollarKeys = __webpack_require__(/*! ../query/hasDollarKeys */ \"./node_modules/mongoose/lib/helpers/query/hasDollarKeys.js\");\n\nfunction getRelatedSchemaIndexes(model, schemaIndexes) {\n  return getRelatedIndexes({\n    baseModelName: model.baseModelName,\n    discriminatorMapping: model.schema.discriminatorMapping,\n    indexes: schemaIndexes,\n    indexesType: 'schema'\n  });\n}\n\nfunction getRelatedDBIndexes(model, dbIndexes) {\n  return getRelatedIndexes({\n    baseModelName: model.baseModelName,\n    discriminatorMapping: model.schema.discriminatorMapping,\n    indexes: dbIndexes,\n    indexesType: 'db'\n  });\n}\n\nmodule.exports = {\n  getRelatedSchemaIndexes,\n  getRelatedDBIndexes\n};\n\nfunction getRelatedIndexes({\n  baseModelName,\n  discriminatorMapping,\n  indexes,\n  indexesType\n}) {\n  const discriminatorKey = discriminatorMapping && discriminatorMapping.key;\n  const discriminatorValue = discriminatorMapping && discriminatorMapping.value;\n\n  if (!discriminatorKey) {\n    return indexes;\n  }\n\n  const isChildDiscriminatorModel = Boolean(baseModelName);\n  if (isChildDiscriminatorModel) {\n    return indexes.filter(index => {\n      const partialFilterExpression = getPartialFilterExpression(index, indexesType);\n      return partialFilterExpression && partialFilterExpression[discriminatorKey] === discriminatorValue;\n    });\n  }\n\n  return indexes.filter(index => {\n    const partialFilterExpression = getPartialFilterExpression(index, indexesType);\n    return !partialFilterExpression\n      || !partialFilterExpression[discriminatorKey]\n      || (hasDollarKeys(partialFilterExpression[discriminatorKey]) && !('$eq' in partialFilterExpression[discriminatorKey]));\n  });\n}\n\nfunction getPartialFilterExpression(index, indexesType) {\n  if (indexesType === 'schema') {\n    const options = index[1];\n    return options && options.partialFilterExpression;\n  }\n  return index.partialFilterExpression;\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/indexes/getRelatedIndexes.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/indexes/isDefaultIdIndex.js":
/*!***********************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/indexes/isDefaultIdIndex.js ***!
  \***********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst get = __webpack_require__(/*! ../get */ \"./node_modules/mongoose/lib/helpers/get.js\");\n\nmodule.exports = function isDefaultIdIndex(index) {\n  if (Array.isArray(index)) {\n    // Mongoose syntax\n    const keys = Object.keys(index[0]);\n    return keys.length === 1 && keys[0] === '_id' && index[0]._id !== 'hashed';\n  }\n\n  if (typeof index !== 'object') {\n    return false;\n  }\n\n  const key = get(index, 'key', {});\n  return Object.keys(key).length === 1 && key.hasOwnProperty('_id');\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/indexes/isDefaultIdIndex.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/indexes/isIndexEqual.js":
/*!*******************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/indexes/isIndexEqual.js ***!
  \*******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst get = __webpack_require__(/*! ../get */ \"./node_modules/mongoose/lib/helpers/get.js\");\nconst utils = __webpack_require__(/*! ../../utils */ \"./node_modules/mongoose/lib/utils.js\");\n/**\n * Given a Mongoose index definition (key + options objects) and a MongoDB server\n * index definition, determine if the two indexes are equal.\n *\n * @param {Object} schemaIndexKeysObject the Mongoose index spec\n * @param {Object} options the Mongoose index definition's options\n * @param {Object} dbIndex the index in MongoDB as returned by `listIndexes()`\n * @api private\n */\n\nmodule.exports = function isIndexEqual(schemaIndexKeysObject, options, dbIndex) {\n  // Special case: text indexes have a special format in the db. For example,\n  // `{ name: 'text' }` becomes:\n  // {\n  //   v: 2,\n  //   key: { _fts: 'text', _ftsx: 1 },\n  //   name: 'name_text',\n  //   ns: 'test.tests',\n  //   background: true,\n  //   weights: { name: 1 },\n  //   default_language: 'english',\n  //   language_override: 'language',\n  //   textIndexVersion: 3\n  // }\n  if (dbIndex.textIndexVersion != null) {\n    delete dbIndex.key._fts;\n    delete dbIndex.key._ftsx;\n    const weights = { ...dbIndex.weights, ...dbIndex.key };\n    if (Object.keys(weights).length !== Object.keys(schemaIndexKeysObject).length) {\n      return false;\n    }\n    for (const prop of Object.keys(weights)) {\n      if (!(prop in schemaIndexKeysObject)) {\n        return false;\n      }\n      const weight = weights[prop];\n      if (weight !== get(options, 'weights.' + prop) && !(weight === 1 && get(options, 'weights.' + prop) == null)) {\n        return false;\n      }\n    }\n\n    if (options['default_language'] !== dbIndex['default_language']) {\n      return dbIndex['default_language'] === 'english' && options['default_language'] == null;\n    }\n\n    return true;\n  }\n\n  const optionKeys = [\n    'unique',\n    'partialFilterExpression',\n    'sparse',\n    'expireAfterSeconds',\n    'collation'\n  ];\n  for (const key of optionKeys) {\n    if (!(key in options) && !(key in dbIndex)) {\n      continue;\n    }\n    if (key === 'collation') {\n      if (options[key] == null || dbIndex[key] == null) {\n        return options[key] == null && dbIndex[key] == null;\n      }\n      const definedKeys = Object.keys(options.collation);\n      const schemaCollation = options.collation;\n      const dbCollation = dbIndex.collation;\n      for (const opt of definedKeys) {\n        if (get(schemaCollation, opt) !== get(dbCollation, opt)) {\n          return false;\n        }\n      }\n    } else if (!utils.deepEqual(options[key], dbIndex[key])) {\n      return false;\n    }\n  }\n\n  const schemaIndexKeys = Object.keys(schemaIndexKeysObject);\n  const dbIndexKeys = Object.keys(dbIndex.key);\n  if (schemaIndexKeys.length !== dbIndexKeys.length) {\n    return false;\n  }\n  for (let i = 0; i < schemaIndexKeys.length; ++i) {\n    if (schemaIndexKeys[i] !== dbIndexKeys[i]) {\n      return false;\n    }\n    if (!utils.deepEqual(schemaIndexKeysObject[schemaIndexKeys[i]], dbIndex.key[dbIndexKeys[i]])) {\n      return false;\n    }\n  }\n\n  return true;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/indexes/isIndexEqual.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/indexes/isTextIndex.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/indexes/isTextIndex.js ***!
  \******************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/**\n * Returns `true` if the given index options have a `text` option.\n */\n\nmodule.exports = function isTextIndex(indexKeys) {\n  let isTextIndex = false;\n  for (const key of Object.keys(indexKeys)) {\n    if (indexKeys[key] === 'text') {\n      isTextIndex = true;\n    }\n  }\n\n  return isTextIndex;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/indexes/isTextIndex.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/isAsyncFunction.js":
/*!**************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/isAsyncFunction.js ***!
  \**************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function isAsyncFunction(v) {\n  return (\n    typeof v === 'function' &&\n    v.constructor &&\n    v.constructor.name === 'AsyncFunction'\n  );\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/isAsyncFunction.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/isBsonType.js":
/*!*********************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/isBsonType.js ***!
  \*********************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/**\n * Get the bson type, if it exists\n * @api private\n */\n\nfunction isBsonType(obj, typename) {\n  return (\n    typeof obj === 'object' &&\n    obj !== null &&\n    obj._bsontype === typename\n  );\n}\n\nmodule.exports = isBsonType;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/isBsonType.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/isMongooseObject.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/isMongooseObject.js ***!
  \***************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst isMongooseArray = (__webpack_require__(/*! ../types/array/isMongooseArray */ \"./node_modules/mongoose/lib/types/array/isMongooseArray.js\").isMongooseArray);\n/**\n * Returns if `v` is a mongoose object that has a `toObject()` method we can use.\n *\n * This is for compatibility with libs like Date.js which do foolish things to Natives.\n *\n * @param {Any} v\n * @api private\n */\n\nmodule.exports = function(v) {\n  return (\n    v != null && (\n      isMongooseArray(v) || // Array or Document Array\n      v.$__ != null || // Document\n      v.isMongooseBuffer || // Buffer\n      v.$isMongooseMap // Map\n    )\n  );\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/isMongooseObject.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/isObject.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/isObject.js ***!
  \*******************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/**\n * Determines if `arg` is an object.\n *\n * @param {Object|Array|String|Function|RegExp|any} arg\n * @api private\n * @return {Boolean}\n */\n\nmodule.exports = function(arg) {\n  return (\n    Buffer.isBuffer(arg) ||\n    Object.prototype.toString.call(arg) === '[object Object]'\n  );\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/isObject.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/isPOJO.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/isPOJO.js ***!
  \*****************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function isPOJO(arg) {\n  if (arg == null || typeof arg !== 'object') {\n    return false;\n  }\n  const proto = Object.getPrototypeOf(arg);\n  // Prototype may be null if you used `Object.create(null)`\n  // Checking `proto`'s constructor is safe because `getPrototypeOf()`\n  // explicitly crosses the boundary from object data to object metadata\n  return !proto || proto.constructor.name === 'Object';\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/isPOJO.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/isPromise.js":
/*!********************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/isPromise.js ***!
  \********************************************************/
/***/ ((module) => {

"use strict";
eval("\nfunction isPromise(val) {\n  return !!val && (typeof val === 'object' || typeof val === 'function') && typeof val.then === 'function';\n}\n\nmodule.exports = isPromise;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/isPromise.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/isSimpleValidator.js":
/*!****************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/isSimpleValidator.js ***!
  \****************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/**\n * Determines if `arg` is a flat object.\n *\n * @param {Object|Array|String|Function|RegExp|any} arg\n * @api private\n * @return {Boolean}\n */\n\nmodule.exports = function isSimpleValidator(obj) {\n  const keys = Object.keys(obj);\n  let result = true;\n  for (let i = 0, len = keys.length; i < len; ++i) {\n    if (typeof obj[keys[i]] === 'object' && obj[keys[i]] !== null) {\n      result = false;\n      break;\n    }\n  }\n\n  return result;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/isSimpleValidator.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/minimize.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/minimize.js ***!
  \*******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst { isPOJO } = __webpack_require__(/*! ../utils */ \"./node_modules/mongoose/lib/utils.js\");\n\nmodule.exports = minimize;\n\n/**\n * Minimizes an object, removing undefined values and empty objects\n *\n * @param {Object} object to minimize\n * @return {Object|undefined}\n * @api private\n */\n\nfunction minimize(obj) {\n  const keys = Object.keys(obj);\n  let i = keys.length;\n  let hasKeys;\n  let key;\n  let val;\n\n  while (i--) {\n    key = keys[i];\n    val = obj[key];\n\n    if (isPOJO(val)) {\n      obj[key] = minimize(val);\n    }\n\n    if (undefined === obj[key]) {\n      delete obj[key];\n      continue;\n    }\n\n    hasKeys = true;\n  }\n\n  return hasKeys\n    ? obj\n    : undefined;\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/minimize.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/model/applyDefaultsToPOJO.js":
/*!************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/model/applyDefaultsToPOJO.js ***!
  \************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function applyDefaultsToPOJO(doc, schema) {\n  const paths = Object.keys(schema.paths);\n  const plen = paths.length;\n\n  for (let i = 0; i < plen; ++i) {\n    let curPath = '';\n    const p = paths[i];\n\n    const type = schema.paths[p];\n    const path = type.splitPath();\n    const len = path.length;\n    let doc_ = doc;\n    for (let j = 0; j < len; ++j) {\n      if (doc_ == null) {\n        break;\n      }\n\n      const piece = path[j];\n      curPath += (!curPath.length ? '' : '.') + piece;\n\n      if (j === len - 1) {\n        if (typeof doc_[piece] !== 'undefined') {\n          if (type.$isSingleNested) {\n            applyDefaultsToPOJO(doc_[piece], type.caster.schema);\n          } else if (type.$isMongooseDocumentArray && Array.isArray(doc_[piece])) {\n            doc_[piece].forEach(el => applyDefaultsToPOJO(el, type.schema));\n          }\n\n          break;\n        }\n\n        const def = type.getDefault(doc, false, { skipCast: true });\n        if (typeof def !== 'undefined') {\n          doc_[piece] = def;\n\n          if (type.$isSingleNested) {\n            applyDefaultsToPOJO(def, type.caster.schema);\n          } else if (type.$isMongooseDocumentArray && Array.isArray(def)) {\n            def.forEach(el => applyDefaultsToPOJO(el, type.schema));\n          }\n        }\n      } else {\n        if (doc_[piece] == null) {\n          doc_[piece] = {};\n        }\n        doc_ = doc_[piece];\n      }\n    }\n  }\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/model/applyDefaultsToPOJO.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/model/applyHooks.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/model/applyHooks.js ***!
  \***************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst symbols = __webpack_require__(/*! ../../schema/symbols */ \"./node_modules/mongoose/lib/schema/symbols.js\");\nconst promiseOrCallback = __webpack_require__(/*! ../promiseOrCallback */ \"./node_modules/mongoose/lib/helpers/promiseOrCallback.js\");\n\n/*!\n * ignore\n */\n\nmodule.exports = applyHooks;\n\n/*!\n * ignore\n */\n\napplyHooks.middlewareFunctions = [\n  'deleteOne',\n  'save',\n  'validate',\n  'remove',\n  'updateOne',\n  'init'\n];\n\n/*!\n * ignore\n */\n\nconst alreadyHookedFunctions = new Set(applyHooks.middlewareFunctions.flatMap(fn => ([fn, `$__${fn}`])));\n\n/**\n * Register hooks for this model\n *\n * @param {Model} model\n * @param {Schema} schema\n * @param {Object} options\n * @api private\n */\n\nfunction applyHooks(model, schema, options) {\n  options = options || {};\n\n  const kareemOptions = {\n    useErrorHandlers: true,\n    numCallbackParams: 1,\n    nullResultByDefault: true,\n    contextParameter: true\n  };\n  const objToDecorate = options.decorateDoc ? model : model.prototype;\n\n  model.$appliedHooks = true;\n  for (const key of Object.keys(schema.paths)) {\n    const type = schema.paths[key];\n    let childModel = null;\n    if (type.$isSingleNested) {\n      childModel = type.caster;\n    } else if (type.$isMongooseDocumentArray) {\n      childModel = type.Constructor;\n    } else {\n      continue;\n    }\n\n    if (childModel.$appliedHooks) {\n      continue;\n    }\n\n    applyHooks(childModel, type.schema, { ...options, isChildSchema: true });\n    if (childModel.discriminators != null) {\n      const keys = Object.keys(childModel.discriminators);\n      for (const key of keys) {\n        applyHooks(childModel.discriminators[key],\n          childModel.discriminators[key].schema, options);\n      }\n    }\n  }\n\n  // Built-in hooks rely on hooking internal functions in order to support\n  // promises and make it so that `doc.save.toString()` provides meaningful\n  // information.\n\n  const middleware = schema.s.hooks.\n    filter(hook => {\n      if (hook.name === 'updateOne' || hook.name === 'deleteOne') {\n        return !!hook['document'];\n      }\n      if (hook.name === 'remove' || hook.name === 'init') {\n        return hook['document'] == null || !!hook['document'];\n      }\n      if (hook.query != null || hook.document != null) {\n        return hook.document !== false;\n      }\n      return true;\n    }).\n    filter(hook => {\n      // If user has overwritten the method, don't apply built-in middleware\n      if (schema.methods[hook.name]) {\n        return !hook.fn[symbols.builtInMiddleware];\n      }\n\n      return true;\n    });\n\n  model._middleware = middleware;\n\n  objToDecorate.$__originalValidate = objToDecorate.$__originalValidate || objToDecorate.$__validate;\n\n  const internalMethodsToWrap = options && options.isChildSchema ? ['save', 'validate', 'deleteOne'] : ['save', 'validate'];\n  for (const method of internalMethodsToWrap) {\n    const toWrap = method === 'validate' ? '$__originalValidate' : `$__${method}`;\n    const wrapped = middleware.\n      createWrapper(method, objToDecorate[toWrap], null, kareemOptions);\n    objToDecorate[`$__${method}`] = wrapped;\n  }\n  objToDecorate.$__init = middleware.\n    createWrapperSync('init', objToDecorate.$__init, null, kareemOptions);\n\n  // Support hooks for custom methods\n  const customMethods = Object.keys(schema.methods);\n  const customMethodOptions = Object.assign({}, kareemOptions, {\n    // Only use `checkForPromise` for custom methods, because mongoose\n    // query thunks are not as consistent as I would like about returning\n    // a nullish value rather than the query. If a query thunk returns\n    // a query, `checkForPromise` causes infinite recursion\n    checkForPromise: true\n  });\n  for (const method of customMethods) {\n    if (alreadyHookedFunctions.has(method)) {\n      continue;\n    }\n    if (!middleware.hasHooks(method)) {\n      // Don't wrap if there are no hooks for the custom method to avoid\n      // surprises. Also, `createWrapper()` enforces consistent async,\n      // so wrapping a sync method would break it.\n      continue;\n    }\n    const originalMethod = objToDecorate[method];\n    objToDecorate[method] = function() {\n      const args = Array.prototype.slice.call(arguments);\n      const cb = args.slice(-1).pop();\n      const argsWithoutCallback = typeof cb === 'function' ?\n        args.slice(0, args.length - 1) : args;\n      return promiseOrCallback(cb, callback => {\n        return this[`$__${method}`].apply(this,\n          argsWithoutCallback.concat([callback]));\n      }, model.events);\n    };\n    objToDecorate[`$__${method}`] = middleware.\n      createWrapper(method, originalMethod, null, customMethodOptions);\n  }\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/model/applyHooks.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/model/applyMethods.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/model/applyMethods.js ***!
  \*****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst get = __webpack_require__(/*! ../get */ \"./node_modules/mongoose/lib/helpers/get.js\");\nconst utils = __webpack_require__(/*! ../../utils */ \"./node_modules/mongoose/lib/utils.js\");\n\n/**\n * Register methods for this model\n *\n * @param {Model} model\n * @param {Schema} schema\n * @api private\n */\n\nmodule.exports = function applyMethods(model, schema) {\n  const Model = __webpack_require__(/*! ../../model */ \"./node_modules/mongoose/lib/model.js\");\n\n  function apply(method, schema) {\n    Object.defineProperty(model.prototype, method, {\n      get: function() {\n        const h = {};\n        for (const k in schema.methods[method]) {\n          h[k] = schema.methods[method][k].bind(this);\n        }\n        return h;\n      },\n      configurable: true\n    });\n  }\n  for (const method of Object.keys(schema.methods)) {\n    const fn = schema.methods[method];\n    if (schema.tree.hasOwnProperty(method)) {\n      throw new Error('You have a method and a property in your schema both ' +\n        'named \"' + method + '\"');\n    }\n\n    // Avoid making custom methods if user sets a method to itself, e.g.\n    // `schema.method(save, Document.prototype.save)`. Can happen when\n    // calling `loadClass()` with a class that `extends Document`. See gh-12254\n    if (typeof fn === 'function' &&\n        Model.prototype[method] === fn) {\n      delete schema.methods[method];\n      continue;\n    }\n\n    if (schema.reserved[method] &&\n        !get(schema, `methodOptions.${method}.suppressWarning`, false)) {\n      utils.warn(`mongoose: the method name \"${method}\" is used by mongoose ` +\n        'internally, overwriting it may cause bugs. If you\\'re sure you know ' +\n        'what you\\'re doing, you can suppress this error by using ' +\n        `\\`schema.method('${method}', fn, { suppressWarning: true })\\`.`);\n    }\n    if (typeof fn === 'function') {\n      model.prototype[method] = fn;\n    } else {\n      apply(method, schema);\n    }\n  }\n\n  // Recursively call `applyMethods()` on child schemas\n  model.$appliedMethods = true;\n  for (const key of Object.keys(schema.paths)) {\n    const type = schema.paths[key];\n    if (type.$isSingleNested && !type.caster.$appliedMethods) {\n      applyMethods(type.caster, type.schema);\n    }\n    if (type.$isMongooseDocumentArray && !type.Constructor.$appliedMethods) {\n      applyMethods(type.Constructor, type.schema);\n    }\n  }\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/model/applyMethods.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/model/applyStaticHooks.js":
/*!*********************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/model/applyStaticHooks.js ***!
  \*********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst middlewareFunctions = (__webpack_require__(/*! ../../constants */ \"./node_modules/mongoose/lib/constants.js\").queryMiddlewareFunctions);\nconst promiseOrCallback = __webpack_require__(/*! ../promiseOrCallback */ \"./node_modules/mongoose/lib/helpers/promiseOrCallback.js\");\n\nmodule.exports = function applyStaticHooks(model, hooks, statics) {\n  const kareemOptions = {\n    useErrorHandlers: true,\n    numCallbackParams: 1\n  };\n\n  hooks = hooks.filter(hook => {\n    // If the custom static overwrites an existing query middleware, don't apply\n    // middleware to it by default. This avoids a potential backwards breaking\n    // change with plugins like `mongoose-delete` that use statics to overwrite\n    // built-in Mongoose functions.\n    if (middlewareFunctions.indexOf(hook.name) !== -1) {\n      return !!hook.model;\n    }\n    return hook.model !== false;\n  });\n\n  model.$__insertMany = hooks.createWrapper('insertMany',\n    model.$__insertMany, model, kareemOptions);\n\n  for (const key of Object.keys(statics)) {\n    if (hooks.hasHooks(key)) {\n      const original = model[key];\n\n      model[key] = function() {\n        const numArgs = arguments.length;\n        const lastArg = numArgs > 0 ? arguments[numArgs - 1] : null;\n        const cb = typeof lastArg === 'function' ? lastArg : null;\n        const args = Array.prototype.slice.\n          call(arguments, 0, cb == null ? numArgs : numArgs - 1);\n        // Special case: can't use `Kareem#wrap()` because it doesn't currently\n        // support wrapped functions that return a promise.\n        return promiseOrCallback(cb, callback => {\n          hooks.execPre(key, model, args, function(err) {\n            if (err != null) {\n              return callback(err);\n            }\n\n            let postCalled = 0;\n            const ret = original.apply(model, args.concat(post));\n            if (ret != null && typeof ret.then === 'function') {\n              ret.then(res => post(null, res), err => post(err));\n            }\n\n            function post(error, res) {\n              if (postCalled++ > 0) {\n                return;\n              }\n\n              if (error != null) {\n                return callback(error);\n              }\n\n              hooks.execPost(key, model, [res], function(error) {\n                if (error != null) {\n                  return callback(error);\n                }\n                callback(null, res);\n              });\n            }\n          });\n        }, model.events);\n      };\n    }\n  }\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/model/applyStaticHooks.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/model/applyStatics.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/model/applyStatics.js ***!
  \*****************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/**\n * Register statics for this model\n * @param {Model} model\n * @param {Schema} schema\n * @api private\n */\nmodule.exports = function applyStatics(model, schema) {\n  for (const i in schema.statics) {\n    model[i] = schema.statics[i];\n  }\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/model/applyStatics.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/model/castBulkWrite.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/model/castBulkWrite.js ***!
  \******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst MongooseError = __webpack_require__(/*! ../../error/mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\nconst getDiscriminatorByValue = __webpack_require__(/*! ../../helpers/discriminator/getDiscriminatorByValue */ \"./node_modules/mongoose/lib/helpers/discriminator/getDiscriminatorByValue.js\");\nconst applyTimestampsToChildren = __webpack_require__(/*! ../update/applyTimestampsToChildren */ \"./node_modules/mongoose/lib/helpers/update/applyTimestampsToChildren.js\");\nconst applyTimestampsToUpdate = __webpack_require__(/*! ../update/applyTimestampsToUpdate */ \"./node_modules/mongoose/lib/helpers/update/applyTimestampsToUpdate.js\");\nconst cast = __webpack_require__(/*! ../../cast */ \"./node_modules/mongoose/lib/cast.js\");\nconst castUpdate = __webpack_require__(/*! ../query/castUpdate */ \"./node_modules/mongoose/lib/helpers/query/castUpdate.js\");\nconst clone = __webpack_require__(/*! ../clone */ \"./node_modules/mongoose/lib/helpers/clone.js\");\nconst decorateUpdateWithVersionKey = __webpack_require__(/*! ../update/decorateUpdateWithVersionKey */ \"./node_modules/mongoose/lib/helpers/update/decorateUpdateWithVersionKey.js\");\nconst { inspect } = __webpack_require__(/*! util */ \"util\");\nconst setDefaultsOnInsert = __webpack_require__(/*! ../setDefaultsOnInsert */ \"./node_modules/mongoose/lib/helpers/setDefaultsOnInsert.js\");\n\n/**\n * Given a model and a bulkWrite op, return a thunk that handles casting and\n * validating the individual op.\n * @param {Model} originalModel\n * @param {Object} op\n * @param {Object} [options]\n * @api private\n */\n\nmodule.exports = function castBulkWrite(originalModel, op, options) {\n  const now = originalModel.base.now();\n\n  const globalSetDefaultsOnInsert = originalModel.base.options.setDefaultsOnInsert;\n  if (op['insertOne']) {\n    return (callback) => {\n      const model = decideModelByObject(originalModel, op['insertOne']['document']);\n\n      const doc = new model(op['insertOne']['document']);\n      if (model.schema.options.timestamps && getTimestampsOpt(op['insertOne'], options)) {\n        doc.initializeTimestamps();\n      }\n      if (options.session != null) {\n        doc.$session(options.session);\n      }\n      const versionKey = model?.schema?.options?.versionKey;\n      if (versionKey && doc[versionKey] == null) {\n        doc[versionKey] = 0;\n      }\n      op['insertOne']['document'] = doc;\n\n      if (options.skipValidation || op['insertOne'].skipValidation) {\n        callback(null);\n        return;\n      }\n\n      op['insertOne']['document'].$validate().then(\n        () => { callback(null); },\n        err => { callback(err, null); }\n      );\n    };\n  } else if (op['updateOne']) {\n    return (callback) => {\n      try {\n        if (!op['updateOne']['filter']) {\n          throw new Error('Must provide a filter object.');\n        }\n        if (!op['updateOne']['update']) {\n          throw new Error('Must provide an update object.');\n        }\n\n        const model = decideModelByObject(originalModel, op['updateOne']['filter']);\n        const schema = model.schema;\n        const strict = options.strict != null ? options.strict : model.schema.options.strict;\n\n        const update = clone(op['updateOne']['update']);\n\n        _addDiscriminatorToObject(schema, op['updateOne']['filter']);\n\n        const doInitTimestamps = getTimestampsOpt(op['updateOne'], options);\n\n        if (model.schema.$timestamps != null && doInitTimestamps) {\n          const createdAt = model.schema.$timestamps.createdAt;\n          const updatedAt = model.schema.$timestamps.updatedAt;\n          applyTimestampsToUpdate(now, createdAt, updatedAt, update, {});\n        }\n\n        if (doInitTimestamps) {\n          applyTimestampsToChildren(now, update, model.schema);\n        }\n\n        const shouldSetDefaultsOnInsert = op['updateOne'].setDefaultsOnInsert == null ?\n          globalSetDefaultsOnInsert :\n          op['updateOne'].setDefaultsOnInsert;\n        if (shouldSetDefaultsOnInsert !== false) {\n          setDefaultsOnInsert(op['updateOne']['filter'], model.schema, update, {\n            setDefaultsOnInsert: true,\n            upsert: op['updateOne'].upsert\n          });\n        }\n\n        decorateUpdateWithVersionKey(\n          update,\n          op['updateOne'],\n          model.schema.options.versionKey\n        );\n\n        op['updateOne']['filter'] = cast(model.schema, op['updateOne']['filter'], {\n          strict: strict,\n          upsert: op['updateOne'].upsert\n        });\n        op['updateOne']['update'] = castUpdate(model.schema, update, {\n          strict: strict,\n          upsert: op['updateOne'].upsert\n        }, model, op['updateOne']['filter']);\n      } catch (error) {\n        return callback(error, null);\n      }\n\n      callback(null);\n    };\n  } else if (op['updateMany']) {\n    return (callback) => {\n      try {\n        if (!op['updateMany']['filter']) {\n          throw new Error('Must provide a filter object.');\n        }\n        if (!op['updateMany']['update']) {\n          throw new Error('Must provide an update object.');\n        }\n\n        const model = decideModelByObject(originalModel, op['updateMany']['filter']);\n        const schema = model.schema;\n        const strict = options.strict != null ? options.strict : model.schema.options.strict;\n\n        const shouldSetDefaultsOnInsert = op['updateMany'].setDefaultsOnInsert == null ?\n          globalSetDefaultsOnInsert :\n          op['updateMany'].setDefaultsOnInsert;\n\n        if (shouldSetDefaultsOnInsert !== false) {\n          setDefaultsOnInsert(op['updateMany']['filter'], model.schema, op['updateMany']['update'], {\n            setDefaultsOnInsert: true,\n            upsert: op['updateMany'].upsert\n          });\n        }\n\n        const doInitTimestamps = getTimestampsOpt(op['updateMany'], options);\n\n        if (model.schema.$timestamps != null && doInitTimestamps) {\n          const createdAt = model.schema.$timestamps.createdAt;\n          const updatedAt = model.schema.$timestamps.updatedAt;\n          applyTimestampsToUpdate(now, createdAt, updatedAt, op['updateMany']['update'], {});\n        }\n        if (doInitTimestamps) {\n          applyTimestampsToChildren(now, op['updateMany']['update'], model.schema);\n        }\n\n        _addDiscriminatorToObject(schema, op['updateMany']['filter']);\n\n        decorateUpdateWithVersionKey(\n          op['updateMany']['update'],\n          op['updateMany'],\n          model.schema.options.versionKey\n        );\n\n        op['updateMany']['filter'] = cast(model.schema, op['updateMany']['filter'], {\n          strict: strict,\n          upsert: op['updateMany'].upsert\n        });\n\n        op['updateMany']['update'] = castUpdate(model.schema, op['updateMany']['update'], {\n          strict: strict,\n          upsert: op['updateMany'].upsert\n        }, model, op['updateMany']['filter']);\n      } catch (error) {\n        return callback(error, null);\n      }\n\n      callback(null);\n    };\n  } else if (op['replaceOne']) {\n    return (callback) => {\n      const model = decideModelByObject(originalModel, op['replaceOne']['filter']);\n      const schema = model.schema;\n      const strict = options.strict != null ? options.strict : model.schema.options.strict;\n\n      _addDiscriminatorToObject(schema, op['replaceOne']['filter']);\n      try {\n        op['replaceOne']['filter'] = cast(model.schema, op['replaceOne']['filter'], {\n          strict: strict,\n          upsert: op['replaceOne'].upsert\n        });\n      } catch (error) {\n        return callback(error, null);\n      }\n\n      // set `skipId`, otherwise we get \"_id field cannot be changed\"\n      const doc = new model(op['replaceOne']['replacement'], strict, true);\n      if (model.schema.options.timestamps && getTimestampsOpt(op['replaceOne'], options)) {\n        doc.initializeTimestamps();\n      }\n      if (options.session != null) {\n        doc.$session(options.session);\n      }\n      const versionKey = model?.schema?.options?.versionKey;\n      if (versionKey && doc[versionKey] == null) {\n        doc[versionKey] = 0;\n      }\n      op['replaceOne']['replacement'] = doc;\n\n      if (options.skipValidation || op['replaceOne'].skipValidation) {\n        op['replaceOne']['replacement'] = op['replaceOne']['replacement'].toBSON();\n        callback(null);\n        return;\n      }\n\n      op['replaceOne']['replacement'].$validate().then(\n        () => {\n          op['replaceOne']['replacement'] = op['replaceOne']['replacement'].toBSON();\n          callback(null);\n        },\n        error => {\n          callback(error, null);\n        }\n      );\n    };\n  } else if (op['deleteOne']) {\n    return (callback) => {\n      const model = decideModelByObject(originalModel, op['deleteOne']['filter']);\n      const schema = model.schema;\n\n      _addDiscriminatorToObject(schema, op['deleteOne']['filter']);\n\n      try {\n        op['deleteOne']['filter'] = cast(model.schema,\n          op['deleteOne']['filter']);\n      } catch (error) {\n        return callback(error, null);\n      }\n\n      callback(null);\n    };\n  } else if (op['deleteMany']) {\n    return (callback) => {\n      const model = decideModelByObject(originalModel, op['deleteMany']['filter']);\n      const schema = model.schema;\n\n      _addDiscriminatorToObject(schema, op['deleteMany']['filter']);\n\n      try {\n        op['deleteMany']['filter'] = cast(model.schema,\n          op['deleteMany']['filter']);\n      } catch (error) {\n        return callback(error, null);\n      }\n\n      callback(null);\n    };\n  } else {\n    return (callback) => {\n      const error = new MongooseError(`Invalid op passed to \\`bulkWrite()\\`: ${inspect(op)}`);\n      callback(error, null);\n    };\n  }\n};\n\nfunction _addDiscriminatorToObject(schema, obj) {\n  if (schema == null) {\n    return;\n  }\n  if (schema.discriminatorMapping && !schema.discriminatorMapping.isRoot) {\n    obj[schema.discriminatorMapping.key] = schema.discriminatorMapping.value;\n  }\n}\n\n/**\n * gets discriminator model if discriminator key is present in object\n * @api private\n */\n\nfunction decideModelByObject(model, object) {\n  const discriminatorKey = model.schema.options.discriminatorKey;\n  if (object != null && object.hasOwnProperty(discriminatorKey)) {\n    model = getDiscriminatorByValue(model.discriminators, object[discriminatorKey]) || model;\n  }\n  return model;\n}\n\n\n/**\n * gets timestamps option for a given operation. If the option is set within an individual operation, use it. Otherwise, use the global timestamps option configured in the `bulkWrite` options. Overall default is `true`.\n * @api private\n */\n\nfunction getTimestampsOpt(opCommand, options) {\n  const opLevelOpt = opCommand.timestamps;\n  const bulkLevelOpt = options.timestamps;\n  if (opLevelOpt != null) {\n    return opLevelOpt;\n  } else if (bulkLevelOpt != null) {\n    return bulkLevelOpt;\n  }\n  return true;\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/model/castBulkWrite.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/model/discriminator.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/model/discriminator.js ***!
  \******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst Mixed = __webpack_require__(/*! ../../schema/mixed */ \"./node_modules/mongoose/lib/schema/mixed.js\");\nconst applyBuiltinPlugins = __webpack_require__(/*! ../schema/applyBuiltinPlugins */ \"./node_modules/mongoose/lib/helpers/schema/applyBuiltinPlugins.js\");\nconst clone = __webpack_require__(/*! ../clone */ \"./node_modules/mongoose/lib/helpers/clone.js\");\nconst defineKey = (__webpack_require__(/*! ../document/compile */ \"./node_modules/mongoose/lib/helpers/document/compile.js\").defineKey);\nconst get = __webpack_require__(/*! ../get */ \"./node_modules/mongoose/lib/helpers/get.js\");\nconst utils = __webpack_require__(/*! ../../utils */ \"./node_modules/mongoose/lib/utils.js\");\nconst mergeDiscriminatorSchema = __webpack_require__(/*! ../../helpers/discriminator/mergeDiscriminatorSchema */ \"./node_modules/mongoose/lib/helpers/discriminator/mergeDiscriminatorSchema.js\");\n\nconst CUSTOMIZABLE_DISCRIMINATOR_OPTIONS = {\n  toJSON: true,\n  toObject: true,\n  _id: true,\n  id: true,\n  virtuals: true,\n  methods: true\n};\n\n/*!\n * ignore\n */\n\nmodule.exports = function discriminator(model, name, schema, tiedValue, applyPlugins, mergeHooks, overwriteExisting) {\n  if (!(schema && schema.instanceOfSchema)) {\n    throw new Error('You must pass a valid discriminator Schema');\n  }\n\n  mergeHooks = mergeHooks == null ? true : mergeHooks;\n\n  if (model.schema.discriminatorMapping &&\n      !model.schema.discriminatorMapping.isRoot) {\n    throw new Error('Discriminator \"' + name +\n        '\" can only be a discriminator of the root model');\n  }\n\n  if (applyPlugins) {\n    const applyPluginsToDiscriminators = get(model.base,\n      'options.applyPluginsToDiscriminators', false) || !mergeHooks;\n    // Even if `applyPluginsToDiscriminators` isn't set, we should still apply\n    // global plugins to schemas embedded in the discriminator schema (gh-7370)\n    model.base._applyPlugins(schema, {\n      skipTopLevel: !applyPluginsToDiscriminators\n    });\n  } else if (!mergeHooks) {\n    applyBuiltinPlugins(schema);\n  }\n\n  const key = model.schema.options.discriminatorKey;\n\n  const existingPath = model.schema.path(key);\n  if (existingPath != null) {\n    if (!utils.hasUserDefinedProperty(existingPath.options, 'select')) {\n      existingPath.options.select = true;\n    }\n    existingPath.options.$skipDiscriminatorCheck = true;\n  } else {\n    const baseSchemaAddition = {};\n    baseSchemaAddition[key] = {\n      default: void 0,\n      select: true,\n      $skipDiscriminatorCheck: true\n    };\n    baseSchemaAddition[key][model.schema.options.typeKey] = String;\n    model.schema.add(baseSchemaAddition);\n    defineKey({\n      prop: key,\n      prototype: model.prototype,\n      options: model.schema.options\n    });\n  }\n\n  if (schema.path(key) && schema.path(key).options.$skipDiscriminatorCheck !== true) {\n    throw new Error('Discriminator \"' + name +\n        '\" cannot have field with name \"' + key + '\"');\n  }\n\n  let value = name;\n  if ((typeof tiedValue === 'string' && tiedValue.length) || tiedValue != null) {\n    value = tiedValue;\n  }\n\n  function merge(schema, baseSchema) {\n    // Retain original schema before merging base schema\n    schema._baseSchema = baseSchema;\n    if (baseSchema.paths._id &&\n        baseSchema.paths._id.options &&\n        !baseSchema.paths._id.options.auto) {\n      schema.remove('_id');\n    }\n\n    // Find conflicting paths: if something is a path in the base schema\n    // and a nested path in the child schema, overwrite the base schema path.\n    // See gh-6076\n    const baseSchemaPaths = Object.keys(baseSchema.paths);\n    const conflictingPaths = [];\n\n    for (const path of baseSchemaPaths) {\n      if (schema.nested[path]) {\n        conflictingPaths.push(path);\n        continue;\n      }\n\n      if (path.indexOf('.') === -1) {\n        continue;\n      }\n      const sp = path.split('.').slice(0, -1);\n      let cur = '';\n      for (const piece of sp) {\n        cur += (cur.length ? '.' : '') + piece;\n        if (schema.paths[cur] instanceof Mixed ||\n            schema.singleNestedPaths[cur] instanceof Mixed) {\n          conflictingPaths.push(path);\n        }\n      }\n    }\n\n    mergeDiscriminatorSchema(schema, baseSchema);\n\n    // Clean up conflicting paths _after_ merging re: gh-6076\n    for (const conflictingPath of conflictingPaths) {\n      delete schema.paths[conflictingPath];\n    }\n\n    // Rebuild schema models because schemas may have been merged re: #7884\n    schema.childSchemas.forEach(obj => {\n      obj.model.prototype.$__setSchema(obj.schema);\n    });\n\n    const obj = {};\n    obj[key] = {\n      default: value,\n      select: true,\n      set: function(newName) {\n        if (newName === value || (Array.isArray(value) && utils.deepEqual(newName, value))) {\n          return value;\n        }\n        throw new Error('Can\\'t set discriminator key \"' + key + '\"');\n      },\n      $skipDiscriminatorCheck: true\n    };\n    obj[key][schema.options.typeKey] = existingPath ? existingPath.options[schema.options.typeKey] : String;\n    schema.add(obj);\n\n    schema.discriminatorMapping = { key: key, value: value, isRoot: false };\n\n    if (baseSchema.options.collection) {\n      schema.options.collection = baseSchema.options.collection;\n    }\n    const toJSON = schema.options.toJSON;\n    const toObject = schema.options.toObject;\n    const _id = schema.options._id;\n    const id = schema.options.id;\n\n    const keys = Object.keys(schema.options);\n    schema.options.discriminatorKey = baseSchema.options.discriminatorKey;\n    const userProvidedOptions = schema._userProvidedOptions;\n    for (const _key of keys) {\n      if (!CUSTOMIZABLE_DISCRIMINATOR_OPTIONS[_key]) {\n        // Use `schema.options` in `deepEqual()` because of `discriminatorKey`\n        // set above. We don't allow customizing discriminator key, always\n        // overwrite. See gh-9238\n        if (_key in userProvidedOptions && !utils.deepEqual(schema.options[_key], baseSchema.options[_key])) {\n          throw new Error('Can\\'t customize discriminator option ' + _key +\n            ' (can only modify ' +\n            Object.keys(CUSTOMIZABLE_DISCRIMINATOR_OPTIONS).join(', ') +\n            ')');\n        }\n      }\n    }\n    schema.options = clone(baseSchema.options);\n\n    for (const _key of Object.keys(userProvidedOptions)) {\n      schema.options[_key] = userProvidedOptions[_key];\n    }\n    if (toJSON) schema.options.toJSON = toJSON;\n    if (toObject) schema.options.toObject = toObject;\n    if (typeof _id !== 'undefined') {\n      schema.options._id = _id;\n    }\n    schema.options.id = id;\n    if (mergeHooks) {\n      schema.s.hooks = model.schema.s.hooks.merge(schema.s.hooks);\n    }\n    if (applyPlugins) {\n      schema.plugins = Array.prototype.slice.call(baseSchema.plugins);\n    }\n    schema.callQueue = baseSchema.callQueue.concat(schema.callQueue);\n    delete schema._requiredpaths; // reset just in case Schema#requiredPaths() was called on either schema\n  }\n\n  // merges base schema into new discriminator schema and sets new type field.\n  merge(schema, model.schema);\n\n  if (!model.discriminators) {\n    model.discriminators = {};\n  }\n\n  if (!model.schema.discriminatorMapping) {\n    model.schema.discriminatorMapping = { key: key, value: null, isRoot: true };\n  }\n  if (!model.schema.discriminators) {\n    model.schema.discriminators = {};\n  }\n\n  model.schema.discriminators[name] = schema;\n\n  if (model.discriminators[name] && !schema.options.overwriteModels && !overwriteExisting) {\n    throw new Error('Discriminator with name \"' + name + '\" already exists');\n  }\n\n  return schema;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/model/discriminator.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/model/pushNestedArrayPaths.js":
/*!*************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/model/pushNestedArrayPaths.js ***!
  \*************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function pushNestedArrayPaths(paths, nestedArray, path) {\n  if (nestedArray == null) {\n    return;\n  }\n\n  for (let i = 0; i < nestedArray.length; ++i) {\n    if (Array.isArray(nestedArray[i])) {\n      pushNestedArrayPaths(paths, nestedArray[i], path + '.' + i);\n    } else {\n      paths.push(path + '.' + i);\n    }\n  }\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/model/pushNestedArrayPaths.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/omitUndefined.js":
/*!************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/omitUndefined.js ***!
  \************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function omitUndefined(val) {\n  if (val == null || typeof val !== 'object') {\n    return val;\n  }\n  if (Array.isArray(val)) {\n    for (let i = val.length - 1; i >= 0; --i) {\n      if (val[i] === undefined) {\n        val.splice(i, 1);\n      }\n    }\n  }\n  for (const key of Object.keys(val)) {\n    if (val[key] === void 0) {\n      delete val[key];\n    }\n  }\n  return val;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/omitUndefined.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/parallelLimit.js":
/*!************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/parallelLimit.js ***!
  \************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = parallelLimit;\n\n/*!\n * ignore\n */\n\nfunction parallelLimit(fns, limit, callback) {\n  let numInProgress = 0;\n  let numFinished = 0;\n  let error = null;\n\n  if (limit <= 0) {\n    throw new Error('Limit must be positive');\n  }\n\n  if (fns.length === 0) {\n    return callback(null, []);\n  }\n\n  for (let i = 0; i < fns.length && i < limit; ++i) {\n    _start();\n  }\n\n  function _start() {\n    fns[numFinished + numInProgress](_done(numFinished + numInProgress));\n    ++numInProgress;\n  }\n\n  const results = [];\n\n  function _done(index) {\n    return (err, res) => {\n      --numInProgress;\n      ++numFinished;\n\n      if (error != null) {\n        return;\n      }\n      if (err != null) {\n        error = err;\n        return callback(error);\n      }\n\n      results[index] = res;\n\n      if (numFinished === fns.length) {\n        return callback(null, results);\n      } else if (numFinished + numInProgress < fns.length) {\n        _start();\n      }\n    };\n  }\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/parallelLimit.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/path/parentPaths.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/path/parentPaths.js ***!
  \***************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nconst dotRE = /\\./g;\nmodule.exports = function parentPaths(path) {\n  if (path.indexOf('.') === -1) {\n    return [path];\n  }\n  const pieces = path.split(dotRE);\n  const len = pieces.length;\n  const ret = new Array(len);\n  let cur = '';\n  for (let i = 0; i < len; ++i) {\n    cur += (cur.length !== 0) ? '.' + pieces[i] : pieces[i];\n    ret[i] = cur;\n  }\n\n  return ret;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/path/parentPaths.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/path/setDottedPath.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/path/setDottedPath.js ***!
  \*****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst specialProperties = __webpack_require__(/*! ../specialProperties */ \"./node_modules/mongoose/lib/helpers/specialProperties.js\");\n\n\nmodule.exports = function setDottedPath(obj, path, val) {\n  if (path.indexOf('.') === -1) {\n    if (specialProperties.has(path)) {\n      return;\n    }\n\n    obj[path] = val;\n    return;\n  }\n  const parts = path.split('.');\n\n  const last = parts.pop();\n  let cur = obj;\n  for (const part of parts) {\n    if (specialProperties.has(part)) {\n      continue;\n    }\n    if (cur[part] == null) {\n      cur[part] = {};\n    }\n\n    cur = cur[part];\n  }\n\n  if (!specialProperties.has(last)) {\n    cur[last] = val;\n  }\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/path/setDottedPath.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/pluralize.js":
/*!********************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/pluralize.js ***!
  \********************************************************/
/***/ ((module, exports) => {

"use strict";
eval("\n\nmodule.exports = pluralize;\n\n/**\n * Pluralization rules.\n */\n\nexports.pluralization = [\n  [/human$/gi, 'humans'],\n  [/(m)an$/gi, '$1en'],\n  [/(pe)rson$/gi, '$1ople'],\n  [/(child)$/gi, '$1ren'],\n  [/^(ox)$/gi, '$1en'],\n  [/(ax|test)is$/gi, '$1es'],\n  [/(octop|vir)us$/gi, '$1i'],\n  [/(alias|status)$/gi, '$1es'],\n  [/(bu)s$/gi, '$1ses'],\n  [/(buffal|tomat|potat)o$/gi, '$1oes'],\n  [/([ti])um$/gi, '$1a'],\n  [/sis$/gi, 'ses'],\n  [/(?:([^f])fe|([lr])f)$/gi, '$1$2ves'],\n  [/(hive)$/gi, '$1s'],\n  [/([^aeiouy]|qu)y$/gi, '$1ies'],\n  [/(x|ch|ss|sh)$/gi, '$1es'],\n  [/(matr|vert|ind)ix|ex$/gi, '$1ices'],\n  [/([m|l])ouse$/gi, '$1ice'],\n  [/(kn|w|l)ife$/gi, '$1ives'],\n  [/(quiz)$/gi, '$1zes'],\n  [/^goose$/i, 'geese'],\n  [/s$/gi, 's'],\n  [/([^a-z])$/, '$1'],\n  [/$/gi, 's']\n];\nconst rules = exports.pluralization;\n\n/**\n * Uncountable words.\n *\n * These words are applied while processing the argument to `toCollectionName`.\n * @api public\n */\n\nexports.uncountables = [\n  'advice',\n  'energy',\n  'excretion',\n  'digestion',\n  'cooperation',\n  'health',\n  'justice',\n  'labour',\n  'machinery',\n  'equipment',\n  'information',\n  'pollution',\n  'sewage',\n  'paper',\n  'money',\n  'species',\n  'series',\n  'rain',\n  'rice',\n  'fish',\n  'sheep',\n  'moose',\n  'deer',\n  'news',\n  'expertise',\n  'status',\n  'media'\n];\nconst uncountables = exports.uncountables;\n\n/**\n * Pluralize function.\n *\n * @author TJ Holowaychuk (extracted from _ext.js_)\n * @param {String} string to pluralize\n * @api private\n */\n\nfunction pluralize(str) {\n  let found;\n  str = str.toLowerCase();\n  if (!~uncountables.indexOf(str)) {\n    found = rules.filter(function(rule) {\n      return str.match(rule[0]);\n    });\n    if (found[0]) {\n      return str.replace(found[0][0], found[0][1]);\n    }\n  }\n  return str;\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/pluralize.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/populate/assignRawDocsToIdStructure.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/populate/assignRawDocsToIdStructure.js ***!
  \**********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst clone = __webpack_require__(/*! ../../helpers/clone */ \"./node_modules/mongoose/lib/helpers/clone.js\");\nconst leanPopulateMap = __webpack_require__(/*! ./leanPopulateMap */ \"./node_modules/mongoose/lib/helpers/populate/leanPopulateMap.js\");\nconst modelSymbol = (__webpack_require__(/*! ../symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").modelSymbol);\nconst utils = __webpack_require__(/*! ../../utils */ \"./node_modules/mongoose/lib/utils.js\");\n\nmodule.exports = assignRawDocsToIdStructure;\n\nconst kHasArray = Symbol('mongoose#assignRawDocsToIdStructure#hasArray');\n\n/**\n * Assign `vals` returned by mongo query to the `rawIds`\n * structure returned from utils.getVals() honoring\n * query sort order if specified by user.\n *\n * This can be optimized.\n *\n * Rules:\n *\n *   if the value of the path is not an array, use findOne rules, else find.\n *   for findOne the results are assigned directly to doc path (including null results).\n *   for find, if user specified sort order, results are assigned directly\n *   else documents are put back in original order of array if found in results\n *\n * @param {Array} rawIds\n * @param {Array} resultDocs\n * @param {Array} resultOrder\n * @param {Object} options\n * @param {Boolean} recursed\n * @api private\n */\n\nfunction assignRawDocsToIdStructure(rawIds, resultDocs, resultOrder, options, recursed) {\n  // honor user specified sort order, unless we're populating a single\n  // virtual underneath an array (e.g. populating `employees.mostRecentShift` where\n  // `mostRecentShift` is a virtual with `justOne`)\n  const newOrder = [];\n  const sorting = options.isVirtual && options.justOne && rawIds.length > 1\n    ? false :\n    options.sort && rawIds.length > 1;\n  const nullIfNotFound = options.$nullIfNotFound;\n  let doc;\n  let sid;\n  let id;\n\n  if (utils.isMongooseArray(rawIds)) {\n    rawIds = rawIds.__array;\n  }\n\n  let i = 0;\n  const len = rawIds.length;\n\n  if (sorting && recursed && options[kHasArray] === undefined) {\n    options[kHasArray] = false;\n    for (const key in resultOrder) {\n      if (Array.isArray(resultOrder[key])) {\n        options[kHasArray] = true;\n        break;\n      }\n    }\n  }\n\n  for (i = 0; i < len; ++i) {\n    id = rawIds[i];\n\n    if (Array.isArray(id)) {\n      // handle [ [id0, id2], [id3] ]\n      assignRawDocsToIdStructure(id, resultDocs, resultOrder, options, true);\n      newOrder.push(id);\n      continue;\n    }\n\n    if (id === null && sorting === false) {\n      // keep nulls for findOne unless sorting, which always\n      // removes them (backward compat)\n      newOrder.push(id);\n      continue;\n    }\n\n    sid = String(id);\n    doc = resultDocs[sid];\n    // If user wants separate copies of same doc, use this option\n    if (options.clone && doc != null) {\n      if (options.lean) {\n        const _model = leanPopulateMap.get(doc);\n        doc = clone(doc);\n        leanPopulateMap.set(doc, _model);\n      } else {\n        doc = doc.constructor.hydrate(doc._doc);\n      }\n    }\n\n    if (recursed) {\n      if (doc) {\n        if (sorting) {\n          const _resultOrder = resultOrder[sid];\n          if (options[kHasArray]) {\n            // If result arrays, rely on the MongoDB server response for ordering\n            newOrder.push(doc);\n          } else {\n            newOrder[_resultOrder] = doc;\n          }\n        } else {\n          newOrder.push(doc);\n        }\n      } else if (id != null && id[modelSymbol] != null) {\n        newOrder.push(id);\n      } else {\n        newOrder.push(options.retainNullValues || nullIfNotFound ? null : id);\n      }\n    } else {\n      // apply findOne behavior - if document in results, assign, else assign null\n      newOrder[i] = doc || null;\n    }\n  }\n\n  rawIds.length = 0;\n  if (newOrder.length) {\n    // reassign the documents based on corrected order\n\n    // forEach skips over sparse entries in arrays so we\n    // can safely use this to our advantage dealing with sorted\n    // result sets too.\n    newOrder.forEach(function(doc, i) {\n      rawIds[i] = doc;\n    });\n  }\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/populate/assignRawDocsToIdStructure.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/populate/assignVals.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/populate/assignVals.js ***!
  \******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst MongooseMap = __webpack_require__(/*! ../../types/map */ \"./node_modules/mongoose/lib/types/map.js\");\nconst SkipPopulateValue = __webpack_require__(/*! ./skipPopulateValue */ \"./node_modules/mongoose/lib/helpers/populate/skipPopulateValue.js\");\nconst assignRawDocsToIdStructure = __webpack_require__(/*! ./assignRawDocsToIdStructure */ \"./node_modules/mongoose/lib/helpers/populate/assignRawDocsToIdStructure.js\");\nconst get = __webpack_require__(/*! ../get */ \"./node_modules/mongoose/lib/helpers/get.js\");\nconst getVirtual = __webpack_require__(/*! ./getVirtual */ \"./node_modules/mongoose/lib/helpers/populate/getVirtual.js\");\nconst leanPopulateMap = __webpack_require__(/*! ./leanPopulateMap */ \"./node_modules/mongoose/lib/helpers/populate/leanPopulateMap.js\");\nconst lookupLocalFields = __webpack_require__(/*! ./lookupLocalFields */ \"./node_modules/mongoose/lib/helpers/populate/lookupLocalFields.js\");\nconst markArraySubdocsPopulated = __webpack_require__(/*! ./markArraySubdocsPopulated */ \"./node_modules/mongoose/lib/helpers/populate/markArraySubdocsPopulated.js\");\nconst mpath = __webpack_require__(/*! mpath */ \"./node_modules/mpath/index.js\");\nconst sift = (__webpack_require__(/*! sift */ \"./node_modules/sift/es5m/index.js\")[\"default\"]);\nconst utils = __webpack_require__(/*! ../../utils */ \"./node_modules/mongoose/lib/utils.js\");\nconst { populateModelSymbol } = __webpack_require__(/*! ../symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\");\n\nmodule.exports = function assignVals(o) {\n  // Options that aren't explicitly listed in `populateOptions`\n  const userOptions = Object.assign({}, get(o, 'allOptions.options.options'), get(o, 'allOptions.options'));\n  // `o.options` contains options explicitly listed in `populateOptions`, like\n  // `match` and `limit`.\n  const populateOptions = Object.assign({}, o.options, userOptions, {\n    justOne: o.justOne,\n    isVirtual: o.isVirtual\n  });\n  populateOptions.$nullIfNotFound = o.isVirtual;\n  const populatedModel = o.populatedModel;\n\n  const originalIds = [].concat(o.rawIds);\n\n  // replace the original ids in our intermediate _ids structure\n  // with the documents found by query\n  o.allIds = [].concat(o.allIds);\n  assignRawDocsToIdStructure(o.rawIds, o.rawDocs, o.rawOrder, populateOptions);\n\n  // now update the original documents being populated using the\n  // result structure that contains real documents.\n  const docs = o.docs;\n  const rawIds = o.rawIds;\n  const options = o.options;\n  const count = o.count && o.isVirtual;\n  let i;\n  let setValueIndex = 0;\n\n  function setValue(val) {\n    ++setValueIndex;\n    if (count) {\n      return val;\n    }\n    if (val instanceof SkipPopulateValue) {\n      return val.val;\n    }\n    if (val === void 0) {\n      return val;\n    }\n\n    const _allIds = o.allIds[i];\n\n    if (o.path.endsWith('.$*')) {\n      // Skip maps re: gh-12494\n      return valueFilter(val, options, populateOptions, _allIds);\n    }\n\n    if (o.justOne === true && Array.isArray(val)) {\n      // Might be an embedded discriminator (re: gh-9244) with multiple models, so make sure to pick the right\n      // model before assigning.\n      const ret = [];\n      for (const doc of val) {\n        const _docPopulatedModel = leanPopulateMap.get(doc);\n        if (_docPopulatedModel == null || _docPopulatedModel === populatedModel) {\n          ret.push(doc);\n        }\n      }\n      // Since we don't want to have to create a new mongoosearray, make sure to\n      // modify the array in place\n      while (val.length > ret.length) {\n        Array.prototype.pop.apply(val, []);\n      }\n      for (let i = 0; i < ret.length; ++i) {\n        val[i] = ret[i];\n      }\n\n      return valueFilter(val[0], options, populateOptions, _allIds);\n    } else if (o.justOne === false && !Array.isArray(val)) {\n      return valueFilter([val], options, populateOptions, _allIds);\n    } else if (o.justOne === true && !Array.isArray(val) && Array.isArray(_allIds)) {\n      return valueFilter(val, options, populateOptions, val == null ? val : _allIds[setValueIndex - 1]);\n    }\n    return valueFilter(val, options, populateOptions, _allIds);\n  }\n\n  for (i = 0; i < docs.length; ++i) {\n    setValueIndex = 0;\n    const _path = o.path.endsWith('.$*') ? o.path.slice(0, -3) : o.path;\n    const existingVal = mpath.get(_path, docs[i], lookupLocalFields);\n    if (existingVal == null && !getVirtual(o.originalModel.schema, _path)) {\n      continue;\n    }\n\n    let valueToSet;\n    if (count) {\n      valueToSet = numDocs(rawIds[i]);\n    } else if (Array.isArray(o.match)) {\n      valueToSet = Array.isArray(rawIds[i]) ?\n        rawIds[i].filter(v => v == null || sift(o.match[i])(v)) :\n        [rawIds[i]].filter(v => v == null || sift(o.match[i])(v))[0];\n    } else {\n      valueToSet = rawIds[i];\n    }\n\n    // If we're populating a map, the existing value will be an object, so\n    // we need to transform again\n    const originalSchema = o.originalModel.schema;\n    const isDoc = get(docs[i], '$__', null) != null;\n    let isMap = isDoc ?\n      existingVal instanceof Map :\n      utils.isPOJO(existingVal);\n    // If we pass the first check, also make sure the local field's schematype\n    // is map (re: gh-6460)\n    isMap = isMap && get(originalSchema._getSchema(_path), '$isSchemaMap');\n    if (!o.isVirtual && isMap) {\n      const _keys = existingVal instanceof Map ?\n        Array.from(existingVal.keys()) :\n        Object.keys(existingVal);\n      valueToSet = valueToSet.reduce((cur, v, i) => {\n        cur.set(_keys[i], v);\n        return cur;\n      }, new Map());\n    }\n\n    if (isDoc && Array.isArray(valueToSet)) {\n      for (const val of valueToSet) {\n        if (val != null && val.$__ != null) {\n          val.$__.parent = docs[i];\n        }\n      }\n    } else if (isDoc && valueToSet != null && valueToSet.$__ != null) {\n      valueToSet.$__.parent = docs[i];\n    }\n\n    if (o.isVirtual && isDoc) {\n      docs[i].$populated(_path, o.justOne ? originalIds[0] : originalIds, o.allOptions);\n      // If virtual populate and doc is already init-ed, need to walk through\n      // the actual doc to set rather than setting `_doc` directly\n      if (Array.isArray(valueToSet)) {\n        valueToSet = valueToSet.map(v => v == null ? void 0 : v);\n      }\n      mpath.set(_path, valueToSet, docs[i], void 0, setValue, false);\n      continue;\n    }\n\n    const parts = _path.split('.');\n    let cur = docs[i];\n    for (let j = 0; j < parts.length - 1; ++j) {\n      // If we get to an array with a dotted path, like `arr.foo`, don't set\n      // `foo` on the array.\n      if (Array.isArray(cur) && !utils.isArrayIndex(parts[j])) {\n        break;\n      }\n\n      if (parts[j] === '$*') {\n        break;\n      }\n\n      if (cur[parts[j]] == null) {\n        // If nothing to set, avoid creating an unnecessary array. Otherwise\n        // we'll end up with a single doc in the array with only defaults.\n        // See gh-8342, gh-8455\n        const curPath = parts.slice(0, j + 1).join('.');\n        const schematype = originalSchema._getSchema(curPath);\n        if (valueToSet == null && schematype != null && schematype.$isMongooseArray) {\n          break;\n        }\n        cur[parts[j]] = {};\n      }\n      cur = cur[parts[j]];\n      // If the property in MongoDB is a primitive, we won't be able to populate\n      // the nested path, so skip it. See gh-7545\n      if (typeof cur !== 'object') {\n        break;\n      }\n    }\n    if (docs[i].$__) {\n      o.allOptions.options[populateModelSymbol] = o.allOptions.model;\n      docs[i].$populated(_path, o.unpopulatedValues[i], o.allOptions.options);\n\n      if (valueToSet != null && valueToSet.$__ != null) {\n        valueToSet.$__.wasPopulated = { value: o.unpopulatedValues[i] };\n      }\n\n      if (valueToSet instanceof Map && !valueToSet.$isMongooseMap) {\n        valueToSet = new MongooseMap(valueToSet, _path, docs[i], docs[i].schema.path(_path).$__schemaType);\n      }\n    }\n\n    // If lean, need to check that each individual virtual respects\n    // `justOne`, because you may have a populated virtual with `justOne`\n    // underneath an array. See gh-6867\n    mpath.set(_path, valueToSet, docs[i], lookupLocalFields, setValue, false);\n\n    if (docs[i].$__) {\n      markArraySubdocsPopulated(docs[i], [o.allOptions.options]);\n    }\n  }\n};\n\nfunction numDocs(v) {\n  if (Array.isArray(v)) {\n    // If setting underneath an array of populated subdocs, we may have an\n    // array of arrays. See gh-7573\n    if (v.some(el => Array.isArray(el) || el === null)) {\n      return v.map(el => {\n        if (el == null) {\n          return 0;\n        }\n        if (Array.isArray(el)) {\n          return el.filter(el => el != null).length;\n        }\n        return 1;\n      });\n    }\n    return v.filter(el => el != null).length;\n  }\n  return v == null ? 0 : 1;\n}\n\n/**\n * 1) Apply backwards compatible find/findOne behavior to sub documents\n *\n *    find logic:\n *      a) filter out non-documents\n *      b) remove _id from sub docs when user specified\n *\n *    findOne\n *      a) if no doc found, set to null\n *      b) remove _id from sub docs when user specified\n *\n * 2) Remove _ids when specified by users query.\n *\n * background:\n * _ids are left in the query even when user excludes them so\n * that population mapping can occur.\n * @param {Any} val\n * @param {Object} assignmentOpts\n * @param {Object} populateOptions\n * @param {Function} [populateOptions.transform]\n * @param {Boolean} allIds\n * @api private\n */\n\nfunction valueFilter(val, assignmentOpts, populateOptions, allIds) {\n  const userSpecifiedTransform = typeof populateOptions.transform === 'function';\n  const transform = userSpecifiedTransform ? populateOptions.transform : noop;\n  if (Array.isArray(val)) {\n    // find logic\n    const ret = [];\n    const numValues = val.length;\n    for (let i = 0; i < numValues; ++i) {\n      let subdoc = val[i];\n      const _allIds = Array.isArray(allIds) ? allIds[i] : allIds;\n      if (!isPopulatedObject(subdoc) && (!populateOptions.retainNullValues || subdoc != null) && !userSpecifiedTransform) {\n        continue;\n      } else if (!populateOptions.retainNullValues && subdoc == null) {\n        continue;\n      } else if (userSpecifiedTransform) {\n        subdoc = transform(isPopulatedObject(subdoc) ? subdoc : null, _allIds);\n      }\n      maybeRemoveId(subdoc, assignmentOpts);\n      ret.push(subdoc);\n      if (assignmentOpts.originalLimit &&\n          ret.length >= assignmentOpts.originalLimit) {\n        break;\n      }\n    }\n\n    const rLen = ret.length;\n    // Since we don't want to have to create a new mongoosearray, make sure to\n    // modify the array in place\n    while (val.length > rLen) {\n      Array.prototype.pop.apply(val, []);\n    }\n    let i = 0;\n    if (utils.isMongooseArray(val)) {\n      for (i = 0; i < rLen; ++i) {\n        val.set(i, ret[i], true);\n      }\n    } else {\n      for (i = 0; i < rLen; ++i) {\n        val[i] = ret[i];\n      }\n    }\n    return val;\n  }\n\n  // findOne\n  if (isPopulatedObject(val) || utils.isPOJO(val)) {\n    maybeRemoveId(val, assignmentOpts);\n    return transform(val, allIds);\n  }\n  if (val instanceof Map) {\n    return val;\n  }\n\n  if (populateOptions.justOne === false) {\n    return [];\n  }\n\n  return val == null ? transform(val, allIds) : transform(null, allIds);\n}\n\n/**\n * Remove _id from `subdoc` if user specified \"lean\" query option\n * @param {Document} subdoc\n * @param {Object} assignmentOpts\n * @api private\n */\n\nfunction maybeRemoveId(subdoc, assignmentOpts) {\n  if (subdoc != null && assignmentOpts.excludeId) {\n    if (typeof subdoc.$__setValue === 'function') {\n      delete subdoc._doc._id;\n    } else {\n      delete subdoc._id;\n    }\n  }\n}\n\n/**\n * Determine if `obj` is something we can set a populated path to. Can be a\n * document, a lean document, or an array/map that contains docs.\n * @param {Any} obj\n * @api private\n */\n\nfunction isPopulatedObject(obj) {\n  if (obj == null) {\n    return false;\n  }\n\n  return Array.isArray(obj) ||\n    obj.$isMongooseMap ||\n    obj.$__ != null ||\n    leanPopulateMap.has(obj);\n}\n\nfunction noop(v) {\n  return v;\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/populate/assignVals.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/populate/createPopulateQueryFilter.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/populate/createPopulateQueryFilter.js ***!
  \*********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst SkipPopulateValue = __webpack_require__(/*! ./skipPopulateValue */ \"./node_modules/mongoose/lib/helpers/populate/skipPopulateValue.js\");\nconst parentPaths = __webpack_require__(/*! ../path/parentPaths */ \"./node_modules/mongoose/lib/helpers/path/parentPaths.js\");\nconst { trusted } = __webpack_require__(/*! ../query/trusted */ \"./node_modules/mongoose/lib/helpers/query/trusted.js\");\nconst hasDollarKeys = __webpack_require__(/*! ../query/hasDollarKeys */ \"./node_modules/mongoose/lib/helpers/query/hasDollarKeys.js\");\n\nmodule.exports = function createPopulateQueryFilter(ids, _match, _foreignField, model, skipInvalidIds) {\n  const match = _formatMatch(_match);\n\n  if (_foreignField.size === 1) {\n    const foreignField = Array.from(_foreignField)[0];\n    const foreignSchemaType = model.schema.path(foreignField);\n    if (foreignField !== '_id' || !match['_id']) {\n      ids = _filterInvalidIds(ids, foreignSchemaType, skipInvalidIds);\n      match[foreignField] = trusted({ $in: ids });\n    } else if (foreignField === '_id' && match['_id']) {\n      const userSpecifiedMatch = hasDollarKeys(match[foreignField]) ?\n        match[foreignField] :\n        { $eq: match[foreignField] };\n      match[foreignField] = { ...trusted({ $in: ids }), ...userSpecifiedMatch };\n    }\n\n    const _parentPaths = parentPaths(foreignField);\n    for (let i = 0; i < _parentPaths.length - 1; ++i) {\n      const cur = _parentPaths[i];\n      if (match[cur] != null && match[cur].$elemMatch != null) {\n        match[cur].$elemMatch[foreignField.slice(cur.length + 1)] = trusted({ $in: ids });\n        delete match[foreignField];\n        break;\n      }\n    }\n  } else {\n    const $or = [];\n    if (Array.isArray(match.$or)) {\n      match.$and = [{ $or: match.$or }, { $or: $or }];\n      delete match.$or;\n    } else {\n      match.$or = $or;\n    }\n    for (const foreignField of _foreignField) {\n      if (foreignField !== '_id' || !match['_id']) {\n        const foreignSchemaType = model.schema.path(foreignField);\n        ids = _filterInvalidIds(ids, foreignSchemaType, skipInvalidIds);\n        $or.push({ [foreignField]: { $in: ids } });\n      } else if (foreignField === '_id' && match['_id']) {\n        const userSpecifiedMatch = hasDollarKeys(match[foreignField]) ?\n          match[foreignField] :\n          { $eq: match[foreignField] };\n        match[foreignField] = { ...trusted({ $in: ids }), ...userSpecifiedMatch };\n      }\n    }\n  }\n\n  return match;\n};\n\n/**\n * Optionally filter out invalid ids that don't conform to foreign field's schema\n * to avoid cast errors (gh-7706)\n * @param {Array} ids\n * @param {SchemaType} foreignSchemaType\n * @param {Boolean} [skipInvalidIds]\n * @api private\n */\n\nfunction _filterInvalidIds(ids, foreignSchemaType, skipInvalidIds) {\n  ids = ids.filter(v => !(v instanceof SkipPopulateValue));\n  if (!skipInvalidIds) {\n    return ids;\n  }\n  return ids.filter(id => {\n    try {\n      foreignSchemaType.cast(id);\n      return true;\n    } catch (err) {\n      return false;\n    }\n  });\n}\n\n/**\n * Format `mod.match` given that it may be an array that we need to $or if\n * the client has multiple docs with match functions\n * @param {Array|Any} match\n * @api private\n */\n\nfunction _formatMatch(match) {\n  if (Array.isArray(match)) {\n    if (match.length > 1) {\n      return { $or: [].concat(match.map(m => Object.assign({}, m))) };\n    }\n    return Object.assign({}, match[0]);\n  }\n  return Object.assign({}, match);\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/populate/createPopulateQueryFilter.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/populate/getModelsMapForPopulate.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/populate/getModelsMapForPopulate.js ***!
  \*******************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst MongooseError = __webpack_require__(/*! ../../error/index */ \"./node_modules/mongoose/lib/error/index.js\");\nconst SkipPopulateValue = __webpack_require__(/*! ./skipPopulateValue */ \"./node_modules/mongoose/lib/helpers/populate/skipPopulateValue.js\");\nconst clone = __webpack_require__(/*! ../clone */ \"./node_modules/mongoose/lib/helpers/clone.js\");\nconst get = __webpack_require__(/*! ../get */ \"./node_modules/mongoose/lib/helpers/get.js\");\nconst getDiscriminatorByValue = __webpack_require__(/*! ../discriminator/getDiscriminatorByValue */ \"./node_modules/mongoose/lib/helpers/discriminator/getDiscriminatorByValue.js\");\nconst getConstructorName = __webpack_require__(/*! ../getConstructorName */ \"./node_modules/mongoose/lib/helpers/getConstructorName.js\");\nconst getSchemaTypes = __webpack_require__(/*! ./getSchemaTypes */ \"./node_modules/mongoose/lib/helpers/populate/getSchemaTypes.js\");\nconst getVirtual = __webpack_require__(/*! ./getVirtual */ \"./node_modules/mongoose/lib/helpers/populate/getVirtual.js\");\nconst lookupLocalFields = __webpack_require__(/*! ./lookupLocalFields */ \"./node_modules/mongoose/lib/helpers/populate/lookupLocalFields.js\");\nconst mpath = __webpack_require__(/*! mpath */ \"./node_modules/mpath/index.js\");\nconst modelNamesFromRefPath = __webpack_require__(/*! ./modelNamesFromRefPath */ \"./node_modules/mongoose/lib/helpers/populate/modelNamesFromRefPath.js\");\nconst utils = __webpack_require__(/*! ../../utils */ \"./node_modules/mongoose/lib/utils.js\");\n\nconst modelSymbol = (__webpack_require__(/*! ../symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").modelSymbol);\nconst populateModelSymbol = (__webpack_require__(/*! ../symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").populateModelSymbol);\nconst schemaMixedSymbol = (__webpack_require__(/*! ../../schema/symbols */ \"./node_modules/mongoose/lib/schema/symbols.js\").schemaMixedSymbol);\nconst StrictPopulate = __webpack_require__(/*! ../../error/strictPopulate */ \"./node_modules/mongoose/lib/error/strictPopulate.js\");\n\nmodule.exports = function getModelsMapForPopulate(model, docs, options) {\n  let doc;\n  const len = docs.length;\n  const map = [];\n  const modelNameFromQuery = options.model && options.model.modelName || options.model;\n  let schema;\n  let refPath;\n  let modelNames;\n  const available = {};\n\n  const modelSchema = model.schema;\n\n  // Populating a nested path should always be a no-op re: #9073.\n  // People shouldn't do this, but apparently they do.\n  if (options._localModel != null && options._localModel.schema.nested[options.path]) {\n    return [];\n  }\n\n  const _virtualRes = getVirtual(model.schema, options.path);\n  const virtual = _virtualRes == null ? null : _virtualRes.virtual;\n  if (virtual != null) {\n    return _virtualPopulate(model, docs, options, _virtualRes);\n  }\n\n  let allSchemaTypes = getSchemaTypes(model, modelSchema, null, options.path);\n  allSchemaTypes = Array.isArray(allSchemaTypes) ? allSchemaTypes : [allSchemaTypes].filter(v => v != null);\n\n  const isStrictPopulateDisabled = options.strictPopulate === false || options.options?.strictPopulate === false;\n  if (!isStrictPopulateDisabled && allSchemaTypes.length === 0 && options._localModel != null) {\n    return new StrictPopulate(options._fullPath || options.path);\n  }\n\n  for (let i = 0; i < len; i++) {\n    doc = docs[i];\n    let justOne = null;\n\n    const docSchema = doc != null && doc.$__ != null ? doc.$__schema : modelSchema;\n    schema = getSchemaTypes(model, docSchema, doc, options.path);\n\n    // Special case: populating a path that's a DocumentArray unless\n    // there's an explicit `ref` or `refPath` re: gh-8946\n    if (schema != null &&\n        schema.$isMongooseDocumentArray &&\n        schema.options.ref == null &&\n        schema.options.refPath == null) {\n      continue;\n    }\n    const isUnderneathDocArray = schema && schema.$parentSchemaDocArray;\n    if (isUnderneathDocArray && get(options, 'options.sort') != null) {\n      return new MongooseError('Cannot populate with `sort` on path ' + options.path +\n        ' because it is a subproperty of a document array');\n    }\n\n    modelNames = null;\n    let isRefPath = false;\n    let normalizedRefPath = null;\n    let schemaOptions = null;\n    let modelNamesInOrder = null;\n\n    if (schema != null && schema.instance === 'Embedded') {\n      if (schema.options.ref) {\n        const data = {\n          localField: options.path + '._id',\n          foreignField: '_id',\n          justOne: true\n        };\n        const res = _getModelNames(doc, schema, modelNameFromQuery, model);\n\n        const unpopulatedValue = mpath.get(options.path, doc);\n        const id = mpath.get('_id', unpopulatedValue);\n        addModelNamesToMap(model, map, available, res.modelNames, options, data, id, doc, schemaOptions, unpopulatedValue);\n      }\n      // No-op if no `ref` set. See gh-11538\n      continue;\n    }\n\n    if (Array.isArray(schema)) {\n      const schemasArray = schema;\n      for (const _schema of schemasArray) {\n        let _modelNames;\n        let res;\n        try {\n          res = _getModelNames(doc, _schema, modelNameFromQuery, model);\n          _modelNames = res.modelNames;\n          isRefPath = isRefPath || res.isRefPath;\n          normalizedRefPath = normalizedRefPath || res.refPath;\n          justOne = res.justOne;\n        } catch (error) {\n          return error;\n        }\n\n        if (isRefPath && !res.isRefPath) {\n          continue;\n        }\n        if (!_modelNames) {\n          continue;\n        }\n        modelNames = modelNames || [];\n        for (const modelName of _modelNames) {\n          if (modelNames.indexOf(modelName) === -1) {\n            modelNames.push(modelName);\n          }\n        }\n      }\n    } else {\n      try {\n        const res = _getModelNames(doc, schema, modelNameFromQuery, model);\n        modelNames = res.modelNames;\n        isRefPath = res.isRefPath;\n        normalizedRefPath = normalizedRefPath || res.refPath;\n        justOne = res.justOne;\n        schemaOptions = get(schema, 'options.populate', null);\n        // Dedupe, because `refPath` can return duplicates of the same model name,\n        // and that causes perf issues.\n        if (isRefPath) {\n          modelNamesInOrder = modelNames;\n          modelNames = Array.from(new Set(modelNames));\n        }\n      } catch (error) {\n        return error;\n      }\n\n      if (!modelNames) {\n        continue;\n      }\n    }\n\n    const data = {};\n    const localField = options.path;\n    const foreignField = '_id';\n\n    // `justOne = null` means we don't know from the schema whether the end\n    // result should be an array or a single doc. This can result from\n    // populating a POJO using `Model.populate()`\n    if ('justOne' in options && options.justOne !== void 0) {\n      justOne = options.justOne;\n    } else if (schema && !schema[schemaMixedSymbol]) {\n      // Skip Mixed types because we explicitly don't do casting on those.\n      if (options.path.endsWith('.' + schema.path) || options.path === schema.path) {\n        justOne = Array.isArray(schema) ?\n          schema.every(schema => !schema.$isMongooseArray) :\n          !schema.$isMongooseArray;\n      }\n    }\n\n    if (!modelNames) {\n      continue;\n    }\n\n    data.isVirtual = false;\n    data.justOne = justOne;\n    data.localField = localField;\n    data.foreignField = foreignField;\n\n    // Get local fields\n    const ret = _getLocalFieldValues(doc, localField, model, options, null, schema);\n\n    const id = String(utils.getValue(foreignField, doc));\n    options._docs[id] = Array.isArray(ret) ? ret.slice() : ret;\n\n    let match = get(options, 'match', null);\n\n    const hasMatchFunction = typeof match === 'function';\n    if (hasMatchFunction) {\n      match = match.call(doc, doc);\n    }\n    data.match = match;\n    data.hasMatchFunction = hasMatchFunction;\n    data.isRefPath = isRefPath;\n    data.modelNamesInOrder = modelNamesInOrder;\n\n    if (isRefPath) {\n      const embeddedDiscriminatorModelNames = _findRefPathForDiscriminators(doc,\n        modelSchema, data, options, normalizedRefPath, ret);\n\n      modelNames = embeddedDiscriminatorModelNames || modelNames;\n    }\n\n    try {\n      addModelNamesToMap(model, map, available, modelNames, options, data, ret, doc, schemaOptions);\n    } catch (err) {\n      return err;\n    }\n  }\n  return map;\n\n  function _getModelNames(doc, schema, modelNameFromQuery, model) {\n    let modelNames;\n    let isRefPath = false;\n    let justOne = null;\n\n    const originalSchema = schema;\n    if (schema && schema.instance === 'Array') {\n      schema = schema.caster;\n    }\n    if (schema && schema.$isSchemaMap) {\n      schema = schema.$__schemaType;\n    }\n\n    const ref = schema && schema.options && schema.options.ref;\n    refPath = schema && schema.options && schema.options.refPath;\n    if (schema != null &&\n        schema[schemaMixedSymbol] &&\n        !ref &&\n        !refPath &&\n        !modelNameFromQuery) {\n      return { modelNames: null };\n    }\n\n    if (modelNameFromQuery) {\n      modelNames = [modelNameFromQuery]; // query options\n    } else if (refPath != null) {\n      if (typeof refPath === 'function') {\n        const subdocPath = options.path.slice(0, options.path.length - schema.path.length - 1);\n        const vals = mpath.get(subdocPath, doc, lookupLocalFields);\n        const subdocsBeingPopulated = Array.isArray(vals) ?\n          utils.array.flatten(vals) :\n          (vals ? [vals] : []);\n\n        modelNames = new Set();\n        for (const subdoc of subdocsBeingPopulated) {\n          refPath = refPath.call(subdoc, subdoc, options.path);\n          modelNamesFromRefPath(refPath, doc, options.path, modelSchema, options._queryProjection).\n            forEach(name => modelNames.add(name));\n        }\n        modelNames = Array.from(modelNames);\n      } else {\n        modelNames = modelNamesFromRefPath(refPath, doc, options.path, modelSchema, options._queryProjection);\n      }\n\n      isRefPath = true;\n    } else {\n      let ref;\n      let refPath;\n      let schemaForCurrentDoc;\n      let discriminatorValue;\n      let modelForCurrentDoc = model;\n      const discriminatorKey = model.schema.options.discriminatorKey;\n\n      if (!schema && discriminatorKey && (discriminatorValue = utils.getValue(discriminatorKey, doc))) {\n        // `modelNameForFind` is the discriminator value, so we might need\n        // find the discriminated model name\n        const discriminatorModel = getDiscriminatorByValue(model.discriminators, discriminatorValue) || model;\n        if (discriminatorModel != null) {\n          modelForCurrentDoc = discriminatorModel;\n        } else {\n          try {\n            modelForCurrentDoc = _getModelFromConn(model.db, discriminatorValue);\n          } catch (error) {\n            return error;\n          }\n        }\n\n        schemaForCurrentDoc = modelForCurrentDoc.schema._getSchema(options.path);\n\n        if (schemaForCurrentDoc && schemaForCurrentDoc.caster) {\n          schemaForCurrentDoc = schemaForCurrentDoc.caster;\n        }\n      } else {\n        schemaForCurrentDoc = schema;\n      }\n\n      if (originalSchema && originalSchema.path.endsWith('.$*')) {\n        justOne = !originalSchema.$isMongooseArray && !originalSchema._arrayPath;\n      } else if (schemaForCurrentDoc != null) {\n        justOne = !schemaForCurrentDoc.$isMongooseArray && !schemaForCurrentDoc._arrayPath;\n      }\n\n      if ((ref = get(schemaForCurrentDoc, 'options.ref')) != null) {\n        if (schemaForCurrentDoc != null &&\n            typeof ref === 'function' &&\n            options.path.endsWith('.' + schemaForCurrentDoc.path)) {\n          // Ensure correct context for ref functions: subdoc, not top-level doc. See gh-8469\n          modelNames = new Set();\n\n          const subdocPath = options.path.slice(0, options.path.length - schemaForCurrentDoc.path.length - 1);\n          const vals = mpath.get(subdocPath, doc, lookupLocalFields);\n          const subdocsBeingPopulated = Array.isArray(vals) ?\n            utils.array.flatten(vals) :\n            (vals ? [vals] : []);\n          for (const subdoc of subdocsBeingPopulated) {\n            modelNames.add(handleRefFunction(ref, subdoc));\n          }\n\n          if (subdocsBeingPopulated.length === 0) {\n            modelNames = [handleRefFunction(ref, doc)];\n          } else {\n            modelNames = Array.from(modelNames);\n          }\n        } else {\n          ref = handleRefFunction(ref, doc);\n          modelNames = [ref];\n        }\n      } else if ((schemaForCurrentDoc = get(schema, 'options.refPath')) != null) {\n        isRefPath = true;\n        if (typeof refPath === 'function') {\n          const subdocPath = options.path.slice(0, options.path.length - schemaForCurrentDoc.path.length - 1);\n          const vals = mpath.get(subdocPath, doc, lookupLocalFields);\n          const subdocsBeingPopulated = Array.isArray(vals) ?\n            utils.array.flatten(vals) :\n            (vals ? [vals] : []);\n\n          modelNames = new Set();\n          for (const subdoc of subdocsBeingPopulated) {\n            refPath = refPath.call(subdoc, subdoc, options.path);\n            modelNamesFromRefPath(refPath, doc, options.path, modelSchema, options._queryProjection).\n              forEach(name => modelNames.add(name));\n          }\n          modelNames = Array.from(modelNames);\n        } else {\n          modelNames = modelNamesFromRefPath(refPath, doc, options.path, modelSchema, options._queryProjection);\n        }\n      }\n    }\n\n    if (!modelNames) {\n      // `Model.populate()` on a POJO with no known local model. Default to using the `Model`\n      if (options._localModel == null) {\n        modelNames = [model.modelName];\n      } else {\n        return { modelNames: modelNames, justOne: justOne, isRefPath: isRefPath, refPath: refPath };\n      }\n    }\n\n    if (!Array.isArray(modelNames)) {\n      modelNames = [modelNames];\n    }\n\n    return { modelNames: modelNames, justOne: justOne, isRefPath: isRefPath, refPath: refPath };\n  }\n};\n\n/*!\n * ignore\n */\n\nfunction _virtualPopulate(model, docs, options, _virtualRes) {\n  const map = [];\n  const available = {};\n  const virtual = _virtualRes.virtual;\n\n  for (const doc of docs) {\n    let modelNames = null;\n    const data = {};\n\n    // localField and foreignField\n    let localField;\n    const virtualPrefix = _virtualRes.nestedSchemaPath ?\n      _virtualRes.nestedSchemaPath + '.' : '';\n    if (typeof options.localField === 'string') {\n      localField = options.localField;\n    } else if (typeof virtual.options.localField === 'function') {\n      localField = virtualPrefix + virtual.options.localField.call(doc, doc);\n    } else if (Array.isArray(virtual.options.localField)) {\n      localField = virtual.options.localField.map(field => virtualPrefix + field);\n    } else {\n      localField = virtualPrefix + virtual.options.localField;\n    }\n    data.count = virtual.options.count;\n\n    if (virtual.options.skip != null && !options.hasOwnProperty('skip')) {\n      options.skip = virtual.options.skip;\n    }\n    if (virtual.options.limit != null && !options.hasOwnProperty('limit')) {\n      options.limit = virtual.options.limit;\n    }\n    if (virtual.options.perDocumentLimit != null && !options.hasOwnProperty('perDocumentLimit')) {\n      options.perDocumentLimit = virtual.options.perDocumentLimit;\n    }\n    let foreignField = virtual.options.foreignField;\n\n    if (!localField || !foreignField) {\n      return new MongooseError(`Cannot populate virtual \\`${options.path}\\` on model \\`${model.modelName}\\`, because options \\`localField\\` and / or \\`foreignField\\` are missing`);\n    }\n\n    if (typeof localField === 'function') {\n      localField = localField.call(doc, doc);\n    }\n    if (typeof foreignField === 'function') {\n      foreignField = foreignField.call(doc, doc);\n    }\n\n    data.isRefPath = false;\n\n    // `justOne = null` means we don't know from the schema whether the end\n    // result should be an array or a single doc. This can result from\n    // populating a POJO using `Model.populate()`\n    let justOne = null;\n    if ('justOne' in options && options.justOne !== void 0) {\n      justOne = options.justOne;\n    }\n\n    modelNames = virtual._getModelNamesForPopulate(doc);\n    if (virtual.options.refPath) {\n      justOne = !!virtual.options.justOne;\n      data.isRefPath = true;\n    } else if (virtual.options.ref) {\n      justOne = !!virtual.options.justOne;\n    }\n\n    data.isVirtual = true;\n    data.virtual = virtual;\n    data.justOne = justOne;\n\n    // `match`\n    const baseMatch = get(data, 'virtual.options.match', null) ||\n      get(data, 'virtual.options.options.match', null);\n    let match = get(options, 'match', null) || baseMatch;\n\n    let hasMatchFunction = typeof match === 'function';\n    if (hasMatchFunction) {\n      match = match.call(doc, doc, data.virtual);\n    }\n\n    if (Array.isArray(localField) && Array.isArray(foreignField) && localField.length === foreignField.length) {\n      match = Object.assign({}, match);\n      for (let i = 1; i < localField.length; ++i) {\n        match[foreignField[i]] = convertTo_id(mpath.get(localField[i], doc, lookupLocalFields), model.schema);\n        hasMatchFunction = true;\n      }\n\n      localField = localField[0];\n      foreignField = foreignField[0];\n    }\n    data.localField = localField;\n    data.foreignField = foreignField;\n    data.match = match;\n    data.hasMatchFunction = hasMatchFunction;\n\n    // Get local fields\n    const ret = _getLocalFieldValues(doc, localField, model, options, virtual);\n\n    try {\n      addModelNamesToMap(model, map, available, modelNames, options, data, ret, doc);\n    } catch (err) {\n      return err;\n    }\n  }\n\n  return map;\n}\n\n/*!\n * ignore\n */\n\nfunction addModelNamesToMap(model, map, available, modelNames, options, data, ret, doc, schemaOptions, unpopulatedValue) {\n  // `PopulateOptions#connection`: if the model is passed as a string, the\n  // connection matters because different connections have different models.\n  const connection = options.connection != null ? options.connection : model.db;\n\n  unpopulatedValue = unpopulatedValue === void 0 ? ret : unpopulatedValue;\n  if (Array.isArray(unpopulatedValue)) {\n    unpopulatedValue = utils.cloneArrays(unpopulatedValue);\n  }\n\n  if (modelNames == null) {\n    return;\n  }\n\n  let k = modelNames.length;\n  while (k--) {\n    let modelName = modelNames[k];\n    if (modelName == null) {\n      continue;\n    }\n\n    let Model;\n    if (options.model && options.model[modelSymbol]) {\n      Model = options.model;\n    } else if (modelName[modelSymbol]) {\n      Model = modelName;\n      modelName = Model.modelName;\n    } else {\n      try {\n        Model = _getModelFromConn(connection, modelName);\n      } catch (err) {\n        if (ret !== void 0) {\n          throw err;\n        }\n        Model = null;\n      }\n    }\n\n    let ids = ret;\n    const flat = Array.isArray(ret) ? utils.array.flatten(ret) : [];\n\n    const modelNamesForRefPath = data.modelNamesInOrder ? data.modelNamesInOrder : modelNames;\n    if (data.isRefPath && Array.isArray(ret) && flat.length === modelNamesForRefPath.length) {\n      ids = flat.filter((val, i) => modelNamesForRefPath[i] === modelName);\n    }\n\n    const perDocumentLimit = options.perDocumentLimit == null ?\n      get(options, 'options.perDocumentLimit', null) :\n      options.perDocumentLimit;\n\n    if (!available[modelName] || perDocumentLimit != null) {\n      const currentOptions = {\n        model: Model\n      };\n      if (data.isVirtual && get(data.virtual, 'options.options')) {\n        currentOptions.options = clone(data.virtual.options.options);\n      } else if (schemaOptions != null) {\n        currentOptions.options = Object.assign({}, schemaOptions);\n      }\n      utils.merge(currentOptions, options);\n\n      // Used internally for checking what model was used to populate this\n      // path.\n      options[populateModelSymbol] = Model;\n      currentOptions[populateModelSymbol] = Model;\n      available[modelName] = {\n        model: Model,\n        options: currentOptions,\n        match: data.hasMatchFunction ? [data.match] : data.match,\n        docs: [doc],\n        ids: [ids],\n        allIds: [ret],\n        unpopulatedValues: [unpopulatedValue],\n        localField: new Set([data.localField]),\n        foreignField: new Set([data.foreignField]),\n        justOne: data.justOne,\n        isVirtual: data.isVirtual,\n        virtual: data.virtual,\n        count: data.count,\n        [populateModelSymbol]: Model\n      };\n      map.push(available[modelName]);\n    } else {\n      available[modelName].localField.add(data.localField);\n      available[modelName].foreignField.add(data.foreignField);\n      available[modelName].docs.push(doc);\n      available[modelName].ids.push(ids);\n      available[modelName].allIds.push(ret);\n      available[modelName].unpopulatedValues.push(unpopulatedValue);\n      if (data.hasMatchFunction) {\n        available[modelName].match.push(data.match);\n      }\n    }\n  }\n}\n\nfunction _getModelFromConn(conn, modelName) {\n  /* If this connection has a parent from `useDb()`, bubble up to parent's models */\n  if (conn.models[modelName] == null && conn._parent != null) {\n    return _getModelFromConn(conn._parent, modelName);\n  }\n\n  return conn.model(modelName);\n}\n\n/*!\n * ignore\n */\n\nfunction handleRefFunction(ref, doc) {\n  if (typeof ref === 'function' && !ref[modelSymbol]) {\n    return ref.call(doc, doc);\n  }\n  return ref;\n}\n\n/*!\n * ignore\n */\n\nfunction _getLocalFieldValues(doc, localField, model, options, virtual, schema) {\n  // Get Local fields\n  const localFieldPathType = model.schema._getPathType(localField);\n  const localFieldPath = localFieldPathType === 'real' ?\n    model.schema.path(localField) :\n    localFieldPathType.schema;\n  const localFieldGetters = localFieldPath && localFieldPath.getters ?\n    localFieldPath.getters : [];\n\n  localField = localFieldPath != null && localFieldPath.instance === 'Embedded' ? localField + '._id' : localField;\n\n  const _populateOptions = get(options, 'options', {});\n\n  const getters = 'getters' in _populateOptions ?\n    _populateOptions.getters :\n    get(virtual, 'options.getters', false);\n  if (localFieldGetters.length !== 0 && getters) {\n    const hydratedDoc = (doc.$__ != null) ? doc : model.hydrate(doc);\n    const localFieldValue = utils.getValue(localField, doc);\n    if (Array.isArray(localFieldValue)) {\n      const localFieldHydratedValue = utils.getValue(localField.split('.').slice(0, -1), hydratedDoc);\n      return localFieldValue.map((localFieldArrVal, localFieldArrIndex) =>\n        localFieldPath.applyGetters(localFieldArrVal, localFieldHydratedValue[localFieldArrIndex]));\n    } else {\n      return localFieldPath.applyGetters(localFieldValue, hydratedDoc);\n    }\n  } else {\n    return convertTo_id(mpath.get(localField, doc, lookupLocalFields), schema);\n  }\n}\n\n/**\n * Retrieve the _id of `val` if a Document or Array of Documents.\n *\n * @param {Array|Document|Any} val\n * @param {Schema} schema\n * @return {Array|Document|Any}\n * @api private\n */\n\nfunction convertTo_id(val, schema) {\n  if (val != null && val.$__ != null) {\n    return val._id;\n  }\n  if (val != null && val._id != null && (schema == null || !schema.$isSchemaMap)) {\n    return val._id;\n  }\n\n  if (Array.isArray(val)) {\n    const rawVal = val.__array != null ? val.__array : val;\n    for (let i = 0; i < rawVal.length; ++i) {\n      if (rawVal[i] != null && rawVal[i].$__ != null) {\n        rawVal[i] = rawVal[i]._id;\n      }\n    }\n    if (utils.isMongooseArray(val) && val.$schema()) {\n      return val.$schema()._castForPopulate(val, val.$parent());\n    }\n\n    return [].concat(val);\n  }\n\n  // `populate('map')` may be an object if populating on a doc that hasn't\n  // been hydrated yet\n  if (getConstructorName(val) === 'Object' &&\n      // The intent here is we should only flatten the object if we expect\n      // to get a Map in the end. Avoid doing this for mixed types.\n      (schema == null || schema[schemaMixedSymbol] == null)) {\n    const ret = [];\n    for (const key of Object.keys(val)) {\n      ret.push(val[key]);\n    }\n    return ret;\n  }\n  // If doc has already been hydrated, e.g. `doc.populate('map')`\n  // then `val` will already be a map\n  if (val instanceof Map) {\n    return Array.from(val.values());\n  }\n\n  return val;\n}\n\n/*!\n * ignore\n */\n\nfunction _findRefPathForDiscriminators(doc, modelSchema, data, options, normalizedRefPath, ret) {\n  // Re: gh-8452. Embedded discriminators may not have `refPath`, so clear\n  // out embedded discriminator docs that don't have a `refPath` on the\n  // populated path.\n  if (!data.isRefPath || normalizedRefPath == null) {\n    return;\n  }\n\n  const pieces = normalizedRefPath.split('.');\n  let cur = '';\n  let modelNames = void 0;\n  for (let i = 0; i < pieces.length; ++i) {\n    const piece = pieces[i];\n    cur = cur + (cur.length === 0 ? '' : '.') + piece;\n    const schematype = modelSchema.path(cur);\n    if (schematype != null &&\n        schematype.$isMongooseArray &&\n        schematype.caster.discriminators != null &&\n        Object.keys(schematype.caster.discriminators).length !== 0) {\n      const subdocs = utils.getValue(cur, doc);\n      const remnant = options.path.substring(cur.length + 1);\n      const discriminatorKey = schematype.caster.schema.options.discriminatorKey;\n      modelNames = [];\n      for (const subdoc of subdocs) {\n        const discriminatorName = utils.getValue(discriminatorKey, subdoc);\n        const discriminator = schematype.caster.discriminators[discriminatorName];\n        const discriminatorSchema = discriminator && discriminator.schema;\n        if (discriminatorSchema == null) {\n          continue;\n        }\n        const _path = discriminatorSchema.path(remnant);\n        if (_path == null || _path.options.refPath == null) {\n          const docValue = utils.getValue(data.localField.substring(cur.length + 1), subdoc);\n          ret.forEach((v, i) => {\n            if (v === docValue) {\n              ret[i] = SkipPopulateValue(v);\n            }\n          });\n          continue;\n        }\n        const modelName = utils.getValue(pieces.slice(i + 1).join('.'), subdoc);\n        modelNames.push(modelName);\n      }\n    }\n  }\n\n  return modelNames;\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/populate/getModelsMapForPopulate.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/populate/getSchemaTypes.js":
/*!**********************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/populate/getSchemaTypes.js ***!
  \**********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * ignore\n */\n\nconst Mixed = __webpack_require__(/*! ../../schema/mixed */ \"./node_modules/mongoose/lib/schema/mixed.js\");\nconst get = __webpack_require__(/*! ../get */ \"./node_modules/mongoose/lib/helpers/get.js\");\nconst getDiscriminatorByValue = __webpack_require__(/*! ../discriminator/getDiscriminatorByValue */ \"./node_modules/mongoose/lib/helpers/discriminator/getDiscriminatorByValue.js\");\nconst leanPopulateMap = __webpack_require__(/*! ./leanPopulateMap */ \"./node_modules/mongoose/lib/helpers/populate/leanPopulateMap.js\");\nconst mpath = __webpack_require__(/*! mpath */ \"./node_modules/mpath/index.js\");\n\nconst populateModelSymbol = (__webpack_require__(/*! ../symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").populateModelSymbol);\n\n/**\n * Given a model and its schema, find all possible schema types for `path`,\n * including searching through discriminators. If `doc` is specified, will\n * use the doc's values for discriminator keys when searching, otherwise\n * will search all discriminators.\n *\n * @param {Model} model\n * @param {Schema} schema\n * @param {Object} doc POJO\n * @param {string} path\n * @api private\n */\n\nmodule.exports = function getSchemaTypes(model, schema, doc, path) {\n  const pathschema = schema.path(path);\n  const topLevelDoc = doc;\n  if (pathschema) {\n    return pathschema;\n  }\n\n  const discriminatorKey = schema.discriminatorMapping &&\n    schema.discriminatorMapping.key;\n  if (discriminatorKey && model != null) {\n    if (doc != null && doc[discriminatorKey] != null) {\n      const discriminator = getDiscriminatorByValue(model.discriminators, doc[discriminatorKey]);\n      schema = discriminator ? discriminator.schema : schema;\n    } else if (model.discriminators != null) {\n      return Object.keys(model.discriminators).reduce((arr, name) => {\n        const disc = model.discriminators[name];\n        return arr.concat(getSchemaTypes(disc, disc.schema, null, path));\n      }, []);\n    }\n  }\n\n  function search(parts, schema, subdoc, nestedPath) {\n    let p = parts.length + 1;\n    let foundschema;\n    let trypath;\n\n    while (p--) {\n      trypath = parts.slice(0, p).join('.');\n      foundschema = schema.path(trypath);\n      if (foundschema == null) {\n        continue;\n      }\n\n      if (foundschema.caster) {\n        // array of Mixed?\n        if (foundschema.caster instanceof Mixed) {\n          return foundschema.caster;\n        }\n\n        let schemas = null;\n        if (foundschema.schema != null && foundschema.schema.discriminators != null) {\n          const discriminators = foundschema.schema.discriminators;\n          const discriminatorKeyPath = trypath + '.' +\n            foundschema.schema.options.discriminatorKey;\n          const keys = subdoc ? mpath.get(discriminatorKeyPath, subdoc) || [] : [];\n          schemas = Object.keys(discriminators).\n            reduce(function(cur, discriminator) {\n              const tiedValue = discriminators[discriminator].discriminatorMapping.value;\n              if (doc == null || keys.indexOf(discriminator) !== -1 || keys.indexOf(tiedValue) !== -1) {\n                cur.push(discriminators[discriminator]);\n              }\n              return cur;\n            }, []);\n        }\n\n        // Now that we found the array, we need to check if there\n        // are remaining document paths to look up for casting.\n        // Also we need to handle array.$.path since schema.path\n        // doesn't work for that.\n        // If there is no foundschema.schema we are dealing with\n        // a path like array.$\n        if (p !== parts.length && foundschema.schema) {\n          let ret;\n          if (parts[p] === '$') {\n            if (p + 1 === parts.length) {\n              // comments.$\n              return foundschema;\n            }\n            // comments.$.comments.$.title\n            ret = search(\n              parts.slice(p + 1),\n              schema,\n              subdoc ? mpath.get(trypath, subdoc) : null,\n              nestedPath.concat(parts.slice(0, p))\n            );\n            if (ret) {\n              ret.$parentSchemaDocArray = ret.$parentSchemaDocArray ||\n                (foundschema.schema.$isSingleNested ? null : foundschema);\n            }\n            return ret;\n          }\n\n          if (schemas != null && schemas.length > 0) {\n            ret = [];\n            for (const schema of schemas) {\n              const _ret = search(\n                parts.slice(p),\n                schema,\n                subdoc ? mpath.get(trypath, subdoc) : null,\n                nestedPath.concat(parts.slice(0, p))\n              );\n              if (_ret != null) {\n                _ret.$parentSchemaDocArray = _ret.$parentSchemaDocArray ||\n                  (foundschema.schema.$isSingleNested ? null : foundschema);\n                if (_ret.$parentSchemaDocArray) {\n                  ret.$parentSchemaDocArray = _ret.$parentSchemaDocArray;\n                }\n                ret.push(_ret);\n              }\n            }\n            return ret;\n          } else {\n            ret = search(\n              parts.slice(p),\n              foundschema.schema,\n              subdoc ? mpath.get(trypath, subdoc) : null,\n              nestedPath.concat(parts.slice(0, p))\n            );\n\n            if (ret) {\n              ret.$parentSchemaDocArray = ret.$parentSchemaDocArray ||\n                (foundschema.schema.$isSingleNested ? null : foundschema);\n            }\n            return ret;\n          }\n        } else if (p !== parts.length &&\n            foundschema.$isMongooseArray &&\n            foundschema.casterConstructor.$isMongooseArray) {\n          // Nested arrays. Drill down to the bottom of the nested array.\n          let type = foundschema;\n          while (type.$isMongooseArray && !type.$isMongooseDocumentArray) {\n            type = type.casterConstructor;\n          }\n\n          const ret = search(\n            parts.slice(p),\n            type.schema,\n            null,\n            nestedPath.concat(parts.slice(0, p))\n          );\n          if (ret != null) {\n            return ret;\n          }\n\n          if (type.schema.discriminators) {\n            const discriminatorPaths = [];\n            for (const discriminatorName of Object.keys(type.schema.discriminators)) {\n              const _schema = type.schema.discriminators[discriminatorName] || type.schema;\n              const ret = search(parts.slice(p), _schema, null, nestedPath.concat(parts.slice(0, p)));\n              if (ret != null) {\n                discriminatorPaths.push(ret);\n              }\n            }\n            if (discriminatorPaths.length > 0) {\n              return discriminatorPaths;\n            }\n          }\n        }\n      } else if (foundschema.$isSchemaMap && foundschema.$__schemaType instanceof Mixed) {\n        return foundschema.$__schemaType;\n      }\n\n      const fullPath = nestedPath.concat([trypath]).join('.');\n      if (topLevelDoc != null && topLevelDoc.$__ && topLevelDoc.$populated(fullPath) && p < parts.length) {\n        const model = doc.$__.populated[fullPath].options[populateModelSymbol];\n        if (model != null) {\n          const ret = search(\n            parts.slice(p),\n            model.schema,\n            subdoc ? mpath.get(trypath, subdoc) : null,\n            nestedPath.concat(parts.slice(0, p))\n          );\n\n          return ret;\n        }\n      }\n\n      const _val = get(topLevelDoc, trypath);\n      if (_val != null) {\n        const model = Array.isArray(_val) && _val.length > 0 ?\n          leanPopulateMap.get(_val[0]) :\n          leanPopulateMap.get(_val);\n        // Populated using lean, `leanPopulateMap` value is the foreign model\n        const schema = model != null ? model.schema : null;\n        if (schema != null) {\n          const ret = search(\n            parts.slice(p),\n            schema,\n            subdoc ? mpath.get(trypath, subdoc) : null,\n            nestedPath.concat(parts.slice(0, p))\n          );\n\n          if (ret != null) {\n            ret.$parentSchemaDocArray = ret.$parentSchemaDocArray ||\n              (schema.$isSingleNested ? null : schema);\n            return ret;\n          }\n        }\n      }\n      return foundschema;\n    }\n  }\n  // look for arrays\n  const parts = path.split('.');\n  for (let i = 0; i < parts.length; ++i) {\n    if (parts[i] === '$') {\n      // Re: gh-5628, because `schema.path()` doesn't take $ into account.\n      parts[i] = '0';\n    }\n  }\n  return search(parts, schema, doc, []);\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/populate/getSchemaTypes.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/populate/getVirtual.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/populate/getVirtual.js ***!
  \******************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = getVirtual;\n\n/*!\n * ignore\n */\n\nfunction getVirtual(schema, name) {\n  if (schema.virtuals[name]) {\n    return { virtual: schema.virtuals[name], path: void 0 };\n  }\n\n  const parts = name.split('.');\n  let cur = '';\n  let nestedSchemaPath = '';\n  for (let i = 0; i < parts.length; ++i) {\n    cur += (cur.length > 0 ? '.' : '') + parts[i];\n    if (schema.virtuals[cur]) {\n      if (i === parts.length - 1) {\n        return { virtual: schema.virtuals[cur], path: nestedSchemaPath };\n      }\n      continue;\n    }\n\n    if (schema.nested[cur]) {\n      continue;\n    }\n\n    if (schema.paths[cur] && schema.paths[cur].schema) {\n      schema = schema.paths[cur].schema;\n      const rest = parts.slice(i + 1).join('.');\n\n      if (schema.virtuals[rest]) {\n        if (i === parts.length - 2) {\n          return {\n            virtual: schema.virtuals[rest],\n            nestedSchemaPath: [nestedSchemaPath, cur].filter(v => !!v).join('.')\n          };\n        }\n        continue;\n      }\n\n      if (i + 1 < parts.length && schema.discriminators) {\n        for (const key of Object.keys(schema.discriminators)) {\n          const res = getVirtual(schema.discriminators[key], rest);\n          if (res != null) {\n            const _path = [nestedSchemaPath, cur, res.nestedSchemaPath].\n              filter(v => !!v).join('.');\n            return {\n              virtual: res.virtual,\n              nestedSchemaPath: _path\n            };\n          }\n        }\n      }\n\n      nestedSchemaPath += (nestedSchemaPath.length > 0 ? '.' : '') + cur;\n      cur = '';\n      continue;\n    }\n\n    if (schema.discriminators) {\n      for (const discriminatorKey of Object.keys(schema.discriminators)) {\n        const virtualFromDiscriminator = getVirtual(schema.discriminators[discriminatorKey], name);\n        if (virtualFromDiscriminator) return virtualFromDiscriminator;\n      }\n    }\n\n    return null;\n  }\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/populate/getVirtual.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/populate/leanPopulateMap.js":
/*!***********************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/populate/leanPopulateMap.js ***!
  \***********************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/*!\n * ignore\n */\n\nmodule.exports = new WeakMap();\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/populate/leanPopulateMap.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/populate/lookupLocalFields.js":
/*!*************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/populate/lookupLocalFields.js ***!
  \*************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function lookupLocalFields(cur, path, val) {\n  if (cur == null) {\n    return cur;\n  }\n\n  if (cur._doc != null) {\n    cur = cur._doc;\n  }\n\n  if (arguments.length >= 3) {\n    if (typeof cur !== 'object') {\n      return void 0;\n    }\n    if (val === void 0) {\n      return void 0;\n    }\n    if (cur instanceof Map) {\n      cur.set(path, val);\n    } else {\n      cur[path] = val;\n    }\n    return val;\n  }\n\n\n  // Support populating paths under maps using `map.$*.subpath`\n  if (path === '$*') {\n    return cur instanceof Map ?\n      Array.from(cur.values()) :\n      Object.keys(cur).map(key => cur[key]);\n  }\n\n  if (cur instanceof Map) {\n    return cur.get(path);\n  }\n\n  return cur[path];\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/populate/lookupLocalFields.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/populate/markArraySubdocsPopulated.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/populate/markArraySubdocsPopulated.js ***!
  \*********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst utils = __webpack_require__(/*! ../../utils */ \"./node_modules/mongoose/lib/utils.js\");\n\n/**\n * If populating a path within a document array, make sure each\n * subdoc within the array knows its subpaths are populated.\n *\n * #### Example:\n *\n *     const doc = await Article.findOne().populate('comments.author');\n *     doc.comments[0].populated('author'); // Should be set\n *\n * @param {Document} doc\n * @param {Object} [populated]\n * @api private\n */\n\nmodule.exports = function markArraySubdocsPopulated(doc, populated) {\n  if (doc._id == null || populated == null || populated.length === 0) {\n    return;\n  }\n\n  const id = String(doc._id);\n  for (const item of populated) {\n    if (item.isVirtual) {\n      continue;\n    }\n    const path = item.path;\n    const pieces = path.split('.');\n    for (let i = 0; i < pieces.length - 1; ++i) {\n      const subpath = pieces.slice(0, i + 1).join('.');\n      const rest = pieces.slice(i + 1).join('.');\n      const val = doc.get(subpath);\n      if (val == null) {\n        continue;\n      }\n\n      if (utils.isMongooseDocumentArray(val)) {\n        for (let j = 0; j < val.length; ++j) {\n          if (val[j]) {\n            val[j].populated(rest, item._docs[id] == null ? void 0 : item._docs[id][j], item);\n          }\n        }\n        break;\n      }\n    }\n  }\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/populate/markArraySubdocsPopulated.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/populate/modelNamesFromRefPath.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/populate/modelNamesFromRefPath.js ***!
  \*****************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst MongooseError = __webpack_require__(/*! ../../error/mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\nconst isPathExcluded = __webpack_require__(/*! ../projection/isPathExcluded */ \"./node_modules/mongoose/lib/helpers/projection/isPathExcluded.js\");\nconst lookupLocalFields = __webpack_require__(/*! ./lookupLocalFields */ \"./node_modules/mongoose/lib/helpers/populate/lookupLocalFields.js\");\nconst mpath = __webpack_require__(/*! mpath */ \"./node_modules/mpath/index.js\");\nconst util = __webpack_require__(/*! util */ \"util\");\nconst utils = __webpack_require__(/*! ../../utils */ \"./node_modules/mongoose/lib/utils.js\");\n\nconst hasNumericPropRE = /(\\.\\d+$|\\.\\d+\\.)/g;\n\nmodule.exports = function modelNamesFromRefPath(refPath, doc, populatedPath, modelSchema, queryProjection) {\n  if (refPath == null) {\n    return [];\n  }\n\n  if (typeof refPath === 'string' && queryProjection != null && isPathExcluded(queryProjection, refPath)) {\n    throw new MongooseError('refPath `' + refPath + '` must not be excluded in projection, got ' +\n      util.inspect(queryProjection));\n  }\n\n  // If populated path has numerics, the end `refPath` should too. For example,\n  // if populating `a.0.b` instead of `a.b` and `b` has `refPath = a.c`, we\n  // should return `a.0.c` for the refPath.\n\n  if (hasNumericPropRE.test(populatedPath)) {\n    const chunks = populatedPath.split(hasNumericPropRE);\n\n    if (chunks[chunks.length - 1] === '') {\n      throw new Error('Can\\'t populate individual element in an array');\n    }\n\n    let _refPath = '';\n    let _remaining = refPath;\n    // 2nd, 4th, etc. will be numeric props. For example: `[ 'a', '.0.', 'b' ]`\n    for (let i = 0; i < chunks.length; i += 2) {\n      const chunk = chunks[i];\n      if (_remaining.startsWith(chunk + '.')) {\n        _refPath += _remaining.substring(0, chunk.length) + chunks[i + 1];\n        _remaining = _remaining.substring(chunk.length + 1);\n      } else if (i === chunks.length - 1) {\n        _refPath += _remaining;\n        _remaining = '';\n        break;\n      } else {\n        throw new Error('Could not normalize ref path, chunk ' + chunk + ' not in populated path');\n      }\n    }\n\n    const refValue = mpath.get(_refPath, doc, lookupLocalFields);\n    let modelNames = Array.isArray(refValue) ? refValue : [refValue];\n    modelNames = utils.array.flatten(modelNames);\n    return modelNames;\n  }\n\n  const refValue = mpath.get(refPath, doc, lookupLocalFields);\n\n  let modelNames;\n  if (modelSchema != null && modelSchema.virtuals.hasOwnProperty(refPath)) {\n    modelNames = [modelSchema.virtuals[refPath].applyGetters(void 0, doc)];\n  } else {\n    modelNames = Array.isArray(refValue) ? refValue : [refValue];\n  }\n\n  modelNames = utils.array.flatten(modelNames);\n\n  return modelNames;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/populate/modelNamesFromRefPath.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/populate/removeDeselectedForeignField.js":
/*!************************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/populate/removeDeselectedForeignField.js ***!
  \************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst get = __webpack_require__(/*! ../get */ \"./node_modules/mongoose/lib/helpers/get.js\");\nconst mpath = __webpack_require__(/*! mpath */ \"./node_modules/mpath/index.js\");\nconst parseProjection = __webpack_require__(/*! ../projection/parseProjection */ \"./node_modules/mongoose/lib/helpers/projection/parseProjection.js\");\n\n/*!\n * ignore\n */\n\nmodule.exports = function removeDeselectedForeignField(foreignFields, options, docs) {\n  const projection = parseProjection(get(options, 'select', null), true) ||\n    parseProjection(get(options, 'options.select', null), true);\n\n  if (projection == null) {\n    return;\n  }\n  for (const foreignField of foreignFields) {\n    if (!projection.hasOwnProperty('-' + foreignField)) {\n      continue;\n    }\n\n    for (const val of docs) {\n      if (val.$__ != null) {\n        mpath.unset(foreignField, val._doc);\n      } else {\n        mpath.unset(foreignField, val);\n      }\n    }\n  }\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/populate/removeDeselectedForeignField.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/populate/setPopulatedVirtualValue.js":
/*!********************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/populate/setPopulatedVirtualValue.js ***!
  \********************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/**\n * Set a populated virtual value on a document's `$$populatedVirtuals` value\n *\n * @param {*} populatedVirtuals A document's `$$populatedVirtuals`\n * @param {*} name The virtual name\n * @param {*} v The result of the populate query\n * @param {*} options The populate options. This function handles `justOne` and `count` options.\n * @returns {Array<Document>|Document|Object|Array<Object>} the populated virtual value that was set\n */\n\nmodule.exports = function setPopulatedVirtualValue(populatedVirtuals, name, v, options) {\n  if (options.justOne || options.count) {\n    populatedVirtuals[name] = Array.isArray(v) ?\n      v[0] :\n      v;\n\n    if (typeof populatedVirtuals[name] !== 'object') {\n      populatedVirtuals[name] = options.count ? v : null;\n    }\n  } else {\n    populatedVirtuals[name] = Array.isArray(v) ?\n      v :\n      v == null ? [] : [v];\n\n    populatedVirtuals[name] = populatedVirtuals[name].filter(function(doc) {\n      return doc && typeof doc === 'object';\n    });\n  }\n\n  return populatedVirtuals[name];\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/populate/setPopulatedVirtualValue.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/populate/skipPopulateValue.js":
/*!*************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/populate/skipPopulateValue.js ***!
  \*************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function SkipPopulateValue(val) {\n  if (!(this instanceof SkipPopulateValue)) {\n    return new SkipPopulateValue(val);\n  }\n\n  this.val = val;\n  return this;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/populate/skipPopulateValue.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/populate/validateRef.js":
/*!*******************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/populate/validateRef.js ***!
  \*******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst MongooseError = __webpack_require__(/*! ../../error/mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\nconst util = __webpack_require__(/*! util */ \"util\");\n\nmodule.exports = validateRef;\n\nfunction validateRef(ref, path) {\n  if (typeof ref === 'string') {\n    return;\n  }\n\n  if (typeof ref === 'function') {\n    return;\n  }\n\n  throw new MongooseError('Invalid ref at path \"' + path + '\". Got ' +\n    util.inspect(ref, { depth: 0 }));\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/populate/validateRef.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/printJestWarning.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/printJestWarning.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst utils = __webpack_require__(/*! ../utils */ \"./node_modules/mongoose/lib/utils.js\");\n\nif (typeof jest !== 'undefined' && !process.env.SUPPRESS_JEST_WARNINGS) {\n  if (typeof window !== 'undefined') {\n    utils.warn('Mongoose: looks like you\\'re trying to test a Mongoose app ' +\n      'with Jest\\'s default jsdom test environment. Please make sure you read ' +\n      'Mongoose\\'s docs on configuring Jest to test Node.js apps: ' +\n      'https://mongoosejs.com/docs/jest.html. Set the SUPPRESS_JEST_WARNINGS to true ' +\n      'to hide this warning.');\n  }\n\n  if (setTimeout.clock != null && typeof setTimeout.clock.Date === 'function') {\n    utils.warn('Mongoose: looks like you\\'re trying to test a Mongoose app ' +\n      'with Jest\\'s mock timers enabled. Please make sure you read ' +\n      'Mongoose\\'s docs on configuring Jest to test Node.js apps: ' +\n      'https://mongoosejs.com/docs/jest.html. Set the SUPPRESS_JEST_WARNINGS to true ' +\n      'to hide this warning.');\n  }\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/printJestWarning.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/processConnectionOptions.js":
/*!***********************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/processConnectionOptions.js ***!
  \***********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst clone = __webpack_require__(/*! ./clone */ \"./node_modules/mongoose/lib/helpers/clone.js\");\nconst MongooseError = __webpack_require__(/*! ../error/index */ \"./node_modules/mongoose/lib/error/index.js\");\n\nfunction processConnectionOptions(uri, options) {\n  const opts = options ? options : {};\n  const readPreference = opts.readPreference\n    ? opts.readPreference\n    : getUriReadPreference(uri);\n\n  const clonedOpts = clone(opts);\n  const resolvedOpts = (readPreference && readPreference !== 'primary' && readPreference !== 'primaryPreferred')\n    ? resolveOptsConflicts(readPreference, clonedOpts)\n    : clonedOpts;\n\n  return resolvedOpts;\n}\n\nfunction resolveOptsConflicts(pref, opts) {\n  // don't silently override user-provided indexing options\n  if (setsIndexOptions(opts) && setsSecondaryRead(pref)) {\n    throwReadPreferenceError();\n  }\n\n  // if user has not explicitly set any auto-indexing options,\n  // we can silently default them all to false\n  else {\n    return defaultIndexOptsToFalse(opts);\n  }\n}\n\nfunction setsIndexOptions(opts) {\n  const configIdx = opts.config && opts.config.autoIndex;\n  const { autoCreate, autoIndex } = opts;\n  return !!(configIdx || autoCreate || autoIndex);\n}\n\nfunction setsSecondaryRead(prefString) {\n  return !!(prefString === 'secondary' || prefString === 'secondaryPreferred');\n}\n\nfunction getUriReadPreference(connectionString) {\n  const exp = /(?:&|\\?)readPreference=(\\w+)(?:&|$)/;\n  const match = exp.exec(connectionString);\n  return match ? match[1] : null;\n}\n\nfunction defaultIndexOptsToFalse(opts) {\n  opts.config = { autoIndex: false };\n  opts.autoCreate = false;\n  opts.autoIndex = false;\n  return opts;\n}\n\nfunction throwReadPreferenceError() {\n  throw new MongooseError(\n    'MongoDB prohibits index creation on connections that read from ' +\n            'non-primary replicas.  Connections that set \"readPreference\" to \"secondary\" or ' +\n            '\"secondaryPreferred\" may not opt-in to the following connection options: ' +\n            'autoCreate, autoIndex'\n  );\n}\n\nmodule.exports = processConnectionOptions;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/processConnectionOptions.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/projection/applyProjection.js":
/*!*************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/projection/applyProjection.js ***!
  \*************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst hasIncludedChildren = __webpack_require__(/*! ./hasIncludedChildren */ \"./node_modules/mongoose/lib/helpers/projection/hasIncludedChildren.js\");\nconst isExclusive = __webpack_require__(/*! ./isExclusive */ \"./node_modules/mongoose/lib/helpers/projection/isExclusive.js\");\nconst isInclusive = __webpack_require__(/*! ./isInclusive */ \"./node_modules/mongoose/lib/helpers/projection/isInclusive.js\");\nconst isPOJO = (__webpack_require__(/*! ../../utils */ \"./node_modules/mongoose/lib/utils.js\").isPOJO);\n\nmodule.exports = function applyProjection(doc, projection, _hasIncludedChildren) {\n  if (projection == null) {\n    return doc;\n  }\n  if (doc == null) {\n    return doc;\n  }\n\n  let exclude = null;\n  if (isInclusive(projection)) {\n    exclude = false;\n  } else if (isExclusive(projection)) {\n    exclude = true;\n  }\n\n  if (exclude == null) {\n    return doc;\n  } else if (exclude) {\n    _hasIncludedChildren = _hasIncludedChildren || hasIncludedChildren(projection);\n    return applyExclusiveProjection(doc, projection, _hasIncludedChildren);\n  } else {\n    _hasIncludedChildren = _hasIncludedChildren || hasIncludedChildren(projection);\n    return applyInclusiveProjection(doc, projection, _hasIncludedChildren);\n  }\n};\n\nfunction applyExclusiveProjection(doc, projection, hasIncludedChildren, projectionLimb, prefix) {\n  if (doc == null || typeof doc !== 'object') {\n    return doc;\n  }\n  if (Array.isArray(doc)) {\n    return doc.map(el => applyExclusiveProjection(el, projection, hasIncludedChildren, projectionLimb, prefix));\n  }\n  const ret = { ...doc };\n  projectionLimb = prefix ? (projectionLimb || {}) : projection;\n\n  for (const key of Object.keys(ret)) {\n    const fullPath = prefix ? prefix + '.' + key : key;\n    if (projection.hasOwnProperty(fullPath) || projectionLimb.hasOwnProperty(key)) {\n      if (isPOJO(projection[fullPath]) || isPOJO(projectionLimb[key])) {\n        ret[key] = applyExclusiveProjection(ret[key], projection, hasIncludedChildren, projectionLimb[key], fullPath);\n      } else {\n        delete ret[key];\n      }\n    } else if (hasIncludedChildren[fullPath]) {\n      ret[key] = applyExclusiveProjection(ret[key], projection, hasIncludedChildren, projectionLimb[key], fullPath);\n    }\n  }\n  return ret;\n}\n\nfunction applyInclusiveProjection(doc, projection, hasIncludedChildren, projectionLimb, prefix) {\n  if (doc == null || typeof doc !== 'object') {\n    return doc;\n  }\n  if (Array.isArray(doc)) {\n    return doc.map(el => applyInclusiveProjection(el, projection, hasIncludedChildren, projectionLimb, prefix));\n  }\n  const ret = { ...doc };\n  projectionLimb = prefix ? (projectionLimb || {}) : projection;\n\n  for (const key of Object.keys(ret)) {\n    const fullPath = prefix ? prefix + '.' + key : key;\n    if (projection.hasOwnProperty(fullPath) || projectionLimb.hasOwnProperty(key)) {\n      if (isPOJO(projection[fullPath]) || isPOJO(projectionLimb[key])) {\n        ret[key] = applyInclusiveProjection(ret[key], projection, hasIncludedChildren, projectionLimb[key], fullPath);\n      }\n      continue;\n    } else if (hasIncludedChildren[fullPath]) {\n      ret[key] = applyInclusiveProjection(ret[key], projection, hasIncludedChildren, projectionLimb[key], fullPath);\n    } else {\n      delete ret[key];\n    }\n  }\n  return ret;\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/projection/applyProjection.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/projection/hasIncludedChildren.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/projection/hasIncludedChildren.js ***!
  \*****************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/**\n * Creates an object that precomputes whether a given path has child fields in\n * the projection.\n *\n * #### Example:\n *\n *     const res = hasIncludedChildren({ 'a.b.c': 0 });\n *     res.a; // 1\n *     res['a.b']; // 1\n *     res['a.b.c']; // 1\n *     res['a.c']; // undefined\n *\n * @param {Object} fields\n * @api private\n */\n\nmodule.exports = function hasIncludedChildren(fields) {\n  const hasIncludedChildren = {};\n  const keys = Object.keys(fields);\n\n  for (const key of keys) {\n\n    if (key.indexOf('.') === -1) {\n      hasIncludedChildren[key] = 1;\n      continue;\n    }\n    const parts = key.split('.');\n    let c = parts[0];\n\n    for (let i = 0; i < parts.length; ++i) {\n      hasIncludedChildren[c] = 1;\n      if (i + 1 < parts.length) {\n        c = c + '.' + parts[i + 1];\n      }\n    }\n  }\n\n  return hasIncludedChildren;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/projection/hasIncludedChildren.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/projection/isDefiningProjection.js":
/*!******************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/projection/isDefiningProjection.js ***!
  \******************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/*!\n * ignore\n */\n\nmodule.exports = function isDefiningProjection(val) {\n  if (val == null) {\n    // `undefined` or `null` become exclusive projections\n    return true;\n  }\n  if (typeof val === 'object') {\n    // Only cases where a value does **not** define whether the whole projection\n    // is inclusive or exclusive are `$meta` and `$slice`.\n    return !('$meta' in val) && !('$slice' in val);\n  }\n  return true;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/projection/isDefiningProjection.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/projection/isExclusive.js":
/*!*********************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/projection/isExclusive.js ***!
  \*********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst isDefiningProjection = __webpack_require__(/*! ./isDefiningProjection */ \"./node_modules/mongoose/lib/helpers/projection/isDefiningProjection.js\");\n\n/*!\n * ignore\n */\n\nmodule.exports = function isExclusive(projection) {\n  if (projection == null) {\n    return null;\n  }\n\n  const keys = Object.keys(projection);\n  let exclude = null;\n\n  if (keys.length === 1 && keys[0] === '_id') {\n    exclude = !projection._id;\n  } else {\n    for (let ki = 0; ki < keys.length; ++ki) {\n      // Does this projection explicitly define inclusion/exclusion?\n      // Explicitly avoid `$meta` and `$slice`\n      const key = keys[ki];\n      if (key !== '_id' && isDefiningProjection(projection[key])) {\n        exclude = (projection[key] != null && typeof projection[key] === 'object') ?\n          isExclusive(projection[key]) :\n          !projection[key];\n        break;\n      }\n    }\n  }\n\n  return exclude;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/projection/isExclusive.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/projection/isInclusive.js":
/*!*********************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/projection/isInclusive.js ***!
  \*********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst isDefiningProjection = __webpack_require__(/*! ./isDefiningProjection */ \"./node_modules/mongoose/lib/helpers/projection/isDefiningProjection.js\");\n\n/*!\n * ignore\n */\n\nmodule.exports = function isInclusive(projection) {\n  if (projection == null) {\n    return false;\n  }\n\n  const props = Object.keys(projection);\n  const numProps = props.length;\n  if (numProps === 0) {\n    return false;\n  }\n\n  for (let i = 0; i < numProps; ++i) {\n    const prop = props[i];\n    // Plus paths can't define the projection (see gh-7050)\n    if (prop.startsWith('+')) {\n      continue;\n    }\n    // If field is truthy (1, true, etc.) and not an object, then this\n    // projection must be inclusive. If object, assume its $meta, $slice, etc.\n    if (isDefiningProjection(projection[prop]) && !!projection[prop]) {\n      if (projection[prop] != null && typeof projection[prop] === 'object') {\n        return isInclusive(projection[prop]);\n      } else {\n        return !!projection[prop];\n      }\n    }\n  }\n\n  return false;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/projection/isInclusive.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/projection/isNestedProjection.js":
/*!****************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/projection/isNestedProjection.js ***!
  \****************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function isNestedProjection(val) {\n  if (val == null || typeof val !== 'object') {\n    return false;\n  }\n  return val.$slice == null && val.$elemMatch == null && val.$meta == null && val.$ == null;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/projection/isNestedProjection.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/projection/isPathExcluded.js":
/*!************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/projection/isPathExcluded.js ***!
  \************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst isDefiningProjection = __webpack_require__(/*! ./isDefiningProjection */ \"./node_modules/mongoose/lib/helpers/projection/isDefiningProjection.js\");\n\n/**\n * Determines if `path` is excluded by `projection`\n *\n * @param {Object} projection\n * @param {String} path\n * @return {Boolean}\n * @api private\n */\n\nmodule.exports = function isPathExcluded(projection, path) {\n  if (projection == null) {\n    return false;\n  }\n\n  if (path === '_id') {\n    return projection._id === 0;\n  }\n\n  const paths = Object.keys(projection);\n  let type = null;\n\n  for (const _path of paths) {\n    if (isDefiningProjection(projection[_path])) {\n      type = projection[path] === 1 ? 'inclusive' : 'exclusive';\n      break;\n    }\n  }\n\n  if (type === 'inclusive') {\n    return projection[path] !== 1;\n  }\n  if (type === 'exclusive') {\n    return projection[path] === 0;\n  }\n  return false;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/projection/isPathExcluded.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/projection/isPathSelectedInclusive.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/projection/isPathSelectedInclusive.js ***!
  \*********************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/*!\n * ignore\n */\n\nmodule.exports = function isPathSelectedInclusive(fields, path) {\n  const chunks = path.split('.');\n  let cur = '';\n  let j;\n  let keys;\n  let numKeys;\n  for (let i = 0; i < chunks.length; ++i) {\n    cur += cur.length ? '.' : '' + chunks[i];\n    if (fields[cur]) {\n      keys = Object.keys(fields);\n      numKeys = keys.length;\n      for (j = 0; j < numKeys; ++j) {\n        if (keys[i].indexOf(cur + '.') === 0 && keys[i].indexOf(path) !== 0) {\n          continue;\n        }\n      }\n      return true;\n    }\n  }\n\n  return false;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/projection/isPathSelectedInclusive.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/projection/isSubpath.js":
/*!*******************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/projection/isSubpath.js ***!
  \*******************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/**\n * Determines if `path2` is a subpath of or equal to `path1`\n *\n * @param {string} path1\n * @param {string} path2\n * @return {Boolean}\n * @api private\n */\n\nmodule.exports = function isSubpath(path1, path2) {\n  return path1 === path2 || path2.startsWith(path1 + '.');\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/projection/isSubpath.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/projection/parseProjection.js":
/*!*************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/projection/parseProjection.js ***!
  \*************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/**\n * Convert a string or array into a projection object, retaining all\n * `-` and `+` paths.\n */\n\nmodule.exports = function parseProjection(v, retainMinusPaths) {\n  const type = typeof v;\n\n  if (type === 'string') {\n    v = v.split(/\\s+/);\n  }\n  if (!Array.isArray(v) && Object.prototype.toString.call(v) !== '[object Arguments]') {\n    return v;\n  }\n\n  const len = v.length;\n  const ret = {};\n  for (let i = 0; i < len; ++i) {\n    let field = v[i];\n    if (!field) {\n      continue;\n    }\n    const include = '-' == field[0] ? 0 : 1;\n    if (!retainMinusPaths && include === 0) {\n      field = field.substring(1);\n    }\n    ret[field] = include;\n  }\n\n  return ret;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/projection/parseProjection.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/promiseOrCallback.js":
/*!****************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/promiseOrCallback.js ***!
  \****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst immediate = __webpack_require__(/*! ./immediate */ \"./node_modules/mongoose/lib/helpers/immediate.js\");\n\nconst emittedSymbol = Symbol('mongoose#emitted');\n\nmodule.exports = function promiseOrCallback(callback, fn, ee, Promise) {\n  if (typeof callback === 'function') {\n    try {\n      return fn(function(error) {\n        if (error != null) {\n          if (ee != null && ee.listeners != null && ee.listeners('error').length > 0 && !error[emittedSymbol]) {\n            error[emittedSymbol] = true;\n            ee.emit('error', error);\n          }\n          try {\n            callback(error);\n          } catch (error) {\n            return immediate(() => {\n              throw error;\n            });\n          }\n          return;\n        }\n        callback.apply(this, arguments);\n      });\n    } catch (error) {\n      if (ee != null && ee.listeners != null && ee.listeners('error').length > 0 && !error[emittedSymbol]) {\n        error[emittedSymbol] = true;\n        ee.emit('error', error);\n      }\n\n      return callback(error);\n    }\n  }\n\n  Promise = Promise || global.Promise;\n\n  return new Promise((resolve, reject) => {\n    fn(function(error, res) {\n      if (error != null) {\n        if (ee != null && ee.listeners != null && ee.listeners('error').length > 0 && !error[emittedSymbol]) {\n          error[emittedSymbol] = true;\n          ee.emit('error', error);\n        }\n        return reject(error);\n      }\n      if (arguments.length > 2) {\n        return resolve(Array.prototype.slice.call(arguments, 1));\n      }\n      resolve(res);\n    });\n  });\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/promiseOrCallback.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/query/applyGlobalOption.js":
/*!**********************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/query/applyGlobalOption.js ***!
  \**********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst utils = __webpack_require__(/*! ../../utils */ \"./node_modules/mongoose/lib/utils.js\");\n\nfunction applyGlobalMaxTimeMS(options, connectionOptions, baseOptions) {\n  applyGlobalOption(options, connectionOptions, baseOptions, 'maxTimeMS');\n}\n\nfunction applyGlobalDiskUse(options, connectionOptions, baseOptions) {\n  applyGlobalOption(options, connectionOptions, baseOptions, 'allowDiskUse');\n}\n\nmodule.exports = {\n  applyGlobalMaxTimeMS,\n  applyGlobalDiskUse\n};\n\n\nfunction applyGlobalOption(options, connectionOptions, baseOptions, optionName) {\n  if (utils.hasUserDefinedProperty(options, optionName)) {\n    return;\n  }\n\n  if (utils.hasUserDefinedProperty(connectionOptions, optionName)) {\n    options[optionName] = connectionOptions[optionName];\n  } else if (utils.hasUserDefinedProperty(baseOptions, optionName)) {\n    options[optionName] = baseOptions[optionName];\n  }\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/query/applyGlobalOption.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/query/cast$expr.js":
/*!**************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/query/cast$expr.js ***!
  \**************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst CastError = __webpack_require__(/*! ../../error/cast */ \"./node_modules/mongoose/lib/error/cast.js\");\nconst StrictModeError = __webpack_require__(/*! ../../error/strict */ \"./node_modules/mongoose/lib/error/strict.js\");\nconst castNumber = __webpack_require__(/*! ../../cast/number */ \"./node_modules/mongoose/lib/cast/number.js\");\nconst omitUndefined = __webpack_require__(/*! ../omitUndefined */ \"./node_modules/mongoose/lib/helpers/omitUndefined.js\");\n\nconst booleanComparison = new Set(['$and', '$or']);\nconst comparisonOperator = new Set(['$cmp', '$eq', '$lt', '$lte', '$gt', '$gte']);\nconst arithmeticOperatorArray = new Set([\n  // avoid casting '$add' or '$subtract', because expressions can be either number or date,\n  // and we don't have a good way of inferring which arguments should be numbers and which should\n  // be dates.\n  '$multiply',\n  '$divide',\n  '$log',\n  '$mod',\n  '$trunc',\n  '$avg',\n  '$max',\n  '$min',\n  '$stdDevPop',\n  '$stdDevSamp',\n  '$sum'\n]);\nconst arithmeticOperatorNumber = new Set([\n  '$abs',\n  '$exp',\n  '$ceil',\n  '$floor',\n  '$ln',\n  '$log10',\n  '$sqrt',\n  '$sin',\n  '$cos',\n  '$tan',\n  '$asin',\n  '$acos',\n  '$atan',\n  '$atan2',\n  '$asinh',\n  '$acosh',\n  '$atanh',\n  '$sinh',\n  '$cosh',\n  '$tanh',\n  '$degreesToRadians',\n  '$radiansToDegrees'\n]);\nconst arrayElementOperators = new Set([\n  '$arrayElemAt',\n  '$first',\n  '$last'\n]);\nconst dateOperators = new Set([\n  '$year',\n  '$month',\n  '$week',\n  '$dayOfMonth',\n  '$dayOfYear',\n  '$hour',\n  '$minute',\n  '$second',\n  '$isoDayOfWeek',\n  '$isoWeekYear',\n  '$isoWeek',\n  '$millisecond'\n]);\nconst expressionOperator = new Set(['$not']);\n\nmodule.exports = function cast$expr(val, schema, strictQuery) {\n  if (typeof val !== 'object' || val === null) {\n    throw new Error('`$expr` must be an object');\n  }\n\n  return _castExpression(val, schema, strictQuery);\n};\n\nfunction _castExpression(val, schema, strictQuery) {\n  // Preserve the value if it represents a path or if it's null\n  if (isPath(val) || val === null) {\n    return val;\n  }\n\n  if (val.$cond != null) {\n    if (Array.isArray(val.$cond)) {\n      val.$cond = val.$cond.map(expr => _castExpression(expr, schema, strictQuery));\n    } else {\n      val.$cond.if = _castExpression(val.$cond.if, schema, strictQuery);\n      val.$cond.then = _castExpression(val.$cond.then, schema, strictQuery);\n      val.$cond.else = _castExpression(val.$cond.else, schema, strictQuery);\n    }\n  } else if (val.$ifNull != null) {\n    val.$ifNull.map(v => _castExpression(v, schema, strictQuery));\n  } else if (val.$switch != null) {\n    if (Array.isArray(val.$switch.branches)) {\n      val.$switch.branches = val.$switch.branches.map(v => _castExpression(v, schema, strictQuery));\n    }\n    if ('default' in val.$switch) {\n      val.$switch.default = _castExpression(val.$switch.default, schema, strictQuery);\n    }\n  }\n\n  const keys = Object.keys(val);\n  for (const key of keys) {\n    if (booleanComparison.has(key)) {\n      val[key] = val[key].map(v => _castExpression(v, schema, strictQuery));\n    } else if (comparisonOperator.has(key)) {\n      val[key] = castComparison(val[key], schema, strictQuery);\n    } else if (arithmeticOperatorArray.has(key)) {\n      val[key] = castArithmetic(val[key], schema, strictQuery);\n    } else if (arithmeticOperatorNumber.has(key)) {\n      val[key] = castNumberOperator(val[key], schema, strictQuery);\n    } else if (expressionOperator.has(key)) {\n      val[key] = _castExpression(val[key], schema, strictQuery);\n    }\n  }\n\n  if (val.$in) {\n    val.$in = castIn(val.$in, schema, strictQuery);\n  }\n  if (val.$size) {\n    val.$size = castNumberOperator(val.$size, schema, strictQuery);\n  }\n  if (val.$round) {\n    const $round = val.$round;\n    if (!Array.isArray($round) || $round.length < 1 || $round.length > 2) {\n      throw new CastError('Array', $round, '$round');\n    }\n    val.$round = $round.map(v => castNumberOperator(v, schema, strictQuery));\n  }\n\n  omitUndefined(val);\n\n  return val;\n}\n\n// { $op: <number> }\nfunction castNumberOperator(val) {\n  if (!isLiteral(val)) {\n    return val;\n  }\n\n  try {\n    return castNumber(val);\n  } catch (err) {\n    throw new CastError('Number', val);\n  }\n}\n\nfunction castIn(val, schema, strictQuery) {\n  const path = val[1];\n  if (!isPath(path)) {\n    return val;\n  }\n  const search = val[0];\n\n  const schematype = schema.path(path.slice(1));\n  if (schematype === null) {\n    if (strictQuery === false) {\n      return val;\n    } else if (strictQuery === 'throw') {\n      throw new StrictModeError('$in');\n    }\n\n    return void 0;\n  }\n\n  if (!schematype.$isMongooseArray) {\n    throw new Error('Path must be an array for $in');\n  }\n\n  return [\n    schematype.$isMongooseDocumentArray ? schematype.$embeddedSchemaType.cast(search) : schematype.caster.cast(search),\n    path\n  ];\n}\n\n// { $op: [<number>, <number>] }\nfunction castArithmetic(val) {\n  if (!Array.isArray(val)) {\n    if (!isLiteral(val)) {\n      return val;\n    }\n    try {\n      return castNumber(val);\n    } catch (err) {\n      throw new CastError('Number', val);\n    }\n  }\n\n  return val.map(v => {\n    if (!isLiteral(v)) {\n      return v;\n    }\n    try {\n      return castNumber(v);\n    } catch (err) {\n      throw new CastError('Number', v);\n    }\n  });\n}\n\n// { $op: [expression, expression] }\nfunction castComparison(val, schema, strictQuery) {\n  if (!Array.isArray(val) || val.length !== 2) {\n    throw new Error('Comparison operator must be an array of length 2');\n  }\n\n  val[0] = _castExpression(val[0], schema, strictQuery);\n  const lhs = val[0];\n\n  if (isLiteral(val[1])) {\n    let path = null;\n    let schematype = null;\n    let caster = null;\n    if (isPath(lhs)) {\n      path = lhs.slice(1);\n      schematype = schema.path(path);\n    } else if (typeof lhs === 'object' && lhs != null) {\n      for (const key of Object.keys(lhs)) {\n        if (dateOperators.has(key) && isPath(lhs[key])) {\n          path = lhs[key].slice(1) + '.' + key;\n          caster = castNumber;\n        } else if (arrayElementOperators.has(key) && isPath(lhs[key])) {\n          path = lhs[key].slice(1) + '.' + key;\n          schematype = schema.path(lhs[key].slice(1));\n          if (schematype != null) {\n            if (schematype.$isMongooseDocumentArray) {\n              schematype = schematype.$embeddedSchemaType;\n            } else if (schematype.$isMongooseArray) {\n              schematype = schematype.caster;\n            }\n          }\n        }\n      }\n    }\n\n    const is$literal = typeof val[1] === 'object' && val[1] != null && val[1].$literal != null;\n    if (schematype != null) {\n      if (is$literal) {\n        val[1] = { $literal: schematype.cast(val[1].$literal) };\n      } else {\n        val[1] = schematype.cast(val[1]);\n      }\n    } else if (caster != null) {\n      if (is$literal) {\n        try {\n          val[1] = { $literal: caster(val[1].$literal) };\n        } catch (err) {\n          throw new CastError(caster.name.replace(/^cast/, ''), val[1], path + '.$literal');\n        }\n      } else {\n        try {\n          val[1] = caster(val[1]);\n        } catch (err) {\n          throw new CastError(caster.name.replace(/^cast/, ''), val[1], path);\n        }\n      }\n    } else if (path != null && strictQuery === true) {\n      return void 0;\n    } else if (path != null && strictQuery === 'throw') {\n      throw new StrictModeError(path);\n    }\n  } else {\n    val[1] = _castExpression(val[1]);\n  }\n\n  return val;\n}\n\nfunction isPath(val) {\n  return typeof val === 'string' && val[0] === '$';\n}\n\nfunction isLiteral(val) {\n  if (typeof val === 'string' && val[0] === '$') {\n    return false;\n  }\n  if (typeof val === 'object' && val !== null && Object.keys(val).find(key => key[0] === '$')) {\n    // The `$literal` expression can make an object a literal\n    // https://www.mongodb.com/docs/manual/reference/operator/aggregation/literal/#mongodb-expression-exp.-literal\n    return val.$literal != null;\n  }\n  return true;\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/query/cast$expr.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/query/castFilterPath.js":
/*!*******************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/query/castFilterPath.js ***!
  \*******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst isOperator = __webpack_require__(/*! ./isOperator */ \"./node_modules/mongoose/lib/helpers/query/isOperator.js\");\n\nmodule.exports = function castFilterPath(ctx, schematype, val) {\n  const any$conditionals = Object.keys(val).some(isOperator);\n\n  if (!any$conditionals) {\n    return schematype.castForQuery(\n      null,\n      val,\n      ctx\n    );\n  }\n\n  const ks = Object.keys(val);\n\n  let k = ks.length;\n\n  while (k--) {\n    const $cond = ks[k];\n    const nested = val[$cond];\n\n    if ($cond === '$not') {\n      if (nested && schematype && !schematype.caster) {\n        const _keys = Object.keys(nested);\n        if (_keys.length && isOperator(_keys[0])) {\n          for (const key of Object.keys(nested)) {\n            nested[key] = schematype.castForQuery(\n              key,\n              nested[key],\n              ctx\n            );\n          }\n        } else {\n          val[$cond] = schematype.castForQuery(\n            $cond,\n            nested,\n            ctx\n          );\n        }\n        continue;\n      }\n    } else {\n      val[$cond] = schematype.castForQuery(\n        $cond,\n        nested,\n        ctx\n      );\n    }\n  }\n\n  return val;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/query/castFilterPath.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/query/castUpdate.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/query/castUpdate.js ***!
  \***************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst CastError = __webpack_require__(/*! ../../error/cast */ \"./node_modules/mongoose/lib/error/cast.js\");\nconst MongooseError = __webpack_require__(/*! ../../error/mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\nconst StrictModeError = __webpack_require__(/*! ../../error/strict */ \"./node_modules/mongoose/lib/error/strict.js\");\nconst ValidationError = __webpack_require__(/*! ../../error/validation */ \"./node_modules/mongoose/lib/error/validation.js\");\nconst castNumber = __webpack_require__(/*! ../../cast/number */ \"./node_modules/mongoose/lib/cast/number.js\");\nconst cast = __webpack_require__(/*! ../../cast */ \"./node_modules/mongoose/lib/cast.js\");\nconst getConstructorName = __webpack_require__(/*! ../getConstructorName */ \"./node_modules/mongoose/lib/helpers/getConstructorName.js\");\nconst getEmbeddedDiscriminatorPath = __webpack_require__(/*! ./getEmbeddedDiscriminatorPath */ \"./node_modules/mongoose/lib/helpers/query/getEmbeddedDiscriminatorPath.js\");\nconst handleImmutable = __webpack_require__(/*! ./handleImmutable */ \"./node_modules/mongoose/lib/helpers/query/handleImmutable.js\");\nconst moveImmutableProperties = __webpack_require__(/*! ../update/moveImmutableProperties */ \"./node_modules/mongoose/lib/helpers/update/moveImmutableProperties.js\");\nconst schemaMixedSymbol = (__webpack_require__(/*! ../../schema/symbols */ \"./node_modules/mongoose/lib/schema/symbols.js\").schemaMixedSymbol);\nconst setDottedPath = __webpack_require__(/*! ../path/setDottedPath */ \"./node_modules/mongoose/lib/helpers/path/setDottedPath.js\");\nconst utils = __webpack_require__(/*! ../../utils */ \"./node_modules/mongoose/lib/utils.js\");\nconst { internalToObjectOptions } = __webpack_require__(/*! ../../options */ \"./node_modules/mongoose/lib/options.js\");\n\nconst mongodbUpdateOperators = new Set([\n  '$currentDate',\n  '$inc',\n  '$min',\n  '$max',\n  '$mul',\n  '$rename',\n  '$set',\n  '$setOnInsert',\n  '$unset',\n  '$addToSet',\n  '$pop',\n  '$pull',\n  '$push',\n  '$pullAll',\n  '$bit'\n]);\n\n/**\n * Casts an update op based on the given schema\n *\n * @param {Schema} schema\n * @param {Object} obj\n * @param {Object} [options]\n * @param {Boolean|String} [options.strict] defaults to true\n * @param {Query} context passed to setters\n * @return {Boolean} true iff the update is non-empty\n * @api private\n */\nmodule.exports = function castUpdate(schema, obj, options, context, filter) {\n  if (obj == null) {\n    return undefined;\n  }\n  options = options || {};\n  // Update pipeline\n  if (Array.isArray(obj)) {\n    const len = obj.length;\n    for (let i = 0; i < len; ++i) {\n      const ops = Object.keys(obj[i]);\n      for (const op of ops) {\n        obj[i][op] = castPipelineOperator(op, obj[i][op]);\n      }\n    }\n    return obj;\n  }\n\n  if (options.upsert) {\n    moveImmutableProperties(schema, obj, context);\n  }\n\n  const ops = Object.keys(obj);\n  let i = ops.length;\n  const ret = {};\n  let val;\n  let hasDollarKey = false;\n\n  filter = filter || {};\n  while (i--) {\n    const op = ops[i];\n    if (!mongodbUpdateOperators.has(op)) {\n      // fix up $set sugar\n      if (!ret.$set) {\n        if (obj.$set) {\n          ret.$set = obj.$set;\n        } else {\n          ret.$set = {};\n        }\n      }\n      ret.$set[op] = obj[op];\n      ops.splice(i, 1);\n      if (!~ops.indexOf('$set')) ops.push('$set');\n    } else if (op === '$set') {\n      if (!ret.$set) {\n        ret[op] = obj[op];\n      }\n    } else {\n      ret[op] = obj[op];\n    }\n  }\n  // cast each value\n  i = ops.length;\n  while (i--) {\n    const op = ops[i];\n    val = ret[op];\n    hasDollarKey = hasDollarKey || op.startsWith('$');\n    if (val != null && val.$__) {\n      val = val.toObject(internalToObjectOptions);\n      ret[op] = val;\n    }\n    if (val &&\n        typeof val === 'object' &&\n        !Buffer.isBuffer(val) &&\n        mongodbUpdateOperators.has(op)) {\n      walkUpdatePath(schema, val, op, options, context, filter);\n    } else {\n      const msg = 'Invalid atomic update value for ' + op + '. '\n          + 'Expected an object, received ' + typeof val;\n      throw new Error(msg);\n    }\n\n    if (op.startsWith('$') && utils.isEmptyObject(val)) {\n      delete ret[op];\n    }\n  }\n\n  if (Object.keys(ret).length === 0 &&\n      options.upsert &&\n      Object.keys(filter).length > 0) {\n    // Trick the driver into allowing empty upserts to work around\n    // https://github.com/mongodb/node-mongodb-native/pull/2490\n    // Shallow clone to avoid passing defaults in re: gh-13962\n    return { $setOnInsert: { ...filter } };\n  }\n  return ret;\n};\n\n/*!\n * ignore\n */\n\nfunction castPipelineOperator(op, val) {\n  if (op === '$unset') {\n    if (typeof val !== 'string' && (!Array.isArray(val) || val.find(v => typeof v !== 'string'))) {\n      throw new MongooseError('Invalid $unset in pipeline, must be ' +\n        ' a string or an array of strings');\n    }\n    return val;\n  }\n  if (op === '$project') {\n    if (val == null || typeof val !== 'object') {\n      throw new MongooseError('Invalid $project in pipeline, must be an object');\n    }\n    return val;\n  }\n  if (op === '$addFields' || op === '$set') {\n    if (val == null || typeof val !== 'object') {\n      throw new MongooseError('Invalid ' + op + ' in pipeline, must be an object');\n    }\n    return val;\n  } else if (op === '$replaceRoot' || op === '$replaceWith') {\n    if (val == null || typeof val !== 'object') {\n      throw new MongooseError('Invalid ' + op + ' in pipeline, must be an object');\n    }\n    return val;\n  }\n\n  throw new MongooseError('Invalid update pipeline operator: \"' + op + '\"');\n}\n\n/**\n * Walk each path of obj and cast its values\n * according to its schema.\n *\n * @param {Schema} schema\n * @param {Object} obj part of a query\n * @param {String} op the atomic operator ($pull, $set, etc)\n * @param {Object} [options]\n * @param {Boolean|String} [options.strict]\n * @param {Query} context\n * @param {Object} filter\n * @param {String} pref path prefix (internal only)\n * @return {Bool} true if this path has keys to update\n * @api private\n */\n\nfunction walkUpdatePath(schema, obj, op, options, context, filter, pref) {\n  const strict = options.strict;\n  const prefix = pref ? pref + '.' : '';\n  const keys = Object.keys(obj);\n  let i = keys.length;\n  let hasKeys = false;\n  let schematype;\n  let key;\n  let val;\n\n  let aggregatedError = null;\n\n  const strictMode = strict != null ? strict : schema.options.strict;\n\n  while (i--) {\n    key = keys[i];\n    val = obj[key];\n\n    // `$pull` is special because we need to cast the RHS as a query, not as\n    // an update.\n    if (op === '$pull') {\n      schematype = schema._getSchema(prefix + key);\n      if (schematype == null) {\n        const _res = getEmbeddedDiscriminatorPath(schema, obj, filter, prefix + key, options);\n        if (_res.schematype != null) {\n          schematype = _res.schematype;\n        }\n      }\n      if (schematype != null && schematype.schema != null) {\n        obj[key] = cast(schematype.schema, obj[key], options, context);\n        hasKeys = true;\n        continue;\n      }\n    }\n\n    const discriminatorKey = (prefix ? prefix + key : key);\n    if (\n      schema.discriminatorMapping != null &&\n      discriminatorKey === schema.options.discriminatorKey &&\n      schema.discriminatorMapping.value !== obj[key] &&\n      !options.overwriteDiscriminatorKey\n    ) {\n      if (strictMode === 'throw') {\n        const err = new Error('Can\\'t modify discriminator key \"' + discriminatorKey + '\" on discriminator model');\n        aggregatedError = _appendError(err, context, discriminatorKey, aggregatedError);\n        continue;\n      } else if (strictMode) {\n        delete obj[key];\n        continue;\n      }\n    }\n\n    if (getConstructorName(val) === 'Object') {\n      // watch for embedded doc schemas\n      schematype = schema._getSchema(prefix + key);\n\n      if (schematype == null) {\n        const _res = getEmbeddedDiscriminatorPath(schema, obj, filter, prefix + key, options);\n        if (_res.schematype != null) {\n          schematype = _res.schematype;\n        }\n      }\n\n      if (op !== '$setOnInsert' &&\n          handleImmutable(schematype, strict, obj, key, prefix + key, context)) {\n        continue;\n      }\n\n      if (schematype && schematype.caster && op in castOps) {\n        // embedded doc schema\n        if ('$each' in val) {\n          hasKeys = true;\n          try {\n            obj[key] = {\n              $each: castUpdateVal(schematype, val.$each, op, key, context, prefix + key)\n            };\n          } catch (error) {\n            aggregatedError = _appendError(error, context, key, aggregatedError);\n          }\n\n          if (val.$slice != null) {\n            obj[key].$slice = val.$slice | 0;\n          }\n\n          if (val.$sort) {\n            obj[key].$sort = val.$sort;\n          }\n\n          if (val.$position != null) {\n            obj[key].$position = castNumber(val.$position);\n          }\n        } else {\n          if (schematype != null && schematype.$isSingleNested) {\n            const _strict = strict == null ? schematype.schema.options.strict : strict;\n            try {\n              obj[key] = schematype.castForQuery(null, val, context, { strict: _strict });\n            } catch (error) {\n              aggregatedError = _appendError(error, context, key, aggregatedError);\n            }\n          } else {\n            try {\n              obj[key] = castUpdateVal(schematype, val, op, key, context, prefix + key);\n            } catch (error) {\n              aggregatedError = _appendError(error, context, key, aggregatedError);\n            }\n          }\n\n          if (obj[key] === void 0) {\n            delete obj[key];\n            continue;\n          }\n\n          hasKeys = true;\n        }\n      } else if ((op === '$currentDate') || (op in castOps && schematype)) {\n        // $currentDate can take an object\n        try {\n          obj[key] = castUpdateVal(schematype, val, op, key, context, prefix + key);\n        } catch (error) {\n          aggregatedError = _appendError(error, context, key, aggregatedError);\n        }\n\n        if (obj[key] === void 0) {\n          delete obj[key];\n          continue;\n        }\n\n        hasKeys = true;\n      } else {\n        const pathToCheck = (prefix + key);\n        const v = schema._getPathType(pathToCheck);\n        let _strict = strict;\n        if (v && v.schema && _strict == null) {\n          _strict = v.schema.options.strict;\n        }\n\n        if (v.pathType === 'undefined') {\n          if (_strict === 'throw') {\n            throw new StrictModeError(pathToCheck);\n          } else if (_strict) {\n            delete obj[key];\n            continue;\n          }\n        }\n\n        // gh-2314\n        // we should be able to set a schema-less field\n        // to an empty object literal\n        hasKeys |= walkUpdatePath(schema, val, op, options, context, filter, prefix + key) ||\n          (utils.isObject(val) && Object.keys(val).length === 0);\n      }\n    } else {\n      const checkPath = (key === '$each' || key === '$or' || key === '$and' || key === '$in') ?\n        pref : prefix + key;\n      schematype = schema._getSchema(checkPath);\n\n      // You can use `$setOnInsert` with immutable keys\n      if (op !== '$setOnInsert' &&\n          handleImmutable(schematype, strict, obj, key, prefix + key, context)) {\n        continue;\n      }\n\n      let pathDetails = schema._getPathType(checkPath);\n\n      // If no schema type, check for embedded discriminators because the\n      // filter or update may imply an embedded discriminator type. See #8378\n      if (schematype == null) {\n        const _res = getEmbeddedDiscriminatorPath(schema, obj, filter, checkPath, options);\n        if (_res.schematype != null) {\n          schematype = _res.schematype;\n          pathDetails = _res.type;\n        }\n      }\n\n      let isStrict = strict;\n      if (pathDetails && pathDetails.schema && strict == null) {\n        isStrict = pathDetails.schema.options.strict;\n      }\n\n      const skip = isStrict &&\n        !schematype &&\n        !/real|nested/.test(pathDetails.pathType);\n\n      if (skip) {\n        // Even if strict is `throw`, avoid throwing an error because of\n        // virtuals because of #6731\n        if (isStrict === 'throw' && schema.virtuals[checkPath] == null) {\n          throw new StrictModeError(prefix + key);\n        } else {\n          delete obj[key];\n        }\n      } else {\n        // gh-1845 temporary fix: ignore $rename. See gh-3027 for tracking\n        // improving this.\n        if (op === '$rename') {\n          hasKeys = true;\n          continue;\n        }\n\n        try {\n          if (prefix.length === 0 || key.indexOf('.') === -1) {\n            obj[key] = castUpdateVal(schematype, val, op, key, context, prefix + key);\n          } else if (isStrict !== false || schematype != null) {\n            // Setting a nested dotted path that's in the schema. We don't allow paths with '.' in\n            // a schema, so replace the dotted path with a nested object to avoid ending up with\n            // dotted properties in the updated object. See (gh-10200)\n            setDottedPath(obj, key, castUpdateVal(schematype, val, op, key, context, prefix + key));\n            delete obj[key];\n          }\n        } catch (error) {\n          aggregatedError = _appendError(error, context, key, aggregatedError);\n        }\n\n        if (Array.isArray(obj[key]) && (op === '$addToSet' || op === '$push') && key !== '$each') {\n          if (schematype &&\n              schematype.caster &&\n              !schematype.caster.$isMongooseArray &&\n              !schematype.caster[schemaMixedSymbol]) {\n            obj[key] = { $each: obj[key] };\n          }\n        }\n\n        if (obj[key] === void 0) {\n          delete obj[key];\n          continue;\n        }\n\n        hasKeys = true;\n      }\n    }\n  }\n\n  if (aggregatedError != null) {\n    throw aggregatedError;\n  }\n\n  return hasKeys;\n}\n\n/*!\n * ignore\n */\n\nfunction _appendError(error, query, key, aggregatedError) {\n  if (typeof query !== 'object' || !query.options.multipleCastError) {\n    throw error;\n  }\n  aggregatedError = aggregatedError || new ValidationError();\n  aggregatedError.addError(key, error);\n  return aggregatedError;\n}\n\n/**\n * These operators should be cast to numbers instead\n * of their path schema type.\n * @api private\n */\n\nconst numberOps = {\n  $pop: 1,\n  $inc: 1\n};\n\n/**\n * These ops require no casting because the RHS doesn't do anything.\n * @api private\n */\n\nconst noCastOps = {\n  $unset: 1\n};\n\n/**\n * These operators require casting docs\n * to real Documents for Update operations.\n * @api private\n */\n\nconst castOps = {\n  $push: 1,\n  $addToSet: 1,\n  $set: 1,\n  $setOnInsert: 1\n};\n\n/*!\n * ignore\n */\n\nconst overwriteOps = {\n  $set: 1,\n  $setOnInsert: 1\n};\n\n/**\n * Casts `val` according to `schema` and atomic `op`.\n *\n * @param {SchemaType} schema\n * @param {Object} val\n * @param {String} op the atomic operator ($pull, $set, etc)\n * @param {String} $conditional\n * @param {Query} context\n * @param {String} path\n * @api private\n */\n\nfunction castUpdateVal(schema, val, op, $conditional, context, path) {\n  if (!schema) {\n    // non-existing schema path\n    if (op in numberOps) {\n      try {\n        return castNumber(val);\n      } catch (err) {\n        throw new CastError('number', val, path);\n      }\n    }\n    return val;\n  }\n\n  // console.log('CastUpdateVal', path, op, val, schema);\n\n  const cond = schema.caster && op in castOps &&\n      (utils.isObject(val) || Array.isArray(val));\n  if (cond && !overwriteOps[op]) {\n    // Cast values for ops that add data to MongoDB.\n    // Ensures embedded documents get ObjectIds etc.\n    let schemaArrayDepth = 0;\n    let cur = schema;\n    while (cur.$isMongooseArray) {\n      ++schemaArrayDepth;\n      cur = cur.caster;\n    }\n    let arrayDepth = 0;\n    let _val = val;\n    while (Array.isArray(_val)) {\n      ++arrayDepth;\n      _val = _val[0];\n    }\n\n    const additionalNesting = schemaArrayDepth - arrayDepth;\n    while (arrayDepth < schemaArrayDepth) {\n      val = [val];\n      ++arrayDepth;\n    }\n\n    let tmp = schema.applySetters(Array.isArray(val) ? val : [val], context);\n\n    for (let i = 0; i < additionalNesting; ++i) {\n      tmp = tmp[0];\n    }\n    return tmp;\n  }\n\n  if (op in noCastOps) {\n    return val;\n  }\n  if (op in numberOps) {\n    // Null and undefined not allowed for $pop, $inc\n    if (val == null) {\n      throw new CastError('number', val, schema.path);\n    }\n    if (op === '$inc') {\n      // Support `$inc` with long, int32, etc. (gh-4283)\n      return schema.castForQuery(\n        null,\n        val,\n        context\n      );\n    }\n    try {\n      return castNumber(val);\n    } catch (error) {\n      throw new CastError('number', val, schema.path);\n    }\n  }\n  if (op === '$currentDate') {\n    if (typeof val === 'object') {\n      return { $type: val.$type };\n    }\n    return Boolean(val);\n  }\n\n  if (mongodbUpdateOperators.has($conditional)) {\n    return schema.castForQuery(\n      $conditional,\n      val,\n      context\n    );\n  }\n\n  if (overwriteOps[op]) {\n    const skipQueryCastForUpdate = val != null && schema.$isMongooseArray && schema.$fullPath != null && !schema.$fullPath.match(/\\d+$/);\n    const applySetters = schema[schemaMixedSymbol] != null;\n    if (skipQueryCastForUpdate || applySetters) {\n      return schema.applySetters(val, context);\n    }\n    return schema.castForQuery(\n      null,\n      val,\n      context\n    );\n  }\n\n  return schema.castForQuery(null, val, context);\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/query/castUpdate.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/query/getEmbeddedDiscriminatorPath.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/query/getEmbeddedDiscriminatorPath.js ***!
  \*********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst cleanPositionalOperators = __webpack_require__(/*! ../schema/cleanPositionalOperators */ \"./node_modules/mongoose/lib/helpers/schema/cleanPositionalOperators.js\");\nconst get = __webpack_require__(/*! ../get */ \"./node_modules/mongoose/lib/helpers/get.js\");\nconst getDiscriminatorByValue = __webpack_require__(/*! ../discriminator/getDiscriminatorByValue */ \"./node_modules/mongoose/lib/helpers/discriminator/getDiscriminatorByValue.js\");\nconst updatedPathsByArrayFilter = __webpack_require__(/*! ../update/updatedPathsByArrayFilter */ \"./node_modules/mongoose/lib/helpers/update/updatedPathsByArrayFilter.js\");\n\n/**\n * Like `schema.path()`, except with a document, because impossible to\n * determine path type without knowing the embedded discriminator key.\n * @param {Schema} schema\n * @param {Object} [update]\n * @param {Object} [filter]\n * @param {String} path\n * @param {Object} [options]\n * @api private\n */\n\nmodule.exports = function getEmbeddedDiscriminatorPath(schema, update, filter, path, options) {\n  const parts = path.split('.');\n  let schematype = null;\n  let type = 'adhocOrUndefined';\n\n  filter = filter || {};\n  update = update || {};\n  const arrayFilters = options != null && Array.isArray(options.arrayFilters) ?\n    options.arrayFilters : [];\n  const updatedPathsByFilter = updatedPathsByArrayFilter(update);\n\n  for (let i = 0; i < parts.length; ++i) {\n    const subpath = cleanPositionalOperators(parts.slice(0, i + 1).join('.'));\n    schematype = schema.path(subpath);\n    if (schematype == null) {\n      continue;\n    }\n\n    type = schema.pathType(subpath);\n    if ((schematype.$isSingleNested || schematype.$isMongooseDocumentArrayElement) &&\n        schematype.schema.discriminators != null) {\n      const key = get(schematype, 'schema.options.discriminatorKey');\n      const discriminatorValuePath = subpath + '.' + key;\n      const discriminatorFilterPath =\n        discriminatorValuePath.replace(/\\.\\d+\\./, '.');\n      let discriminatorKey = null;\n\n      if (discriminatorValuePath in filter) {\n        discriminatorKey = filter[discriminatorValuePath];\n      }\n      if (discriminatorFilterPath in filter) {\n        discriminatorKey = filter[discriminatorFilterPath];\n      }\n\n      const wrapperPath = subpath.replace(/\\.\\d+$/, '');\n      if (schematype.$isMongooseDocumentArrayElement &&\n          get(filter[wrapperPath], '$elemMatch.' + key) != null) {\n        discriminatorKey = filter[wrapperPath].$elemMatch[key];\n      }\n\n      if (discriminatorValuePath in update) {\n        discriminatorKey = update[discriminatorValuePath];\n      }\n\n      for (const filterKey of Object.keys(updatedPathsByFilter)) {\n        const schemaKey = updatedPathsByFilter[filterKey] + '.' + key;\n        const arrayFilterKey = filterKey + '.' + key;\n        if (schemaKey === discriminatorFilterPath) {\n          const filter = arrayFilters.find(filter => filter.hasOwnProperty(arrayFilterKey));\n          if (filter != null) {\n            discriminatorKey = filter[arrayFilterKey];\n          }\n        }\n      }\n\n      if (discriminatorKey == null) {\n        continue;\n      }\n\n      const discriminator = getDiscriminatorByValue(schematype.caster.discriminators, discriminatorKey);\n      const discriminatorSchema = discriminator && discriminator.schema;\n      if (discriminatorSchema == null) {\n        continue;\n      }\n\n      const rest = parts.slice(i + 1).join('.');\n      schematype = discriminatorSchema.path(rest);\n      if (schematype != null) {\n        type = discriminatorSchema._getPathType(rest);\n        break;\n      }\n    }\n  }\n\n  return { type: type, schematype: schematype };\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/query/getEmbeddedDiscriminatorPath.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/query/handleImmutable.js":
/*!********************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/query/handleImmutable.js ***!
  \********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst StrictModeError = __webpack_require__(/*! ../../error/strict */ \"./node_modules/mongoose/lib/error/strict.js\");\n\nmodule.exports = function handleImmutable(schematype, strict, obj, key, fullPath, ctx) {\n  if (schematype == null || !schematype.options || !schematype.options.immutable) {\n    return false;\n  }\n  let immutable = schematype.options.immutable;\n\n  if (typeof immutable === 'function') {\n    immutable = immutable.call(ctx, ctx);\n  }\n  if (!immutable) {\n    return false;\n  }\n\n  if (strict === false) {\n    return false;\n  }\n  if (strict === 'throw') {\n    throw new StrictModeError(null,\n      `Field ${fullPath} is immutable and strict = 'throw'`);\n  }\n\n  delete obj[key];\n  return true;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/query/handleImmutable.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/query/handleReadPreferenceAliases.js":
/*!********************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/query/handleReadPreferenceAliases.js ***!
  \********************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function handleReadPreferenceAliases(pref) {\n  switch (pref) {\n    case 'p':\n      pref = 'primary';\n      break;\n    case 'pp':\n      pref = 'primaryPreferred';\n      break;\n    case 's':\n      pref = 'secondary';\n      break;\n    case 'sp':\n      pref = 'secondaryPreferred';\n      break;\n    case 'n':\n      pref = 'nearest';\n      break;\n  }\n\n  return pref;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/query/handleReadPreferenceAliases.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/query/hasDollarKeys.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/query/hasDollarKeys.js ***!
  \******************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/*!\n * ignore\n */\n\nmodule.exports = function hasDollarKeys(obj) {\n\n  if (typeof obj !== 'object' || obj === null) {\n    return false;\n  }\n\n  const keys = Object.keys(obj);\n  const len = keys.length;\n\n  for (let i = 0; i < len; ++i) {\n    if (keys[i][0] === '$') {\n      return true;\n    }\n  }\n\n  return false;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/query/hasDollarKeys.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/query/isOperator.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/query/isOperator.js ***!
  \***************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nconst specialKeys = new Set([\n  '$ref',\n  '$id',\n  '$db'\n]);\n\nmodule.exports = function isOperator(path) {\n  return (\n    path[0] === '$' &&\n    !specialKeys.has(path)\n  );\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/query/isOperator.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/query/sanitizeFilter.js":
/*!*******************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/query/sanitizeFilter.js ***!
  \*******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst hasDollarKeys = __webpack_require__(/*! ./hasDollarKeys */ \"./node_modules/mongoose/lib/helpers/query/hasDollarKeys.js\");\nconst { trustedSymbol } = __webpack_require__(/*! ./trusted */ \"./node_modules/mongoose/lib/helpers/query/trusted.js\");\n\nmodule.exports = function sanitizeFilter(filter) {\n  if (filter == null || typeof filter !== 'object') {\n    return filter;\n  }\n  if (Array.isArray(filter)) {\n    for (const subfilter of filter) {\n      sanitizeFilter(subfilter);\n    }\n    return filter;\n  }\n\n  const filterKeys = Object.keys(filter);\n  for (const key of filterKeys) {\n    const value = filter[key];\n    if (value != null && value[trustedSymbol]) {\n      continue;\n    }\n    if (key === '$and' || key === '$or') {\n      sanitizeFilter(value);\n      continue;\n    }\n\n    if (hasDollarKeys(value)) {\n      const keys = Object.keys(value);\n      if (keys.length === 1 && keys[0] === '$eq') {\n        continue;\n      }\n      filter[key] = { $eq: filter[key] };\n    }\n  }\n\n  return filter;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/query/sanitizeFilter.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/query/sanitizeProjection.js":
/*!***********************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/query/sanitizeProjection.js ***!
  \***********************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function sanitizeProjection(projection) {\n  if (projection == null) {\n    return;\n  }\n\n  const keys = Object.keys(projection);\n  for (let i = 0; i < keys.length; ++i) {\n    if (typeof projection[keys[i]] === 'string') {\n      projection[keys[i]] = 1;\n    }\n  }\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/query/sanitizeProjection.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/query/selectPopulatedFields.js":
/*!**************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/query/selectPopulatedFields.js ***!
  \**************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst isExclusive = __webpack_require__(/*! ../projection/isExclusive */ \"./node_modules/mongoose/lib/helpers/projection/isExclusive.js\");\nconst isInclusive = __webpack_require__(/*! ../projection/isInclusive */ \"./node_modules/mongoose/lib/helpers/projection/isInclusive.js\");\n\n/*!\n * ignore\n */\n\nmodule.exports = function selectPopulatedFields(fields, userProvidedFields, populateOptions) {\n  if (populateOptions == null) {\n    return;\n  }\n\n  const paths = Object.keys(populateOptions);\n  userProvidedFields = userProvidedFields || {};\n  if (isInclusive(fields)) {\n    for (const path of paths) {\n      if (!isPathInFields(userProvidedFields, path)) {\n        fields[path] = 1;\n      } else if (userProvidedFields[path] === 0) {\n        delete fields[path];\n      }\n\n      const refPath = populateOptions[path]?.refPath;\n      if (typeof refPath === 'string') {\n        if (!isPathInFields(userProvidedFields, refPath)) {\n          fields[refPath] = 1;\n        } else if (userProvidedFields[refPath] === 0) {\n          delete fields[refPath];\n        }\n      }\n    }\n  } else if (isExclusive(fields)) {\n    for (const path of paths) {\n      if (userProvidedFields[path] == null) {\n        delete fields[path];\n      }\n      const refPath = populateOptions[path]?.refPath;\n      if (typeof refPath === 'string' && userProvidedFields[refPath] == null) {\n        delete fields[refPath];\n      }\n    }\n  }\n};\n\n/*!\n * ignore\n */\n\nfunction isPathInFields(userProvidedFields, path) {\n  const pieces = path.split('.');\n  const len = pieces.length;\n  let cur = pieces[0];\n  for (let i = 1; i < len; ++i) {\n    if (userProvidedFields[cur] != null || userProvidedFields[cur + '.$'] != null) {\n      return true;\n    }\n    cur += '.' + pieces[i];\n  }\n  return userProvidedFields[cur] != null || userProvidedFields[cur + '.$'] != null;\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/query/selectPopulatedFields.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/query/trusted.js":
/*!************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/query/trusted.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nconst trustedSymbol = Symbol('mongoose#trustedSymbol');\n\nexports.trustedSymbol = trustedSymbol;\n\nexports.trusted = function trusted(obj) {\n  if (obj == null || typeof obj !== 'object') {\n    return obj;\n  }\n  obj[trustedSymbol] = true;\n  return obj;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/query/trusted.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/schema/addAutoId.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/schema/addAutoId.js ***!
  \***************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function addAutoId(schema) {\n  const _obj = { _id: { auto: true } };\n  _obj._id[schema.options.typeKey] = 'ObjectId';\n  schema.add(_obj);\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/schema/addAutoId.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/schema/applyBuiltinPlugins.js":
/*!*************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/schema/applyBuiltinPlugins.js ***!
  \*************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst builtinPlugins = __webpack_require__(/*! ../../plugins */ \"./node_modules/mongoose/lib/plugins/index.js\");\n\nmodule.exports = function applyBuiltinPlugins(schema) {\n  for (const plugin of Object.values(builtinPlugins)) {\n    plugin(schema, { deduplicate: true });\n  }\n  schema.plugins = Object.values(builtinPlugins).\n    map(fn => ({ fn, opts: { deduplicate: true } })).\n    concat(schema.plugins);\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/schema/applyBuiltinPlugins.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/schema/applyPlugins.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/schema/applyPlugins.js ***!
  \******************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function applyPlugins(schema, plugins, options, cacheKey) {\n  if (schema[cacheKey]) {\n    return;\n  }\n  schema[cacheKey] = true;\n\n  if (!options || !options.skipTopLevel) {\n    let pluginTags = null;\n    for (const plugin of plugins) {\n      const tags = plugin[1] == null ? null : plugin[1].tags;\n      if (!Array.isArray(tags)) {\n        schema.plugin(plugin[0], plugin[1]);\n        continue;\n      }\n\n      pluginTags = pluginTags || new Set(schema.options.pluginTags || []);\n      if (!tags.find(tag => pluginTags.has(tag))) {\n        continue;\n      }\n      schema.plugin(plugin[0], plugin[1]);\n    }\n  }\n\n  options = Object.assign({}, options);\n  delete options.skipTopLevel;\n\n  if (options.applyPluginsToChildSchemas !== false) {\n    for (const path of Object.keys(schema.paths)) {\n      const type = schema.paths[path];\n      if (type.schema != null) {\n        applyPlugins(type.schema, plugins, options, cacheKey);\n\n        // Recompile schema because plugins may have changed it, see gh-7572\n        type.caster.prototype.$__setSchema(type.schema);\n      }\n    }\n  }\n\n  const discriminators = schema.discriminators;\n  if (discriminators == null) {\n    return;\n  }\n\n  const applyPluginsToDiscriminators = options.applyPluginsToDiscriminators;\n\n  const keys = Object.keys(discriminators);\n  for (const discriminatorKey of keys) {\n    const discriminatorSchema = discriminators[discriminatorKey];\n\n    applyPlugins(discriminatorSchema, plugins,\n      { skipTopLevel: !applyPluginsToDiscriminators }, cacheKey);\n  }\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/schema/applyPlugins.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/schema/applyReadConcern.js":
/*!**********************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/schema/applyReadConcern.js ***!
  \**********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst get = __webpack_require__(/*! ../get */ \"./node_modules/mongoose/lib/helpers/get.js\");\n\nmodule.exports = function applyReadConcern(schema, options) {\n  if (options.readConcern !== undefined) {\n    return;\n  }\n\n  // Don't apply default read concern to operations in transactions,\n  // because you shouldn't set read concern on individual operations\n  // within a transaction.\n  // See: https://www.mongodb.com/docs/manual/reference/read-concern/\n  if (options && options.session && options.session.transaction) {\n    return;\n  }\n\n  const level = get(schema, 'options.readConcern.level', null);\n  if (level != null) {\n    options.readConcern = { level };\n  }\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/schema/applyReadConcern.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/schema/applyWriteConcern.js":
/*!***********************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/schema/applyWriteConcern.js ***!
  \***********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst get = __webpack_require__(/*! ../get */ \"./node_modules/mongoose/lib/helpers/get.js\");\n\nmodule.exports = function applyWriteConcern(schema, options) {\n  if (options.writeConcern != null) {\n    return;\n  }\n  // Don't apply default write concern to operations in transactions,\n  // because setting write concern on an operation in a transaction is an error\n  // See: https://www.mongodb.com/docs/manual/reference/write-concern/\n  if (options && options.session && options.session.transaction) {\n    return;\n  }\n  const writeConcern = get(schema, 'options.writeConcern', {});\n  if (Object.keys(writeConcern).length != 0) {\n    options.writeConcern = {};\n    if (!('w' in options) && writeConcern.w != null) {\n      options.writeConcern.w = writeConcern.w;\n    }\n    if (!('j' in options) && writeConcern.j != null) {\n      options.writeConcern.j = writeConcern.j;\n    }\n    if (!('wtimeout' in options) && writeConcern.wtimeout != null) {\n      options.writeConcern.wtimeout = writeConcern.wtimeout;\n    }\n  }\n  else {\n    if (!('w' in options) && writeConcern.w != null) {\n      options.w = writeConcern.w;\n    }\n    if (!('j' in options) && writeConcern.j != null) {\n      options.j = writeConcern.j;\n    }\n    if (!('wtimeout' in options) && writeConcern.wtimeout != null) {\n      options.wtimeout = writeConcern.wtimeout;\n    }\n  }\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/schema/applyWriteConcern.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/schema/cleanPositionalOperators.js":
/*!******************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/schema/cleanPositionalOperators.js ***!
  \******************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/**\n * For consistency's sake, we replace positional operator `$` and array filters\n * `$[]` and `$[foo]` with `0` when looking up schema paths.\n */\n\nmodule.exports = function cleanPositionalOperators(path) {\n  return path.\n    replace(/\\.\\$(\\[[^\\]]*\\])?(?=\\.)/g, '.0').\n    replace(/\\.\\$(\\[[^\\]]*\\])?$/g, '.0');\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/schema/cleanPositionalOperators.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/schema/getIndexes.js":
/*!****************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/schema/getIndexes.js ***!
  \****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst get = __webpack_require__(/*! ../get */ \"./node_modules/mongoose/lib/helpers/get.js\");\nconst helperIsObject = __webpack_require__(/*! ../isObject */ \"./node_modules/mongoose/lib/helpers/isObject.js\");\nconst decorateDiscriminatorIndexOptions = __webpack_require__(/*! ../indexes/decorateDiscriminatorIndexOptions */ \"./node_modules/mongoose/lib/helpers/indexes/decorateDiscriminatorIndexOptions.js\");\n\n/**\n * Gather all indexes defined in the schema, including single nested,\n * document arrays, and embedded discriminators.\n * @param {Schema} schema\n * @api private\n */\n\nmodule.exports = function getIndexes(schema) {\n  let indexes = [];\n  const schemaStack = new WeakMap();\n  const indexTypes = schema.constructor.indexTypes;\n  const indexByName = new Map();\n\n  collectIndexes(schema);\n  return indexes;\n\n  function collectIndexes(schema, prefix, baseSchema) {\n    // Ignore infinitely nested schemas, if we've already seen this schema\n    // along this path there must be a cycle\n    if (schemaStack.has(schema)) {\n      return;\n    }\n    schemaStack.set(schema, true);\n\n    prefix = prefix || '';\n    const keys = Object.keys(schema.paths);\n\n    for (const key of keys) {\n      const path = schema.paths[key];\n      if (baseSchema != null && baseSchema.paths[key]) {\n        // If looking at an embedded discriminator schema, don't look at paths\n        // that the\n        continue;\n      }\n\n      if (path.$isMongooseDocumentArray || path.$isSingleNested) {\n        if (get(path, 'options.excludeIndexes') !== true &&\n            get(path, 'schemaOptions.excludeIndexes') !== true &&\n            get(path, 'schema.options.excludeIndexes') !== true) {\n          collectIndexes(path.schema, prefix + key + '.');\n        }\n\n        if (path.schema.discriminators != null) {\n          const discriminators = path.schema.discriminators;\n          const discriminatorKeys = Object.keys(discriminators);\n          for (const discriminatorKey of discriminatorKeys) {\n            collectIndexes(discriminators[discriminatorKey],\n              prefix + key + '.', path.schema);\n          }\n        }\n\n        // Retained to minimize risk of backwards breaking changes due to\n        // gh-6113\n        if (path.$isMongooseDocumentArray) {\n          continue;\n        }\n      }\n\n      const index = path._index || (path.caster && path.caster._index);\n\n      if (index !== false && index !== null && index !== undefined) {\n        const field = {};\n        const isObject = helperIsObject(index);\n        const options = isObject ? index : {};\n        const type = typeof index === 'string' ? index :\n          isObject ? index.type :\n            false;\n\n        if (type && indexTypes.indexOf(type) !== -1) {\n          field[prefix + key] = type;\n        } else if (options.text) {\n          field[prefix + key] = 'text';\n          delete options.text;\n        } else {\n          let isDescendingIndex = false;\n          if (index === 'descending' || index === 'desc') {\n            isDescendingIndex = true;\n          } else if (index === 'ascending' || index === 'asc') {\n            isDescendingIndex = false;\n          } else {\n            isDescendingIndex = Number(index) === -1;\n          }\n\n          field[prefix + key] = isDescendingIndex ? -1 : 1;\n        }\n\n        delete options.type;\n        if (!('background' in options)) {\n          options.background = true;\n        }\n        if (schema.options.autoIndex != null) {\n          options._autoIndex = schema.options.autoIndex;\n        }\n\n        const indexName = options && options.name;\n\n        if (typeof indexName === 'string') {\n          if (indexByName.has(indexName)) {\n            Object.assign(indexByName.get(indexName), field);\n          } else {\n            indexes.push([field, options]);\n            indexByName.set(indexName, field);\n          }\n        } else {\n          indexes.push([field, options]);\n          indexByName.set(indexName, field);\n        }\n      }\n    }\n\n    schemaStack.delete(schema);\n\n    if (prefix) {\n      fixSubIndexPaths(schema, prefix);\n    } else {\n      schema._indexes.forEach(function(index) {\n        const options = index[1];\n        if (!('background' in options)) {\n          options.background = true;\n        }\n        decorateDiscriminatorIndexOptions(schema, options);\n      });\n      indexes = indexes.concat(schema._indexes);\n    }\n  }\n\n  /**\n   * Checks for indexes added to subdocs using Schema.index().\n   * These indexes need their paths prefixed properly.\n   *\n   * schema._indexes = [ [indexObj, options], [indexObj, options] ..]\n   * @param {Schema} schema\n   * @param {String} prefix\n   * @api private\n   */\n\n  function fixSubIndexPaths(schema, prefix) {\n    const subindexes = schema._indexes;\n    const len = subindexes.length;\n    for (let i = 0; i < len; ++i) {\n      const indexObj = subindexes[i][0];\n      const indexOptions = subindexes[i][1];\n      const keys = Object.keys(indexObj);\n      const klen = keys.length;\n      const newindex = {};\n\n      // use forward iteration, order matters\n      for (let j = 0; j < klen; ++j) {\n        const key = keys[j];\n        newindex[prefix + key] = indexObj[key];\n      }\n\n      const newIndexOptions = Object.assign({}, indexOptions);\n      if (indexOptions != null && indexOptions.partialFilterExpression != null) {\n        newIndexOptions.partialFilterExpression = {};\n        const partialFilterExpression = indexOptions.partialFilterExpression;\n        for (const key of Object.keys(partialFilterExpression)) {\n          newIndexOptions.partialFilterExpression[prefix + key] =\n            partialFilterExpression[key];\n        }\n      }\n\n      indexes.push([newindex, newIndexOptions]);\n    }\n  }\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/schema/getIndexes.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/schema/getKeysInSchemaOrder.js":
/*!**************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/schema/getKeysInSchemaOrder.js ***!
  \**************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst get = __webpack_require__(/*! ../get */ \"./node_modules/mongoose/lib/helpers/get.js\");\n\nmodule.exports = function getKeysInSchemaOrder(schema, val, path) {\n  const schemaKeys = path != null ? Object.keys(get(schema.tree, path, {})) : Object.keys(schema.tree);\n  const valKeys = new Set(Object.keys(val));\n\n  let keys;\n  if (valKeys.size > 1) {\n    keys = new Set();\n    for (const key of schemaKeys) {\n      if (valKeys.has(key)) {\n        keys.add(key);\n      }\n    }\n    for (const key of valKeys) {\n      if (!keys.has(key)) {\n        keys.add(key);\n      }\n    }\n    keys = Array.from(keys);\n  } else {\n    keys = Array.from(valKeys);\n  }\n\n  return keys;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/schema/getKeysInSchemaOrder.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/schema/getPath.js":
/*!*************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/schema/getPath.js ***!
  \*************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nconst numberRE = /^\\d+$/;\n\n/**\n * Behaves like `Schema#path()`, except for it also digs into arrays without\n * needing to put `.0.`, so `getPath(schema, 'docArr.elProp')` works.\n * @api private\n */\n\nmodule.exports = function getPath(schema, path) {\n  let schematype = schema.path(path);\n  if (schematype != null) {\n    return schematype;\n  }\n  const pieces = path.split('.');\n  let cur = '';\n  let isArray = false;\n\n  for (const piece of pieces) {\n    if (isArray && numberRE.test(piece)) {\n      continue;\n    }\n    cur = cur.length === 0 ? piece : cur + '.' + piece;\n\n    schematype = schema.path(cur);\n    if (schematype != null && schematype.schema) {\n      schema = schematype.schema;\n      cur = '';\n      if (!isArray && schematype.$isMongooseDocumentArray) {\n        isArray = true;\n      }\n    }\n  }\n\n  return schematype;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/schema/getPath.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/schema/getSubdocumentStrictValue.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/schema/getSubdocumentStrictValue.js ***!
  \*******************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/**\n * Find the `strict` mode setting for the deepest subdocument along a given path\n * to ensure we have the correct default value for `strict`. When setting values\n * underneath a subdocument, we should use the subdocument's `strict` setting by\n * default, not the top-level document's.\n *\n * @param {Schema} schema\n * @param {String[]} parts\n * @returns {boolean | 'throw' | undefined}\n */\n\nmodule.exports = function getSubdocumentStrictValue(schema, parts) {\n  if (parts.length === 1) {\n    return undefined;\n  }\n  let cur = parts[0];\n  let strict = undefined;\n  for (let i = 0; i < parts.length - 1; ++i) {\n    const curSchemaType = schema.path(cur);\n    if (curSchemaType && curSchemaType.schema) {\n      strict = curSchemaType.schema.options.strict;\n      schema = curSchemaType.schema;\n      cur = curSchemaType.$isMongooseDocumentArray && !isNaN(parts[i + 1]) ? '' : parts[i + 1];\n    } else {\n      cur += cur.length ? ('.' + parts[i + 1]) : parts[i + 1];\n    }\n  }\n\n  return strict;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/schema/getSubdocumentStrictValue.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/schema/handleIdOption.js":
/*!********************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/schema/handleIdOption.js ***!
  \********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst addAutoId = __webpack_require__(/*! ./addAutoId */ \"./node_modules/mongoose/lib/helpers/schema/addAutoId.js\");\n\nmodule.exports = function handleIdOption(schema, options) {\n  if (options == null || options._id == null) {\n    return schema;\n  }\n\n  schema = schema.clone();\n  if (!options._id) {\n    schema.remove('_id');\n    schema.options._id = false;\n  } else if (!schema.paths['_id']) {\n    addAutoId(schema);\n    schema.options._id = true;\n  }\n\n  return schema;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/schema/handleIdOption.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/schema/handleTimestampOption.js":
/*!***************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/schema/handleTimestampOption.js ***!
  \***************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = handleTimestampOption;\n\n/*!\n * ignore\n */\n\nfunction handleTimestampOption(arg, prop) {\n  if (arg == null) {\n    return null;\n  }\n\n  if (typeof arg === 'boolean') {\n    return prop;\n  }\n  if (typeof arg[prop] === 'boolean') {\n    return arg[prop] ? prop : null;\n  }\n  if (!(prop in arg)) {\n    return prop;\n  }\n  return arg[prop];\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/schema/handleTimestampOption.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/schema/idGetter.js":
/*!**************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/schema/idGetter.js ***!
  \**************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/*!\n * ignore\n */\n\nmodule.exports = function addIdGetter(schema) {\n  // ensure the documents receive an id getter unless disabled\n  const autoIdGetter = !schema.paths['id'] &&\n    schema.paths['_id'] &&\n    schema.options.id;\n  if (!autoIdGetter) {\n    return schema;\n  }\n  if (schema.aliases && schema.aliases.id) {\n    return schema;\n  }\n  schema.virtual('id').get(idGetter);\n\n  return schema;\n};\n\n/**\n * Returns this documents _id cast to a string.\n * @api private\n */\n\nfunction idGetter() {\n  if (this._id != null) {\n    return this._id.toString();\n  }\n\n  return null;\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/schema/idGetter.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/schema/merge.js":
/*!***********************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/schema/merge.js ***!
  \***********************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function merge(s1, s2, skipConflictingPaths) {\n  const paths = Object.keys(s2.tree);\n  const pathsToAdd = {};\n  for (const key of paths) {\n    if (skipConflictingPaths && (s1.paths[key] || s1.nested[key] || s1.singleNestedPaths[key])) {\n      continue;\n    }\n    pathsToAdd[key] = s2.tree[key];\n  }\n  s1.options._isMerging = true;\n  s1.add(pathsToAdd, null);\n  delete s1.options._isMerging;\n\n  s1.callQueue = s1.callQueue.concat(s2.callQueue);\n  s1.method(s2.methods);\n  s1.static(s2.statics);\n\n  for (const [option, value] of Object.entries(s2._userProvidedOptions)) {\n    if (!(option in s1._userProvidedOptions)) {\n      s1.set(option, value);\n    }\n  }\n\n  for (const query in s2.query) {\n    s1.query[query] = s2.query[query];\n  }\n\n  for (const virtual in s2.virtuals) {\n    s1.virtuals[virtual] = s2.virtuals[virtual].clone();\n  }\n\n  s1._indexes = s1._indexes.concat(s2._indexes || []);\n  s1.s.hooks.merge(s2.s.hooks, false);\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/schema/merge.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/schematype/handleImmutable.js":
/*!*************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/schematype/handleImmutable.js ***!
  \*************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst StrictModeError = __webpack_require__(/*! ../../error/strict */ \"./node_modules/mongoose/lib/error/strict.js\");\n\n/*!\n * ignore\n */\n\nmodule.exports = function(schematype) {\n  if (schematype.$immutable) {\n    schematype.$immutableSetter = createImmutableSetter(schematype.path,\n      schematype.options.immutable);\n    schematype.set(schematype.$immutableSetter);\n  } else if (schematype.$immutableSetter) {\n    schematype.setters = schematype.setters.\n      filter(fn => fn !== schematype.$immutableSetter);\n    delete schematype.$immutableSetter;\n  }\n};\n\nfunction createImmutableSetter(path, immutable) {\n  return function immutableSetter(v, _priorVal, _doc, options) {\n    if (this == null || this.$__ == null) {\n      return v;\n    }\n    if (this.isNew) {\n      return v;\n    }\n    if (options && options.overwriteImmutable) {\n      return v;\n    }\n\n    const _immutable = typeof immutable === 'function' ?\n      immutable.call(this, this) :\n      immutable;\n    if (!_immutable) {\n      return v;\n    }\n\n    const _value = this.$__.priorDoc != null ?\n      this.$__.priorDoc.$__getValue(path) :\n      this.$__getValue(path);\n    if (this.$__.strictMode === 'throw' && v !== _value) {\n      throw new StrictModeError(path, 'Path `' + path + '` is immutable ' +\n        'and strict mode is set to throw.', true);\n    }\n\n    return _value;\n  };\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/schematype/handleImmutable.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/setDefaultsOnInsert.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/setDefaultsOnInsert.js ***!
  \******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst modifiedPaths = (__webpack_require__(/*! ./common */ \"./node_modules/mongoose/lib/helpers/common.js\").modifiedPaths);\nconst get = __webpack_require__(/*! ./get */ \"./node_modules/mongoose/lib/helpers/get.js\");\n\n/**\n * Applies defaults to update and findOneAndUpdate operations.\n *\n * @param {Object} filter\n * @param {Schema} schema\n * @param {Object} castedDoc\n * @param {Object} options\n * @method setDefaultsOnInsert\n * @api private\n */\n\nmodule.exports = function(filter, schema, castedDoc, options) {\n  options = options || {};\n\n  const shouldSetDefaultsOnInsert =\n    options.setDefaultsOnInsert != null ?\n      options.setDefaultsOnInsert :\n      schema.base.options.setDefaultsOnInsert;\n\n  if (!options.upsert || shouldSetDefaultsOnInsert === false) {\n    return castedDoc;\n  }\n\n  const keys = Object.keys(castedDoc || {});\n  const updatedKeys = {};\n  const updatedValues = {};\n  const numKeys = keys.length;\n  const modified = {};\n\n  let hasDollarUpdate = false;\n\n  for (let i = 0; i < numKeys; ++i) {\n    if (keys[i].startsWith('$')) {\n      modifiedPaths(castedDoc[keys[i]], '', modified);\n      hasDollarUpdate = true;\n    }\n  }\n\n  if (!hasDollarUpdate) {\n    modifiedPaths(castedDoc, '', modified);\n  }\n\n  const paths = Object.keys(filter);\n  const numPaths = paths.length;\n  for (let i = 0; i < numPaths; ++i) {\n    const path = paths[i];\n    const condition = filter[path];\n    if (condition && typeof condition === 'object') {\n      const conditionKeys = Object.keys(condition);\n      const numConditionKeys = conditionKeys.length;\n      let hasDollarKey = false;\n      for (let j = 0; j < numConditionKeys; ++j) {\n        if (conditionKeys[j].startsWith('$')) {\n          hasDollarKey = true;\n          break;\n        }\n      }\n      if (hasDollarKey) {\n        continue;\n      }\n    }\n    updatedKeys[path] = true;\n    modified[path] = true;\n  }\n\n  if (options && options.overwrite && !hasDollarUpdate) {\n    // Defaults will be set later, since we're overwriting we'll cast\n    // the whole update to a document\n    return castedDoc;\n  }\n\n  schema.eachPath(function(path, schemaType) {\n    // Skip single nested paths if underneath a map\n    if (schemaType.path === '_id' && schemaType.options.auto) {\n      return;\n    }\n    const def = schemaType.getDefault(null, true);\n    if (isModified(modified, path)) {\n      return;\n    }\n    if (typeof def === 'undefined') {\n      return;\n    }\n    if (schemaType.splitPath().includes('$*')) {\n      // Skip defaults underneath maps. We should never do `$setOnInsert` on a path with `$*`\n      return;\n    }\n\n    castedDoc = castedDoc || {};\n    castedDoc.$setOnInsert = castedDoc.$setOnInsert || {};\n    if (get(castedDoc, path) == null) {\n      castedDoc.$setOnInsert[path] = def;\n    }\n    updatedValues[path] = def;\n  });\n\n  return castedDoc;\n};\n\nfunction isModified(modified, path) {\n  if (modified[path]) {\n    return true;\n  }\n\n  // Is any parent path of `path` modified?\n  const sp = path.split('.');\n  let cur = sp[0];\n  for (let i = 1; i < sp.length; ++i) {\n    if (modified[cur]) {\n      return true;\n    }\n    cur += '.' + sp[i];\n  }\n\n  // Is any child of `path` modified?\n  const modifiedKeys = Object.keys(modified);\n  if (modifiedKeys.length) {\n    const parentPath = path + '.';\n\n    for (const modifiedPath of modifiedKeys) {\n      if (modifiedPath.slice(0, path.length + 1) === parentPath) {\n        return true;\n      }\n    }\n  }\n\n  return false;\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/setDefaultsOnInsert.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/specialProperties.js":
/*!****************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/specialProperties.js ***!
  \****************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = new Set(['__proto__', 'constructor', 'prototype']);\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/specialProperties.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/symbols.js":
/*!******************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/symbols.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nexports.arrayAtomicsBackupSymbol = Symbol('mongoose#Array#atomicsBackup');\nexports.arrayAtomicsSymbol = Symbol('mongoose#Array#_atomics');\nexports.arrayParentSymbol = Symbol('mongoose#Array#_parent');\nexports.arrayPathSymbol = Symbol('mongoose#Array#_path');\nexports.arraySchemaSymbol = Symbol('mongoose#Array#_schema');\nexports.documentArrayParent = Symbol('mongoose#documentArrayParent');\nexports.documentIsSelected = Symbol('mongoose#Document#isSelected');\nexports.documentIsModified = Symbol('mongoose#Document#isModified');\nexports.documentModifiedPaths = Symbol('mongoose#Document#modifiedPaths');\nexports.documentSchemaSymbol = Symbol('mongoose#Document#schema');\nexports.getSymbol = Symbol('mongoose#Document#get');\nexports.modelSymbol = Symbol('mongoose#Model');\nexports.objectIdSymbol = Symbol('mongoose#ObjectId');\nexports.populateModelSymbol = Symbol('mongoose#PopulateOptions#Model');\nexports.schemaTypeSymbol = Symbol('mongoose#schemaType');\nexports.sessionNewDocuments = Symbol('mongoose#ClientSession#newDocuments');\nexports.scopeSymbol = Symbol('mongoose#Document#scope');\nexports.validatorErrorSymbol = Symbol('mongoose#validatorError');\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/symbols.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/timers.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/timers.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nexports.setTimeout = setTimeout;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/timers.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/timestamps/setDocumentTimestamps.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/timestamps/setDocumentTimestamps.js ***!
  \*******************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function setDocumentTimestamps(doc, timestampOption, currentTime, createdAt, updatedAt) {\n  const skipUpdatedAt = timestampOption != null && timestampOption.updatedAt === false;\n  const skipCreatedAt = timestampOption != null && timestampOption.createdAt === false;\n\n  const defaultTimestamp = currentTime != null ?\n    currentTime() :\n    doc.ownerDocument().constructor.base.now();\n\n  if (!skipCreatedAt &&\n      (doc.isNew || doc.$isSubdocument) &&\n      createdAt &&\n      !doc.$__getValue(createdAt) &&\n      doc.$__isSelected(createdAt)) {\n    doc.$set(createdAt, defaultTimestamp, undefined, { overwriteImmutable: true });\n  }\n\n  if (!skipUpdatedAt && updatedAt && (doc.isNew || doc.$isModified())) {\n    let ts = defaultTimestamp;\n    if (doc.isNew && createdAt != null) {\n      ts = doc.$__getValue(createdAt);\n    }\n    doc.$set(updatedAt, ts);\n  }\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/timestamps/setDocumentTimestamps.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/timestamps/setupTimestamps.js":
/*!*************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/timestamps/setupTimestamps.js ***!
  \*************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst applyTimestampsToChildren = __webpack_require__(/*! ../update/applyTimestampsToChildren */ \"./node_modules/mongoose/lib/helpers/update/applyTimestampsToChildren.js\");\nconst applyTimestampsToUpdate = __webpack_require__(/*! ../update/applyTimestampsToUpdate */ \"./node_modules/mongoose/lib/helpers/update/applyTimestampsToUpdate.js\");\nconst get = __webpack_require__(/*! ../get */ \"./node_modules/mongoose/lib/helpers/get.js\");\nconst handleTimestampOption = __webpack_require__(/*! ../schema/handleTimestampOption */ \"./node_modules/mongoose/lib/helpers/schema/handleTimestampOption.js\");\nconst setDocumentTimestamps = __webpack_require__(/*! ./setDocumentTimestamps */ \"./node_modules/mongoose/lib/helpers/timestamps/setDocumentTimestamps.js\");\nconst symbols = __webpack_require__(/*! ../../schema/symbols */ \"./node_modules/mongoose/lib/schema/symbols.js\");\n\nconst replaceOps = new Set([\n  'replaceOne',\n  'findOneAndReplace'\n]);\n\nmodule.exports = function setupTimestamps(schema, timestamps) {\n  const childHasTimestamp = schema.childSchemas.find(withTimestamp);\n  function withTimestamp(s) {\n    const ts = s.schema.options.timestamps;\n    return !!ts;\n  }\n  if (!timestamps && !childHasTimestamp) {\n    return;\n  }\n  const createdAt = handleTimestampOption(timestamps, 'createdAt');\n  const updatedAt = handleTimestampOption(timestamps, 'updatedAt');\n  const currentTime = timestamps != null && timestamps.hasOwnProperty('currentTime') ?\n    timestamps.currentTime :\n    null;\n  const schemaAdditions = {};\n\n  schema.$timestamps = { createdAt: createdAt, updatedAt: updatedAt };\n\n  if (createdAt && !schema.paths[createdAt]) {\n    const baseImmutableCreatedAt = schema.base != null ? schema.base.get('timestamps.createdAt.immutable') : null;\n    const immutable = baseImmutableCreatedAt != null ? baseImmutableCreatedAt : true;\n    schemaAdditions[createdAt] = { [schema.options.typeKey || 'type']: Date, immutable };\n  }\n\n  if (updatedAt && !schema.paths[updatedAt]) {\n    schemaAdditions[updatedAt] = Date;\n  }\n\n  schema.add(schemaAdditions);\n\n  schema.pre('save', function timestampsPreSave(next) {\n    const timestampOption = get(this, '$__.saveOptions.timestamps');\n    if (timestampOption === false) {\n      return next();\n    }\n\n    setDocumentTimestamps(this, timestampOption, currentTime, createdAt, updatedAt);\n\n    next();\n  });\n\n  schema.methods.initializeTimestamps = function() {\n    const ts = currentTime != null ?\n      currentTime() : this.constructor.base.now();\n\n\n    if (createdAt && !this.get(createdAt)) {\n      this.$set(createdAt, ts);\n    }\n    if (updatedAt && !this.get(updatedAt)) {\n      this.$set(updatedAt, ts);\n    }\n    if (this.$isSubdocument) {\n      return this;\n    }\n\n    const subdocs = this.$getAllSubdocs();\n    for (const subdoc of subdocs) {\n      if (subdoc.initializeTimestamps) {\n        subdoc.initializeTimestamps();\n      }\n    }\n\n    return this;\n  };\n\n  _setTimestampsOnUpdate[symbols.builtInMiddleware] = true;\n\n  const opts = { query: true, model: false };\n  schema.pre('findOneAndReplace', opts, _setTimestampsOnUpdate);\n  schema.pre('findOneAndUpdate', opts, _setTimestampsOnUpdate);\n  schema.pre('replaceOne', opts, _setTimestampsOnUpdate);\n  schema.pre('update', opts, _setTimestampsOnUpdate);\n  schema.pre('updateOne', opts, _setTimestampsOnUpdate);\n  schema.pre('updateMany', opts, _setTimestampsOnUpdate);\n\n  function _setTimestampsOnUpdate(next) {\n    const now = currentTime != null ?\n      currentTime() :\n      this.model.base.now();\n    // Replacing with null update should still trigger timestamps\n    if (replaceOps.has(this.op) && this.getUpdate() == null) {\n      this.setUpdate({});\n    }\n    applyTimestampsToUpdate(\n      now,\n      createdAt,\n      updatedAt,\n      this.getUpdate(),\n      this._mongooseOptions,\n      replaceOps.has(this.op)\n    );\n    applyTimestampsToChildren(now, this.getUpdate(), this.model.schema);\n    next();\n  }\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/timestamps/setupTimestamps.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/topology/allServersUnknown.js":
/*!*************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/topology/allServersUnknown.js ***!
  \*************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst getConstructorName = __webpack_require__(/*! ../getConstructorName */ \"./node_modules/mongoose/lib/helpers/getConstructorName.js\");\n\nmodule.exports = function allServersUnknown(topologyDescription) {\n  if (getConstructorName(topologyDescription) !== 'TopologyDescription') {\n    return false;\n  }\n\n  const servers = Array.from(topologyDescription.servers.values());\n  return servers.length > 0 && servers.every(server => server.type === 'Unknown');\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/topology/allServersUnknown.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/topology/isAtlas.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/topology/isAtlas.js ***!
  \***************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst getConstructorName = __webpack_require__(/*! ../getConstructorName */ \"./node_modules/mongoose/lib/helpers/getConstructorName.js\");\n\n/**\n * @typedef { import('mongodb').TopologyDescription } TopologyDescription\n */\n\n/**\n * Checks if topologyDescription contains servers connected to an atlas instance\n *\n * @param  {TopologyDescription} topologyDescription\n * @returns {boolean}\n */\nmodule.exports = function isAtlas(topologyDescription) {\n  if (getConstructorName(topologyDescription) !== 'TopologyDescription') {\n    return false;\n  }\n\n  if (topologyDescription.servers.size === 0) {\n    return false;\n  }\n\n  for (const server of topologyDescription.servers.values()) {\n    if (server.host.endsWith('.mongodb.net') === false || server.port !== 27017) {\n      return false;\n    }\n  }\n\n  return true;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/topology/isAtlas.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/topology/isSSLError.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/topology/isSSLError.js ***!
  \******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst getConstructorName = __webpack_require__(/*! ../getConstructorName */ \"./node_modules/mongoose/lib/helpers/getConstructorName.js\");\n\nconst nonSSLMessage = 'Client network socket disconnected before secure TLS ' +\n  'connection was established';\n\nmodule.exports = function isSSLError(topologyDescription) {\n  if (getConstructorName(topologyDescription) !== 'TopologyDescription') {\n    return false;\n  }\n\n  const descriptions = Array.from(topologyDescription.servers.values());\n  return descriptions.length > 0 &&\n    descriptions.every(descr => descr.error && descr.error.message.indexOf(nonSSLMessage) !== -1);\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/topology/isSSLError.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/update/applyTimestampsToChildren.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/update/applyTimestampsToChildren.js ***!
  \*******************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst cleanPositionalOperators = __webpack_require__(/*! ../schema/cleanPositionalOperators */ \"./node_modules/mongoose/lib/helpers/schema/cleanPositionalOperators.js\");\nconst handleTimestampOption = __webpack_require__(/*! ../schema/handleTimestampOption */ \"./node_modules/mongoose/lib/helpers/schema/handleTimestampOption.js\");\n\nmodule.exports = applyTimestampsToChildren;\n\n/*!\n * ignore\n */\n\nfunction applyTimestampsToChildren(now, update, schema) {\n  if (update == null) {\n    return;\n  }\n\n  const keys = Object.keys(update);\n  const hasDollarKey = keys.some(key => key[0] === '$');\n\n  if (hasDollarKey) {\n    if (update.$push) {\n      _applyTimestampToUpdateOperator(update.$push);\n    }\n    if (update.$addToSet) {\n      _applyTimestampToUpdateOperator(update.$addToSet);\n    }\n    if (update.$set != null) {\n      const keys = Object.keys(update.$set);\n      for (const key of keys) {\n        applyTimestampsToUpdateKey(schema, key, update.$set, now);\n      }\n    }\n    if (update.$setOnInsert != null) {\n      const keys = Object.keys(update.$setOnInsert);\n      for (const key of keys) {\n        applyTimestampsToUpdateKey(schema, key, update.$setOnInsert, now);\n      }\n    }\n  }\n\n  const updateKeys = Object.keys(update).filter(key => key[0] !== '$');\n  for (const key of updateKeys) {\n    applyTimestampsToUpdateKey(schema, key, update, now);\n  }\n\n  function _applyTimestampToUpdateOperator(op) {\n    for (const key of Object.keys(op)) {\n      const $path = schema.path(key.replace(/\\.\\$\\./i, '.').replace(/.\\$$/, ''));\n      if (op[key] &&\n          $path &&\n          $path.$isMongooseDocumentArray &&\n          $path.schema.options.timestamps) {\n        const timestamps = $path.schema.options.timestamps;\n        const createdAt = handleTimestampOption(timestamps, 'createdAt');\n        const updatedAt = handleTimestampOption(timestamps, 'updatedAt');\n        if (op[key].$each) {\n          op[key].$each.forEach(function(subdoc) {\n            if (updatedAt != null) {\n              subdoc[updatedAt] = now;\n            }\n            if (createdAt != null) {\n              subdoc[createdAt] = now;\n            }\n\n            applyTimestampsToChildren(now, subdoc, $path.schema);\n          });\n        } else {\n          if (updatedAt != null) {\n            op[key][updatedAt] = now;\n          }\n          if (createdAt != null) {\n            op[key][createdAt] = now;\n          }\n\n          applyTimestampsToChildren(now, op[key], $path.schema);\n        }\n      }\n    }\n  }\n}\n\nfunction applyTimestampsToDocumentArray(arr, schematype, now) {\n  const timestamps = schematype.schema.options.timestamps;\n\n  const len = arr.length;\n\n  if (!timestamps) {\n    for (let i = 0; i < len; ++i) {\n      applyTimestampsToChildren(now, arr[i], schematype.schema);\n    }\n    return;\n  }\n\n  const createdAt = handleTimestampOption(timestamps, 'createdAt');\n  const updatedAt = handleTimestampOption(timestamps, 'updatedAt');\n  for (let i = 0; i < len; ++i) {\n    if (updatedAt != null) {\n      arr[i][updatedAt] = now;\n    }\n    if (createdAt != null) {\n      arr[i][createdAt] = now;\n    }\n\n    applyTimestampsToChildren(now, arr[i], schematype.schema);\n  }\n}\n\nfunction applyTimestampsToSingleNested(subdoc, schematype, now) {\n  const timestamps = schematype.schema.options.timestamps;\n  if (!timestamps) {\n    applyTimestampsToChildren(now, subdoc, schematype.schema);\n    return;\n  }\n\n  const createdAt = handleTimestampOption(timestamps, 'createdAt');\n  const updatedAt = handleTimestampOption(timestamps, 'updatedAt');\n  if (updatedAt != null) {\n    subdoc[updatedAt] = now;\n  }\n  if (createdAt != null) {\n    subdoc[createdAt] = now;\n  }\n\n  applyTimestampsToChildren(now, subdoc, schematype.schema);\n}\n\nfunction applyTimestampsToUpdateKey(schema, key, update, now) {\n  // Replace positional operator `$` and array filters `$[]` and `$[.*]`\n  const keyToSearch = cleanPositionalOperators(key);\n  const path = schema.path(keyToSearch);\n  if (!path) {\n    return;\n  }\n\n  const parentSchemaTypes = [];\n  const pieces = keyToSearch.split('.');\n  for (let i = pieces.length - 1; i > 0; --i) {\n    const s = schema.path(pieces.slice(0, i).join('.'));\n    if (s != null &&\n      (s.$isMongooseDocumentArray || s.$isSingleNested)) {\n      parentSchemaTypes.push({ parentPath: key.split('.').slice(0, i).join('.'), parentSchemaType: s });\n    }\n  }\n\n  if (Array.isArray(update[key]) && path.$isMongooseDocumentArray) {\n    applyTimestampsToDocumentArray(update[key], path, now);\n  } else if (update[key] && path.$isSingleNested) {\n    applyTimestampsToSingleNested(update[key], path, now);\n  } else if (parentSchemaTypes.length > 0) {\n    for (const item of parentSchemaTypes) {\n      const parentPath = item.parentPath;\n      const parentSchemaType = item.parentSchemaType;\n      const timestamps = parentSchemaType.schema.options.timestamps;\n      const updatedAt = handleTimestampOption(timestamps, 'updatedAt');\n\n      if (!timestamps || updatedAt == null) {\n        continue;\n      }\n\n      if (parentSchemaType.$isSingleNested) {\n        // Single nested is easy\n        update[parentPath + '.' + updatedAt] = now;\n      } else if (parentSchemaType.$isMongooseDocumentArray) {\n        let childPath = key.substring(parentPath.length + 1);\n\n        if (/^\\d+$/.test(childPath)) {\n          update[parentPath + '.' + childPath][updatedAt] = now;\n          continue;\n        }\n\n        const firstDot = childPath.indexOf('.');\n        childPath = firstDot !== -1 ? childPath.substring(0, firstDot) : childPath;\n\n        update[parentPath + '.' + childPath + '.' + updatedAt] = now;\n      }\n    }\n  } else if (path.schema != null && path.schema != schema && update[key]) {\n    const timestamps = path.schema.options.timestamps;\n    const createdAt = handleTimestampOption(timestamps, 'createdAt');\n    const updatedAt = handleTimestampOption(timestamps, 'updatedAt');\n\n    if (!timestamps) {\n      return;\n    }\n\n    if (updatedAt != null) {\n      update[key][updatedAt] = now;\n    }\n    if (createdAt != null) {\n      update[key][createdAt] = now;\n    }\n  }\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/update/applyTimestampsToChildren.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/update/applyTimestampsToUpdate.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/update/applyTimestampsToUpdate.js ***!
  \*****************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * ignore\n */\n\nconst get = __webpack_require__(/*! ../get */ \"./node_modules/mongoose/lib/helpers/get.js\");\n\nmodule.exports = applyTimestampsToUpdate;\n\n/*!\n * ignore\n */\n\nfunction applyTimestampsToUpdate(now, createdAt, updatedAt, currentUpdate, options, isReplace) {\n  const updates = currentUpdate;\n  let _updates = updates;\n  const timestamps = get(options, 'timestamps', true);\n\n  // Support skipping timestamps at the query level, see gh-6980\n  if (!timestamps || updates == null) {\n    return currentUpdate;\n  }\n\n  const skipCreatedAt = timestamps != null && timestamps.createdAt === false;\n  const skipUpdatedAt = timestamps != null && timestamps.updatedAt === false;\n\n  if (isReplace) {\n    if (currentUpdate && currentUpdate.$set) {\n      currentUpdate = currentUpdate.$set;\n      updates.$set = {};\n      _updates = updates.$set;\n    }\n    if (!skipUpdatedAt && updatedAt && !currentUpdate[updatedAt]) {\n      _updates[updatedAt] = now;\n    }\n    if (!skipCreatedAt && createdAt && !currentUpdate[createdAt]) {\n      _updates[createdAt] = now;\n    }\n    return updates;\n  }\n  currentUpdate = currentUpdate || {};\n\n  if (Array.isArray(updates)) {\n    // Update with aggregation pipeline\n    if (updatedAt == null) {\n      return updates;\n    }\n    updates.push({ $set: { [updatedAt]: now } });\n    return updates;\n  }\n  updates.$set = updates.$set || {};\n  if (!skipUpdatedAt && updatedAt &&\n      (!currentUpdate.$currentDate || !currentUpdate.$currentDate[updatedAt])) {\n    let timestampSet = false;\n    if (updatedAt.indexOf('.') !== -1) {\n      const pieces = updatedAt.split('.');\n      for (let i = 1; i < pieces.length; ++i) {\n        const remnant = pieces.slice(-i).join('.');\n        const start = pieces.slice(0, -i).join('.');\n        if (currentUpdate[start] != null) {\n          currentUpdate[start][remnant] = now;\n          timestampSet = true;\n          break;\n        } else if (currentUpdate.$set && currentUpdate.$set[start]) {\n          currentUpdate.$set[start][remnant] = now;\n          timestampSet = true;\n          break;\n        }\n      }\n    }\n\n    if (!timestampSet) {\n      updates.$set[updatedAt] = now;\n    }\n\n    if (updates.hasOwnProperty(updatedAt)) {\n      delete updates[updatedAt];\n    }\n  }\n\n  if (!skipCreatedAt && createdAt) {\n    if (currentUpdate[createdAt]) {\n      delete currentUpdate[createdAt];\n    }\n    if (currentUpdate.$set && currentUpdate.$set[createdAt]) {\n      delete currentUpdate.$set[createdAt];\n    }\n    let timestampSet = false;\n    if (createdAt.indexOf('.') !== -1) {\n      const pieces = createdAt.split('.');\n      for (let i = 1; i < pieces.length; ++i) {\n        const remnant = pieces.slice(-i).join('.');\n        const start = pieces.slice(0, -i).join('.');\n        if (currentUpdate[start] != null) {\n          currentUpdate[start][remnant] = now;\n          timestampSet = true;\n          break;\n        } else if (currentUpdate.$set && currentUpdate.$set[start]) {\n          currentUpdate.$set[start][remnant] = now;\n          timestampSet = true;\n          break;\n        }\n      }\n    }\n\n    if (!timestampSet) {\n      updates.$setOnInsert = updates.$setOnInsert || {};\n      updates.$setOnInsert[createdAt] = now;\n    }\n  }\n\n  if (Object.keys(updates.$set).length === 0) {\n    delete updates.$set;\n  }\n  return updates;\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/update/applyTimestampsToUpdate.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/update/castArrayFilters.js":
/*!**********************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/update/castArrayFilters.js ***!
  \**********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst castFilterPath = __webpack_require__(/*! ../query/castFilterPath */ \"./node_modules/mongoose/lib/helpers/query/castFilterPath.js\");\nconst cleanPositionalOperators = __webpack_require__(/*! ../schema/cleanPositionalOperators */ \"./node_modules/mongoose/lib/helpers/schema/cleanPositionalOperators.js\");\nconst getPath = __webpack_require__(/*! ../schema/getPath */ \"./node_modules/mongoose/lib/helpers/schema/getPath.js\");\nconst updatedPathsByArrayFilter = __webpack_require__(/*! ./updatedPathsByArrayFilter */ \"./node_modules/mongoose/lib/helpers/update/updatedPathsByArrayFilter.js\");\n\nmodule.exports = function castArrayFilters(query) {\n  const arrayFilters = query.options.arrayFilters;\n  const update = query.getUpdate();\n  const schema = query.schema;\n  const updatedPathsByFilter = updatedPathsByArrayFilter(update);\n\n  let strictQuery = schema.options.strict;\n  if (query._mongooseOptions.strict != null) {\n    strictQuery = query._mongooseOptions.strict;\n  }\n  if (query.model && query.model.base.options.strictQuery != null) {\n    strictQuery = query.model.base.options.strictQuery;\n  }\n  if (schema._userProvidedOptions.strictQuery != null) {\n    strictQuery = schema._userProvidedOptions.strictQuery;\n  }\n  if (query._mongooseOptions.strictQuery != null) {\n    strictQuery = query._mongooseOptions.strictQuery;\n  }\n\n  _castArrayFilters(arrayFilters, schema, strictQuery, updatedPathsByFilter, query);\n};\n\nfunction _castArrayFilters(arrayFilters, schema, strictQuery, updatedPathsByFilter, query) {\n  if (!Array.isArray(arrayFilters)) {\n    return;\n  }\n\n  for (const filter of arrayFilters) {\n    if (filter == null) {\n      throw new Error(`Got null array filter in ${arrayFilters}`);\n    }\n    const keys = Object.keys(filter).filter(key => filter[key] != null);\n    if (keys.length === 0) {\n      continue;\n    }\n\n    const firstKey = keys[0];\n    if (firstKey === '$and' || firstKey === '$or') {\n      for (const key of keys) {\n        _castArrayFilters(filter[key], schema, strictQuery, updatedPathsByFilter, query);\n      }\n      continue;\n    }\n    const dot = firstKey.indexOf('.');\n    const filterWildcardPath = dot === -1 ? firstKey : firstKey.substring(0, dot);\n    if (updatedPathsByFilter[filterWildcardPath] == null) {\n      continue;\n    }\n    const baseFilterPath = cleanPositionalOperators(\n      updatedPathsByFilter[filterWildcardPath]\n    );\n\n    const baseSchematype = getPath(schema, baseFilterPath);\n    let filterBaseSchema = baseSchematype != null ? baseSchematype.schema : null;\n    if (filterBaseSchema != null &&\n        filterBaseSchema.discriminators != null &&\n        filter[filterWildcardPath + '.' + filterBaseSchema.options.discriminatorKey]) {\n      filterBaseSchema = filterBaseSchema.discriminators[filter[filterWildcardPath + '.' + filterBaseSchema.options.discriminatorKey]] || filterBaseSchema;\n    }\n\n    for (const key of keys) {\n      if (updatedPathsByFilter[key] === null) {\n        continue;\n      }\n      if (Object.keys(updatedPathsByFilter).length === 0) {\n        continue;\n      }\n      const dot = key.indexOf('.');\n\n      let filterPathRelativeToBase = dot === -1 ? null : key.substring(dot);\n      let schematype;\n      if (filterPathRelativeToBase == null || filterBaseSchema == null) {\n        schematype = baseSchematype;\n      } else {\n        // If there are multiple array filters in the path being updated, make sure\n        // to replace them so we can get the schema path.\n        filterPathRelativeToBase = cleanPositionalOperators(filterPathRelativeToBase);\n        schematype = getPath(filterBaseSchema, filterPathRelativeToBase);\n      }\n\n      if (schematype == null) {\n        if (!strictQuery) {\n          return;\n        }\n        const filterPath = filterPathRelativeToBase == null ?\n          baseFilterPath + '.0' :\n          baseFilterPath + '.0' + filterPathRelativeToBase;\n        // For now, treat `strictQuery = true` and `strictQuery = 'throw'` as\n        // equivalent for casting array filters. `strictQuery = true` doesn't\n        // quite work in this context because we never want to silently strip out\n        // array filters, even if the path isn't in the schema.\n        throw new Error(`Could not find path \"${filterPath}\" in schema`);\n      }\n      if (typeof filter[key] === 'object') {\n        filter[key] = castFilterPath(query, schematype, filter[key]);\n      } else {\n        filter[key] = schematype.castForQuery(null, filter[key]);\n      }\n    }\n  }\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/update/castArrayFilters.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/update/decorateUpdateWithVersionKey.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/update/decorateUpdateWithVersionKey.js ***!
  \**********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst modifiedPaths = __webpack_require__(/*! ./modifiedPaths */ \"./node_modules/mongoose/lib/helpers/update/modifiedPaths.js\");\n\n/**\n * Decorate the update with a version key, if necessary\n * @api private\n */\n\nmodule.exports = function decorateUpdateWithVersionKey(update, options, versionKey) {\n  if (!versionKey || !(options && options.upsert || false)) {\n    return;\n  }\n\n  const updatedPaths = modifiedPaths(update);\n  if (!updatedPaths[versionKey]) {\n    if (options.overwrite) {\n      update[versionKey] = 0;\n    } else {\n      if (!update.$setOnInsert) {\n        update.$setOnInsert = {};\n      }\n      update.$setOnInsert[versionKey] = 0;\n    }\n  }\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/update/decorateUpdateWithVersionKey.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/update/modifiedPaths.js":
/*!*******************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/update/modifiedPaths.js ***!
  \*******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst _modifiedPaths = (__webpack_require__(/*! ../common */ \"./node_modules/mongoose/lib/helpers/common.js\").modifiedPaths);\n\n/**\n * Given an update document with potential update operators (`$set`, etc.)\n * returns an object whose keys are the directly modified paths.\n *\n * If there are any top-level keys that don't start with `$`, we assume those\n * will get wrapped in a `$set`. The Mongoose Query is responsible for wrapping\n * top-level keys in `$set`.\n *\n * @param {Object} update\n * @return {Object} modified\n */\n\nmodule.exports = function modifiedPaths(update) {\n  const keys = Object.keys(update);\n  const res = {};\n\n  const withoutDollarKeys = {};\n  for (const key of keys) {\n    if (key.startsWith('$')) {\n      _modifiedPaths(update[key], '', res);\n      continue;\n    }\n    withoutDollarKeys[key] = update[key];\n  }\n\n  _modifiedPaths(withoutDollarKeys, '', res);\n\n  return res;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/update/modifiedPaths.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/update/moveImmutableProperties.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/update/moveImmutableProperties.js ***!
  \*****************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst get = __webpack_require__(/*! ../get */ \"./node_modules/mongoose/lib/helpers/get.js\");\n\n/**\n * Given an update, move all $set on immutable properties to $setOnInsert.\n * This should only be called for upserts, because $setOnInsert bypasses the\n * strictness check for immutable properties.\n */\n\nmodule.exports = function moveImmutableProperties(schema, update, ctx) {\n  if (update == null) {\n    return;\n  }\n\n  const keys = Object.keys(update);\n  for (const key of keys) {\n    const isDollarKey = key.startsWith('$');\n\n    if (key === '$set') {\n      const updatedPaths = Object.keys(update[key]);\n      for (const path of updatedPaths) {\n        _walkUpdatePath(schema, update[key], path, update, ctx);\n      }\n    } else if (!isDollarKey) {\n      _walkUpdatePath(schema, update, key, update, ctx);\n    }\n\n  }\n};\n\nfunction _walkUpdatePath(schema, op, path, update, ctx) {\n  const schematype = schema.path(path);\n  if (schematype == null) {\n    return;\n  }\n\n  let immutable = get(schematype, 'options.immutable', null);\n  if (immutable == null) {\n    return;\n  }\n  if (typeof immutable === 'function') {\n    immutable = immutable.call(ctx, ctx);\n  }\n\n  if (!immutable) {\n    return;\n  }\n\n  update.$setOnInsert = update.$setOnInsert || {};\n  update.$setOnInsert[path] = op[path];\n  delete op[path];\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/update/moveImmutableProperties.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/update/removeUnusedArrayFilters.js":
/*!******************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/update/removeUnusedArrayFilters.js ***!
  \******************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/**\n * MongoDB throws an error if there's unused array filters. That is, if `options.arrayFilters` defines\n * a filter, but none of the `update` keys use it. This should be enough to filter out all unused array\n * filters.\n */\n\nmodule.exports = function removeUnusedArrayFilters(update, arrayFilters) {\n  const updateKeys = Object.keys(update).\n    map(key => Object.keys(update[key])).\n    reduce((cur, arr) => cur.concat(arr), []);\n  return arrayFilters.filter(obj => {\n    return _checkSingleFilterKey(obj, updateKeys);\n  });\n};\n\nfunction _checkSingleFilterKey(arrayFilter, updateKeys) {\n  const firstKey = Object.keys(arrayFilter)[0];\n\n  if (firstKey === '$and' || firstKey === '$or') {\n    if (!Array.isArray(arrayFilter[firstKey])) {\n      return false;\n    }\n    return arrayFilter[firstKey].find(filter => _checkSingleFilterKey(filter, updateKeys)) != null;\n  }\n\n  const firstDot = firstKey.indexOf('.');\n  const arrayFilterKey = firstDot === -1 ? firstKey : firstKey.slice(0, firstDot);\n\n  return updateKeys.find(key => key.includes('$[' + arrayFilterKey + ']')) != null;\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/update/removeUnusedArrayFilters.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/update/updatedPathsByArrayFilter.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/update/updatedPathsByArrayFilter.js ***!
  \*******************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst modifiedPaths = __webpack_require__(/*! ./modifiedPaths */ \"./node_modules/mongoose/lib/helpers/update/modifiedPaths.js\");\n\nmodule.exports = function updatedPathsByArrayFilter(update) {\n  if (update == null) {\n    return {};\n  }\n  const updatedPaths = modifiedPaths(update);\n\n  return Object.keys(updatedPaths).reduce((cur, path) => {\n    const matches = path.match(/\\$\\[[^\\]]+\\]/g);\n    if (matches == null) {\n      return cur;\n    }\n    for (const match of matches) {\n      const firstMatch = path.indexOf(match);\n      if (firstMatch !== path.lastIndexOf(match)) {\n        throw new Error(`Path '${path}' contains the same array filter multiple times`);\n      }\n      cur[match.substring(2, match.length - 1)] = path.\n        substring(0, firstMatch - 1).\n        replace(/\\$\\[[^\\]]+\\]/g, '0');\n    }\n    return cur;\n  }, {});\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/update/updatedPathsByArrayFilter.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/helpers/updateValidators.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongoose/lib/helpers/updateValidators.js ***!
  \***************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst ValidationError = __webpack_require__(/*! ../error/validation */ \"./node_modules/mongoose/lib/error/validation.js\");\nconst cleanPositionalOperators = __webpack_require__(/*! ./schema/cleanPositionalOperators */ \"./node_modules/mongoose/lib/helpers/schema/cleanPositionalOperators.js\");\nconst flatten = (__webpack_require__(/*! ./common */ \"./node_modules/mongoose/lib/helpers/common.js\").flatten);\nconst modifiedPaths = (__webpack_require__(/*! ./common */ \"./node_modules/mongoose/lib/helpers/common.js\").modifiedPaths);\n\n/**\n * Applies validators and defaults to update and findOneAndUpdate operations,\n * specifically passing a null doc as `this` to validators and defaults\n *\n * @param {Query} query\n * @param {Schema} schema\n * @param {Object} castedDoc\n * @param {Object} options\n * @method runValidatorsOnUpdate\n * @api private\n */\n\nmodule.exports = function(query, schema, castedDoc, options, callback) {\n  const keys = Object.keys(castedDoc || {});\n  let updatedKeys = {};\n  let updatedValues = {};\n  const isPull = {};\n  const arrayAtomicUpdates = {};\n  const numKeys = keys.length;\n  let hasDollarUpdate = false;\n  const modified = {};\n  let currentUpdate;\n  let key;\n  let i;\n\n  for (i = 0; i < numKeys; ++i) {\n    if (keys[i].startsWith('$')) {\n      hasDollarUpdate = true;\n      if (keys[i] === '$push' || keys[i] === '$addToSet') {\n        const _keys = Object.keys(castedDoc[keys[i]]);\n        for (let ii = 0; ii < _keys.length; ++ii) {\n          currentUpdate = castedDoc[keys[i]][_keys[ii]];\n          if (currentUpdate && currentUpdate.$each) {\n            arrayAtomicUpdates[_keys[ii]] = (arrayAtomicUpdates[_keys[ii]] || []).\n              concat(currentUpdate.$each);\n          } else {\n            arrayAtomicUpdates[_keys[ii]] = (arrayAtomicUpdates[_keys[ii]] || []).\n              concat([currentUpdate]);\n          }\n        }\n        continue;\n      }\n      modifiedPaths(castedDoc[keys[i]], '', modified);\n      const flat = flatten(castedDoc[keys[i]], null, null, schema);\n      const paths = Object.keys(flat);\n      const numPaths = paths.length;\n      for (let j = 0; j < numPaths; ++j) {\n        const updatedPath = cleanPositionalOperators(paths[j]);\n        key = keys[i];\n        // With `$pull` we might flatten `$in`. Skip stuff nested under `$in`\n        // for the rest of the logic, it will get handled later.\n        if (updatedPath.includes('$')) {\n          continue;\n        }\n        if (key === '$set' || key === '$setOnInsert' ||\n            key === '$pull' || key === '$pullAll') {\n          updatedValues[updatedPath] = flat[paths[j]];\n          isPull[updatedPath] = key === '$pull' || key === '$pullAll';\n        } else if (key === '$unset') {\n          updatedValues[updatedPath] = undefined;\n        }\n        updatedKeys[updatedPath] = true;\n      }\n    }\n  }\n\n  if (!hasDollarUpdate) {\n    modifiedPaths(castedDoc, '', modified);\n    updatedValues = flatten(castedDoc, null, null, schema);\n    updatedKeys = Object.keys(updatedValues);\n  }\n\n  const updates = Object.keys(updatedValues);\n  const numUpdates = updates.length;\n  const validatorsToExecute = [];\n  const validationErrors = [];\n\n  const alreadyValidated = [];\n\n  const context = query;\n  function iter(i, v) {\n    const schemaPath = schema._getSchema(updates[i]);\n    if (schemaPath == null) {\n      return;\n    }\n    if (schemaPath.instance === 'Mixed' && schemaPath.path !== updates[i]) {\n      return;\n    }\n\n    if (v && Array.isArray(v.$in)) {\n      v.$in.forEach((v, i) => {\n        validatorsToExecute.push(function(callback) {\n          schemaPath.doValidate(\n            v,\n            function(err) {\n              if (err) {\n                err.path = updates[i] + '.$in.' + i;\n                validationErrors.push(err);\n              }\n              callback(null);\n            },\n            context,\n            { updateValidator: true });\n        });\n      });\n    } else {\n      if (isPull[updates[i]] &&\n          schemaPath.$isMongooseArray) {\n        return;\n      }\n\n      if (schemaPath.$isMongooseDocumentArrayElement && v != null && v.$__ != null) {\n        alreadyValidated.push(updates[i]);\n        validatorsToExecute.push(function(callback) {\n          schemaPath.doValidate(v, function(err) {\n            if (err) {\n              if (err.errors) {\n                for (const key of Object.keys(err.errors)) {\n                  const _err = err.errors[key];\n                  _err.path = updates[i] + '.' + key;\n                  validationErrors.push(_err);\n                }\n              } else {\n                err.path = updates[i];\n                validationErrors.push(err);\n              }\n            }\n\n            return callback(null);\n          }, context, { updateValidator: true });\n        });\n      } else {\n        validatorsToExecute.push(function(callback) {\n          for (const path of alreadyValidated) {\n            if (updates[i].startsWith(path + '.')) {\n              return callback(null);\n            }\n          }\n\n          schemaPath.doValidate(v, function(err) {\n            if (schemaPath.schema != null &&\n                schemaPath.schema.options.storeSubdocValidationError === false &&\n                err instanceof ValidationError) {\n              return callback(null);\n            }\n\n            if (err) {\n              err.path = updates[i];\n              validationErrors.push(err);\n            }\n            callback(null);\n          }, context, { updateValidator: true });\n        });\n      }\n    }\n  }\n  for (i = 0; i < numUpdates; ++i) {\n    iter(i, updatedValues[updates[i]]);\n  }\n\n  const arrayUpdates = Object.keys(arrayAtomicUpdates);\n  for (const arrayUpdate of arrayUpdates) {\n    let schemaPath = schema._getSchema(arrayUpdate);\n    if (schemaPath && schemaPath.$isMongooseDocumentArray) {\n      validatorsToExecute.push(function(callback) {\n        schemaPath.doValidate(\n          arrayAtomicUpdates[arrayUpdate],\n          getValidationCallback(arrayUpdate, validationErrors, callback),\n          options && options.context === 'query' ? query : null);\n      });\n    } else {\n      schemaPath = schema._getSchema(arrayUpdate + '.0');\n      for (const atomicUpdate of arrayAtomicUpdates[arrayUpdate]) {\n        validatorsToExecute.push(function(callback) {\n          schemaPath.doValidate(\n            atomicUpdate,\n            getValidationCallback(arrayUpdate, validationErrors, callback),\n            options && options.context === 'query' ? query : null,\n            { updateValidator: true });\n        });\n      }\n    }\n  }\n\n  if (callback != null) {\n    let numValidators = validatorsToExecute.length;\n    if (numValidators === 0) {\n      return _done(callback);\n    }\n    for (const validator of validatorsToExecute) {\n      validator(function() {\n        if (--numValidators <= 0) {\n          _done(callback);\n        }\n      });\n    }\n\n    return;\n  }\n\n  return function(callback) {\n    let numValidators = validatorsToExecute.length;\n    if (numValidators === 0) {\n      return _done(callback);\n    }\n    for (const validator of validatorsToExecute) {\n      validator(function() {\n        if (--numValidators <= 0) {\n          _done(callback);\n        }\n      });\n    }\n  };\n\n  function _done(callback) {\n    if (validationErrors.length) {\n      const err = new ValidationError(null);\n\n      for (const validationError of validationErrors) {\n        err.addError(validationError.path, validationError);\n      }\n\n      return callback(err);\n    }\n    callback(null);\n  }\n\n  function getValidationCallback(arrayUpdate, validationErrors, callback) {\n    return function(err) {\n      if (err) {\n        err.path = arrayUpdate;\n        validationErrors.push(err);\n      }\n      callback(null);\n    };\n  }\n};\n\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/helpers/updateValidators.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/index.js":
/*!********************************************!*\
  !*** ./node_modules/mongoose/lib/index.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst mongodbDriver = __webpack_require__(/*! ./drivers/node-mongodb-native */ \"./node_modules/mongoose/lib/drivers/node-mongodb-native/index.js\");\n\n(__webpack_require__(/*! ./driver */ \"./node_modules/mongoose/lib/driver.js\").set)(mongodbDriver);\n\nconst mongoose = __webpack_require__(/*! ./mongoose */ \"./node_modules/mongoose/lib/mongoose.js\");\n\nmongoose.setDriver(mongodbDriver);\n\nmongoose.Mongoose.prototype.mongo = __webpack_require__(/*! mongodb */ \"./node_modules/mongodb/lib/index.js\");\n\nmodule.exports = mongoose;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/index.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/internal.js":
/*!***********************************************!*\
  !*** ./node_modules/mongoose/lib/internal.js ***!
  \***********************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Dependencies\n */\n\n\n\nconst StateMachine = __webpack_require__(/*! ./stateMachine */ \"./node_modules/mongoose/lib/stateMachine.js\");\nconst ActiveRoster = StateMachine.ctor('require', 'modify', 'init', 'default', 'ignore');\n\nmodule.exports = exports = InternalCache;\n\nfunction InternalCache() {\n  this.activePaths = new ActiveRoster();\n}\n\nInternalCache.prototype.strictMode = true;\n\nInternalCache.prototype.fullPath = undefined;\nInternalCache.prototype.selected = undefined;\nInternalCache.prototype.shardval = undefined;\nInternalCache.prototype.saveError = undefined;\nInternalCache.prototype.validationError = undefined;\nInternalCache.prototype.adhocPaths = undefined;\nInternalCache.prototype.removing = undefined;\nInternalCache.prototype.inserting = undefined;\nInternalCache.prototype.saving = undefined;\nInternalCache.prototype.version = undefined;\nInternalCache.prototype._id = undefined;\nInternalCache.prototype.ownerDocument = undefined;\nInternalCache.prototype.populate = undefined; // what we want to populate in this doc\nInternalCache.prototype.populated = undefined;// the _ids that have been populated\nInternalCache.prototype.primitiveAtomics = undefined;\n\n/**\n * If `false`, this document was not the result of population.\n * If `true`, this document is a populated doc underneath another doc\n * If an object, this document is a populated doc and the `value` property of the\n * object contains the original depopulated value.\n */\nInternalCache.prototype.wasPopulated = false;\n\nInternalCache.prototype.scope = undefined;\n\nInternalCache.prototype.session = null;\nInternalCache.prototype.pathsToScopes = null;\nInternalCache.prototype.cachedRequired = null;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/internal.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/model.js":
/*!********************************************!*\
  !*** ./node_modules/mongoose/lib/model.js ***!
  \********************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst Aggregate = __webpack_require__(/*! ./aggregate */ \"./node_modules/mongoose/lib/aggregate.js\");\nconst ChangeStream = __webpack_require__(/*! ./cursor/changeStream */ \"./node_modules/mongoose/lib/cursor/changeStream.js\");\nconst Document = __webpack_require__(/*! ./document */ \"./node_modules/mongoose/lib/document.js\");\nconst DocumentNotFoundError = __webpack_require__(/*! ./error/notFound */ \"./node_modules/mongoose/lib/error/notFound.js\");\nconst EventEmitter = (__webpack_require__(/*! events */ \"events\").EventEmitter);\nconst Kareem = __webpack_require__(/*! kareem */ \"./node_modules/kareem/index.js\");\nconst MongooseError = __webpack_require__(/*! ./error/index */ \"./node_modules/mongoose/lib/error/index.js\");\nconst ObjectParameterError = __webpack_require__(/*! ./error/objectParameter */ \"./node_modules/mongoose/lib/error/objectParameter.js\");\nconst OverwriteModelError = __webpack_require__(/*! ./error/overwriteModel */ \"./node_modules/mongoose/lib/error/overwriteModel.js\");\nconst Query = __webpack_require__(/*! ./query */ \"./node_modules/mongoose/lib/query.js\");\nconst SaveOptions = __webpack_require__(/*! ./options/saveOptions */ \"./node_modules/mongoose/lib/options/saveOptions.js\");\nconst Schema = __webpack_require__(/*! ./schema */ \"./node_modules/mongoose/lib/schema.js\");\nconst ValidationError = __webpack_require__(/*! ./error/validation */ \"./node_modules/mongoose/lib/error/validation.js\");\nconst VersionError = __webpack_require__(/*! ./error/version */ \"./node_modules/mongoose/lib/error/version.js\");\nconst ParallelSaveError = __webpack_require__(/*! ./error/parallelSave */ \"./node_modules/mongoose/lib/error/parallelSave.js\");\nconst applyDefaultsHelper = __webpack_require__(/*! ./helpers/document/applyDefaults */ \"./node_modules/mongoose/lib/helpers/document/applyDefaults.js\");\nconst applyDefaultsToPOJO = __webpack_require__(/*! ./helpers/model/applyDefaultsToPOJO */ \"./node_modules/mongoose/lib/helpers/model/applyDefaultsToPOJO.js\");\nconst applyEmbeddedDiscriminators = __webpack_require__(/*! ./helpers/discriminator/applyEmbeddedDiscriminators */ \"./node_modules/mongoose/lib/helpers/discriminator/applyEmbeddedDiscriminators.js\");\nconst applyHooks = __webpack_require__(/*! ./helpers/model/applyHooks */ \"./node_modules/mongoose/lib/helpers/model/applyHooks.js\");\nconst applyMethods = __webpack_require__(/*! ./helpers/model/applyMethods */ \"./node_modules/mongoose/lib/helpers/model/applyMethods.js\");\nconst applyProjection = __webpack_require__(/*! ./helpers/projection/applyProjection */ \"./node_modules/mongoose/lib/helpers/projection/applyProjection.js\");\nconst applyReadConcern = __webpack_require__(/*! ./helpers/schema/applyReadConcern */ \"./node_modules/mongoose/lib/helpers/schema/applyReadConcern.js\");\nconst applySchemaCollation = __webpack_require__(/*! ./helpers/indexes/applySchemaCollation */ \"./node_modules/mongoose/lib/helpers/indexes/applySchemaCollation.js\");\nconst applyStaticHooks = __webpack_require__(/*! ./helpers/model/applyStaticHooks */ \"./node_modules/mongoose/lib/helpers/model/applyStaticHooks.js\");\nconst applyStatics = __webpack_require__(/*! ./helpers/model/applyStatics */ \"./node_modules/mongoose/lib/helpers/model/applyStatics.js\");\nconst applyWriteConcern = __webpack_require__(/*! ./helpers/schema/applyWriteConcern */ \"./node_modules/mongoose/lib/helpers/schema/applyWriteConcern.js\");\nconst assignVals = __webpack_require__(/*! ./helpers/populate/assignVals */ \"./node_modules/mongoose/lib/helpers/populate/assignVals.js\");\nconst castBulkWrite = __webpack_require__(/*! ./helpers/model/castBulkWrite */ \"./node_modules/mongoose/lib/helpers/model/castBulkWrite.js\");\nconst clone = __webpack_require__(/*! ./helpers/clone */ \"./node_modules/mongoose/lib/helpers/clone.js\");\nconst createPopulateQueryFilter = __webpack_require__(/*! ./helpers/populate/createPopulateQueryFilter */ \"./node_modules/mongoose/lib/helpers/populate/createPopulateQueryFilter.js\");\nconst decorateUpdateWithVersionKey = __webpack_require__(/*! ./helpers/update/decorateUpdateWithVersionKey */ \"./node_modules/mongoose/lib/helpers/update/decorateUpdateWithVersionKey.js\");\nconst getDefaultBulkwriteResult = __webpack_require__(/*! ./helpers/getDefaultBulkwriteResult */ \"./node_modules/mongoose/lib/helpers/getDefaultBulkwriteResult.js\");\nconst getSchemaDiscriminatorByValue = __webpack_require__(/*! ./helpers/discriminator/getSchemaDiscriminatorByValue */ \"./node_modules/mongoose/lib/helpers/discriminator/getSchemaDiscriminatorByValue.js\");\nconst discriminator = __webpack_require__(/*! ./helpers/model/discriminator */ \"./node_modules/mongoose/lib/helpers/model/discriminator.js\");\nconst each = __webpack_require__(/*! ./helpers/each */ \"./node_modules/mongoose/lib/helpers/each.js\");\nconst get = __webpack_require__(/*! ./helpers/get */ \"./node_modules/mongoose/lib/helpers/get.js\");\nconst getConstructorName = __webpack_require__(/*! ./helpers/getConstructorName */ \"./node_modules/mongoose/lib/helpers/getConstructorName.js\");\nconst getDiscriminatorByValue = __webpack_require__(/*! ./helpers/discriminator/getDiscriminatorByValue */ \"./node_modules/mongoose/lib/helpers/discriminator/getDiscriminatorByValue.js\");\nconst getModelsMapForPopulate = __webpack_require__(/*! ./helpers/populate/getModelsMapForPopulate */ \"./node_modules/mongoose/lib/helpers/populate/getModelsMapForPopulate.js\");\nconst immediate = __webpack_require__(/*! ./helpers/immediate */ \"./node_modules/mongoose/lib/helpers/immediate.js\");\nconst internalToObjectOptions = (__webpack_require__(/*! ./options */ \"./node_modules/mongoose/lib/options.js\").internalToObjectOptions);\nconst isDefaultIdIndex = __webpack_require__(/*! ./helpers/indexes/isDefaultIdIndex */ \"./node_modules/mongoose/lib/helpers/indexes/isDefaultIdIndex.js\");\nconst isIndexEqual = __webpack_require__(/*! ./helpers/indexes/isIndexEqual */ \"./node_modules/mongoose/lib/helpers/indexes/isIndexEqual.js\");\nconst {\n  getRelatedDBIndexes,\n  getRelatedSchemaIndexes\n} = __webpack_require__(/*! ./helpers/indexes/getRelatedIndexes */ \"./node_modules/mongoose/lib/helpers/indexes/getRelatedIndexes.js\");\nconst decorateDiscriminatorIndexOptions = __webpack_require__(/*! ./helpers/indexes/decorateDiscriminatorIndexOptions */ \"./node_modules/mongoose/lib/helpers/indexes/decorateDiscriminatorIndexOptions.js\");\nconst isPathSelectedInclusive = __webpack_require__(/*! ./helpers/projection/isPathSelectedInclusive */ \"./node_modules/mongoose/lib/helpers/projection/isPathSelectedInclusive.js\");\nconst leanPopulateMap = __webpack_require__(/*! ./helpers/populate/leanPopulateMap */ \"./node_modules/mongoose/lib/helpers/populate/leanPopulateMap.js\");\nconst parallelLimit = __webpack_require__(/*! ./helpers/parallelLimit */ \"./node_modules/mongoose/lib/helpers/parallelLimit.js\");\nconst prepareDiscriminatorPipeline = __webpack_require__(/*! ./helpers/aggregate/prepareDiscriminatorPipeline */ \"./node_modules/mongoose/lib/helpers/aggregate/prepareDiscriminatorPipeline.js\");\nconst pushNestedArrayPaths = __webpack_require__(/*! ./helpers/model/pushNestedArrayPaths */ \"./node_modules/mongoose/lib/helpers/model/pushNestedArrayPaths.js\");\nconst removeDeselectedForeignField = __webpack_require__(/*! ./helpers/populate/removeDeselectedForeignField */ \"./node_modules/mongoose/lib/helpers/populate/removeDeselectedForeignField.js\");\nconst setDottedPath = __webpack_require__(/*! ./helpers/path/setDottedPath */ \"./node_modules/mongoose/lib/helpers/path/setDottedPath.js\");\nconst STATES = __webpack_require__(/*! ./connectionState */ \"./node_modules/mongoose/lib/connectionState.js\");\nconst util = __webpack_require__(/*! util */ \"util\");\nconst utils = __webpack_require__(/*! ./utils */ \"./node_modules/mongoose/lib/utils.js\");\nconst MongooseBulkWriteError = __webpack_require__(/*! ./error/bulkWriteError */ \"./node_modules/mongoose/lib/error/bulkWriteError.js\");\nconst minimize = __webpack_require__(/*! ./helpers/minimize */ \"./node_modules/mongoose/lib/helpers/minimize.js\");\n\nconst modelCollectionSymbol = Symbol('mongoose#Model#collection');\nconst modelDbSymbol = Symbol('mongoose#Model#db');\nconst modelSymbol = (__webpack_require__(/*! ./helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").modelSymbol);\nconst subclassedSymbol = Symbol('mongoose#Model#subclassed');\n\nconst { VERSION_INC, VERSION_WHERE, VERSION_ALL } = Document;\n\nconst saveToObjectOptions = Object.assign({}, internalToObjectOptions, {\n  bson: true,\n  flattenObjectIds: false\n});\n\n/**\n * A Model is a class that's your primary tool for interacting with MongoDB.\n * An instance of a Model is called a [Document](https://mongoosejs.com/docs/api/document.html#Document).\n *\n * In Mongoose, the term \"Model\" refers to subclasses of the `mongoose.Model`\n * class. You should not use the `mongoose.Model` class directly. The\n * [`mongoose.model()`](https://mongoosejs.com/docs/api/mongoose.html#Mongoose.prototype.model()) and\n * [`connection.model()`](https://mongoosejs.com/docs/api/connection.html#Connection.prototype.model()) functions\n * create subclasses of `mongoose.Model` as shown below.\n *\n * #### Example:\n *\n *     // `UserModel` is a \"Model\", a subclass of `mongoose.Model`.\n *     const UserModel = mongoose.model('User', new Schema({ name: String }));\n *\n *     // You can use a Model to create new documents using `new`:\n *     const userDoc = new UserModel({ name: 'Foo' });\n *     await userDoc.save();\n *\n *     // You also use a model to create queries:\n *     const userFromDb = await UserModel.findOne({ name: 'Foo' });\n *\n * @param {Object} doc values for initial set\n * @param {Object} [fields] optional object containing the fields that were selected in the query which returned this document. You do **not** need to set this parameter to ensure Mongoose handles your [query projection](https://mongoosejs.com/docs/api/query.html#Query.prototype.select()).\n * @param {Boolean} [skipId=false] optional boolean. If true, mongoose doesn't add an `_id` field to the document.\n * @inherits Document https://mongoosejs.com/docs/api/document.html\n * @event `error`: If listening to this event, 'error' is emitted when a document was saved and an `error` occurred. If not listening, the event bubbles to the connection used to create this Model.\n * @event `index`: Emitted after `Model#ensureIndexes` completes. If an error occurred it is passed with the event.\n * @event `index-single-start`: Emitted when an individual index starts within `Model#ensureIndexes`. The fields and options being used to build the index are also passed with the event.\n * @event `index-single-done`: Emitted when an individual index finishes within `Model#ensureIndexes`. If an error occurred it is passed with the event. The fields, options, and index name are also passed.\n * @api public\n */\n\nfunction Model(doc, fields, skipId) {\n  if (fields instanceof Schema) {\n    throw new TypeError('2nd argument to `Model` constructor must be a POJO or string, ' +\n      '**not** a schema. Make sure you\\'re calling `mongoose.model()`, not ' +\n      '`mongoose.Model()`.');\n  }\n  if (typeof doc === 'string') {\n    throw new TypeError('First argument to `Model` constructor must be an object, ' +\n      '**not** a string. Make sure you\\'re calling `mongoose.model()`, not ' +\n      '`mongoose.Model()`.');\n  }\n  Document.call(this, doc, fields, skipId);\n}\n\n/**\n * Inherits from Document.\n *\n * All Model.prototype features are available on\n * top level (non-sub) documents.\n * @api private\n */\n\nObject.setPrototypeOf(Model.prototype, Document.prototype);\nModel.prototype.$isMongooseModelPrototype = true;\n\n/**\n * Connection the model uses.\n *\n * @api public\n * @property db\n * @memberOf Model\n * @instance\n */\n\nModel.prototype.db;\n\n/**\n * The collection instance this model uses.\n * A Mongoose collection is a thin wrapper around a [MongoDB Node.js driver collection]([MongoDB Node.js driver collection](https://mongodb.github.io/node-mongodb-native/Next/classes/Collection.html)).\n * Using `Model.collection` means you bypass Mongoose middleware, validation, and casting.\n *\n * This property is read-only. Modifying this property is a no-op.\n *\n * @api public\n * @property collection\n * @memberOf Model\n * @instance\n */\n\nModel.prototype.collection;\n\n/**\n * Internal collection the model uses.\n *\n * This property is read-only. Modifying this property is a no-op.\n *\n * @api private\n * @property collection\n * @memberOf Model\n * @instance\n */\n\n\nModel.prototype.$__collection;\n\n/**\n * The name of the model\n *\n * @api public\n * @property modelName\n * @memberOf Model\n * @instance\n */\n\nModel.prototype.modelName;\n\n/**\n * Additional properties to attach to the query when calling `save()` and\n * `isNew` is false.\n *\n * @api public\n * @property $where\n * @memberOf Model\n * @instance\n */\n\nModel.prototype.$where;\n\n/**\n * If this is a discriminator model, `baseModelName` is the name of\n * the base model.\n *\n * @api public\n * @property baseModelName\n * @memberOf Model\n * @instance\n */\n\nModel.prototype.baseModelName;\n\n/**\n * Event emitter that reports any errors that occurred. Useful for global error\n * handling.\n *\n * #### Example:\n *\n *     MyModel.events.on('error', err => console.log(err.message));\n *\n *     // Prints a 'CastError' because of the above handler\n *     await MyModel.findOne({ _id: 'Not a valid ObjectId' }).catch(noop);\n *\n * @api public\n * @property events\n * @fires error whenever any query or model function errors\n * @memberOf Model\n * @static\n */\n\nModel.events;\n\n/**\n * Compiled middleware for this model. Set in `applyHooks()`.\n *\n * @api private\n * @property _middleware\n * @memberOf Model\n * @static\n */\n\nModel._middleware;\n\n/*!\n * ignore\n */\n\nfunction _applyCustomWhere(doc, where) {\n  if (doc.$where == null) {\n    return;\n  }\n  for (const key of Object.keys(doc.$where)) {\n    where[key] = doc.$where[key];\n  }\n}\n\n/*!\n * ignore\n */\n\nModel.prototype.$__handleSave = function(options, callback) {\n  const saveOptions = {};\n\n  applyWriteConcern(this.$__schema, options);\n  if (typeof options.writeConcern !== 'undefined') {\n    saveOptions.writeConcern = {};\n    if ('w' in options.writeConcern) {\n      saveOptions.writeConcern.w = options.writeConcern.w;\n    }\n    if ('j' in options.writeConcern) {\n      saveOptions.writeConcern.j = options.writeConcern.j;\n    }\n    if ('wtimeout' in options.writeConcern) {\n      saveOptions.writeConcern.wtimeout = options.writeConcern.wtimeout;\n    }\n  } else {\n    if ('w' in options) {\n      saveOptions.w = options.w;\n    }\n    if ('j' in options) {\n      saveOptions.j = options.j;\n    }\n    if ('wtimeout' in options) {\n      saveOptions.wtimeout = options.wtimeout;\n    }\n  }\n  if ('checkKeys' in options) {\n    saveOptions.checkKeys = options.checkKeys;\n  }\n\n  const session = this.$session();\n  const asyncLocalStorage = this[modelDbSymbol].base.transactionAsyncLocalStorage?.getStore();\n  if (session != null) {\n    saveOptions.session = session;\n  } else if (!options.hasOwnProperty('session') && asyncLocalStorage?.session != null) {\n    // Only set session from asyncLocalStorage if `session` option wasn't originally passed in options\n    saveOptions.session = asyncLocalStorage.session;\n  }\n  if (this.$isNew) {\n    // send entire doc\n    const obj = this.toObject(saveToObjectOptions);\n    if ((obj || {})._id === void 0) {\n      // documents must have an _id else mongoose won't know\n      // what to update later if more changes are made. the user\n      // wouldn't know what _id was generated by mongodb either\n      // nor would the ObjectId generated by mongodb necessarily\n      // match the schema definition.\n      immediate(function() {\n        callback(new MongooseError('document must have an _id before saving'));\n      });\n      return;\n    }\n\n    this.$__version(true, obj);\n    this[modelCollectionSymbol].insertOne(obj, saveOptions).then(\n      ret => callback(null, ret),\n      err => {\n        _setIsNew(this, true);\n\n        callback(err, null);\n      }\n    );\n\n    this.$__reset();\n    _setIsNew(this, false);\n    // Make it possible to retry the insert\n    this.$__.inserting = true;\n    return;\n  }\n\n  // Make sure we don't treat it as a new object on error,\n  // since it already exists\n  this.$__.inserting = false;\n  const delta = this.$__delta();\n\n  if (options.pathsToSave) {\n    for (const key in delta[1]['$set']) {\n      if (options.pathsToSave.includes(key)) {\n        continue;\n      } else if (options.pathsToSave.some(pathToSave => key.slice(0, pathToSave.length) === pathToSave && key.charAt(pathToSave.length) === '.')) {\n        continue;\n      } else {\n        delete delta[1]['$set'][key];\n      }\n    }\n  }\n  if (delta) {\n    if (delta instanceof MongooseError) {\n      callback(delta);\n      return;\n    }\n\n    const where = this.$__where(delta[0]);\n    if (where instanceof MongooseError) {\n      callback(where);\n      return;\n    }\n\n    _applyCustomWhere(this, where);\n\n    const update = delta[1];\n    if (this.$__schema.options.minimize) {\n      for (const updateOp of Object.values(update)) {\n        if (updateOp == null) {\n          continue;\n        }\n        for (const key of Object.keys(updateOp)) {\n          if (updateOp[key] == null || typeof updateOp[key] !== 'object') {\n            continue;\n          }\n          if (!utils.isPOJO(updateOp[key])) {\n            continue;\n          }\n          minimize(updateOp[key]);\n          if (Object.keys(updateOp[key]).length === 0) {\n            delete updateOp[key];\n            update.$unset = update.$unset || {};\n            update.$unset[key] = 1;\n          }\n        }\n      }\n    }\n\n    this[modelCollectionSymbol].updateOne(where, update, saveOptions).then(\n      ret => {\n        ret.$where = where;\n        callback(null, ret);\n      },\n      err => {\n        this.$__undoReset();\n\n        callback(err);\n      }\n    );\n  } else {\n    handleEmptyUpdate.call(this);\n    return;\n  }\n\n  // store the modified paths before the document is reset\n  this.$__.modifiedPaths = this.modifiedPaths();\n  this.$__reset();\n\n  _setIsNew(this, false);\n\n  function handleEmptyUpdate() {\n    const optionsWithCustomValues = Object.assign({}, options, saveOptions);\n    const where = this.$__where();\n    const optimisticConcurrency = this.$__schema.options.optimisticConcurrency;\n    if (optimisticConcurrency && !Array.isArray(optimisticConcurrency)) {\n      const key = this.$__schema.options.versionKey;\n      const val = this.$__getValue(key);\n      if (val != null) {\n        where[key] = val;\n      }\n    }\n\n    applyReadConcern(this.$__schema, optionsWithCustomValues);\n    this.constructor.collection.findOne(where, optionsWithCustomValues)\n      .then(documentExists => {\n        const matchedCount = !documentExists ? 0 : 1;\n        callback(null, { $where: where, matchedCount });\n      })\n      .catch(callback);\n  }\n};\n\n/*!\n * ignore\n */\n\nModel.prototype.$__save = function(options, callback) {\n  this.$__handleSave(options, (error, result) => {\n    if (error) {\n      const hooks = this.$__schema.s.hooks;\n      return hooks.execPost('save:error', this, [this], { error: error }, (error) => {\n        callback(error, this);\n      });\n    }\n    let numAffected = 0;\n    const writeConcern = options != null ?\n      options.writeConcern != null ?\n        options.writeConcern.w :\n        options.w :\n      0;\n    if (writeConcern !== 0) {\n      // Skip checking if write succeeded if writeConcern is set to\n      // unacknowledged writes, because otherwise `numAffected` will always be 0\n      if (result != null) {\n        if (Array.isArray(result)) {\n          numAffected = result.length;\n        } else if (result.matchedCount != null) {\n          numAffected = result.matchedCount;\n        } else {\n          numAffected = result;\n        }\n      }\n\n      const versionBump = this.$__.version;\n      // was this an update that required a version bump?\n      if (versionBump && !this.$__.inserting) {\n        const doIncrement = VERSION_INC === (VERSION_INC & this.$__.version);\n        this.$__.version = undefined;\n        const key = this.$__schema.options.versionKey;\n        const version = this.$__getValue(key) || 0;\n        if (numAffected <= 0) {\n          // the update failed. pass an error back\n          this.$__undoReset();\n          const err = this.$__.$versionError ||\n            new VersionError(this, version, this.$__.modifiedPaths);\n          return callback(err);\n        }\n\n        // increment version if was successful\n        if (doIncrement) {\n          this.$__setValue(key, version + 1);\n        }\n      }\n      if (result != null && numAffected <= 0) {\n        this.$__undoReset();\n        error = new DocumentNotFoundError(result.$where,\n          this.constructor.modelName, numAffected, result);\n        const hooks = this.$__schema.s.hooks;\n        return hooks.execPost('save:error', this, [this], { error: error }, (error) => {\n          callback(error, this);\n        });\n      }\n    }\n    this.$__.saving = undefined;\n    this.$__.savedState = {};\n    this.$emit('save', this, numAffected);\n    this.constructor.emit('save', this, numAffected);\n    callback(null, this);\n  });\n};\n\n/*!\n * ignore\n */\n\nfunction generateVersionError(doc, modifiedPaths) {\n  const key = doc.$__schema.options.versionKey;\n  if (!key) {\n    return null;\n  }\n  const version = doc.$__getValue(key) || 0;\n  return new VersionError(doc, version, modifiedPaths);\n}\n\n/**\n * Saves this document by inserting a new document into the database if [document.isNew](https://mongoosejs.com/docs/api/document.html#Document.prototype.isNew) is `true`,\n * or sends an [updateOne](https://mongoosejs.com/docs/api/document.html#Document.prototype.updateOne()) operation with just the modified paths if `isNew` is `false`.\n *\n * #### Example:\n *\n *     product.sold = Date.now();\n *     product = await product.save();\n *\n * If save is successful, the returned promise will fulfill with the document\n * saved.\n *\n * #### Example:\n *\n *     const newProduct = await product.save();\n *     newProduct === product; // true\n *\n * @param {Object} [options] options optional options\n * @param {Session} [options.session=null] the [session](https://www.mongodb.com/docs/manual/reference/server-sessions/) associated with this save operation. If not specified, defaults to the [document's associated session](https://mongoosejs.com/docs/api/document.html#Document.prototype.session()).\n * @param {Object} [options.safe] (DEPRECATED) overrides [schema's safe option](https://mongoosejs.com/docs/guide.html#safe). Use the `w` option instead.\n * @param {Boolean} [options.validateBeforeSave] set to false to save without validating.\n * @param {Boolean} [options.validateModifiedOnly=false] if `true`, Mongoose will only validate modified paths, as opposed to modified paths and `required` paths.\n * @param {Number|String} [options.w] set the [write concern](https://www.mongodb.com/docs/manual/reference/write-concern/#w-option). Overrides the [schema-level `writeConcern` option](https://mongoosejs.com/docs/guide.html#writeConcern)\n * @param {Boolean} [options.j] set to true for MongoDB to wait until this `save()` has been [journaled before resolving the returned promise](https://www.mongodb.com/docs/manual/reference/write-concern/#j-option). Overrides the [schema-level `writeConcern` option](https://mongoosejs.com/docs/guide.html#writeConcern)\n * @param {Number} [options.wtimeout] sets a [timeout for the write concern](https://www.mongodb.com/docs/manual/reference/write-concern/#wtimeout). Overrides the [schema-level `writeConcern` option](https://mongoosejs.com/docs/guide.html#writeConcern).\n * @param {Boolean} [options.checkKeys=true] the MongoDB driver prevents you from saving keys that start with '$' or contain '.' by default. Set this option to `false` to skip that check. See [restrictions on field names](https://docs.mongodb.com/manual/reference/limits/#mongodb-limit-Restrictions-on-Field-Names)\n * @param {Boolean} [options.timestamps=true] if `false` and [timestamps](https://mongoosejs.com/docs/guide.html#timestamps) are enabled, skip timestamps for this `save()`.\n * @param {Array} [options.pathsToSave] An array of paths that tell mongoose to only validate and save the paths in `pathsToSave`.\n * @throws {DocumentNotFoundError} if this [save updates an existing document](https://mongoosejs.com/docs/api/document.html#Document.prototype.isNew) but the document doesn't exist in the database. For example, you will get this error if the document is [deleted between when you retrieved the document and when you saved it](documents.html#updating).\n * @return {Promise}\n * @api public\n * @see middleware https://mongoosejs.com/docs/middleware.html\n */\n\nModel.prototype.save = async function save(options) {\n  if (typeof options === 'function' || typeof arguments[1] === 'function') {\n    throw new MongooseError('Model.prototype.save() no longer accepts a callback');\n  }\n\n  let parallelSave;\n  this.$op = 'save';\n\n  if (this.$__.saving) {\n    parallelSave = new ParallelSaveError(this);\n  } else {\n    this.$__.saving = new ParallelSaveError(this);\n  }\n\n  options = new SaveOptions(options);\n  if (options.hasOwnProperty('session')) {\n    this.$session(options.session);\n  }\n  if (this.$__.timestamps != null) {\n    options.timestamps = this.$__.timestamps;\n  }\n  this.$__.$versionError = generateVersionError(this, this.modifiedPaths());\n\n  if (parallelSave) {\n    this.$__handleReject(parallelSave);\n    throw parallelSave;\n  }\n\n  this.$__.saveOptions = options;\n\n  await new Promise((resolve, reject) => {\n    this.$__save(options, error => {\n      this.$__.saving = null;\n      this.$__.saveOptions = null;\n      this.$__.$versionError = null;\n      this.$op = null;\n      if (error != null) {\n        this.$__handleReject(error);\n        return reject(error);\n      }\n\n      resolve();\n    });\n  });\n\n  return this;\n};\n\nModel.prototype.$save = Model.prototype.save;\n\n/**\n * Appends versioning to the where and update clauses.\n *\n * @api private\n * @method $__version\n * @memberOf Model\n * @instance\n */\n\nModel.prototype.$__version = function(where, delta) {\n  const key = this.$__schema.options.versionKey;\n  if (where === true) {\n    // this is an insert\n    if (key) {\n      setDottedPath(delta, key, 0);\n      this.$__setValue(key, 0);\n    }\n    return;\n  }\n\n  if (key === false) {\n    return;\n  }\n\n  // updates\n\n  // only apply versioning if our versionKey was selected. else\n  // there is no way to select the correct version. we could fail\n  // fast here and force them to include the versionKey but\n  // thats a bit intrusive. can we do this automatically?\n\n  if (!this.$__isSelected(key)) {\n    return;\n  }\n\n  // $push $addToSet don't need the where clause set\n  if (VERSION_WHERE === (VERSION_WHERE & this.$__.version)) {\n    const value = this.$__getValue(key);\n    if (value != null) where[key] = value;\n  }\n\n  if (VERSION_INC === (VERSION_INC & this.$__.version)) {\n    if (get(delta.$set, key, null) != null) {\n      // Version key is getting set, means we'll increment the doc's version\n      // after a successful save, so we should set the incremented version so\n      // future saves don't fail (gh-5779)\n      ++delta.$set[key];\n    } else {\n      delta.$inc = delta.$inc || {};\n      delta.$inc[key] = 1;\n    }\n  }\n};\n\n/**\n * Signal that we desire an increment of this documents version.\n *\n * #### Example:\n *\n *     const doc = await Model.findById(id);\n *     doc.increment();\n *     await doc.save();\n *\n * @see versionKeys https://mongoosejs.com/docs/guide.html#versionKey\n * @memberOf Model\n * @method increment\n * @api public\n */\n\nModel.prototype.increment = function increment() {\n  this.$__.version = VERSION_ALL;\n  return this;\n};\n\n/**\n * Returns a query object\n *\n * @api private\n * @method $__where\n * @memberOf Model\n * @instance\n */\n\nModel.prototype.$__where = function _where(where) {\n  where || (where = {});\n\n  if (!where._id) {\n    where._id = this._doc._id;\n  }\n\n  if (this._doc._id === void 0) {\n    return new MongooseError('No _id found on document!');\n  }\n\n  return where;\n};\n\n/**\n * Delete this document from the db.\n *\n * #### Example:\n *\n *     await product.deleteOne();\n *     await Product.findById(product._id); // null\n *\n * @return {Query} Query\n * @api public\n */\n\nModel.prototype.deleteOne = function deleteOne(options) {\n  if (typeof options === 'function' ||\n      typeof arguments[1] === 'function') {\n    throw new MongooseError('Model.prototype.deleteOne() no longer accepts a callback');\n  }\n\n  if (!options) {\n    options = {};\n  }\n\n  if (options.hasOwnProperty('session')) {\n    this.$session(options.session);\n  }\n\n  const self = this;\n  const where = this.$__where();\n  if (where instanceof Error) {\n    throw where;\n  }\n  const query = self.constructor.deleteOne(where, options);\n\n  if (this.$session() != null) {\n    if (!('session' in query.options)) {\n      query.options.session = this.$session();\n    }\n  }\n\n  query.pre(function queryPreDeleteOne(cb) {\n    self.constructor._middleware.execPre('deleteOne', self, [self], cb);\n  });\n  query.pre(function callSubdocPreHooks(cb) {\n    each(self.$getAllSubdocs(), (subdoc, cb) => {\n      subdoc.constructor._middleware.execPre('deleteOne', subdoc, [subdoc], cb);\n    }, cb);\n  });\n  query.pre(function skipIfAlreadyDeleted(cb) {\n    if (self.$__.isDeleted) {\n      return cb(Kareem.skipWrappedFunction());\n    }\n    return cb();\n  });\n  query.post(function callSubdocPostHooks(cb) {\n    each(self.$getAllSubdocs(), (subdoc, cb) => {\n      subdoc.constructor._middleware.execPost('deleteOne', subdoc, [subdoc], {}, cb);\n    }, cb);\n  });\n  query.post(function queryPostDeleteOne(cb) {\n    self.constructor._middleware.execPost('deleteOne', self, [self], {}, cb);\n  });\n\n  return query;\n};\n\n/**\n * Returns the model instance used to create this document if no `name` specified.\n * If `name` specified, returns the model with the given `name`.\n *\n * #### Example:\n *\n *     const doc = new Tank({});\n *     doc.$model() === Tank; // true\n *     await doc.$model('User').findById(id);\n *\n * @param {String} [name] model name\n * @method $model\n * @api public\n * @return {Model}\n */\n\nModel.prototype.$model = function $model(name) {\n  if (arguments.length === 0) {\n    return this.constructor;\n  }\n  return this[modelDbSymbol].model(name);\n};\n\n/**\n * Returns the model instance used to create this document if no `name` specified.\n * If `name` specified, returns the model with the given `name`.\n *\n * #### Example:\n *\n *     const doc = new Tank({});\n *     doc.$model() === Tank; // true\n *     await doc.$model('User').findById(id);\n *\n * @param {String} [name] model name\n * @method model\n * @api public\n * @return {Model}\n */\n\nModel.prototype.model = Model.prototype.$model;\n\n/**\n * Returns a document with `_id` only if at least one document exists in the database that matches\n * the given `filter`, and `null` otherwise.\n *\n * Under the hood, `MyModel.exists({ answer: 42 })` is equivalent to\n * `MyModel.findOne({ answer: 42 }).select({ _id: 1 }).lean()`\n *\n * #### Example:\n *\n *     await Character.deleteMany({});\n *     await Character.create({ name: 'Jean-Luc Picard' });\n *\n *     await Character.exists({ name: /picard/i }); // { _id: ... }\n *     await Character.exists({ name: /riker/i }); // null\n *\n * This function triggers the following middleware.\n *\n * - `findOne()`\n *\n * @param {Object} filter\n * @param {Object} [options] optional see [`Query.prototype.setOptions()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.setOptions())\n * @return {Query}\n */\n\nModel.exists = function exists(filter, options) {\n  _checkContext(this, 'exists');\n  if (typeof arguments[2] === 'function') {\n    throw new MongooseError('Model.exists() no longer accepts a callback');\n  }\n\n  const query = this.findOne(filter).\n    select({ _id: 1 }).\n    lean().\n    setOptions(options);\n\n  return query;\n};\n\n/**\n * Adds a discriminator type.\n *\n * #### Example:\n *\n *     function BaseSchema() {\n *       Schema.apply(this, arguments);\n *\n *       this.add({\n *         name: String,\n *         createdAt: Date\n *       });\n *     }\n *     util.inherits(BaseSchema, Schema);\n *\n *     const PersonSchema = new BaseSchema();\n *     const BossSchema = new BaseSchema({ department: String });\n *\n *     const Person = mongoose.model('Person', PersonSchema);\n *     const Boss = Person.discriminator('Boss', BossSchema);\n *     new Boss().__t; // \"Boss\". `__t` is the default `discriminatorKey`\n *\n *     const employeeSchema = new Schema({ boss: ObjectId });\n *     const Employee = Person.discriminator('Employee', employeeSchema, 'staff');\n *     new Employee().__t; // \"staff\" because of 3rd argument above\n *\n * @param {String} name discriminator model name\n * @param {Schema} schema discriminator model schema\n * @param {Object|String} [options] If string, same as `options.value`.\n * @param {String} [options.value] the string stored in the `discriminatorKey` property. If not specified, Mongoose uses the `name` parameter.\n * @param {Boolean} [options.clone=true] By default, `discriminator()` clones the given `schema`. Set to `false` to skip cloning.\n * @param {Boolean} [options.overwriteModels=false] by default, Mongoose does not allow you to define a discriminator with the same name as another discriminator. Set this to allow overwriting discriminators with the same name.\n * @param {Boolean} [options.mergeHooks=true] By default, Mongoose merges the base schema's hooks with the discriminator schema's hooks. Set this option to `false` to make Mongoose use the discriminator schema's hooks instead.\n * @param {Boolean} [options.mergePlugins=true] By default, Mongoose merges the base schema's plugins with the discriminator schema's plugins. Set this option to `false` to make Mongoose use the discriminator schema's plugins instead.\n * @return {Model} The newly created discriminator model\n * @api public\n */\n\nModel.discriminator = function(name, schema, options) {\n  let model;\n  if (typeof name === 'function') {\n    model = name;\n    name = utils.getFunctionName(model);\n    if (!(model.prototype instanceof Model)) {\n      throw new MongooseError('The provided class ' + name + ' must extend Model');\n    }\n  }\n\n  options = options || {};\n  const value = utils.isPOJO(options) ? options.value : options;\n  const clone = typeof options.clone === 'boolean' ? options.clone : true;\n  const mergePlugins = typeof options.mergePlugins === 'boolean' ? options.mergePlugins : true;\n  const overwriteModels = typeof options.overwriteModels === 'boolean' ? options.overwriteModels : false;\n\n  _checkContext(this, 'discriminator');\n\n  if (utils.isObject(schema) && !schema.instanceOfSchema) {\n    schema = new Schema(schema);\n  }\n  if (schema instanceof Schema && clone) {\n    schema = schema.clone();\n  }\n\n  schema = discriminator(this, name, schema, value, mergePlugins, options.mergeHooks, overwriteModels);\n  if (this.db.models[name] && !schema.options.overwriteModels && !overwriteModels) {\n    throw new OverwriteModelError(name);\n  }\n\n  schema.$isRootDiscriminator = true;\n  schema.$globalPluginsApplied = true;\n\n  model = this.db.model(model || name, schema, this.$__collection.name);\n  this.discriminators[name] = model;\n  const d = this.discriminators[name];\n  Object.setPrototypeOf(d.prototype, this.prototype);\n  Object.defineProperty(d, 'baseModelName', {\n    value: this.modelName,\n    configurable: true,\n    writable: false\n  });\n\n  // apply methods and statics\n  applyMethods(d, schema);\n  applyStatics(d, schema);\n\n  if (this[subclassedSymbol] != null) {\n    for (const submodel of this[subclassedSymbol]) {\n      submodel.discriminators = submodel.discriminators || {};\n      submodel.discriminators[name] =\n        model.__subclass(model.db, schema, submodel.collection.name);\n    }\n  }\n\n  return d;\n};\n\n/**\n * Make sure `this` is a model\n * @api private\n */\n\nfunction _checkContext(ctx, fnName) {\n  // Check context, because it is easy to mistakenly type\n  // `new Model.discriminator()` and get an incomprehensible error\n  if (ctx == null || ctx === global) {\n    throw new MongooseError('`Model.' + fnName + '()` cannot run without a ' +\n      'model as `this`. Make sure you are calling `MyModel.' + fnName + '()` ' +\n      'where `MyModel` is a Mongoose model.');\n  } else if (ctx[modelSymbol] == null) {\n    throw new MongooseError('`Model.' + fnName + '()` cannot run without a ' +\n      'model as `this`. Make sure you are not calling ' +\n      '`new Model.' + fnName + '()`');\n  }\n}\n\n// Model (class) features\n\n/*!\n * Give the constructor the ability to emit events.\n */\n\nfor (const i in EventEmitter.prototype) {\n  Model[i] = EventEmitter.prototype[i];\n}\n\n/**\n * This function is responsible for initializing the underlying connection in MongoDB based on schema options.\n * This function performs the following operations:\n *\n * - `createCollection()` unless [`autoCreate`](https://mongoosejs.com/docs/guide.html#autoCreate) option is turned off\n * - `ensureIndexes()` unless [`autoIndex`](https://mongoosejs.com/docs/guide.html#autoIndex) option is turned off\n * - `createSearchIndex()` on all schema search indexes if `autoSearchIndex` is enabled.\n *\n * Mongoose calls this function automatically when a model is a created using\n * [`mongoose.model()`](https://mongoosejs.com/docs/api/mongoose.html#Mongoose.prototype.model()) or\n * [`connection.model()`](https://mongoosejs.com/docs/api/connection.html#Connection.prototype.model()), so you\n * don't need to call `init()` to trigger index builds.\n *\n * However, you _may_ need to call `init()`  to get back a promise that will resolve when your indexes are finished.\n * Calling `await Model.init()` is helpful if you need to wait for indexes to build before continuing.\n * For example, if you want to wait for unique indexes to build before continuing with a test case.\n *\n * #### Example:\n *\n *     const eventSchema = new Schema({ thing: { type: 'string', unique: true } })\n *     // This calls `Event.init()` implicitly, so you don't need to call\n *     // `Event.init()` on your own.\n *     const Event = mongoose.model('Event', eventSchema);\n *\n *     await Event.init();\n *     console.log('Indexes are done building!');\n *\n * @api public\n * @returns {Promise}\n */\n\nModel.init = function init() {\n  _checkContext(this, 'init');\n  if (typeof arguments[0] === 'function') {\n    throw new MongooseError('Model.init() no longer accepts a callback');\n  }\n\n  this.schema.emit('init', this);\n\n  if (this.$init != null) {\n    return this.$init;\n  }\n\n  const conn = this.db;\n  const _ensureIndexes = async() => {\n    const autoIndex = utils.getOption(\n      'autoIndex',\n      this.schema.options,\n      conn.config,\n      conn.base.options\n    );\n    if (!autoIndex) {\n      return;\n    }\n    return await this.ensureIndexes({ _automatic: true });\n  };\n  const _createSearchIndexes = async() => {\n    const autoSearchIndex = utils.getOption(\n      'autoSearchIndex',\n      this.schema.options,\n      conn.config,\n      conn.base.options\n    );\n    if (!autoSearchIndex) {\n      return;\n    }\n\n    const results = [];\n    for (const searchIndex of this.schema._searchIndexes) {\n      results.push(await this.createSearchIndex(searchIndex));\n    }\n    return results;\n  };\n  const _createCollection = async() => {\n    if ((conn.readyState === STATES.connecting || conn.readyState === STATES.disconnected) && conn._shouldBufferCommands()) {\n      await new Promise(resolve => {\n        conn._queue.push({ fn: resolve });\n      });\n    }\n    const autoCreate = utils.getOption(\n      'autoCreate',\n      this.schema.options,\n      conn.config,\n      conn.base.options\n    );\n    if (!autoCreate) {\n      return;\n    }\n    return await this.createCollection();\n  };\n\n  this.$init = _createCollection().\n    then(() => _ensureIndexes()).\n    then(() => _createSearchIndexes());\n\n  const _catch = this.$init.catch;\n  const _this = this;\n  this.$init.catch = function() {\n    _this.$caught = true;\n    return _catch.apply(_this.$init, arguments);\n  };\n\n  return this.$init;\n};\n\n\n/**\n * Create the collection for this model. By default, if no indexes are specified,\n * mongoose will not create the collection for the model until any documents are\n * created. Use this method to create the collection explicitly.\n *\n * Note 1: You may need to call this before starting a transaction\n * See https://www.mongodb.com/docs/manual/core/transactions/#transactions-and-operations\n *\n * Note 2: You don't have to call this if your schema contains index or unique field.\n * In that case, just use `Model.init()`\n *\n * #### Example:\n *\n *     const userSchema = new Schema({ name: String })\n *     const User = mongoose.model('User', userSchema);\n *\n *     User.createCollection().then(function(collection) {\n *       console.log('Collection is created!');\n *     });\n *\n * @api public\n * @param {Object} [options] see [MongoDB driver docs](https://mongodb.github.io/node-mongodb-native/4.9/classes/Db.html#createCollection)\n * @returns {Promise}\n */\n\nModel.createCollection = async function createCollection(options) {\n  _checkContext(this, 'createCollection');\n  if (typeof arguments[0] === 'function' || typeof arguments[1] === 'function') {\n    throw new MongooseError('Model.createCollection() no longer accepts a callback');\n  }\n\n  const shouldSkip = await new Promise((resolve, reject) => {\n    this.hooks.execPre('createCollection', this, [options], (err) => {\n      if (err != null) {\n        if (err instanceof Kareem.skipWrappedFunction) {\n          return resolve(true);\n        }\n        return reject(err);\n      }\n      resolve();\n    });\n  });\n\n  const collectionOptions = this &&\n    this.schema &&\n    this.schema.options &&\n    this.schema.options.collectionOptions;\n  if (collectionOptions != null) {\n    options = Object.assign({}, collectionOptions, options);\n  }\n\n  const schemaCollation = this &&\n    this.schema &&\n    this.schema.options &&\n    this.schema.options.collation;\n  if (schemaCollation != null) {\n    options = Object.assign({ collation: schemaCollation }, options);\n  }\n  const capped = this &&\n    this.schema &&\n    this.schema.options &&\n    this.schema.options.capped;\n  if (capped != null) {\n    if (typeof capped === 'number') {\n      options = Object.assign({ capped: true, size: capped }, options);\n    } else if (typeof capped === 'object') {\n      options = Object.assign({ capped: true }, capped, options);\n    }\n  }\n  const timeseries = this &&\n    this.schema &&\n    this.schema.options &&\n    this.schema.options.timeseries;\n  if (timeseries != null) {\n    options = Object.assign({ timeseries }, options);\n    if (options.expireAfterSeconds != null) {\n      // do nothing\n    } else if (options.expires != null) {\n      utils.expires(options);\n    } else if (this.schema.options.expireAfterSeconds != null) {\n      options.expireAfterSeconds = this.schema.options.expireAfterSeconds;\n    } else if (this.schema.options.expires != null) {\n      options.expires = this.schema.options.expires;\n      utils.expires(options);\n    }\n  }\n\n  const clusteredIndex = this &&\n    this.schema &&\n    this.schema.options &&\n    this.schema.options.clusteredIndex;\n  if (clusteredIndex != null) {\n    options = Object.assign({ clusteredIndex: { ...clusteredIndex, unique: true } }, options);\n  }\n\n  try {\n    if (!shouldSkip) {\n      await this.db.createCollection(this.$__collection.collectionName, options);\n    }\n  } catch (err) {\n    if (err != null && (err.name !== 'MongoServerError' || err.code !== 48)) {\n      await new Promise((resolve, reject) => {\n        const _opts = { error: err };\n        this.hooks.execPost('createCollection', this, [null], _opts, (err) => {\n          if (err != null) {\n            return reject(err);\n          }\n          resolve();\n        });\n      });\n    }\n  }\n\n  await new Promise((resolve, reject) => {\n    this.hooks.execPost('createCollection', this, [this.$__collection], (err) => {\n      if (err != null) {\n        return reject(err);\n      }\n      resolve();\n    });\n  });\n\n  return this.$__collection;\n};\n\n/**\n * Makes the indexes in MongoDB match the indexes defined in this model's\n * schema. This function will drop any indexes that are not defined in\n * the model's schema except the `_id` index, and build any indexes that\n * are in your schema but not in MongoDB.\n *\n * See the [introductory blog post](https://thecodebarbarian.com/whats-new-in-mongoose-5-2-syncindexes)\n * for more information.\n *\n * #### Example:\n *\n *     const schema = new Schema({ name: { type: String, unique: true } });\n *     const Customer = mongoose.model('Customer', schema);\n *     await Customer.collection.createIndex({ age: 1 }); // Index is not in schema\n *     // Will drop the 'age' index and create an index on `name`\n *     await Customer.syncIndexes();\n *\n * You should be careful about running `syncIndexes()` on production applications under heavy load,\n * because index builds are expensive operations, and unexpected index drops can lead to degraded\n * performance. Before running `syncIndexes()`, you can use the [`diffIndexes()` function](#Model.diffIndexes())\n * to check what indexes `syncIndexes()` will drop and create.\n *\n * #### Example:\n *\n *     const { toDrop, toCreate } = await Model.diffIndexes();\n *     toDrop; // Array of strings containing names of indexes that `syncIndexes()` will drop\n *     toCreate; // Array of strings containing names of indexes that `syncIndexes()` will create\n *\n * @param {Object} [options] options to pass to `ensureIndexes()`\n * @param {Boolean} [options.background=null] if specified, overrides each index's `background` property\n * @return {Promise}\n * @api public\n */\n\nModel.syncIndexes = async function syncIndexes(options) {\n  _checkContext(this, 'syncIndexes');\n  if (typeof arguments[0] === 'function' || typeof arguments[1] === 'function') {\n    throw new MongooseError('Model.syncIndexes() no longer accepts a callback');\n  }\n\n  const model = this;\n\n  try {\n    await model.createCollection();\n  } catch (err) {\n    if (err != null && (err.name !== 'MongoServerError' || err.code !== 48)) {\n      throw err;\n    }\n  }\n\n  const diffIndexesResult = await model.diffIndexes();\n  const dropped = await model.cleanIndexes({ ...options, toDrop: diffIndexesResult.toDrop });\n  await model.createIndexes({ ...options, toCreate: diffIndexesResult.toCreate });\n\n  return dropped;\n};\n\n/**\n * Create an [Atlas search index](https://www.mongodb.com/docs/atlas/atlas-search/create-index/).\n * This function only works when connected to MongoDB Atlas.\n *\n * #### Example:\n *\n *     const schema = new Schema({ name: { type: String, unique: true } });\n *     const Customer = mongoose.model('Customer', schema);\n *     await Customer.createSearchIndex({ name: 'test', definition: { mappings: { dynamic: true } } });\n *\n * @param {Object} description index options, including `name` and `definition`\n * @param {String} description.name\n * @param {Object} description.definition\n * @return {Promise}\n * @api public\n */\n\nModel.createSearchIndex = async function createSearchIndex(description) {\n  _checkContext(this, 'createSearchIndex');\n\n  return await this.$__collection.createSearchIndex(description);\n};\n\n/**\n * Update an existing [Atlas search index](https://www.mongodb.com/docs/atlas/atlas-search/create-index/).\n * This function only works when connected to MongoDB Atlas.\n *\n * #### Example:\n *\n *     const schema = new Schema({ name: { type: String, unique: true } });\n *     const Customer = mongoose.model('Customer', schema);\n *     await Customer.updateSearchIndex('test', { mappings: { dynamic: true } });\n *\n * @param {String} name\n * @param {Object} definition\n * @return {Promise}\n * @api public\n */\n\nModel.updateSearchIndex = async function updateSearchIndex(name, definition) {\n  _checkContext(this, 'updateSearchIndex');\n\n  return await this.$__collection.updateSearchIndex(name, definition);\n};\n\n/**\n * Delete an existing [Atlas search index](https://www.mongodb.com/docs/atlas/atlas-search/create-index/) by name.\n * This function only works when connected to MongoDB Atlas.\n *\n * #### Example:\n *\n *     const schema = new Schema({ name: { type: String, unique: true } });\n *     const Customer = mongoose.model('Customer', schema);\n *     await Customer.dropSearchIndex('test');\n *\n * @param {String} name\n * @return {Promise}\n * @api public\n */\n\nModel.dropSearchIndex = async function dropSearchIndex(name) {\n  _checkContext(this, 'dropSearchIndex');\n\n  return await this.$__collection.dropSearchIndex(name);\n};\n\n/**\n * List all [Atlas search indexes](https://www.mongodb.com/docs/atlas/atlas-search/create-index/) on this model's collection.\n * This function only works when connected to MongoDB Atlas.\n *\n * #### Example:\n *\n *     const schema = new Schema({ name: { type: String, unique: true } });\n *     const Customer = mongoose.model('Customer', schema);\n *\n *     await Customer.createSearchIndex({ name: 'test', definition: { mappings: { dynamic: true } } });\n *     const res = await Customer.listSearchIndexes(); // Includes `[{ name: 'test' }]`\n *\n * @param {Object} [options]\n * @return {Promise<Array>}\n * @api public\n */\n\nModel.listSearchIndexes = async function listSearchIndexes(options) {\n  _checkContext(this, 'listSearchIndexes');\n\n  const cursor = await this.$__collection.listSearchIndexes(options);\n\n  return await cursor.toArray();\n};\n\n/**\n * Does a dry-run of `Model.syncIndexes()`, returning the indexes that `syncIndexes()` would drop and create if you were to run `syncIndexes()`.\n *\n * #### Example:\n *\n *     const { toDrop, toCreate } = await Model.diffIndexes();\n *     toDrop; // Array of strings containing names of indexes that `syncIndexes()` will drop\n *     toCreate; // Array of strings containing names of indexes that `syncIndexes()` will create\n *\n * @param {Object} [options]\n * @return {Promise<Object>} contains the indexes that would be dropped in MongoDB and indexes that would be created in MongoDB as `{ toDrop: string[], toCreate: string[] }`.\n */\n\nModel.diffIndexes = async function diffIndexes() {\n  if (typeof arguments[0] === 'function' || typeof arguments[1] === 'function') {\n    throw new MongooseError('Model.syncIndexes() no longer accepts a callback');\n  }\n\n  const model = this;\n\n  let dbIndexes = await model.listIndexes().catch(err => {\n    if (err.codeName == 'NamespaceNotFound') {\n      return undefined;\n    }\n    throw err;\n  });\n  if (dbIndexes === undefined) {\n    dbIndexes = [];\n  }\n  dbIndexes = getRelatedDBIndexes(model, dbIndexes);\n\n  const schema = model.schema;\n  const schemaIndexes = getRelatedSchemaIndexes(model, schema.indexes());\n\n  const toDrop = getIndexesToDrop(schema, schemaIndexes, dbIndexes);\n  const toCreate = getIndexesToCreate(schema, schemaIndexes, dbIndexes, toDrop);\n\n  return { toDrop, toCreate };\n};\n\nfunction getIndexesToCreate(schema, schemaIndexes, dbIndexes, toDrop) {\n  const toCreate = [];\n\n  for (const [schemaIndexKeysObject, schemaIndexOptions] of schemaIndexes) {\n    let found = false;\n\n    const options = decorateDiscriminatorIndexOptions(schema, clone(schemaIndexOptions));\n\n    for (const index of dbIndexes) {\n      if (isDefaultIdIndex(index)) {\n        continue;\n      }\n      if (\n        isIndexEqual(schemaIndexKeysObject, options, index) &&\n        !toDrop.includes(index.name)\n      ) {\n        found = true;\n        break;\n      }\n    }\n\n    if (!found) {\n      toCreate.push(schemaIndexKeysObject);\n    }\n  }\n\n  return toCreate;\n}\n\nfunction getIndexesToDrop(schema, schemaIndexes, dbIndexes) {\n  const toDrop = [];\n\n  for (const dbIndex of dbIndexes) {\n    let found = false;\n    // Never try to drop `_id` index, MongoDB server doesn't allow it\n    if (isDefaultIdIndex(dbIndex)) {\n      continue;\n    }\n\n    for (const [schemaIndexKeysObject, schemaIndexOptions] of schemaIndexes) {\n      const options = decorateDiscriminatorIndexOptions(schema, clone(schemaIndexOptions));\n      applySchemaCollation(schemaIndexKeysObject, options, schema.options);\n\n      if (isIndexEqual(schemaIndexKeysObject, options, dbIndex)) {\n        found = true;\n        break;\n      }\n    }\n\n    if (!found) {\n      toDrop.push(dbIndex.name);\n    }\n  }\n\n  return toDrop;\n}\n/**\n * Deletes all indexes that aren't defined in this model's schema. Used by\n * `syncIndexes()`.\n *\n * The returned promise resolves to a list of the dropped indexes' names as an array\n *\n * @param {Function} [callback] optional callback\n * @return {Promise|undefined} Returns `undefined` if callback is specified, returns a promise if no callback.\n * @api public\n */\n\nModel.cleanIndexes = async function cleanIndexes(options) {\n  _checkContext(this, 'cleanIndexes');\n  if (typeof arguments[0] === 'function' || typeof arguments[1] === 'function') {\n    throw new MongooseError('Model.cleanIndexes() no longer accepts a callback');\n  }\n  const model = this;\n\n  const collection = model.$__collection;\n\n  if (Array.isArray(options && options.toDrop)) {\n    const res = await _dropIndexes(options.toDrop, collection);\n    return res;\n  }\n\n  const res = await model.diffIndexes();\n  return await _dropIndexes(res.toDrop, collection);\n};\n\nasync function _dropIndexes(toDrop, collection) {\n  if (toDrop.length === 0) {\n    return [];\n  }\n\n  await Promise.all(toDrop.map(indexName => collection.dropIndex(indexName)));\n  return toDrop;\n}\n\n/**\n * Lists the indexes currently defined in MongoDB. This may or may not be\n * the same as the indexes defined in your schema depending on whether you\n * use the [`autoIndex` option](https://mongoosejs.com/docs/guide.html#autoIndex) and if you\n * build indexes manually.\n *\n * @return {Promise}\n * @api public\n */\n\nModel.listIndexes = async function listIndexes() {\n  _checkContext(this, 'listIndexes');\n  if (typeof arguments[0] === 'function') {\n    throw new MongooseError('Model.listIndexes() no longer accepts a callback');\n  }\n\n  if (this.$__collection.buffer) {\n    await new Promise(resolve => {\n      this.$__collection.addQueue(resolve);\n    });\n  }\n\n  return this.$__collection.listIndexes().toArray();\n};\n\n/**\n * Sends `createIndex` commands to mongo for each index declared in the schema.\n * The `createIndex` commands are sent in series.\n *\n * #### Example:\n *\n *     await Event.ensureIndexes();\n *\n * After completion, an `index` event is emitted on this `Model` passing an error if one occurred.\n *\n * #### Example:\n *\n *     const eventSchema = new Schema({ thing: { type: 'string', unique: true } })\n *     const Event = mongoose.model('Event', eventSchema);\n *\n *     Event.on('index', function (err) {\n *       if (err) console.error(err); // error occurred during index creation\n *     });\n *\n * _NOTE: It is not recommended that you run this in production. Index creation may impact database performance depending on your load. Use with caution._\n *\n * @param {Object} [options] internal options\n * @return {Promise}\n * @api public\n */\n\nModel.ensureIndexes = async function ensureIndexes(options) {\n  _checkContext(this, 'ensureIndexes');\n  if (typeof arguments[0] === 'function' || typeof arguments[1] === 'function') {\n    throw new MongooseError('Model.ensureIndexes() no longer accepts a callback');\n  }\n\n  await new Promise((resolve, reject) => {\n    _ensureIndexes(this, options, (err) => {\n      if (err != null) {\n        return reject(err);\n      }\n      resolve();\n    });\n  });\n};\n\n/**\n * Similar to `ensureIndexes()`, except for it uses the [`createIndex`](https://mongodb.github.io/node-mongodb-native/4.9/classes/Db.html#createIndex)\n * function.\n *\n * @param {Object} [options] internal options\n * @return {Promise}\n * @api public\n */\n\nModel.createIndexes = async function createIndexes(options) {\n  _checkContext(this, 'createIndexes');\n\n  if (typeof arguments[0] === 'function' || typeof arguments[1] === 'function') {\n    throw new MongooseError('Model.createIndexes() no longer accepts a callback');\n  }\n\n  return this.ensureIndexes(options);\n};\n\n\n/*!\n * ignore\n */\n\nfunction _ensureIndexes(model, options, callback) {\n  const indexes = model.schema.indexes();\n  let indexError;\n\n  options = options || {};\n  const done = function(err) {\n    if (err && !model.$caught) {\n      model.emit('error', err);\n    }\n    model.emit('index', err || indexError);\n    callback && callback(err || indexError);\n  };\n\n  for (const index of indexes) {\n    if (isDefaultIdIndex(index)) {\n      utils.warn('mongoose: Cannot specify a custom index on `_id` for ' +\n        'model name \"' + model.modelName + '\", ' +\n        'MongoDB does not allow overwriting the default `_id` index. See ' +\n        'https://bit.ly/mongodb-id-index');\n    }\n  }\n\n  if (!indexes.length) {\n    immediate(function() {\n      done();\n    });\n    return;\n  }\n  // Indexes are created one-by-one to support how MongoDB < 2.4 deals\n  // with background indexes.\n\n  const indexSingleDone = function(err, fields, options, name) {\n    model.emit('index-single-done', err, fields, options, name);\n  };\n  const indexSingleStart = function(fields, options) {\n    model.emit('index-single-start', fields, options);\n  };\n\n  const baseSchema = model.schema._baseSchema;\n  const baseSchemaIndexes = baseSchema ? baseSchema.indexes() : [];\n\n  immediate(function() {\n    // If buffering is off, do this manually.\n    if (options._automatic && !model.collection.collection) {\n      model.collection.addQueue(create, []);\n    } else {\n      create();\n    }\n  });\n\n\n  function create() {\n    if (options._automatic) {\n      if (model.schema.options.autoIndex === false ||\n          (model.schema.options.autoIndex == null && model.db.config.autoIndex === false)) {\n        return done();\n      }\n    }\n\n    const index = indexes.shift();\n    if (!index) {\n      return done();\n    }\n    if (options._automatic && index[1]._autoIndex === false) {\n      return create();\n    }\n\n    if (baseSchemaIndexes.find(i => utils.deepEqual(i, index))) {\n      return create();\n    }\n\n    const indexFields = clone(index[0]);\n    const indexOptions = clone(index[1]);\n\n    delete indexOptions._autoIndex;\n    decorateDiscriminatorIndexOptions(model.schema, indexOptions);\n    applyWriteConcern(model.schema, indexOptions);\n    applySchemaCollation(indexFields, indexOptions, model.schema.options);\n\n    indexSingleStart(indexFields, options);\n\n    if ('background' in options) {\n      indexOptions.background = options.background;\n    }\n\n    if ('toCreate' in options) {\n      if (options.toCreate.length === 0) {\n        return done();\n      }\n    }\n\n    model.collection.createIndex(indexFields, indexOptions).then(\n      name => {\n        indexSingleDone(null, indexFields, indexOptions, name);\n        create();\n      },\n      err => {\n        if (!indexError) {\n          indexError = err;\n        }\n        if (!model.$caught) {\n          model.emit('error', err);\n        }\n\n        indexSingleDone(err, indexFields, indexOptions);\n        create();\n      }\n    );\n  }\n}\n\n/**\n * Schema the model uses.\n *\n * @property schema\n * @static\n * @api public\n * @memberOf Model\n */\n\nModel.schema;\n\n/**\n * Connection instance the model uses.\n *\n * @property db\n * @static\n * @api public\n * @memberOf Model\n */\n\nModel.db;\n\n/**\n * Collection the model uses.\n *\n * @property collection\n * @api public\n * @memberOf Model\n */\n\nModel.collection;\n\n/**\n * Internal collection the model uses.\n *\n * @property collection\n * @api private\n * @memberOf Model\n */\nModel.$__collection;\n\n/**\n * Base Mongoose instance the model uses.\n *\n * @property base\n * @api public\n * @memberOf Model\n */\n\nModel.base;\n\n/**\n * Registered discriminators for this model.\n *\n * @property discriminators\n * @api public\n * @memberOf Model\n */\n\nModel.discriminators;\n\n/**\n * Translate any aliases fields/conditions so the final query or document object is pure\n *\n * #### Example:\n *\n *     await Character.find(Character.translateAliases({\n *        '': 'Eddard Stark' // Alias for 'name'\n *     });\n *\n * By default, `translateAliases()` overwrites raw fields with aliased fields.\n * So if `n` is an alias for `name`, `{ n: 'alias', name: 'raw' }` will resolve to `{ name: 'alias' }`.\n * However, you can set the `errorOnDuplicates` option to throw an error if there are potentially conflicting paths.\n * The `translateAliases` option for queries uses `errorOnDuplicates`.\n *\n * #### Note:\n *\n * Only translate arguments of object type anything else is returned raw\n *\n * @param {Object} fields fields/conditions that may contain aliased keys\n * @param {Boolean} [errorOnDuplicates] if true, throw an error if there's both a key and an alias for that key in `fields`\n * @return {Object} the translated 'pure' fields/conditions\n */\nModel.translateAliases = function translateAliases(fields, errorOnDuplicates) {\n  _checkContext(this, 'translateAliases');\n\n  const translate = (key, value) => {\n    let alias;\n    const translated = [];\n    const fieldKeys = key.split('.');\n    let currentSchema = this.schema;\n    for (const i in fieldKeys) {\n      const name = fieldKeys[i];\n      if (currentSchema && currentSchema.aliases[name]) {\n        alias = currentSchema.aliases[name];\n        if (errorOnDuplicates && alias in fields) {\n          throw new MongooseError(`Provided object has both field \"${name}\" and its alias \"${alias}\"`);\n        }\n        // Alias found,\n        translated.push(alias);\n      } else {\n        alias = name;\n        // Alias not found, so treat as un-aliased key\n        translated.push(name);\n      }\n\n      // Check if aliased path is a schema\n      if (currentSchema && currentSchema.paths[alias]) {\n        currentSchema = currentSchema.paths[alias].schema;\n      }\n      else\n        currentSchema = null;\n    }\n\n    const translatedKey = translated.join('.');\n    if (fields instanceof Map)\n      fields.set(translatedKey, value);\n    else\n      fields[translatedKey] = value;\n\n    if (translatedKey !== key) {\n      // We'll be using the translated key instead\n      if (fields instanceof Map) {\n        // Delete from map\n        fields.delete(key);\n      } else {\n        // Delete from object\n        delete fields[key]; // We'll be using the translated key instead\n      }\n    }\n    return fields;\n  };\n\n  if (typeof fields === 'object') {\n    // Fields is an object (query conditions or document fields)\n    if (fields instanceof Map) {\n      // A Map was supplied\n      for (const field of new Map(fields)) {\n        fields = translate(field[0], field[1]);\n      }\n    } else {\n      // Infer a regular object was supplied\n      for (const key of Object.keys(fields)) {\n        fields = translate(key, fields[key]);\n        if (key[0] === '$') {\n          if (Array.isArray(fields[key])) {\n            for (const i in fields[key]) {\n              // Recursively translate nested queries\n              fields[key][i] = this.translateAliases(fields[key][i]);\n            }\n          } else {\n            this.translateAliases(fields[key]);\n          }\n        }\n      }\n    }\n\n    return fields;\n  } else {\n    // Don't know typeof fields\n    return fields;\n  }\n};\n\n/**\n * Deletes the first document that matches `conditions` from the collection.\n * It returns an object with the property `deletedCount` indicating how many documents were deleted.\n * Behaves like `remove()`, but deletes at most one document regardless of the\n * `single` option.\n *\n * #### Example:\n *\n *     await Character.deleteOne({ name: 'Eddard Stark' }); // returns {deletedCount: 1}\n *\n * #### Note:\n *\n * This function triggers `deleteOne` query hooks. Read the\n * [middleware docs](https://mongoosejs.com/docs/middleware.html#naming) to learn more.\n *\n * @param {Object} conditions\n * @param {Object} [options] optional see [`Query.prototype.setOptions()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.setOptions())\n * @param {Boolean} [options.translateAliases=null] If set to `true`, translates any schema-defined aliases in `filter`, `projection`, `update`, and `distinct`. Throws an error if there are any conflicts where both alias and raw property are defined on the same object.\n * @return {Query}\n * @api public\n */\n\nModel.deleteOne = function deleteOne(conditions, options) {\n  _checkContext(this, 'deleteOne');\n\n  if (typeof arguments[0] === 'function' || typeof arguments[1] === 'function' || typeof arguments[2] === 'function') {\n    throw new MongooseError('Model.prototype.deleteOne() no longer accepts a callback');\n  }\n\n  const mq = new this.Query({}, {}, this, this.$__collection);\n  mq.setOptions(options);\n\n  return mq.deleteOne(conditions);\n};\n\n/**\n * Deletes all of the documents that match `conditions` from the collection.\n * It returns an object with the property `deletedCount` containing the number of documents deleted.\n * Behaves like `remove()`, but deletes all documents that match `conditions`\n * regardless of the `single` option.\n *\n * #### Example:\n *\n *     await Character.deleteMany({ name: /Stark/, age: { $gte: 18 } }); // returns {deletedCount: x} where x is the number of documents deleted.\n *\n * #### Note:\n *\n * This function triggers `deleteMany` query hooks. Read the\n * [middleware docs](https://mongoosejs.com/docs/middleware.html#naming) to learn more.\n *\n * @param {Object} conditions\n * @param {Object} [options] optional see [`Query.prototype.setOptions()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.setOptions())\n * @param {Boolean} [options.translateAliases=null] If set to `true`, translates any schema-defined aliases in `filter`, `projection`, `update`, and `distinct`. Throws an error if there are any conflicts where both alias and raw property are defined on the same object.\n * @return {Query}\n * @api public\n */\n\nModel.deleteMany = function deleteMany(conditions, options) {\n  _checkContext(this, 'deleteMany');\n\n  if (typeof arguments[0] === 'function' || typeof arguments[1] === 'function' || typeof arguments[2] === 'function') {\n    throw new MongooseError('Model.deleteMany() no longer accepts a callback');\n  }\n\n  const mq = new this.Query({}, {}, this, this.$__collection);\n  mq.setOptions(options);\n\n  return mq.deleteMany(conditions);\n};\n\n/**\n * Finds documents.\n *\n * Mongoose casts the `filter` to match the model's schema before the command is sent.\n * See our [query casting tutorial](https://mongoosejs.com/docs/tutorials/query_casting.html) for\n * more information on how Mongoose casts `filter`.\n *\n * #### Example:\n *\n *     // find all documents\n *     await MyModel.find({});\n *\n *     // find all documents named john and at least 18\n *     await MyModel.find({ name: 'john', age: { $gte: 18 } }).exec();\n *\n *     // executes, name LIKE john and only selecting the \"name\" and \"friends\" fields\n *     await MyModel.find({ name: /john/i }, 'name friends').exec();\n *\n *     // passing options\n *     await MyModel.find({ name: /john/i }, null, { skip: 10 }).exec();\n *\n * @param {Object|ObjectId} filter\n * @param {Object|String|String[]} [projection] optional fields to return, see [`Query.prototype.select()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.select())\n * @param {Object} [options] optional see [`Query.prototype.setOptions()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.setOptions())\n * @param {Boolean} [options.translateAliases=null] If set to `true`, translates any schema-defined aliases in `filter`, `projection`, `update`, and `distinct`. Throws an error if there are any conflicts where both alias and raw property are defined on the same object.\n * @return {Query}\n * @see field selection https://mongoosejs.com/docs/api/query.html#Query.prototype.select()\n * @see query casting https://mongoosejs.com/docs/tutorials/query_casting.html\n * @api public\n */\n\nModel.find = function find(conditions, projection, options) {\n  _checkContext(this, 'find');\n  if (typeof arguments[0] === 'function' || typeof arguments[1] === 'function' || typeof arguments[2] === 'function' || typeof arguments[3] === 'function') {\n    throw new MongooseError('Model.find() no longer accepts a callback');\n  }\n\n  const mq = new this.Query({}, {}, this, this.$__collection);\n  mq.select(projection);\n  mq.setOptions(options);\n\n  return mq.find(conditions);\n};\n\n/**\n * Finds a single document by its _id field. `findById(id)` is almost*\n * equivalent to `findOne({ _id: id })`. If you want to query by a document's\n * `_id`, use `findById()` instead of `findOne()`.\n *\n * The `id` is cast based on the Schema before sending the command.\n *\n * This function triggers the following middleware.\n *\n * - `findOne()`\n *\n * \\* Except for how it treats `undefined`. If you use `findOne()`, you'll see\n * that `findOne(undefined)` and `findOne({ _id: undefined })` are equivalent\n * to `findOne({})` and return arbitrary documents. However, mongoose\n * translates `findById(undefined)` into `findOne({ _id: null })`.\n *\n * #### Example:\n *\n *     // Find the adventure with the given `id`, or `null` if not found\n *     await Adventure.findById(id).exec();\n *\n *     // select only the adventures name and length\n *     await Adventure.findById(id, 'name length').exec();\n *\n * @param {Any} id value of `_id` to query by\n * @param {Object|String|String[]} [projection] optional fields to return, see [`Query.prototype.select()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.select())\n * @param {Object} [options] optional see [`Query.prototype.setOptions()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.setOptions())\n * @return {Query}\n * @see field selection https://mongoosejs.com/docs/api/query.html#Query.prototype.select()\n * @see lean queries https://mongoosejs.com/docs/tutorials/lean.html\n * @see findById in Mongoose https://masteringjs.io/tutorials/mongoose/find-by-id\n * @api public\n */\n\nModel.findById = function findById(id, projection, options) {\n  _checkContext(this, 'findById');\n  if (typeof arguments[0] === 'function' || typeof arguments[1] === 'function' || typeof arguments[2] === 'function') {\n    throw new MongooseError('Model.findById() no longer accepts a callback');\n  }\n\n  if (typeof id === 'undefined') {\n    id = null;\n  }\n\n  return this.findOne({ _id: id }, projection, options);\n};\n\n/**\n * Finds one document.\n *\n * The `conditions` are cast to their respective SchemaTypes before the command is sent.\n *\n * *Note:* `conditions` is optional, and if `conditions` is null or undefined,\n * mongoose will send an empty `findOne` command to MongoDB, which will return\n * an arbitrary document. If you're querying by `_id`, use `findById()` instead.\n *\n * #### Example:\n *\n *     // Find one adventure whose `country` is 'Croatia', otherwise `null`\n *     await Adventure.findOne({ country: 'Croatia' }).exec();\n *\n *     // Model.findOne() no longer accepts a callback\n *\n *     // Select only the adventures name and length\n *     await Adventure.findOne({ country: 'Croatia' }, 'name length').exec();\n *\n * @param {Object} [conditions]\n * @param {Object|String|String[]} [projection] optional fields to return, see [`Query.prototype.select()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.select())\n * @param {Object} [options] optional see [`Query.prototype.setOptions()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.setOptions())\n * @param {Boolean} [options.translateAliases=null] If set to `true`, translates any schema-defined aliases in `filter`, `projection`, `update`, and `distinct`. Throws an error if there are any conflicts where both alias and raw property are defined on the same object.\n * @return {Query}\n * @see field selection https://mongoosejs.com/docs/api/query.html#Query.prototype.select()\n * @see lean queries https://mongoosejs.com/docs/tutorials/lean.html\n * @api public\n */\n\nModel.findOne = function findOne(conditions, projection, options) {\n  _checkContext(this, 'findOne');\n  if (typeof arguments[0] === 'function' || typeof arguments[1] === 'function' || typeof arguments[2] === 'function') {\n    throw new MongooseError('Model.findOne() no longer accepts a callback');\n  }\n\n  const mq = new this.Query({}, {}, this, this.$__collection);\n  mq.select(projection);\n  mq.setOptions(options);\n\n  return mq.findOne(conditions);\n};\n\n/**\n * Estimates the number of documents in the MongoDB collection. Faster than\n * using `countDocuments()` for large collections because\n * `estimatedDocumentCount()` uses collection metadata rather than scanning\n * the entire collection.\n *\n * #### Example:\n *\n *     const numAdventures = await Adventure.estimatedDocumentCount();\n *\n * @param {Object} [options]\n * @return {Query}\n * @api public\n */\n\nModel.estimatedDocumentCount = function estimatedDocumentCount(options) {\n  _checkContext(this, 'estimatedDocumentCount');\n\n  const mq = new this.Query({}, {}, this, this.$__collection);\n\n  return mq.estimatedDocumentCount(options);\n};\n\n/**\n * Counts number of documents matching `filter` in a database collection.\n *\n * #### Example:\n *\n *     Adventure.countDocuments({ type: 'jungle' }, function (err, count) {\n *       console.log('there are %d jungle adventures', count);\n *     });\n *\n * If you want to count all documents in a large collection,\n * use the [`estimatedDocumentCount()` function](https://mongoosejs.com/docs/api/model.html#Model.estimatedDocumentCount())\n * instead. If you call `countDocuments({})`, MongoDB will always execute\n * a full collection scan and **not** use any indexes.\n *\n * The `countDocuments()` function is similar to `count()`, but there are a\n * [few operators that `countDocuments()` does not support](https://mongodb.github.io/node-mongodb-native/4.9/classes/Collection.html#countDocuments).\n * Below are the operators that `count()` supports but `countDocuments()` does not,\n * and the suggested replacement:\n *\n * - `$where`: [`$expr`](https://www.mongodb.com/docs/manual/reference/operator/query/expr/)\n * - `$near`: [`$geoWithin`](https://www.mongodb.com/docs/manual/reference/operator/query/geoWithin/) with [`$center`](https://www.mongodb.com/docs/manual/reference/operator/query/center/#op._S_center)\n * - `$nearSphere`: [`$geoWithin`](https://www.mongodb.com/docs/manual/reference/operator/query/geoWithin/) with [`$centerSphere`](https://www.mongodb.com/docs/manual/reference/operator/query/centerSphere/#op._S_centerSphere)\n *\n * @param {Object} filter\n * @return {Query}\n * @api public\n */\n\nModel.countDocuments = function countDocuments(conditions, options) {\n  _checkContext(this, 'countDocuments');\n  if (typeof arguments[0] === 'function' || typeof arguments[1] === 'function' || typeof arguments[2] === 'function') {\n    throw new MongooseError('Model.countDocuments() no longer accepts a callback');\n  }\n\n  const mq = new this.Query({}, {}, this, this.$__collection);\n  if (options != null) {\n    mq.setOptions(options);\n  }\n\n  return mq.countDocuments(conditions);\n};\n\n\n/**\n * Creates a Query for a `distinct` operation.\n *\n * #### Example:\n *\n *     const query = Link.distinct('url');\n *     query.exec();\n *\n * @param {String} field\n * @param {Object} [conditions] optional\n * @return {Query}\n * @api public\n */\n\nModel.distinct = function distinct(field, conditions) {\n  _checkContext(this, 'distinct');\n  if (typeof arguments[0] === 'function' || typeof arguments[1] === 'function') {\n    throw new MongooseError('Model.distinct() no longer accepts a callback');\n  }\n\n  const mq = new this.Query({}, {}, this, this.$__collection);\n\n  return mq.distinct(field, conditions);\n};\n\n/**\n * Creates a Query, applies the passed conditions, and returns the Query.\n *\n * For example, instead of writing:\n *\n *     User.find({ age: { $gte: 21, $lte: 65 } });\n *\n * we can instead write:\n *\n *     User.where('age').gte(21).lte(65).exec();\n *\n * Since the Query class also supports `where` you can continue chaining\n *\n *     User\n *     .where('age').gte(21).lte(65)\n *     .where('name', /^b/i)\n *     ... etc\n *\n * @param {String} path\n * @param {Object} [val] optional value\n * @return {Query}\n * @api public\n */\n\nModel.where = function where(path, val) {\n  _checkContext(this, 'where');\n\n  void val; // eslint\n  const mq = new this.Query({}, {}, this, this.$__collection).find({});\n  return mq.where.apply(mq, arguments);\n};\n\n/**\n * Creates a `Query` and specifies a `$where` condition.\n *\n * Sometimes you need to query for things in mongodb using a JavaScript expression. You can do so via `find({ $where: javascript })`, or you can use the mongoose shortcut method $where via a Query chain or from your mongoose Model.\n *\n *     Blog.$where('this.username.indexOf(\"val\") !== -1').exec(function (err, docs) {});\n *\n * @param {String|Function} argument is a javascript string or anonymous function\n * @method $where\n * @memberOf Model\n * @return {Query}\n * @see Query.$where https://mongoosejs.com/docs/api/query.html#Query.prototype.$where\n * @api public\n */\n\nModel.$where = function $where() {\n  _checkContext(this, '$where');\n\n  const mq = new this.Query({}, {}, this, this.$__collection).find({});\n  return mq.$where.apply(mq, arguments);\n};\n\n/**\n * Issues a mongodb findOneAndUpdate command.\n *\n * Finds a matching document, updates it according to the `update` arg, passing any `options`, and returns the found document (if any) to the callback. The query executes if `callback` is passed else a Query object is returned.\n *\n * #### Example:\n *\n *     A.findOneAndUpdate(conditions, update, options)  // returns Query\n *     A.findOneAndUpdate(conditions, update)           // returns Query\n *     A.findOneAndUpdate()                             // returns Query\n *\n * #### Note:\n *\n * All top level update keys which are not `atomic` operation names are treated as set operations:\n *\n * #### Example:\n *\n *     const query = { name: 'borne' };\n *     Model.findOneAndUpdate(query, { name: 'jason bourne' }, options)\n *\n *     // is sent as\n *     Model.findOneAndUpdate(query, { $set: { name: 'jason bourne' }}, options)\n *\n * #### Note:\n *\n * `findOneAndX` and `findByIdAndX` functions support limited validation that\n * you can enable by setting the `runValidators` option.\n *\n * If you need full-fledged validation, use the traditional approach of first\n * retrieving the document.\n *\n *     const doc = await Model.findById(id);\n *     doc.name = 'jason bourne';\n *     await doc.save();\n *\n * @param {Object} [conditions]\n * @param {Object} [update]\n * @param {Object} [options] optional see [`Query.prototype.setOptions()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.setOptions())\n * @param {String} [options.returnDocument='before'] Has two possible values, `'before'` and `'after'`. By default, it will return the document before the update was applied.\n * @param {Object} [options.lean] if truthy, mongoose will return the document as a plain JavaScript object rather than a mongoose document. See [`Query.lean()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.lean()) and [the Mongoose lean tutorial](https://mongoosejs.com/docs/tutorials/lean.html).\n * @param {ClientSession} [options.session=null] The session associated with this query. See [transactions docs](https://mongoosejs.com/docs/transactions.html).\n * @param {Boolean|String} [options.strict] overwrites the schema's [strict mode option](https://mongoosejs.com/docs/guide.html#strict)\n * @param {Boolean} [options.timestamps=null] If set to `false` and [schema-level timestamps](https://mongoosejs.com/docs/guide.html#timestamps) are enabled, skip timestamps for this update. Note that this allows you to overwrite timestamps. Does nothing if schema-level timestamps are not set.\n * @param {Boolean} [options.upsert=false] if true, and no documents found, insert a new document\n * @param {Object|String|String[]} [options.projection=null] optional fields to return, see [`Query.prototype.select()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.select())\n * @param {Boolean} [options.new=false] if true, return the modified document rather than the original\n * @param {Object|String} [options.fields] Field selection. Equivalent to `.select(fields).findOneAndUpdate()`\n * @param {Number} [options.maxTimeMS] puts a time limit on the query - requires mongodb >= 2.6.0\n * @param {Object|String} [options.sort] if multiple docs are found by the conditions, sets the sort order to choose which doc to update.\n * @param {Boolean} [options.runValidators] if true, runs [update validators](https://mongoosejs.com/docs/validation.html#update-validators) on this command. Update validators validate the update operation against the model's schema\n * @param {Boolean} [options.setDefaultsOnInsert=true] If `setDefaultsOnInsert` and `upsert` are true, mongoose will apply the [defaults](https://mongoosejs.com/docs/defaults.html) specified in the model's schema if a new document is created\n * @param {Boolean} [options.includeResultMetadata] if true, returns the [raw result from the MongoDB driver](https://mongodb.github.io/node-mongodb-native/4.9/interfaces/ModifyResult.html)\n * @param {Boolean} [options.translateAliases=null] If set to `true`, translates any schema-defined aliases in `filter`, `projection`, `update`, and `distinct`. Throws an error if there are any conflicts where both alias and raw property are defined on the same object.\n * @param {Boolean} [options.overwriteDiscriminatorKey=false] Mongoose removes discriminator key updates from `update` by default, set `overwriteDiscriminatorKey` to `true` to allow updating the discriminator key\n * @return {Query}\n * @see Tutorial https://mongoosejs.com/docs/tutorials/findoneandupdate.html\n * @see mongodb https://www.mongodb.com/docs/manual/reference/command/findAndModify/\n * @api public\n */\n\nModel.findOneAndUpdate = function(conditions, update, options) {\n  _checkContext(this, 'findOneAndUpdate');\n  if (typeof arguments[0] === 'function' || typeof arguments[1] === 'function' || typeof arguments[2] === 'function' || typeof arguments[3] === 'function') {\n    throw new MongooseError('Model.findOneAndUpdate() no longer accepts a callback');\n  }\n\n  if (arguments.length === 1) {\n    update = conditions;\n    conditions = null;\n    options = null;\n  }\n\n  let fields;\n  if (options) {\n    fields = options.fields || options.projection;\n  }\n\n  update = clone(update, {\n    depopulate: true,\n    _isNested: true\n  });\n\n  decorateUpdateWithVersionKey(update, options, this.schema.options.versionKey);\n\n  const mq = new this.Query({}, {}, this, this.$__collection);\n  mq.select(fields);\n\n  return mq.findOneAndUpdate(conditions, update, options);\n};\n\n/**\n * Issues a mongodb findOneAndUpdate command by a document's _id field.\n * `findByIdAndUpdate(id, ...)` is equivalent to `findOneAndUpdate({ _id: id }, ...)`.\n *\n * Finds a matching document, updates it according to the `update` arg,\n * passing any `options`, and returns the found document (if any).\n *\n * This function triggers the following middleware.\n *\n * - `findOneAndUpdate()`\n *\n * #### Example:\n *\n *     A.findByIdAndUpdate(id, update, options)  // returns Query\n *     A.findByIdAndUpdate(id, update)           // returns Query\n *     A.findByIdAndUpdate()                     // returns Query\n *\n * #### Note:\n *\n * All top level update keys which are not `atomic` operation names are treated as set operations:\n *\n * #### Example:\n *\n *     Model.findByIdAndUpdate(id, { name: 'jason bourne' }, options)\n *\n *     // is sent as\n *     Model.findByIdAndUpdate(id, { $set: { name: 'jason bourne' }}, options)\n *\n * #### Note:\n *\n * `findOneAndX` and `findByIdAndX` functions support limited validation. You can\n * enable validation by setting the `runValidators` option.\n *\n * If you need full-fledged validation, use the traditional approach of first\n * retrieving the document.\n *\n *     const doc = await Model.findById(id)\n *     doc.name = 'jason bourne';\n *     await doc.save();\n *\n * @param {Object|Number|String} id value of `_id` to query by\n * @param {Object} [update]\n * @param {Object} [options] optional see [`Query.prototype.setOptions()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.setOptions())\n * @param {String} [options.returnDocument='before'] Has two possible values, `'before'` and `'after'`. By default, it will return the document before the update was applied.\n * @param {Object} [options.lean] if truthy, mongoose will return the document as a plain JavaScript object rather than a mongoose document. See [`Query.lean()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.lean()) and [the Mongoose lean tutorial](https://mongoosejs.com/docs/tutorials/lean.html).\n * @param {ClientSession} [options.session=null] The session associated with this query. See [transactions docs](https://mongoosejs.com/docs/transactions.html).\n * @param {Boolean|String} [options.strict] overwrites the schema's [strict mode option](https://mongoosejs.com/docs/guide.html#strict)\n * @param {Boolean} [options.timestamps=null] If set to `false` and [schema-level timestamps](https://mongoosejs.com/docs/guide.html#timestamps) are enabled, skip timestamps for this update. Note that this allows you to overwrite timestamps. Does nothing if schema-level timestamps are not set.\n * @param {Object|String} [options.sort] if multiple docs are found by the conditions, sets the sort order to choose which doc to update.\n * @param {Boolean} [options.runValidators] if true, runs [update validators](https://mongoosejs.com/docs/validation.html#update-validators) on this command. Update validators validate the update operation against the model's schema\n * @param {Boolean} [options.setDefaultsOnInsert=true] If `setDefaultsOnInsert` and `upsert` are true, mongoose will apply the [defaults](https://mongoosejs.com/docs/defaults.html) specified in the model's schema if a new document is created\n * @param {Boolean} [options.includeResultMetadata] if true, returns the full [ModifyResult from the MongoDB driver](https://mongodb.github.io/node-mongodb-native/4.9/interfaces/ModifyResult.html) rather than just the document\n * @param {Boolean} [options.upsert=false] if true, and no documents found, insert a new document\n * @param {Boolean} [options.new=false] if true, return the modified document rather than the original\n * @param {Object|String} [options.select] sets the document fields to return.\n * @param {Boolean} [options.translateAliases=null] If set to `true`, translates any schema-defined aliases in `filter`, `projection`, `update`, and `distinct`. Throws an error if there are any conflicts where both alias and raw property are defined on the same object.\n * @param {Boolean} [options.overwriteDiscriminatorKey=false] Mongoose removes discriminator key updates from `update` by default, set `overwriteDiscriminatorKey` to `true` to allow updating the discriminator key\n * @return {Query}\n * @see Model.findOneAndUpdate https://mongoosejs.com/docs/api/model.html#Model.findOneAndUpdate()\n * @see mongodb https://www.mongodb.com/docs/manual/reference/command/findAndModify/\n * @api public\n */\n\nModel.findByIdAndUpdate = function(id, update, options) {\n  _checkContext(this, 'findByIdAndUpdate');\n  if (typeof arguments[0] === 'function' || typeof arguments[1] === 'function' || typeof arguments[2] === 'function' || typeof arguments[3] === 'function') {\n    throw new MongooseError('Model.findByIdAndUpdate() no longer accepts a callback');\n  }\n\n  // if a model is passed in instead of an id\n  if (id instanceof Document) {\n    id = id._id;\n  }\n\n  return this.findOneAndUpdate.call(this, { _id: id }, update, options);\n};\n\n/**\n * Issue a MongoDB `findOneAndDelete()` command.\n *\n * Finds a matching document, removes it, and returns the found document (if any).\n *\n * This function triggers the following middleware.\n *\n * - `findOneAndDelete()`\n *\n * #### Example:\n *\n *     A.findOneAndDelete(conditions, options)  // return Query\n *     A.findOneAndDelete(conditions) // returns Query\n *     A.findOneAndDelete()           // returns Query\n *\n * `findOneAndX` and `findByIdAndX` functions support limited validation. You can\n * enable validation by setting the `runValidators` option.\n *\n * If you need full-fledged validation, use the traditional approach of first\n * retrieving the document.\n *\n *     const doc = await Model.findById(id)\n *     doc.name = 'jason bourne';\n *     await doc.save();\n *\n * @param {Object} conditions\n * @param {Object} [options] optional see [`Query.prototype.setOptions()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.setOptions())\n * @param {Boolean|String} [options.strict] overwrites the schema's [strict mode option](https://mongoosejs.com/docs/guide.html#strict)\n * @param {Object|String|String[]} [options.projection=null] optional fields to return, see [`Query.prototype.select()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.select())\n * @param {ClientSession} [options.session=null] The session associated with this query. See [transactions docs](https://mongoosejs.com/docs/transactions.html).\n * @param {Boolean} [options.includeResultMetadata] if true, returns the full [ModifyResult from the MongoDB driver](https://mongodb.github.io/node-mongodb-native/4.9/interfaces/ModifyResult.html) rather than just the document\n * @param {Object|String} [options.sort] if multiple docs are found by the conditions, sets the sort order to choose which doc to update.\n * @param {Object|String} [options.select] sets the document fields to return.\n * @param {Number} [options.maxTimeMS] puts a time limit on the query - requires mongodb >= 2.6.0\n * @param {Boolean} [options.translateAliases=null] If set to `true`, translates any schema-defined aliases in `filter`, `projection`, `update`, and `distinct`. Throws an error if there are any conflicts where both alias and raw property are defined on the same object.\n * @return {Query}\n * @api public\n */\n\nModel.findOneAndDelete = function(conditions, options) {\n  _checkContext(this, 'findOneAndDelete');\n\n  if (typeof arguments[0] === 'function' || typeof arguments[1] === 'function' || typeof arguments[2] === 'function') {\n    throw new MongooseError('Model.findOneAndDelete() no longer accepts a callback');\n  }\n\n  let fields;\n  if (options) {\n    fields = options.select;\n    options.select = undefined;\n  }\n\n  const mq = new this.Query({}, {}, this, this.$__collection);\n  mq.select(fields);\n\n  return mq.findOneAndDelete(conditions, options);\n};\n\n/**\n * Issue a MongoDB `findOneAndDelete()` command by a document's _id field.\n * In other words, `findByIdAndDelete(id)` is a shorthand for\n * `findOneAndDelete({ _id: id })`.\n *\n * This function triggers the following middleware.\n *\n * - `findOneAndDelete()`\n *\n * @param {Object|Number|String} id value of `_id` to query by\n * @param {Object} [options] optional see [`Query.prototype.setOptions()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.setOptions())\n * @param {Boolean|String} [options.strict] overwrites the schema's [strict mode option](https://mongoosejs.com/docs/guide.html#strict)\n * @param {Boolean} [options.translateAliases=null] If set to `true`, translates any schema-defined aliases in `filter`, `projection`, `update`, and `distinct`. Throws an error if there are any conflicts where both alias and raw property are defined on the same object.\n * @return {Query}\n * @see Model.findOneAndDelete https://mongoosejs.com/docs/api/model.html#Model.findOneAndDelete()\n * @see mongodb https://www.mongodb.com/docs/manual/reference/command/findAndModify/\n */\n\nModel.findByIdAndDelete = function(id, options) {\n  _checkContext(this, 'findByIdAndDelete');\n\n  if (typeof arguments[0] === 'function' || typeof arguments[1] === 'function' || typeof arguments[2] === 'function') {\n    throw new MongooseError('Model.findByIdAndDelete() no longer accepts a callback');\n  }\n\n  return this.findOneAndDelete({ _id: id }, options);\n};\n\n/**\n * Issue a MongoDB `findOneAndReplace()` command.\n *\n * Finds a matching document, replaces it with the provided doc, and returns the document.\n *\n * This function triggers the following query middleware.\n *\n * - `findOneAndReplace()`\n *\n * #### Example:\n *\n *     A.findOneAndReplace(filter, replacement, options)  // return Query\n *     A.findOneAndReplace(filter, replacement) // returns Query\n *     A.findOneAndReplace()                    // returns Query\n *\n * @param {Object} filter Replace the first document that matches this filter\n * @param {Object} [replacement] Replace with this document\n * @param {Object} [options] optional see [`Query.prototype.setOptions()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.setOptions())\n * @param {String} [options.returnDocument='before'] Has two possible values, `'before'` and `'after'`. By default, it will return the document before the update was applied.\n * @param {Object} [options.lean] if truthy, mongoose will return the document as a plain JavaScript object rather than a mongoose document. See [`Query.lean()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.lean()) and [the Mongoose lean tutorial](https://mongoosejs.com/docs/tutorials/lean.html).\n * @param {ClientSession} [options.session=null] The session associated with this query. See [transactions docs](https://mongoosejs.com/docs/transactions.html).\n * @param {Boolean|String} [options.strict] overwrites the schema's [strict mode option](https://mongoosejs.com/docs/guide.html#strict)\n * @param {Boolean} [options.timestamps=null] If set to `false` and [schema-level timestamps](https://mongoosejs.com/docs/guide.html#timestamps) are enabled, skip timestamps for this update. Note that this allows you to overwrite timestamps. Does nothing if schema-level timestamps are not set.\n * @param {Object|String|String[]} [options.projection=null] optional fields to return, see [`Query.prototype.select()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.select())\n * @param {Object|String} [options.sort] if multiple docs are found by the conditions, sets the sort order to choose which doc to update.\n * @param {Boolean} [options.includeResultMetadata] if true, returns the full [ModifyResult from the MongoDB driver](https://mongodb.github.io/node-mongodb-native/4.9/interfaces/ModifyResult.html) rather than just the document\n * @param {Object|String} [options.select] sets the document fields to return.\n * @param {Number} [options.maxTimeMS] puts a time limit on the query - requires mongodb >= 2.6.0\n * @param {Boolean} [options.translateAliases=null] If set to `true`, translates any schema-defined aliases in `filter`, `projection`, `update`, and `distinct`. Throws an error if there are any conflicts where both alias and raw property are defined on the same object.\n * @return {Query}\n * @api public\n */\n\nModel.findOneAndReplace = function(filter, replacement, options) {\n  _checkContext(this, 'findOneAndReplace');\n\n  if (typeof arguments[0] === 'function' || typeof arguments[1] === 'function' || typeof arguments[2] === 'function' || typeof arguments[3] === 'function') {\n    throw new MongooseError('Model.findOneAndReplace() no longer accepts a callback');\n  }\n\n  let fields;\n  if (options) {\n    fields = options.select;\n    options.select = undefined;\n  }\n\n  const mq = new this.Query({}, {}, this, this.$__collection);\n  mq.select(fields);\n\n  return mq.findOneAndReplace(filter, replacement, options);\n};\n\n/**\n * Shortcut for saving one or more documents to the database.\n * `MyModel.create(docs)` does `new MyModel(doc).save()` for every doc in\n * docs.\n *\n * This function triggers the following middleware.\n *\n * - `save()`\n *\n * #### Example:\n *\n *     // Insert one new `Character` document\n *     await Character.create({ name: 'Jean-Luc Picard' });\n *\n *     // Insert multiple new `Character` documents\n *     await Character.create([{ name: 'Will Riker' }, { name: 'Geordi LaForge' }]);\n *\n *     // Create a new character within a transaction. Note that you **must**\n *     // pass an array as the first parameter to `create()` if you want to\n *     // specify options.\n *     await Character.create([{ name: 'Jean-Luc Picard' }], { session });\n *\n * @param {Array|Object} docs Documents to insert, as a spread or array\n * @param {Object} [options] Options passed down to `save()`. To specify `options`, `docs` **must** be an array, not a spread. See [Model.save](https://mongoosejs.com/docs/api/model.html#Model.prototype.save()) for available options.\n * @param {Boolean} [options.ordered] saves the docs in series rather than parallel.\n * @param {Boolean} [options.aggregateErrors] Aggregate Errors instead of throwing the first one that occurs. Default: false\n * @return {Promise}\n * @api public\n */\n\nModel.create = async function create(doc, options) {\n  if (typeof options === 'function' ||\n      typeof arguments[2] === 'function') {\n    throw new MongooseError('Model.create() no longer accepts a callback');\n  }\n\n  _checkContext(this, 'create');\n\n  let args;\n  const discriminatorKey = this.schema.options.discriminatorKey;\n\n  if (Array.isArray(doc)) {\n    args = doc;\n    options = options != null && typeof options === 'object' ? options : {};\n  } else {\n    const last = arguments[arguments.length - 1];\n    options = {};\n    const hasCallback = typeof last === 'function' ||\n      typeof options === 'function' ||\n      typeof arguments[2] === 'function';\n    if (hasCallback) {\n      throw new MongooseError('Model.create() no longer accepts a callback');\n    } else {\n      args = [...arguments];\n      // For backwards compatibility with 6.x, because of gh-5061 Mongoose 6.x and\n      // older would treat a falsy last arg as a callback. We don't want to throw\n      // an error here, because it would look strange if `Test.create({}, void 0)`\n      // threw a callback error. But we also don't want to create an unnecessary document.\n      if (args.length > 1 && !last) {\n        args.pop();\n      }\n    }\n\n    if (args.length === 2 &&\n        args[0] != null &&\n        args[1] != null &&\n        args[0].session == null &&\n        last &&\n        getConstructorName(last.session) === 'ClientSession' &&\n        !this.schema.path('session')) {\n      // Probably means the user is running into the common mistake of trying\n      // to use a spread to specify options, see gh-7535\n      utils.warn('WARNING: to pass a `session` to `Model.create()` in ' +\n        'Mongoose, you **must** pass an array as the first argument. See: ' +\n        'https://mongoosejs.com/docs/api/model.html#Model.create()');\n    }\n  }\n\n  if (args.length === 0) {\n    return Array.isArray(doc) ? [] : null;\n  }\n  let res = [];\n  const immediateError = typeof options.aggregateErrors === 'boolean' ? !options.aggregateErrors : true;\n\n  delete options.aggregateErrors; // dont pass on the option to \"$save\"\n\n  if (options.ordered) {\n    for (let i = 0; i < args.length; i++) {\n      try {\n        const doc = args[i];\n        const Model = this.discriminators && doc[discriminatorKey] != null ?\n          this.discriminators[doc[discriminatorKey]] || getDiscriminatorByValue(this.discriminators, doc[discriminatorKey]) :\n          this;\n        if (Model == null) {\n          throw new MongooseError(`Discriminator \"${doc[discriminatorKey]}\" not ` +\n          `found for model \"${this.modelName}\"`);\n        }\n        let toSave = doc;\n        if (!(toSave instanceof Model)) {\n          toSave = new Model(toSave);\n        }\n\n        await toSave.$save(options);\n        res.push(toSave);\n      } catch (err) {\n        if (!immediateError) {\n          res.push(err);\n        } else {\n          throw err;\n        }\n      }\n    }\n    return res;\n  } else if (!immediateError) {\n    res = await Promise.allSettled(args.map(async doc => {\n      const Model = this.discriminators && doc[discriminatorKey] != null ?\n        this.discriminators[doc[discriminatorKey]] || getDiscriminatorByValue(this.discriminators, doc[discriminatorKey]) :\n        this;\n      if (Model == null) {\n        throw new MongooseError(`Discriminator \"${doc[discriminatorKey]}\" not ` +\n            `found for model \"${this.modelName}\"`);\n      }\n      let toSave = doc;\n\n      if (!(toSave instanceof Model)) {\n        toSave = new Model(toSave);\n      }\n\n      await toSave.$save(options);\n\n      return toSave;\n    }));\n    res = res.map(result => result.status === 'fulfilled' ? result.value : result.reason);\n  } else {\n    let firstError = null;\n    res = await Promise.all(args.map(async doc => {\n      const Model = this.discriminators && doc[discriminatorKey] != null ?\n        this.discriminators[doc[discriminatorKey]] || getDiscriminatorByValue(this.discriminators, doc[discriminatorKey]) :\n        this;\n      if (Model == null) {\n        throw new MongooseError(`Discriminator \"${doc[discriminatorKey]}\" not ` +\n            `found for model \"${this.modelName}\"`);\n      }\n      try {\n        let toSave = doc;\n\n        if (!(toSave instanceof Model)) {\n          toSave = new Model(toSave);\n        }\n\n        await toSave.$save(options);\n\n        return toSave;\n      } catch (err) {\n        if (!firstError) {\n          firstError = err;\n        }\n      }\n    }));\n    if (firstError) {\n      throw firstError;\n    }\n  }\n\n\n  if (!Array.isArray(doc) && args.length === 1) {\n    return res[0];\n  }\n\n  return res;\n};\n\n/**\n * _Requires a replica set running MongoDB >= 3.6.0._ Watches the\n * underlying collection for changes using\n * [MongoDB change streams](https://www.mongodb.com/docs/manual/changeStreams/).\n *\n * This function does **not** trigger any middleware. In particular, it\n * does **not** trigger aggregate middleware.\n *\n * The ChangeStream object is an event emitter that emits the following events:\n *\n * - 'change': A change occurred, see below example\n * - 'error': An unrecoverable error occurred. In particular, change streams currently error out if they lose connection to the replica set primary. Follow [this GitHub issue](https://github.com/Automattic/mongoose/issues/6799) for updates.\n * - 'end': Emitted if the underlying stream is closed\n * - 'close': Emitted if the underlying stream is closed\n *\n * #### Example:\n *\n *     const doc = await Person.create({ name: 'Ned Stark' });\n *     const changeStream = Person.watch().on('change', change => console.log(change));\n *     // Will print from the above `console.log()`:\n *     // { _id: { _data: ... },\n *     //   operationType: 'delete',\n *     //   ns: { db: 'mydb', coll: 'Person' },\n *     //   documentKey: { _id: 5a51b125c5500f5aa094c7bd } }\n *     await doc.remove();\n *\n * @param {Array} [pipeline]\n * @param {Object} [options] see the [mongodb driver options](https://mongodb.github.io/node-mongodb-native/4.9/classes/Collection.html#watch)\n * @param {Boolean} [options.hydrate=false] if true and `fullDocument: 'updateLookup'` is set, Mongoose will automatically hydrate `fullDocument` into a fully fledged Mongoose document\n * @return {ChangeStream} mongoose-specific change stream wrapper, inherits from EventEmitter\n * @api public\n */\n\nModel.watch = function(pipeline, options) {\n  _checkContext(this, 'watch');\n\n  const changeStreamThunk = cb => {\n    pipeline = pipeline || [];\n    prepareDiscriminatorPipeline(pipeline, this.schema, 'fullDocument');\n    if (this.$__collection.buffer) {\n      this.$__collection.addQueue(() => {\n        if (this.closed) {\n          return;\n        }\n        const driverChangeStream = this.$__collection.watch(pipeline, options);\n        cb(null, driverChangeStream);\n      });\n    } else {\n      const driverChangeStream = this.$__collection.watch(pipeline, options);\n      cb(null, driverChangeStream);\n    }\n  };\n\n  options = options || {};\n  options.model = this;\n\n  return new ChangeStream(changeStreamThunk, pipeline, options);\n};\n\n/**\n * _Requires MongoDB >= 3.6.0._ Starts a [MongoDB session](https://www.mongodb.com/docs/manual/release-notes/3.6/#client-sessions)\n * for benefits like causal consistency, [retryable writes](https://www.mongodb.com/docs/manual/core/retryable-writes/),\n * and [transactions](https://thecodebarbarian.com/a-node-js-perspective-on-mongodb-4-transactions.html).\n *\n * Calling `MyModel.startSession()` is equivalent to calling `MyModel.db.startSession()`.\n *\n * This function does not trigger any middleware.\n *\n * #### Example:\n *\n *     const session = await Person.startSession();\n *     let doc = await Person.findOne({ name: 'Ned Stark' }, null, { session });\n *     await doc.remove();\n *     // `doc` will always be null, even if reading from a replica set\n *     // secondary. Without causal consistency, it is possible to\n *     // get a doc back from the below query if the query reads from a\n *     // secondary that is experiencing replication lag.\n *     doc = await Person.findOne({ name: 'Ned Stark' }, null, { session, readPreference: 'secondary' });\n *\n * @param {Object} [options] see the [mongodb driver options](https://mongodb.github.io/node-mongodb-native/4.9/classes/MongoClient.html#startSession)\n * @param {Boolean} [options.causalConsistency=true] set to false to disable causal consistency\n * @return {Promise<ClientSession>} promise that resolves to a MongoDB driver `ClientSession`\n * @api public\n */\n\nModel.startSession = function() {\n  _checkContext(this, 'startSession');\n\n  return this.db.startSession.apply(this.db, arguments);\n};\n\n/**\n * Shortcut for validating an array of documents and inserting them into\n * MongoDB if they're all valid. This function is faster than `.create()`\n * because it only sends one operation to the server, rather than one for each\n * document.\n *\n * Mongoose always validates each document **before** sending `insertMany`\n * to MongoDB. So if one document has a validation error, no documents will\n * be saved, unless you set\n * [the `ordered` option to false](https://www.mongodb.com/docs/manual/reference/method/db.collection.insertMany/#error-handling).\n *\n * This function does **not** trigger save middleware.\n *\n * This function triggers the following middleware.\n *\n * - `insertMany()`\n *\n * #### Example:\n *\n *     const docs = await Movies.insertMany([\n *       { name: 'Star Wars' },\n *       { name: 'The Empire Strikes Back' }\n *     ]);\n *     docs[0].name; // 'Star Wars'\n *\n *     // Return raw result from MongoDB\n *     const result = await Movies.insertMany([\n *       { name: 'Star Wars' },\n *       { name: 'The Empire Strikes Back' }\n *     ], { rawResult: true });\n *\n * @param {Array|Object|*} doc(s)\n * @param {Object} [options] see the [mongodb driver options](https://mongodb.github.io/node-mongodb-native/4.9/classes/Collection.html#insertMany)\n * @param {Boolean} [options.ordered=true] if true, will fail fast on the first error encountered. If false, will insert all the documents it can and report errors later. An `insertMany()` with `ordered = false` is called an \"unordered\" `insertMany()`.\n * @param {Boolean} [options.rawResult=false] if false, the returned promise resolves to the documents that passed mongoose document validation. If `true`, will return the [raw result from the MongoDB driver](https://mongodb.github.io/node-mongodb-native/4.9/interfaces/InsertManyResult.html) with a `mongoose` property that contains `validationErrors` and `results` if this is an unordered `insertMany`.\n * @param {Boolean} [options.lean=false] if `true`, skips hydrating the documents. This means Mongoose will **not** cast, validate, or apply defaults to any of the documents passed to `insertMany()`. This option is useful if you need the extra performance, but comes with data integrity risk. Consider using with [`castObject()`](https://mongoosejs.com/docs/api/model.html#Model.castObject()) and [`applyDefaults()`](https://mongoosejs.com/docs/api/model.html#Model.applyDefaults()).\n * @param {Number} [options.limit=null] this limits the number of documents being processed (validation/casting) by mongoose in parallel, this does **NOT** send the documents in batches to MongoDB. Use this option if you're processing a large number of documents and your app is running out of memory.\n * @param {String|Object|Array} [options.populate=null] populates the result documents. This option is a no-op if `rawResult` is set.\n * @param {Boolean} [options.throwOnValidationError=false] If true and `ordered: false`, throw an error if one of the operations failed validation, but all valid operations completed successfully.\n * @return {Promise} resolving to the raw result from the MongoDB driver if `options.rawResult` was `true`, or the documents that passed validation, otherwise\n * @api public\n */\n\nModel.insertMany = async function insertMany(arr, options) {\n  _checkContext(this, 'insertMany');\n  if (typeof options === 'function' ||\n    typeof arguments[2] === 'function') {\n    throw new MongooseError('Model.insertMany() no longer accepts a callback');\n  }\n\n  return new Promise((resolve, reject) => {\n    this.$__insertMany(arr, options, (err, res) => {\n      if (err != null) {\n        return reject(err);\n      }\n      resolve(res);\n    });\n  });\n};\n\n/**\n * ignore\n *\n * @param {Array} arr\n * @param {Object} options\n * @param {Function} callback\n * @api private\n * @memberOf Model\n * @method $__insertMany\n * @static\n */\n\nModel.$__insertMany = function(arr, options, callback) {\n  const _this = this;\n  if (typeof options === 'function') {\n    callback = options;\n    options = null;\n  }\n\n  callback = callback || utils.noop;\n  options = options || {};\n  const limit = options.limit || 1000;\n  const rawResult = !!options.rawResult;\n  const ordered = typeof options.ordered === 'boolean' ? options.ordered : true;\n  const throwOnValidationError = typeof options.throwOnValidationError === 'boolean' ? options.throwOnValidationError : false;\n  const lean = !!options.lean;\n\n  const asyncLocalStorage = this.db.base.transactionAsyncLocalStorage?.getStore();\n  if ((!options || !options.hasOwnProperty('session')) && asyncLocalStorage?.session != null) {\n    options = { ...options, session: asyncLocalStorage.session };\n  }\n\n  if (!Array.isArray(arr)) {\n    arr = [arr];\n  }\n\n  const validationErrors = [];\n  const validationErrorsToOriginalOrder = new Map();\n  const results = ordered ? null : new Array(arr.length);\n  const toExecute = arr.map((doc, index) =>\n    callback => {\n      // If option `lean` is set to true bypass validation and hydration\n      if (lean) {\n        // we have to execute callback at the nextTick to be compatible\n        // with parallelLimit, as `results` variable has TDZ issue if we\n        // execute the callback synchronously\n        return immediate(() => callback(null, doc));\n      }\n      let createdNewDoc = false;\n      if (!(doc instanceof _this)) {\n        if (doc != null && typeof doc !== 'object') {\n          return callback(new ObjectParameterError(doc, 'arr.' + index, 'insertMany'));\n        }\n        try {\n          doc = new _this(doc);\n          createdNewDoc = true;\n        } catch (err) {\n          return callback(err);\n        }\n      }\n\n      if (options.session != null) {\n        doc.$session(options.session);\n      }\n      // If option `lean` is set to true bypass validation\n      if (lean) {\n        // we have to execute callback at the nextTick to be compatible\n        // with parallelLimit, as `results` variable has TDZ issue if we\n        // execute the callback synchronously\n        return immediate(() => callback(null, doc));\n      }\n      doc.$validate(createdNewDoc ? { _skipParallelValidateCheck: true } : null).then(\n        () => { callback(null, doc); },\n        error => {\n          if (ordered === false) {\n            validationErrors.push(error);\n            validationErrorsToOriginalOrder.set(error, index);\n            results[index] = error;\n            return callback(null, null);\n          }\n          callback(error);\n        }\n      );\n    });\n\n  parallelLimit(toExecute, limit, function(error, docs) {\n    if (error) {\n      callback(error, null);\n      return;\n    }\n\n    const originalDocIndex = new Map();\n    const validDocIndexToOriginalIndex = new Map();\n    for (let i = 0; i < docs.length; ++i) {\n      originalDocIndex.set(docs[i], i);\n    }\n\n    // We filter all failed pre-validations by removing nulls\n    const docAttributes = docs.filter(function(doc) {\n      return doc != null;\n    });\n    for (let i = 0; i < docAttributes.length; ++i) {\n      validDocIndexToOriginalIndex.set(i, originalDocIndex.get(docAttributes[i]));\n    }\n\n    // Make sure validation errors are in the same order as the\n    // original documents, so if both doc1 and doc2 both fail validation,\n    // `Model.insertMany([doc1, doc2])` will always have doc1's validation\n    // error before doc2's. Re: gh-12791.\n    if (validationErrors.length > 0) {\n      validationErrors.sort((err1, err2) => {\n        return validationErrorsToOriginalOrder.get(err1) - validationErrorsToOriginalOrder.get(err2);\n      });\n    }\n\n    // Quickly escape while there aren't any valid docAttributes\n    if (docAttributes.length === 0) {\n      if (throwOnValidationError) {\n        return callback(new MongooseBulkWriteError(\n          validationErrors,\n          results,\n          null,\n          'insertMany'\n        ));\n      }\n      if (rawResult) {\n        const res = {\n          acknowledged: true,\n          insertedCount: 0,\n          insertedIds: {},\n          mongoose: {\n            validationErrors: validationErrors\n          }\n        };\n        return callback(null, res);\n      }\n      callback(null, []);\n      return;\n    }\n    const docObjects = lean ? docAttributes : docAttributes.map(function(doc) {\n      if (doc.$__schema.options.versionKey) {\n        doc[doc.$__schema.options.versionKey] = 0;\n      }\n      const shouldSetTimestamps = (!options || options.timestamps !== false) && doc.initializeTimestamps && (!doc.$__ || doc.$__.timestamps !== false);\n      if (shouldSetTimestamps) {\n        doc.initializeTimestamps();\n      }\n      if (doc.$__hasOnlyPrimitiveValues()) {\n        return doc.$__toObjectShallow();\n      }\n      return doc.toObject(internalToObjectOptions);\n    });\n\n    _this.$__collection.insertMany(docObjects, options).then(\n      res => {\n        if (!lean) {\n          for (const attribute of docAttributes) {\n            attribute.$__reset();\n            _setIsNew(attribute, false);\n          }\n        }\n\n        if (ordered === false && throwOnValidationError && validationErrors.length > 0) {\n          for (let i = 0; i < results.length; ++i) {\n            if (results[i] === void 0) {\n              results[i] = docs[i];\n            }\n          }\n          return callback(new MongooseBulkWriteError(\n            validationErrors,\n            results,\n            res,\n            'insertMany'\n          ));\n        }\n\n        if (rawResult) {\n          if (ordered === false) {\n            for (let i = 0; i < results.length; ++i) {\n              if (results[i] === void 0) {\n                results[i] = docs[i];\n              }\n            }\n\n            // Decorate with mongoose validation errors in case of unordered,\n            // because then still do `insertMany()`\n            res.mongoose = {\n              validationErrors: validationErrors,\n              results: results\n            };\n          }\n          return callback(null, res);\n        }\n\n        if (options.populate != null) {\n          return _this.populate(docAttributes, options.populate).then(\n            docs => { callback(null, docs); },\n            err => {\n              if (err != null) {\n                err.insertedDocs = docAttributes;\n              }\n              throw err;\n            }\n          );\n        }\n\n        callback(null, docAttributes);\n      },\n      error => {\n        // `writeErrors` is a property reported by the MongoDB driver,\n        // just not if there's only 1 error.\n        if (error.writeErrors == null &&\n            (error.result && error.result.result && error.result.result.writeErrors) != null) {\n          error.writeErrors = error.result.result.writeErrors;\n        }\n\n        // `insertedDocs` is a Mongoose-specific property\n        const hasWriteErrors = error && error.writeErrors;\n        const erroredIndexes = new Set((error && error.writeErrors || []).map(err => err.index));\n\n        if (error.writeErrors != null) {\n          for (let i = 0; i < error.writeErrors.length; ++i) {\n            const originalIndex = validDocIndexToOriginalIndex.get(error.writeErrors[i].index);\n            error.writeErrors[i] = {\n              ...error.writeErrors[i],\n              index: originalIndex\n            };\n            if (!ordered) {\n              results[originalIndex] = error.writeErrors[i];\n            }\n          }\n        }\n\n        if (!ordered) {\n          for (let i = 0; i < results.length; ++i) {\n            if (results[i] === void 0) {\n              results[i] = docs[i];\n            }\n          }\n\n          error.results = results;\n        }\n\n        let firstErroredIndex = -1;\n        error.insertedDocs = docAttributes.\n          filter((doc, i) => {\n            const isErrored = !hasWriteErrors || erroredIndexes.has(i);\n\n            if (ordered) {\n              if (firstErroredIndex > -1) {\n                return i < firstErroredIndex;\n              }\n\n              if (isErrored) {\n                firstErroredIndex = i;\n              }\n            }\n\n            return !isErrored;\n          }).\n          map(function setIsNewForInsertedDoc(doc) {\n            if (lean) {\n              return doc;\n            }\n            doc.$__reset();\n            _setIsNew(doc, false);\n            return doc;\n          });\n\n        if (rawResult && ordered === false) {\n          error.mongoose = {\n            validationErrors: validationErrors,\n            results: results\n          };\n        }\n\n        callback(error, null);\n      }\n    );\n  });\n};\n\n/*!\n * ignore\n */\n\nfunction _setIsNew(doc, val) {\n  doc.$isNew = val;\n  doc.$emit('isNew', val);\n  doc.constructor.emit('isNew', val);\n\n  const subdocs = doc.$getAllSubdocs();\n  for (const subdoc of subdocs) {\n    subdoc.$isNew = val;\n    subdoc.$emit('isNew', val);\n  }\n}\n\n/**\n * Sends multiple `insertOne`, `updateOne`, `updateMany`, `replaceOne`,\n * `deleteOne`, and/or `deleteMany` operations to the MongoDB server in one\n * command. This is faster than sending multiple independent operations (e.g.\n * if you use `create()`) because with `bulkWrite()` there is only one round\n * trip to MongoDB.\n *\n * Mongoose will perform casting on all operations you provide.\n * The only exception is [setting the `update` operator for `updateOne` or `updateMany` to a pipeline](https://www.mongodb.com/docs/manual/reference/method/db.collection.bulkWrite/#updateone-and-updatemany): Mongoose does **not** cast update pipelines.\n *\n * This function does **not** trigger any middleware, neither `save()`, nor `update()`.\n * If you need to trigger\n * `save()` middleware for every document use [`create()`](https://mongoosejs.com/docs/api/model.html#Model.create()) instead.\n *\n * #### Example:\n *\n *     Character.bulkWrite([\n *       {\n *         insertOne: {\n *           document: {\n *             name: 'Eddard Stark',\n *             title: 'Warden of the North'\n *           }\n *         }\n *       },\n *       {\n *         updateOne: {\n *           filter: { name: 'Eddard Stark' },\n *           // If you were using the MongoDB driver directly, you'd need to do\n *           // `update: { $set: { title: ... } }` but mongoose adds $set for\n *           // you.\n *           update: { title: 'Hand of the King' }\n *         }\n *       },\n *       {\n *         deleteOne: {\n *           filter: { name: 'Eddard Stark' }\n *         }\n *       }\n *     ]).then(res => {\n *      // Prints \"1 1 1\"\n *      console.log(res.insertedCount, res.modifiedCount, res.deletedCount);\n *     });\n *\n *     // Mongoose does **not** cast update pipelines, so no casting for the `update` option below.\n *     // Mongoose does still cast `filter`\n *     await Character.bulkWrite([{\n *       updateOne: {\n *         filter: { name: 'Annika Hansen' },\n *         update: [{ $set: { name: 7 } }] // Array means update pipeline, so Mongoose skips casting\n *       }\n *     }]);\n *\n * The [supported operations](https://www.mongodb.com/docs/manual/reference/method/db.collection.bulkWrite/#db.collection.bulkWrite) are:\n *\n * - `insertOne`\n * - `updateOne`\n * - `updateMany`\n * - `deleteOne`\n * - `deleteMany`\n * - `replaceOne`\n *\n * @param {Array} ops\n * @param {Object} [ops.insertOne.document] The document to insert\n * @param {Object} [ops.insertOne.timestamps=true] If false, do not apply [timestamps](https://mongoosejs.com/docs/guide.html#timestamps) to the operation\n * @param {Object} [ops.updateOne.filter] Update the first document that matches this filter\n * @param {Object} [ops.updateOne.update] An object containing [update operators](https://www.mongodb.com/docs/manual/reference/operator/update/)\n * @param {Boolean} [ops.updateOne.upsert=false] If true, insert a doc if none match\n * @param {Boolean} [ops.updateOne.timestamps=true] If false, do not apply [timestamps](https://mongoosejs.com/docs/guide.html#timestamps) to the operation\n * @param {Object} [ops.updateOne.collation] The [MongoDB collation](https://thecodebarbarian.com/a-nodejs-perspective-on-mongodb-34-collations) to use\n * @param {Array} [ops.updateOne.arrayFilters] The [array filters](https://thecodebarbarian.com/a-nodejs-perspective-on-mongodb-36-array-filters.html) used in `update`\n * @param {Object} [ops.updateMany.filter] Update all the documents that match this filter\n * @param {Object} [ops.updateMany.update] An object containing [update operators](https://www.mongodb.com/docs/manual/reference/operator/update/)\n * @param {Boolean} [ops.updateMany.upsert=false] If true, insert a doc if no documents match `filter`\n * @param {Boolean} [ops.updateMany.timestamps=true] If false, do not apply [timestamps](https://mongoosejs.com/docs/guide.html#timestamps) to the operation\n * @param {Object} [ops.updateMany.collation] The [MongoDB collation](https://thecodebarbarian.com/a-nodejs-perspective-on-mongodb-34-collations) to use\n * @param {Array} [ops.updateMany.arrayFilters] The [array filters](https://thecodebarbarian.com/a-nodejs-perspective-on-mongodb-36-array-filters.html) used in `update`\n * @param {Object} [ops.deleteOne.filter] Delete the first document that matches this filter\n * @param {Object} [ops.deleteMany.filter] Delete all documents that match this filter\n * @param {Object} [ops.replaceOne.filter] Replace the first document that matches this filter\n * @param {Object} [ops.replaceOne.replacement] The replacement document\n * @param {Boolean} [ops.replaceOne.upsert=false] If true, insert a doc if no documents match `filter`\n * @param {Object} [ops.replaceOne.timestamps=true] If false, do not apply [timestamps](https://mongoosejs.com/docs/guide.html#timestamps) to the operation\n * @param {Object} [options]\n * @param {Boolean} [options.ordered=true] If true, execute writes in order and stop at the first error. If false, execute writes in parallel and continue until all writes have either succeeded or errored.\n * @param {Boolean} [options.timestamps=true] If false, do not apply [timestamps](https://mongoosejs.com/docs/guide.html#timestamps) to any operations. Can be overridden at the operation-level.\n * @param {ClientSession} [options.session=null] The session associated with this bulk write. See [transactions docs](https://mongoosejs.com/docs/transactions.html).\n * @param {String|number} [options.w=1] The [write concern](https://www.mongodb.com/docs/manual/reference/write-concern/). See [`Query#w()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.w()) for more information.\n * @param {number} [options.wtimeout=null] The [write concern timeout](https://www.mongodb.com/docs/manual/reference/write-concern/#wtimeout).\n * @param {Boolean} [options.j=true] If false, disable [journal acknowledgement](https://www.mongodb.com/docs/manual/reference/write-concern/#j-option)\n * @param {Boolean} [options.skipValidation=false] Set to true to skip Mongoose schema validation on bulk write operations. Mongoose currently runs validation on `insertOne` and `replaceOne` operations by default.\n * @param {Boolean} [options.bypassDocumentValidation=false] If true, disable [MongoDB server-side schema validation](https://www.mongodb.com/docs/manual/core/schema-validation/) for all writes in this bulk.\n * @param {Boolean} [options.throwOnValidationError=false] If true and `ordered: false`, throw an error if one of the operations failed validation, but all valid operations completed successfully.\n * @param {Boolean} [options.strict=null] Overwrites the [`strict` option](https://mongoosejs.com/docs/guide.html#strict) on schema. If false, allows filtering and writing fields not defined in the schema for all writes in this bulk.\n * @return {Promise} resolves to a [`BulkWriteOpResult`](https://mongodb.github.io/node-mongodb-native/4.9/classes/BulkWriteResult.html) if the operation succeeds\n * @api public\n */\n\nModel.bulkWrite = async function bulkWrite(ops, options) {\n  _checkContext(this, 'bulkWrite');\n\n  if (typeof options === 'function' ||\n      typeof arguments[2] === 'function') {\n    throw new MongooseError('Model.bulkWrite() no longer accepts a callback');\n  }\n  options = options || {};\n\n  const shouldSkip = await new Promise((resolve, reject) => {\n    this.hooks.execPre('bulkWrite', this, [ops, options], (err) => {\n      if (err != null) {\n        if (err instanceof Kareem.skipWrappedFunction) {\n          return resolve(err);\n        }\n        return reject(err);\n      }\n      resolve();\n    });\n  });\n\n  if (shouldSkip) {\n    return shouldSkip.args[0];\n  }\n\n  const ordered = options.ordered == null ? true : options.ordered;\n\n  if (ops.length === 0) {\n    return getDefaultBulkwriteResult();\n  }\n\n  const validations = ops.map(op => castBulkWrite(this, op, options));\n  const asyncLocalStorage = this.db.base.transactionAsyncLocalStorage?.getStore();\n  if ((!options || !options.hasOwnProperty('session')) && asyncLocalStorage?.session != null) {\n    options = { ...options, session: asyncLocalStorage.session };\n  }\n\n  let res = null;\n  if (ordered) {\n    await new Promise((resolve, reject) => {\n      each(validations, (fn, cb) => fn(cb), error => {\n        if (error) {\n          return reject(error);\n        }\n\n        resolve();\n      });\n    });\n\n    try {\n      res = await this.$__collection.bulkWrite(ops, options);\n    } catch (error) {\n      await new Promise((resolve, reject) => {\n        const _opts = { error: error };\n        this.hooks.execPost('bulkWrite', this, [null], _opts, (err) => {\n          if (err != null) {\n            return reject(err);\n          }\n          resolve();\n        });\n      });\n    }\n  } else {\n    let remaining = validations.length;\n    let validOps = [];\n    let validationErrors = [];\n    const results = [];\n    await new Promise((resolve) => {\n      for (let i = 0; i < validations.length; ++i) {\n        validations[i]((err) => {\n          if (err == null) {\n            validOps.push(i);\n          } else {\n            validationErrors.push({ index: i, error: err });\n            results[i] = err;\n          }\n          if (--remaining <= 0) {\n            resolve();\n          }\n        });\n      }\n    });\n\n    validationErrors = validationErrors.\n      sort((v1, v2) => v1.index - v2.index).\n      map(v => v.error);\n\n    const validOpIndexes = validOps;\n    validOps = validOps.sort().map(index => ops[index]);\n\n    if (validOps.length === 0) {\n      if (options.throwOnValidationError && validationErrors.length) {\n        throw new MongooseBulkWriteError(\n          validationErrors,\n          results,\n          res,\n          'bulkWrite'\n        );\n      }\n      return getDefaultBulkwriteResult();\n    }\n\n    let error;\n    [res, error] = await this.$__collection.bulkWrite(validOps, options).\n      then(res => ([res, null])).\n      catch(err => ([null, err]));\n\n    if (error) {\n      if (validationErrors.length > 0) {\n        error.mongoose = error.mongoose || {};\n        error.mongoose.validationErrors = validationErrors;\n      }\n\n      await new Promise((resolve, reject) => {\n        const _opts = { error: error };\n        this.hooks.execPost('bulkWrite', this, [null], _opts, (err) => {\n          if (err != null) {\n            return reject(err);\n          }\n          resolve();\n        });\n      });\n    }\n\n    for (let i = 0; i < validOpIndexes.length; ++i) {\n      results[validOpIndexes[i]] = null;\n    }\n    if (validationErrors.length > 0) {\n      if (options.throwOnValidationError) {\n        throw new MongooseBulkWriteError(\n          validationErrors,\n          results,\n          res,\n          'bulkWrite'\n        );\n      } else {\n        res.mongoose = res.mongoose || {};\n        res.mongoose.validationErrors = validationErrors;\n        res.mongoose.results = results;\n      }\n    }\n  }\n\n  await new Promise((resolve, reject) => {\n    this.hooks.execPost('bulkWrite', this, [res], (err) => {\n      if (err != null) {\n        return reject(err);\n      }\n      resolve();\n    });\n  });\n\n  return res;\n};\n\n/**\n *  takes an array of documents, gets the changes and inserts/updates documents in the database\n *  according to whether or not the document is new, or whether it has changes or not.\n *\n * `bulkSave` uses `bulkWrite` under the hood, so it's mostly useful when dealing with many documents (10K+)\n *\n * @param {Array<Document>} documents\n * @param {Object} [options] options passed to the underlying `bulkWrite()`\n * @param {Boolean} [options.timestamps] defaults to `null`, when set to false, mongoose will not add/update timestamps to the documents.\n * @param {ClientSession} [options.session=null] The session associated with this bulk write. See [transactions docs](https://mongoosejs.com/docs/transactions.html).\n * @param {String|number} [options.w=1] The [write concern](https://www.mongodb.com/docs/manual/reference/write-concern/). See [`Query#w()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.w()) for more information.\n * @param {number} [options.wtimeout=null] The [write concern timeout](https://www.mongodb.com/docs/manual/reference/write-concern/#wtimeout).\n * @param {Boolean} [options.j=true] If false, disable [journal acknowledgement](https://www.mongodb.com/docs/manual/reference/write-concern/#j-option)\n *\n */\nModel.bulkSave = async function bulkSave(documents, options) {\n  options = options || {};\n\n  if (options.timestamps != null) {\n    for (const document of documents) {\n      document.$__.saveOptions = document.$__.saveOptions || {};\n      document.$__.saveOptions.timestamps = options.timestamps;\n    }\n  } else {\n    for (const document of documents) {\n      if (document.$__.timestamps != null) {\n        document.$__.saveOptions = document.$__.saveOptions || {};\n        document.$__.saveOptions.timestamps = document.$__.timestamps;\n      }\n    }\n  }\n\n  await Promise.all(documents.map(buildPreSavePromise));\n\n  const writeOperations = this.buildBulkWriteOperations(documents, { skipValidation: true, timestamps: options.timestamps });\n\n  const { bulkWriteResult, bulkWriteError } = await this.bulkWrite(writeOperations, options).then(\n    (res) => ({ bulkWriteResult: res, bulkWriteError: null }),\n    (err) => ({ bulkWriteResult: null, bulkWriteError: err })\n  );\n\n  await Promise.all(\n    documents.map(async(document) => {\n      const documentError = bulkWriteError && bulkWriteError.writeErrors.find(writeError => {\n        const writeErrorDocumentId = writeError.err.op._id || writeError.err.op.q._id;\n        return writeErrorDocumentId.toString() === document._id.toString();\n      });\n\n      if (documentError == null) {\n        await handleSuccessfulWrite(document);\n      }\n    })\n  );\n\n  if (bulkWriteError && bulkWriteError.writeErrors && bulkWriteError.writeErrors.length) {\n    throw bulkWriteError;\n  }\n\n  return bulkWriteResult;\n};\n\nfunction buildPreSavePromise(document) {\n  return new Promise((resolve, reject) => {\n    document.schema.s.hooks.execPre('save', document, (err) => {\n      if (err) {\n        reject(err);\n        return;\n      }\n      resolve();\n    });\n  });\n}\n\nfunction handleSuccessfulWrite(document) {\n  return new Promise((resolve, reject) => {\n    if (document.$isNew) {\n      _setIsNew(document, false);\n    }\n\n    document.$__reset();\n    document.schema.s.hooks.execPost('save', document, [document], {}, (err) => {\n      if (err) {\n        reject(err);\n        return;\n      }\n      resolve();\n    });\n\n  });\n}\n\n/**\n * Apply defaults to the given document or POJO.\n *\n * @param {Object|Document} obj object or document to apply defaults on\n * @returns {Object|Document}\n * @api public\n */\n\nModel.applyDefaults = function applyDefaults(doc) {\n  if (doc.$__ != null) {\n    applyDefaultsHelper(doc, doc.$__.fields, doc.$__.exclude);\n\n    for (const subdoc of doc.$getAllSubdocs()) {\n      applyDefaults(subdoc, subdoc.$__.fields, subdoc.$__.exclude);\n    }\n\n    return doc;\n  }\n\n  applyDefaultsToPOJO(doc, this.schema);\n\n  return doc;\n};\n\n/**\n * Cast the given POJO to the model's schema\n *\n * #### Example:\n *\n *     const Test = mongoose.model('Test', Schema({ num: Number }));\n *\n *     const obj = Test.castObject({ num: '42' });\n *     obj.num; // 42 as a number\n *\n *     Test.castObject({ num: 'not a number' }); // Throws a ValidationError\n *\n * @param {Object} obj object or document to cast\n * @param {Object} options options passed to castObject\n * @param {Boolean} options.ignoreCastErrors If set to `true` will not throw a ValidationError and only return values that were successfully cast.\n * @returns {Object} POJO casted to the model's schema\n * @throws {ValidationError} if casting failed for at least one path\n * @api public\n */\n\nModel.castObject = function castObject(obj, options) {\n  options = options || {};\n  const ret = {};\n\n  const schema = this.schema;\n  const paths = Object.keys(schema.paths);\n\n  for (const path of paths) {\n    const schemaType = schema.path(path);\n    if (!schemaType || !schemaType.$isMongooseArray) {\n      continue;\n    }\n\n    const val = get(obj, path);\n    pushNestedArrayPaths(paths, val, path);\n  }\n\n  let error = null;\n\n  for (const path of paths) {\n    const schemaType = schema.path(path);\n    if (schemaType == null) {\n      continue;\n    }\n\n    let val = get(obj, path, void 0);\n\n    if (val == null) {\n      continue;\n    }\n\n    const pieces = path.indexOf('.') === -1 ? [path] : path.split('.');\n    let cur = ret;\n    for (let i = 0; i < pieces.length - 1; ++i) {\n      if (cur[pieces[i]] == null) {\n        cur[pieces[i]] = isNaN(pieces[i + 1]) ? {} : [];\n      }\n      cur = cur[pieces[i]];\n    }\n\n    if (schemaType.$isMongooseDocumentArray) {\n      continue;\n    }\n    if (schemaType.$isSingleNested || schemaType.$isMongooseDocumentArrayElement) {\n      try {\n        val = Model.castObject.call(schemaType.caster, val);\n      } catch (err) {\n        if (!options.ignoreCastErrors) {\n          error = error || new ValidationError();\n          error.addError(path, err);\n        }\n        continue;\n      }\n\n      cur[pieces[pieces.length - 1]] = val;\n      continue;\n    }\n\n    try {\n      val = schemaType.cast(val);\n      cur[pieces[pieces.length - 1]] = val;\n    } catch (err) {\n      if (!options.ignoreCastErrors) {\n        error = error || new ValidationError();\n        error.addError(path, err);\n      }\n\n      continue;\n    }\n  }\n\n  if (error != null) {\n    throw error;\n  }\n\n  return ret;\n};\n\n/**\n * Build bulk write operations for `bulkSave()`.\n *\n * @param {Array<Document>} documents The array of documents to build write operations of\n * @param {Object} options\n * @param {Boolean} options.skipValidation defaults to `false`, when set to true, building the write operations will bypass validating the documents.\n * @param {Boolean} options.timestamps defaults to `null`, when set to false, mongoose will not add/update timestamps to the documents.\n * @return {Array<Promise>} Returns a array of all Promises the function executes to be awaited.\n * @api private\n */\n\nModel.buildBulkWriteOperations = function buildBulkWriteOperations(documents, options) {\n  if (!Array.isArray(documents)) {\n    throw new Error(`bulkSave expects an array of documents to be passed, received \\`${documents}\\` instead`);\n  }\n\n  setDefaultOptions();\n  const discriminatorKey = this.schema.options.discriminatorKey;\n\n  const writeOperations = documents.reduce((accumulator, document, i) => {\n    if (!options.skipValidation) {\n      if (!(document instanceof Document)) {\n        throw new Error(`documents.${i} was not a mongoose document, documents must be an array of mongoose documents (instanceof mongoose.Document).`);\n      }\n      const validationError = document.validateSync();\n      if (validationError) {\n        throw validationError;\n      }\n    }\n\n    const isANewDocument = document.isNew;\n    if (isANewDocument) {\n      const writeOperation = { insertOne: { document } };\n      utils.injectTimestampsOption(writeOperation.insertOne, options.timestamps);\n      accumulator.push(writeOperation);\n\n      return accumulator;\n    }\n\n    const delta = document.$__delta();\n    const isDocumentWithChanges = delta != null && !utils.isEmptyObject(delta[0]);\n\n    if (isDocumentWithChanges) {\n      const where = document.$__where(delta[0]);\n      const changes = delta[1];\n\n      _applyCustomWhere(document, where);\n\n      // If shard key is set, add shard keys to _filter_ condition to right shard is targeted\n      const shardKey = this.schema.options.shardKey;\n      if (shardKey) {\n        const paths = Object.keys(shardKey);\n        const len = paths.length;\n\n        for (let i = 0; i < len; ++i) {\n          where[paths[i]] = document[paths[i]];\n        }\n      }\n\n      // Set the discriminator key, so bulk write casting knows which\n      // schema to use re: gh-13907\n      if (document[discriminatorKey] != null && !(discriminatorKey in where)) {\n        where[discriminatorKey] = document[discriminatorKey];\n      }\n\n      document.$__version(where, delta);\n      const writeOperation = { updateOne: { filter: where, update: changes } };\n      utils.injectTimestampsOption(writeOperation.updateOne, options.timestamps);\n      accumulator.push(writeOperation);\n\n      return accumulator;\n    }\n\n    return accumulator;\n  }, []);\n\n  return writeOperations;\n\n\n  function setDefaultOptions() {\n    options = options || {};\n    if (options.skipValidation == null) {\n      options.skipValidation = false;\n    }\n  }\n};\n\n\n/**\n * Shortcut for creating a new Document from existing raw data, pre-saved in the DB.\n * The document returned has no paths marked as modified initially.\n *\n * #### Example:\n *\n *     // hydrate previous data into a Mongoose document\n *     const mongooseCandy = Candy.hydrate({ _id: '54108337212ffb6d459f854c', type: 'jelly bean' });\n *\n * @param {Object} obj\n * @param {Object|String|String[]} [projection] optional projection containing which fields should be selected for this document\n * @param {Object} [options] optional options\n * @param {Boolean} [options.setters=false] if true, apply schema setters when hydrating\n * @param {Boolean} [options.hydratedPopulatedDocs=false] if true, populates the docs if passing pre-populated data\n * @return {Document} document instance\n * @api public\n */\n\nModel.hydrate = function(obj, projection, options) {\n  _checkContext(this, 'hydrate');\n\n  if (projection != null) {\n    if (obj != null && obj.$__ != null) {\n      obj = obj.toObject(internalToObjectOptions);\n    }\n    obj = applyProjection(obj, projection);\n  }\n  const document = (__webpack_require__(/*! ./queryHelpers */ \"./node_modules/mongoose/lib/queryHelpers.js\").createModel)(this, obj, projection);\n  document.$init(obj, options);\n  return document;\n};\n\n/**\n * Same as `updateOne()`, except MongoDB will update _all_ documents that match\n * `filter` (as opposed to just the first one) regardless of the value of\n * the `multi` option.\n *\n * **Note** updateMany will _not_ fire update middleware. Use `pre('updateMany')`\n * and `post('updateMany')` instead.\n *\n * #### Example:\n *\n *     const res = await Person.updateMany({ name: /Stark$/ }, { isDeleted: true });\n *     res.matchedCount; // Number of documents matched\n *     res.modifiedCount; // Number of documents modified\n *     res.acknowledged; // Boolean indicating everything went smoothly.\n *     res.upsertedId; // null or an id containing a document that had to be upserted.\n *     res.upsertedCount; // Number indicating how many documents had to be upserted. Will either be 0 or 1.\n *\n * This function triggers the following middleware.\n *\n * - `updateMany()`\n *\n * @param {Object} filter\n * @param {Object|Array} update. If array, this update will be treated as an update pipeline and not casted.\n * @param {Object} [options] optional see [`Query.prototype.setOptions()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.setOptions())\n * @param {Boolean|String} [options.strict] overwrites the schema's [strict mode option](https://mongoosejs.com/docs/guide.html#strict)\n * @param {Boolean} [options.upsert=false] if true, and no documents found, insert a new document\n * @param {Object} [options.writeConcern=null] sets the [write concern](https://www.mongodb.com/docs/manual/reference/write-concern/) for replica sets. Overrides the [schema-level write concern](https://mongoosejs.com/docs/guide.html#writeConcern)\n * @param {Boolean} [options.timestamps=null] If set to `false` and [schema-level timestamps](https://mongoosejs.com/docs/guide.html#timestamps) are enabled, skip timestamps for this update. Does nothing if schema-level timestamps are not set.\n * @param {Boolean} [options.translateAliases=null] If set to `true`, translates any schema-defined aliases in `filter`, `projection`, `update`, and `distinct`. Throws an error if there are any conflicts where both alias and raw property are defined on the same object.\n * @param {Boolean} [options.overwriteDiscriminatorKey=false] Mongoose removes discriminator key updates from `update` by default, set `overwriteDiscriminatorKey` to `true` to allow updating the discriminator key\n * @return {Query}\n * @see Query docs https://mongoosejs.com/docs/queries.html\n * @see MongoDB docs https://www.mongodb.com/docs/manual/reference/command/update/#update-command-output\n * @see UpdateResult https://mongodb.github.io/node-mongodb-native/4.9/interfaces/UpdateResult.html\n * @api public\n */\n\nModel.updateMany = function updateMany(conditions, doc, options) {\n  _checkContext(this, 'updateMany');\n\n  return _update(this, 'updateMany', conditions, doc, options);\n};\n\n/**\n * Update _only_ the first document that matches `filter`.\n *\n * - Use `replaceOne()` if you want to overwrite an entire document rather than using atomic operators like `$set`.\n *\n * #### Example:\n *\n *     const res = await Person.updateOne({ name: 'Jean-Luc Picard' }, { ship: 'USS Enterprise' });\n *     res.matchedCount; // Number of documents matched\n *     res.modifiedCount; // Number of documents modified\n *     res.acknowledged; // Boolean indicating everything went smoothly.\n *     res.upsertedId; // null or an id containing a document that had to be upserted.\n *     res.upsertedCount; // Number indicating how many documents had to be upserted. Will either be 0 or 1.\n *\n * This function triggers the following middleware.\n *\n * - `updateOne()`\n *\n * @param {Object} filter\n * @param {Object|Array} update. If array, this update will be treated as an update pipeline and not casted.\n * @param {Object} [options] optional see [`Query.prototype.setOptions()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.setOptions())\n * @param {Boolean|String} [options.strict] overwrites the schema's [strict mode option](https://mongoosejs.com/docs/guide.html#strict)\n * @param {Boolean} [options.upsert=false] if true, and no documents found, insert a new document\n * @param {Object} [options.writeConcern=null] sets the [write concern](https://www.mongodb.com/docs/manual/reference/write-concern/) for replica sets. Overrides the [schema-level write concern](https://mongoosejs.com/docs/guide.html#writeConcern)\n * @param {Boolean} [options.timestamps=null] If set to `false` and [schema-level timestamps](https://mongoosejs.com/docs/guide.html#timestamps) are enabled, skip timestamps for this update. Note that this allows you to overwrite timestamps. Does nothing if schema-level timestamps are not set.\n * @param {Boolean} [options.translateAliases=null] If set to `true`, translates any schema-defined aliases in `filter`, `projection`, `update`, and `distinct`. Throws an error if there are any conflicts where both alias and raw property are defined on the same object.\n * @param {Boolean} [options.overwriteDiscriminatorKey=false] Mongoose removes discriminator key updates from `update` by default, set `overwriteDiscriminatorKey` to `true` to allow updating the discriminator key\n * @return {Query}\n * @see Query docs https://mongoosejs.com/docs/queries.html\n * @see MongoDB docs https://www.mongodb.com/docs/manual/reference/command/update/#update-command-output\n * @see UpdateResult https://mongodb.github.io/node-mongodb-native/4.9/interfaces/UpdateResult.html\n * @api public\n */\n\nModel.updateOne = function updateOne(conditions, doc, options) {\n  _checkContext(this, 'updateOne');\n\n  return _update(this, 'updateOne', conditions, doc, options);\n};\n\n/**\n * Replace the existing document with the given document (no atomic operators like `$set`).\n *\n * #### Example:\n *\n *     const res = await Person.replaceOne({ _id: 24601 }, { name: 'Jean Valjean' });\n *     res.matchedCount; // Number of documents matched\n *     res.modifiedCount; // Number of documents modified\n *     res.acknowledged; // Boolean indicating everything went smoothly.\n *     res.upsertedId; // null or an id containing a document that had to be upserted.\n *     res.upsertedCount; // Number indicating how many documents had to be upserted. Will either be 0 or 1.\n *\n * This function triggers the following middleware.\n *\n * - `replaceOne()`\n *\n * @param {Object} filter\n * @param {Object} doc\n * @param {Object} [options] optional see [`Query.prototype.setOptions()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.setOptions())\n * @param {Boolean|String} [options.strict] overwrites the schema's [strict mode option](https://mongoosejs.com/docs/guide.html#strict)\n * @param {Boolean} [options.upsert=false] if true, and no documents found, insert a new document\n * @param {Object} [options.writeConcern=null] sets the [write concern](https://www.mongodb.com/docs/manual/reference/write-concern/) for replica sets. Overrides the [schema-level write concern](https://mongoosejs.com/docs/guide.html#writeConcern)\n * @param {Boolean} [options.timestamps=null] If set to `false` and [schema-level timestamps](https://mongoosejs.com/docs/guide.html#timestamps) are enabled, skip timestamps for this update. Does nothing if schema-level timestamps are not set.\n * @param {Boolean} [options.translateAliases=null] If set to `true`, translates any schema-defined aliases in `filter`, `projection`, `update`, and `distinct`. Throws an error if there are any conflicts where both alias and raw property are defined on the same object.\n * @return {Query}\n * @see Query docs https://mongoosejs.com/docs/queries.html\n * @see UpdateResult https://mongodb.github.io/node-mongodb-native/4.9/interfaces/UpdateResult.html\n * @return {Query}\n * @api public\n */\n\nModel.replaceOne = function replaceOne(conditions, doc, options) {\n  _checkContext(this, 'replaceOne');\n\n  const versionKey = this && this.schema && this.schema.options && this.schema.options.versionKey || null;\n  if (versionKey && !doc[versionKey]) {\n    doc[versionKey] = 0;\n  }\n\n  return _update(this, 'replaceOne', conditions, doc, options);\n};\n\n/**\n * Common code for `updateOne()`, `updateMany()`, `replaceOne()`, and `update()`\n * because they need to do the same thing\n * @api private\n */\n\nfunction _update(model, op, conditions, doc, options) {\n  const mq = new model.Query({}, {}, model, model.collection);\n\n  // gh-2406\n  // make local deep copy of conditions\n  if (conditions instanceof Document) {\n    conditions = conditions.toObject();\n  } else {\n    conditions = clone(conditions);\n  }\n  options = typeof options === 'function' ? options : clone(options);\n\n  const versionKey = model &&\n  model.schema &&\n  model.schema.options &&\n  model.schema.options.versionKey || null;\n  decorateUpdateWithVersionKey(doc, options, versionKey);\n\n  return mq[op](conditions, doc, options);\n}\n\n/**\n * Performs [aggregations](https://www.mongodb.com/docs/manual/aggregation/) on the models collection.\n *\n * If a `callback` is passed, the `aggregate` is executed and a `Promise` is returned. If a callback is not passed, the `aggregate` itself is returned.\n *\n * This function triggers the following middleware.\n *\n * - `aggregate()`\n *\n * #### Example:\n *\n *     // Find the max balance of all accounts\n *     const res = await Users.aggregate([\n *       { $group: { _id: null, maxBalance: { $max: '$balance' }}},\n *       { $project: { _id: 0, maxBalance: 1 }}\n *     ]);\n *\n *     console.log(res); // [ { maxBalance: 98000 } ]\n *\n *     // Or use the aggregation pipeline builder.\n *     const res = await Users.aggregate().\n *       group({ _id: null, maxBalance: { $max: '$balance' } }).\n *       project('-id maxBalance').\n *       exec();\n *     console.log(res); // [ { maxBalance: 98 } ]\n *\n * #### Note:\n *\n * - Mongoose does **not** cast aggregation pipelines to the model's schema because `$project` and `$group` operators allow redefining the \"shape\" of the documents at any stage of the pipeline, which may leave documents in an incompatible format. You can use the [mongoose-cast-aggregation plugin](https://github.com/AbdelrahmanHafez/mongoose-cast-aggregation) to enable minimal casting for aggregation pipelines.\n * - The documents returned are plain javascript objects, not mongoose documents (since any shape of document can be returned).\n *\n * #### More About Aggregations:\n *\n * - [Mongoose `Aggregate`](https://mongoosejs.com/docs/api/aggregate.html)\n * - [An Introduction to Mongoose Aggregate](https://masteringjs.io/tutorials/mongoose/aggregate)\n * - [MongoDB Aggregation docs](https://www.mongodb.com/docs/manual/applications/aggregation/)\n *\n * @see Aggregate https://mongoosejs.com/docs/api/aggregate.html#Aggregate()\n * @see MongoDB https://www.mongodb.com/docs/manual/applications/aggregation/\n * @param {Array} [pipeline] aggregation pipeline as an array of objects\n * @param {Object} [options] aggregation options\n * @return {Aggregate}\n * @api public\n */\n\nModel.aggregate = function aggregate(pipeline, options) {\n  _checkContext(this, 'aggregate');\n\n  if (typeof options === 'function' || typeof arguments[2] === 'function') {\n    throw new MongooseError('Model.aggregate() no longer accepts a callback');\n  }\n\n  const aggregate = new Aggregate(pipeline || []);\n  aggregate.model(this);\n  if (options != null) {\n    aggregate.option(options);\n  }\n\n  if (typeof callback === 'undefined') {\n    return aggregate;\n  }\n\n  return aggregate;\n};\n\n/**\n * Casts and validates the given object against this model's schema, passing the\n * given `context` to custom validators.\n *\n * #### Example:\n *\n *     const Model = mongoose.model('Test', Schema({\n *       name: { type: String, required: true },\n *       age: { type: Number, required: true }\n *     });\n *\n *     try {\n *       await Model.validate({ name: null }, ['name'])\n *     } catch (err) {\n *       err instanceof mongoose.Error.ValidationError; // true\n *       Object.keys(err.errors); // ['name']\n *     }\n *\n * @param {Object} obj\n * @param {Object|Array|String} pathsOrOptions\n * @param {Object} [context]\n * @return {Promise<Object>} casted and validated copy of `obj` if validation succeeded\n * @api public\n */\n\nModel.validate = async function validate(obj, pathsOrOptions, context) {\n  if ((arguments.length < 3) || (arguments.length === 3 && typeof arguments[2] === 'function')) {\n    // For convenience, if we're validating a document or an object, make `context` default to\n    // the model so users don't have to always pass `context`, re: gh-10132, gh-10346\n    context = obj;\n  }\n  if (typeof context === 'function' || typeof arguments[3] === 'function') {\n    throw new MongooseError('Model.validate() no longer accepts a callback');\n  }\n\n  let schema = this.schema;\n  const discriminatorKey = schema.options.discriminatorKey;\n  if (schema.discriminators != null && obj != null && obj[discriminatorKey] != null) {\n    schema = getSchemaDiscriminatorByValue(schema, obj[discriminatorKey]) || schema;\n  }\n  let paths = Object.keys(schema.paths);\n\n  if (pathsOrOptions != null) {\n    const _pathsToValidate = typeof pathsOrOptions === 'string' ? new Set(pathsOrOptions.split(' ')) : Array.isArray(pathsOrOptions) ? new Set(pathsOrOptions) : new Set(paths);\n    paths = paths.filter(p => {\n      if (pathsOrOptions.pathsToSkip) {\n        if (Array.isArray(pathsOrOptions.pathsToSkip)) {\n          if (pathsOrOptions.pathsToSkip.find(x => x == p)) {\n            return false;\n          }\n        } else if (typeof pathsOrOptions.pathsToSkip == 'string') {\n          if (pathsOrOptions.pathsToSkip.includes(p)) {\n            return false;\n          }\n        }\n      }\n      const pieces = p.split('.');\n      let cur = pieces[0];\n\n      for (const piece of pieces) {\n        if (_pathsToValidate.has(cur)) {\n          return true;\n        }\n        cur += '.' + piece;\n      }\n\n      return _pathsToValidate.has(p);\n    });\n  }\n\n  for (const path of paths) {\n    const schemaType = schema.path(path);\n    if (!schemaType || !schemaType.$isMongooseArray || schemaType.$isMongooseDocumentArray) {\n      continue;\n    }\n\n    const val = get(obj, path);\n    pushNestedArrayPaths(paths, val, path);\n  }\n\n  let error = null;\n  paths = new Set(paths);\n\n  try {\n    obj = this.castObject(obj);\n  } catch (err) {\n    error = err;\n    for (const key of Object.keys(error.errors || {})) {\n      paths.delete(key);\n    }\n  }\n\n  let remaining = paths.size;\n\n  return new Promise((resolve, reject) => {\n    for (const path of paths) {\n      const schemaType = schema.path(path);\n      if (schemaType == null) {\n        _checkDone();\n        continue;\n      }\n\n      const pieces = path.indexOf('.') === -1 ? [path] : path.split('.');\n      let cur = obj;\n      for (let i = 0; i < pieces.length - 1; ++i) {\n        cur = cur[pieces[i]];\n      }\n\n      const val = get(obj, path, void 0);\n\n      schemaType.doValidate(val, err => {\n        if (err) {\n          error = error || new ValidationError();\n          error.addError(path, err);\n        }\n        _checkDone();\n      }, context, { path: path });\n    }\n\n    function _checkDone() {\n      if (--remaining <= 0) {\n        if (error) {\n          reject(error);\n        } else {\n          resolve(obj);\n        }\n      }\n    }\n  });\n};\n\n/**\n * Populates document references.\n *\n * Changed in Mongoose 6: the model you call `populate()` on should be the\n * \"local field\" model, **not** the \"foreign field\" model.\n *\n * #### Available top-level options:\n *\n * - path: space delimited path(s) to populate\n * - select: optional fields to select\n * - match: optional query conditions to match\n * - model: optional name of the model to use for population\n * - options: optional query options like sort, limit, etc\n * - justOne: optional boolean, if true Mongoose will always set `path` to a document, or `null` if no document was found. If false, Mongoose will always set `path` to an array, which will be empty if no documents are found. Inferred from schema by default.\n * - strictPopulate: optional boolean, set to `false` to allow populating paths that aren't in the schema.\n *\n * #### Example:\n *\n *     const Dog = mongoose.model('Dog', new Schema({ name: String, breed: String }));\n *     const Person = mongoose.model('Person', new Schema({\n *       name: String,\n *       pet: { type: mongoose.ObjectId, ref: 'Dog' }\n *     }));\n *\n *     const pets = await Pet.create([\n *       { name: 'Daisy', breed: 'Beagle' },\n *       { name: 'Einstein', breed: 'Catalan Sheepdog' }\n *     ]);\n *\n *     // populate many plain objects\n *     const users = [\n *       { name: 'John Wick', dog: pets[0]._id },\n *       { name: 'Doc Brown', dog: pets[1]._id }\n *     ];\n *     await User.populate(users, { path: 'dog', select: 'name' });\n *     users[0].dog.name; // 'Daisy'\n *     users[0].dog.breed; // undefined because of `select`\n *\n * @param {Document|Array} docs Either a single document or array of documents to populate.\n * @param {Object|String} options Either the paths to populate or an object specifying all parameters\n * @param {string} [options.path=null] The path to populate.\n * @param {string|PopulateOptions} [options.populate=null] Recursively populate paths in the populated documents. See [deep populate docs](https://mongoosejs.com/docs/populate.html#deep-populate).\n * @param {boolean} [options.retainNullValues=false] By default, Mongoose removes null and undefined values from populated arrays. Use this option to make `populate()` retain `null` and `undefined` array entries.\n * @param {boolean} [options.getters=false] If true, Mongoose will call any getters defined on the `localField`. By default, Mongoose gets the raw value of `localField`. For example, you would need to set this option to `true` if you wanted to [add a `lowercase` getter to your `localField`](https://mongoosejs.com/docs/schematypes.html#schematype-options).\n * @param {boolean} [options.clone=false] When you do `BlogPost.find().populate('author')`, blog posts with the same author will share 1 copy of an `author` doc. Enable this option to make Mongoose clone populated docs before assigning them.\n * @param {Object|Function} [options.match=null] Add an additional filter to the populate query. Can be a filter object containing [MongoDB query syntax](https://www.mongodb.com/docs/manual/tutorial/query-documents/), or a function that returns a filter object.\n * @param {Boolean} [options.skipInvalidIds=false] By default, Mongoose throws a cast error if `localField` and `foreignField` schemas don't line up. If you enable this option, Mongoose will instead filter out any `localField` properties that cannot be casted to `foreignField`'s schema type.\n * @param {Number} [options.perDocumentLimit=null] For legacy reasons, `limit` with `populate()` may give incorrect results because it only executes a single query for every document being populated. If you set `perDocumentLimit`, Mongoose will ensure correct `limit` per document by executing a separate query for each document to `populate()`. For example, `.find().populate({ path: 'test', perDocumentLimit: 2 })` will execute 2 additional queries if `.find()` returns 2 documents.\n * @param {Boolean} [options.strictPopulate=true] Set to false to allow populating paths that aren't defined in the given model's schema.\n * @param {Object} [options.options=null] Additional options like `limit` and `lean`.\n * @param {Function} [options.transform=null] Function that Mongoose will call on every populated document that allows you to transform the populated document.\n * @param {Function} [callback(err,doc)] Optional callback, executed upon completion. Receives `err` and the `doc(s)`.\n * @return {Promise}\n * @api public\n */\n\nModel.populate = async function populate(docs, paths) {\n  _checkContext(this, 'populate');\n  if (typeof paths === 'function' || typeof arguments[2] === 'function') {\n    throw new MongooseError('Model.populate() no longer accepts a callback');\n  }\n  const _this = this;\n  // normalized paths\n  paths = utils.populate(paths);\n  // data that should persist across subPopulate calls\n  const cache = {};\n\n  return new Promise((resolve, reject) => {\n    _populate(_this, docs, paths, cache, (err, res) => {\n      if (err) {\n        return reject(err);\n      }\n      resolve(res);\n    });\n  });\n};\n\n/**\n * Populate helper\n *\n * @param {Model} model the model to use\n * @param {Document|Array} docs Either a single document or array of documents to populate.\n * @param {Object} paths\n * @param {never} cache Unused\n * @param {Function} [callback] Optional callback, executed upon completion. Receives `err` and the `doc(s)`.\n * @return {Function}\n * @api private\n */\n\nfunction _populate(model, docs, paths, cache, callback) {\n  let pending = paths.length;\n  if (paths.length === 0) {\n    return callback(null, docs);\n  }\n  // each path has its own query options and must be executed separately\n  for (const path of paths) {\n    populate(model, docs, path, next);\n  }\n\n  function next(err) {\n    if (err) {\n      return callback(err, null);\n    }\n    if (--pending) {\n      return;\n    }\n    callback(null, docs);\n  }\n}\n\n/*!\n * Populates `docs`\n */\nconst excludeIdReg = /\\s?-_id\\s?/;\nconst excludeIdRegGlobal = /\\s?-_id\\s?/g;\n\nfunction populate(model, docs, options, callback) {\n  const populateOptions = options;\n  if (options.strictPopulate == null) {\n    if (options._localModel != null && options._localModel.schema._userProvidedOptions.strictPopulate != null) {\n      populateOptions.strictPopulate = options._localModel.schema._userProvidedOptions.strictPopulate;\n    } else if (options._localModel != null && model.base.options.strictPopulate != null) {\n      populateOptions.strictPopulate = model.base.options.strictPopulate;\n    } else if (model.base.options.strictPopulate != null) {\n      populateOptions.strictPopulate = model.base.options.strictPopulate;\n    }\n  }\n\n  // normalize single / multiple docs passed\n  if (!Array.isArray(docs)) {\n    docs = [docs];\n  }\n  if (docs.length === 0 || docs.every(utils.isNullOrUndefined)) {\n    return callback();\n  }\n\n  const modelsMap = getModelsMapForPopulate(model, docs, populateOptions);\n\n  if (modelsMap instanceof MongooseError) {\n    return immediate(function() {\n      callback(modelsMap);\n    });\n  }\n  const len = modelsMap.length;\n  let vals = [];\n\n  function flatten(item) {\n    // no need to include undefined values in our query\n    return undefined !== item;\n  }\n\n  let _remaining = len;\n  let hasOne = false;\n  const params = [];\n  for (let i = 0; i < len; ++i) {\n    const mod = modelsMap[i];\n    let select = mod.options.select;\n    let ids = utils.array.flatten(mod.ids, flatten);\n    ids = utils.array.unique(ids);\n\n    const assignmentOpts = {};\n    assignmentOpts.sort = mod &&\n      mod.options &&\n      mod.options.options &&\n      mod.options.options.sort || void 0;\n    assignmentOpts.excludeId = excludeIdReg.test(select) || (select && select._id === 0);\n\n    // Lean transform may delete `_id`, which would cause assignment\n    // to fail. So delay running lean transform until _after_\n    // `_assign()`\n    if (mod.options &&\n        mod.options.options &&\n        mod.options.options.lean &&\n        mod.options.options.lean.transform) {\n      mod.options.options._leanTransform = mod.options.options.lean.transform;\n      mod.options.options.lean = true;\n    }\n\n    if (ids.length === 0 || ids.every(utils.isNullOrUndefined)) {\n      // Ensure that we set to 0 or empty array even\n      // if we don't actually execute a query to make sure there's a value\n      // and we know this path was populated for future sets. See gh-7731, gh-8230\n      --_remaining;\n      _assign(model, [], mod, assignmentOpts);\n      continue;\n    }\n\n    hasOne = true;\n    if (typeof populateOptions.foreignField === 'string') {\n      mod.foreignField.clear();\n      mod.foreignField.add(populateOptions.foreignField);\n    }\n    const match = createPopulateQueryFilter(ids, mod.match, mod.foreignField, mod.model, mod.options.skipInvalidIds);\n    if (assignmentOpts.excludeId) {\n      // override the exclusion from the query so we can use the _id\n      // for document matching during assignment. we'll delete the\n      // _id back off before returning the result.\n      if (typeof select === 'string') {\n        select = select.replace(excludeIdRegGlobal, ' ');\n      } else if (Array.isArray(select)) {\n        select = select.filter(field => field !== '-_id');\n      } else {\n        // preserve original select conditions by copying\n        select = { ...select };\n        delete select._id;\n      }\n    }\n\n    if (mod.options.options && mod.options.options.limit != null) {\n      assignmentOpts.originalLimit = mod.options.options.limit;\n    } else if (mod.options.limit != null) {\n      assignmentOpts.originalLimit = mod.options.limit;\n    }\n    params.push([mod, match, select, assignmentOpts, _next]);\n  }\n  if (!hasOne) {\n    // If models but no docs, skip further deep populate.\n    if (modelsMap.length !== 0) {\n      return callback();\n    }\n    // If no models to populate but we have a nested populate,\n    // keep trying, re: gh-8946\n    if (populateOptions.populate != null) {\n      const opts = utils.populate(populateOptions.populate).map(pop => Object.assign({}, pop, {\n        path: populateOptions.path + '.' + pop.path\n      }));\n      model.populate(docs, opts).then(res => { callback(null, res); }, err => { callback(err); });\n      return;\n    }\n    return callback();\n  }\n\n  for (const arr of params) {\n    _execPopulateQuery.apply(null, arr);\n  }\n  function _next(err, valsFromDb) {\n    if (err != null) {\n      return callback(err, null);\n    }\n    vals = vals.concat(valsFromDb);\n    if (--_remaining === 0) {\n      _done();\n    }\n  }\n\n  function _done() {\n    for (const arr of params) {\n      const mod = arr[0];\n      const assignmentOpts = arr[3];\n      for (const val of vals) {\n        mod.options._childDocs.push(val);\n      }\n      try {\n        _assign(model, vals, mod, assignmentOpts);\n      } catch (err) {\n        return callback(err);\n      }\n    }\n\n    for (const arr of params) {\n      removeDeselectedForeignField(arr[0].foreignField, arr[0].options, vals);\n    }\n    for (const arr of params) {\n      const mod = arr[0];\n      if (mod.options && mod.options.options && mod.options.options._leanTransform) {\n        for (const doc of vals) {\n          mod.options.options._leanTransform(doc);\n        }\n      }\n    }\n    callback();\n  }\n}\n\n/*!\n * ignore\n */\n\nfunction _execPopulateQuery(mod, match, select, assignmentOpts, callback) {\n  let subPopulate = clone(mod.options.populate);\n  const queryOptions = Object.assign({\n    skip: mod.options.skip,\n    limit: mod.options.limit,\n    perDocumentLimit: mod.options.perDocumentLimit\n  }, mod.options.options);\n\n  if (mod.count) {\n    delete queryOptions.skip;\n  }\n\n  if (queryOptions.perDocumentLimit != null) {\n    queryOptions.limit = queryOptions.perDocumentLimit;\n    delete queryOptions.perDocumentLimit;\n  } else if (queryOptions.limit != null) {\n    queryOptions.limit = queryOptions.limit * mod.ids.length;\n  }\n\n  const query = mod.model.find(match, select, queryOptions);\n  // If we're doing virtual populate and projection is inclusive and foreign\n  // field is not selected, automatically select it because mongoose needs it.\n  // If projection is exclusive and client explicitly unselected the foreign\n  // field, that's the client's fault.\n  for (const foreignField of mod.foreignField) {\n    if (foreignField !== '_id' &&\n        query.selectedInclusively() &&\n        !isPathSelectedInclusive(query._fields, foreignField)) {\n      query.select(foreignField);\n    }\n  }\n\n  // If using count, still need the `foreignField` so we can match counts\n  // to documents, otherwise we would need a separate `count()` for every doc.\n  if (mod.count) {\n    for (const foreignField of mod.foreignField) {\n      query.select(foreignField);\n    }\n  }\n\n  // If we need to sub-populate, call populate recursively\n  if (subPopulate) {\n    // If subpopulating on a discriminator, skip check for non-existent\n    // paths. Because the discriminator may not have the path defined.\n    if (mod.model.baseModelName != null) {\n      if (Array.isArray(subPopulate)) {\n        subPopulate.forEach(pop => { pop.strictPopulate = false; });\n      } else if (typeof subPopulate === 'string') {\n        subPopulate = { path: subPopulate, strictPopulate: false };\n      } else {\n        subPopulate.strictPopulate = false;\n      }\n    }\n    const basePath = mod.options._fullPath || mod.options.path;\n\n    if (Array.isArray(subPopulate)) {\n      for (const pop of subPopulate) {\n        pop._fullPath = basePath + '.' + pop.path;\n      }\n    } else if (typeof subPopulate === 'object') {\n      subPopulate._fullPath = basePath + '.' + subPopulate.path;\n    }\n\n    query.populate(subPopulate);\n  }\n\n  query.exec().then(\n    docs => {\n      for (const val of docs) {\n        leanPopulateMap.set(val, mod.model);\n      }\n      callback(null, docs);\n    },\n    err => {\n      callback(err);\n    }\n  );\n}\n\n/*!\n * ignore\n */\n\nfunction _assign(model, vals, mod, assignmentOpts) {\n  const options = mod.options;\n  const isVirtual = mod.isVirtual;\n  const justOne = mod.justOne;\n  let _val;\n  const lean = options &&\n    options.options &&\n    options.options.lean || false;\n  const len = vals.length;\n  const rawOrder = {};\n  const rawDocs = {};\n  let key;\n  let val;\n\n  // Clone because `assignRawDocsToIdStructure` will mutate the array\n  const allIds = clone(mod.allIds);\n  // optimization:\n  // record the document positions as returned by\n  // the query result.\n  for (let i = 0; i < len; i++) {\n    val = vals[i];\n    if (val == null) {\n      continue;\n    }\n    for (const foreignField of mod.foreignField) {\n      _val = utils.getValue(foreignField, val);\n      if (Array.isArray(_val)) {\n        _val = utils.array.unique(utils.array.flatten(_val));\n\n        for (let __val of _val) {\n          if (__val instanceof Document) {\n            __val = __val._id;\n          }\n          key = String(__val);\n          if (rawDocs[key]) {\n            if (Array.isArray(rawDocs[key])) {\n              rawDocs[key].push(val);\n              rawOrder[key].push(i);\n            } else {\n              rawDocs[key] = [rawDocs[key], val];\n              rawOrder[key] = [rawOrder[key], i];\n            }\n          } else {\n            if (isVirtual && !justOne) {\n              rawDocs[key] = [val];\n              rawOrder[key] = [i];\n            } else {\n              rawDocs[key] = val;\n              rawOrder[key] = i;\n            }\n          }\n        }\n      } else {\n        if (_val instanceof Document) {\n          _val = _val._doc._id;\n        }\n        key = String(_val);\n        if (rawDocs[key]) {\n          if (Array.isArray(rawDocs[key])) {\n            rawDocs[key].push(val);\n            rawOrder[key].push(i);\n          } else if (isVirtual ||\n            rawDocs[key].constructor !== val.constructor ||\n            (rawDocs[key] instanceof Document ? String(rawDocs[key]._doc._id) : String(rawDocs[key]._id)) !== (val instanceof Document ? String(val._doc._id) : String(val._id))) {\n            // May need to store multiple docs with the same id if there's multiple models\n            // if we have discriminators or a ref function. But avoid converting to an array\n            // if we have multiple queries on the same model because of `perDocumentLimit` re: gh-9906\n            rawDocs[key] = [rawDocs[key], val];\n            rawOrder[key] = [rawOrder[key], i];\n          }\n        } else {\n          rawDocs[key] = val;\n          rawOrder[key] = i;\n        }\n      }\n      // flag each as result of population\n      if (!lean) {\n        val.$__.wasPopulated = val.$__.wasPopulated || { value: _val };\n      }\n    }\n  }\n\n  assignVals({\n    originalModel: model,\n    // If virtual, make sure to not mutate original field\n    rawIds: mod.isVirtual ? allIds : mod.allIds,\n    allIds: allIds,\n    unpopulatedValues: mod.unpopulatedValues,\n    foreignField: mod.foreignField,\n    rawDocs: rawDocs,\n    rawOrder: rawOrder,\n    docs: mod.docs,\n    path: options.path,\n    options: assignmentOpts,\n    justOne: mod.justOne,\n    isVirtual: mod.isVirtual,\n    allOptions: mod,\n    populatedModel: mod.model,\n    lean: lean,\n    virtual: mod.virtual,\n    count: mod.count,\n    match: mod.match\n  });\n}\n\n/**\n * Compiler utility.\n *\n * @param {String|Function} name model name or class extending Model\n * @param {Schema} schema\n * @param {String} collectionName\n * @param {Connection} connection\n * @param {Mongoose} base mongoose instance\n * @api private\n */\n\nModel.compile = function compile(name, schema, collectionName, connection, base) {\n  const versioningEnabled = schema.options.versionKey !== false;\n\n  if (versioningEnabled && !schema.paths[schema.options.versionKey]) {\n    // add versioning to top level documents only\n    const o = {};\n    o[schema.options.versionKey] = Number;\n    schema.add(o);\n  }\n  let model;\n  if (typeof name === 'function' && name.prototype instanceof Model) {\n    model = name;\n    name = model.name;\n    schema.loadClass(model, false);\n    model.prototype.$isMongooseModelPrototype = true;\n  } else {\n    // generate new class\n    model = function model(doc, fields, skipId) {\n      model.hooks.execPreSync('createModel', doc);\n      if (!(this instanceof model)) {\n        return new model(doc, fields, skipId);\n      }\n      const discriminatorKey = model.schema.options.discriminatorKey;\n\n      if (model.discriminators == null || doc == null || doc[discriminatorKey] == null) {\n        Model.call(this, doc, fields, skipId);\n        return;\n      }\n\n      // If discriminator key is set, use the discriminator instead (gh-7586)\n      const Discriminator = model.discriminators[doc[discriminatorKey]] ||\n        getDiscriminatorByValue(model.discriminators, doc[discriminatorKey]);\n      if (Discriminator != null) {\n        return new Discriminator(doc, fields, skipId);\n      }\n\n      // Otherwise, just use the top-level model\n      Model.call(this, doc, fields, skipId);\n    };\n  }\n\n  model.hooks = schema.s.hooks.clone();\n  model.base = base;\n  model.modelName = name;\n\n  if (!(model.prototype instanceof Model)) {\n    Object.setPrototypeOf(model, Model);\n    Object.setPrototypeOf(model.prototype, Model.prototype);\n  }\n  model.model = function model(name) {\n    return this.db.model(name);\n  };\n\n  model.db = connection;\n  model.prototype.db = connection;\n  model.prototype[modelDbSymbol] = connection;\n  model.discriminators = model.prototype.discriminators = undefined;\n  model[modelSymbol] = true;\n  model.events = new EventEmitter();\n\n  schema._preCompile();\n\n  const _userProvidedOptions = schema._userProvidedOptions || {};\n\n  const collectionOptions = {\n    schemaUserProvidedOptions: _userProvidedOptions,\n    capped: schema.options.capped,\n    Promise: model.base.Promise,\n    modelName: name\n  };\n  if (schema.options.autoCreate !== void 0) {\n    collectionOptions.autoCreate = schema.options.autoCreate;\n  }\n\n  const collection = connection.collection(\n    collectionName,\n    collectionOptions\n  );\n\n  model.prototype.collection = collection;\n  model.prototype.$collection = collection;\n  model.prototype[modelCollectionSymbol] = collection;\n\n  model.prototype.$__setSchema(schema);\n\n  // apply methods and statics\n  applyMethods(model, schema);\n  applyStatics(model, schema);\n  applyHooks(model, schema);\n  applyStaticHooks(model, schema.s.hooks, schema.statics);\n\n  model.schema = model.prototype.$__schema;\n  model.collection = collection;\n  model.$__collection = collection;\n\n  // Create custom query constructor\n  model.Query = function() {\n    Query.apply(this, arguments);\n  };\n  Object.setPrototypeOf(model.Query.prototype, Query.prototype);\n  model.Query.base = Query.base;\n  model.Query.prototype.constructor = Query;\n  model._applyQueryMiddleware();\n  applyQueryMethods(model, schema.query);\n\n  return model;\n};\n\n/**\n * Update this model to use the new connection, including updating all internal\n * references and creating a new `Collection` instance using the new connection.\n * Not for external use, only used by `setDriver()` to ensure that you can still\n * call `setDriver()` after creating a model using `mongoose.model()`.\n *\n * @param {Connection} newConnection the new connection to use\n * @api private\n */\n\nModel.$__updateConnection = function $__updateConnection(newConnection) {\n  this.db = newConnection;\n  this.prototype.db = newConnection;\n  this.prototype[modelDbSymbol] = newConnection;\n\n  const collection = newConnection.collection(\n    this.collection.collectionName,\n    this.collection.opts\n  );\n\n  this.prototype.collection = collection;\n  this.prototype.$collection = collection;\n  this.prototype[modelCollectionSymbol] = collection;\n\n  this.collection = collection;\n  this.$__collection = collection;\n};\n\n/**\n * Register custom query methods for this model\n *\n * @param {Model} model\n * @param {Schema} schema\n * @api private\n */\n\nfunction applyQueryMethods(model, methods) {\n  for (const i in methods) {\n    model.Query.prototype[i] = methods[i];\n  }\n}\n\n/**\n * Subclass this model with `conn`, `schema`, and `collection` settings.\n *\n * @param {Connection} conn\n * @param {Schema} [schema]\n * @param {String} [collection]\n * @return {Model}\n * @api private\n * @memberOf Model\n * @static\n * @method __subclass\n */\n\nModel.__subclass = function subclass(conn, schema, collection) {\n  // subclass model using this connection and collection name\n  const _this = this;\n\n  const Model = function Model(doc, fields, skipId) {\n    if (!(this instanceof Model)) {\n      return new Model(doc, fields, skipId);\n    }\n    _this.call(this, doc, fields, skipId);\n  };\n\n  Object.setPrototypeOf(Model, _this);\n  Object.setPrototypeOf(Model.prototype, _this.prototype);\n  Model.db = conn;\n  Model.prototype.db = conn;\n  Model.prototype[modelDbSymbol] = conn;\n\n  _this[subclassedSymbol] = _this[subclassedSymbol] || [];\n  _this[subclassedSymbol].push(Model);\n  if (_this.discriminators != null) {\n    Model.discriminators = {};\n    for (const key of Object.keys(_this.discriminators)) {\n      Model.discriminators[key] = _this.discriminators[key].\n        __subclass(_this.db, _this.discriminators[key].schema, collection);\n    }\n  }\n\n  const s = schema && typeof schema !== 'string'\n    ? schema\n    : _this.prototype.$__schema;\n\n  const options = s.options || {};\n  const _userProvidedOptions = s._userProvidedOptions || {};\n\n  if (!collection) {\n    collection = _this.prototype.$__schema.get('collection') ||\n      utils.toCollectionName(_this.modelName, this.base.pluralize());\n  }\n\n  const collectionOptions = {\n    schemaUserProvidedOptions: _userProvidedOptions,\n    capped: s && options.capped\n  };\n\n  Model.prototype.collection = conn.collection(collection, collectionOptions);\n  Model.prototype.$collection = Model.prototype.collection;\n  Model.prototype[modelCollectionSymbol] = Model.prototype.collection;\n  Model.collection = Model.prototype.collection;\n  Model.$__collection = Model.collection;\n  // Errors handled internally, so ignore\n  Model.init().catch(() => {});\n  return Model;\n};\n\n/**\n * Apply changes made to this model's schema after this model was compiled.\n * By default, adding virtuals and other properties to a schema after the model is compiled does nothing.\n * Call this function to apply virtuals and properties that were added later.\n *\n * #### Example:\n *\n *     const schema = new mongoose.Schema({ field: String });\n *     const TestModel = mongoose.model('Test', schema);\n *     TestModel.schema.virtual('myVirtual').get(function() {\n *       return this.field + ' from myVirtual';\n *     });\n *     const doc = new TestModel({ field: 'Hello' });\n *     doc.myVirtual; // undefined\n *\n *     TestModel.recompileSchema();\n *     doc.myVirtual; // 'Hello from myVirtual'\n *\n * @return {undefined}\n * @api public\n * @memberOf Model\n * @static\n * @method recompileSchema\n */\n\nModel.recompileSchema = function recompileSchema() {\n  this.prototype.$__setSchema(this.schema);\n\n  if (this.schema._applyDiscriminators != null) {\n    for (const disc of this.schema._applyDiscriminators.keys()) {\n      this.discriminator(disc, this.schema._applyDiscriminators.get(disc));\n    }\n  }\n\n  delete this.schema._defaultToObjectOptionsMap;\n\n  applyEmbeddedDiscriminators(this.schema, new WeakSet(), true);\n};\n\n/**\n * Helper for console.log. Given a model named 'MyModel', returns the string\n * `'Model { MyModel }'`.\n *\n * #### Example:\n *\n *     const MyModel = mongoose.model('Test', Schema({ name: String }));\n *     MyModel.inspect(); // 'Model { Test }'\n *     console.log(MyModel); // Prints 'Model { Test }'\n *\n * @api public\n */\n\nModel.inspect = function() {\n  return `Model { ${this.modelName} }`;\n};\n\nif (util.inspect.custom) {\n  // Avoid Node deprecation warning DEP0079\n  Model[util.inspect.custom] = Model.inspect;\n}\n\n/*!\n * Applies query middleware from this model's schema to this model's\n * Query constructor.\n */\n\nModel._applyQueryMiddleware = function _applyQueryMiddleware() {\n  const Query = this.Query;\n  const queryMiddleware = this.schema.s.hooks.filter(hook => {\n    const contexts = _getContexts(hook);\n    if (hook.name === 'validate') {\n      return !!contexts.query;\n    }\n    if (hook.name === 'deleteOne' || hook.name === 'updateOne') {\n      return !!contexts.query || Object.keys(contexts).length === 0;\n    }\n    if (hook.query != null || hook.document != null) {\n      return !!hook.query;\n    }\n    return true;\n  });\n\n  Query.prototype._queryMiddleware = queryMiddleware;\n};\n\nfunction _getContexts(hook) {\n  const ret = {};\n  if (hook.hasOwnProperty('query')) {\n    ret.query = hook.query;\n  }\n  if (hook.hasOwnProperty('document')) {\n    ret.document = hook.document;\n  }\n  return ret;\n}\n\n/*!\n * Module exports.\n */\n\nmodule.exports = exports = Model;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/model.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/modifiedPathsSnapshot.js":
/*!************************************************************!*\
  !*** ./node_modules/mongoose/lib/modifiedPathsSnapshot.js ***!
  \************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = class ModifiedPathsSnapshot {\n  constructor(subdocSnapshot, activePaths, version) {\n    this.subdocSnapshot = subdocSnapshot;\n    this.activePaths = activePaths;\n    this.version = version;\n  }\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/modifiedPathsSnapshot.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/mongoose.js":
/*!***********************************************!*\
  !*** ./node_modules/mongoose/lib/mongoose.js ***!
  \***********************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst Document = __webpack_require__(/*! ./document */ \"./node_modules/mongoose/lib/document.js\");\nconst EventEmitter = (__webpack_require__(/*! events */ \"events\").EventEmitter);\nconst Kareem = __webpack_require__(/*! kareem */ \"./node_modules/kareem/index.js\");\nconst Schema = __webpack_require__(/*! ./schema */ \"./node_modules/mongoose/lib/schema.js\");\nconst SchemaType = __webpack_require__(/*! ./schemaType */ \"./node_modules/mongoose/lib/schemaType.js\");\nconst SchemaTypes = __webpack_require__(/*! ./schema/index */ \"./node_modules/mongoose/lib/schema/index.js\");\nconst VirtualType = __webpack_require__(/*! ./virtualType */ \"./node_modules/mongoose/lib/virtualType.js\");\nconst STATES = __webpack_require__(/*! ./connectionState */ \"./node_modules/mongoose/lib/connectionState.js\");\nconst VALID_OPTIONS = __webpack_require__(/*! ./validOptions */ \"./node_modules/mongoose/lib/validOptions.js\");\nconst Types = __webpack_require__(/*! ./types */ \"./node_modules/mongoose/lib/types/index.js\");\nconst Query = __webpack_require__(/*! ./query */ \"./node_modules/mongoose/lib/query.js\");\nconst Model = __webpack_require__(/*! ./model */ \"./node_modules/mongoose/lib/model.js\");\nconst applyPlugins = __webpack_require__(/*! ./helpers/schema/applyPlugins */ \"./node_modules/mongoose/lib/helpers/schema/applyPlugins.js\");\nconst builtinPlugins = __webpack_require__(/*! ./plugins */ \"./node_modules/mongoose/lib/plugins/index.js\");\nconst driver = __webpack_require__(/*! ./driver */ \"./node_modules/mongoose/lib/driver.js\");\nconst legacyPluralize = __webpack_require__(/*! ./helpers/pluralize */ \"./node_modules/mongoose/lib/helpers/pluralize.js\");\nconst utils = __webpack_require__(/*! ./utils */ \"./node_modules/mongoose/lib/utils.js\");\nconst pkg = __webpack_require__(/*! ../package.json */ \"./node_modules/mongoose/package.json\");\nconst cast = __webpack_require__(/*! ./cast */ \"./node_modules/mongoose/lib/cast.js\");\n\nconst Aggregate = __webpack_require__(/*! ./aggregate */ \"./node_modules/mongoose/lib/aggregate.js\");\nconst trusted = (__webpack_require__(/*! ./helpers/query/trusted */ \"./node_modules/mongoose/lib/helpers/query/trusted.js\").trusted);\nconst sanitizeFilter = __webpack_require__(/*! ./helpers/query/sanitizeFilter */ \"./node_modules/mongoose/lib/helpers/query/sanitizeFilter.js\");\nconst isBsonType = __webpack_require__(/*! ./helpers/isBsonType */ \"./node_modules/mongoose/lib/helpers/isBsonType.js\");\nconst MongooseError = __webpack_require__(/*! ./error/mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\nconst SetOptionError = __webpack_require__(/*! ./error/setOptionError */ \"./node_modules/mongoose/lib/error/setOptionError.js\");\nconst applyEmbeddedDiscriminators = __webpack_require__(/*! ./helpers/discriminator/applyEmbeddedDiscriminators */ \"./node_modules/mongoose/lib/helpers/discriminator/applyEmbeddedDiscriminators.js\");\n\nconst defaultMongooseSymbol = Symbol.for('mongoose:default');\nconst defaultConnectionSymbol = Symbol('mongoose:defaultConnection');\n\n__webpack_require__(/*! ./helpers/printJestWarning */ \"./node_modules/mongoose/lib/helpers/printJestWarning.js\");\n\nconst objectIdHexRegexp = /^[0-9A-Fa-f]{24}$/;\n\nconst { AsyncLocalStorage } = __webpack_require__(/*! node:async_hooks */ \"node:async_hooks\");\n\n/**\n * Mongoose constructor.\n *\n * The exports object of the `mongoose` module is an instance of this class.\n * Most apps will only use this one instance.\n *\n * #### Example:\n *\n *     const mongoose = require('mongoose');\n *     mongoose instanceof mongoose.Mongoose; // true\n *\n *     // Create a new Mongoose instance with its own `connect()`, `set()`, `model()`, etc.\n *     const m = new mongoose.Mongoose();\n *\n * @api public\n * @param {Object} options see [`Mongoose#set()` docs](https://mongoosejs.com/docs/api/mongoose.html#Mongoose.prototype.set())\n */\nfunction Mongoose(options) {\n  this.connections = [];\n  this.nextConnectionId = 0;\n  this.models = {};\n  this.events = new EventEmitter();\n  this.__driver = driver.get();\n  // default global options\n  this.options = Object.assign({\n    pluralization: true,\n    autoIndex: true,\n    autoCreate: true,\n    autoSearchIndex: false\n  }, options);\n  const createInitialConnection = utils.getOption('createInitialConnection', this.options) ?? true;\n  if (createInitialConnection && this.__driver != null) {\n    _createDefaultConnection(this);\n  }\n\n  if (this.options.pluralization) {\n    this._pluralize = legacyPluralize;\n  }\n\n  // If a user creates their own Mongoose instance, give them a separate copy\n  // of the `Schema` constructor so they get separate custom types. (gh-6933)\n  if (!options || !options[defaultMongooseSymbol]) {\n    const _this = this;\n    this.Schema = function() {\n      this.base = _this;\n      return Schema.apply(this, arguments);\n    };\n    this.Schema.prototype = Object.create(Schema.prototype);\n\n    Object.assign(this.Schema, Schema);\n    this.Schema.base = this;\n    this.Schema.Types = Object.assign({}, Schema.Types);\n  } else {\n    // Hack to work around babel's strange behavior with\n    // `import mongoose, { Schema } from 'mongoose'`. Because `Schema` is not\n    // an own property of a Mongoose global, Schema will be undefined. See gh-5648\n    for (const key of ['Schema', 'model']) {\n      this[key] = Mongoose.prototype[key];\n    }\n  }\n  this.Schema.prototype.base = this;\n\n  if (options?.transactionAsyncLocalStorage) {\n    this.transactionAsyncLocalStorage = new AsyncLocalStorage();\n  }\n\n  Object.defineProperty(this, 'plugins', {\n    configurable: false,\n    enumerable: true,\n    writable: false,\n    value: Object.values(builtinPlugins).map(plugin => ([plugin, { deduplicate: true }]))\n  });\n}\n\nMongoose.prototype.cast = cast;\n/**\n * Expose connection states for user-land\n *\n * @memberOf Mongoose\n * @property STATES\n * @api public\n */\nMongoose.prototype.STATES = STATES;\n\n/**\n * Expose connection states for user-land\n *\n * @memberOf Mongoose\n * @property ConnectionStates\n * @api public\n */\nMongoose.prototype.ConnectionStates = STATES;\n\n/**\n * Object with `get()` and `set()` containing the underlying driver this Mongoose instance\n * uses to communicate with the database. A driver is a Mongoose-specific interface that defines functions\n * like `find()`.\n *\n * @deprecated\n * @memberOf Mongoose\n * @property driver\n * @api public\n */\n\nMongoose.prototype.driver = driver;\n\n/**\n * Overwrites the current driver used by this Mongoose instance. A driver is a\n * Mongoose-specific interface that defines functions like `find()`.\n *\n * @memberOf Mongoose\n * @method setDriver\n * @api public\n */\n\nMongoose.prototype.setDriver = function setDriver(driver) {\n  const _mongoose = this instanceof Mongoose ? this : mongoose;\n\n  if (_mongoose.__driver === driver) {\n    return _mongoose;\n  }\n\n  const openConnection = _mongoose.connections && _mongoose.connections.find(conn => conn.readyState !== STATES.disconnected);\n  if (openConnection) {\n    const msg = 'Cannot modify Mongoose driver if a connection is already open. ' +\n      'Call `mongoose.disconnect()` before modifying the driver';\n    throw new MongooseError(msg);\n  }\n  _mongoose.__driver = driver;\n\n  if (Array.isArray(driver.plugins)) {\n    for (const plugin of driver.plugins) {\n      if (typeof plugin === 'function') {\n        _mongoose.plugin(plugin);\n      }\n    }\n  }\n\n  const Connection = driver.Connection;\n  const oldDefaultConnection = _mongoose.connections[0];\n  _mongoose.connections = [new Connection(_mongoose)];\n  _mongoose.connections[0].models = _mongoose.models;\n  if (oldDefaultConnection == null) {\n    return _mongoose;\n  }\n\n  // Update all models that pointed to the old default connection to\n  // the new default connection, including collections\n  for (const model of Object.values(_mongoose.models)) {\n    if (model.db !== oldDefaultConnection) {\n      continue;\n    }\n    model.$__updateConnection(_mongoose.connections[0]);\n  }\n\n  return _mongoose;\n};\n\n/**\n * Sets mongoose options\n *\n * `key` can be used a object to set multiple options at once.\n * If a error gets thrown for one option, other options will still be evaluated.\n *\n * #### Example:\n *\n *     mongoose.set('test', value) // sets the 'test' option to `value`\n *\n *     mongoose.set('debug', true) // enable logging collection methods + arguments to the console/file\n *\n *     mongoose.set('debug', function(collectionName, methodName, ...methodArgs) {}); // use custom function to log collection methods + arguments\n *\n *     mongoose.set({ debug: true, autoIndex: false }); // set multiple options at once\n *\n * Currently supported options are:\n * - `allowDiskUse`: Set to `true` to set `allowDiskUse` to true to all aggregation operations by default.\n * - `applyPluginsToChildSchemas`: `true` by default. Set to false to skip applying global plugins to child schemas\n * - `applyPluginsToDiscriminators`: `false` by default. Set to true to apply global plugins to discriminator schemas. This typically isn't necessary because plugins are applied to the base schema and discriminators copy all middleware, methods, statics, and properties from the base schema.\n * - `autoCreate`: Set to `true` to make Mongoose call [`Model.createCollection()`](https://mongoosejs.com/docs/api/model.html#Model.createCollection()) automatically when you create a model with `mongoose.model()` or `conn.model()`. This is useful for testing transactions, change streams, and other features that require the collection to exist.\n * - `autoIndex`: `true` by default. Set to false to disable automatic index creation for all models associated with this Mongoose instance.\n * - `bufferCommands`: enable/disable mongoose's buffering mechanism for all connections and models\n * - `bufferTimeoutMS`: If bufferCommands is on, this option sets the maximum amount of time Mongoose buffering will wait before throwing an error. If not specified, Mongoose will use 10000 (10 seconds).\n * - `cloneSchemas`: `false` by default. Set to `true` to `clone()` all schemas before compiling into a model.\n * - `debug`: If `true`, prints the operations mongoose sends to MongoDB to the console. If a writable stream is passed, it will log to that stream, without colorization. If a callback function is passed, it will receive the collection name, the method name, then all arguments passed to the method. For example, if you wanted to replicate the default logging, you could output from the callback `Mongoose: ${collectionName}.${methodName}(${methodArgs.join(', ')})`.\n * - `id`: If `true`, adds a `id` virtual to all schemas unless overwritten on a per-schema basis.\n * - `timestamps.createdAt.immutable`: `true` by default. If `false`, it will change the `createdAt` field to be [`immutable: false`](https://mongoosejs.com/docs/api/schematype.html#SchemaType.prototype.immutable) which means you can update the `createdAt`\n * - `maxTimeMS`: If set, attaches [maxTimeMS](https://www.mongodb.com/docs/manual/reference/operator/meta/maxTimeMS/) to every query\n * - `objectIdGetter`: `true` by default. Mongoose adds a getter to MongoDB ObjectId's called `_id` that returns `this` for convenience with populate. Set this to false to remove the getter.\n * - `overwriteModels`: Set to `true` to default to overwriting models with the same name when calling `mongoose.model()`, as opposed to throwing an `OverwriteModelError`.\n * - `returnOriginal`: If `false`, changes the default `returnOriginal` option to `findOneAndUpdate()`, `findByIdAndUpdate`, and `findOneAndReplace()` to false. This is equivalent to setting the `new` option to `true` for `findOneAndX()` calls by default. Read our [`findOneAndUpdate()` tutorial](https://mongoosejs.com/docs/tutorials/findoneandupdate.html) for more information.\n * - `runValidators`: `false` by default. Set to true to enable [update validators](https://mongoosejs.com/docs/validation.html#update-validators) for all validators by default.\n * - `sanitizeFilter`: `false` by default. Set to true to enable the [sanitization of the query filters](https://mongoosejs.com/docs/api/mongoose.html#Mongoose.prototype.sanitizeFilter()) against query selector injection attacks by wrapping any nested objects that have a property whose name starts with `$` in a `$eq`.\n * - `selectPopulatedPaths`: `true` by default. Set to false to opt out of Mongoose adding all fields that you `populate()` to your `select()`. The schema-level option `selectPopulatedPaths` overwrites this one.\n * - `strict`: `true` by default, may be `false`, `true`, or `'throw'`. Sets the default strict mode for schemas.\n * - `strictQuery`: `false` by default. May be `false`, `true`, or `'throw'`. Sets the default [strictQuery](https://mongoosejs.com/docs/guide.html#strictQuery) mode for schemas.\n * - `toJSON`: `{ transform: true, flattenDecimals: true }` by default. Overwrites default objects to [`toJSON()`](https://mongoosejs.com/docs/api/document.html#Document.prototype.toJSON()), for determining how Mongoose documents get serialized by `JSON.stringify()`\n * - `toObject`: `{ transform: true, flattenDecimals: true }` by default. Overwrites default objects to [`toObject()`](https://mongoosejs.com/docs/api/document.html#Document.prototype.toObject())\n *\n * @param {String|Object} key The name of the option or a object of multiple key-value pairs\n * @param {String|Function|Boolean} value The value of the option, unused if \"key\" is a object\n * @returns {Mongoose} The used Mongoose instnace\n * @api public\n */\n\nMongoose.prototype.set = function(key, value) {\n  const _mongoose = this instanceof Mongoose ? this : mongoose;\n\n  if (arguments.length === 1 && typeof key !== 'object') {\n    if (VALID_OPTIONS.indexOf(key) === -1) {\n      const error = new SetOptionError();\n      error.addError(key, new SetOptionError.SetOptionInnerError(key));\n      throw error;\n    }\n\n    return _mongoose.options[key];\n  }\n\n  let options = {};\n\n  if (arguments.length === 2) {\n    options = { [key]: value };\n  }\n\n  if (arguments.length === 1 && typeof key === 'object') {\n    options = key;\n  }\n\n  // array for errors to collect all errors for all key-value pairs, like \".validate\"\n  let error = undefined;\n\n  for (const [optionKey, optionValue] of Object.entries(options)) {\n    if (VALID_OPTIONS.indexOf(optionKey) === -1) {\n      if (!error) {\n        error = new SetOptionError();\n      }\n      error.addError(optionKey, new SetOptionError.SetOptionInnerError(optionKey));\n      continue;\n    }\n\n    _mongoose.options[optionKey] = optionValue;\n\n    if (optionKey === 'objectIdGetter') {\n      if (optionValue) {\n        Object.defineProperty(_mongoose.Types.ObjectId.prototype, '_id', {\n          enumerable: false,\n          configurable: true,\n          get: function() {\n            return this;\n          }\n        });\n      } else {\n        delete _mongoose.Types.ObjectId.prototype._id;\n      }\n    } else if (optionKey === 'transactionAsyncLocalStorage') {\n      if (optionValue && !_mongoose.transactionAsyncLocalStorage) {\n        _mongoose.transactionAsyncLocalStorage = new AsyncLocalStorage();\n      } else if (!optionValue && _mongoose.transactionAsyncLocalStorage) {\n        delete _mongoose.transactionAsyncLocalStorage;\n      }\n    } else if (optionKey === 'createInitialConnection') {\n      if (optionValue && !_mongoose.connection) {\n        _createDefaultConnection(_mongoose);\n      } else if (optionValue === false && _mongoose.connection && _mongoose.connection[defaultConnectionSymbol]) {\n        if (_mongoose.connection.readyState === STATES.disconnected && Object.keys(_mongoose.connection.models).length === 0) {\n          _mongoose.connections.shift();\n        }\n      }\n    }\n  }\n\n  if (error) {\n    throw error;\n  }\n\n  return _mongoose;\n};\n\n/**\n * Gets mongoose options\n *\n * #### Example:\n *\n *     mongoose.get('test') // returns the 'test' value\n *\n * @param {String} key\n * @method get\n * @api public\n */\n\nMongoose.prototype.get = Mongoose.prototype.set;\n\n/**\n * Creates a Connection instance.\n *\n * Each `connection` instance maps to a single database. This method is helpful when managing multiple db connections.\n *\n *\n * _Options passed take precedence over options included in connection strings._\n *\n * #### Example:\n *\n *     // with mongodb:// URI\n *     db = mongoose.createConnection('mongodb://user:pass@127.0.0.1:port/database');\n *\n *     // and options\n *     const opts = { db: { native_parser: true }}\n *     db = mongoose.createConnection('mongodb://user:pass@127.0.0.1:port/database', opts);\n *\n *     // replica sets\n *     db = mongoose.createConnection('mongodb://user:pass@127.0.0.1:port,anotherhost:port,yetanother:port/database');\n *\n *     // and options\n *     const opts = { replset: { strategy: 'ping', rs_name: 'testSet' }}\n *     db = mongoose.createConnection('mongodb://user:pass@127.0.0.1:port,anotherhost:port,yetanother:port/database', opts);\n *\n *     // initialize now, connect later\n *     db = mongoose.createConnection();\n *     db.openUri('127.0.0.1', 'database', port, [opts]);\n *\n * @param {String} uri mongodb URI to connect to\n * @param {Object} [options] passed down to the [MongoDB driver's `connect()` function](https://mongodb.github.io/node-mongodb-native/4.9/interfaces/MongoClientOptions.html), except for 4 mongoose-specific options explained below.\n * @param {Boolean} [options.bufferCommands=true] Mongoose specific option. Set to false to [disable buffering](https://mongoosejs.com/docs/faq.html#callback_never_executes) on all models associated with this connection.\n * @param {String} [options.dbName] The name of the database you want to use. If not provided, Mongoose uses the database name from connection string.\n * @param {String} [options.user] username for authentication, equivalent to `options.auth.user`. Maintained for backwards compatibility.\n * @param {String} [options.pass] password for authentication, equivalent to `options.auth.password`. Maintained for backwards compatibility.\n * @param {Boolean} [options.autoIndex=true] Mongoose-specific option. Set to false to disable automatic index creation for all models associated with this connection.\n * @param {Class} [options.promiseLibrary] Sets the [underlying driver's promise library](https://mongodb.github.io/node-mongodb-native/4.9/interfaces/MongoClientOptions.html#promiseLibrary).\n * @param {Number} [options.maxPoolSize=5] The maximum number of sockets the MongoDB driver will keep open for this connection. Keep in mind that MongoDB only allows one operation per socket at a time, so you may want to increase this if you find you have a few slow queries that are blocking faster queries from proceeding. See [Slow Trains in MongoDB and Node.js](https://thecodebarbarian.com/slow-trains-in-mongodb-and-nodejs).\n * @param {Number} [options.minPoolSize=1] The minimum number of sockets the MongoDB driver will keep open for this connection. Keep in mind that MongoDB only allows one operation per socket at a time, so you may want to increase this if you find you have a few slow queries that are blocking faster queries from proceeding. See [Slow Trains in MongoDB and Node.js](https://thecodebarbarian.com/slow-trains-in-mongodb-and-nodejs).\n * @param {Number} [options.socketTimeoutMS=0] How long the MongoDB driver will wait before killing a socket due to inactivity _after initial connection_. Defaults to 0, which means Node.js will not time out the socket due to inactivity. A socket may be inactive because of either no activity or a long-running operation. This option is passed to [Node.js `socket#setTimeout()` function](https://nodejs.org/api/net.html#net_socket_settimeout_timeout_callback) after the MongoDB driver successfully completes.\n * @param {Number} [options.family=0] Passed transparently to [Node.js' `dns.lookup()`](https://nodejs.org/api/dns.html#dns_dns_lookup_hostname_options_callback) function. May be either `0`, `4`, or `6`. `4` means use IPv4 only, `6` means use IPv6 only, `0` means try both.\n * @return {Connection} the created Connection object. Connections are not thenable, so you can't do `await mongoose.createConnection()`. To await use `mongoose.createConnection(uri).asPromise()` instead.\n * @api public\n */\n\nMongoose.prototype.createConnection = function(uri, options) {\n  const _mongoose = this instanceof Mongoose ? this : mongoose;\n\n  const Connection = _mongoose.__driver.Connection;\n  const conn = new Connection(_mongoose);\n  _mongoose.connections.push(conn);\n  _mongoose.nextConnectionId++;\n  _mongoose.events.emit('createConnection', conn);\n\n  if (arguments.length > 0) {\n    conn.openUri(uri, { ...options, _fireAndForget: true });\n  }\n\n  return conn;\n};\n\n/**\n * Opens the default mongoose connection.\n *\n * #### Example:\n *\n *     mongoose.connect('mongodb://user:pass@127.0.0.1:port/database');\n *\n *     // replica sets\n *     const uri = 'mongodb://user:pass@127.0.0.1:port,anotherhost:port,yetanother:port/mydatabase';\n *     mongoose.connect(uri);\n *\n *     // with options\n *     mongoose.connect(uri, options);\n *\n *     // optional callback that gets fired when initial connection completed\n *     const uri = 'mongodb://nonexistent.domain:27000';\n *     mongoose.connect(uri, function(error) {\n *       // if error is truthy, the initial connection failed.\n *     })\n *\n * @param {String} uri mongodb URI to connect to\n * @param {Object} [options] passed down to the [MongoDB driver's `connect()` function](https://mongodb.github.io/node-mongodb-native/4.9/interfaces/MongoClientOptions.html), except for 4 mongoose-specific options explained below.\n * @param {Boolean} [options.bufferCommands=true] Mongoose specific option. Set to false to [disable buffering](https://mongoosejs.com/docs/faq.html#callback_never_executes) on all models associated with this connection.\n * @param {Number} [options.bufferTimeoutMS=10000] Mongoose specific option. If `bufferCommands` is true, Mongoose will throw an error after `bufferTimeoutMS` if the operation is still buffered.\n * @param {String} [options.dbName] The name of the database we want to use. If not provided, use database name from connection string.\n * @param {String} [options.user] username for authentication, equivalent to `options.auth.user`. Maintained for backwards compatibility.\n * @param {String} [options.pass] password for authentication, equivalent to `options.auth.password`. Maintained for backwards compatibility.\n * @param {Number} [options.maxPoolSize=100] The maximum number of sockets the MongoDB driver will keep open for this connection. Keep in mind that MongoDB only allows one operation per socket at a time, so you may want to increase this if you find you have a few slow queries that are blocking faster queries from proceeding. See [Slow Trains in MongoDB and Node.js](https://thecodebarbarian.com/slow-trains-in-mongodb-and-nodejs).\n * @param {Number} [options.minPoolSize=0] The minimum number of sockets the MongoDB driver will keep open for this connection.\n * @param {Number} [options.serverSelectionTimeoutMS] If `useUnifiedTopology = true`, the MongoDB driver will try to find a server to send any given operation to, and keep retrying for `serverSelectionTimeoutMS` milliseconds before erroring out. If not set, the MongoDB driver defaults to using `30000` (30 seconds).\n * @param {Number} [options.heartbeatFrequencyMS] If `useUnifiedTopology = true`, the MongoDB driver sends a heartbeat every `heartbeatFrequencyMS` to check on the status of the connection. A heartbeat is subject to `serverSelectionTimeoutMS`, so the MongoDB driver will retry failed heartbeats for up to 30 seconds by default. Mongoose only emits a `'disconnected'` event after a heartbeat has failed, so you may want to decrease this setting to reduce the time between when your server goes down and when Mongoose emits `'disconnected'`. We recommend you do **not** set this setting below 1000, too many heartbeats can lead to performance degradation.\n * @param {Boolean} [options.autoIndex=true] Mongoose-specific option. Set to false to disable automatic index creation for all models associated with this connection.\n * @param {Class} [options.promiseLibrary] Sets the [underlying driver's promise library](https://mongodb.github.io/node-mongodb-native/4.9/interfaces/MongoClientOptions.html#promiseLibrary).\n * @param {Number} [options.socketTimeoutMS=0] How long the MongoDB driver will wait before killing a socket due to inactivity _after initial connection_. A socket may be inactive because of either no activity or a long-running operation. `socketTimeoutMS` defaults to 0, which means Node.js will not time out the socket due to inactivity. This option is passed to [Node.js `socket#setTimeout()` function](https://nodejs.org/api/net.html#net_socket_settimeout_timeout_callback) after the MongoDB driver successfully completes.\n * @param {Number} [options.family=0] Passed transparently to [Node.js' `dns.lookup()`](https://nodejs.org/api/dns.html#dns_dns_lookup_hostname_options_callback) function. May be either `0`, `4`, or `6`. `4` means use IPv4 only, `6` means use IPv6 only, `0` means try both.\n * @param {Boolean} [options.autoCreate=false] Set to `true` to make Mongoose automatically call `createCollection()` on every model created on this connection.\n * @param {Function} [callback]\n * @see Mongoose#createConnection https://mongoosejs.com/docs/api/mongoose.html#Mongoose.prototype.createConnection()\n * @api public\n * @return {Promise} resolves to `this` if connection succeeded\n */\n\nMongoose.prototype.connect = async function connect(uri, options) {\n  if (typeof options === 'function' || (arguments.length >= 3 && typeof arguments[2] === 'function')) {\n    throw new MongooseError('Mongoose.prototype.connect() no longer accepts a callback');\n  }\n\n  const _mongoose = this instanceof Mongoose ? this : mongoose;\n  if (_mongoose.connection == null) {\n    _createDefaultConnection(_mongoose);\n  }\n  const conn = _mongoose.connection;\n\n  return conn.openUri(uri, options).then(() => _mongoose);\n};\n\n/**\n * Runs `.close()` on all connections in parallel.\n *\n * @return {Promise} resolves when all connections are closed, or rejects with the first error that occurred.\n * @api public\n */\n\nMongoose.prototype.disconnect = async function disconnect() {\n  if (arguments.length >= 1 && typeof arguments[0] === 'function') {\n    throw new MongooseError('Mongoose.prototype.disconnect() no longer accepts a callback');\n  }\n\n  const _mongoose = this instanceof Mongoose ? this : mongoose;\n\n  const remaining = _mongoose.connections.length;\n  if (remaining <= 0) {\n    return;\n  }\n  await Promise.all(_mongoose.connections.map(conn => conn.close()));\n};\n\n/**\n * _Requires MongoDB >= 3.6.0._ Starts a [MongoDB session](https://www.mongodb.com/docs/manual/release-notes/3.6/#client-sessions)\n * for benefits like causal consistency, [retryable writes](https://www.mongodb.com/docs/manual/core/retryable-writes/),\n * and [transactions](https://thecodebarbarian.com/a-node-js-perspective-on-mongodb-4-transactions.html).\n *\n * Calling `mongoose.startSession()` is equivalent to calling `mongoose.connection.startSession()`.\n * Sessions are scoped to a connection, so calling `mongoose.startSession()`\n * starts a session on the [default mongoose connection](https://mongoosejs.com/docs/api/mongoose.html#Mongoose.prototype.connection).\n *\n * @param {Object} [options] see the [mongodb driver options](https://mongodb.github.io/node-mongodb-native/4.9/classes/MongoClient.html#startSession)\n * @param {Boolean} [options.causalConsistency=true] set to false to disable causal consistency\n * @param {Function} [callback]\n * @return {Promise<ClientSession>} promise that resolves to a MongoDB driver `ClientSession`\n * @api public\n */\n\nMongoose.prototype.startSession = function() {\n  const _mongoose = this instanceof Mongoose ? this : mongoose;\n\n  return _mongoose.connection.startSession.apply(_mongoose.connection, arguments);\n};\n\n/**\n * Getter/setter around function for pluralizing collection names.\n *\n * @param {Function|null} [fn] overwrites the function used to pluralize collection names\n * @return {Function|null} the current function used to pluralize collection names, defaults to the legacy function from `mongoose-legacy-pluralize`.\n * @api public\n */\n\nMongoose.prototype.pluralize = function(fn) {\n  const _mongoose = this instanceof Mongoose ? this : mongoose;\n\n  if (arguments.length > 0) {\n    _mongoose._pluralize = fn;\n  }\n  return _mongoose._pluralize;\n};\n\n/**\n * Defines a model or retrieves it.\n *\n * Models defined on the `mongoose` instance are available to all connection\n * created by the same `mongoose` instance.\n *\n * If you call `mongoose.model()` with twice the same name but a different schema,\n * you will get an `OverwriteModelError`. If you call `mongoose.model()` with\n * the same name and same schema, you'll get the same schema back.\n *\n * #### Example:\n *\n *     const mongoose = require('mongoose');\n *\n *     // define an Actor model with this mongoose instance\n *     const schema = new Schema({ name: String });\n *     mongoose.model('Actor', schema);\n *\n *     // create a new connection\n *     const conn = mongoose.createConnection(..);\n *\n *     // create Actor model\n *     const Actor = conn.model('Actor', schema);\n *     conn.model('Actor') === Actor; // true\n *     conn.model('Actor', schema) === Actor; // true, same schema\n *     conn.model('Actor', schema, 'actors') === Actor; // true, same schema and collection name\n *\n *     // This throws an `OverwriteModelError` because the schema is different.\n *     conn.model('Actor', new Schema({ name: String }));\n *\n * _When no `collection` argument is passed, Mongoose uses the model name. If you don't like this behavior, either pass a collection name, use `mongoose.pluralize()`, or set your schemas collection name option._\n *\n * #### Example:\n *\n *     const schema = new Schema({ name: String }, { collection: 'actor' });\n *\n *     // or\n *\n *     schema.set('collection', 'actor');\n *\n *     // or\n *\n *     const collectionName = 'actor';\n *     const M = mongoose.model('Actor', schema, collectionName);\n *\n * @param {String|Function} name model name or class extending Model\n * @param {Schema} [schema] the schema to use.\n * @param {String} [collection] name (optional, inferred from model name)\n * @param {Object} [options]\n * @param {Boolean} [options.overwriteModels=false] If true, overwrite existing models with the same name to avoid `OverwriteModelError`\n * @return {Model} The model associated with `name`. Mongoose will create the model if it doesn't already exist.\n * @api public\n */\n\nMongoose.prototype.model = function(name, schema, collection, options) {\n  const _mongoose = this instanceof Mongoose ? this : mongoose;\n\n  if (typeof schema === 'string') {\n    collection = schema;\n    schema = false;\n  }\n\n  if (arguments.length === 1) {\n    const model = _mongoose.models[name];\n    if (!model) {\n      throw new MongooseError.MissingSchemaError(name);\n    }\n    return model;\n  }\n\n  if (utils.isObject(schema) && !(schema instanceof Schema)) {\n    schema = new Schema(schema);\n  }\n  if (schema && !(schema instanceof Schema)) {\n    throw new Error('The 2nd parameter to `mongoose.model()` should be a ' +\n      'schema or a POJO');\n  }\n\n  // handle internal options from connection.model()\n  options = options || {};\n\n  const originalSchema = schema;\n  if (schema) {\n    if (_mongoose.get('cloneSchemas')) {\n      schema = schema.clone();\n    }\n    _mongoose._applyPlugins(schema);\n  }\n\n  // connection.model() may be passing a different schema for\n  // an existing model name. in this case don't read from cache.\n  const overwriteModels = _mongoose.options.hasOwnProperty('overwriteModels') ?\n    _mongoose.options.overwriteModels :\n    options.overwriteModels;\n  if (_mongoose.models.hasOwnProperty(name) && options.cache !== false && overwriteModels !== true) {\n    if (originalSchema &&\n        originalSchema.instanceOfSchema &&\n        originalSchema !== _mongoose.models[name].schema) {\n      throw new _mongoose.Error.OverwriteModelError(name);\n    }\n    if (collection && collection !== _mongoose.models[name].collection.name) {\n      // subclass current model with alternate collection\n      const model = _mongoose.models[name];\n      schema = model.prototype.schema;\n      const sub = model.__subclass(_mongoose.connection, schema, collection);\n      // do not cache the sub model\n      return sub;\n    }\n    return _mongoose.models[name];\n  }\n  if (schema == null) {\n    throw new _mongoose.Error.MissingSchemaError(name);\n  }\n\n  const model = _mongoose._model(name, schema, collection, options);\n  _mongoose.connection.models[name] = model;\n  _mongoose.models[name] = model;\n\n  return model;\n};\n\n/*!\n * ignore\n */\n\nMongoose.prototype._model = function(name, schema, collection, options) {\n  const _mongoose = this instanceof Mongoose ? this : mongoose;\n\n  let model;\n  if (typeof name === 'function') {\n    model = name;\n    name = model.name;\n    if (!(model.prototype instanceof Model)) {\n      throw new _mongoose.Error('The provided class ' + name + ' must extend Model');\n    }\n  }\n\n  if (schema) {\n    if (_mongoose.get('cloneSchemas')) {\n      schema = schema.clone();\n    }\n    _mongoose._applyPlugins(schema);\n  }\n\n  // Apply relevant \"global\" options to the schema\n  if (schema == null || !('pluralization' in schema.options)) {\n    schema.options.pluralization = _mongoose.options.pluralization;\n  }\n\n  if (!collection) {\n    collection = schema.get('collection') ||\n      utils.toCollectionName(name, _mongoose.pluralize());\n  }\n\n  const connection = options.connection || _mongoose.connection;\n  model = _mongoose.Model.compile(model || name, schema, collection, connection, _mongoose);\n  // Errors handled internally, so safe to ignore error\n  model.init().catch(function $modelInitNoop() {});\n\n  connection.emit('model', model);\n\n  if (schema._applyDiscriminators != null) {\n    for (const disc of schema._applyDiscriminators.keys()) {\n      const {\n        schema: discriminatorSchema,\n        options\n      } = schema._applyDiscriminators.get(disc);\n      model.discriminator(disc, discriminatorSchema, options);\n    }\n  }\n\n  applyEmbeddedDiscriminators(schema);\n\n  return model;\n};\n\n/**\n * Removes the model named `name` from the default connection, if it exists.\n * You can use this function to clean up any models you created in your tests to\n * prevent OverwriteModelErrors.\n *\n * Equivalent to `mongoose.connection.deleteModel(name)`.\n *\n * #### Example:\n *\n *     mongoose.model('User', new Schema({ name: String }));\n *     console.log(mongoose.model('User')); // Model object\n *     mongoose.deleteModel('User');\n *     console.log(mongoose.model('User')); // undefined\n *\n *     // Usually useful in a Mocha `afterEach()` hook\n *     afterEach(function() {\n *       mongoose.deleteModel(/.+/); // Delete every model\n *     });\n *\n * @api public\n * @param {String|RegExp} name if string, the name of the model to remove. If regexp, removes all models whose name matches the regexp.\n * @return {Mongoose} this\n */\n\nMongoose.prototype.deleteModel = function(name) {\n  const _mongoose = this instanceof Mongoose ? this : mongoose;\n\n  _mongoose.connection.deleteModel(name);\n  delete _mongoose.models[name];\n  return _mongoose;\n};\n\n/**\n * Returns an array of model names created on this instance of Mongoose.\n *\n * #### Note:\n *\n * _Does not include names of models created using `connection.model()`._\n *\n * @api public\n * @return {Array}\n */\n\nMongoose.prototype.modelNames = function() {\n  const _mongoose = this instanceof Mongoose ? this : mongoose;\n\n  const names = Object.keys(_mongoose.models);\n  return names;\n};\n\n/**\n * Applies global plugins to `schema`.\n *\n * @param {Schema} schema\n * @api private\n */\n\nMongoose.prototype._applyPlugins = function(schema, options) {\n  const _mongoose = this instanceof Mongoose ? this : mongoose;\n\n  options = options || {};\n  options.applyPluginsToDiscriminators = _mongoose.options && _mongoose.options.applyPluginsToDiscriminators || false;\n  options.applyPluginsToChildSchemas = typeof (_mongoose.options && _mongoose.options.applyPluginsToChildSchemas) === 'boolean' ?\n    _mongoose.options.applyPluginsToChildSchemas :\n    true;\n  applyPlugins(schema, _mongoose.plugins, options, '$globalPluginsApplied');\n};\n\n/**\n * Declares a global plugin executed on all Schemas.\n *\n * Equivalent to calling `.plugin(fn)` on each Schema you create.\n *\n * @param {Function} fn plugin callback\n * @param {Object} [opts] optional options\n * @return {Mongoose} this\n * @see plugins https://mongoosejs.com/docs/plugins.html\n * @api public\n */\n\nMongoose.prototype.plugin = function(fn, opts) {\n  const _mongoose = this instanceof Mongoose ? this : mongoose;\n\n  _mongoose.plugins.push([fn, opts]);\n  return _mongoose;\n};\n\n/**\n * The Mongoose module's default connection. Equivalent to `mongoose.connections[0]`, see [`connections`](https://mongoosejs.com/docs/api/mongoose.html#Mongoose.prototype.connections).\n *\n * #### Example:\n *\n *     const mongoose = require('mongoose');\n *     mongoose.connect(...);\n *     mongoose.connection.on('error', cb);\n *\n * This is the connection used by default for every model created using [mongoose.model](https://mongoosejs.com/docs/api/mongoose.html#Mongoose.prototype.model()).\n *\n * To create a new connection, use [`createConnection()`](https://mongoosejs.com/docs/api/mongoose.html#Mongoose.prototype.createConnection()).\n *\n * @memberOf Mongoose\n * @instance\n * @property {Connection} connection\n * @api public\n */\n\nMongoose.prototype.__defineGetter__('connection', function() {\n  return this.connections[0];\n});\n\nMongoose.prototype.__defineSetter__('connection', function(v) {\n  if (v instanceof this.__driver.Connection) {\n    this.connections[0] = v;\n    this.models = v.models;\n  }\n});\n\n/**\n * An array containing all [connections](connection.html) associated with this\n * Mongoose instance. By default, there is 1 connection. Calling\n * [`createConnection()`](https://mongoosejs.com/docs/api/mongoose.html#Mongoose.prototype.createConnection()) adds a connection\n * to this array.\n *\n * #### Example:\n *\n *     const mongoose = require('mongoose');\n *     mongoose.connections.length; // 1, just the default connection\n *     mongoose.connections[0] === mongoose.connection; // true\n *\n *     mongoose.createConnection('mongodb://127.0.0.1:27017/test');\n *     mongoose.connections.length; // 2\n *\n * @memberOf Mongoose\n * @instance\n * @property {Array} connections\n * @api public\n */\n\nMongoose.prototype.connections;\n\n/**\n * An integer containing the value of the next connection id. Calling\n * [`createConnection()`](https://mongoosejs.com/docs/api/mongoose.html#Mongoose.prototype.createConnection()) increments\n * this value.\n *\n * #### Example:\n *\n *     const mongoose = require('mongoose');\n *     mongoose.createConnection(); // id `0`, `nextConnectionId` becomes `1`\n *     mongoose.createConnection(); // id `1`, `nextConnectionId` becomes `2`\n *     mongoose.connections[0].destroy() // Removes connection with id `0`\n *     mongoose.createConnection(); // id `2`, `nextConnectionId` becomes `3`\n *\n * @memberOf Mongoose\n * @instance\n * @property {Number} nextConnectionId\n * @api private\n */\n\nMongoose.prototype.nextConnectionId;\n\n/**\n * The Mongoose Aggregate constructor\n *\n * @method Aggregate\n * @api public\n */\n\nMongoose.prototype.Aggregate = Aggregate;\n\n/**\n * The Mongoose Collection constructor\n *\n * @memberOf Mongoose\n * @instance\n * @method Collection\n * @api public\n */\n\nObject.defineProperty(Mongoose.prototype, 'Collection', {\n  get: function() {\n    return this.__driver.Collection;\n  },\n  set: function(Collection) {\n    this.__driver.Collection = Collection;\n  }\n});\n\n/**\n * The Mongoose [Connection](https://mongoosejs.com/docs/api/connection.html#Connection()) constructor\n *\n * @memberOf Mongoose\n * @instance\n * @method Connection\n * @api public\n */\n\nObject.defineProperty(Mongoose.prototype, 'Connection', {\n  get: function() {\n    return this.__driver.Connection;\n  },\n  set: function(Connection) {\n    if (Connection === this.__driver.Connection) {\n      return;\n    }\n\n    this.__driver.Connection = Connection;\n  }\n});\n\n/**\n * The Mongoose version\n *\n * #### Example:\n *\n *     console.log(mongoose.version); // '5.x.x'\n *\n * @property version\n * @api public\n */\n\nMongoose.prototype.version = pkg.version;\n\n/**\n * The Mongoose constructor\n *\n * The exports of the mongoose module is an instance of this class.\n *\n * #### Example:\n *\n *     const mongoose = require('mongoose');\n *     const mongoose2 = new mongoose.Mongoose();\n *\n * @method Mongoose\n * @api public\n */\n\nMongoose.prototype.Mongoose = Mongoose;\n\n/**\n * The Mongoose [Schema](https://mongoosejs.com/docs/api/schema.html#Schema()) constructor\n *\n * #### Example:\n *\n *     const mongoose = require('mongoose');\n *     const Schema = mongoose.Schema;\n *     const CatSchema = new Schema(..);\n *\n * @method Schema\n * @api public\n */\n\nMongoose.prototype.Schema = Schema;\n\n/**\n * The Mongoose [SchemaType](https://mongoosejs.com/docs/api/schematype.html#SchemaType()) constructor\n *\n * @method SchemaType\n * @api public\n */\n\nMongoose.prototype.SchemaType = SchemaType;\n\n/**\n * The various Mongoose SchemaTypes.\n *\n * #### Note:\n *\n * _Alias of mongoose.Schema.Types for backwards compatibility._\n *\n * @property SchemaTypes\n * @see Schema.SchemaTypes https://mongoosejs.com/docs/schematypes.html\n * @api public\n */\n\nMongoose.prototype.SchemaTypes = Schema.Types;\n\n/**\n * The Mongoose [VirtualType](https://mongoosejs.com/docs/api/virtualtype.html#VirtualType()) constructor\n *\n * @method VirtualType\n * @api public\n */\n\nMongoose.prototype.VirtualType = VirtualType;\n\n/**\n * The various Mongoose Types.\n *\n * #### Example:\n *\n *     const mongoose = require('mongoose');\n *     const array = mongoose.Types.Array;\n *\n * #### Types:\n *\n * - [Array](https://mongoosejs.com/docs/schematypes.html#arrays)\n * - [Buffer](https://mongoosejs.com/docs/schematypes.html#buffers)\n * - [Embedded](https://mongoosejs.com/docs/schematypes.html#schemas)\n * - [DocumentArray](https://mongoosejs.com/docs/api/documentarraypath.html)\n * - [Decimal128](https://mongoosejs.com/docs/api/mongoose.html#Mongoose.prototype.Decimal128)\n * - [ObjectId](https://mongoosejs.com/docs/schematypes.html#objectids)\n * - [Map](https://mongoosejs.com/docs/schematypes.html#maps)\n * - [Subdocument](https://mongoosejs.com/docs/schematypes.html#schemas)\n *\n * Using this exposed access to the `ObjectId` type, we can construct ids on demand.\n *\n *     const ObjectId = mongoose.Types.ObjectId;\n *     const id1 = new ObjectId;\n *\n * @property Types\n * @api public\n */\n\nMongoose.prototype.Types = Types;\n\n/**\n * The Mongoose [Query](https://mongoosejs.com/docs/api/query.html#Query()) constructor.\n *\n * @method Query\n * @api public\n */\n\nMongoose.prototype.Query = Query;\n\n/**\n * The Mongoose [Model](https://mongoosejs.com/docs/api/model.html#Model()) constructor.\n *\n * @method Model\n * @api public\n */\n\nMongoose.prototype.Model = Model;\n\n/**\n * The Mongoose [Document](https://mongoosejs.com/docs/api/document.html#Document()) constructor.\n *\n * @method Document\n * @api public\n */\n\nMongoose.prototype.Document = Document;\n\n/**\n * The Mongoose DocumentProvider constructor. Mongoose users should not have to\n * use this directly\n *\n * @method DocumentProvider\n * @api public\n */\n\nMongoose.prototype.DocumentProvider = __webpack_require__(/*! ./documentProvider */ \"./node_modules/mongoose/lib/documentProvider.js\");\n\n/**\n * The Mongoose ObjectId [SchemaType](https://mongoosejs.com/docs/schematypes.html). Used for\n * declaring paths in your schema that should be\n * [MongoDB ObjectIds](https://www.mongodb.com/docs/manual/reference/method/ObjectId/).\n * Do not use this to create a new ObjectId instance, use `mongoose.Types.ObjectId`\n * instead.\n *\n * #### Example:\n *\n *     const childSchema = new Schema({ parentId: mongoose.ObjectId });\n *\n * @property ObjectId\n * @api public\n */\n\nMongoose.prototype.ObjectId = SchemaTypes.ObjectId;\n\n/**\n * Returns true if Mongoose can cast the given value to an ObjectId, or\n * false otherwise.\n *\n * #### Example:\n *\n *     mongoose.isValidObjectId(new mongoose.Types.ObjectId()); // true\n *     mongoose.isValidObjectId('0123456789ab'); // true\n *     mongoose.isValidObjectId(6); // true\n *     mongoose.isValidObjectId(new User({ name: 'test' })); // true\n *\n *     mongoose.isValidObjectId({ test: 42 }); // false\n *\n * @method isValidObjectId\n * @param {Any} v\n * @returns {boolean} true if `v` is something Mongoose can coerce to an ObjectId\n * @api public\n */\n\nMongoose.prototype.isValidObjectId = function(v) {\n  const _mongoose = this instanceof Mongoose ? this : mongoose;\n  return _mongoose.Types.ObjectId.isValid(v);\n};\n\n/**\n * Returns true if the given value is a Mongoose ObjectId (using `instanceof`) or if the\n * given value is a 24 character hex string, which is the most commonly used string representation\n * of an ObjectId.\n *\n * This function is similar to `isValidObjectId()`, but considerably more strict, because\n * `isValidObjectId()` will return `true` for _any_ value that Mongoose can convert to an\n * ObjectId. That includes Mongoose documents, any string of length 12, and any number.\n * `isObjectIdOrHexString()` returns true only for `ObjectId` instances or 24 character hex\n * strings, and will return false for numbers, documents, and strings of length 12.\n *\n * #### Example:\n *\n *     mongoose.isObjectIdOrHexString(new mongoose.Types.ObjectId()); // true\n *     mongoose.isObjectIdOrHexString('62261a65d66c6be0a63c051f'); // true\n *\n *     mongoose.isObjectIdOrHexString('0123456789ab'); // false\n *     mongoose.isObjectIdOrHexString(6); // false\n *     mongoose.isObjectIdOrHexString(new User({ name: 'test' })); // false\n *     mongoose.isObjectIdOrHexString({ test: 42 }); // false\n *\n * @method isObjectIdOrHexString\n * @param {Any} v\n * @returns {boolean} true if `v` is an ObjectId instance _or_ a 24 char hex string\n * @api public\n */\n\nMongoose.prototype.isObjectIdOrHexString = function(v) {\n  return isBsonType(v, 'ObjectId') || (typeof v === 'string' && objectIdHexRegexp.test(v));\n};\n\n/**\n *\n * Syncs all the indexes for the models registered with this connection.\n *\n * @param {Object} options\n * @param {Boolean} options.continueOnError `false` by default. If set to `true`, mongoose will not throw an error if one model syncing failed, and will return an object where the keys are the names of the models, and the values are the results/errors for each model.\n * @return {Promise} Returns a Promise, when the Promise resolves the value is a list of the dropped indexes.\n */\nMongoose.prototype.syncIndexes = function(options) {\n  const _mongoose = this instanceof Mongoose ? this : mongoose;\n  return _mongoose.connection.syncIndexes(options);\n};\n\n/**\n * The Mongoose Decimal128 [SchemaType](https://mongoosejs.com/docs/schematypes.html). Used for\n * declaring paths in your schema that should be\n * [128-bit decimal floating points](https://thecodebarbarian.com/a-nodejs-perspective-on-mongodb-34-decimal.html).\n * Do not use this to create a new Decimal128 instance, use `mongoose.Types.Decimal128`\n * instead.\n *\n * #### Example:\n *\n *     const vehicleSchema = new Schema({ fuelLevel: mongoose.Decimal128 });\n *\n * @property Decimal128\n * @api public\n */\n\nMongoose.prototype.Decimal128 = SchemaTypes.Decimal128;\n\n/**\n * The Mongoose Mixed [SchemaType](https://mongoosejs.com/docs/schematypes.html). Used for\n * declaring paths in your schema that Mongoose's change tracking, casting,\n * and validation should ignore.\n *\n * #### Example:\n *\n *     const schema = new Schema({ arbitrary: mongoose.Mixed });\n *\n * @property Mixed\n * @api public\n */\n\nMongoose.prototype.Mixed = SchemaTypes.Mixed;\n\n/**\n * The Mongoose Date [SchemaType](https://mongoosejs.com/docs/schematypes.html).\n *\n * #### Example:\n *\n *     const schema = new Schema({ test: Date });\n *     schema.path('test') instanceof mongoose.Date; // true\n *\n * @property Date\n * @api public\n */\n\nMongoose.prototype.Date = SchemaTypes.Date;\n\n/**\n * The Mongoose Number [SchemaType](https://mongoosejs.com/docs/schematypes.html). Used for\n * declaring paths in your schema that Mongoose should cast to numbers.\n *\n * #### Example:\n *\n *     const schema = new Schema({ num: mongoose.Number });\n *     // Equivalent to:\n *     const schema = new Schema({ num: 'number' });\n *\n * @property Number\n * @api public\n */\n\nMongoose.prototype.Number = SchemaTypes.Number;\n\n/**\n * The [MongooseError](https://mongoosejs.com/docs/api/error.html#Error()) constructor.\n *\n * @method Error\n * @api public\n */\n\nMongoose.prototype.Error = __webpack_require__(/*! ./error/index */ \"./node_modules/mongoose/lib/error/index.js\");\nMongoose.prototype.MongooseError = __webpack_require__(/*! ./error/mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\n\n/**\n * Mongoose uses this function to get the current time when setting\n * [timestamps](https://mongoosejs.com/docs/guide.html#timestamps). You may stub out this function\n * using a tool like [Sinon](https://www.npmjs.com/package/sinon) for testing.\n *\n * @method now\n * @returns Date the current time\n * @api public\n */\n\nMongoose.prototype.now = function now() { return new Date(); };\n\n/**\n * The Mongoose CastError constructor\n *\n * @method CastError\n * @param {String} type The name of the type\n * @param {Any} value The value that failed to cast\n * @param {String} path The path `a.b.c` in the doc where this cast error occurred\n * @param {Error} [reason] The original error that was thrown\n * @api public\n */\n\nMongoose.prototype.CastError = __webpack_require__(/*! ./error/cast */ \"./node_modules/mongoose/lib/error/cast.js\");\n\n/**\n * The constructor used for schematype options\n *\n * @method SchemaTypeOptions\n * @api public\n */\n\nMongoose.prototype.SchemaTypeOptions = __webpack_require__(/*! ./options/schemaTypeOptions */ \"./node_modules/mongoose/lib/options/schemaTypeOptions.js\");\n\n/**\n * The [mquery](https://github.com/aheckmann/mquery) query builder Mongoose uses.\n *\n * @property mquery\n * @api public\n */\n\nMongoose.prototype.mquery = __webpack_require__(/*! mquery */ \"./node_modules/mquery/lib/mquery.js\");\n\n/**\n * Sanitizes query filters against [query selector injection attacks](https://thecodebarbarian.com/2014/09/04/defending-against-query-selector-injection-attacks.html)\n * by wrapping any nested objects that have a property whose name starts with `$` in a `$eq`.\n *\n * ```javascript\n * const obj = { username: 'val', pwd: { $ne: null } };\n * sanitizeFilter(obj);\n * obj; // { username: 'val', pwd: { $eq: { $ne: null } } });\n * ```\n *\n * @method sanitizeFilter\n * @param {Object} filter\n * @returns Object the sanitized object\n * @api public\n */\n\nMongoose.prototype.sanitizeFilter = sanitizeFilter;\n\n/**\n * Tells `sanitizeFilter()` to skip the given object when filtering out potential [query selector injection attacks](https://thecodebarbarian.com/2014/09/04/defending-against-query-selector-injection-attacks.html).\n * Use this method when you have a known query selector that you want to use.\n *\n * ```javascript\n * const obj = { username: 'val', pwd: trusted({ $type: 'string', $eq: 'my secret' }) };\n * sanitizeFilter(obj);\n *\n * // Note that `sanitizeFilter()` did not add `$eq` around `$type`.\n * obj; // { username: 'val', pwd: { $type: 'string', $eq: 'my secret' } });\n * ```\n *\n * @method trusted\n * @param {Object} obj\n * @returns Object the passed in object\n * @api public\n */\n\nMongoose.prototype.trusted = trusted;\n\n/**\n * Use this function in `pre()` middleware to skip calling the wrapped function.\n *\n * #### Example:\n *\n *     schema.pre('save', function() {\n *       // Will skip executing `save()`, but will execute post hooks as if\n *       // `save()` had executed with the result `{ matchedCount: 0 }`\n *       return mongoose.skipMiddlewareFunction({ matchedCount: 0 });\n *     });\n *\n * @method skipMiddlewareFunction\n * @param {any} result\n * @api public\n */\n\nMongoose.prototype.skipMiddlewareFunction = Kareem.skipWrappedFunction;\n\n/**\n * Use this function in `post()` middleware to replace the result\n *\n * #### Example:\n *\n *     schema.post('find', function(res) {\n *       // Normally you have to modify `res` in place. But with\n *       // `overwriteMiddlewarResult()`, you can make `find()` return a\n *       // completely different value.\n *       return mongoose.overwriteMiddlewareResult(res.filter(doc => !doc.isDeleted));\n *     });\n *\n * @method overwriteMiddlewareResult\n * @param {any} result\n * @api public\n */\n\nMongoose.prototype.overwriteMiddlewareResult = Kareem.overwriteResult;\n\n/**\n * Takes in an object and deletes any keys from the object whose values\n * are strictly equal to `undefined`.\n * This function is useful for query filters because Mongoose treats\n * `TestModel.find({ name: undefined })` as `TestModel.find({ name: null })`.\n *\n * #### Example:\n *\n *     const filter = { name: 'John', age: undefined, status: 'active' };\n *     mongoose.omitUndefined(filter); // { name: 'John', status: 'active' }\n *     filter; // { name: 'John', status: 'active' }\n *\n *     await UserModel.findOne(mongoose.omitUndefined(filter));\n *\n * @method omitUndefined\n * @param {Object} [val] the object to remove undefined keys from\n * @returns {Object} the object passed in\n * @api public\n */\n\nMongoose.prototype.omitUndefined = __webpack_require__(/*! ./helpers/omitUndefined */ \"./node_modules/mongoose/lib/helpers/omitUndefined.js\");\n\n/*!\n * Create a new default connection (`mongoose.connection`) for a Mongoose instance.\n * No-op if there is already a default connection.\n */\n\nfunction _createDefaultConnection(mongoose) {\n  if (mongoose.connection) {\n    return;\n  }\n  const conn = mongoose.createConnection(); // default connection\n  conn[defaultConnectionSymbol] = true;\n  conn.models = mongoose.models;\n}\n\n/**\n * The exports object is an instance of Mongoose.\n *\n * @api private\n */\n\nconst mongoose = module.exports = exports = new Mongoose({\n  [defaultMongooseSymbol]: true\n});\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/mongoose.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/options.js":
/*!**********************************************!*\
  !*** ./node_modules/mongoose/lib/options.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\n/*!\n * ignore\n */\n\nexports.internalToObjectOptions = {\n  transform: false,\n  virtuals: false,\n  getters: false,\n  _skipDepopulateTopLevel: true,\n  depopulate: true,\n  flattenDecimals: false,\n  useProjection: false,\n  versionKey: true\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/options.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/options/populateOptions.js":
/*!**************************************************************!*\
  !*** ./node_modules/mongoose/lib/options/populateOptions.js ***!
  \**************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst clone = __webpack_require__(/*! ../helpers/clone */ \"./node_modules/mongoose/lib/helpers/clone.js\");\n\nclass PopulateOptions {\n  constructor(obj) {\n    this._docs = {};\n    this._childDocs = [];\n\n    if (obj == null) {\n      return;\n    }\n    obj = clone(obj);\n    Object.assign(this, obj);\n    if (typeof obj.subPopulate === 'object') {\n      this.populate = obj.subPopulate;\n    }\n\n\n    if (obj.perDocumentLimit != null && obj.limit != null) {\n      throw new Error('Can not use `limit` and `perDocumentLimit` at the same time. Path: `' + obj.path + '`.');\n    }\n  }\n}\n\n/**\n * The connection used to look up models by name. If not specified, Mongoose\n * will default to using the connection associated with the model in\n * `PopulateOptions#model`.\n *\n * @memberOf PopulateOptions\n * @property {Connection} connection\n * @api public\n */\n\nmodule.exports = PopulateOptions;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/options/populateOptions.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/options/propertyOptions.js":
/*!**************************************************************!*\
  !*** ./node_modules/mongoose/lib/options/propertyOptions.js ***!
  \**************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = Object.freeze({\n  enumerable: true,\n  configurable: true,\n  writable: true,\n  value: void 0\n});\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/options/propertyOptions.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/options/saveOptions.js":
/*!**********************************************************!*\
  !*** ./node_modules/mongoose/lib/options/saveOptions.js ***!
  \**********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst clone = __webpack_require__(/*! ../helpers/clone */ \"./node_modules/mongoose/lib/helpers/clone.js\");\n\nclass SaveOptions {\n  constructor(obj) {\n    if (obj == null) {\n      return;\n    }\n    Object.assign(this, clone(obj));\n  }\n}\n\nmodule.exports = SaveOptions;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/options/saveOptions.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/options/schemaArrayOptions.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mongoose/lib/options/schemaArrayOptions.js ***!
  \*****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst SchemaTypeOptions = __webpack_require__(/*! ./schemaTypeOptions */ \"./node_modules/mongoose/lib/options/schemaTypeOptions.js\");\n\n/**\n * The options defined on an Array schematype.\n *\n * #### Example:\n *\n *     const schema = new Schema({ tags: [String] });\n *     schema.path('tags').options; // SchemaArrayOptions instance\n *\n * @api public\n * @inherits SchemaTypeOptions\n * @constructor SchemaArrayOptions\n */\n\nclass SchemaArrayOptions extends SchemaTypeOptions {}\n\nconst opts = __webpack_require__(/*! ./propertyOptions */ \"./node_modules/mongoose/lib/options/propertyOptions.js\");\n\n/**\n * If this is an array of strings, an array of allowed values for this path.\n * Throws an error if this array isn't an array of strings.\n *\n * @api public\n * @property enum\n * @memberOf SchemaArrayOptions\n * @type {Array}\n * @instance\n */\n\nObject.defineProperty(SchemaArrayOptions.prototype, 'enum', opts);\n\n/**\n * If set, specifies the type of this array's values. Equivalent to setting\n * `type` to an array whose first element is `of`.\n *\n * #### Example:\n *\n *     // `arr` is an array of numbers.\n *     new Schema({ arr: [Number] });\n *     // Equivalent way to define `arr` as an array of numbers\n *     new Schema({ arr: { type: Array, of: Number } });\n *\n * @api public\n * @property of\n * @memberOf SchemaArrayOptions\n * @type {Function|String}\n * @instance\n */\n\nObject.defineProperty(SchemaArrayOptions.prototype, 'of', opts);\n\n/**\n * If set to `false`, will always deactivate casting non-array values to arrays.\n * If set to `true`, will cast non-array values to arrays if `init` and `SchemaArray.options.castNonArrays` are also `true`\n *\n * #### Example:\n *\n *     const Model = db.model('Test', new Schema({ x1: { castNonArrays: false, type: [String] } }));\n *     const doc = new Model({ x1: \"some non-array value\" });\n *     await doc.validate(); // Errors with \"CastError\"\n *\n * @api public\n * @property castNonArrays\n * @memberOf SchemaArrayOptions\n * @type {Boolean}\n * @instance\n */\n\nObject.defineProperty(SchemaArrayOptions.prototype, 'castNonArrays', opts);\n\n/*!\n * ignore\n */\n\nmodule.exports = SchemaArrayOptions;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/options/schemaArrayOptions.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/options/schemaBufferOptions.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongoose/lib/options/schemaBufferOptions.js ***!
  \******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst SchemaTypeOptions = __webpack_require__(/*! ./schemaTypeOptions */ \"./node_modules/mongoose/lib/options/schemaTypeOptions.js\");\n\n/**\n * The options defined on a Buffer schematype.\n *\n * #### Example:\n *\n *     const schema = new Schema({ bitmap: Buffer });\n *     schema.path('bitmap').options; // SchemaBufferOptions instance\n *\n * @api public\n * @inherits SchemaTypeOptions\n * @constructor SchemaBufferOptions\n */\n\nclass SchemaBufferOptions extends SchemaTypeOptions {}\n\nconst opts = __webpack_require__(/*! ./propertyOptions */ \"./node_modules/mongoose/lib/options/propertyOptions.js\");\n\n/**\n * Set the default subtype for this buffer.\n *\n * @api public\n * @property subtype\n * @memberOf SchemaBufferOptions\n * @type {Number}\n * @instance\n */\n\nObject.defineProperty(SchemaBufferOptions.prototype, 'subtype', opts);\n\n/*!\n * ignore\n */\n\nmodule.exports = SchemaBufferOptions;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/options/schemaBufferOptions.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/options/schemaDateOptions.js":
/*!****************************************************************!*\
  !*** ./node_modules/mongoose/lib/options/schemaDateOptions.js ***!
  \****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst SchemaTypeOptions = __webpack_require__(/*! ./schemaTypeOptions */ \"./node_modules/mongoose/lib/options/schemaTypeOptions.js\");\n\n/**\n * The options defined on a Date schematype.\n *\n * #### Example:\n *\n *     const schema = new Schema({ startedAt: Date });\n *     schema.path('startedAt').options; // SchemaDateOptions instance\n *\n * @api public\n * @inherits SchemaTypeOptions\n * @constructor SchemaDateOptions\n */\n\nclass SchemaDateOptions extends SchemaTypeOptions {}\n\nconst opts = __webpack_require__(/*! ./propertyOptions */ \"./node_modules/mongoose/lib/options/propertyOptions.js\");\n\n/**\n * If set, Mongoose adds a validator that checks that this path is after the\n * given `min`.\n *\n * @api public\n * @property min\n * @memberOf SchemaDateOptions\n * @type {Date}\n * @instance\n */\n\nObject.defineProperty(SchemaDateOptions.prototype, 'min', opts);\n\n/**\n * If set, Mongoose adds a validator that checks that this path is before the\n * given `max`.\n *\n * @api public\n * @property max\n * @memberOf SchemaDateOptions\n * @type {Date}\n * @instance\n */\n\nObject.defineProperty(SchemaDateOptions.prototype, 'max', opts);\n\n/**\n * If set, Mongoose creates a TTL index on this path.\n *\n * mongo TTL index `expireAfterSeconds` value will take 'expires' value expressed in seconds.\n *\n * #### Example:\n *\n *     const schema = new Schema({ \"expireAt\": { type: Date,  expires: 11 } });\n *     // if 'expireAt' is set, then document expires at expireAt + 11 seconds\n *\n * @api public\n * @property expires\n * @memberOf SchemaDateOptions\n * @type {Date}\n * @instance\n */\n\nObject.defineProperty(SchemaDateOptions.prototype, 'expires', opts);\n\n/*!\n * ignore\n */\n\nmodule.exports = SchemaDateOptions;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/options/schemaDateOptions.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/options/schemaDocumentArrayOptions.js":
/*!*************************************************************************!*\
  !*** ./node_modules/mongoose/lib/options/schemaDocumentArrayOptions.js ***!
  \*************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst SchemaTypeOptions = __webpack_require__(/*! ./schemaTypeOptions */ \"./node_modules/mongoose/lib/options/schemaTypeOptions.js\");\n\n/**\n * The options defined on an Document Array schematype.\n *\n * #### Example:\n *\n *     const schema = new Schema({ users: [{ name: string }] });\n *     schema.path('users').options; // SchemaDocumentArrayOptions instance\n *\n * @api public\n * @inherits SchemaTypeOptions\n * @constructor SchemaDocumentOptions\n */\n\nclass SchemaDocumentArrayOptions extends SchemaTypeOptions {}\n\nconst opts = __webpack_require__(/*! ./propertyOptions */ \"./node_modules/mongoose/lib/options/propertyOptions.js\");\n\n/**\n * If `true`, Mongoose will skip building any indexes defined in this array's schema.\n * If not set, Mongoose will build all indexes defined in this array's schema.\n *\n * #### Example:\n *\n *     const childSchema = Schema({ name: { type: String, index: true } });\n *     // If `excludeIndexes` is `true`, Mongoose will skip building an index\n *     // on `arr.name`. Otherwise, Mongoose will build an index on `arr.name`.\n *     const parentSchema = Schema({\n *       arr: { type: [childSchema], excludeIndexes: true }\n *     });\n *\n * @api public\n * @property excludeIndexes\n * @memberOf SchemaDocumentArrayOptions\n * @type {Array}\n * @instance\n */\n\nObject.defineProperty(SchemaDocumentArrayOptions.prototype, 'excludeIndexes', opts);\n\n/**\n * If set, overwrites the child schema's `_id` option.\n *\n * #### Example:\n *\n *     const childSchema = Schema({ name: String });\n *     const parentSchema = Schema({\n *       child: { type: childSchema, _id: false }\n *     });\n *     parentSchema.path('child').schema.options._id; // false\n *\n * @api public\n * @property _id\n * @memberOf SchemaDocumentArrayOptions\n * @type {Array}\n * @instance\n */\n\nObject.defineProperty(SchemaDocumentArrayOptions.prototype, '_id', opts);\n\n/*!\n * ignore\n */\n\nmodule.exports = SchemaDocumentArrayOptions;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/options/schemaDocumentArrayOptions.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/options/schemaMapOptions.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongoose/lib/options/schemaMapOptions.js ***!
  \***************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst SchemaTypeOptions = __webpack_require__(/*! ./schemaTypeOptions */ \"./node_modules/mongoose/lib/options/schemaTypeOptions.js\");\n\n/**\n * The options defined on a Map schematype.\n *\n * #### Example:\n *\n *     const schema = new Schema({ socialMediaHandles: { type: Map, of: String } });\n *     schema.path('socialMediaHandles').options; // SchemaMapOptions instance\n *\n * @api public\n * @inherits SchemaTypeOptions\n * @constructor SchemaMapOptions\n */\n\nclass SchemaMapOptions extends SchemaTypeOptions {}\n\nconst opts = __webpack_require__(/*! ./propertyOptions */ \"./node_modules/mongoose/lib/options/propertyOptions.js\");\n\n/**\n * If set, specifies the type of this map's values. Mongoose will cast\n * this map's values to the given type.\n *\n * If not set, Mongoose will not cast the map's values.\n *\n * #### Example:\n *\n *     // Mongoose will cast `socialMediaHandles` values to strings\n *     const schema = new Schema({ socialMediaHandles: { type: Map, of: String } });\n *     schema.path('socialMediaHandles').options.of; // String\n *\n * @api public\n * @property of\n * @memberOf SchemaMapOptions\n * @type {Function|string}\n * @instance\n */\n\nObject.defineProperty(SchemaMapOptions.prototype, 'of', opts);\n\nmodule.exports = SchemaMapOptions;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/options/schemaMapOptions.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/options/schemaNumberOptions.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongoose/lib/options/schemaNumberOptions.js ***!
  \******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst SchemaTypeOptions = __webpack_require__(/*! ./schemaTypeOptions */ \"./node_modules/mongoose/lib/options/schemaTypeOptions.js\");\n\n/**\n * The options defined on a Number schematype.\n *\n * #### Example:\n *\n *     const schema = new Schema({ count: Number });\n *     schema.path('count').options; // SchemaNumberOptions instance\n *\n * @api public\n * @inherits SchemaTypeOptions\n * @constructor SchemaNumberOptions\n */\n\nclass SchemaNumberOptions extends SchemaTypeOptions {}\n\nconst opts = __webpack_require__(/*! ./propertyOptions */ \"./node_modules/mongoose/lib/options/propertyOptions.js\");\n\n/**\n * If set, Mongoose adds a validator that checks that this path is at least the\n * given `min`.\n *\n * @api public\n * @property min\n * @memberOf SchemaNumberOptions\n * @type {Number}\n * @instance\n */\n\nObject.defineProperty(SchemaNumberOptions.prototype, 'min', opts);\n\n/**\n * If set, Mongoose adds a validator that checks that this path is less than the\n * given `max`.\n *\n * @api public\n * @property max\n * @memberOf SchemaNumberOptions\n * @type {Number}\n * @instance\n */\n\nObject.defineProperty(SchemaNumberOptions.prototype, 'max', opts);\n\n/**\n * If set, Mongoose adds a validator that checks that this path is strictly\n * equal to one of the given values.\n *\n * #### Example:\n *\n *     const schema = new Schema({\n *       favoritePrime: {\n *         type: Number,\n *         enum: [3, 5, 7]\n *       }\n *     });\n *     schema.path('favoritePrime').options.enum; // [3, 5, 7]\n *\n * @api public\n * @property enum\n * @memberOf SchemaNumberOptions\n * @type {Array}\n * @instance\n */\n\nObject.defineProperty(SchemaNumberOptions.prototype, 'enum', opts);\n\n/**\n * Sets default [populate options](https://mongoosejs.com/docs/populate.html#query-conditions).\n *\n * #### Example:\n *\n *     const schema = new Schema({\n *       child: {\n *         type: Number,\n *         ref: 'Child',\n *         populate: { select: 'name' }\n *       }\n *     });\n *     const Parent = mongoose.model('Parent', schema);\n *\n *     // Automatically adds `.select('name')`\n *     Parent.findOne().populate('child');\n *\n * @api public\n * @property populate\n * @memberOf SchemaNumberOptions\n * @type {Object}\n * @instance\n */\n\nObject.defineProperty(SchemaNumberOptions.prototype, 'populate', opts);\n\n/*!\n * ignore\n */\n\nmodule.exports = SchemaNumberOptions;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/options/schemaNumberOptions.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/options/schemaObjectIdOptions.js":
/*!********************************************************************!*\
  !*** ./node_modules/mongoose/lib/options/schemaObjectIdOptions.js ***!
  \********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst SchemaTypeOptions = __webpack_require__(/*! ./schemaTypeOptions */ \"./node_modules/mongoose/lib/options/schemaTypeOptions.js\");\n\n/**\n * The options defined on an ObjectId schematype.\n *\n * #### Example:\n *\n *     const schema = new Schema({ testId: mongoose.ObjectId });\n *     schema.path('testId').options; // SchemaObjectIdOptions instance\n *\n * @api public\n * @inherits SchemaTypeOptions\n * @constructor SchemaObjectIdOptions\n */\n\nclass SchemaObjectIdOptions extends SchemaTypeOptions {}\n\nconst opts = __webpack_require__(/*! ./propertyOptions */ \"./node_modules/mongoose/lib/options/propertyOptions.js\");\n\n/**\n * If truthy, uses Mongoose's default built-in ObjectId path.\n *\n * @api public\n * @property auto\n * @memberOf SchemaObjectIdOptions\n * @type {Boolean}\n * @instance\n */\n\nObject.defineProperty(SchemaObjectIdOptions.prototype, 'auto', opts);\n\n/**\n * Sets default [populate options](https://mongoosejs.com/docs/populate.html#query-conditions).\n *\n * #### Example:\n *\n *     const schema = new Schema({\n *       child: {\n *         type: 'ObjectId',\n *         ref: 'Child',\n *         populate: { select: 'name' }\n *       }\n *     });\n *     const Parent = mongoose.model('Parent', schema);\n *\n *     // Automatically adds `.select('name')`\n *     Parent.findOne().populate('child');\n *\n * @api public\n * @property populate\n * @memberOf SchemaObjectIdOptions\n * @type {Object}\n * @instance\n */\n\nObject.defineProperty(SchemaObjectIdOptions.prototype, 'populate', opts);\n\n/*!\n * ignore\n */\n\nmodule.exports = SchemaObjectIdOptions;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/options/schemaObjectIdOptions.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/options/schemaStringOptions.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongoose/lib/options/schemaStringOptions.js ***!
  \******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst SchemaTypeOptions = __webpack_require__(/*! ./schemaTypeOptions */ \"./node_modules/mongoose/lib/options/schemaTypeOptions.js\");\n\n/**\n * The options defined on a string schematype.\n *\n * #### Example:\n *\n *     const schema = new Schema({ name: String });\n *     schema.path('name').options; // SchemaStringOptions instance\n *\n * @api public\n * @inherits SchemaTypeOptions\n * @constructor SchemaStringOptions\n */\n\nclass SchemaStringOptions extends SchemaTypeOptions {}\n\nconst opts = __webpack_require__(/*! ./propertyOptions */ \"./node_modules/mongoose/lib/options/propertyOptions.js\");\n\n/**\n * Array of allowed values for this path\n *\n * @api public\n * @property enum\n * @memberOf SchemaStringOptions\n * @type {Array}\n * @instance\n */\n\nObject.defineProperty(SchemaStringOptions.prototype, 'enum', opts);\n\n/**\n * Attach a validator that succeeds if the data string matches the given regular\n * expression, and fails otherwise.\n *\n * @api public\n * @property match\n * @memberOf SchemaStringOptions\n * @type {RegExp}\n * @instance\n */\n\nObject.defineProperty(SchemaStringOptions.prototype, 'match', opts);\n\n/**\n * If truthy, Mongoose will add a custom setter that lowercases this string\n * using JavaScript's built-in `String#toLowerCase()`.\n *\n * @api public\n * @property lowercase\n * @memberOf SchemaStringOptions\n * @type {Boolean}\n * @instance\n */\n\nObject.defineProperty(SchemaStringOptions.prototype, 'lowercase', opts);\n\n/**\n * If truthy, Mongoose will add a custom setter that removes leading and trailing\n * whitespace using [JavaScript's built-in `String#trim()`](https://masteringjs.io/tutorials/fundamentals/trim-string).\n *\n * @api public\n * @property trim\n * @memberOf SchemaStringOptions\n * @type {Boolean}\n * @instance\n */\n\nObject.defineProperty(SchemaStringOptions.prototype, 'trim', opts);\n\n/**\n * If truthy, Mongoose will add a custom setter that uppercases this string\n * using JavaScript's built-in [`String#toUpperCase()`](https://masteringjs.io/tutorials/fundamentals/uppercase).\n *\n * @api public\n * @property uppercase\n * @memberOf SchemaStringOptions\n * @type {Boolean}\n * @instance\n */\n\nObject.defineProperty(SchemaStringOptions.prototype, 'uppercase', opts);\n\n/**\n * If set, Mongoose will add a custom validator that ensures the given\n * string's `length` is at least the given number.\n *\n * Mongoose supports two different spellings for this option: `minLength` and `minlength`.\n * `minLength` is the recommended way to specify this option, but Mongoose also supports\n * `minlength` (lowercase \"l\").\n *\n * @api public\n * @property minLength\n * @memberOf SchemaStringOptions\n * @type {Number}\n * @instance\n */\n\nObject.defineProperty(SchemaStringOptions.prototype, 'minLength', opts);\nObject.defineProperty(SchemaStringOptions.prototype, 'minlength', opts);\n\n/**\n * If set, Mongoose will add a custom validator that ensures the given\n * string's `length` is at most the given number.\n *\n * Mongoose supports two different spellings for this option: `maxLength` and `maxlength`.\n * `maxLength` is the recommended way to specify this option, but Mongoose also supports\n * `maxlength` (lowercase \"l\").\n *\n * @api public\n * @property maxLength\n * @memberOf SchemaStringOptions\n * @type {Number}\n * @instance\n */\n\nObject.defineProperty(SchemaStringOptions.prototype, 'maxLength', opts);\nObject.defineProperty(SchemaStringOptions.prototype, 'maxlength', opts);\n\n/**\n * Sets default [populate options](https://mongoosejs.com/docs/populate.html#query-conditions).\n *\n * @api public\n * @property populate\n * @memberOf SchemaStringOptions\n * @type {Object}\n * @instance\n */\n\nObject.defineProperty(SchemaStringOptions.prototype, 'populate', opts);\n\n/*!\n * ignore\n */\n\nmodule.exports = SchemaStringOptions;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/options/schemaStringOptions.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/options/schemaSubdocumentOptions.js":
/*!***********************************************************************!*\
  !*** ./node_modules/mongoose/lib/options/schemaSubdocumentOptions.js ***!
  \***********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst SchemaTypeOptions = __webpack_require__(/*! ./schemaTypeOptions */ \"./node_modules/mongoose/lib/options/schemaTypeOptions.js\");\n\n/**\n * The options defined on a single nested schematype.\n *\n * #### Example:\n *\n *     const schema = Schema({ child: Schema({ name: String }) });\n *     schema.path('child').options; // SchemaSubdocumentOptions instance\n *\n * @api public\n * @inherits SchemaTypeOptions\n * @constructor SchemaSubdocumentOptions\n */\n\nclass SchemaSubdocumentOptions extends SchemaTypeOptions {}\n\nconst opts = __webpack_require__(/*! ./propertyOptions */ \"./node_modules/mongoose/lib/options/propertyOptions.js\");\n\n/**\n * If set, overwrites the child schema's `_id` option.\n *\n * #### Example:\n *\n *     const childSchema = Schema({ name: String });\n *     const parentSchema = Schema({\n *       child: { type: childSchema, _id: false }\n *     });\n *     parentSchema.path('child').schema.options._id; // false\n *\n * @api public\n * @property of\n * @memberOf SchemaSubdocumentOptions\n * @type {Function|string}\n * @instance\n */\n\nObject.defineProperty(SchemaSubdocumentOptions.prototype, '_id', opts);\n\nmodule.exports = SchemaSubdocumentOptions;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/options/schemaSubdocumentOptions.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/options/schemaTypeOptions.js":
/*!****************************************************************!*\
  !*** ./node_modules/mongoose/lib/options/schemaTypeOptions.js ***!
  \****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst clone = __webpack_require__(/*! ../helpers/clone */ \"./node_modules/mongoose/lib/helpers/clone.js\");\n\n/**\n * The options defined on a schematype.\n *\n * #### Example:\n *\n *     const schema = new Schema({ name: String });\n *     schema.path('name').options instanceof mongoose.SchemaTypeOptions; // true\n *\n * @api public\n * @constructor SchemaTypeOptions\n */\n\nclass SchemaTypeOptions {\n  constructor(obj) {\n    if (obj == null) {\n      return this;\n    }\n    Object.assign(this, clone(obj));\n  }\n}\n\nconst opts = __webpack_require__(/*! ./propertyOptions */ \"./node_modules/mongoose/lib/options/propertyOptions.js\");\n\n/**\n * The type to cast this path to.\n *\n * @api public\n * @property type\n * @memberOf SchemaTypeOptions\n * @type {Function|String|Object}\n * @instance\n */\n\nObject.defineProperty(SchemaTypeOptions.prototype, 'type', opts);\n\n/**\n * Function or object describing how to validate this schematype.\n *\n * @api public\n * @property validate\n * @memberOf SchemaTypeOptions\n * @type {Function|Object}\n * @instance\n */\n\nObject.defineProperty(SchemaTypeOptions.prototype, 'validate', opts);\n\n/**\n * Allows overriding casting logic for this individual path. If a string, the\n * given string overwrites Mongoose's default cast error message.\n *\n * #### Example:\n *\n *     const schema = new Schema({\n *       num: {\n *         type: Number,\n *         cast: '{VALUE} is not a valid number'\n *       }\n *     });\n *\n *     // Throws 'CastError: \"bad\" is not a valid number'\n *     schema.path('num').cast('bad');\n *\n *     const Model = mongoose.model('Test', schema);\n *     const doc = new Model({ num: 'fail' });\n *     const err = doc.validateSync();\n *\n *     err.errors['num']; // 'CastError: \"fail\" is not a valid number'\n *\n * @api public\n * @property cast\n * @memberOf SchemaTypeOptions\n * @type {String}\n * @instance\n */\n\nObject.defineProperty(SchemaTypeOptions.prototype, 'cast', opts);\n\n/**\n * If true, attach a required validator to this path, which ensures this path\n * cannot be set to a nullish value. If a function, Mongoose calls the\n * function and only checks for nullish values if the function returns a truthy value.\n *\n * @api public\n * @property required\n * @memberOf SchemaTypeOptions\n * @type {Function|Boolean}\n * @instance\n */\n\nObject.defineProperty(SchemaTypeOptions.prototype, 'required', opts);\n\n/**\n * The default value for this path. If a function, Mongoose executes the function\n * and uses the return value as the default.\n *\n * @api public\n * @property default\n * @memberOf SchemaTypeOptions\n * @type {Function|Any}\n * @instance\n */\n\nObject.defineProperty(SchemaTypeOptions.prototype, 'default', opts);\n\n/**\n * The model that `populate()` should use if populating this path.\n *\n * @api public\n * @property ref\n * @memberOf SchemaTypeOptions\n * @type {Function|String}\n * @instance\n */\n\nObject.defineProperty(SchemaTypeOptions.prototype, 'ref', opts);\n\n/**\n * The path in the document that `populate()` should use to find the model\n * to use.\n *\n * @api public\n * @property ref\n * @memberOf SchemaTypeOptions\n * @type {Function|String}\n * @instance\n */\n\nObject.defineProperty(SchemaTypeOptions.prototype, 'refPath', opts);\n\n/**\n * Whether to include or exclude this path by default when loading documents\n * using `find()`, `findOne()`, etc.\n *\n * @api public\n * @property select\n * @memberOf SchemaTypeOptions\n * @type {Boolean|Number}\n * @instance\n */\n\nObject.defineProperty(SchemaTypeOptions.prototype, 'select', opts);\n\n/**\n * If [truthy](https://masteringjs.io/tutorials/fundamentals/truthy), Mongoose will\n * build an index on this path when the model is compiled.\n *\n * @api public\n * @property index\n * @memberOf SchemaTypeOptions\n * @type {Boolean|Number|Object}\n * @instance\n */\n\nObject.defineProperty(SchemaTypeOptions.prototype, 'index', opts);\n\n/**\n * If [truthy](https://masteringjs.io/tutorials/fundamentals/truthy), Mongoose\n * will build a unique index on this path when the\n * model is compiled. [The `unique` option is **not** a validator](https://mongoosejs.com/docs/validation.html#the-unique-option-is-not-a-validator).\n *\n * @api public\n * @property unique\n * @memberOf SchemaTypeOptions\n * @type {Boolean|Number}\n * @instance\n */\n\nObject.defineProperty(SchemaTypeOptions.prototype, 'unique', opts);\n\n/**\n * If [truthy](https://masteringjs.io/tutorials/fundamentals/truthy), Mongoose will\n * disallow changes to this path once the document\n * is saved to the database for the first time. Read more about [immutability in Mongoose here](https://thecodebarbarian.com/whats-new-in-mongoose-5-6-immutable-properties.html).\n *\n * @api public\n * @property immutable\n * @memberOf SchemaTypeOptions\n * @type {Function|Boolean}\n * @instance\n */\n\nObject.defineProperty(SchemaTypeOptions.prototype, 'immutable', opts);\n\n/**\n * If [truthy](https://masteringjs.io/tutorials/fundamentals/truthy), Mongoose will\n * build a sparse index on this path.\n *\n * @api public\n * @property sparse\n * @memberOf SchemaTypeOptions\n * @type {Boolean|Number}\n * @instance\n */\n\nObject.defineProperty(SchemaTypeOptions.prototype, 'sparse', opts);\n\n/**\n * If [truthy](https://masteringjs.io/tutorials/fundamentals/truthy), Mongoose\n * will build a text index on this path.\n *\n * @api public\n * @property text\n * @memberOf SchemaTypeOptions\n * @type {Boolean|Number|Object}\n * @instance\n */\n\nObject.defineProperty(SchemaTypeOptions.prototype, 'text', opts);\n\n/**\n * Define a transform function for this individual schema type.\n * Only called when calling `toJSON()` or `toObject()`.\n *\n * #### Example:\n *\n *     const schema = Schema({\n *       myDate: {\n *         type: Date,\n *         transform: v => v.getFullYear()\n *       }\n *     });\n *     const Model = mongoose.model('Test', schema);\n *\n *     const doc = new Model({ myDate: new Date('2019/06/01') });\n *     doc.myDate instanceof Date; // true\n *\n *     const res = doc.toObject({ transform: true });\n *     res.myDate; // 2019\n *\n * @api public\n * @property transform\n * @memberOf SchemaTypeOptions\n * @type {Function}\n * @instance\n */\n\nObject.defineProperty(SchemaTypeOptions.prototype, 'transform', opts);\n\nmodule.exports = SchemaTypeOptions;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/options/schemaTypeOptions.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/options/virtualOptions.js":
/*!*************************************************************!*\
  !*** ./node_modules/mongoose/lib/options/virtualOptions.js ***!
  \*************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst opts = __webpack_require__(/*! ./propertyOptions */ \"./node_modules/mongoose/lib/options/propertyOptions.js\");\n\nclass VirtualOptions {\n  constructor(obj) {\n    Object.assign(this, obj);\n\n    if (obj != null && obj.options != null) {\n      this.options = Object.assign({}, obj.options);\n    }\n  }\n}\n\n/**\n * Marks this virtual as a populate virtual, and specifies the model to\n * use for populate.\n *\n * @api public\n * @property ref\n * @memberOf VirtualOptions\n * @type {String|Model|Function}\n * @instance\n */\n\nObject.defineProperty(VirtualOptions.prototype, 'ref', opts);\n\n/**\n * Marks this virtual as a populate virtual, and specifies the path that\n * contains the name of the model to populate\n *\n * @api public\n * @property refPath\n * @memberOf VirtualOptions\n * @type {String|Function}\n * @instance\n */\n\nObject.defineProperty(VirtualOptions.prototype, 'refPath', opts);\n\n/**\n * The name of the property in the local model to match to `foreignField`\n * in the foreign model.\n *\n * @api public\n * @property localField\n * @memberOf VirtualOptions\n * @type {String|Function}\n * @instance\n */\n\nObject.defineProperty(VirtualOptions.prototype, 'localField', opts);\n\n/**\n * The name of the property in the foreign model to match to `localField`\n * in the local model.\n *\n * @api public\n * @property foreignField\n * @memberOf VirtualOptions\n * @type {String|Function}\n * @instance\n */\n\nObject.defineProperty(VirtualOptions.prototype, 'foreignField', opts);\n\n/**\n * Whether to populate this virtual as a single document (true) or an\n * array of documents (false).\n *\n * @api public\n * @property justOne\n * @memberOf VirtualOptions\n * @type {Boolean}\n * @instance\n */\n\nObject.defineProperty(VirtualOptions.prototype, 'justOne', opts);\n\n/**\n * If true, populate just the number of documents where `localField`\n * matches `foreignField`, as opposed to the documents themselves.\n *\n * If `count` is set, it overrides `justOne`.\n *\n * @api public\n * @property count\n * @memberOf VirtualOptions\n * @type {Boolean}\n * @instance\n */\n\nObject.defineProperty(VirtualOptions.prototype, 'count', opts);\n\n/**\n * Add an additional filter to populate, in addition to `localField`\n * matches `foreignField`.\n *\n * @api public\n * @property match\n * @memberOf VirtualOptions\n * @type {Object|Function}\n * @instance\n */\n\nObject.defineProperty(VirtualOptions.prototype, 'match', opts);\n\n/**\n * Additional options to pass to the query used to `populate()`:\n *\n * - `sort`\n * - `skip`\n * - `limit`\n *\n * @api public\n * @property options\n * @memberOf VirtualOptions\n * @type {Object}\n * @instance\n */\n\nObject.defineProperty(VirtualOptions.prototype, 'options', opts);\n\n/**\n * If true, add a `skip` to the query used to `populate()`.\n *\n * @api public\n * @property skip\n * @memberOf VirtualOptions\n * @type {Number}\n * @instance\n */\n\nObject.defineProperty(VirtualOptions.prototype, 'skip', opts);\n\n/**\n * If true, add a `limit` to the query used to `populate()`.\n *\n * @api public\n * @property limit\n * @memberOf VirtualOptions\n * @type {Number}\n * @instance\n */\n\nObject.defineProperty(VirtualOptions.prototype, 'limit', opts);\n\n/**\n * The `limit` option for `populate()` has [some unfortunate edge cases](https://mongoosejs.com/docs/populate.html#query-conditions)\n * when working with multiple documents, like `.find().populate()`. The\n * `perDocumentLimit` option makes `populate()` execute a separate query\n * for each document returned from `find()` to ensure each document\n * gets up to `perDocumentLimit` populated docs if possible.\n *\n * @api public\n * @property perDocumentLimit\n * @memberOf VirtualOptions\n * @type {Number}\n * @instance\n */\n\nObject.defineProperty(VirtualOptions.prototype, 'perDocumentLimit', opts);\n\nmodule.exports = VirtualOptions;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/options/virtualOptions.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/plugins/index.js":
/*!****************************************************!*\
  !*** ./node_modules/mongoose/lib/plugins/index.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nexports.saveSubdocs = __webpack_require__(/*! ./saveSubdocs */ \"./node_modules/mongoose/lib/plugins/saveSubdocs.js\");\nexports.sharding = __webpack_require__(/*! ./sharding */ \"./node_modules/mongoose/lib/plugins/sharding.js\");\nexports.trackTransaction = __webpack_require__(/*! ./trackTransaction */ \"./node_modules/mongoose/lib/plugins/trackTransaction.js\");\nexports.validateBeforeSave = __webpack_require__(/*! ./validateBeforeSave */ \"./node_modules/mongoose/lib/plugins/validateBeforeSave.js\");\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/plugins/index.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/plugins/saveSubdocs.js":
/*!**********************************************************!*\
  !*** ./node_modules/mongoose/lib/plugins/saveSubdocs.js ***!
  \**********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst each = __webpack_require__(/*! ../helpers/each */ \"./node_modules/mongoose/lib/helpers/each.js\");\n\n/*!\n * ignore\n */\n\nmodule.exports = function saveSubdocs(schema) {\n  const unshift = true;\n  schema.s.hooks.pre('save', false, function saveSubdocsPreSave(next) {\n    if (this.$isSubdocument) {\n      next();\n      return;\n    }\n\n    const _this = this;\n    const subdocs = this.$getAllSubdocs();\n\n    if (!subdocs.length) {\n      next();\n      return;\n    }\n\n    each(subdocs, function(subdoc, cb) {\n      subdoc.$__schema.s.hooks.execPre('save', subdoc, function(err) {\n        cb(err);\n      });\n    }, function(error) {\n      if (error) {\n        return _this.$__schema.s.hooks.execPost('save:error', _this, [_this], { error: error }, function(error) {\n          next(error);\n        });\n      }\n      next();\n    });\n  }, null, unshift);\n\n  schema.s.hooks.post('save', async function saveSubdocsPostDeleteOne() {\n    const removedSubdocs = this.$__.removedSubdocs;\n    if (!removedSubdocs || !removedSubdocs.length) {\n      return;\n    }\n\n    const promises = [];\n    for (const subdoc of removedSubdocs) {\n      promises.push(new Promise((resolve, reject) => {\n        subdoc.$__schema.s.hooks.execPost('deleteOne', subdoc, [subdoc], function(err) {\n          if (err) {\n            return reject(err);\n          }\n          resolve();\n        });\n      }));\n    }\n\n    this.$__.removedSubdocs = null;\n    await Promise.all(promises);\n  });\n\n  schema.s.hooks.post('save', async function saveSubdocsPostSave() {\n    if (this.$isSubdocument) {\n      return;\n    }\n\n    const _this = this;\n    const subdocs = this.$getAllSubdocs();\n\n    if (!subdocs.length) {\n      return;\n    }\n\n    const promises = [];\n    for (const subdoc of subdocs) {\n      promises.push(new Promise((resolve, reject) => {\n        subdoc.$__schema.s.hooks.execPost('save', subdoc, [subdoc], function(err) {\n          if (err) {\n            return reject(err);\n          }\n          resolve();\n        });\n      }));\n    }\n\n    try {\n      await Promise.all(promises);\n    } catch (error) {\n      await new Promise((resolve, reject) => {\n        this.$__schema.s.hooks.execPost('save:error', _this, [_this], { error: error }, function(error) {\n          if (error) {\n            return reject(error);\n          }\n          resolve();\n        });\n      });\n    }\n  }, null, unshift);\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/plugins/saveSubdocs.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/plugins/sharding.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongoose/lib/plugins/sharding.js ***!
  \*******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst objectIdSymbol = (__webpack_require__(/*! ../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").objectIdSymbol);\nconst utils = __webpack_require__(/*! ../utils */ \"./node_modules/mongoose/lib/utils.js\");\n\n/*!\n * ignore\n */\n\nmodule.exports = function shardingPlugin(schema) {\n  schema.post('init', function shardingPluginPostInit() {\n    storeShard.call(this);\n    return this;\n  });\n  schema.pre('save', function shardingPluginPreSave(next) {\n    applyWhere.call(this);\n    next();\n  });\n  schema.pre('remove', function shardingPluginPreRemove(next) {\n    applyWhere.call(this);\n    next();\n  });\n  schema.post('save', function shardingPluginPostSave() {\n    storeShard.call(this);\n  });\n};\n\n/*!\n * ignore\n */\n\nfunction applyWhere() {\n  let paths;\n  let len;\n\n  if (this.$__.shardval) {\n    paths = Object.keys(this.$__.shardval);\n    len = paths.length;\n\n    this.$where = this.$where || {};\n    for (let i = 0; i < len; ++i) {\n      this.$where[paths[i]] = this.$__.shardval[paths[i]];\n    }\n  }\n}\n\n/*!\n * ignore\n */\n\nmodule.exports.storeShard = storeShard;\n\n/*!\n * ignore\n */\n\nfunction storeShard() {\n  // backwards compat\n  const key = this.$__schema.options.shardKey || this.$__schema.options.shardkey;\n  if (!utils.isPOJO(key)) {\n    return;\n  }\n\n  const orig = this.$__.shardval = {};\n  const paths = Object.keys(key);\n  const len = paths.length;\n  let val;\n\n  for (let i = 0; i < len; ++i) {\n    val = this.$__getValue(paths[i]);\n    if (val == null) {\n      orig[paths[i]] = val;\n    } else if (utils.isMongooseObject(val)) {\n      orig[paths[i]] = val.toObject({ depopulate: true, _isNested: true });\n    } else if (val instanceof Date || val[objectIdSymbol]) {\n      orig[paths[i]] = val;\n    } else if (typeof val.valueOf === 'function') {\n      orig[paths[i]] = val.valueOf();\n    } else {\n      orig[paths[i]] = val;\n    }\n  }\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/plugins/sharding.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/plugins/trackTransaction.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongoose/lib/plugins/trackTransaction.js ***!
  \***************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst arrayAtomicsSymbol = (__webpack_require__(/*! ../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").arrayAtomicsSymbol);\nconst sessionNewDocuments = (__webpack_require__(/*! ../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").sessionNewDocuments);\nconst utils = __webpack_require__(/*! ../utils */ \"./node_modules/mongoose/lib/utils.js\");\n\nmodule.exports = function trackTransaction(schema) {\n  schema.pre('save', function trackTransactionPreSave() {\n    const session = this.$session();\n    if (session == null) {\n      return;\n    }\n    if (session.transaction == null || session[sessionNewDocuments] == null) {\n      return;\n    }\n\n    if (!session[sessionNewDocuments].has(this)) {\n      const initialState = {};\n      if (this.isNew) {\n        initialState.isNew = true;\n      }\n      if (this.$__schema.options.versionKey) {\n        initialState.versionKey = this.get(this.$__schema.options.versionKey);\n      }\n\n      initialState.modifiedPaths = new Set(Object.keys(this.$__.activePaths.getStatePaths('modify')));\n      initialState.atomics = _getAtomics(this);\n\n      session[sessionNewDocuments].set(this, initialState);\n    } else {\n      const state = session[sessionNewDocuments].get(this);\n\n      for (const path of Object.keys(this.$__.activePaths.getStatePaths('modify'))) {\n        state.modifiedPaths.add(path);\n      }\n      state.atomics = _getAtomics(this, state.atomics);\n    }\n  });\n};\n\nfunction _getAtomics(doc, previous) {\n  const pathToAtomics = new Map();\n  previous = previous || new Map();\n\n  const pathsToCheck = Object.keys(doc.$__.activePaths.init).concat(Object.keys(doc.$__.activePaths.modify));\n\n  for (const path of pathsToCheck) {\n    const val = doc.$__getValue(path);\n    if (val != null &&\n        Array.isArray(val) &&\n        utils.isMongooseDocumentArray(val) &&\n        val.length &&\n        val[arrayAtomicsSymbol] != null &&\n        Object.keys(val[arrayAtomicsSymbol]).length !== 0) {\n      const existing = previous.get(path) || {};\n      pathToAtomics.set(path, mergeAtomics(existing, val[arrayAtomicsSymbol]));\n    }\n  }\n\n  const dirty = doc.$__dirty();\n  for (const dirt of dirty) {\n    const path = dirt.path;\n\n    const val = dirt.value;\n    if (val != null && val[arrayAtomicsSymbol] != null && Object.keys(val[arrayAtomicsSymbol]).length !== 0) {\n      const existing = previous.get(path) || {};\n      pathToAtomics.set(path, mergeAtomics(existing, val[arrayAtomicsSymbol]));\n    }\n  }\n\n  return pathToAtomics;\n}\n\nfunction mergeAtomics(destination, source) {\n  destination = destination || {};\n\n  if (source.$pullAll != null) {\n    destination.$pullAll = (destination.$pullAll || []).concat(source.$pullAll);\n  }\n  if (source.$push != null) {\n    destination.$push = destination.$push || {};\n    destination.$push.$each = (destination.$push.$each || []).concat(source.$push.$each);\n  }\n  if (source.$addToSet != null) {\n    destination.$addToSet = (destination.$addToSet || []).concat(source.$addToSet);\n  }\n  if (source.$set != null) {\n    destination.$set = Array.isArray(source.$set) ? [...source.$set] : Object.assign({}, source.$set);\n  }\n\n  return destination;\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/plugins/trackTransaction.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/plugins/validateBeforeSave.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mongoose/lib/plugins/validateBeforeSave.js ***!
  \*****************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/*!\n * ignore\n */\n\nmodule.exports = function validateBeforeSave(schema) {\n  const unshift = true;\n  schema.pre('save', false, function validateBeforeSave(next, options) {\n    const _this = this;\n    // Nested docs have their own presave\n    if (this.$isSubdocument) {\n      return next();\n    }\n\n    const hasValidateBeforeSaveOption = options &&\n        (typeof options === 'object') &&\n        ('validateBeforeSave' in options);\n\n    let shouldValidate;\n    if (hasValidateBeforeSaveOption) {\n      shouldValidate = !!options.validateBeforeSave;\n    } else {\n      shouldValidate = this.$__schema.options.validateBeforeSave;\n    }\n\n    // Validate\n    if (shouldValidate) {\n      const hasValidateModifiedOnlyOption = options &&\n          (typeof options === 'object') &&\n          ('validateModifiedOnly' in options);\n      const validateOptions = hasValidateModifiedOnlyOption ?\n        { validateModifiedOnly: options.validateModifiedOnly } :\n        null;\n      this.$validate(validateOptions).then(\n        () => {\n          this.$op = 'save';\n          next();\n        },\n        error => {\n          _this.$__schema.s.hooks.execPost('save:error', _this, [_this], { error: error }, function(error) {\n            _this.$op = 'save';\n            next(error);\n          });\n        }\n      );\n    } else {\n      next();\n    }\n  }, null, unshift);\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/plugins/validateBeforeSave.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/query.js":
/*!********************************************!*\
  !*** ./node_modules/mongoose/lib/query.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst CastError = __webpack_require__(/*! ./error/cast */ \"./node_modules/mongoose/lib/error/cast.js\");\nconst DocumentNotFoundError = __webpack_require__(/*! ./error/notFound */ \"./node_modules/mongoose/lib/error/notFound.js\");\nconst Kareem = __webpack_require__(/*! kareem */ \"./node_modules/kareem/index.js\");\nconst MongooseError = __webpack_require__(/*! ./error/mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\nconst ObjectParameterError = __webpack_require__(/*! ./error/objectParameter */ \"./node_modules/mongoose/lib/error/objectParameter.js\");\nconst QueryCursor = __webpack_require__(/*! ./cursor/queryCursor */ \"./node_modules/mongoose/lib/cursor/queryCursor.js\");\nconst ValidationError = __webpack_require__(/*! ./error/validation */ \"./node_modules/mongoose/lib/error/validation.js\");\nconst { applyGlobalMaxTimeMS, applyGlobalDiskUse } = __webpack_require__(/*! ./helpers/query/applyGlobalOption */ \"./node_modules/mongoose/lib/helpers/query/applyGlobalOption.js\");\nconst handleReadPreferenceAliases = __webpack_require__(/*! ./helpers/query/handleReadPreferenceAliases */ \"./node_modules/mongoose/lib/helpers/query/handleReadPreferenceAliases.js\");\nconst applyReadConcern = __webpack_require__(/*! ./helpers/schema/applyReadConcern */ \"./node_modules/mongoose/lib/helpers/schema/applyReadConcern.js\");\nconst applyWriteConcern = __webpack_require__(/*! ./helpers/schema/applyWriteConcern */ \"./node_modules/mongoose/lib/helpers/schema/applyWriteConcern.js\");\nconst cast = __webpack_require__(/*! ./cast */ \"./node_modules/mongoose/lib/cast.js\");\nconst castArrayFilters = __webpack_require__(/*! ./helpers/update/castArrayFilters */ \"./node_modules/mongoose/lib/helpers/update/castArrayFilters.js\");\nconst castNumber = __webpack_require__(/*! ./cast/number */ \"./node_modules/mongoose/lib/cast/number.js\");\nconst castUpdate = __webpack_require__(/*! ./helpers/query/castUpdate */ \"./node_modules/mongoose/lib/helpers/query/castUpdate.js\");\nconst clone = __webpack_require__(/*! ./helpers/clone */ \"./node_modules/mongoose/lib/helpers/clone.js\");\nconst getDiscriminatorByValue = __webpack_require__(/*! ./helpers/discriminator/getDiscriminatorByValue */ \"./node_modules/mongoose/lib/helpers/discriminator/getDiscriminatorByValue.js\");\nconst helpers = __webpack_require__(/*! ./queryHelpers */ \"./node_modules/mongoose/lib/queryHelpers.js\");\nconst immediate = __webpack_require__(/*! ./helpers/immediate */ \"./node_modules/mongoose/lib/helpers/immediate.js\");\nconst internalToObjectOptions = (__webpack_require__(/*! ./options */ \"./node_modules/mongoose/lib/options.js\").internalToObjectOptions);\nconst isExclusive = __webpack_require__(/*! ./helpers/projection/isExclusive */ \"./node_modules/mongoose/lib/helpers/projection/isExclusive.js\");\nconst isInclusive = __webpack_require__(/*! ./helpers/projection/isInclusive */ \"./node_modules/mongoose/lib/helpers/projection/isInclusive.js\");\nconst isPathSelectedInclusive = __webpack_require__(/*! ./helpers/projection/isPathSelectedInclusive */ \"./node_modules/mongoose/lib/helpers/projection/isPathSelectedInclusive.js\");\nconst isSubpath = __webpack_require__(/*! ./helpers/projection/isSubpath */ \"./node_modules/mongoose/lib/helpers/projection/isSubpath.js\");\nconst mpath = __webpack_require__(/*! mpath */ \"./node_modules/mpath/index.js\");\nconst mquery = __webpack_require__(/*! mquery */ \"./node_modules/mquery/lib/mquery.js\");\nconst parseProjection = __webpack_require__(/*! ./helpers/projection/parseProjection */ \"./node_modules/mongoose/lib/helpers/projection/parseProjection.js\");\nconst removeUnusedArrayFilters = __webpack_require__(/*! ./helpers/update/removeUnusedArrayFilters */ \"./node_modules/mongoose/lib/helpers/update/removeUnusedArrayFilters.js\");\nconst sanitizeFilter = __webpack_require__(/*! ./helpers/query/sanitizeFilter */ \"./node_modules/mongoose/lib/helpers/query/sanitizeFilter.js\");\nconst sanitizeProjection = __webpack_require__(/*! ./helpers/query/sanitizeProjection */ \"./node_modules/mongoose/lib/helpers/query/sanitizeProjection.js\");\nconst selectPopulatedFields = __webpack_require__(/*! ./helpers/query/selectPopulatedFields */ \"./node_modules/mongoose/lib/helpers/query/selectPopulatedFields.js\");\nconst setDefaultsOnInsert = __webpack_require__(/*! ./helpers/setDefaultsOnInsert */ \"./node_modules/mongoose/lib/helpers/setDefaultsOnInsert.js\");\nconst specialProperties = __webpack_require__(/*! ./helpers/specialProperties */ \"./node_modules/mongoose/lib/helpers/specialProperties.js\");\nconst updateValidators = __webpack_require__(/*! ./helpers/updateValidators */ \"./node_modules/mongoose/lib/helpers/updateValidators.js\");\nconst util = __webpack_require__(/*! util */ \"util\");\nconst utils = __webpack_require__(/*! ./utils */ \"./node_modules/mongoose/lib/utils.js\");\nconst queryMiddlewareFunctions = (__webpack_require__(/*! ./constants */ \"./node_modules/mongoose/lib/constants.js\").queryMiddlewareFunctions);\n\nconst queryOptionMethods = new Set([\n  'allowDiskUse',\n  'batchSize',\n  'collation',\n  'comment',\n  'explain',\n  'hint',\n  'j',\n  'lean',\n  'limit',\n  'maxTimeMS',\n  'populate',\n  'projection',\n  'read',\n  'select',\n  'skip',\n  'slice',\n  'sort',\n  'tailable',\n  'w',\n  'writeConcern',\n  'wtimeout'\n]);\n\n/**\n * Query constructor used for building queries. You do not need\n * to instantiate a `Query` directly. Instead use Model functions like\n * [`Model.find()`](https://mongoosejs.com/docs/api/model.html#Model.find()).\n *\n * #### Example:\n *\n *     const query = MyModel.find(); // `query` is an instance of `Query`\n *     query.setOptions({ lean : true });\n *     query.collection(MyModel.collection);\n *     query.where('age').gte(21).exec(callback);\n *\n *     // You can instantiate a query directly. There is no need to do\n *     // this unless you're an advanced user with a very good reason to.\n *     const query = new mongoose.Query();\n *\n * @param {Object} [options]\n * @param {Object} [model]\n * @param {Object} [conditions]\n * @param {Object} [collection] Mongoose collection\n * @api public\n */\n\nfunction Query(conditions, options, model, collection) {\n  // this stuff is for dealing with custom queries created by #toConstructor\n  if (!this._mongooseOptions) {\n    this._mongooseOptions = {};\n  }\n  options = options || {};\n\n  this._transforms = [];\n  this._hooks = new Kareem();\n  this._executionStack = null;\n\n  // this is the case where we have a CustomQuery, we need to check if we got\n  // options passed in, and if we did, merge them in\n  const keys = Object.keys(options);\n  for (const key of keys) {\n    this._mongooseOptions[key] = options[key];\n  }\n\n  if (collection) {\n    this.mongooseCollection = collection;\n  }\n\n  if (model) {\n    this.model = model;\n    this.schema = model.schema;\n  }\n\n  // this is needed because map reduce returns a model that can be queried, but\n  // all of the queries on said model should be lean\n  if (this.model && this.model._mapreduce) {\n    this.lean();\n  }\n\n  // inherit mquery\n  mquery.call(this, null, options);\n  if (collection) {\n    this.collection(collection);\n  }\n\n  if (conditions) {\n    this.find(conditions);\n  }\n\n  this.options = this.options || {};\n\n  // For gh-6880. mquery still needs to support `fields` by default for old\n  // versions of MongoDB\n  this.$useProjection = true;\n\n  const collation = this &&\n    this.schema &&\n    this.schema.options &&\n    this.schema.options.collation || null;\n  if (collation != null) {\n    this.options.collation = collation;\n  }\n}\n\n/*!\n * inherit mquery\n */\n\nQuery.prototype = new mquery();\nQuery.prototype.constructor = Query;\n\n// Remove some legacy methods that we removed in Mongoose 8, but\n// are still in mquery 5.\nQuery.prototype.count = undefined;\nQuery.prototype.findOneAndRemove = undefined;\n\nQuery.base = mquery.prototype;\n\n/*!\n * Overwrite mquery's `_distinct`, because Mongoose uses that name\n * to store the field to apply distinct on.\n */\n\nObject.defineProperty(Query.prototype, '_distinct', {\n  configurable: true,\n  writable: true,\n  enumerable: true,\n  value: undefined\n});\n\n/**\n * Flag to opt out of using `$geoWithin`.\n *\n * ```javascript\n * mongoose.Query.use$geoWithin = false;\n * ```\n *\n * MongoDB 2.4 deprecated the use of `$within`, replacing it with `$geoWithin`. Mongoose uses `$geoWithin` by default (which is 100% backward compatible with `$within`). If you are running an older version of MongoDB, set this flag to `false` so your `within()` queries continue to work.\n *\n * @see geoWithin https://www.mongodb.com/docs/manual/reference/operator/geoWithin/\n * @default true\n * @property use$geoWithin\n * @memberOf Query\n * @static\n * @api public\n */\n\nQuery.use$geoWithin = mquery.use$geoWithin;\n\n/**\n * Converts this query to a customized, reusable query constructor with all arguments and options retained.\n *\n * #### Example:\n *\n *     // Create a query for adventure movies and read from the primary\n *     // node in the replica-set unless it is down, in which case we'll\n *     // read from a secondary node.\n *     const query = Movie.find({ tags: 'adventure' }).read('primaryPreferred');\n *\n *     // create a custom Query constructor based off these settings\n *     const Adventure = query.toConstructor();\n *\n *     // further narrow down our query results while still using the previous settings\n *     await Adventure().where({ name: /^Life/ }).exec();\n *\n *     // since Adventure is a stand-alone constructor we can also add our own\n *     // helper methods and getters without impacting global queries\n *     Adventure.prototype.startsWith = function (prefix) {\n *       this.where({ name: new RegExp('^' + prefix) })\n *       return this;\n *     }\n *     Object.defineProperty(Adventure.prototype, 'highlyRated', {\n *       get: function () {\n *         this.where({ rating: { $gt: 4.5 }});\n *         return this;\n *       }\n *     })\n *     await Adventure().highlyRated.startsWith('Life').exec();\n *\n * @return {Query} subclass-of-Query\n * @api public\n */\n\nQuery.prototype.toConstructor = function toConstructor() {\n  const model = this.model;\n  const coll = this.mongooseCollection;\n\n  const CustomQuery = function(criteria, options) {\n    if (!(this instanceof CustomQuery)) {\n      return new CustomQuery(criteria, options);\n    }\n    this._mongooseOptions = clone(p._mongooseOptions);\n    Query.call(this, criteria, options || null, model, coll);\n  };\n\n  util.inherits(CustomQuery, model.Query);\n\n  // set inherited defaults\n  const p = CustomQuery.prototype;\n\n  p.options = {};\n\n  // Need to handle `sort()` separately because entries-style `sort()` syntax\n  // `sort([['prop1', 1]])` confuses mquery into losing the outer nested array.\n  // See gh-8159\n  const options = Object.assign({}, this.options);\n  if (options.sort != null) {\n    p.sort(options.sort);\n    delete options.sort;\n  }\n  p.setOptions(options);\n\n  p.op = this.op;\n  p._validateOp();\n  p._conditions = clone(this._conditions);\n  p._fields = clone(this._fields);\n  p._update = clone(this._update, {\n    flattenDecimals: false\n  });\n  p._path = this._path;\n  p._distinct = this._distinct;\n  p._collection = this._collection;\n  p._mongooseOptions = this._mongooseOptions;\n\n  return CustomQuery;\n};\n\n/**\n * Make a copy of this query so you can re-execute it.\n *\n * #### Example:\n *\n *     const q = Book.findOne({ title: 'Casino Royale' });\n *     await q.exec();\n *     await q.exec(); // Throws an error because you can't execute a query twice\n *\n *     await q.clone().exec(); // Works\n *\n * @method clone\n * @return {Query} copy\n * @memberOf Query\n * @instance\n * @api public\n */\n\nQuery.prototype.clone = function() {\n  const model = this.model;\n  const collection = this.mongooseCollection;\n\n  const q = new this.model.Query({}, {}, model, collection);\n\n  // Need to handle `sort()` separately because entries-style `sort()` syntax\n  // `sort([['prop1', 1]])` confuses mquery into losing the outer nested array.\n  // See gh-8159\n  const options = Object.assign({}, this.options);\n  if (options.sort != null) {\n    q.sort(options.sort);\n    delete options.sort;\n  }\n  q.setOptions(options);\n\n  q.op = this.op;\n  q._validateOp();\n  q._conditions = clone(this._conditions);\n  q._fields = clone(this._fields);\n  q._update = clone(this._update, {\n    flattenDecimals: false\n  });\n  q._path = this._path;\n  q._distinct = this._distinct;\n  q._collection = this._collection;\n  q._mongooseOptions = this._mongooseOptions;\n\n  return q;\n};\n\n/**\n * Specifies a javascript function or expression to pass to MongoDBs query system.\n *\n * #### Example:\n *\n *     query.$where('this.comments.length === 10 || this.name.length === 5')\n *\n *     // or\n *\n *     query.$where(function () {\n *       return this.comments.length === 10 || this.name.length === 5;\n *     })\n *\n * #### Note:\n *\n * Only use `$where` when you have a condition that cannot be met using other MongoDB operators like `$lt`.\n * **Be sure to read about all of [its caveats](https://www.mongodb.com/docs/manual/reference/operator/where/) before using.**\n *\n * @see $where https://www.mongodb.com/docs/manual/reference/operator/where/\n * @method $where\n * @param {String|Function} js javascript string or function\n * @return {Query} this\n * @memberOf Query\n * @instance\n * @method $where\n * @api public\n */\n\n/**\n * Specifies a `path` for use with chaining.\n *\n * #### Example:\n *\n *     // instead of writing:\n *     User.find({age: {$gte: 21, $lte: 65}});\n *\n *     // we can instead write:\n *     User.where('age').gte(21).lte(65);\n *\n *     // passing query conditions is permitted\n *     User.find().where({ name: 'vonderful' })\n *\n *     // chaining\n *     User\n *     .where('age').gte(21).lte(65)\n *     .where('name', /^vonderful/i)\n *     .where('friends').slice(10)\n *     .exec()\n *\n * @method where\n * @memberOf Query\n * @instance\n * @param {String|Object} [path]\n * @param {any} [val]\n * @return {Query} this\n * @api public\n */\n\n/**\n * Specifies a `$slice` projection for an array.\n *\n * #### Example:\n *\n *     query.slice('comments', 5); // Returns the first 5 comments\n *     query.slice('comments', -5); // Returns the last 5 comments\n *     query.slice('comments', [10, 5]); // Returns the first 5 comments after the 10-th\n *     query.where('comments').slice(5); // Returns the first 5 comments\n *     query.where('comments').slice([-10, 5]); // Returns the first 5 comments after the 10-th to last\n *\n * **Note:** If the absolute value of the number of elements to be sliced is greater than the number of elements in the array, all array elements will be returned.\n *\n *      // Given `arr`: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n *      query.slice('arr', 20); // Returns [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n *      query.slice('arr', -20); // Returns [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n *\n * **Note:** If the number of elements to skip is positive and greater than the number of elements in the array, an empty array will be returned.\n *\n *      // Given `arr`: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n *      query.slice('arr', [20, 5]); // Returns []\n *\n * **Note:** If the number of elements to skip is negative and its absolute value is greater than the number of elements in the array, the starting position is the start of the array.\n *\n *      // Given `arr`: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n *      query.slice('arr', [-20, 5]); // Returns [1, 2, 3, 4, 5]\n *\n * @method slice\n * @memberOf Query\n * @instance\n * @param {String} [path]\n * @param {Number|Array} val number of elements to slice or array with number of elements to skip and number of elements to slice\n * @return {Query} this\n * @see mongodb https://www.mongodb.com/docs/manual/tutorial/query-documents/#projection\n * @see $slice https://www.mongodb.com/docs/manual/reference/projection/slice/#prj._S_slice\n * @api public\n */\n\nQuery.prototype.slice = function() {\n  if (arguments.length === 0) {\n    return this;\n  }\n\n  this._validate('slice');\n\n  let path;\n  let val;\n\n  if (arguments.length === 1) {\n    const arg = arguments[0];\n    if (typeof arg === 'object' && !Array.isArray(arg)) {\n      const keys = Object.keys(arg);\n      const numKeys = keys.length;\n      for (let i = 0; i < numKeys; ++i) {\n        this.slice(keys[i], arg[keys[i]]);\n      }\n      return this;\n    }\n    this._ensurePath('slice');\n    path = this._path;\n    val = arguments[0];\n  } else if (arguments.length === 2) {\n    if ('number' === typeof arguments[0]) {\n      this._ensurePath('slice');\n      path = this._path;\n      val = [arguments[0], arguments[1]];\n    } else {\n      path = arguments[0];\n      val = arguments[1];\n    }\n  } else if (arguments.length === 3) {\n    path = arguments[0];\n    val = [arguments[1], arguments[2]];\n  }\n\n  const p = {};\n  p[path] = { $slice: val };\n  this.select(p);\n\n  return this;\n};\n\n/*!\n * ignore\n */\n\nconst validOpsSet = new Set(queryMiddlewareFunctions);\n\nQuery.prototype._validateOp = function() {\n  if (this.op != null && !validOpsSet.has(this.op)) {\n    this.error(new Error('Query has invalid `op`: \"' + this.op + '\"'));\n  }\n};\n\n/**\n * Specifies the complementary comparison value for paths specified with `where()`\n *\n * #### Example:\n *\n *     User.where('age').equals(49);\n *\n *     // is the same as\n *\n *     User.where('age', 49);\n *\n * @method equals\n * @memberOf Query\n * @instance\n * @param {Object} val\n * @return {Query} this\n * @api public\n */\n\n/**\n * Specifies arguments for an `$or` condition.\n *\n * #### Example:\n *\n *     query.or([{ color: 'red' }, { status: 'emergency' }]);\n *\n * @see $or https://www.mongodb.com/docs/manual/reference/operator/or/\n * @method or\n * @memberOf Query\n * @instance\n * @param {Array} array array of conditions\n * @return {Query} this\n * @api public\n */\n\n/**\n * Specifies arguments for a `$nor` condition.\n *\n * #### Example:\n *\n *     query.nor([{ color: 'green' }, { status: 'ok' }]);\n *\n * @see $nor https://www.mongodb.com/docs/manual/reference/operator/nor/\n * @method nor\n * @memberOf Query\n * @instance\n * @param {Array} array array of conditions\n * @return {Query} this\n * @api public\n */\n\n/**\n * Specifies arguments for a `$and` condition.\n *\n * #### Example:\n *\n *     query.and([{ color: 'green' }, { status: 'ok' }])\n *\n * @method and\n * @memberOf Query\n * @instance\n * @see $and https://www.mongodb.com/docs/manual/reference/operator/and/\n * @param {Array} array array of conditions\n * @return {Query} this\n * @api public\n */\n\n/**\n * Specifies a `$gt` query condition.\n *\n * When called with one argument, the most recent path passed to `where()` is used.\n *\n * #### Example:\n *\n *     Thing.find().where('age').gt(21);\n *\n *     // or\n *     Thing.find().gt('age', 21);\n *\n * @method gt\n * @memberOf Query\n * @instance\n * @param {String} [path]\n * @param {Number} val\n * @see $gt https://www.mongodb.com/docs/manual/reference/operator/gt/\n * @api public\n */\n\n/**\n * Specifies a `$gte` query condition.\n *\n * When called with one argument, the most recent path passed to `where()` is used.\n *\n * @method gte\n * @memberOf Query\n * @instance\n * @param {String} [path]\n * @param {Number} val\n * @see $gte https://www.mongodb.com/docs/manual/reference/operator/gte/\n * @api public\n */\n\n/**\n * Specifies a `$lt` query condition.\n *\n * When called with one argument, the most recent path passed to `where()` is used.\n *\n * @method lt\n * @memberOf Query\n * @instance\n * @param {String} [path]\n * @param {Number} val\n * @see $lt https://www.mongodb.com/docs/manual/reference/operator/lt/\n * @api public\n */\n\n/**\n * Specifies a `$lte` query condition.\n *\n * When called with one argument, the most recent path passed to `where()` is used.\n *\n * @method lte\n * @see $lte https://www.mongodb.com/docs/manual/reference/operator/lte/\n * @memberOf Query\n * @instance\n * @param {String} [path]\n * @param {Number} val\n * @api public\n */\n\n/**\n * Specifies a `$ne` query condition.\n *\n * When called with one argument, the most recent path passed to `where()` is used.\n *\n * @see $ne https://www.mongodb.com/docs/manual/reference/operator/ne/\n * @method ne\n * @memberOf Query\n * @instance\n * @param {String} [path]\n * @param {any} val\n * @api public\n */\n\n/**\n * Specifies an `$in` query condition.\n *\n * When called with one argument, the most recent path passed to `where()` is used.\n *\n * @see $in https://www.mongodb.com/docs/manual/reference/operator/in/\n * @method in\n * @memberOf Query\n * @instance\n * @param {String} [path]\n * @param {Array} val\n * @api public\n */\n\n/**\n * Specifies an `$nin` query condition.\n *\n * When called with one argument, the most recent path passed to `where()` is used.\n *\n * @see $nin https://www.mongodb.com/docs/manual/reference/operator/nin/\n * @method nin\n * @memberOf Query\n * @instance\n * @param {String} [path]\n * @param {Array} val\n * @api public\n */\n\n/**\n * Specifies an `$all` query condition.\n *\n * When called with one argument, the most recent path passed to `where()` is used.\n *\n * #### Example:\n *\n *     MyModel.find().where('pets').all(['dog', 'cat', 'ferret']);\n *     // Equivalent:\n *     MyModel.find().all('pets', ['dog', 'cat', 'ferret']);\n *\n * @see $all https://www.mongodb.com/docs/manual/reference/operator/all/\n * @method all\n * @memberOf Query\n * @instance\n * @param {String} [path]\n * @param {Array} val\n * @api public\n */\n\n/**\n * Specifies a `$size` query condition.\n *\n * When called with one argument, the most recent path passed to `where()` is used.\n *\n * #### Example:\n *\n *     const docs = await MyModel.where('tags').size(0).exec();\n *     assert(Array.isArray(docs));\n *     console.log('documents with 0 tags', docs);\n *\n * @see $size https://www.mongodb.com/docs/manual/reference/operator/size/\n * @method size\n * @memberOf Query\n * @instance\n * @param {String} [path]\n * @param {Number} val\n * @api public\n */\n\n/**\n * Specifies a `$regex` query condition.\n *\n * When called with one argument, the most recent path passed to `where()` is used.\n *\n * @see $regex https://www.mongodb.com/docs/manual/reference/operator/regex/\n * @method regex\n * @memberOf Query\n * @instance\n * @param {String} [path]\n * @param {String|RegExp} val\n * @api public\n */\n\n/**\n * Specifies a `maxDistance` query condition.\n *\n * When called with one argument, the most recent path passed to `where()` is used.\n *\n * @see $maxDistance https://www.mongodb.com/docs/manual/reference/operator/maxDistance/\n * @method maxDistance\n * @memberOf Query\n * @instance\n * @param {String} [path]\n * @param {Number} val\n * @api public\n */\n\n/**\n * Specifies a `$mod` condition, filters documents for documents whose\n * `path` property is a number that is equal to `remainder` modulo `divisor`.\n *\n * #### Example:\n *\n *     // All find products whose inventory is odd\n *     Product.find().mod('inventory', [2, 1]);\n *     Product.find().where('inventory').mod([2, 1]);\n *     // This syntax is a little strange, but supported.\n *     Product.find().where('inventory').mod(2, 1);\n *\n * @method mod\n * @memberOf Query\n * @instance\n * @param {String} [path]\n * @param {Array} val must be of length 2, first element is `divisor`, 2nd element is `remainder`.\n * @return {Query} this\n * @see $mod https://www.mongodb.com/docs/manual/reference/operator/mod/\n * @api public\n */\n\nQuery.prototype.mod = function() {\n  let val;\n  let path;\n\n  if (arguments.length === 1) {\n    this._ensurePath('mod');\n    val = arguments[0];\n    path = this._path;\n  } else if (arguments.length === 2 && !Array.isArray(arguments[1])) {\n    this._ensurePath('mod');\n    val = [arguments[0], arguments[1]];\n    path = this._path;\n  } else if (arguments.length === 3) {\n    val = [arguments[1], arguments[2]];\n    path = arguments[0];\n  } else {\n    val = arguments[1];\n    path = arguments[0];\n  }\n\n  const conds = this._conditions[path] || (this._conditions[path] = {});\n  conds.$mod = val;\n  return this;\n};\n\n/**\n * Specifies an `$exists` condition\n *\n * #### Example:\n *\n *     // { name: { $exists: true }}\n *     Thing.where('name').exists()\n *     Thing.where('name').exists(true)\n *     Thing.find().exists('name')\n *\n *     // { name: { $exists: false }}\n *     Thing.where('name').exists(false);\n *     Thing.find().exists('name', false);\n *\n * @method exists\n * @memberOf Query\n * @instance\n * @param {String} [path]\n * @param {Boolean} val\n * @return {Query} this\n * @see $exists https://www.mongodb.com/docs/manual/reference/operator/exists/\n * @api public\n */\n\n/**\n * Specifies an `$elemMatch` condition\n *\n * #### Example:\n *\n *     query.elemMatch('comment', { author: 'autobot', votes: {$gte: 5}})\n *\n *     query.where('comment').elemMatch({ author: 'autobot', votes: {$gte: 5}})\n *\n *     query.elemMatch('comment', function (elem) {\n *       elem.where('author').equals('autobot');\n *       elem.where('votes').gte(5);\n *     })\n *\n *     query.where('comment').elemMatch(function (elem) {\n *       elem.where({ author: 'autobot' });\n *       elem.where('votes').gte(5);\n *     })\n *\n * @method elemMatch\n * @memberOf Query\n * @instance\n * @param {String|Object|Function} path\n * @param {Object|Function} filter\n * @return {Query} this\n * @see $elemMatch https://www.mongodb.com/docs/manual/reference/operator/elemMatch/\n * @api public\n */\n\n/**\n * Defines a `$within` or `$geoWithin` argument for geo-spatial queries.\n *\n * #### Example:\n *\n *     query.where(path).within().box()\n *     query.where(path).within().circle()\n *     query.where(path).within().geometry()\n *\n *     query.where('loc').within({ center: [50,50], radius: 10, unique: true, spherical: true });\n *     query.where('loc').within({ box: [[40.73, -73.9], [40.7, -73.988]] });\n *     query.where('loc').within({ polygon: [[],[],[],[]] });\n *\n *     query.where('loc').within([], [], []) // polygon\n *     query.where('loc').within([], []) // box\n *     query.where('loc').within({ type: 'LineString', coordinates: [...] }); // geometry\n *\n * **MUST** be used after `where()`.\n *\n * #### Note:\n *\n * As of Mongoose 3.7, `$geoWithin` is always used for queries. To change this behavior, see [Query.use$geoWithin](https://mongoosejs.com/docs/api/query.html#Query.prototype.use$geoWithin).\n *\n * #### Note:\n *\n * In Mongoose 3.7, `within` changed from a getter to a function. If you need the old syntax, use [this](https://github.com/ebensing/mongoose-within).\n *\n * @method within\n * @see $polygon https://www.mongodb.com/docs/manual/reference/operator/polygon/\n * @see $box https://www.mongodb.com/docs/manual/reference/operator/box/\n * @see $geometry https://www.mongodb.com/docs/manual/reference/operator/geometry/\n * @see $center https://www.mongodb.com/docs/manual/reference/operator/center/\n * @see $centerSphere https://www.mongodb.com/docs/manual/reference/operator/centerSphere/\n * @memberOf Query\n * @instance\n * @return {Query} this\n * @api public\n */\n\n/**\n * Specifies the maximum number of documents the query will return.\n *\n * #### Example:\n *\n *     query.limit(20);\n *\n * #### Note:\n *\n * Cannot be used with `distinct()`\n *\n * @method limit\n * @memberOf Query\n * @instance\n * @param {Number} val\n * @api public\n */\n\nQuery.prototype.limit = function limit(v) {\n  this._validate('limit');\n\n  if (typeof v === 'string') {\n    try {\n      v = castNumber(v);\n    } catch (err) {\n      throw new CastError('Number', v, 'limit');\n    }\n  }\n\n  this.options.limit = v;\n  return this;\n};\n\n/**\n * Specifies the number of documents to skip.\n *\n * #### Example:\n *\n *     query.skip(100).limit(20);\n *\n * #### Note:\n *\n * Cannot be used with `distinct()`\n *\n * @method skip\n * @memberOf Query\n * @instance\n * @param {Number} val\n * @see cursor.skip https://www.mongodb.com/docs/manual/reference/method/cursor.skip/\n * @api public\n */\n\nQuery.prototype.skip = function skip(v) {\n  this._validate('skip');\n\n  if (typeof v === 'string') {\n    try {\n      v = castNumber(v);\n    } catch (err) {\n      throw new CastError('Number', v, 'skip');\n    }\n  }\n\n  this.options.skip = v;\n  return this;\n};\n\n/**\n * Specifies the batchSize option.\n *\n * #### Example:\n *\n *     query.batchSize(100)\n *\n * #### Note:\n *\n * Cannot be used with `distinct()`\n *\n * @method batchSize\n * @memberOf Query\n * @instance\n * @param {Number} val\n * @see batchSize https://www.mongodb.com/docs/manual/reference/method/cursor.batchSize/\n * @api public\n */\n\n/**\n * Specifies the `comment` option.\n *\n * #### Example:\n *\n *     query.comment('login query')\n *\n * #### Note:\n *\n * Cannot be used with `distinct()`\n *\n * @method comment\n * @memberOf Query\n * @instance\n * @param {String} val\n * @see comment https://www.mongodb.com/docs/manual/reference/operator/comment/\n * @api public\n */\n\n/**\n * Sets query hints.\n *\n * #### Example:\n *\n *     query.hint({ indexA: 1, indexB: -1 });\n *\n * #### Note:\n *\n * Cannot be used with `distinct()`\n *\n * @method hint\n * @memberOf Query\n * @instance\n * @param {Object} val a hint object\n * @return {Query} this\n * @see $hint https://www.mongodb.com/docs/manual/reference/operator/hint/\n * @api public\n */\n\n/**\n * Get/set the current projection (AKA fields). Pass `null` to remove the\n * current projection.\n *\n * Unlike `projection()`, the `select()` function modifies the current\n * projection in place. This function overwrites the existing projection.\n *\n * #### Example:\n *\n *     const q = Model.find();\n *     q.projection(); // null\n *\n *     q.select('a b');\n *     q.projection(); // { a: 1, b: 1 }\n *\n *     q.projection({ c: 1 });\n *     q.projection(); // { c: 1 }\n *\n *     q.projection(null);\n *     q.projection(); // null\n *\n *\n * @method projection\n * @memberOf Query\n * @instance\n * @param {Object|null} arg\n * @return {Object} the current projection\n * @api public\n */\n\nQuery.prototype.projection = function(arg) {\n  if (arguments.length === 0) {\n    return this._fields;\n  }\n\n  this._fields = {};\n  this._userProvidedFields = {};\n  this.select(arg);\n  return this._fields;\n};\n\n/**\n * Specifies which document fields to include or exclude (also known as the query \"projection\")\n *\n * When using string syntax, prefixing a path with `-` will flag that path as excluded. When a path does not have the `-` prefix, it is included. Lastly, if a path is prefixed with `+`, it forces inclusion of the path, which is useful for paths excluded at the [schema level](https://mongoosejs.com/docs/api/schematype.html#SchemaType.prototype.select()).\n *\n * A projection _must_ be either inclusive or exclusive. In other words, you must\n * either list the fields to include (which excludes all others), or list the fields\n * to exclude (which implies all other fields are included). The [`_id` field is the only exception because MongoDB includes it by default](https://www.mongodb.com/docs/manual/tutorial/project-fields-from-query-results/#suppress-id-field).\n *\n * #### Example:\n *\n *     // include a and b, exclude other fields\n *     query.select('a b');\n *     // Equivalent syntaxes:\n *     query.select(['a', 'b']);\n *     query.select({ a: 1, b: 1 });\n *\n *     // exclude c and d, include other fields\n *     query.select('-c -d');\n *\n *     // Use `+` to override schema-level `select: false` without making the\n *     // projection inclusive.\n *     const schema = new Schema({\n *       foo: { type: String, select: false },\n *       bar: String\n *     });\n *     // ...\n *     query.select('+foo'); // Override foo's `select: false` without excluding `bar`\n *\n *     // or you may use object notation, useful when\n *     // you have keys already prefixed with a \"-\"\n *     query.select({ a: 1, b: 1 });\n *     query.select({ c: 0, d: 0 });\n *\n *     Additional calls to select can override the previous selection:\n *     query.select({ a: 1, b: 1 }).select({ b: 0 }); // selection is now { a: 1 }\n *     query.select({ a: 0, b: 0 }).select({ b: 1 }); // selection is now { a: 0 }\n *\n *\n * @method select\n * @memberOf Query\n * @instance\n * @param {Object|String|String[]} arg\n * @return {Query} this\n * @see SchemaType https://mongoosejs.com/docs/api/schematype.html\n * @api public\n */\n\nQuery.prototype.select = function select() {\n  let arg = arguments[0];\n  if (!arg) return this;\n\n  if (arguments.length !== 1) {\n    throw new Error('Invalid select: select only takes 1 argument');\n  }\n\n  this._validate('select');\n\n  const fields = this._fields || (this._fields = {});\n  const userProvidedFields = this._userProvidedFields || (this._userProvidedFields = {});\n  let sanitizeProjection = undefined;\n  if (this.model != null && utils.hasUserDefinedProperty(this.model.db.options, 'sanitizeProjection')) {\n    sanitizeProjection = this.model.db.options.sanitizeProjection;\n  } else if (this.model != null && utils.hasUserDefinedProperty(this.model.base.options, 'sanitizeProjection')) {\n    sanitizeProjection = this.model.base.options.sanitizeProjection;\n  } else {\n    sanitizeProjection = this._mongooseOptions.sanitizeProjection;\n  }\n\n  function sanitizeValue(value) {\n    return typeof value === 'string' && sanitizeProjection ? value = 1 : value;\n  }\n  arg = parseProjection(arg, true); // we want to keep the minus and pluses, so add boolean arg.\n  if (utils.isObject(arg)) {\n    if (this.selectedInclusively()) {\n      Object.entries(arg).forEach(([key, value]) => {\n        if (value) {\n          // Add the field to the projection\n          if (fields['-' + key] != null) {\n            delete fields['-' + key];\n          }\n          fields[key] = userProvidedFields[key] = sanitizeValue(value);\n        } else {\n          // Remove the field from the projection\n          Object.keys(userProvidedFields).forEach(field => {\n            if (isSubpath(key, field)) {\n              delete fields[field];\n              delete userProvidedFields[field];\n            }\n          });\n        }\n      });\n    } else if (this.selectedExclusively()) {\n      Object.entries(arg).forEach(([key, value]) => {\n        if (!value) {\n          // Add the field to the projection\n          if (fields['+' + key] != null) {\n            delete fields['+' + key];\n          }\n          fields[key] = userProvidedFields[key] = sanitizeValue(value);\n        } else {\n          // Remove the field from the projection\n          Object.keys(userProvidedFields).forEach(field => {\n            if (isSubpath(key, field)) {\n              delete fields[field];\n              delete userProvidedFields[field];\n            }\n          });\n        }\n      });\n    } else {\n      const keys = Object.keys(arg);\n      for (let i = 0; i < keys.length; ++i) {\n        const value = arg[keys[i]];\n        const key = keys[i];\n        fields[key] = sanitizeValue(value);\n        userProvidedFields[key] = sanitizeValue(value);\n      }\n    }\n\n    return this;\n  }\n\n  throw new TypeError('Invalid select() argument. Must be string or object.');\n};\n\n/**\n * Sets this query's `sanitizeProjection` option. If set, `sanitizeProjection` does\n * two things:\n *\n * 1. Enforces that projection values are numbers, not strings.\n * 2. Prevents using `+` syntax to override properties that are deselected by default.\n *\n * With `sanitizeProjection()`, you can pass potentially untrusted user data to `.select()`.\n *\n * #### Example\n *\n *     const userSchema = new Schema({\n *       name: String,\n *       password: { type: String, select: false }\n *     });\n *     const UserModel = mongoose.model('User', userSchema);\n *     const { _id } = await UserModel.create({ name: 'John', password: 'secret' })\n *\n *     // The MongoDB server has special handling for string values that start with '$'\n *     // in projections, which can lead to unexpected leaking of sensitive data.\n *     let doc = await UserModel.findOne().select({ name: '$password' });\n *     doc.name; // 'secret'\n *     doc.password; // undefined\n *\n *     // With `sanitizeProjection`, Mongoose forces all projection values to be numbers\n *     doc = await UserModel.findOne().sanitizeProjection(true).select({ name: '$password' });\n *     doc.name; // 'John'\n *     doc.password; // undefined\n *\n *     // By default, Mongoose supports projecting in `password` using `+password`\n *     doc = await UserModel.findOne().select('+password');\n *     doc.password; // 'secret'\n *\n *     // With `sanitizeProjection`, Mongoose prevents projecting in `password` and other\n *     // fields that have `select: false` in the schema.\n *     doc = await UserModel.findOne().sanitizeProjection(true).select('+password');\n *     doc.password; // undefined\n *\n * @method sanitizeProjection\n * @memberOf Query\n * @instance\n * @param {Boolean} value\n * @return {Query} this\n * @see sanitizeProjection https://thecodebarbarian.com/whats-new-in-mongoose-5-13-sanitizeprojection.html\n * @api public\n */\n\nQuery.prototype.sanitizeProjection = function sanitizeProjection(value) {\n  this._mongooseOptions.sanitizeProjection = value;\n\n  return this;\n};\n\n/**\n * Determines the MongoDB nodes from which to read.\n *\n * #### Preferences:\n *\n * ```\n * primary - (default) Read from primary only. Operations will produce an error if primary is unavailable. Cannot be combined with tags.\n * secondary            Read from secondary if available, otherwise error.\n * primaryPreferred     Read from primary if available, otherwise a secondary.\n * secondaryPreferred   Read from a secondary if available, otherwise read from the primary.\n * nearest              All operations read from among the nearest candidates, but unlike other modes, this option will include both the primary and all secondaries in the random selection.\n * ```\n *\n * Aliases\n *\n * ```\n * p   primary\n * pp  primaryPreferred\n * s   secondary\n * sp  secondaryPreferred\n * n   nearest\n * ```\n *\n * #### Example:\n *\n *     new Query().read('primary')\n *     new Query().read('p')  // same as primary\n *\n *     new Query().read('primaryPreferred')\n *     new Query().read('pp') // same as primaryPreferred\n *\n *     new Query().read('secondary')\n *     new Query().read('s')  // same as secondary\n *\n *     new Query().read('secondaryPreferred')\n *     new Query().read('sp') // same as secondaryPreferred\n *\n *     new Query().read('nearest')\n *     new Query().read('n')  // same as nearest\n *\n *     // read from secondaries with matching tags\n *     new Query().read('s', [{ dc:'sf', s: 1 },{ dc:'ma', s: 2 }])\n *\n * Read more about how to use read preferences [here](https://www.mongodb.com/docs/manual/applications/replication/#read-preference).\n *\n * @method read\n * @memberOf Query\n * @instance\n * @param {String} mode one of the listed preference options or aliases\n * @param {Array} [tags] optional tags for this query\n * @see mongodb https://www.mongodb.com/docs/manual/applications/replication/#read-preference\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.read = function read(mode, tags) {\n  if (typeof mode === 'string') {\n    mode = handleReadPreferenceAliases(mode);\n    this.options.readPreference = { mode, tags };\n  } else {\n    this.options.readPreference = mode;\n  }\n  return this;\n};\n\n/**\n * Overwrite default `.toString` to make logging more useful\n *\n * @memberOf Query\n * @instance\n * @method toString\n * @api private\n */\n\nQuery.prototype.toString = function toString() {\n  if (this.op === 'count' ||\n      this.op === 'countDocuments' ||\n      this.op === 'find' ||\n      this.op === 'findOne' ||\n      this.op === 'deleteMany' ||\n      this.op === 'deleteOne' ||\n      this.op === 'findOneAndDelete' ||\n      this.op === 'remove') {\n    return `${this.model.modelName}.${this.op}(${util.inspect(this._conditions)})`;\n  }\n  if (this.op === 'distinct') {\n    return `${this.model.modelName}.distinct('${this._distinct}', ${util.inspect(this._conditions)})`;\n  }\n  if (this.op === 'findOneAndReplace' ||\n      this.op === 'findOneAndUpdate' ||\n      this.op === 'replaceOne' ||\n      this.op === 'update' ||\n      this.op === 'updateMany' ||\n      this.op === 'updateOne') {\n    return `${this.model.modelName}.${this.op}(${util.inspect(this._conditions)}, ${util.inspect(this._update)})`;\n  }\n\n  // 'estimatedDocumentCount' or any others\n  return `${this.model.modelName}.${this.op}()`;\n};\n\n/**\n * Sets the [MongoDB session](https://www.mongodb.com/docs/manual/reference/server-sessions/)\n * associated with this query. Sessions are how you mark a query as part of a\n * [transaction](https://mongoosejs.com/docs/transactions.html).\n *\n * Calling `session(null)` removes the session from this query.\n *\n * #### Example:\n *\n *     const s = await mongoose.startSession();\n *     await mongoose.model('Person').findOne({ name: 'Axl Rose' }).session(s);\n *\n * @method session\n * @memberOf Query\n * @instance\n * @param {ClientSession} [session] from `await conn.startSession()`\n * @see Connection.prototype.startSession() https://mongoosejs.com/docs/api/connection.html#Connection.prototype.startSession()\n * @see mongoose.startSession() https://mongoosejs.com/docs/api/mongoose.html#Mongoose.prototype.startSession()\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.session = function session(v) {\n  if (v == null) {\n    delete this.options.session;\n  }\n  this.options.session = v;\n  return this;\n};\n\n/**\n * Sets the 3 write concern parameters for this query:\n *\n * - `w`: Sets the specified number of `mongod` servers, or tag set of `mongod` servers, that must acknowledge this write before this write is considered successful.\n * - `j`: Boolean, set to `true` to request acknowledgement that this operation has been persisted to MongoDB's on-disk journal.\n * - `wtimeout`: If [`w > 1`](https://mongoosejs.com/docs/api/query.html#Query.prototype.w()), the maximum amount of time to wait for this write to propagate through the replica set before this operation fails. The default is `0`, which means no timeout.\n *\n * This option is only valid for operations that write to the database:\n *\n * - `deleteOne()`\n * - `deleteMany()`\n * - `findOneAndDelete()`\n * - `findOneAndReplace()`\n * - `findOneAndUpdate()`\n * - `updateOne()`\n * - `updateMany()`\n *\n * Defaults to the schema's [`writeConcern` option](https://mongoosejs.com/docs/guide.html#writeConcern)\n *\n * #### Example:\n *\n *     // The 'majority' option means the `deleteOne()` promise won't resolve\n *     // until the `deleteOne()` has propagated to the majority of the replica set\n *     await mongoose.model('Person').\n *       deleteOne({ name: 'Ned Stark' }).\n *       writeConcern({ w: 'majority' });\n *\n * @method writeConcern\n * @memberOf Query\n * @instance\n * @param {Object} writeConcern the write concern value to set\n * @see WriteConcernSettings https://mongodb.github.io/node-mongodb-native/4.9/interfaces/WriteConcernSettings.html\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.writeConcern = function writeConcern(val) {\n  if (val == null) {\n    delete this.options.writeConcern;\n    return this;\n  }\n  this.options.writeConcern = val;\n  return this;\n};\n\n/**\n * Sets the specified number of `mongod` servers, or tag set of `mongod` servers,\n * that must acknowledge this write before this write is considered successful.\n * This option is only valid for operations that write to the database:\n *\n * - `deleteOne()`\n * - `deleteMany()`\n * - `findOneAndDelete()`\n * - `findOneAndReplace()`\n * - `findOneAndUpdate()`\n * - `updateOne()`\n * - `updateMany()`\n *\n * Defaults to the schema's [`writeConcern.w` option](https://mongoosejs.com/docs/guide.html#writeConcern)\n *\n * #### Example:\n *\n *     // The 'majority' option means the `deleteOne()` promise won't resolve\n *     // until the `deleteOne()` has propagated to the majority of the replica set\n *     await mongoose.model('Person').\n *       deleteOne({ name: 'Ned Stark' }).\n *       w('majority');\n *\n * @method w\n * @memberOf Query\n * @instance\n * @param {String|number} val 0 for fire-and-forget, 1 for acknowledged by one server, 'majority' for majority of the replica set, or [any of the more advanced options](https://www.mongodb.com/docs/manual/reference/write-concern/#w-option).\n * @see mongodb https://www.mongodb.com/docs/manual/reference/write-concern/#w-option\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.w = function w(val) {\n  if (val == null) {\n    delete this.options.w;\n  }\n  if (this.options.writeConcern != null) {\n    this.options.writeConcern.w = val;\n  } else {\n    this.options.w = val;\n  }\n  return this;\n};\n\n/**\n * Requests acknowledgement that this operation has been persisted to MongoDB's\n * on-disk journal.\n * This option is only valid for operations that write to the database:\n *\n * - `deleteOne()`\n * - `deleteMany()`\n * - `findOneAndDelete()`\n * - `findOneAndReplace()`\n * - `findOneAndUpdate()`\n * - `updateOne()`\n * - `updateMany()`\n *\n * Defaults to the schema's [`writeConcern.j` option](https://mongoosejs.com/docs/guide.html#writeConcern)\n *\n * #### Example:\n *\n *     await mongoose.model('Person').deleteOne({ name: 'Ned Stark' }).j(true);\n *\n * @method j\n * @memberOf Query\n * @instance\n * @param {boolean} val\n * @see mongodb https://www.mongodb.com/docs/manual/reference/write-concern/#j-option\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.j = function j(val) {\n  if (val == null) {\n    delete this.options.j;\n  }\n  if (this.options.writeConcern != null) {\n    this.options.writeConcern.j = val;\n  } else {\n    this.options.j = val;\n  }\n  return this;\n};\n\n/**\n * If [`w > 1`](https://mongoosejs.com/docs/api/query.html#Query.prototype.w()), the maximum amount of time to\n * wait for this write to propagate through the replica set before this\n * operation fails. The default is `0`, which means no timeout.\n *\n * This option is only valid for operations that write to the database:\n *\n * - `deleteOne()`\n * - `deleteMany()`\n * - `findOneAndDelete()`\n * - `findOneAndReplace()`\n * - `findOneAndUpdate()`\n * - `updateOne()`\n * - `updateMany()`\n *\n * Defaults to the schema's [`writeConcern.wtimeout` option](https://mongoosejs.com/docs/guide.html#writeConcern)\n *\n * #### Example:\n *\n *     // The `deleteOne()` promise won't resolve until this `deleteOne()` has\n *     // propagated to at least `w = 2` members of the replica set. If it takes\n *     // longer than 1 second, this `deleteOne()` will fail.\n *     await mongoose.model('Person').\n *       deleteOne({ name: 'Ned Stark' }).\n *       w(2).\n *       wtimeout(1000);\n *\n * @method wtimeout\n * @memberOf Query\n * @instance\n * @param {number} ms number of milliseconds to wait\n * @see mongodb https://www.mongodb.com/docs/manual/reference/write-concern/#wtimeout\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.wtimeout = function wtimeout(ms) {\n  if (ms == null) {\n    delete this.options.wtimeout;\n  }\n  if (this.options.writeConcern != null) {\n    this.options.writeConcern.wtimeout = ms;\n  } else {\n    this.options.wtimeout = ms;\n  }\n  return this;\n};\n\n/**\n * Sets the readConcern option for the query.\n *\n * #### Example:\n *\n *     new Query().readConcern('local')\n *     new Query().readConcern('l')  // same as local\n *\n *     new Query().readConcern('available')\n *     new Query().readConcern('a')  // same as available\n *\n *     new Query().readConcern('majority')\n *     new Query().readConcern('m')  // same as majority\n *\n *     new Query().readConcern('linearizable')\n *     new Query().readConcern('lz') // same as linearizable\n *\n *     new Query().readConcern('snapshot')\n *     new Query().readConcern('s')  // same as snapshot\n *\n *\n * #### Read Concern Level:\n *\n * ```\n * local         MongoDB 3.2+ The query returns from the instance with no guarantee guarantee that the data has been written to a majority of the replica set members (i.e. may be rolled back).\n * available     MongoDB 3.6+ The query returns from the instance with no guarantee guarantee that the data has been written to a majority of the replica set members (i.e. may be rolled back).\n * majority      MongoDB 3.2+ The query returns the data that has been acknowledged by a majority of the replica set members. The documents returned by the read operation are durable, even in the event of failure.\n * linearizable  MongoDB 3.4+ The query returns data that reflects all successful majority-acknowledged writes that completed prior to the start of the read operation. The query may wait for concurrently executing writes to propagate to a majority of replica set members before returning results.\n * snapshot      MongoDB 4.0+ Only available for operations within multi-document transactions. Upon transaction commit with write concern \"majority\", the transaction operations are guaranteed to have read from a snapshot of majority-committed data.\n * ```\n *\n * Aliases\n *\n * ```\n * l   local\n * a   available\n * m   majority\n * lz  linearizable\n * s   snapshot\n * ```\n *\n * Read more about how to use read concern [here](https://www.mongodb.com/docs/manual/reference/read-concern/).\n *\n * @memberOf Query\n * @method readConcern\n * @param {String} level one of the listed read concern level or their aliases\n * @see mongodb https://www.mongodb.com/docs/manual/reference/read-concern/\n * @return {Query} this\n * @api public\n */\n\n/**\n * Gets query options.\n *\n * #### Example:\n *\n *     const query = new Query();\n *     query.limit(10);\n *     query.setOptions({ maxTimeMS: 1000 });\n *     query.getOptions(); // { limit: 10, maxTimeMS: 1000 }\n *\n * @return {Object} the options\n * @api public\n */\n\nQuery.prototype.getOptions = function() {\n  return this.options;\n};\n\n/**\n * Sets query options. Some options only make sense for certain operations.\n *\n * #### Options:\n *\n * The following options are only for `find()`:\n *\n * - [tailable](https://www.mongodb.com/docs/manual/core/tailable-cursors/)\n * - [limit](https://www.mongodb.com/docs/manual/reference/method/cursor.limit/)\n * - [skip](https://www.mongodb.com/docs/manual/reference/method/cursor.skip/)\n * - [allowDiskUse](https://www.mongodb.com/docs/manual/reference/method/cursor.allowDiskUse/)\n * - [batchSize](https://www.mongodb.com/docs/manual/reference/method/cursor.batchSize/)\n * - [readPreference](https://www.mongodb.com/docs/manual/applications/replication/#read-preference)\n * - [hint](https://www.mongodb.com/docs/manual/reference/method/cursor.hint/)\n * - [comment](https://www.mongodb.com/docs/manual/reference/method/cursor.comment/)\n *\n * The following options are only for write operations: `updateOne()`, `updateMany()`, `replaceOne()`, `findOneAndUpdate()`, and `findByIdAndUpdate()`:\n *\n * - [upsert](https://www.mongodb.com/docs/manual/reference/method/db.collection.update/)\n * - [writeConcern](https://www.mongodb.com/docs/manual/reference/method/db.collection.update/)\n * - [timestamps](https://mongoosejs.com/docs/guide.html#timestamps): If `timestamps` is set in the schema, set this option to `false` to skip timestamps for that particular update. Has no effect if `timestamps` is not enabled in the schema options.\n * - overwriteDiscriminatorKey: allow setting the discriminator key in the update. Will use the correct discriminator schema if the update changes the discriminator key.\n *\n * The following options are only for `find()`, `findOne()`, `findById()`, `findOneAndUpdate()`, `findOneAndReplace()`, `findOneAndDelete()`, and `findByIdAndUpdate()`:\n *\n * - [lean](https://mongoosejs.com/docs/api/query.html#Query.prototype.lean())\n * - [populate](https://mongoosejs.com/docs/populate.html)\n * - [projection](https://mongoosejs.com/docs/api/query.html#Query.prototype.projection())\n * - sanitizeProjection\n * - useBigInt64\n *\n * The following options are only for all operations **except** `updateOne()`, `updateMany()`, `deleteOne()`, and `deleteMany()`:\n *\n * - [maxTimeMS](https://www.mongodb.com/docs/manual/reference/operator/meta/maxTimeMS/)\n *\n * The following options are for `find()`, `findOne()`, `findOneAndUpdate()`, `findOneAndDelete()`, `updateOne()`, and `deleteOne()`:\n *\n * - [sort](https://www.mongodb.com/docs/manual/reference/method/cursor.sort/)\n *\n * The following options are for `findOneAndUpdate()` and `findOneAndDelete()`\n *\n * - includeResultMetadata\n *\n * The following options are for all operations:\n *\n * - [strict](https://mongoosejs.com/docs/guide.html#strict)\n * - [collation](https://www.mongodb.com/docs/manual/reference/collation/)\n * - [session](https://www.mongodb.com/docs/manual/reference/server-sessions/)\n * - [explain](https://www.mongodb.com/docs/manual/reference/method/cursor.explain/)\n *\n * @param {Object} options\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.setOptions = function(options, overwrite) {\n  // overwrite is only for internal use\n  if (overwrite) {\n    // ensure that _mongooseOptions & options are two different objects\n    this._mongooseOptions = (options && clone(options)) || {};\n    this.options = options || {};\n\n    if ('populate' in options) {\n      this.populate(this._mongooseOptions);\n    }\n    return this;\n  }\n  if (options == null) {\n    return this;\n  }\n  if (typeof options !== 'object') {\n    throw new Error('Options must be an object, got \"' + options + '\"');\n  }\n\n  options = Object.assign({}, options);\n\n  if (Array.isArray(options.populate)) {\n    const populate = options.populate;\n    delete options.populate;\n    const _numPopulate = populate.length;\n    for (let i = 0; i < _numPopulate; ++i) {\n      this.populate(populate[i]);\n    }\n  }\n\n  if ('setDefaultsOnInsert' in options) {\n    this._mongooseOptions.setDefaultsOnInsert = options.setDefaultsOnInsert;\n    delete options.setDefaultsOnInsert;\n  }\n  if ('overwriteDiscriminatorKey' in options) {\n    this._mongooseOptions.overwriteDiscriminatorKey = options.overwriteDiscriminatorKey;\n    delete options.overwriteDiscriminatorKey;\n  }\n  if ('sanitizeProjection' in options) {\n    if (options.sanitizeProjection && !this._mongooseOptions.sanitizeProjection) {\n      sanitizeProjection(this._fields);\n    }\n\n    this._mongooseOptions.sanitizeProjection = options.sanitizeProjection;\n    delete options.sanitizeProjection;\n  }\n  if ('sanitizeFilter' in options) {\n    this._mongooseOptions.sanitizeFilter = options.sanitizeFilter;\n    delete options.sanitizeFilter;\n  }\n  if ('timestamps' in options) {\n    this._mongooseOptions.timestamps = options.timestamps;\n    delete options.timestamps;\n  }\n  if ('defaults' in options) {\n    this._mongooseOptions.defaults = options.defaults;\n    // deleting options.defaults will cause 7287 to fail\n  }\n  if ('translateAliases' in options) {\n    this._mongooseOptions.translateAliases = options.translateAliases;\n    delete options.translateAliases;\n  }\n\n  if (options.lean == null && this.schema && 'lean' in this.schema.options) {\n    this._mongooseOptions.lean = this.schema.options.lean;\n  }\n\n  if (typeof options.limit === 'string') {\n    try {\n      options.limit = castNumber(options.limit);\n    } catch (err) {\n      throw new CastError('Number', options.limit, 'limit');\n    }\n  }\n  if (typeof options.skip === 'string') {\n    try {\n      options.skip = castNumber(options.skip);\n    } catch (err) {\n      throw new CastError('Number', options.skip, 'skip');\n    }\n  }\n\n  // set arbitrary options\n  for (const key of Object.keys(options)) {\n    if (queryOptionMethods.has(key)) {\n      const args = Array.isArray(options[key]) ?\n        options[key] :\n        [options[key]];\n      this[key].apply(this, args);\n    } else {\n      this.options[key] = options[key];\n    }\n  }\n\n  return this;\n};\n\n/**\n * Sets the [`explain` option](https://www.mongodb.com/docs/manual/reference/method/cursor.explain/),\n * which makes this query return detailed execution stats instead of the actual\n * query result. This method is useful for determining what index your queries\n * use.\n *\n * Calling `query.explain(v)` is equivalent to `query.setOptions({ explain: v })`\n *\n * #### Example:\n *\n *     const query = new Query();\n *     const res = await query.find({ a: 1 }).explain('queryPlanner');\n *     console.log(res);\n *\n * @param {String} [verbose] The verbosity mode. Either 'queryPlanner', 'executionStats', or 'allPlansExecution'. The default is 'queryPlanner'\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.explain = function explain(verbose) {\n  if (arguments.length === 0) {\n    this.options.explain = true;\n  } else if (verbose === false) {\n    delete this.options.explain;\n  } else {\n    this.options.explain = verbose;\n  }\n  return this;\n};\n\n/**\n * Sets the [`allowDiskUse` option](https://www.mongodb.com/docs/manual/reference/method/cursor.allowDiskUse/),\n * which allows the MongoDB server to use more than 100 MB for this query's `sort()`. This option can\n * let you work around `QueryExceededMemoryLimitNoDiskUseAllowed` errors from the MongoDB server.\n *\n * Note that this option requires MongoDB server >= 4.4. Setting this option is a no-op for MongoDB 4.2\n * and earlier.\n *\n * Calling `query.allowDiskUse(v)` is equivalent to `query.setOptions({ allowDiskUse: v })`\n *\n * #### Example:\n *\n *     await query.find().sort({ name: 1 }).allowDiskUse(true);\n *     // Equivalent:\n *     await query.find().sort({ name: 1 }).allowDiskUse();\n *\n * @param {Boolean} [v] Enable/disable `allowDiskUse`. If called with 0 arguments, sets `allowDiskUse: true`\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.allowDiskUse = function(v) {\n  if (arguments.length === 0) {\n    this.options.allowDiskUse = true;\n  } else if (v === false) {\n    delete this.options.allowDiskUse;\n  } else {\n    this.options.allowDiskUse = v;\n  }\n  return this;\n};\n\n/**\n * Sets the [maxTimeMS](https://www.mongodb.com/docs/manual/reference/method/cursor.maxTimeMS/)\n * option. This will tell the MongoDB server to abort if the query or write op\n * has been running for more than `ms` milliseconds.\n *\n * Calling `query.maxTimeMS(v)` is equivalent to `query.setOptions({ maxTimeMS: v })`\n *\n * #### Example:\n *\n *     const query = new Query();\n *     // Throws an error 'operation exceeded time limit' as long as there's\n *     // >= 1 doc in the queried collection\n *     const res = await query.find({ $where: 'sleep(1000) || true' }).maxTimeMS(100);\n *\n * @param {Number} [ms] The number of milliseconds\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.maxTimeMS = function(ms) {\n  this.options.maxTimeMS = ms;\n  return this;\n};\n\n/**\n * Returns the current query filter (also known as conditions) as a [POJO](https://masteringjs.io/tutorials/fundamentals/pojo).\n *\n * #### Example:\n *\n *     const query = new Query();\n *     query.find({ a: 1 }).where('b').gt(2);\n *     query.getFilter(); // { a: 1, b: { $gt: 2 } }\n *\n * @return {Object} current query filter\n * @api public\n */\n\nQuery.prototype.getFilter = function() {\n  return this._conditions;\n};\n\n/**\n * Returns the current query filter. Equivalent to `getFilter()`.\n *\n * You should use `getFilter()` instead of `getQuery()` where possible. `getQuery()`\n * will likely be deprecated in a future release.\n *\n * #### Example:\n *\n *     const query = new Query();\n *     query.find({ a: 1 }).where('b').gt(2);\n *     query.getQuery(); // { a: 1, b: { $gt: 2 } }\n *\n * @return {Object} current query filter\n * @api public\n */\n\nQuery.prototype.getQuery = function() {\n  return this._conditions;\n};\n\n/**\n * Sets the query conditions to the provided JSON object.\n *\n * #### Example:\n *\n *     const query = new Query();\n *     query.find({ a: 1 })\n *     query.setQuery({ a: 2 });\n *     query.getQuery(); // { a: 2 }\n *\n * @param {Object} new query conditions\n * @return {undefined}\n * @api public\n */\n\nQuery.prototype.setQuery = function(val) {\n  this._conditions = val;\n};\n\n/**\n * Returns the current update operations as a JSON object.\n *\n * #### Example:\n *\n *     const query = new Query();\n *     query.updateOne({}, { $set: { a: 5 } });\n *     query.getUpdate(); // { $set: { a: 5 } }\n *\n * @return {Object} current update operations\n * @api public\n */\n\nQuery.prototype.getUpdate = function() {\n  return this._update;\n};\n\n/**\n * Sets the current update operation to new value.\n *\n * #### Example:\n *\n *     const query = new Query();\n *     query.updateOne({}, { $set: { a: 5 } });\n *     query.setUpdate({ $set: { b: 6 } });\n *     query.getUpdate(); // { $set: { b: 6 } }\n *\n * @param {Object} new update operation\n * @return {undefined}\n * @api public\n */\n\nQuery.prototype.setUpdate = function(val) {\n  this._update = val;\n};\n\n/**\n * Returns fields selection for this query.\n *\n * @method _fieldsForExec\n * @return {Object}\n * @api private\n * @memberOf Query\n */\n\nQuery.prototype._fieldsForExec = function() {\n  if (this._fields == null) {\n    return null;\n  }\n  if (Object.keys(this._fields).length === 0) {\n    return null;\n  }\n  return clone(this._fields);\n};\n\n\n/**\n * Return an update document with corrected `$set` operations.\n *\n * @method _updateForExec\n * @return {Object}\n * @api private\n * @memberOf Query\n */\n\nQuery.prototype._updateForExec = function() {\n  const update = clone(this._update, {\n    transform: false,\n    depopulate: true\n  });\n  const ops = Object.keys(update);\n  let i = ops.length;\n  const ret = {};\n\n  while (i--) {\n    const op = ops[i];\n\n    if ('$' !== op[0]) {\n      // fix up $set sugar\n      if (!ret.$set) {\n        if (update.$set) {\n          ret.$set = update.$set;\n        } else {\n          ret.$set = {};\n        }\n      }\n      ret.$set[op] = update[op];\n      ops.splice(i, 1);\n      if (!~ops.indexOf('$set')) ops.push('$set');\n    } else if ('$set' === op) {\n      if (!ret.$set) {\n        ret[op] = update[op];\n      }\n    } else {\n      ret[op] = update[op];\n    }\n  }\n\n  return ret;\n};\n\n/**\n * Makes sure _path is set.\n *\n * This method is inherited by `mquery`\n *\n * @method _ensurePath\n * @param {String} method\n * @api private\n * @memberOf Query\n */\n\n/**\n * Determines if `conds` can be merged using `mquery().merge()`\n *\n * @method canMerge\n * @memberOf Query\n * @instance\n * @param {Object} conds\n * @return {Boolean}\n * @api private\n */\n\n/**\n * Returns default options for this query.\n *\n * @param {Model} model\n * @api private\n */\n\nQuery.prototype._optionsForExec = function(model) {\n  const options = clone(this.options);\n  delete options.populate;\n  model = model || this.model;\n\n  if (!model) {\n    return options;\n  }\n  applyReadConcern(model.schema, options);\n  // Apply schema-level `writeConcern` option\n  applyWriteConcern(model.schema, options);\n\n  const asyncLocalStorage = this.model?.db?.base.transactionAsyncLocalStorage?.getStore();\n  if (!this.options.hasOwnProperty('session') && asyncLocalStorage?.session != null) {\n    options.session = asyncLocalStorage.session;\n  }\n\n  const readPreference = model &&\n  model.schema &&\n  model.schema.options &&\n  model.schema.options.read;\n  if (!('readPreference' in options) && readPreference) {\n    options.readPreference = readPreference;\n  }\n\n  if (options.upsert !== void 0) {\n    options.upsert = !!options.upsert;\n  }\n  if (options.writeConcern) {\n    if (options.j) {\n      options.writeConcern.j = options.j;\n      delete options.j;\n    }\n    if (options.w) {\n      options.writeConcern.w = options.w;\n      delete options.w;\n    }\n    if (options.wtimeout) {\n      options.writeConcern.wtimeout = options.wtimeout;\n      delete options.wtimeout;\n    }\n  }\n\n  this._applyPaths();\n  if (this._fields != null) {\n    this._fields = this._castFields(this._fields);\n    const projection = this._fieldsForExec();\n    if (projection != null) {\n      options.projection = projection;\n    }\n  }\n\n  return options;\n};\n\n/**\n * Sets the lean option.\n *\n * Documents returned from queries with the `lean` option enabled are plain\n * javascript objects, not [Mongoose Documents](https://mongoosejs.com/docs/api/document.html). They have no\n * `save` method, getters/setters, virtuals, or other Mongoose features.\n *\n * #### Example:\n *\n *     new Query().lean() // true\n *     new Query().lean(true)\n *     new Query().lean(false)\n *\n *     const docs = await Model.find().lean();\n *     docs[0] instanceof mongoose.Document; // false\n *\n * [Lean is great for high-performance, read-only cases](https://mongoosejs.com/docs/tutorials/lean.html),\n * especially when combined\n * with [cursors](https://mongoosejs.com/docs/queries.html#streaming).\n *\n * If you need virtuals, getters/setters, or defaults with `lean()`, you need\n * to use a plugin. See:\n *\n * - [mongoose-lean-virtuals](https://plugins.mongoosejs.io/plugins/lean-virtuals)\n * - [mongoose-lean-getters](https://plugins.mongoosejs.io/plugins/lean-getters)\n * - [mongoose-lean-defaults](https://www.npmjs.com/package/mongoose-lean-defaults)\n *\n * @param {Boolean|Object} bool defaults to true\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.lean = function(v) {\n  this._mongooseOptions.lean = arguments.length ? v : true;\n  return this;\n};\n\n/**\n * Adds a `$set` to this query's update without changing the operation.\n * This is useful for query middleware so you can add an update regardless\n * of whether you use `updateOne()`, `updateMany()`, `findOneAndUpdate()`, etc.\n *\n * #### Example:\n *\n *     // Updates `{ $set: { updatedAt: new Date() } }`\n *     new Query().updateOne({}, {}).set('updatedAt', new Date());\n *     new Query().updateMany({}, {}).set({ updatedAt: new Date() });\n *\n * @param {String|Object} path path or object of key/value pairs to set\n * @param {Any} [val] the value to set\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.set = function(path, val) {\n  if (typeof path === 'object') {\n    const keys = Object.keys(path);\n    for (const key of keys) {\n      this.set(key, path[key]);\n    }\n    return this;\n  }\n\n  this._update = this._update || {};\n  if (path in this._update) {\n    delete this._update[path];\n  }\n  this._update.$set = this._update.$set || {};\n  this._update.$set[path] = val;\n  return this;\n};\n\n/**\n * For update operations, returns the value of a path in the update's `$set`.\n * Useful for writing getters/setters that can work with both update operations\n * and `save()`.\n *\n * #### Example:\n *\n *     const query = Model.updateOne({}, { $set: { name: 'Jean-Luc Picard' } });\n *     query.get('name'); // 'Jean-Luc Picard'\n *\n * @param {String|Object} path path or object of key/value pairs to get\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.get = function get(path) {\n  const update = this._update;\n  if (update == null) {\n    return void 0;\n  }\n  const $set = update.$set;\n  if ($set == null) {\n    return update[path];\n  }\n\n  if (utils.hasUserDefinedProperty(update, path)) {\n    return update[path];\n  }\n  if (utils.hasUserDefinedProperty($set, path)) {\n    return $set[path];\n  }\n\n  return void 0;\n};\n\n/**\n * Gets/sets the error flag on this query. If this flag is not null or\n * undefined, the `exec()` promise will reject without executing.\n *\n * #### Example:\n *\n *     Query().error(); // Get current error value\n *     Query().error(null); // Unset the current error\n *     Query().error(new Error('test')); // `exec()` will resolve with test\n *     Schema.pre('find', function() {\n *       if (!this.getQuery().userId) {\n *         this.error(new Error('Not allowed to query without setting userId'));\n *       }\n *     });\n *\n * Note that query casting runs **after** hooks, so cast errors will override\n * custom errors.\n *\n * #### Example:\n *\n *     const TestSchema = new Schema({ num: Number });\n *     const TestModel = db.model('Test', TestSchema);\n *     TestModel.find({ num: 'not a number' }).error(new Error('woops')).exec(function(error) {\n *       // `error` will be a cast error because `num` failed to cast\n *     });\n *\n * @param {Error|null} err if set, `exec()` will fail fast before sending the query to MongoDB\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.error = function error(err) {\n  if (arguments.length === 0) {\n    return this._error;\n  }\n\n  this._error = err;\n  return this;\n};\n\n/**\n * ignore\n * @method _unsetCastError\n * @instance\n * @memberOf Query\n * @api private\n */\n\nQuery.prototype._unsetCastError = function _unsetCastError() {\n  if (this._error != null && !(this._error instanceof CastError)) {\n    return;\n  }\n  return this.error(null);\n};\n\n/**\n * Getter/setter around the current mongoose-specific options for this query\n * Below are the current Mongoose-specific options.\n *\n * - `populate`: an array representing what paths will be populated. Should have one entry for each call to [`Query.prototype.populate()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.populate())\n * - `lean`: if truthy, Mongoose will not [hydrate](https://mongoosejs.com/docs/api/model.html#Model.hydrate()) any documents that are returned from this query. See [`Query.prototype.lean()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.lean()) for more information.\n * - `strict`: controls how Mongoose handles keys that aren't in the schema for updates. This option is `true` by default, which means Mongoose will silently strip any paths in the update that aren't in the schema. See the [`strict` mode docs](https://mongoosejs.com/docs/guide.html#strict) for more information.\n * - `strictQuery`: controls how Mongoose handles keys that aren't in the schema for the query `filter`. This option is `false` by default, which means Mongoose will allow `Model.find({ foo: 'bar' })` even if `foo` is not in the schema. See the [`strictQuery` docs](https://mongoosejs.com/docs/guide.html#strictQuery) for more information.\n * - `nearSphere`: use `$nearSphere` instead of `near()`. See the [`Query.prototype.nearSphere()` docs](https://mongoosejs.com/docs/api/query.html#Query.prototype.nearSphere())\n *\n * Mongoose maintains a separate object for internal options because\n * Mongoose sends `Query.prototype.options` to the MongoDB server, and the\n * above options are not relevant for the MongoDB server.\n *\n * @param {Object} options if specified, overwrites the current options\n * @return {Object} the options\n * @api public\n */\n\nQuery.prototype.mongooseOptions = function(v) {\n  if (arguments.length > 0) {\n    this._mongooseOptions = v;\n  }\n  return this._mongooseOptions;\n};\n\n/**\n * ignore\n * @method _castConditions\n * @memberOf Query\n * @api private\n * @instance\n */\n\nQuery.prototype._castConditions = function() {\n  let sanitizeFilterOpt = undefined;\n  if (this.model != null && utils.hasUserDefinedProperty(this.model.db.options, 'sanitizeFilter')) {\n    sanitizeFilterOpt = this.model.db.options.sanitizeFilter;\n  } else if (this.model != null && utils.hasUserDefinedProperty(this.model.base.options, 'sanitizeFilter')) {\n    sanitizeFilterOpt = this.model.base.options.sanitizeFilter;\n  } else {\n    sanitizeFilterOpt = this._mongooseOptions.sanitizeFilter;\n  }\n\n  if (sanitizeFilterOpt) {\n    sanitizeFilter(this._conditions);\n  }\n\n  try {\n    this.cast(this.model);\n    this._unsetCastError();\n  } catch (err) {\n    this.error(err);\n  }\n};\n\n/*!\n * ignore\n */\n\nfunction _castArrayFilters(query) {\n  try {\n    castArrayFilters(query);\n  } catch (err) {\n    query.error(err);\n  }\n}\n\n/**\n * Execute a `find()`\n *\n * @return {Query} this\n * @api private\n */\nQuery.prototype._find = async function _find() {\n  this._applyTranslateAliases();\n  this._castConditions();\n\n  if (this.error() != null) {\n    throw this.error();\n  }\n\n  const mongooseOptions = this._mongooseOptions;\n  const _this = this;\n  const userProvidedFields = _this._userProvidedFields || {};\n\n  applyGlobalMaxTimeMS(this.options, this.model.db.options, this.model.base.options);\n  applyGlobalDiskUse(this.options, this.model.db.options, this.model.base.options);\n\n  // Separate options to pass down to `completeMany()` in case we need to\n  // set a session on the document\n  const completeManyOptions = Object.assign({}, {\n    session: this && this.options && this.options.session || null,\n    lean: mongooseOptions.lean || null\n  });\n\n  const options = this._optionsForExec();\n\n  const filter = this._conditions;\n  const fields = options.projection;\n\n  const cursor = await this.mongooseCollection.find(filter, options);\n  if (options.explain) {\n    return cursor.explain();\n  }\n\n  let docs = await cursor.toArray();\n  if (docs.length === 0) {\n    return docs;\n  }\n\n  if (!mongooseOptions.populate) {\n    const versionKey = _this.schema.options.versionKey;\n    if (mongooseOptions.lean && mongooseOptions.lean.versionKey === false && versionKey) {\n      docs.forEach((doc) => {\n        if (versionKey in doc) {\n          delete doc[versionKey];\n        }\n      });\n    }\n    return mongooseOptions.lean ?\n      _completeManyLean(_this.model.schema, docs, null, completeManyOptions) :\n      _this._completeMany(docs, fields, userProvidedFields, completeManyOptions);\n  }\n  const pop = helpers.preparePopulationOptionsMQ(_this, mongooseOptions);\n\n  if (mongooseOptions.lean) {\n    return _this.model.populate(docs, pop);\n  }\n\n  docs = await _this._completeMany(docs, fields, userProvidedFields, completeManyOptions);\n  await this.model.populate(docs, pop);\n\n  return docs;\n};\n\n/**\n * Find all documents that match `selector`. The result will be an array of documents.\n *\n * If there are too many documents in the result to fit in memory, use\n * [`Query.prototype.cursor()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.cursor())\n *\n * #### Example:\n *\n *     const arr = await Movie.find({ year: { $gte: 1980, $lte: 1989 } });\n *\n * @param {Object|ObjectId} [filter] mongodb filter. If not specified, returns all documents.\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.find = function(conditions) {\n  if (typeof conditions === 'function' ||\n      typeof arguments[1] === 'function') {\n    throw new MongooseError('Query.prototype.find() no longer accepts a callback');\n  }\n\n  this.op = 'find';\n\n  if (mquery.canMerge(conditions)) {\n    this.merge(conditions);\n\n    prepareDiscriminatorCriteria(this);\n  } else if (conditions != null) {\n    this.error(new ObjectParameterError(conditions, 'filter', 'find'));\n  }\n\n  return this;\n};\n\n/**\n * Merges another Query or conditions object into this one.\n *\n * When a Query is passed, conditions, field selection and options are merged.\n *\n * @param {Query|Object} source\n * @return {Query} this\n */\n\nQuery.prototype.merge = function(source) {\n  if (!source) {\n    return this;\n  }\n\n  const opts = { overwrite: true };\n\n  if (source instanceof Query) {\n    // if source has a feature, apply it to ourselves\n\n    if (source._conditions) {\n      opts.omit = {};\n      if (this._conditions && this._conditions.$and && source._conditions.$and) {\n        opts.omit['$and'] = true;\n        this._conditions.$and = this._conditions.$and.concat(source._conditions.$and);\n      }\n      if (this._conditions && this._conditions.$or && source._conditions.$or) {\n        opts.omit['$or'] = true;\n        this._conditions.$or = this._conditions.$or.concat(source._conditions.$or);\n      }\n      utils.merge(this._conditions, source._conditions, opts);\n    }\n\n    if (source._fields) {\n      this._fields || (this._fields = {});\n      utils.merge(this._fields, source._fields, opts);\n    }\n\n    if (source.options) {\n      this.options || (this.options = {});\n      utils.merge(this.options, source.options, opts);\n    }\n\n    if (source._update) {\n      this._update || (this._update = {});\n      utils.mergeClone(this._update, source._update);\n    }\n\n    if (source._distinct) {\n      this._distinct = source._distinct;\n    }\n\n    utils.merge(this._mongooseOptions, source._mongooseOptions);\n\n    return this;\n  } else if (this.model != null && source instanceof this.model.base.Types.ObjectId) {\n    utils.merge(this._conditions, { _id: source }, opts);\n\n    return this;\n  } else if (source && source.$__) {\n    source = source.toObject(internalToObjectOptions);\n  }\n\n  opts.omit = {};\n  if (source.$and) {\n    opts.omit['$and'] = true;\n    if (!this._conditions) {\n      this._conditions = {};\n    }\n    this._conditions.$and = (this._conditions.$and || []).concat(source.$and);\n  }\n  if (source.$or) {\n    opts.omit['$or'] = true;\n    if (!this._conditions) {\n      this._conditions = {};\n    }\n    this._conditions.$or = (this._conditions.$or || []).concat(source.$or);\n  }\n\n  // plain object\n  utils.merge(this._conditions, source, opts);\n\n  return this;\n};\n\n/**\n * Adds a collation to this op (MongoDB 3.4 and up)\n *\n * @param {Object} value\n * @return {Query} this\n * @see MongoDB docs https://www.mongodb.com/docs/manual/reference/method/cursor.collation/#cursor.collation\n * @api public\n */\n\nQuery.prototype.collation = function(value) {\n  if (this.options == null) {\n    this.options = {};\n  }\n  this.options.collation = value;\n  return this;\n};\n\n/**\n * Hydrate a single doc from `findOne()`, `findOneAndUpdate()`, etc.\n *\n * @api private\n */\n\nQuery.prototype._completeOne = function(doc, res, callback) {\n  if (!doc && !this.options.includeResultMetadata) {\n    return callback(null, null);\n  }\n\n  const model = this.model;\n  const projection = clone(this._fields);\n  const userProvidedFields = this._userProvidedFields || {};\n  // `populate`, `lean`\n  const mongooseOptions = this._mongooseOptions;\n\n  const options = this.options;\n  if (!options.lean && mongooseOptions.lean) {\n    options.lean = mongooseOptions.lean;\n  }\n\n  if (options.explain) {\n    return callback(null, doc);\n  }\n\n  if (!mongooseOptions.populate) {\n    const versionKey = this.schema.options.versionKey;\n    if (mongooseOptions.lean && mongooseOptions.lean.versionKey === false && versionKey) {\n      if (versionKey in doc) {\n        delete doc[versionKey];\n      }\n    }\n    return mongooseOptions.lean ?\n      _completeOneLean(model.schema, doc, null, res, options, callback) :\n      completeOne(model, doc, res, options, projection, userProvidedFields,\n        null, callback);\n  }\n\n  const pop = helpers.preparePopulationOptionsMQ(this, this._mongooseOptions);\n  if (mongooseOptions.lean) {\n    return model.populate(doc, pop).then(\n      doc => {\n        _completeOneLean(model.schema, doc, null, res, options, callback);\n      },\n      error => {\n        callback(error);\n      }\n    );\n  }\n\n  completeOne(model, doc, res, options, projection, userProvidedFields, [], (err, doc) => {\n    if (err != null) {\n      return callback(err);\n    }\n    model.populate(doc, pop).then(res => { callback(null, res); }, err => { callback(err); });\n  });\n};\n\n/**\n * Given a model and an array of docs, hydrates all the docs to be instances\n * of the model. Used to initialize docs returned from the db from `find()`\n *\n * @param {Array} docs\n * @param {Object} fields the projection used, including `select` from schemas\n * @param {Object} userProvidedFields the user-specified projection\n * @param {Object} [opts]\n * @param {Array} [opts.populated]\n * @param {ClientSession} [opts.session]\n * @api private\n */\n\nQuery.prototype._completeMany = async function _completeMany(docs, fields, userProvidedFields, opts) {\n  const model = this.model;\n  return Promise.all(docs.map(doc => new Promise((resolve, reject) => {\n    const rawDoc = doc;\n    doc = helpers.createModel(model, doc, fields, userProvidedFields);\n    if (opts.session != null) {\n      doc.$session(opts.session);\n    }\n    doc.$init(rawDoc, opts, (err) => {\n      if (err != null) {\n        return reject(err);\n      }\n      resolve(doc);\n    });\n  })));\n};\n\n/**\n * Internal helper to execute a findOne() operation\n *\n * @see findOne https://www.mongodb.com/docs/manual/reference/method/db.collection.findOne/\n * @api private\n */\n\nQuery.prototype._findOne = async function _findOne() {\n  this._applyTranslateAliases();\n  this._castConditions();\n\n  if (this.error()) {\n    const err = this.error();\n    throw err;\n  }\n\n  applyGlobalMaxTimeMS(this.options, this.model.db.options, this.model.base.options);\n  applyGlobalDiskUse(this.options, this.model.db.options, this.model.base.options);\n\n  const options = this._optionsForExec();\n\n  // don't pass in the conditions because we already merged them in\n  const doc = await this.mongooseCollection.findOne(this._conditions, options);\n  return new Promise((resolve, reject) => {\n    this._completeOne(doc, null, (err, res) => {\n      if (err) {\n        return reject(err);\n      }\n      resolve(res);\n    });\n  });\n};\n\n/**\n * Declares the query a findOne operation. When executed, the first found document is passed to the callback.\n *\n * The result of the query is a single document, or `null` if no document was found.\n *\n * * *Note:* `conditions` is optional, and if `conditions` is null or undefined,\n * mongoose will send an empty `findOne` command to MongoDB, which will return\n * an arbitrary document. If you're querying by `_id`, use `Model.findById()`\n * instead.\n *\n * This function triggers the following middleware.\n *\n * - `findOne()`\n *\n * #### Example:\n *\n *     const query = Kitten.where({ color: 'white' });\n *     const kitten = await query.findOne();\n *\n * @param {Object} [filter] mongodb selector\n * @param {Object} [projection] optional fields to return\n * @param {Object} [options] see [`setOptions()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.setOptions())\n * @param {Boolean} [options.translateAliases=null] If set to `true`, translates any schema-defined aliases in `filter`, `projection`, `update`, and `distinct`. Throws an error if there are any conflicts where both alias and raw property are defined on the same object.\n * @return {Query} this\n * @see findOne https://www.mongodb.com/docs/manual/reference/method/db.collection.findOne/\n * @see Query.select https://mongoosejs.com/docs/api/query.html#Query.prototype.select()\n * @api public\n */\n\nQuery.prototype.findOne = function(conditions, projection, options) {\n  if (typeof conditions === 'function' ||\n      typeof projection === 'function' ||\n      typeof options === 'function' ||\n      typeof arguments[3] === 'function') {\n    throw new MongooseError('Query.prototype.findOne() no longer accepts a callback');\n  }\n\n  this.op = 'findOne';\n  this._validateOp();\n\n  if (options) {\n    this.setOptions(options);\n  }\n\n  if (projection) {\n    this.select(projection);\n  }\n\n  if (mquery.canMerge(conditions)) {\n    this.merge(conditions);\n\n    prepareDiscriminatorCriteria(this);\n  } else if (conditions != null) {\n    this.error(new ObjectParameterError(conditions, 'filter', 'findOne'));\n  }\n\n  return this;\n};\n\n\n/**\n * Execute a countDocuments query\n *\n * @see countDocuments https://mongodb.github.io/node-mongodb-native/4.9/classes/Collection.html#countDocuments\n * @api private\n */\n\nQuery.prototype._countDocuments = async function _countDocuments() {\n  this._applyTranslateAliases();\n\n  try {\n    this.cast(this.model);\n  } catch (err) {\n    this.error(err);\n  }\n\n  if (this.error()) {\n    throw this.error();\n  }\n\n  applyGlobalMaxTimeMS(this.options, this.model.db.options, this.model.base.options);\n  applyGlobalDiskUse(this.options, this.model.db.options, this.model.base.options);\n\n  const options = this._optionsForExec();\n\n  const conds = this._conditions;\n\n  return this.mongooseCollection.countDocuments(conds, options);\n};\n\n/*!\n * If `translateAliases` option is set, call `Model.translateAliases()`\n * on the following query properties: filter, projection, update, distinct.\n */\n\nQuery.prototype._applyTranslateAliases = function _applyTranslateAliases() {\n  let applyTranslateAliases = false;\n  if ('translateAliases' in this._mongooseOptions) {\n    applyTranslateAliases = this._mongooseOptions.translateAliases;\n  } else if (this.model?.schema?._userProvidedOptions?.translateAliases != null) {\n    applyTranslateAliases = this.model.schema._userProvidedOptions.translateAliases;\n  } else if (this.model?.base?.options?.translateAliases != null) {\n    applyTranslateAliases = this.model.base.options.translateAliases;\n  }\n  if (!applyTranslateAliases) {\n    return;\n  }\n\n  if (this.model?.schema?.aliases && Object.keys(this.model.schema.aliases).length > 0) {\n    this.model.translateAliases(this._conditions, true);\n    this.model.translateAliases(this._fields, true);\n    this.model.translateAliases(this._update, true);\n    if (this._distinct != null && this.model.schema.aliases[this._distinct] != null) {\n      this._distinct = this.model.schema.aliases[this._distinct];\n    }\n  }\n};\n\n/**\n * Execute a estimatedDocumentCount() query\n *\n * @see estimatedDocumentCount https://mongodb.github.io/node-mongodb-native/4.9/classes/Collection.html#estimatedDocumentCount\n * @api private\n */\n\nQuery.prototype._estimatedDocumentCount = async function _estimatedDocumentCount() {\n  if (this.error()) {\n    throw this.error();\n  }\n\n  const options = this._optionsForExec();\n\n  return this.mongooseCollection.estimatedDocumentCount(options);\n};\n\n/**\n * Specifies this query as a `estimatedDocumentCount()` query. Faster than\n * using `countDocuments()` for large collections because\n * `estimatedDocumentCount()` uses collection metadata rather than scanning\n * the entire collection.\n *\n * `estimatedDocumentCount()` does **not** accept a filter. `Model.find({ foo: bar }).estimatedDocumentCount()`\n * is equivalent to `Model.find().estimatedDocumentCount()`\n *\n * This function triggers the following middleware.\n *\n * - `estimatedDocumentCount()`\n *\n * #### Example:\n *\n *     await Model.find().estimatedDocumentCount();\n *\n * @param {Object} [options] passed transparently to the [MongoDB driver](https://mongodb.github.io/node-mongodb-native/4.9/interfaces/EstimatedDocumentCountOptions.html)\n * @return {Query} this\n * @see estimatedDocumentCount https://mongodb.github.io/node-mongodb-native/4.9/classes/Collection.html#estimatedDocumentCount\n * @api public\n */\n\nQuery.prototype.estimatedDocumentCount = function(options) {\n  if (typeof options === 'function' ||\n      typeof arguments[1] === 'function') {\n    throw new MongooseError('Query.prototype.estimatedDocumentCount() no longer accepts a callback');\n  }\n\n  this.op = 'estimatedDocumentCount';\n  this._validateOp();\n\n  if (typeof options === 'object' && options != null) {\n    this.setOptions(options);\n  }\n\n  return this;\n};\n\n/**\n * Specifies this query as a `countDocuments()` query. Behaves like `count()`,\n * except it always does a full collection scan when passed an empty filter `{}`.\n *\n * There are also minor differences in how `countDocuments()` handles\n * [`$where` and a couple geospatial operators](https://mongodb.github.io/node-mongodb-native/4.9/classes/Collection.html#countDocuments).\n * versus `count()`.\n *\n * This function triggers the following middleware.\n *\n * - `countDocuments()`\n *\n * #### Example:\n *\n *     const countQuery = model.where({ 'color': 'black' }).countDocuments();\n *\n *     query.countDocuments({ color: 'black' }).count().exec();\n *\n *     await query.countDocuments({ color: 'black' });\n *\n *     query.where('color', 'black').countDocuments().exec();\n *\n * The `countDocuments()` function is similar to `count()`, but there are a\n * [few operators that `countDocuments()` does not support](https://mongodb.github.io/node-mongodb-native/4.9/classes/Collection.html#countDocuments).\n * Below are the operators that `count()` supports but `countDocuments()` does not,\n * and the suggested replacement:\n *\n * - `$where`: [`$expr`](https://www.mongodb.com/docs/manual/reference/operator/query/expr/)\n * - `$near`: [`$geoWithin`](https://www.mongodb.com/docs/manual/reference/operator/query/geoWithin/) with [`$center`](https://www.mongodb.com/docs/manual/reference/operator/query/center/#op._S_center)\n * - `$nearSphere`: [`$geoWithin`](https://www.mongodb.com/docs/manual/reference/operator/query/geoWithin/) with [`$centerSphere`](https://www.mongodb.com/docs/manual/reference/operator/query/centerSphere/#op._S_centerSphere)\n *\n * @param {Object} [filter] mongodb selector\n * @param {Object} [options]\n * @return {Query} this\n * @see countDocuments https://mongodb.github.io/node-mongodb-native/4.9/classes/Collection.html#countDocuments\n * @api public\n */\n\nQuery.prototype.countDocuments = function(conditions, options) {\n  if (typeof conditions === 'function' ||\n      typeof options === 'function' ||\n      typeof arguments[2] === 'function') {\n    throw new MongooseError('Query.prototype.countDocuments() no longer accepts a callback');\n  }\n\n  this.op = 'countDocuments';\n  this._validateOp();\n\n  if (mquery.canMerge(conditions)) {\n    this.merge(conditions);\n  }\n\n  if (typeof options === 'object' && options != null) {\n    this.setOptions(options);\n  }\n\n  return this;\n};\n\n/**\n * Execute a `distinct()` query\n *\n * @see distinct https://www.mongodb.com/docs/manual/reference/method/db.collection.distinct/\n * @api private\n */\n\nQuery.prototype.__distinct = async function __distinct() {\n  this._applyTranslateAliases();\n  this._castConditions();\n\n  if (this.error()) {\n    throw this.error();\n  }\n\n  applyGlobalMaxTimeMS(this.options, this.model.db.options, this.model.base.options);\n  applyGlobalDiskUse(this.options, this.model.db.options, this.model.base.options);\n\n  const options = this._optionsForExec();\n\n  return this.mongooseCollection.\n    distinct(this._distinct, this._conditions, options);\n};\n\n/**\n * Declares or executes a distinct() operation.\n *\n * This function does not trigger any middleware.\n *\n * #### Example:\n *\n *     distinct(field, conditions)\n *     distinct(field)\n *     distinct()\n *\n * @param {String} [field]\n * @param {Object|Query} [filter]\n * @return {Query} this\n * @see distinct https://www.mongodb.com/docs/manual/reference/method/db.collection.distinct/\n * @api public\n */\n\nQuery.prototype.distinct = function(field, conditions) {\n  if (typeof field === 'function' ||\n      typeof conditions === 'function' ||\n      typeof arguments[2] === 'function') {\n    throw new MongooseError('Query.prototype.distinct() no longer accepts a callback');\n  }\n\n  this.op = 'distinct';\n  this._validateOp();\n\n  if (mquery.canMerge(conditions)) {\n    this.merge(conditions);\n\n    prepareDiscriminatorCriteria(this);\n  } else if (conditions != null) {\n    this.error(new ObjectParameterError(conditions, 'filter', 'distinct'));\n  }\n\n  if (field != null) {\n    this._distinct = field;\n  }\n\n  return this;\n};\n\n/**\n * Sets the sort order\n *\n * If an object is passed, values allowed are `asc`, `desc`, `ascending`, `descending`, `1`, and `-1`.\n *\n * If a string is passed, it must be a space delimited list of path names. The\n * sort order of each path is ascending unless the path name is prefixed with `-`\n * which will be treated as descending.\n *\n * #### Example:\n *\n *     // sort by \"field\" ascending and \"test\" descending\n *     query.sort({ field: 'asc', test: -1 });\n *\n *     // equivalent\n *     query.sort('field -test');\n *\n *     // also possible is to use a array with array key-value pairs\n *     query.sort([['field', 'asc']]);\n *\n * #### Note:\n *\n * Cannot be used with `distinct()`\n *\n * @param {Object|String|Array<Array<(string | number)>>} arg\n * @param {Object} [options]\n * @param {Boolean} [options.override=false] If true, replace existing sort options with `arg`\n * @return {Query} this\n * @see cursor.sort https://www.mongodb.com/docs/manual/reference/method/cursor.sort/\n * @api public\n */\n\nQuery.prototype.sort = function(arg, options) {\n  if (arguments.length > 2) {\n    throw new Error('sort() takes at most 2 arguments');\n  }\n  if (options != null && typeof options !== 'object') {\n    throw new Error('sort() options argument must be an object or nullish');\n  }\n\n  if (this.options.sort == null) {\n    this.options.sort = {};\n  }\n  if (options && options.override) {\n    this.options.sort = {};\n  }\n  const sort = this.options.sort;\n  if (typeof arg === 'string') {\n    const properties = arg.indexOf(' ') === -1 ? [arg] : arg.split(' ');\n    for (let property of properties) {\n      const ascend = '-' == property[0] ? -1 : 1;\n      if (ascend === -1) {\n        property = property.slice(1);\n      }\n      if (specialProperties.has(property)) {\n        continue;\n      }\n      sort[property] = ascend;\n    }\n  } else if (Array.isArray(arg)) {\n    for (const pair of arg) {\n      if (!Array.isArray(pair)) {\n        throw new TypeError('Invalid sort() argument, must be array of arrays');\n      }\n      const key = '' + pair[0];\n      if (specialProperties.has(key)) {\n        continue;\n      }\n      sort[key] = _handleSortValue(pair[1], key);\n    }\n  } else if (typeof arg === 'object' && arg != null && !(arg instanceof Map)) {\n    for (const key of Object.keys(arg)) {\n      if (specialProperties.has(key)) {\n        continue;\n      }\n      sort[key] = _handleSortValue(arg[key], key);\n    }\n  } else if (arg instanceof Map) {\n    for (let key of arg.keys()) {\n      key = '' + key;\n      if (specialProperties.has(key)) {\n        continue;\n      }\n      sort[key] = _handleSortValue(arg.get(key), key);\n    }\n  } else if (arg != null) {\n    throw new TypeError('Invalid sort() argument. Must be a string, object, array, or map.');\n  }\n\n  return this;\n};\n\n/*!\n * Convert sort values\n */\n\nfunction _handleSortValue(val, key) {\n  if (val === 1 || val === 'asc' || val === 'ascending') {\n    return 1;\n  }\n  if (val === -1 || val === 'desc' || val === 'descending') {\n    return -1;\n  }\n  if (val?.$meta != null) {\n    return { $meta: val.$meta };\n  }\n  throw new TypeError('Invalid sort value: { ' + key + ': ' + val + ' }');\n}\n\n/**\n * Declare and/or execute this query as a `deleteOne()` operation. Works like\n * remove, except it deletes at most one document regardless of the `single`\n * option.\n *\n * This function triggers `deleteOne` middleware.\n *\n * #### Example:\n *\n *     await Character.deleteOne({ name: 'Eddard Stark' });\n *\n * This function calls the MongoDB driver's [`Collection#deleteOne()` function](https://mongodb.github.io/node-mongodb-native/4.9/classes/Collection.html#deleteOne).\n * The returned [promise](https://mongoosejs.com/docs/queries.html) resolves to an\n * object that contains 3 properties:\n *\n * - `ok`: `1` if no errors occurred\n * - `deletedCount`: the number of documents deleted\n * - `n`: the number of documents deleted. Equal to `deletedCount`.\n *\n * #### Example:\n *\n *     const res = await Character.deleteOne({ name: 'Eddard Stark' });\n *     // `1` if MongoDB deleted a doc, `0` if no docs matched the filter `{ name: ... }`\n *     res.deletedCount;\n *\n * @param {Object|Query} [filter] mongodb selector\n * @param {Object} [options] optional see [`Query.prototype.setOptions()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.setOptions())\n * @return {Query} this\n * @see DeleteResult https://mongodb.github.io/node-mongodb-native/4.9/interfaces/DeleteResult.html\n * @see deleteOne https://mongodb.github.io/node-mongodb-native/4.9/classes/Collection.html#deleteOne\n * @api public\n */\n\nQuery.prototype.deleteOne = function deleteOne(filter, options) {\n  if (typeof filter === 'function' || typeof options === 'function' || typeof arguments[2] === 'function') {\n    throw new MongooseError('Query.prototype.deleteOne() no longer accepts a callback');\n  }\n  this.op = 'deleteOne';\n  this.setOptions(options);\n\n  if (mquery.canMerge(filter)) {\n    this.merge(filter);\n\n    prepareDiscriminatorCriteria(this);\n  } else if (filter != null) {\n    this.error(new ObjectParameterError(filter, 'filter', 'deleteOne'));\n  }\n\n  return this;\n};\n\n/**\n * Internal thunk for `deleteOne()`\n *\n * @method _deleteOne\n * @instance\n * @memberOf Query\n * @api private\n */\n\nQuery.prototype._deleteOne = async function _deleteOne() {\n  this._applyTranslateAliases();\n  this._castConditions();\n\n  if (this.error() != null) {\n    throw this.error();\n  }\n\n  const options = this._optionsForExec();\n\n  return this.mongooseCollection.deleteOne(this._conditions, options);\n};\n\n/**\n * Declare and/or execute this query as a `deleteMany()` operation. Works like\n * remove, except it deletes _every_ document that matches `filter` in the\n * collection, regardless of the value of `single`.\n *\n * This function triggers `deleteMany` middleware.\n *\n * #### Example:\n *\n *     await Character.deleteMany({ name: /Stark/, age: { $gte: 18 } });\n *\n * This function calls the MongoDB driver's [`Collection#deleteMany()` function](https://mongodb.github.io/node-mongodb-native/4.9/classes/Collection.html#deleteMany).\n * The returned [promise](https://mongoosejs.com/docs/queries.html) resolves to an\n * object that contains 3 properties:\n *\n * - `ok`: `1` if no errors occurred\n * - `deletedCount`: the number of documents deleted\n * - `n`: the number of documents deleted. Equal to `deletedCount`.\n *\n * #### Example:\n *\n *     const res = await Character.deleteMany({ name: /Stark/, age: { $gte: 18 } });\n *     // `0` if no docs matched the filter, number of docs deleted otherwise\n *     res.deletedCount;\n *\n * @param {Object|Query} [filter] mongodb selector\n * @param {Object} [options] optional see [`Query.prototype.setOptions()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.setOptions())\n * @return {Query} this\n * @see DeleteResult https://mongodb.github.io/node-mongodb-native/4.9/interfaces/DeleteResult.html\n * @see deleteMany https://mongodb.github.io/node-mongodb-native/4.9/classes/Collection.html#deleteMany\n * @api public\n */\n\nQuery.prototype.deleteMany = function(filter, options) {\n  if (typeof filter === 'function' || typeof options === 'function' || typeof arguments[2] === 'function') {\n    throw new MongooseError('Query.prototype.deleteMany() no longer accepts a callback');\n  }\n  this.setOptions(options);\n  this.op = 'deleteMany';\n\n  if (mquery.canMerge(filter)) {\n    this.merge(filter);\n\n    prepareDiscriminatorCriteria(this);\n  } else if (filter != null) {\n    this.error(new ObjectParameterError(filter, 'filter', 'deleteMany'));\n  }\n\n  return this;\n};\n\n/**\n * Execute a `deleteMany()` query\n *\n * @param {Function} callback\n * @method _deleteMany\n * @instance\n * @memberOf Query\n * @api private\n */\n\nQuery.prototype._deleteMany = async function _deleteMany() {\n  this._applyTranslateAliases();\n  this._castConditions();\n\n  if (this.error() != null) {\n    throw this.error();\n  }\n\n  const options = this._optionsForExec();\n\n  return this.mongooseCollection.deleteMany(this._conditions, options);\n};\n\n/**\n * hydrates a document\n *\n * @param {Model} model\n * @param {Document} doc\n * @param {Object} res 3rd parameter to callback\n * @param {Object} fields\n * @param {Query} self\n * @param {Array} [pop] array of paths used in population\n * @param {Function} callback\n * @api private\n */\n\nfunction completeOne(model, doc, res, options, fields, userProvidedFields, pop, callback) {\n  if (options.includeResultMetadata && doc == null) {\n    _init(null);\n    return null;\n  }\n\n  helpers.createModelAndInit(model, doc, fields, userProvidedFields, options, pop, _init);\n\n  function _init(err, casted) {\n    if (err) {\n      return immediate(() => callback(err));\n    }\n\n\n    if (options.includeResultMetadata) {\n      if (doc && casted) {\n        if (options.session != null) {\n          casted.$session(options.session);\n        }\n        res.value = casted;\n      } else {\n        res.value = null;\n      }\n      return immediate(() => callback(null, res));\n    }\n    if (options.session != null) {\n      casted.$session(options.session);\n    }\n    immediate(() => callback(null, casted));\n  }\n}\n\n/**\n * If the model is a discriminator type and not root, then add the key & value to the criteria.\n * @param {Query} query\n * @api private\n */\n\nfunction prepareDiscriminatorCriteria(query) {\n  if (!query || !query.model || !query.model.schema) {\n    return;\n  }\n\n  const schema = query.model.schema;\n\n  if (schema && schema.discriminatorMapping && !schema.discriminatorMapping.isRoot) {\n    query._conditions[schema.discriminatorMapping.key] = schema.discriminatorMapping.value;\n  }\n}\n\n/**\n * Issues a mongodb `findOneAndUpdate()` command.\n *\n * Finds a matching document, updates it according to the `update` arg, passing any `options`, and returns the found\n * document (if any).\n *\n * This function triggers the following middleware.\n *\n * - `findOneAndUpdate()`\n *\n * #### Available options\n *\n * - `new`: bool - if true, return the modified document rather than the original. defaults to false (changed in 4.0)\n * - `upsert`: bool - creates the object if it doesn't exist. defaults to false.\n * - `fields`: {Object|String} - Field selection. Equivalent to `.select(fields).findOneAndUpdate()`\n * - `sort`: if multiple docs are found by the conditions, sets the sort order to choose which doc to update\n * - `maxTimeMS`: puts a time limit on the query - requires mongodb >= 2.6.0\n * - `runValidators`: if true, runs [update validators](https://mongoosejs.com/docs/validation.html#update-validators) on this command. Update validators validate the update operation against the model's schema.\n * - `setDefaultsOnInsert`: `true` by default. If `setDefaultsOnInsert` and `upsert` are true, mongoose will apply the [defaults](https://mongoosejs.com/docs/defaults.html) specified in the model's schema if a new document is created.\n *\n * #### Example:\n *\n *     query.findOneAndUpdate(conditions, update, options)  // returns Query\n *     query.findOneAndUpdate(conditions, update)           // returns Query\n *     query.findOneAndUpdate(update)                       // returns Query\n *     query.findOneAndUpdate()                             // returns Query\n *\n * @method findOneAndUpdate\n * @memberOf Query\n * @instance\n * @param {Object|Query} [filter]\n * @param {Object} [doc]\n * @param {Object} [options]\n * @param {Boolean} [options.includeResultMetadata] if true, returns the full [ModifyResult from the MongoDB driver](https://mongodb.github.io/node-mongodb-native/4.9/interfaces/ModifyResult.html) rather than just the document\n * @param {Boolean|String} [options.strict] overwrites the schema's [strict mode option](https://mongoosejs.com/docs/guide.html#strict)\n * @param {ClientSession} [options.session=null] The session associated with this query. See [transactions docs](https://mongoosejs.com/docs/transactions.html).\n * @param {Boolean} [options.multipleCastError] by default, mongoose only returns the first error that occurred in casting the query. Turn on this option to aggregate all the cast errors.\n * @param {Boolean} [options.new=false] By default, `findOneAndUpdate()` returns the document as it was **before** `update` was applied. If you set `new: true`, `findOneAndUpdate()` will instead give you the object after `update` was applied.\n * @param {Object} [options.lean] if truthy, mongoose will return the document as a plain JavaScript object rather than a mongoose document. See [`Query.lean()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.lean()) and [the Mongoose lean tutorial](https://mongoosejs.com/docs/tutorials/lean.html).\n * @param {ClientSession} [options.session=null] The session associated with this query. See [transactions docs](https://mongoosejs.com/docs/transactions.html).\n * @param {Boolean|String} [options.strict] overwrites the schema's [strict mode option](https://mongoosejs.com/docs/guide.html#strict)\n * @param {Boolean} [options.timestamps=null] If set to `false` and [schema-level timestamps](https://mongoosejs.com/docs/guide.html#timestamps) are enabled, skip timestamps for this update. Note that this allows you to overwrite timestamps. Does nothing if schema-level timestamps are not set.\n * @param {Boolean} [options.returnOriginal=null] An alias for the `new` option. `returnOriginal: false` is equivalent to `new: true`.\n * @param {Boolean} [options.translateAliases=null] If set to `true`, translates any schema-defined aliases in `filter`, `projection`, `update`, and `distinct`. Throws an error if there are any conflicts where both alias and raw property are defined on the same object.\n * @param {Boolean} [options.overwriteDiscriminatorKey=false] Mongoose removes discriminator key updates from `update` by default, set `overwriteDiscriminatorKey` to `true` to allow updating the discriminator key\n * @see Tutorial https://mongoosejs.com/docs/tutorials/findoneandupdate.html\n * @see findAndModify command https://www.mongodb.com/docs/manual/reference/command/findAndModify/\n * @see ModifyResult https://mongodb.github.io/node-mongodb-native/4.9/interfaces/ModifyResult.html\n * @see findOneAndUpdate https://mongodb.github.io/node-mongodb-native/4.9/classes/Collection.html#findOneAndUpdate\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.findOneAndUpdate = function(filter, doc, options) {\n  if (typeof filter === 'function' ||\n      typeof doc === 'function' ||\n      typeof options === 'function' ||\n      typeof arguments[3] === 'function') {\n    throw new MongooseError('Query.prototype.findOneAndUpdate() no longer accepts a callback');\n  }\n\n  this.op = 'findOneAndUpdate';\n  this._validateOp();\n  this._validate();\n\n  switch (arguments.length) {\n    case 2:\n      options = undefined;\n      break;\n    case 1:\n      doc = filter;\n      filter = options = undefined;\n      break;\n  }\n\n  if (mquery.canMerge(filter)) {\n    this.merge(filter);\n  } else if (filter != null) {\n    this.error(\n      new ObjectParameterError(filter, 'filter', 'findOneAndUpdate')\n    );\n  }\n\n  // apply doc\n  if (doc) {\n    this._mergeUpdate(doc);\n  }\n\n  options = options ? clone(options) : {};\n\n  if (options.projection) {\n    this.select(options.projection);\n    delete options.projection;\n  }\n  if (options.fields) {\n    this.select(options.fields);\n    delete options.fields;\n  }\n\n  const returnOriginal = this &&\n    this.model &&\n    this.model.base &&\n    this.model.base.options &&\n    this.model.base.options.returnOriginal;\n  if (options.new == null && options.returnDocument == null && options.returnOriginal == null && returnOriginal != null) {\n    options.returnOriginal = returnOriginal;\n  }\n\n  this.setOptions(options);\n\n  return this;\n};\n\n/**\n * Execute a findOneAndUpdate operation\n *\n * @method _findOneAndUpdate\n * @memberOf Query\n * @api private\n */\n\nQuery.prototype._findOneAndUpdate = async function _findOneAndUpdate() {\n  this._applyTranslateAliases();\n  this._castConditions();\n\n  _castArrayFilters(this);\n\n  if (this.error()) {\n    throw this.error();\n  }\n\n  applyGlobalMaxTimeMS(this.options, this.model.db.options, this.model.base.options);\n  applyGlobalDiskUse(this.options, this.model.db.options, this.model.base.options);\n\n  if ('strict' in this.options) {\n    this._mongooseOptions.strict = this.options.strict;\n  }\n  const options = this._optionsForExec(this.model);\n  convertNewToReturnDocument(options);\n\n  this._update = this._castUpdate(this._update);\n\n  const _opts = Object.assign({}, options, {\n    setDefaultsOnInsert: this._mongooseOptions.setDefaultsOnInsert\n  });\n  this._update = setDefaultsOnInsert(this._conditions, this.model.schema,\n    this._update, _opts);\n\n  if (!this._update || Object.keys(this._update).length === 0) {\n    if (options.upsert) {\n      // still need to do the upsert to empty doc\n      const doc = clone(this._update);\n      delete doc._id;\n      this._update = { $set: doc };\n    } else {\n      this._executionStack = null;\n      const res = await this._findOne();\n      return res;\n    }\n  } else if (this._update instanceof Error) {\n    throw this._update;\n  } else {\n    // In order to make MongoDB 2.6 happy (see\n    // https://jira.mongodb.org/browse/SERVER-12266 and related issues)\n    // if we have an actual update document but $set is empty, junk the $set.\n    if (this._update.$set && Object.keys(this._update.$set).length === 0) {\n      delete this._update.$set;\n    }\n  }\n\n  const runValidators = _getOption(this, 'runValidators', false);\n  if (runValidators) {\n    await this.validate(this._update, options, false);\n  }\n\n  if (this._update.toBSON) {\n    this._update = this._update.toBSON();\n  }\n\n  let res = await this.mongooseCollection.findOneAndUpdate(this._conditions, this._update, options);\n  for (const fn of this._transforms) {\n    res = fn(res);\n  }\n  const doc = !options.includeResultMetadata ? res : res.value;\n\n  return new Promise((resolve, reject) => {\n    this._completeOne(doc, res, (err, res) => {\n      if (err) {\n        return reject(err);\n      }\n      resolve(res);\n    });\n  });\n};\n\n/**\n * Issues a MongoDB [findOneAndDelete](https://www.mongodb.com/docs/manual/reference/method/db.collection.findOneAndDelete/) command.\n *\n * Finds a matching document, removes it, and returns the found document (if any).\n *\n * This function triggers the following middleware.\n *\n * - `findOneAndDelete()`\n *\n * #### Available options\n *\n * - `sort`: if multiple docs are found by the conditions, sets the sort order to choose which doc to update\n * - `maxTimeMS`: puts a time limit on the query - requires mongodb >= 2.6.0\n *\n * #### Callback Signature\n *\n *     function(error, doc) {\n *       // error: any errors that occurred\n *       // doc: the document before updates are applied if `new: false`, or after updates if `new = true`\n *     }\n *\n * #### Example:\n *\n *     A.where().findOneAndDelete(conditions, options)  // return Query\n *     A.where().findOneAndDelete(conditions) // returns Query\n *     A.where().findOneAndDelete()           // returns Query\n *\n * @method findOneAndDelete\n * @memberOf Query\n * @param {Object} [filter]\n * @param {Object} [options]\n * @param {Boolean} [options.includeResultMetadata] if true, returns the full [ModifyResult from the MongoDB driver](https://mongodb.github.io/node-mongodb-native/4.9/interfaces/ModifyResult.html) rather than just the document\n * @param {ClientSession} [options.session=null] The session associated with this query. See [transactions docs](https://mongoosejs.com/docs/transactions.html).\n * @param {Boolean|String} [options.strict] overwrites the schema's [strict mode option](https://mongoosejs.com/docs/guide.html#strict)\n * @return {Query} this\n * @see findAndModify command https://www.mongodb.com/docs/manual/reference/command/findAndModify/\n * @api public\n */\n\nQuery.prototype.findOneAndDelete = function(filter, options) {\n  if (typeof filter === 'function' ||\n      typeof options === 'function' ||\n      typeof arguments[2] === 'function') {\n    throw new MongooseError('Query.prototype.findOneAndDelete() no longer accepts a callback');\n  }\n\n  this.op = 'findOneAndDelete';\n  this._validateOp();\n  this._validate();\n\n  if (mquery.canMerge(filter)) {\n    this.merge(filter);\n  }\n\n  options && this.setOptions(options);\n\n  return this;\n};\n\n/**\n * Execute a `findOneAndDelete()` query\n *\n * @return {Query} this\n * @method _findOneAndDelete\n * @memberOf Query\n * @api private\n */\nQuery.prototype._findOneAndDelete = async function _findOneAndDelete() {\n  this._applyTranslateAliases();\n  this._castConditions();\n\n  if (this.error() != null) {\n    throw this.error();\n  }\n\n  const includeResultMetadata = this.options.includeResultMetadata;\n\n  const filter = this._conditions;\n  const options = this._optionsForExec(this.model);\n\n  let res = await this.mongooseCollection.findOneAndDelete(filter, options);\n  for (const fn of this._transforms) {\n    res = fn(res);\n  }\n  const doc = !includeResultMetadata ? res : res.value;\n\n  return new Promise((resolve, reject) => {\n    this._completeOne(doc, res, (err, res) => {\n      if (err) {\n        return reject(err);\n      }\n      resolve(res);\n    });\n  });\n};\n\n/**\n * Issues a MongoDB [findOneAndReplace](https://www.mongodb.com/docs/manual/reference/method/db.collection.findOneAndReplace/) command.\n *\n * Finds a matching document, removes it, and returns the found document (if any).\n *\n * This function triggers the following middleware.\n *\n * - `findOneAndReplace()`\n *\n * #### Available options\n *\n * - `sort`: if multiple docs are found by the conditions, sets the sort order to choose which doc to update\n * - `maxTimeMS`: puts a time limit on the query - requires mongodb >= 2.6.0\n * - `includeResultMetadata`: if true, returns the full [ModifyResult from the MongoDB driver](https://mongodb.github.io/node-mongodb-native/4.9/interfaces/ModifyResult.html) rather than just the document\n *\n * #### Callback Signature\n *\n *     function(error, doc) {\n *       // error: any errors that occurred\n *       // doc: the document before updates are applied if `new: false`, or after updates if `new = true`\n *     }\n *\n * #### Example:\n *\n *     A.where().findOneAndReplace(filter, replacement, options); // return Query\n *     A.where().findOneAndReplace(filter); // returns Query\n *     A.where().findOneAndReplace(); // returns Query\n *\n * @method findOneAndReplace\n * @memberOf Query\n * @param {Object} [filter]\n * @param {Object} [replacement]\n * @param {Object} [options]\n * @param {Boolean} [options.includeResultMetadata] if true, returns the full [ModifyResult from the MongoDB driver](https://mongodb.github.io/node-mongodb-native/4.9/interfaces/ModifyResult.html) rather than just the document\n * @param {ClientSession} [options.session=null] The session associated with this query. See [transactions docs](https://mongoosejs.com/docs/transactions.html).\n * @param {Boolean|String} [options.strict] overwrites the schema's [strict mode option](https://mongoosejs.com/docs/guide.html#strict)\n * @param {Boolean} [options.new=false] By default, `findOneAndUpdate()` returns the document as it was **before** `update` was applied. If you set `new: true`, `findOneAndUpdate()` will instead give you the object after `update` was applied.\n * @param {Object} [options.lean] if truthy, mongoose will return the document as a plain JavaScript object rather than a mongoose document. See [`Query.lean()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.lean()) and [the Mongoose lean tutorial](https://mongoosejs.com/docs/tutorials/lean.html).\n * @param {ClientSession} [options.session=null] The session associated with this query. See [transactions docs](https://mongoosejs.com/docs/transactions.html).\n * @param {Boolean|String} [options.strict] overwrites the schema's [strict mode option](https://mongoosejs.com/docs/guide.html#strict)\n * @param {Boolean} [options.timestamps=null] If set to `false` and [schema-level timestamps](https://mongoosejs.com/docs/guide.html#timestamps) are enabled, skip timestamps for this update. Note that this allows you to overwrite timestamps. Does nothing if schema-level timestamps are not set.\n * @param {Boolean} [options.returnOriginal=null] An alias for the `new` option. `returnOriginal: false` is equivalent to `new: true`.\n * @param {Boolean} [options.translateAliases=null] If set to `true`, translates any schema-defined aliases in `filter`, `projection`, `update`, and `distinct`. Throws an error if there are any conflicts where both alias and raw property are defined on the same object.\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.findOneAndReplace = function(filter, replacement, options) {\n  if (typeof filter === 'function' ||\n      typeof replacement === 'function' ||\n      typeof options === 'function' ||\n      typeof arguments[4] === 'function') {\n    throw new MongooseError('Query.prototype.findOneAndReplace() no longer accepts a callback');\n  }\n\n  this.op = 'findOneAndReplace';\n  this._validateOp();\n  this._validate();\n\n  if (mquery.canMerge(filter)) {\n    this.merge(filter);\n  } else if (filter != null) {\n    this.error(\n      new ObjectParameterError(filter, 'filter', 'findOneAndReplace')\n    );\n  }\n\n  if (replacement != null) {\n    this._mergeUpdate(replacement);\n  }\n\n  options = options || {};\n\n  const returnOriginal = this &&\n  this.model &&\n  this.model.base &&\n  this.model.base.options &&\n  this.model.base.options.returnOriginal;\n  if (options.new == null && options.returnDocument == null && options.returnOriginal == null && returnOriginal != null) {\n    options.returnOriginal = returnOriginal;\n  }\n  this.setOptions(options);\n\n  return this;\n};\n\n/**\n * Execute a findOneAndReplace() query\n *\n * @return {Query} this\n * @method _findOneAndReplace\n * @instance\n * @memberOf Query\n * @api private\n */\nQuery.prototype._findOneAndReplace = async function _findOneAndReplace() {\n  this._applyTranslateAliases();\n  this._castConditions();\n  if (this.error() != null) {\n    throw this.error();\n  }\n\n  if ('strict' in this.options) {\n    this._mongooseOptions.strict = this.options.strict;\n    delete this.options.strict;\n  }\n\n  const filter = this._conditions;\n  const options = this._optionsForExec();\n  convertNewToReturnDocument(options);\n\n  const includeResultMetadata = this.options.includeResultMetadata;\n\n  const modelOpts = { skipId: true };\n  if ('strict' in this._mongooseOptions) {\n    modelOpts.strict = this._mongooseOptions.strict;\n  }\n\n  const runValidators = _getOption(this, 'runValidators', false);\n\n  try {\n    const update = new this.model(this._update, null, modelOpts);\n    if (runValidators) {\n      await update.validate();\n    } else if (update.$__.validationError) {\n      throw update.$__.validationError;\n    }\n    this._update = update.toBSON();\n  } catch (err) {\n    if (err instanceof ValidationError) {\n      throw err;\n    }\n    const validationError = new ValidationError();\n    validationError.errors[err.path] = err;\n    throw validationError;\n  }\n\n  let res = await this.mongooseCollection.findOneAndReplace(filter, this._update, options);\n\n  for (const fn of this._transforms) {\n    res = fn(res);\n  }\n\n  const doc = !includeResultMetadata ? res : res.value;\n  return new Promise((resolve, reject) => {\n    this._completeOne(doc, res, (err, res) => {\n      if (err) {\n        return reject(err);\n      }\n      resolve(res);\n    });\n  });\n};\n\n/**\n * Support the `new` option as an alternative to `returnOriginal` for backwards\n * compat.\n * @api private\n */\n\nfunction convertNewToReturnDocument(options) {\n  if ('new' in options) {\n    options.returnDocument = options['new'] ? 'after' : 'before';\n    delete options['new'];\n  }\n  if ('returnOriginal' in options) {\n    options.returnDocument = options['returnOriginal'] ? 'before' : 'after';\n    delete options['returnOriginal'];\n  }\n  // Temporary since driver 4.0.0-beta does not support `returnDocument`\n  if (typeof options.returnDocument === 'string') {\n    options.returnOriginal = options.returnDocument === 'before';\n  }\n}\n\n/**\n * Get options from query opts, falling back to the base mongoose object.\n * @param {Query} query\n * @param {Object} option\n * @param {Any} def\n * @api private\n */\n\nfunction _getOption(query, option, def) {\n  const opts = query._optionsForExec(query.model);\n\n  if (option in opts) {\n    return opts[option];\n  }\n  if (option in query.model.base.options) {\n    return query.model.base.options[option];\n  }\n  return def;\n}\n\n/*!\n * ignore\n */\n\nfunction _completeOneLean(schema, doc, path, res, opts, callback) {\n  if (opts.lean && typeof opts.lean.transform === 'function') {\n    opts.lean.transform(doc);\n\n    for (let i = 0; i < schema.childSchemas.length; i++) {\n      const childPath = path ? path + '.' + schema.childSchemas[i].model.path : schema.childSchemas[i].model.path;\n      const _schema = schema.childSchemas[i].schema;\n      const obj = mpath.get(childPath, doc);\n      if (obj == null) {\n        continue;\n      }\n      if (Array.isArray(obj)) {\n        for (let i = 0; i < obj.length; i++) {\n          opts.lean.transform(obj[i]);\n        }\n      } else {\n        opts.lean.transform(obj);\n      }\n      _completeOneLean(_schema, obj, childPath, res, opts);\n    }\n    if (callback) {\n      return callback(null, doc);\n    } else {\n      return;\n    }\n  }\n  if (opts.includeResultMetadata) {\n    return callback(null, res);\n  }\n  return callback(null, doc);\n}\n\n/*!\n * ignore\n */\n\nfunction _completeManyLean(schema, docs, path, opts) {\n  if (opts.lean && typeof opts.lean.transform === 'function') {\n    for (const doc of docs) {\n      opts.lean.transform(doc);\n    }\n\n    for (let i = 0; i < schema.childSchemas.length; i++) {\n      const childPath = path ? path + '.' + schema.childSchemas[i].model.path : schema.childSchemas[i].model.path;\n      const _schema = schema.childSchemas[i].schema;\n      let doc = mpath.get(childPath, docs);\n      if (doc == null) {\n        continue;\n      }\n      doc = doc.flat();\n      for (let i = 0; i < doc.length; i++) {\n        opts.lean.transform(doc[i]);\n      }\n      _completeManyLean(_schema, doc, childPath, opts);\n    }\n  }\n\n  return docs;\n}\n/**\n * Override mquery.prototype._mergeUpdate to handle mongoose objects in\n * updates.\n *\n * @param {Object} doc\n * @method _mergeUpdate\n * @memberOf Query\n * @instance\n * @api private\n */\n\nQuery.prototype._mergeUpdate = function(doc) {\n  if (!this._update) {\n    this._update = Array.isArray(doc) ? [] : {};\n  }\n\n  if (doc == null || (typeof doc === 'object' && Object.keys(doc).length === 0)) {\n    return;\n  }\n\n  if (doc instanceof Query) {\n    if (Array.isArray(this._update)) {\n      throw new Error('Cannot mix array and object updates');\n    }\n    if (doc._update) {\n      utils.mergeClone(this._update, doc._update);\n    }\n  } else if (Array.isArray(doc)) {\n    if (!Array.isArray(this._update)) {\n      throw new Error('Cannot mix array and object updates');\n    }\n    this._update = this._update.concat(doc);\n  } else {\n    if (Array.isArray(this._update)) {\n      throw new Error('Cannot mix array and object updates');\n    }\n    utils.mergeClone(this._update, doc);\n  }\n};\n\n/*!\n * ignore\n */\n\nasync function _updateThunk(op) {\n  this._applyTranslateAliases();\n\n  this._castConditions();\n\n  _castArrayFilters(this);\n\n  if (this.error() != null) {\n    throw this.error();\n  }\n\n  const castedQuery = this._conditions;\n  const options = this._optionsForExec(this.model);\n\n  this._update = clone(this._update, options);\n  const isOverwriting = op === 'replaceOne';\n  if (isOverwriting) {\n    this._update = new this.model(this._update, null, true);\n  } else {\n    this._update = this._castUpdate(this._update);\n\n    if (this._update == null || Object.keys(this._update).length === 0) {\n      return { acknowledged: false };\n    }\n\n    const _opts = Object.assign({}, options, {\n      setDefaultsOnInsert: this._mongooseOptions.setDefaultsOnInsert\n    });\n    this._update = setDefaultsOnInsert(this._conditions, this.model.schema,\n      this._update, _opts);\n  }\n\n  if (Array.isArray(options.arrayFilters)) {\n    options.arrayFilters = removeUnusedArrayFilters(this._update, options.arrayFilters);\n  }\n\n  const runValidators = _getOption(this, 'runValidators', false);\n  if (runValidators) {\n    await this.validate(this._update, options, isOverwriting);\n  }\n\n  if (this._update.toBSON) {\n    this._update = this._update.toBSON();\n  }\n\n  return this.mongooseCollection[op](castedQuery, this._update, options);\n}\n\n/**\n * Mongoose calls this function internally to validate the query if\n * `runValidators` is set\n *\n * @param {Object} castedDoc the update, after casting\n * @param {Object} options the options from `_optionsForExec()`\n * @param {Boolean} isOverwriting\n * @method validate\n * @memberOf Query\n * @instance\n * @api private\n */\n\nQuery.prototype.validate = async function validate(castedDoc, options, isOverwriting) {\n  if (typeof arguments[3] === 'function') {\n    throw new MongooseError('Query.prototype.validate() no longer accepts a callback');\n  }\n\n  await _executePreHooks(this, 'validate');\n\n  if (isOverwriting) {\n    await castedDoc.$validate();\n  } else {\n    await new Promise((resolve, reject) => {\n      updateValidators(this, this.model.schema, castedDoc, options, (err) => {\n        if (err != null) {\n          return reject(err);\n        }\n        resolve();\n      });\n    });\n  }\n\n  await _executePostHooks(this, null, null, 'validate');\n};\n\n/**\n * Execute an updateMany query\n *\n * @see Model.update https://mongoosejs.com/docs/api/model.html#Model.update()\n * @method _updateMany\n * @memberOf Query\n * @instance\n * @api private\n */\nQuery.prototype._updateMany = async function _updateMany() {\n  return _updateThunk.call(this, 'updateMany');\n};\n\n/**\n * Execute an updateOne query\n *\n * @see Model.update https://mongoosejs.com/docs/api/model.html#Model.update()\n * @method _updateOne\n * @memberOf Query\n * @instance\n * @api private\n */\nQuery.prototype._updateOne = async function _updateOne() {\n  return _updateThunk.call(this, 'updateOne');\n};\n\n/**\n * Execute a replaceOne query\n *\n * @see Model.replaceOne https://mongoosejs.com/docs/api/model.html#Model.replaceOne()\n * @method _replaceOne\n * @memberOf Query\n * @instance\n * @api private\n */\nQuery.prototype._replaceOne = async function _replaceOne() {\n  return _updateThunk.call(this, 'replaceOne');\n};\n\n/**\n * Declare and/or execute this query as an updateMany() operation.\n * MongoDB will update _all_ documents that match `filter` (as opposed to just the first one).\n *\n * **Note** updateMany will _not_ fire update middleware. Use `pre('updateMany')`\n * and `post('updateMany')` instead.\n *\n * #### Example:\n *\n *     const res = await Person.updateMany({ name: /Stark$/ }, { isDeleted: true });\n *     res.n; // Number of documents matched\n *     res.nModified; // Number of documents modified\n *\n * This function triggers the following middleware.\n *\n * - `updateMany()`\n *\n * @param {Object} [filter]\n * @param {Object|Array} [update] the update command. If array, this update will be treated as an update pipeline and not casted.\n * @param {Object} [options]\n * @param {Boolean} [options.multipleCastError] by default, mongoose only returns the first error that occurred in casting the query. Turn on this option to aggregate all the cast errors.\n * @param {Boolean|String} [options.strict] overwrites the schema's [strict mode option](https://mongoosejs.com/docs/guide.html#strict)\n * @param {Boolean} [options.upsert=false] if true, and no documents found, insert a new document\n * @param {Object} [options.writeConcern=null] sets the [write concern](https://www.mongodb.com/docs/manual/reference/write-concern/) for replica sets. Overrides the [schema-level write concern](https://mongoosejs.com/docs/guide.html#writeConcern)\n * @param {Boolean} [options.timestamps=null] If set to `false` and [schema-level timestamps](https://mongoosejs.com/docs/guide.html#timestamps) are enabled, skip timestamps for this update. Does nothing if schema-level timestamps are not set.\n * @param {Boolean} [options.translateAliases=null] If set to `true`, translates any schema-defined aliases in `filter`, `projection`, `update`, and `distinct`. Throws an error if there are any conflicts where both alias and raw property are defined on the same object.\n * @param {Boolean} [options.overwriteDiscriminatorKey=false] Mongoose removes discriminator key updates from `update` by default, set `overwriteDiscriminatorKey` to `true` to allow updating the discriminator key\n * @param {Function} [callback] params are (error, writeOpResult)\n * @return {Query} this\n * @see Model.update https://mongoosejs.com/docs/api/model.html#Model.update()\n * @see Query docs https://mongoosejs.com/docs/queries.html\n * @see update https://www.mongodb.com/docs/manual/reference/method/db.collection.update/\n * @see UpdateResult https://mongodb.github.io/node-mongodb-native/4.9/interfaces/UpdateResult.html\n * @see MongoDB docs https://www.mongodb.com/docs/manual/reference/command/update/#update-command-output\n * @api public\n */\n\nQuery.prototype.updateMany = function(conditions, doc, options, callback) {\n  if (typeof options === 'function') {\n    // .update(conditions, doc, callback)\n    callback = options;\n    options = null;\n  } else if (typeof doc === 'function') {\n    // .update(doc, callback);\n    callback = doc;\n    doc = conditions;\n    conditions = {};\n    options = null;\n  } else if (typeof conditions === 'function') {\n    // .update(callback)\n    callback = conditions;\n    conditions = undefined;\n    doc = undefined;\n    options = undefined;\n  } else if (typeof conditions === 'object' && !doc && !options && !callback) {\n    // .update(doc)\n    doc = conditions;\n    conditions = undefined;\n    options = undefined;\n    callback = undefined;\n  }\n\n  return _update(this, 'updateMany', conditions, doc, options, callback);\n};\n\n/**\n * Declare and/or execute this query as an updateOne() operation.\n * MongoDB will update _only_ the first document that matches `filter`.\n *\n * - Use `replaceOne()` if you want to overwrite an entire document rather than using [atomic operators](https://www.mongodb.com/docs/manual/tutorial/model-data-for-atomic-operations/#pattern) like `$set`.\n *\n * **Note** updateOne will _not_ fire update middleware. Use `pre('updateOne')`\n * and `post('updateOne')` instead.\n *\n * #### Example:\n *\n *     const res = await Person.updateOne({ name: 'Jean-Luc Picard' }, { ship: 'USS Enterprise' });\n *     res.acknowledged; // Indicates if this write result was acknowledged. If not, then all other members of this result will be undefined.\n *     res.matchedCount; // Number of documents that matched the filter\n *     res.modifiedCount; // Number of documents that were modified\n *     res.upsertedCount; // Number of documents that were upserted\n *     res.upsertedId; // Identifier of the inserted document (if an upsert took place)\n *\n * This function triggers the following middleware.\n *\n * - `updateOne()`\n *\n * @param {Object} [filter]\n * @param {Object|Array} [update] the update command. If array, this update will be treated as an update pipeline and not casted.\n * @param {Object} [options]\n * @param {Boolean} [options.multipleCastError] by default, mongoose only returns the first error that occurred in casting the query. Turn on this option to aggregate all the cast errors.\n * @param {Boolean|String} [options.strict] overwrites the schema's [strict mode option](https://mongoosejs.com/docs/guide.html#strict)\n * @param {Boolean} [options.upsert=false] if true, and no documents found, insert a new document\n * @param {Object} [options.writeConcern=null] sets the [write concern](https://www.mongodb.com/docs/manual/reference/write-concern/) for replica sets. Overrides the [schema-level write concern](https://mongoosejs.com/docs/guide.html#writeConcern)\n * @param {Boolean} [options.timestamps=null] If set to `false` and [schema-level timestamps](https://mongoosejs.com/docs/guide.html#timestamps) are enabled, skip timestamps for this update. Note that this allows you to overwrite timestamps. Does nothing if schema-level timestamps are not set.\n * @param {Boolean} [options.translateAliases=null] If set to `true`, translates any schema-defined aliases in `filter`, `projection`, `update`, and `distinct`. Throws an error if there are any conflicts where both alias and raw property are defined on the same object.\n * @param {Boolean} [options.overwriteDiscriminatorKey=false] Mongoose removes discriminator key updates from `update` by default, set `overwriteDiscriminatorKey` to `true` to allow updating the discriminator key\n * @param {Function} [callback] params are (error, writeOpResult)\n * @return {Query} this\n * @see Model.update https://mongoosejs.com/docs/api/model.html#Model.update()\n * @see Query docs https://mongoosejs.com/docs/queries.html\n * @see update https://www.mongodb.com/docs/manual/reference/method/db.collection.update/\n * @see UpdateResult https://mongodb.github.io/node-mongodb-native/4.9/interfaces/UpdateResult.html\n * @see MongoDB docs https://www.mongodb.com/docs/manual/reference/command/update/#update-command-output\n * @api public\n */\n\nQuery.prototype.updateOne = function(conditions, doc, options, callback) {\n  if (typeof options === 'function') {\n    // .update(conditions, doc, callback)\n    callback = options;\n    options = null;\n  } else if (typeof doc === 'function') {\n    // .update(doc, callback);\n    callback = doc;\n    doc = conditions;\n    conditions = {};\n    options = null;\n  } else if (typeof conditions === 'function') {\n    // .update(callback)\n    callback = conditions;\n    conditions = undefined;\n    doc = undefined;\n    options = undefined;\n  } else if (typeof conditions === 'object' && !doc && !options && !callback) {\n    // .update(doc)\n    doc = conditions;\n    conditions = undefined;\n    options = undefined;\n    callback = undefined;\n  }\n\n  return _update(this, 'updateOne', conditions, doc, options, callback);\n};\n\n/**\n * Declare and/or execute this query as a replaceOne() operation.\n * MongoDB will replace the existing document and will not accept any [atomic operators](https://www.mongodb.com/docs/manual/tutorial/model-data-for-atomic-operations/#pattern) (`$set`, etc.)\n *\n * **Note** replaceOne will _not_ fire update middleware. Use `pre('replaceOne')`\n * and `post('replaceOne')` instead.\n *\n * #### Example:\n *\n *     const res = await Person.replaceOne({ _id: 24601 }, { name: 'Jean Valjean' });\n *     res.acknowledged; // Indicates if this write result was acknowledged. If not, then all other members of this result will be undefined.\n *     res.matchedCount; // Number of documents that matched the filter\n *     res.modifiedCount; // Number of documents that were modified\n *     res.upsertedCount; // Number of documents that were upserted\n *     res.upsertedId; // Identifier of the inserted document (if an upsert took place)\n *\n * This function triggers the following middleware.\n *\n * - `replaceOne()`\n *\n * @param {Object} [filter]\n * @param {Object} [doc] the update command\n * @param {Object} [options]\n * @param {Boolean} [options.multipleCastError] by default, mongoose only returns the first error that occurred in casting the query. Turn on this option to aggregate all the cast errors.\n * @param {Boolean|String} [options.strict] overwrites the schema's [strict mode option](https://mongoosejs.com/docs/guide.html#strict)\n * @param {Boolean} [options.upsert=false] if true, and no documents found, insert a new document\n * @param {Object} [options.writeConcern=null] sets the [write concern](https://www.mongodb.com/docs/manual/reference/write-concern/) for replica sets. Overrides the [schema-level write concern](https://mongoosejs.com/docs/guide.html#writeConcern)\n * @param {Boolean} [options.timestamps=null] If set to `false` and [schema-level timestamps](https://mongoosejs.com/docs/guide.html#timestamps) are enabled, skip timestamps for this update. Does nothing if schema-level timestamps are not set.\n * @param {Boolean} [options.translateAliases=null] If set to `true`, translates any schema-defined aliases in `filter`, `projection`, `update`, and `distinct`. Throws an error if there are any conflicts where both alias and raw property are defined on the same object.\n * @param {Function} [callback] params are (error, writeOpResult)\n * @return {Query} this\n * @see Model.update https://mongoosejs.com/docs/api/model.html#Model.update()\n * @see Query docs https://mongoosejs.com/docs/queries.html\n * @see update https://www.mongodb.com/docs/manual/reference/method/db.collection.update/\n * @see UpdateResult https://mongodb.github.io/node-mongodb-native/4.9/interfaces/UpdateResult.html\n * @see MongoDB docs https://www.mongodb.com/docs/manual/reference/command/update/#update-command-output\n * @api public\n */\n\nQuery.prototype.replaceOne = function(conditions, doc, options, callback) {\n  if (typeof options === 'function') {\n    // .update(conditions, doc, callback)\n    callback = options;\n    options = null;\n  } else if (typeof doc === 'function') {\n    // .update(doc, callback);\n    callback = doc;\n    doc = conditions;\n    conditions = {};\n    options = null;\n  } else if (typeof conditions === 'function') {\n    // .update(callback)\n    callback = conditions;\n    conditions = undefined;\n    doc = undefined;\n    options = undefined;\n  } else if (typeof conditions === 'object' && !doc && !options && !callback) {\n    // .update(doc)\n    doc = conditions;\n    conditions = undefined;\n    options = undefined;\n    callback = undefined;\n  }\n\n  return _update(this, 'replaceOne', conditions, doc, options, callback);\n};\n\n/**\n * Internal helper for update, updateMany, updateOne, replaceOne\n * @param {Query} query\n * @param {String} op\n * @param {Object} filter\n * @param {Document} [doc]\n * @param {Object} [options]\n * @param {Function} callback\n * @api private\n */\n\nfunction _update(query, op, filter, doc, options, callback) {\n  // make sure we don't send in the whole Document to merge()\n  query.op = op;\n  query._validateOp();\n  doc = doc || {};\n\n  // strict is an option used in the update checking, make sure it gets set\n  if (options != null) {\n    if ('strict' in options) {\n      query._mongooseOptions.strict = options.strict;\n    }\n  }\n\n  if (!(filter instanceof Query) &&\n      filter != null &&\n      filter.toString() !== '[object Object]') {\n    query.error(new ObjectParameterError(filter, 'filter', op));\n  } else {\n    query.merge(filter);\n  }\n\n  if (utils.isObject(options)) {\n    query.setOptions(options);\n  }\n\n  query._mergeUpdate(doc);\n\n  // Hooks\n  if (callback) {\n    query.exec(callback);\n\n    return query;\n  }\n\n  return query;\n}\n\n/**\n * Runs a function `fn` and treats the return value of `fn` as the new value\n * for the query to resolve to.\n *\n * Any functions you pass to `transform()` will run **after** any post hooks.\n *\n * #### Example:\n *\n *     const res = await MyModel.findOne().transform(res => {\n *       // Sets a `loadedAt` property on the doc that tells you the time the\n *       // document was loaded.\n *       return res == null ?\n *         res :\n *         Object.assign(res, { loadedAt: new Date() });\n *     });\n *\n * @method transform\n * @memberOf Query\n * @instance\n * @param {Function} fn function to run to transform the query result\n * @return {Query} this\n */\n\nQuery.prototype.transform = function(fn) {\n  this._transforms.push(fn);\n  return this;\n};\n\n/**\n * Make this query throw an error if no documents match the given `filter`.\n * This is handy for integrating with async/await, because `orFail()` saves you\n * an extra `if` statement to check if no document was found.\n *\n * #### Example:\n *\n *     // Throws if no doc returned\n *     await Model.findOne({ foo: 'bar' }).orFail();\n *\n *     // Throws if no document was updated. Note that `orFail()` will still\n *     // throw if the only document that matches is `{ foo: 'bar', name: 'test' }`,\n *     // because `orFail()` will throw if no document was _updated_, not\n *     // if no document was _found_.\n *     await Model.updateOne({ foo: 'bar' }, { name: 'test' }).orFail();\n *\n *     // Throws \"No docs found!\" error if no docs match `{ foo: 'bar' }`\n *     await Model.find({ foo: 'bar' }).orFail(new Error('No docs found!'));\n *\n *     // Throws \"Not found\" error if no document was found\n *     await Model.findOneAndUpdate({ foo: 'bar' }, { name: 'test' }).\n *       orFail(() => Error('Not found'));\n *\n * @method orFail\n * @memberOf Query\n * @instance\n * @param {Function|Error} [err] optional error to throw if no docs match `filter`. If not specified, `orFail()` will throw a `DocumentNotFoundError`\n * @return {Query} this\n */\n\nQuery.prototype.orFail = function(err) {\n  this.transform(res => {\n    switch (this.op) {\n      case 'find':\n        if (res.length === 0) {\n          throw _orFailError(err, this);\n        }\n        break;\n      case 'findOne':\n        if (res == null) {\n          throw _orFailError(err, this);\n        }\n        break;\n      case 'replaceOne':\n      case 'updateMany':\n      case 'updateOne':\n        if (res && res.matchedCount === 0) {\n          throw _orFailError(err, this);\n        }\n        break;\n      case 'findOneAndDelete':\n      case 'findOneAndUpdate':\n      case 'findOneAndReplace':\n        if (this.options.includeResultMetadata && res != null && res.value == null) {\n          throw _orFailError(err, this);\n        }\n        if (!this.options.includeResultMetadata && res == null) {\n          throw _orFailError(err, this);\n        }\n        break;\n      case 'deleteMany':\n      case 'deleteOne':\n        if (res.deletedCount === 0) {\n          throw _orFailError(err, this);\n        }\n        break;\n      default:\n        break;\n    }\n\n    return res;\n  });\n  return this;\n};\n\n/**\n * Get the error to throw for `orFail()`\n * @param {Error|undefined} err\n * @param {Query} query\n * @api private\n */\n\nfunction _orFailError(err, query) {\n  if (typeof err === 'function') {\n    err = err.call(query);\n  }\n\n  if (err == null) {\n    err = new DocumentNotFoundError(query.getQuery(), query.model.modelName);\n  }\n\n  return err;\n}\n\n/**\n * Wrapper function to call isPathSelectedInclusive on a query.\n * @param {String} path\n * @return {Boolean}\n * @api public\n */\n\nQuery.prototype.isPathSelectedInclusive = function(path) {\n  return isPathSelectedInclusive(this._fields, path);\n};\n\n/**\n * Executes the query\n *\n * #### Example:\n *\n *     const promise = query.exec();\n *     const promise = query.exec('update');\n *\n * @param {String|Function} [operation]\n * @return {Promise}\n * @api public\n */\n\nQuery.prototype.exec = async function exec(op) {\n  if (typeof op === 'function' || (arguments.length >= 2 && typeof arguments[1] === 'function')) {\n    throw new MongooseError('Query.prototype.exec() no longer accepts a callback');\n  }\n\n  if (typeof op === 'string') {\n    this.op = op;\n  }\n\n  if (this.op == null) {\n    throw new MongooseError('Query must have `op` before executing');\n  }\n  if (this.model == null) {\n    throw new MongooseError('Query must have an associated model before executing');\n  }\n  this._validateOp();\n\n  if (!this.op) {\n    return;\n  }\n\n  if (this.options && this.options.sort) {\n    const keys = Object.keys(this.options.sort);\n    if (keys.includes('')) {\n      throw new Error('Invalid field \"\" passed to sort()');\n    }\n  }\n\n  let thunk = '_' + this.op;\n  if (this.op === 'distinct') {\n    thunk = '__distinct';\n  }\n\n  if (this._executionStack != null) {\n    let str = this.toString();\n    if (str.length > 60) {\n      str = str.slice(0, 60) + '...';\n    }\n    const err = new MongooseError('Query was already executed: ' + str);\n    err.originalStack = this._executionStack.stack;\n    throw err;\n  } else {\n    this._executionStack = new Error();\n  }\n\n  let skipWrappedFunction = null;\n  try {\n    await _executePreExecHooks(this);\n  } catch (err) {\n    if (err instanceof Kareem.skipWrappedFunction) {\n      skipWrappedFunction = err;\n    } else {\n      throw err;\n    }\n  }\n\n  let res;\n\n  let error = null;\n  try {\n    await _executePreHooks(this);\n    res = skipWrappedFunction ? skipWrappedFunction.args[0] : await this[thunk]();\n\n    for (const fn of this._transforms) {\n      res = fn(res);\n    }\n  } catch (err) {\n    if (err instanceof Kareem.skipWrappedFunction) {\n      res = err.args[0];\n    } else {\n      error = err;\n    }\n  }\n\n  res = await _executePostHooks(this, res, error);\n\n  await _executePostExecHooks(this);\n\n  return res;\n};\n\n/*!\n * ignore\n */\n\nfunction _executePostExecHooks(query) {\n  return new Promise((resolve, reject) => {\n    query._hooks.execPost('exec', query, [], {}, (error) => {\n      if (error) {\n        return reject(error);\n      }\n\n      resolve();\n    });\n  });\n}\n\n/*!\n * ignore\n */\n\nfunction _executePostHooks(query, res, error, op) {\n  if (query._queryMiddleware == null) {\n    if (error != null) {\n      throw error;\n    }\n    return res;\n  }\n\n  return new Promise((resolve, reject) => {\n    const opts = error ? { error } : {};\n\n    query._queryMiddleware.execPost(op || query.op, query, [res], opts, (error, res) => {\n      if (error) {\n        return reject(error);\n      }\n\n      resolve(res);\n    });\n  });\n}\n\n/*!\n * ignore\n */\n\nfunction _executePreExecHooks(query) {\n  return new Promise((resolve, reject) => {\n    query._hooks.execPre('exec', query, [], (error) => {\n      if (error != null) {\n        return reject(error);\n      }\n      resolve();\n    });\n  });\n}\n\n/*!\n * ignore\n */\n\nfunction _executePreHooks(query, op) {\n  if (query._queryMiddleware == null) {\n    return;\n  }\n\n  return new Promise((resolve, reject) => {\n    query._queryMiddleware.execPre(op || query.op, query, [], (error) => {\n      if (error != null) {\n        return reject(error);\n      }\n      resolve();\n    });\n  });\n}\n\n/**\n * Executes the query returning a `Promise` which will be\n * resolved with either the doc(s) or rejected with the error.\n *\n * More about [`then()` in JavaScript](https://masteringjs.io/tutorials/fundamentals/then).\n *\n * @param {Function} [resolve]\n * @param {Function} [reject]\n * @return {Promise}\n * @api public\n */\n\nQuery.prototype.then = function(resolve, reject) {\n  return this.exec().then(resolve, reject);\n};\n\n/**\n * Executes the query returning a `Promise` which will be\n * resolved with either the doc(s) or rejected with the error.\n * Like `.then()`, but only takes a rejection handler.\n *\n * More about [Promise `catch()` in JavaScript](https://masteringjs.io/tutorials/fundamentals/catch).\n *\n * @param {Function} [reject]\n * @return {Promise}\n * @api public\n */\n\nQuery.prototype.catch = function(reject) {\n  return this.exec().then(null, reject);\n};\n\n/**\n * Executes the query returning a `Promise` which will be\n * resolved with `.finally()` chained.\n *\n * More about [Promise `finally()` in JavaScript](https://thecodebarbarian.com/using-promise-finally-in-node-js.html).\n *\n * @param {Function} [onFinally]\n * @return {Promise}\n * @api public\n */\n\nQuery.prototype.finally = function(onFinally) {\n  return this.exec().finally(onFinally);\n};\n\n/**\n * Returns a string representation of this query.\n *\n * More about [`toString()` in JavaScript](https://masteringjs.io/tutorials/fundamentals/tostring).\n *\n * #### Example:\n *     const q = Model.find();\n *     console.log(q); // Prints \"Query { find }\"\n *\n * @return {String}\n * @api public\n * @method [Symbol.toStringTag]\n * @memberOf Query\n */\n\nQuery.prototype[Symbol.toStringTag] = function toString() {\n  return `Query { ${this.op} }`;\n};\n\n/**\n * Add pre [middleware](https://mongoosejs.com/docs/middleware.html) to this query instance. Doesn't affect\n * other queries.\n *\n * #### Example:\n *\n *     const q1 = Question.find({ answer: 42 });\n *     q1.pre(function middleware() {\n *       console.log(this.getFilter());\n *     });\n *     await q1.exec(); // Prints \"{ answer: 42 }\"\n *\n *     // Doesn't print anything, because `middleware()` is only\n *     // registered on `q1`.\n *     await Question.find({ answer: 42 });\n *\n * @param {Function} fn\n * @return {Promise}\n * @api public\n */\n\nQuery.prototype.pre = function(fn) {\n  this._hooks.pre('exec', fn);\n  return this;\n};\n\n/**\n * Add post [middleware](https://mongoosejs.com/docs/middleware.html) to this query instance. Doesn't affect\n * other queries.\n *\n * #### Example:\n *\n *     const q1 = Question.find({ answer: 42 });\n *     q1.post(function middleware() {\n *       console.log(this.getFilter());\n *     });\n *     await q1.exec(); // Prints \"{ answer: 42 }\"\n *\n *     // Doesn't print anything, because `middleware()` is only\n *     // registered on `q1`.\n *     await Question.find({ answer: 42 });\n *\n * @param {Function} fn\n * @return {Promise}\n * @api public\n */\n\nQuery.prototype.post = function(fn) {\n  this._hooks.post('exec', fn);\n  return this;\n};\n\n/**\n * Casts obj for an update command.\n *\n * @param {Object} obj\n * @return {Object} obj after casting its values\n * @method _castUpdate\n * @memberOf Query\n * @instance\n * @api private\n */\n\nQuery.prototype._castUpdate = function _castUpdate(obj) {\n  let schema = this.schema;\n\n  const discriminatorKey = schema.options.discriminatorKey;\n  const baseSchema = schema._baseSchema ? schema._baseSchema : schema;\n  if (this._mongooseOptions.overwriteDiscriminatorKey &&\n      obj[discriminatorKey] != null &&\n      baseSchema.discriminators) {\n    const _schema = Object.values(baseSchema.discriminators).find(\n      discriminator => discriminator.discriminatorMapping.value === obj[discriminatorKey]\n    );\n    if (_schema != null) {\n      schema = _schema;\n    }\n  }\n\n  let upsert;\n  if ('upsert' in this.options) {\n    upsert = this.options.upsert;\n  }\n\n  const filter = this._conditions;\n  if (schema != null &&\n      utils.hasUserDefinedProperty(filter, schema.options.discriminatorKey) &&\n      typeof filter[schema.options.discriminatorKey] !== 'object' &&\n      schema.discriminators != null) {\n    const discriminatorValue = filter[schema.options.discriminatorKey];\n    const byValue = getDiscriminatorByValue(this.model.discriminators, discriminatorValue);\n    schema = schema.discriminators[discriminatorValue] ||\n      (byValue && byValue.schema) ||\n      schema;\n  }\n\n  return castUpdate(schema, obj, {\n    strict: this._mongooseOptions.strict,\n    upsert: upsert,\n    arrayFilters: this.options.arrayFilters,\n    overwriteDiscriminatorKey: this._mongooseOptions.overwriteDiscriminatorKey\n  }, this, this._conditions);\n};\n\n/**\n * Specifies paths which should be populated with other documents.\n *\n * #### Example:\n *\n *     let book = await Book.findOne().populate('authors');\n *     book.title; // 'Node.js in Action'\n *     book.authors[0].name; // 'TJ Holowaychuk'\n *     book.authors[1].name; // 'Nathan Rajlich'\n *\n *     let books = await Book.find().populate({\n *       path: 'authors',\n *       // `match` and `sort` apply to the Author model,\n *       // not the Book model. These options do not affect\n *       // which documents are in `books`, just the order and\n *       // contents of each book document's `authors`.\n *       match: { name: new RegExp('.*h.*', 'i') },\n *       sort: { name: -1 }\n *     });\n *     books[0].title; // 'Node.js in Action'\n *     // Each book's `authors` are sorted by name, descending.\n *     books[0].authors[0].name; // 'TJ Holowaychuk'\n *     books[0].authors[1].name; // 'Marc Harter'\n *\n *     books[1].title; // 'Professional AngularJS'\n *     // Empty array, no authors' name has the letter 'h'\n *     books[1].authors; // []\n *\n * Paths are populated after the query executes and a response is received. A\n * separate query is then executed for each path specified for population. After\n * a response for each query has also been returned, the results are passed to\n * the callback.\n *\n * @param {Object|String|String[]} path either the path(s) to populate or an object specifying all parameters\n * @param {Object|String} [select] Field selection for the population query\n * @param {Model} [model] The model you wish to use for population. If not specified, populate will look up the model by the name in the Schema's `ref` field.\n * @param {Object} [match] Conditions for the population query\n * @param {Object} [options] Options for the population query (sort, etc)\n * @param {String} [options.path=null] The path to populate.\n * @param {boolean} [options.retainNullValues=false] by default, Mongoose removes null and undefined values from populated arrays. Use this option to make `populate()` retain `null` and `undefined` array entries.\n * @param {boolean} [options.getters=false] if true, Mongoose will call any getters defined on the `localField`. By default, Mongoose gets the raw value of `localField`. For example, you would need to set this option to `true` if you wanted to [add a `lowercase` getter to your `localField`](https://mongoosejs.com/docs/schematypes.html#schematype-options).\n * @param {boolean} [options.clone=false] When you do `BlogPost.find().populate('author')`, blog posts with the same author will share 1 copy of an `author` doc. Enable this option to make Mongoose clone populated docs before assigning them.\n * @param {Object|Function} [options.match=null] Add an additional filter to the populate query. Can be a filter object containing [MongoDB query syntax](https://www.mongodb.com/docs/manual/tutorial/query-documents/), or a function that returns a filter object.\n * @param {Function} [options.transform=null] Function that Mongoose will call on every populated document that allows you to transform the populated document.\n * @param {Object} [options.options=null] Additional options like `limit` and `lean`.\n * @see population https://mongoosejs.com/docs/populate.html\n * @see Query#select https://mongoosejs.com/docs/api/query.html#Query.prototype.select()\n * @see Model.populate https://mongoosejs.com/docs/api/model.html#Model.populate()\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.populate = function() {\n  // Bail when given no truthy arguments\n  if (!Array.from(arguments).some(Boolean)) {\n    return this;\n  }\n\n  const res = utils.populate.apply(null, arguments);\n\n  // Propagate readConcern and readPreference and lean from parent query,\n  // unless one already specified\n  if (this.options != null) {\n    const readConcern = this.options.readConcern;\n    const readPref = this.options.readPreference;\n\n    for (const populateOptions of res) {\n      if (readConcern != null && (populateOptions && populateOptions.options && populateOptions.options.readConcern) == null) {\n        populateOptions.options = populateOptions.options || {};\n        populateOptions.options.readConcern = readConcern;\n      }\n      if (readPref != null && (populateOptions && populateOptions.options && populateOptions.options.readPreference) == null) {\n        populateOptions.options = populateOptions.options || {};\n        populateOptions.options.readPreference = readPref;\n      }\n    }\n  }\n\n  const opts = this._mongooseOptions;\n\n  if (opts.lean != null) {\n    const lean = opts.lean;\n    for (const populateOptions of res) {\n      if ((populateOptions && populateOptions.options && populateOptions.options.lean) == null) {\n        populateOptions.options = populateOptions.options || {};\n        populateOptions.options.lean = lean;\n      }\n    }\n  }\n\n  if (!utils.isObject(opts.populate)) {\n    opts.populate = {};\n  }\n\n  const pop = opts.populate;\n\n  for (const populateOptions of res) {\n    const path = populateOptions.path;\n    if (pop[path] && pop[path].populate && populateOptions.populate) {\n      populateOptions.populate = pop[path].populate.concat(populateOptions.populate);\n    }\n\n    pop[populateOptions.path] = populateOptions;\n  }\n  return this;\n};\n\n/**\n * Gets a list of paths to be populated by this query\n *\n * #### Example:\n *\n *      bookSchema.pre('findOne', function() {\n *        let keys = this.getPopulatedPaths(); // ['author']\n *      });\n *      ...\n *      Book.findOne({}).populate('author');\n *\n * #### Example:\n *\n *      // Deep populate\n *      const q = L1.find().populate({\n *        path: 'level2',\n *        populate: { path: 'level3' }\n *      });\n *      q.getPopulatedPaths(); // ['level2', 'level2.level3']\n *\n * @return {Array} an array of strings representing populated paths\n * @api public\n */\n\nQuery.prototype.getPopulatedPaths = function getPopulatedPaths() {\n  const obj = this._mongooseOptions.populate || {};\n  const ret = Object.keys(obj);\n  for (const path of Object.keys(obj)) {\n    const pop = obj[path];\n    if (!Array.isArray(pop.populate)) {\n      continue;\n    }\n    _getPopulatedPaths(ret, pop.populate, path + '.');\n  }\n  return ret;\n};\n\n/*!\n * ignore\n */\n\nfunction _getPopulatedPaths(list, arr, prefix) {\n  for (const pop of arr) {\n    list.push(prefix + pop.path);\n    if (!Array.isArray(pop.populate)) {\n      continue;\n    }\n    _getPopulatedPaths(list, pop.populate, prefix + pop.path + '.');\n  }\n}\n\n/**\n * Casts this query to the schema of `model`\n *\n * #### Note:\n *\n * If `obj` is present, it is cast instead of this query.\n *\n * @param {Model} [model] the model to cast to. If not set, defaults to `this.model`\n * @param {Object} [obj]\n * @return {Object}\n * @api public\n */\n\nQuery.prototype.cast = function(model, obj) {\n  obj || (obj = this._conditions);\n  model = model || this.model;\n  const discriminatorKey = model.schema.options.discriminatorKey;\n  if (obj != null &&\n      obj.hasOwnProperty(discriminatorKey)) {\n    model = getDiscriminatorByValue(model.discriminators, obj[discriminatorKey]) || model;\n  }\n\n  const opts = { upsert: this.options && this.options.upsert };\n  if (this.options) {\n    if ('strict' in this.options) {\n      opts.strict = this.options.strict;\n    }\n    if ('strictQuery' in this.options) {\n      opts.strictQuery = this.options.strictQuery;\n    }\n  }\n\n  try {\n    return cast(model.schema, obj, opts, this);\n  } catch (err) {\n    // CastError, assign model\n    if (typeof err.setModel === 'function') {\n      err.setModel(model);\n    }\n    throw err;\n  }\n};\n\n/**\n * Casts selected field arguments for field selection with mongo 2.2\n *\n *     query.select({ ids: { $elemMatch: { $in: [hexString] }})\n *\n * @param {Object} fields\n * @see https://github.com/Automattic/mongoose/issues/1091\n * @see https://www.mongodb.com/docs/manual/reference/projection/elemMatch/\n * @api private\n */\n\nQuery.prototype._castFields = function _castFields(fields) {\n  let selected,\n      elemMatchKeys,\n      keys,\n      key,\n      out;\n\n  if (fields) {\n    keys = Object.keys(fields);\n    elemMatchKeys = [];\n\n    // collect $elemMatch args\n    for (let i = 0; i < keys.length; ++i) {\n      key = keys[i];\n      if (fields[key].$elemMatch) {\n        selected || (selected = {});\n        selected[key] = fields[key];\n        elemMatchKeys.push(key);\n      }\n    }\n  }\n\n  if (selected) {\n    // they passed $elemMatch, cast em\n    try {\n      out = this.cast(this.model, selected);\n    } catch (err) {\n      return err;\n    }\n\n    // apply the casted field args\n    for (let i = 0; i < elemMatchKeys.length; ++i) {\n      key = elemMatchKeys[i];\n      fields[key] = out[key];\n    }\n  }\n\n  return fields;\n};\n\n/**\n * Applies schematype selected options to this query.\n * @api private\n */\n\nQuery.prototype._applyPaths = function applyPaths() {\n  if (!this.model) {\n    return;\n  }\n  this._fields = this._fields || {};\n\n  let sanitizeProjection = undefined;\n  if (this.model != null && utils.hasUserDefinedProperty(this.model.db.options, 'sanitizeProjection')) {\n    sanitizeProjection = this.model.db.options.sanitizeProjection;\n  } else if (this.model != null && utils.hasUserDefinedProperty(this.model.base.options, 'sanitizeProjection')) {\n    sanitizeProjection = this.model.base.options.sanitizeProjection;\n  } else {\n    sanitizeProjection = this._mongooseOptions.sanitizeProjection;\n  }\n\n  helpers.applyPaths(this._fields, this.model.schema, sanitizeProjection);\n\n  let _selectPopulatedPaths = true;\n\n  if ('selectPopulatedPaths' in this.model.base.options) {\n    _selectPopulatedPaths = this.model.base.options.selectPopulatedPaths;\n  }\n  if ('selectPopulatedPaths' in this.model.schema.options) {\n    _selectPopulatedPaths = this.model.schema.options.selectPopulatedPaths;\n  }\n\n  if (_selectPopulatedPaths) {\n    selectPopulatedFields(this._fields, this._userProvidedFields, this._mongooseOptions.populate);\n  }\n};\n\n/**\n * Returns a wrapper around a [mongodb driver cursor](https://mongodb.github.io/node-mongodb-native/4.9/classes/FindCursor.html).\n * A QueryCursor exposes a Streams3 interface, as well as a `.next()` function.\n *\n * The `.cursor()` function triggers pre find hooks, but **not** post find hooks.\n *\n * #### Example:\n *\n *     // There are 2 ways to use a cursor. First, as a stream:\n *     Thing.\n *       find({ name: /^hello/ }).\n *       cursor().\n *       on('data', function(doc) { console.log(doc); }).\n *       on('end', function() { console.log('Done!'); });\n *\n *     // Or you can use `.next()` to manually get the next doc in the stream.\n *     // `.next()` returns a promise, so you can use promises or callbacks.\n *     const cursor = Thing.find({ name: /^hello/ }).cursor();\n *     cursor.next(function(error, doc) {\n *       console.log(doc);\n *     });\n *\n *     // Because `.next()` returns a promise, you can use co\n *     // to easily iterate through all documents without loading them\n *     // all into memory.\n *     const cursor = Thing.find({ name: /^hello/ }).cursor();\n *     for (let doc = await cursor.next(); doc != null; doc = await cursor.next()) {\n *       console.log(doc);\n *     }\n *\n * #### Valid options\n *\n *   - `transform`: optional function which accepts a mongoose document. The return value of the function will be emitted on `data` and returned by `.next()`.\n *\n * @return {QueryCursor}\n * @param {Object} [options]\n * @see QueryCursor https://mongoosejs.com/docs/api/querycursor.html\n * @api public\n */\n\nQuery.prototype.cursor = function cursor(opts) {\n  if (opts) {\n    this.setOptions(opts);\n  }\n\n  try {\n    this.cast(this.model);\n  } catch (err) {\n    return (new QueryCursor(this))._markError(err);\n  }\n\n  return new QueryCursor(this);\n};\n\n// the rest of these are basically to support older Mongoose syntax with mquery\n\n/**\n * Sets the tailable option (for use with capped collections).\n *\n * #### Example:\n *\n *     query.tailable(); // true\n *     query.tailable(true);\n *     query.tailable(false);\n *\n *     // Set both `tailable` and `awaitData` options\n *     query.tailable({ awaitData: true });\n *\n * #### Note:\n *\n * Cannot be used with `distinct()`\n *\n * @param {Boolean} bool defaults to true\n * @param {Object} [opts] options to set\n * @param {Boolean} [opts.awaitData] false by default. Set to true to keep the cursor open even if there's no data.\n * @param {Number} [opts.maxAwaitTimeMS] the maximum amount of time for the server to wait on new documents to satisfy a tailable cursor query. Requires `tailable` and `awaitData` to be true\n * @see tailable https://www.mongodb.com/docs/manual/tutorial/create-tailable-cursor/\n * @api public\n */\n\nQuery.prototype.tailable = function(val, opts) {\n  // we need to support the tailable({ awaitData : true }) as well as the\n  // tailable(true, {awaitData :true}) syntax that mquery does not support\n  if (val != null && typeof val.constructor === 'function' && val.constructor.name === 'Object') {\n    opts = val;\n    val = true;\n  }\n\n  if (val === undefined) {\n    val = true;\n  }\n\n  if (opts && typeof opts === 'object') {\n    for (const key of Object.keys(opts)) {\n      if (key === 'awaitData' || key === 'awaitdata') { // backwards compat, see gh-10875\n        // For backwards compatibility\n        this.options['awaitData'] = !!opts[key];\n      } else {\n        this.options[key] = opts[key];\n      }\n    }\n  }\n\n  this.options.tailable = arguments.length ? !!val : true;\n\n  return this;\n};\n\n/**\n * Declares an intersects query for `geometry()`.\n *\n * #### Example:\n *\n *     query.where('path').intersects().geometry({\n *       type: 'LineString',\n *       coordinates: [[180.0, 11.0], [180, 9.0]]\n *     });\n *\n *     query.where('path').intersects({\n *       type: 'LineString',\n *       coordinates: [[180.0, 11.0], [180, 9.0]]\n *     });\n *\n * #### Note:\n *\n * **MUST** be used after `where()`.\n *\n * #### Note:\n *\n * In Mongoose 3.7, `intersects` changed from a getter to a function. If you need the old syntax, use [this](https://github.com/ebensing/mongoose-within).\n *\n * @method intersects\n * @memberOf Query\n * @instance\n * @param {Object} [arg]\n * @return {Query} this\n * @see $geometry https://www.mongodb.com/docs/manual/reference/operator/geometry/\n * @see geoIntersects https://www.mongodb.com/docs/manual/reference/operator/geoIntersects/\n * @api public\n */\n\n/**\n * Specifies a `$geometry` condition\n *\n * #### Example:\n *\n *     const polyA = [[[ 10, 20 ], [ 10, 40 ], [ 30, 40 ], [ 30, 20 ]]]\n *     query.where('loc').within().geometry({ type: 'Polygon', coordinates: polyA })\n *\n *     // or\n *     const polyB = [[ 0, 0 ], [ 1, 1 ]]\n *     query.where('loc').within().geometry({ type: 'LineString', coordinates: polyB })\n *\n *     // or\n *     const polyC = [ 0, 0 ]\n *     query.where('loc').within().geometry({ type: 'Point', coordinates: polyC })\n *\n *     // or\n *     query.where('loc').intersects().geometry({ type: 'Point', coordinates: polyC })\n *\n * The argument is assigned to the most recent path passed to `where()`.\n *\n * #### Note:\n *\n * `geometry()` **must** come after either `intersects()` or `within()`.\n *\n * The `object` argument must contain `type` and `coordinates` properties.\n * - type {String}\n * - coordinates {Array}\n *\n * @method geometry\n * @memberOf Query\n * @instance\n * @param {Object} object Must contain a `type` property which is a String and a `coordinates` property which is an Array. See the examples.\n * @return {Query} this\n * @see $geometry https://www.mongodb.com/docs/manual/reference/operator/geometry/\n * @see Geospatial Support Enhancements https://www.mongodb.com/docs/manual/release-notes/2.4/#geospatial-support-enhancements\n * @see MongoDB Geospatial Indexing https://www.mongodb.com/docs/manual/core/geospatial-indexes/\n * @api public\n */\n\n/**\n * Specifies a `$near` or `$nearSphere` condition\n *\n * These operators return documents sorted by distance.\n *\n * #### Example:\n *\n *     query.where('loc').near({ center: [10, 10] });\n *     query.where('loc').near({ center: [10, 10], maxDistance: 5 });\n *     query.where('loc').near({ center: [10, 10], maxDistance: 5, spherical: true });\n *     query.near('loc', { center: [10, 10], maxDistance: 5 });\n *\n * @method near\n * @memberOf Query\n * @instance\n * @param {String} [path]\n * @param {Object} val\n * @return {Query} this\n * @see $near https://www.mongodb.com/docs/manual/reference/operator/near/\n * @see $nearSphere https://www.mongodb.com/docs/manual/reference/operator/nearSphere/\n * @see $maxDistance https://www.mongodb.com/docs/manual/reference/operator/maxDistance/\n * @see MongoDB Geospatial Indexing https://www.mongodb.com/docs/manual/core/geospatial-indexes/\n * @api public\n */\n\n/**\n * Overwriting mquery is needed to support a couple different near() forms found in older\n * versions of mongoose\n * near([1,1])\n * near(1,1)\n * near(field, [1,2])\n * near(field, 1, 2)\n * In addition to all of the normal forms supported by mquery\n *\n * @method near\n * @memberOf Query\n * @instance\n * @api private\n */\n\nQuery.prototype.near = function() {\n  const params = [];\n  const sphere = this._mongooseOptions.nearSphere;\n\n  // TODO refactor\n\n  if (arguments.length === 1) {\n    if (Array.isArray(arguments[0])) {\n      params.push({ center: arguments[0], spherical: sphere });\n    } else if (typeof arguments[0] === 'string') {\n      // just passing a path\n      params.push(arguments[0]);\n    } else if (utils.isObject(arguments[0])) {\n      if (typeof arguments[0].spherical !== 'boolean') {\n        arguments[0].spherical = sphere;\n      }\n      params.push(arguments[0]);\n    } else {\n      throw new TypeError('invalid argument');\n    }\n  } else if (arguments.length === 2) {\n    if (typeof arguments[0] === 'number' && typeof arguments[1] === 'number') {\n      params.push({ center: [arguments[0], arguments[1]], spherical: sphere });\n    } else if (typeof arguments[0] === 'string' && Array.isArray(arguments[1])) {\n      params.push(arguments[0]);\n      params.push({ center: arguments[1], spherical: sphere });\n    } else if (typeof arguments[0] === 'string' && utils.isObject(arguments[1])) {\n      params.push(arguments[0]);\n      if (typeof arguments[1].spherical !== 'boolean') {\n        arguments[1].spherical = sphere;\n      }\n      params.push(arguments[1]);\n    } else {\n      throw new TypeError('invalid argument');\n    }\n  } else if (arguments.length === 3) {\n    if (typeof arguments[0] === 'string' && typeof arguments[1] === 'number'\n        && typeof arguments[2] === 'number') {\n      params.push(arguments[0]);\n      params.push({ center: [arguments[1], arguments[2]], spherical: sphere });\n    } else {\n      throw new TypeError('invalid argument');\n    }\n  } else {\n    throw new TypeError('invalid argument');\n  }\n\n  return Query.base.near.apply(this, params);\n};\n\n/**\n * _DEPRECATED_ Specifies a `$nearSphere` condition\n *\n * #### Example:\n *\n *     query.where('loc').nearSphere({ center: [10, 10], maxDistance: 5 });\n *\n * **Deprecated.** Use `query.near()` instead with the `spherical` option set to `true`.\n *\n * #### Example:\n *\n *     query.where('loc').near({ center: [10, 10], spherical: true });\n *\n * @deprecated\n * @see near() https://mongoosejs.com/docs/api/query.html#Query.prototype.near()\n * @see $near https://www.mongodb.com/docs/manual/reference/operator/near/\n * @see $nearSphere https://www.mongodb.com/docs/manual/reference/operator/nearSphere/\n * @see $maxDistance https://www.mongodb.com/docs/manual/reference/operator/maxDistance/\n */\n\nQuery.prototype.nearSphere = function() {\n  this._mongooseOptions.nearSphere = true;\n  this.near.apply(this, arguments);\n  return this;\n};\n\n/**\n * Returns an asyncIterator for use with [`for/await/of` loops](https://thecodebarbarian.com/getting-started-with-async-iterators-in-node-js)\n * This function *only* works for `find()` queries.\n * You do not need to call this function explicitly, the JavaScript runtime\n * will call it for you.\n *\n * #### Example:\n *\n *     for await (const doc of Model.aggregate([{ $sort: { name: 1 } }])) {\n *       console.log(doc.name);\n *     }\n *\n * Node.js 10.x supports async iterators natively without any flags. You can\n * enable async iterators in Node.js 8.x using the [`--harmony_async_iteration` flag](https://github.com/tc39/proposal-async-iteration/issues/117#issuecomment-346695187).\n *\n * **Note:** This function is not if `Symbol.asyncIterator` is undefined. If\n * `Symbol.asyncIterator` is undefined, that means your Node.js version does not\n * support async iterators.\n *\n * @method [Symbol.asyncIterator]\n * @memberOf Query\n * @instance\n * @api public\n */\n\nif (Symbol.asyncIterator != null) {\n  Query.prototype[Symbol.asyncIterator] = function() {\n    return this.cursor().transformNull()._transformForAsyncIterator();\n  };\n}\n\n/**\n * Specifies a `$polygon` condition\n *\n * #### Example:\n *\n *     query.where('loc').within().polygon([10, 20], [13, 25], [7, 15]);\n *     query.polygon('loc', [10, 20], [13, 25], [7, 15]);\n *\n * @method polygon\n * @memberOf Query\n * @instance\n * @param {String|Array} [path]\n * @param {...Array|Object} [coordinatePairs]\n * @return {Query} this\n * @see $polygon https://www.mongodb.com/docs/manual/reference/operator/polygon/\n * @see MongoDB Geospatial Indexing https://www.mongodb.com/docs/manual/core/geospatial-indexes/\n * @api public\n */\n\n/**\n * Specifies a `$box` condition\n *\n * #### Example:\n *\n *     const lowerLeft = [40.73083, -73.99756]\n *     const upperRight= [40.741404,  -73.988135]\n *\n *     query.where('loc').within().box(lowerLeft, upperRight)\n *     query.box({ ll : lowerLeft, ur : upperRight })\n *\n * @method box\n * @memberOf Query\n * @instance\n * @see $box https://www.mongodb.com/docs/manual/reference/operator/box/\n * @see within() Query#within https://mongoosejs.com/docs/api/query.html#Query.prototype.within()\n * @see MongoDB Geospatial Indexing https://www.mongodb.com/docs/manual/core/geospatial-indexes/\n * @param {Object|Array<Number>} val1 Lower Left Coordinates OR a object of lower-left(ll) and upper-right(ur) Coordinates\n * @param {Array<Number>} [val2] Upper Right Coordinates\n * @return {Query} this\n * @api public\n */\n\n/**\n * this is needed to support the mongoose syntax of:\n * box(field, { ll : [x,y], ur : [x2,y2] })\n * box({ ll : [x,y], ur : [x2,y2] })\n *\n * @method box\n * @memberOf Query\n * @instance\n * @api private\n */\n\nQuery.prototype.box = function(ll, ur) {\n  if (!Array.isArray(ll) && utils.isObject(ll)) {\n    ur = ll.ur;\n    ll = ll.ll;\n  }\n  return Query.base.box.call(this, ll, ur);\n};\n\n/**\n * Specifies a `$center` or `$centerSphere` condition.\n *\n * #### Example:\n *\n *     const area = { center: [50, 50], radius: 10, unique: true }\n *     query.where('loc').within().circle(area)\n *     // alternatively\n *     query.circle('loc', area);\n *\n *     // spherical calculations\n *     const area = { center: [50, 50], radius: 10, unique: true, spherical: true }\n *     query.where('loc').within().circle(area)\n *     // alternatively\n *     query.circle('loc', area);\n *\n * @method circle\n * @memberOf Query\n * @instance\n * @param {String} [path]\n * @param {Object} area\n * @return {Query} this\n * @see $center https://www.mongodb.com/docs/manual/reference/operator/center/\n * @see $centerSphere https://www.mongodb.com/docs/manual/reference/operator/centerSphere/\n * @see $geoWithin https://www.mongodb.com/docs/manual/reference/operator/geoWithin/\n * @see MongoDB Geospatial Indexing https://www.mongodb.com/docs/manual/core/geospatial-indexes/\n * @api public\n */\n\n/**\n * _DEPRECATED_ Alias for [circle](https://mongoosejs.com/docs/api/query.html#Query.prototype.circle())\n *\n * **Deprecated.** Use [circle](https://mongoosejs.com/docs/api/query.html#Query.prototype.circle()) instead.\n *\n * @deprecated\n * @method center\n * @memberOf Query\n * @instance\n * @api public\n */\n\nQuery.prototype.center = Query.base.circle;\n\n/**\n * _DEPRECATED_ Specifies a `$centerSphere` condition\n *\n * **Deprecated.** Use [circle](https://mongoosejs.com/docs/api/query.html#Query.prototype.circle()) instead.\n *\n * #### Example:\n *\n *     const area = { center: [50, 50], radius: 10 };\n *     query.where('loc').within().centerSphere(area);\n *\n * @deprecated\n * @param {String} [path]\n * @param {Object} val\n * @return {Query} this\n * @see MongoDB Geospatial Indexing https://www.mongodb.com/docs/manual/core/geospatial-indexes/\n * @see $centerSphere https://www.mongodb.com/docs/manual/reference/operator/centerSphere/\n * @api public\n */\n\nQuery.prototype.centerSphere = function() {\n  if (arguments[0] != null && typeof arguments[0].constructor === 'function' && arguments[0].constructor.name === 'Object') {\n    arguments[0].spherical = true;\n  }\n\n  if (arguments[1] != null && typeof arguments[1].constructor === 'function' && arguments[1].constructor.name === 'Object') {\n    arguments[1].spherical = true;\n  }\n\n  Query.base.circle.apply(this, arguments);\n};\n\n/**\n * Determines if field selection has been made.\n *\n * @method selected\n * @memberOf Query\n * @instance\n * @return {Boolean}\n * @api public\n */\n\n/**\n * Determines if inclusive field selection has been made.\n *\n *     query.selectedInclusively(); // false\n *     query.select('name');\n *     query.selectedInclusively(); // true\n *\n * @method selectedInclusively\n * @memberOf Query\n * @instance\n * @return {Boolean}\n * @api public\n */\n\nQuery.prototype.selectedInclusively = function selectedInclusively() {\n  return isInclusive(this._fields);\n};\n\n/**\n * Determines if exclusive field selection has been made.\n *\n *     query.selectedExclusively(); // false\n *     query.select('-name');\n *     query.selectedExclusively(); // true\n *     query.selectedInclusively(); // false\n *\n * @method selectedExclusively\n * @memberOf Query\n * @instance\n * @return {Boolean}\n * @api public\n */\n\nQuery.prototype.selectedExclusively = function selectedExclusively() {\n  return isExclusive(this._fields);\n};\n\n/**\n * The model this query is associated with.\n *\n * #### Example:\n *\n *     const q = MyModel.find();\n *     q.model === MyModel; // true\n *\n * @api public\n * @property model\n * @memberOf Query\n * @instance\n */\n\nQuery.prototype.model;\n\n/*!\n * Export\n */\n\nmodule.exports = Query;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/query.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/queryHelpers.js":
/*!***************************************************!*\
  !*** ./node_modules/mongoose/lib/queryHelpers.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies\n */\n\nconst checkEmbeddedDiscriminatorKeyProjection =\n  __webpack_require__(/*! ./helpers/discriminator/checkEmbeddedDiscriminatorKeyProjection */ \"./node_modules/mongoose/lib/helpers/discriminator/checkEmbeddedDiscriminatorKeyProjection.js\");\nconst get = __webpack_require__(/*! ./helpers/get */ \"./node_modules/mongoose/lib/helpers/get.js\");\nconst getDiscriminatorByValue =\n  __webpack_require__(/*! ./helpers/discriminator/getDiscriminatorByValue */ \"./node_modules/mongoose/lib/helpers/discriminator/getDiscriminatorByValue.js\");\nconst isDefiningProjection = __webpack_require__(/*! ./helpers/projection/isDefiningProjection */ \"./node_modules/mongoose/lib/helpers/projection/isDefiningProjection.js\");\nconst clone = __webpack_require__(/*! ./helpers/clone */ \"./node_modules/mongoose/lib/helpers/clone.js\");\nconst isPathSelectedInclusive = __webpack_require__(/*! ./helpers/projection/isPathSelectedInclusive */ \"./node_modules/mongoose/lib/helpers/projection/isPathSelectedInclusive.js\");\n\n/**\n * Prepare a set of path options for query population.\n *\n * @param {Query} query\n * @param {Object} options\n * @return {Array}\n */\n\nexports.preparePopulationOptions = function preparePopulationOptions(query, options) {\n  const _populate = query.options.populate;\n  const pop = Object.keys(_populate).reduce((vals, key) => vals.concat([_populate[key]]), []);\n\n  // lean options should trickle through all queries\n  if (options.lean != null) {\n    pop\n      .filter(p => (p && p.options && p.options.lean) == null)\n      .forEach(makeLean(options.lean));\n  }\n\n  pop.forEach(opts => {\n    opts._localModel = query.model;\n  });\n\n  return pop;\n};\n\n/**\n * Prepare a set of path options for query population. This is the MongooseQuery\n * version\n *\n * @param {Query} query\n * @param {Object} options\n * @return {Array}\n */\n\nexports.preparePopulationOptionsMQ = function preparePopulationOptionsMQ(query, options) {\n  const _populate = query._mongooseOptions.populate;\n  const pop = Object.keys(_populate).reduce((vals, key) => vals.concat([_populate[key]]), []);\n\n  // lean options should trickle through all queries\n  if (options.lean != null) {\n    pop\n      .filter(p => (p && p.options && p.options.lean) == null)\n      .forEach(makeLean(options.lean));\n  }\n\n  const session = query && query.options && query.options.session || null;\n  if (session != null) {\n    pop.forEach(path => {\n      if (path.options == null) {\n        path.options = { session: session };\n        return;\n      }\n      if (!('session' in path.options)) {\n        path.options.session = session;\n      }\n    });\n  }\n\n  const projection = query._fieldsForExec();\n  pop.forEach(p => {\n    p._queryProjection = projection;\n  });\n  pop.forEach(opts => {\n    opts._localModel = query.model;\n  });\n\n  return pop;\n};\n\n/**\n * If the document is a mapped discriminator type, it returns a model instance for that type, otherwise,\n * it returns an instance of the given model.\n *\n * @param {Model}  model\n * @param {Object} doc\n * @param {Object} fields\n *\n * @return {Document}\n */\nexports.createModel = function createModel(model, doc, fields, userProvidedFields, options) {\n  model.hooks.execPreSync('createModel', doc);\n  const discriminatorMapping = model.schema ?\n    model.schema.discriminatorMapping :\n    null;\n\n  const key = discriminatorMapping && discriminatorMapping.isRoot ?\n    discriminatorMapping.key :\n    null;\n\n  const value = doc[key];\n  if (key && value && model.discriminators) {\n    const discriminator = model.discriminators[value] || getDiscriminatorByValue(model.discriminators, value);\n    if (discriminator) {\n      const _fields = clone(userProvidedFields);\n      exports.applyPaths(_fields, discriminator.schema);\n      return new discriminator(undefined, _fields, true);\n    }\n  }\n\n  const _opts = {\n    skipId: true,\n    isNew: false,\n    willInit: true\n  };\n  if (options != null && 'defaults' in options) {\n    _opts.defaults = options.defaults;\n  }\n  return new model(undefined, fields, _opts);\n};\n\n/*!\n * ignore\n */\n\nexports.createModelAndInit = function createModelAndInit(model, doc, fields, userProvidedFields, options, populatedIds, callback) {\n  const initOpts = populatedIds ?\n    { populated: populatedIds } :\n    undefined;\n\n  const casted = exports.createModel(model, doc, fields, userProvidedFields, options);\n  try {\n    casted.$init(doc, initOpts, callback);\n  } catch (error) {\n    callback(error, casted);\n  }\n};\n\n/*!\n * ignore\n */\n\nexports.applyPaths = function applyPaths(fields, schema, sanitizeProjection) {\n  // determine if query is selecting or excluding fields\n  let exclude;\n  let keys;\n  const minusPathsToSkip = new Set();\n\n  if (fields) {\n    keys = Object.keys(fields);\n\n    // Collapse minus paths\n    const minusPaths = [];\n    for (let i = 0; i < keys.length; ++i) {\n      const key = keys[i];\n      if (keys[i][0] !== '-') {\n        continue;\n      }\n\n      delete fields[key];\n      if (key === '-_id') {\n        fields['_id'] = 0;\n      } else {\n        minusPaths.push(key.slice(1));\n      }\n    }\n\n    keys = Object.keys(fields);\n    for (let keyIndex = 0; keyIndex < keys.length; ++keyIndex) {\n      if (keys[keyIndex][0] === '+') {\n        continue;\n      }\n      const field = fields[keys[keyIndex]];\n      // Skip `$meta` and `$slice`\n      if (!isDefiningProjection(field)) {\n        continue;\n      }\n      if (keys[keyIndex] === '_id' && keys.length > 1) {\n        continue;\n      }\n      if (keys[keyIndex] === schema.options.discriminatorKey && keys.length > 1 && field != null && !field) {\n        continue;\n      }\n      exclude = !field;\n      break;\n    }\n\n    // Potentially add back minus paths based on schema-level path config\n    // and whether the projection is inclusive\n    for (const path of minusPaths) {\n      const type = schema.path(path);\n      // If the path isn't selected by default or the projection is not\n      // inclusive, minus path is treated as equivalent to `key: 0`.\n      // But we also allow using `-name` to remove `name` from an inclusive\n      // projection if `name` has schema-level `select: true`.\n      if ((!type || !type.selected) || exclude !== false) {\n        fields[path] = 0;\n        exclude = true;\n      } else if (type && type.selected && exclude === false) {\n        // Make a note of minus paths that are overwriting paths that are\n        // included by default.\n        minusPathsToSkip.add(path);\n      }\n    }\n  }\n\n  // if selecting, apply default schematype select:true fields\n  // if excluding, apply schematype select:false fields\n  const selected = [];\n  const excluded = [];\n  const stack = [];\n\n  analyzeSchema(schema);\n  switch (exclude) {\n    case true:\n      for (const fieldName of excluded) {\n        fields[fieldName] = 0;\n      }\n      break;\n    case false:\n      if (schema &&\n          schema.paths['_id'] &&\n          schema.paths['_id'].options &&\n          schema.paths['_id'].options.select === false) {\n        fields._id = 0;\n      }\n\n      for (const fieldName of selected) {\n        if (minusPathsToSkip.has(fieldName)) {\n          continue;\n        }\n        if (isPathSelectedInclusive(fields, fieldName)) {\n          continue;\n        }\n        fields[fieldName] = fields[fieldName] || 1;\n      }\n      break;\n    case undefined:\n      if (fields == null) {\n        break;\n      }\n      // Any leftover plus paths must in the schema, so delete them (gh-7017)\n      for (const key of Object.keys(fields || {})) {\n        if (key.startsWith('+')) {\n          delete fields[key];\n        }\n      }\n\n      // user didn't specify fields, implies returning all fields.\n      // only need to apply excluded fields and delete any plus paths\n      for (const fieldName of excluded) {\n        if (fields[fieldName] != null) {\n          // Skip applying default projections to fields with non-defining\n          // projections, like `$slice`\n          continue;\n        }\n        fields[fieldName] = 0;\n      }\n      break;\n  }\n\n  function analyzeSchema(schema, prefix) {\n    prefix || (prefix = '');\n\n    // avoid recursion\n    if (stack.indexOf(schema) !== -1) {\n      return [];\n    }\n    stack.push(schema);\n\n    const addedPaths = [];\n    schema.eachPath(function(path, type) {\n      if (prefix) path = prefix + '.' + path;\n      if (type.$isSchemaMap || path.endsWith('.$*')) {\n        const plusPath = '+' + path;\n        const hasPlusPath = fields && plusPath in fields;\n        if (type.options && type.options.select === false && !hasPlusPath) {\n          excluded.push(path);\n        }\n        return;\n      }\n      let addedPath = analyzePath(path, type);\n      // arrays\n      if (addedPath == null && !Array.isArray(type) && type.$isMongooseArray && !type.$isMongooseDocumentArray) {\n        addedPath = analyzePath(path, type.caster);\n      }\n      if (addedPath != null) {\n        addedPaths.push(addedPath);\n      }\n\n      // nested schemas\n      if (type.schema) {\n        const _addedPaths = analyzeSchema(type.schema, path);\n\n        // Special case: if discriminator key is the only field that would\n        // be projected in, remove it.\n        if (exclude === false) {\n          checkEmbeddedDiscriminatorKeyProjection(fields, path, type.schema,\n            selected, _addedPaths);\n        }\n      }\n    });\n    stack.pop();\n    return addedPaths;\n  }\n\n  function analyzePath(path, type) {\n    if (fields == null) {\n      return;\n    }\n\n    // If schema-level selected not set, nothing to do\n    if (typeof type.selected !== 'boolean') {\n      return;\n    }\n\n    // User overwriting default exclusion\n    if (type.selected === false && fields[path]) {\n      if (sanitizeProjection) {\n        fields[path] = 0;\n      }\n\n      return;\n    }\n\n    // If set to 0, we're explicitly excluding the discriminator key. Can't do this for all fields,\n    // because we have tests that assert that using `-path` to exclude schema-level `select: true`\n    // fields counts as an exclusive projection. See gh-11546\n    if (!exclude && type.selected && path === schema.options.discriminatorKey && fields[path] != null && !fields[path]) {\n      delete fields[path];\n      return;\n    }\n\n    if (exclude === false && type.selected && fields[path] != null && !fields[path]) {\n      delete fields[path];\n      return;\n    }\n\n    const plusPath = '+' + path;\n    const hasPlusPath = fields && plusPath in fields;\n    if (hasPlusPath) {\n      // forced inclusion\n      delete fields[plusPath];\n\n      // if there are other fields being included, add this one\n      // if no other included fields, leave this out (implied inclusion)\n      if (exclude === false && keys.length > 1 && !~keys.indexOf(path) && !sanitizeProjection) {\n        fields[path] = 1;\n      } else if (exclude == null && sanitizeProjection && type.selected === false) {\n        fields[path] = 0;\n      }\n\n      return;\n    }\n\n    // check for parent exclusions\n    const pieces = path.split('.');\n    let cur = '';\n    for (let i = 0; i < pieces.length; ++i) {\n      cur += cur.length ? '.' + pieces[i] : pieces[i];\n      if (excluded.indexOf(cur) !== -1) {\n        return;\n      }\n    }\n\n    // Special case: if user has included a parent path of a discriminator key,\n    // don't explicitly project in the discriminator key because that will\n    // project out everything else under the parent path\n    if (!exclude && (type && type.options && type.options.$skipDiscriminatorCheck || false)) {\n      let cur = '';\n      for (let i = 0; i < pieces.length; ++i) {\n        cur += (cur.length === 0 ? '' : '.') + pieces[i];\n        const projection = get(fields, cur, false) || get(fields, cur + '.$', false);\n        if (projection && typeof projection !== 'object') {\n          return;\n        }\n      }\n    }\n\n    (type.selected ? selected : excluded).push(path);\n    return path;\n  }\n};\n\n/**\n * Set each path query option to lean\n *\n * @param {Object} option\n */\n\nfunction makeLean(val) {\n  return function(option) {\n    option.options || (option.options = {});\n\n    if (val != null && Array.isArray(val.virtuals)) {\n      val = Object.assign({}, val);\n      val.virtuals = val.virtuals.\n        filter(path => typeof path === 'string' && path.startsWith(option.path + '.')).\n        map(path => path.slice(option.path.length + 1));\n    }\n\n    option.options.lean = val;\n  };\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/queryHelpers.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schema.js":
/*!*********************************************!*\
  !*** ./node_modules/mongoose/lib/schema.js ***!
  \*********************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst EventEmitter = (__webpack_require__(/*! events */ \"events\").EventEmitter);\nconst Kareem = __webpack_require__(/*! kareem */ \"./node_modules/kareem/index.js\");\nconst MongooseError = __webpack_require__(/*! ./error/mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\nconst SchemaType = __webpack_require__(/*! ./schemaType */ \"./node_modules/mongoose/lib/schemaType.js\");\nconst SchemaTypeOptions = __webpack_require__(/*! ./options/schemaTypeOptions */ \"./node_modules/mongoose/lib/options/schemaTypeOptions.js\");\nconst VirtualOptions = __webpack_require__(/*! ./options/virtualOptions */ \"./node_modules/mongoose/lib/options/virtualOptions.js\");\nconst VirtualType = __webpack_require__(/*! ./virtualType */ \"./node_modules/mongoose/lib/virtualType.js\");\nconst addAutoId = __webpack_require__(/*! ./helpers/schema/addAutoId */ \"./node_modules/mongoose/lib/helpers/schema/addAutoId.js\");\nconst clone = __webpack_require__(/*! ./helpers/clone */ \"./node_modules/mongoose/lib/helpers/clone.js\");\nconst get = __webpack_require__(/*! ./helpers/get */ \"./node_modules/mongoose/lib/helpers/get.js\");\nconst getConstructorName = __webpack_require__(/*! ./helpers/getConstructorName */ \"./node_modules/mongoose/lib/helpers/getConstructorName.js\");\nconst getIndexes = __webpack_require__(/*! ./helpers/schema/getIndexes */ \"./node_modules/mongoose/lib/helpers/schema/getIndexes.js\");\nconst handleReadPreferenceAliases = __webpack_require__(/*! ./helpers/query/handleReadPreferenceAliases */ \"./node_modules/mongoose/lib/helpers/query/handleReadPreferenceAliases.js\");\nconst idGetter = __webpack_require__(/*! ./helpers/schema/idGetter */ \"./node_modules/mongoose/lib/helpers/schema/idGetter.js\");\nconst merge = __webpack_require__(/*! ./helpers/schema/merge */ \"./node_modules/mongoose/lib/helpers/schema/merge.js\");\nconst mpath = __webpack_require__(/*! mpath */ \"./node_modules/mpath/index.js\");\nconst setPopulatedVirtualValue = __webpack_require__(/*! ./helpers/populate/setPopulatedVirtualValue */ \"./node_modules/mongoose/lib/helpers/populate/setPopulatedVirtualValue.js\");\nconst setupTimestamps = __webpack_require__(/*! ./helpers/timestamps/setupTimestamps */ \"./node_modules/mongoose/lib/helpers/timestamps/setupTimestamps.js\");\nconst utils = __webpack_require__(/*! ./utils */ \"./node_modules/mongoose/lib/utils.js\");\nconst validateRef = __webpack_require__(/*! ./helpers/populate/validateRef */ \"./node_modules/mongoose/lib/helpers/populate/validateRef.js\");\nconst util = __webpack_require__(/*! util */ \"util\");\n\nconst hasNumericSubpathRegex = /\\.\\d+(\\.|$)/;\n\nlet MongooseTypes;\n\nconst queryHooks = (__webpack_require__(/*! ./constants */ \"./node_modules/mongoose/lib/constants.js\").queryMiddlewareFunctions);\nconst documentHooks = (__webpack_require__(/*! ./helpers/model/applyHooks */ \"./node_modules/mongoose/lib/helpers/model/applyHooks.js\").middlewareFunctions);\nconst hookNames = queryHooks.concat(documentHooks).\n  reduce((s, hook) => s.add(hook), new Set());\n\nconst isPOJO = utils.isPOJO;\n\nlet id = 0;\n\nconst numberRE = /^\\d+$/;\n\n/**\n * Schema constructor.\n *\n * #### Example:\n *\n *     const child = new Schema({ name: String });\n *     const schema = new Schema({ name: String, age: Number, children: [child] });\n *     const Tree = mongoose.model('Tree', schema);\n *\n *     // setting schema options\n *     new Schema({ name: String }, { id: false, autoIndex: false })\n *\n * #### Options:\n *\n * - [autoIndex](https://mongoosejs.com/docs/guide.html#autoIndex): bool - defaults to null (which means use the connection's autoIndex option)\n * - [autoCreate](https://mongoosejs.com/docs/guide.html#autoCreate): bool - defaults to null (which means use the connection's autoCreate option)\n * - [bufferCommands](https://mongoosejs.com/docs/guide.html#bufferCommands): bool - defaults to true\n * - [bufferTimeoutMS](https://mongoosejs.com/docs/guide.html#bufferTimeoutMS): number - defaults to 10000 (10 seconds). If `bufferCommands` is enabled, the amount of time Mongoose will wait for connectivity to be restablished before erroring out.\n * - [capped](https://mongoosejs.com/docs/guide.html#capped): bool | number | object - defaults to false\n * - [collection](https://mongoosejs.com/docs/guide.html#collection): string - no default\n * - [discriminatorKey](https://mongoosejs.com/docs/guide.html#discriminatorKey): string - defaults to `__t`\n * - [id](https://mongoosejs.com/docs/guide.html#id): bool - defaults to true\n * - [_id](https://mongoosejs.com/docs/guide.html#_id): bool - defaults to true\n * - [minimize](https://mongoosejs.com/docs/guide.html#minimize): bool - controls [document#toObject](https://mongoosejs.com/docs/api/document.html#Document.prototype.toObject()) behavior when called manually - defaults to true\n * - [read](https://mongoosejs.com/docs/guide.html#read): string\n * - [readConcern](https://mongoosejs.com/docs/guide.html#readConcern): object - defaults to null, use to set a default [read concern](https://www.mongodb.com/docs/manual/reference/read-concern/) for all queries.\n * - [writeConcern](https://mongoosejs.com/docs/guide.html#writeConcern): object - defaults to null, use to override [the MongoDB server's default write concern settings](https://www.mongodb.com/docs/manual/reference/write-concern/)\n * - [shardKey](https://mongoosejs.com/docs/guide.html#shardKey): object - defaults to `null`\n * - [strict](https://mongoosejs.com/docs/guide.html#strict): bool - defaults to true\n * - [strictQuery](https://mongoosejs.com/docs/guide.html#strictQuery): bool - defaults to false\n * - [toJSON](https://mongoosejs.com/docs/guide.html#toJSON) - object - no default\n * - [toObject](https://mongoosejs.com/docs/guide.html#toObject) - object - no default\n * - [typeKey](https://mongoosejs.com/docs/guide.html#typeKey) - string - defaults to 'type'\n * - [validateBeforeSave](https://mongoosejs.com/docs/guide.html#validateBeforeSave) - bool - defaults to `true`\n * - [validateModifiedOnly](https://mongoosejs.com/docs/api/document.html#Document.prototype.validate()) - bool - defaults to `false`\n * - [versionKey](https://mongoosejs.com/docs/guide.html#versionKey): string or object - defaults to \"__v\"\n * - [optimisticConcurrency](https://mongoosejs.com/docs/guide.html#optimisticConcurrency): bool - defaults to false. Set to true to enable [optimistic concurrency](https://thecodebarbarian.com/whats-new-in-mongoose-5-10-optimistic-concurrency.html).\n * - [collation](https://mongoosejs.com/docs/guide.html#collation): object - defaults to null (which means use no collation)\n * - [timeseries](https://mongoosejs.com/docs/guide.html#timeseries): object - defaults to null (which means this schema's collection won't be a timeseries collection)\n * - [selectPopulatedPaths](https://mongoosejs.com/docs/guide.html#selectPopulatedPaths): boolean - defaults to `true`\n * - [skipVersioning](https://mongoosejs.com/docs/guide.html#skipVersioning): object - paths to exclude from versioning\n * - [timestamps](https://mongoosejs.com/docs/guide.html#timestamps): object or boolean - defaults to `false`. If true, Mongoose adds `createdAt` and `updatedAt` properties to your schema and manages those properties for you.\n * - [pluginTags](https://mongoosejs.com/docs/guide.html#pluginTags): array of strings - defaults to `undefined`. If set and plugin called with `tags` option, will only apply that plugin to schemas with a matching tag.\n * - [virtuals](https://mongoosejs.com/docs/tutorials/virtuals.html#virtuals-via-schema-options): object - virtuals to define, alias for [`.virtual`](https://mongoosejs.com/docs/api/schema.html#Schema.prototype.virtual())\n * - [collectionOptions]: object with options passed to [`createCollection()`](https://www.mongodb.com/docs/manual/reference/method/db.createCollection/) when calling `Model.createCollection()` or `autoCreate` set to true.\n *\n * #### Options for Nested Schemas:\n *\n * - `excludeIndexes`: bool - defaults to `false`. If `true`, skip building indexes on this schema's paths.\n *\n * #### Note:\n *\n * _When nesting schemas, (`children` in the example above), always declare the child schema first before passing it into its parent._\n *\n * @param {Object|Schema|Array} [definition] Can be one of: object describing schema paths, or schema to copy, or array of objects and schemas\n * @param {Object} [options]\n * @inherits NodeJS EventEmitter https://nodejs.org/api/events.html#class-eventemitter\n * @event `init`: Emitted after the schema is compiled into a `Model`.\n * @api public\n */\n\nfunction Schema(obj, options) {\n  if (!(this instanceof Schema)) {\n    return new Schema(obj, options);\n  }\n\n  this.obj = obj;\n  this.paths = {};\n  this.aliases = {};\n  this.subpaths = {};\n  this.virtuals = {};\n  this.singleNestedPaths = {};\n  this.nested = {};\n  this.inherits = {};\n  this.callQueue = [];\n  this._indexes = [];\n  this._searchIndexes = [];\n  this.methods = (options && options.methods) || {};\n  this.methodOptions = {};\n  this.statics = (options && options.statics) || {};\n  this.tree = {};\n  this.query = (options && options.query) || {};\n  this.childSchemas = [];\n  this.plugins = [];\n  // For internal debugging. Do not use this to try to save a schema in MDB.\n  this.$id = ++id;\n  this.mapPaths = [];\n\n  this.s = {\n    hooks: new Kareem()\n  };\n  this.options = this.defaultOptions(options);\n\n  // build paths\n  if (Array.isArray(obj)) {\n    for (const definition of obj) {\n      this.add(definition);\n    }\n  } else if (obj) {\n    this.add(obj);\n  }\n\n  // build virtual paths\n  if (options && options.virtuals) {\n    const virtuals = options.virtuals;\n    const pathNames = Object.keys(virtuals);\n    for (const pathName of pathNames) {\n      const pathOptions = virtuals[pathName].options ? virtuals[pathName].options : undefined;\n      const virtual = this.virtual(pathName, pathOptions);\n\n      if (virtuals[pathName].get) {\n        virtual.get(virtuals[pathName].get);\n      }\n\n      if (virtuals[pathName].set) {\n        virtual.set(virtuals[pathName].set);\n      }\n    }\n  }\n\n  // check if _id's value is a subdocument (gh-2276)\n  const _idSubDoc = obj && obj._id && utils.isObject(obj._id);\n\n  // ensure the documents get an auto _id unless disabled\n  const auto_id = !this.paths['_id'] &&\n      (this.options._id) && !_idSubDoc;\n\n  if (auto_id) {\n    addAutoId(this);\n  }\n\n  this.setupTimestamp(this.options.timestamps);\n}\n\n/**\n * Create virtual properties with alias field\n * @api private\n */\nfunction aliasFields(schema, paths) {\n  for (const path of Object.keys(paths)) {\n    let alias = null;\n    if (paths[path] != null) {\n      alias = paths[path];\n    } else {\n      const options = get(schema.paths[path], 'options');\n      if (options == null) {\n        continue;\n      }\n\n      alias = options.alias;\n    }\n\n    if (!alias) {\n      continue;\n    }\n\n    const prop = schema.paths[path].path;\n    if (Array.isArray(alias)) {\n      for (const a of alias) {\n        if (typeof a !== 'string') {\n          throw new Error('Invalid value for alias option on ' + prop + ', got ' + a);\n        }\n\n        schema.aliases[a] = prop;\n\n        schema.\n          virtual(a).\n          get((function(p) {\n            return function() {\n              if (typeof this.get === 'function') {\n                return this.get(p);\n              }\n              return this[p];\n            };\n          })(prop)).\n          set((function(p) {\n            return function(v) {\n              return this.$set(p, v);\n            };\n          })(prop));\n      }\n\n      continue;\n    }\n\n    if (typeof alias !== 'string') {\n      throw new Error('Invalid value for alias option on ' + prop + ', got ' + alias);\n    }\n\n    schema.aliases[alias] = prop;\n\n    schema.\n      virtual(alias).\n      get((function(p) {\n        return function() {\n          if (typeof this.get === 'function') {\n            return this.get(p);\n          }\n          return this[p];\n        };\n      })(prop)).\n      set((function(p) {\n        return function(v) {\n          return this.$set(p, v);\n        };\n      })(prop));\n  }\n}\n\n/*!\n * Inherit from EventEmitter.\n */\nSchema.prototype = Object.create(EventEmitter.prototype);\nSchema.prototype.constructor = Schema;\nSchema.prototype.instanceOfSchema = true;\n\n/*!\n * ignore\n */\n\nObject.defineProperty(Schema.prototype, '$schemaType', {\n  configurable: false,\n  enumerable: false,\n  writable: true\n});\n\n/**\n * Array of child schemas (from document arrays and single nested subdocs)\n * and their corresponding compiled models. Each element of the array is\n * an object with 2 properties: `schema` and `model`.\n *\n * This property is typically only useful for plugin authors and advanced users.\n * You do not need to interact with this property at all to use mongoose.\n *\n * @api public\n * @property childSchemas\n * @memberOf Schema\n * @instance\n */\n\nObject.defineProperty(Schema.prototype, 'childSchemas', {\n  configurable: false,\n  enumerable: true,\n  writable: true\n});\n\n/**\n * Object containing all virtuals defined on this schema.\n * The objects' keys are the virtual paths and values are instances of `VirtualType`.\n *\n * This property is typically only useful for plugin authors and advanced users.\n * You do not need to interact with this property at all to use mongoose.\n *\n * #### Example:\n *\n *     const schema = new Schema({});\n *     schema.virtual('answer').get(() => 42);\n *\n *     console.log(schema.virtuals); // { answer: VirtualType { path: 'answer', ... } }\n *     console.log(schema.virtuals['answer'].getters[0].call()); // 42\n *\n * @api public\n * @property virtuals\n * @memberOf Schema\n * @instance\n */\n\nObject.defineProperty(Schema.prototype, 'virtuals', {\n  configurable: false,\n  enumerable: true,\n  writable: true\n});\n\n/**\n * The original object passed to the schema constructor\n *\n * #### Example:\n *\n *     const schema = new Schema({ a: String }).add({ b: String });\n *     schema.obj; // { a: String }\n *\n * @api public\n * @property obj\n * @memberOf Schema\n * @instance\n */\n\nSchema.prototype.obj;\n\n/**\n * The paths defined on this schema. The keys are the top-level paths\n * in this schema, and the values are instances of the SchemaType class.\n *\n * #### Example:\n *\n *     const schema = new Schema({ name: String }, { _id: false });\n *     schema.paths; // { name: SchemaString { ... } }\n *\n *     schema.add({ age: Number });\n *     schema.paths; // { name: SchemaString { ... }, age: SchemaNumber { ... } }\n *\n * @api public\n * @property paths\n * @memberOf Schema\n * @instance\n */\n\nSchema.prototype.paths;\n\n/**\n * Schema as a tree\n *\n * #### Example:\n *\n *     {\n *         '_id'     : ObjectId\n *       , 'nested'  : {\n *             'key' : String\n *         }\n *     }\n *\n * @api private\n * @property tree\n * @memberOf Schema\n * @instance\n */\n\nSchema.prototype.tree;\n\n/**\n * Returns a deep copy of the schema\n *\n * #### Example:\n *\n *     const schema = new Schema({ name: String });\n *     const clone = schema.clone();\n *     clone === schema; // false\n *     clone.path('name'); // SchemaString { ... }\n *\n * @return {Schema} the cloned schema\n * @api public\n * @memberOf Schema\n * @instance\n */\n\nSchema.prototype.clone = function() {\n  const s = this._clone();\n\n  // Bubble up `init` for backwards compat\n  s.on('init', v => this.emit('init', v));\n\n  return s;\n};\n\n/*!\n * ignore\n */\n\nSchema.prototype._clone = function _clone(Constructor) {\n  Constructor = Constructor || (this.base == null ? Schema : this.base.Schema);\n\n  const s = new Constructor({}, this._userProvidedOptions);\n  s.base = this.base;\n  s.obj = this.obj;\n  s.options = clone(this.options);\n  s.callQueue = this.callQueue.map(function(f) { return f; });\n  s.methods = clone(this.methods);\n  s.methodOptions = clone(this.methodOptions);\n  s.statics = clone(this.statics);\n  s.query = clone(this.query);\n  s.plugins = Array.prototype.slice.call(this.plugins);\n  s._indexes = clone(this._indexes);\n  s._searchIndexes = clone(this._searchIndexes);\n  s.s.hooks = this.s.hooks.clone();\n\n  s.tree = clone(this.tree);\n  s.paths = Object.fromEntries(\n    Object.entries(this.paths).map(([key, value]) => ([key, value.clone()]))\n  );\n  s.nested = clone(this.nested);\n  s.subpaths = clone(this.subpaths);\n  for (const schemaType of Object.values(s.paths)) {\n    if (schemaType.$isSingleNested) {\n      const path = schemaType.path;\n      for (const key of Object.keys(schemaType.schema.paths)) {\n        s.singleNestedPaths[path + '.' + key] = schemaType.schema.paths[key];\n      }\n      for (const key of Object.keys(schemaType.schema.singleNestedPaths)) {\n        s.singleNestedPaths[path + '.' + key] =\n          schemaType.schema.singleNestedPaths[key];\n      }\n      for (const key of Object.keys(schemaType.schema.subpaths)) {\n        s.singleNestedPaths[path + '.' + key] =\n          schemaType.schema.subpaths[key];\n      }\n      for (const key of Object.keys(schemaType.schema.nested)) {\n        s.singleNestedPaths[path + '.' + key] = 'nested';\n      }\n    }\n  }\n  s.childSchemas = gatherChildSchemas(s);\n\n  s.virtuals = clone(this.virtuals);\n  s.$globalPluginsApplied = this.$globalPluginsApplied;\n  s.$isRootDiscriminator = this.$isRootDiscriminator;\n  s.$implicitlyCreated = this.$implicitlyCreated;\n  s.$id = ++id;\n  s.$originalSchemaId = this.$id;\n  s.mapPaths = [].concat(this.mapPaths);\n\n  if (this.discriminatorMapping != null) {\n    s.discriminatorMapping = Object.assign({}, this.discriminatorMapping);\n  }\n  if (this.discriminators != null) {\n    s.discriminators = Object.assign({}, this.discriminators);\n  }\n  if (this._applyDiscriminators != null) {\n    s._applyDiscriminators = new Map(this._applyDiscriminators);\n  }\n\n  s.aliases = Object.assign({}, this.aliases);\n\n  return s;\n};\n\n/**\n * Returns a new schema that has the picked `paths` from this schema.\n *\n * This method is analagous to [Lodash's `pick()` function](https://lodash.com/docs/4.17.15#pick) for Mongoose schemas.\n *\n * #### Example:\n *\n *     const schema = Schema({ name: String, age: Number });\n *     // Creates a new schema with the same `name` path as `schema`,\n *     // but no `age` path.\n *     const newSchema = schema.pick(['name']);\n *\n *     newSchema.path('name'); // SchemaString { ... }\n *     newSchema.path('age'); // undefined\n *\n * @param {String[]} paths List of Paths to pick for the new Schema\n * @param {Object} [options] Options to pass to the new Schema Constructor (same as `new Schema(.., Options)`). Defaults to `this.options` if not set.\n * @return {Schema}\n * @api public\n */\n\nSchema.prototype.pick = function(paths, options) {\n  const newSchema = new Schema({}, options || this.options);\n  if (!Array.isArray(paths)) {\n    throw new MongooseError('Schema#pick() only accepts an array argument, ' +\n      'got \"' + typeof paths + '\"');\n  }\n\n  for (const path of paths) {\n    if (this.nested[path]) {\n      newSchema.add({ [path]: get(this.tree, path) });\n    } else {\n      const schematype = this.path(path);\n      if (schematype == null) {\n        throw new MongooseError('Path `' + path + '` is not in the schema');\n      }\n      newSchema.add({ [path]: schematype });\n    }\n  }\n\n  return newSchema;\n};\n\n/**\n * Returns a new schema that has the `paths` from the original schema, minus the omitted ones.\n *\n * This method is analagous to [Lodash's `omit()` function](https://lodash.com/docs/#omit) for Mongoose schemas.\n *\n * #### Example:\n *\n *     const schema = Schema({ name: String, age: Number });\n *     // Creates a new schema omitting the `age` path\n *     const newSchema = schema.omit(['age']);\n *\n *     newSchema.path('name'); // SchemaString { ... }\n *     newSchema.path('age'); // undefined\n *\n * @param {String[]} paths List of Paths to omit for the new Schema\n * @param {Object} [options] Options to pass to the new Schema Constructor (same as `new Schema(.., Options)`). Defaults to `this.options` if not set.\n * @return {Schema}\n * @api public\n */\n\nSchema.prototype.omit = function(paths, options) {\n  const newSchema = new Schema(this, options || this.options);\n  if (!Array.isArray(paths)) {\n    throw new MongooseError(\n      'Schema#omit() only accepts an array argument, ' +\n        'got \"' +\n        typeof paths +\n        '\"'\n    );\n  }\n\n  newSchema.remove(paths);\n\n  for (const nested in newSchema.singleNestedPaths) {\n    if (paths.includes(nested)) {\n      delete newSchema.singleNestedPaths[nested];\n    }\n  }\n\n  return newSchema;\n};\n\n/**\n * Returns default options for this schema, merged with `options`.\n *\n * @param {Object} [options] Options to overwrite the default options\n * @return {Object} The merged options of `options` and the default options\n * @api private\n */\n\nSchema.prototype.defaultOptions = function(options) {\n  this._userProvidedOptions = options == null ? {} : clone(options);\n  const baseOptions = this.base && this.base.options || {};\n  const strict = 'strict' in baseOptions ? baseOptions.strict : true;\n  const strictQuery = 'strictQuery' in baseOptions ? baseOptions.strictQuery : false;\n  const id = 'id' in baseOptions ? baseOptions.id : true;\n  options = {\n    strict,\n    strictQuery,\n    bufferCommands: true,\n    capped: false, // { size, max, autoIndexId }\n    versionKey: '__v',\n    optimisticConcurrency: false,\n    minimize: true,\n    autoIndex: null,\n    discriminatorKey: '__t',\n    shardKey: null,\n    read: null,\n    validateBeforeSave: true,\n    validateModifiedOnly: false,\n    // the following are only applied at construction time\n    _id: true,\n    id: id,\n    typeKey: 'type',\n    ...options\n  };\n\n  if (options.versionKey && typeof options.versionKey !== 'string') {\n    throw new MongooseError('`versionKey` must be falsy or string, got `' + (typeof options.versionKey) + '`');\n  }\n\n  if (typeof options.read === 'string') {\n    options.read = handleReadPreferenceAliases(options.read);\n  } else if (Array.isArray(options.read) && typeof options.read[0] === 'string') {\n    options.read = {\n      mode: handleReadPreferenceAliases(options.read[0]),\n      tags: options.read[1]\n    };\n  }\n\n  if (options.optimisticConcurrency && !options.versionKey) {\n    throw new MongooseError('Must set `versionKey` if using `optimisticConcurrency`');\n  }\n\n  return options;\n};\n\n/**\n * Inherit a Schema by applying a discriminator on an existing Schema.\n *\n *\n * #### Example:\n *\n *     const eventSchema = new mongoose.Schema({ timestamp: Date }, { discriminatorKey: 'kind' });\n *\n *     const clickedEventSchema = new mongoose.Schema({ element: String }, { discriminatorKey: 'kind' });\n *     const ClickedModel = eventSchema.discriminator('clicked', clickedEventSchema);\n *\n *     const Event = mongoose.model('Event', eventSchema);\n *\n *     Event.discriminators['clicked']; // Model { clicked }\n *\n *     const doc = await Event.create({ kind: 'clicked', element: '#hero' });\n *     doc.element; // '#hero'\n *     doc instanceof ClickedModel; // true\n *\n * @param {String} name the name of the discriminator\n * @param {Schema} schema the discriminated Schema\n * @param {Object} [options] discriminator options\n * @param {String} [options.value] the string stored in the `discriminatorKey` property. If not specified, Mongoose uses the `name` parameter.\n * @param {Boolean} [options.clone=true] By default, `discriminator()` clones the given `schema`. Set to `false` to skip cloning.\n * @param {Boolean} [options.overwriteModels=false] by default, Mongoose does not allow you to define a discriminator with the same name as another discriminator. Set this to allow overwriting discriminators with the same name.\n * @param {Boolean} [options.mergeHooks=true] By default, Mongoose merges the base schema's hooks with the discriminator schema's hooks. Set this option to `false` to make Mongoose use the discriminator schema's hooks instead.\n * @param {Boolean} [options.mergePlugins=true] By default, Mongoose merges the base schema's plugins with the discriminator schema's plugins. Set this option to `false` to make Mongoose use the discriminator schema's plugins instead.\n * @return {Schema} the Schema instance\n * @api public\n */\nSchema.prototype.discriminator = function(name, schema, options) {\n  this._applyDiscriminators = this._applyDiscriminators || new Map();\n  this._applyDiscriminators.set(name, { schema, options });\n\n  return this;\n};\n\n/*!\n * Get this schema's default toObject/toJSON options, including Mongoose global\n * options.\n */\n\nSchema.prototype._defaultToObjectOptions = function(json) {\n  const path = json ? 'toJSON' : 'toObject';\n  if (this._defaultToObjectOptionsMap && this._defaultToObjectOptionsMap[path]) {\n    return this._defaultToObjectOptionsMap[path];\n  }\n\n  const baseOptions = this.base &&\n    this.base.options &&\n    this.base.options[path] || {};\n  const schemaOptions = this.options[path] || {};\n  // merge base default options with Schema's set default options if available.\n  // `clone` is necessary here because `utils.options` directly modifies the second input.\n  const defaultOptions = Object.assign({}, baseOptions, schemaOptions);\n\n  this._defaultToObjectOptionsMap = this._defaultToObjectOptionsMap || {};\n  this._defaultToObjectOptionsMap[path] = defaultOptions;\n  return defaultOptions;\n};\n\n/**\n * Adds key path / schema type pairs to this schema.\n *\n * #### Example:\n *\n *     const ToySchema = new Schema();\n *     ToySchema.add({ name: 'string', color: 'string', price: 'number' });\n *\n *     const TurboManSchema = new Schema();\n *     // You can also `add()` another schema and copy over all paths, virtuals,\n *     // getters, setters, indexes, methods, and statics.\n *     TurboManSchema.add(ToySchema).add({ year: Number });\n *\n * @param {Object|Schema} obj plain object with paths to add, or another schema\n * @param {String} [prefix] path to prefix the newly added paths with\n * @return {Schema} the Schema instance\n * @api public\n */\n\nSchema.prototype.add = function add(obj, prefix) {\n  if (obj instanceof Schema || (obj != null && obj.instanceOfSchema)) {\n    merge(this, obj);\n\n    return this;\n  }\n\n  // Special case: setting top-level `_id` to false should convert to disabling\n  // the `_id` option. This behavior never worked before 5.4.11 but numerous\n  // codebases use it (see gh-7516, gh-7512).\n  if (obj._id === false && prefix == null) {\n    this.options._id = false;\n  }\n\n  prefix = prefix || '';\n  // avoid prototype pollution\n  if (prefix === '__proto__.' || prefix === 'constructor.' || prefix === 'prototype.') {\n    return this;\n  }\n\n  const keys = Object.keys(obj);\n  const typeKey = this.options.typeKey;\n  for (const key of keys) {\n    if (utils.specialProperties.has(key)) {\n      continue;\n    }\n\n    const fullPath = prefix + key;\n    const val = obj[key];\n\n    if (val == null) {\n      throw new TypeError('Invalid value for schema path `' + fullPath +\n        '`, got value \"' + val + '\"');\n    }\n    // Retain `_id: false` but don't set it as a path, re: gh-8274.\n    if (key === '_id' && val === false) {\n      continue;\n    }\n    // Deprecate setting schema paths to primitive types (gh-7558)\n    let isMongooseTypeString = false;\n    if (typeof val === 'string') {\n      // Handle the case in which the type is specified as a string (eg. 'date', 'oid', ...)\n      const MongooseTypes = this.base != null ? this.base.Schema.Types : Schema.Types;\n      const upperVal = val.charAt(0).toUpperCase() + val.substring(1);\n      isMongooseTypeString = MongooseTypes[upperVal] != null;\n    }\n    if (\n      key !== '_id' &&\n      ((typeof val !== 'object' && typeof val !== 'function' && !isMongooseTypeString) ||\n      val == null)\n    ) {\n      throw new TypeError(`Invalid schema configuration: \\`${val}\\` is not ` +\n        `a valid type at path \\`${key}\\`. See ` +\n        'https://bit.ly/mongoose-schematypes for a list of valid schema types.');\n    }\n    if (val instanceof VirtualType || (val.constructor && val.constructor.name || null) === 'VirtualType') {\n      this.virtual(val);\n      continue;\n    }\n\n    if (Array.isArray(val) && val.length === 1 && val[0] == null) {\n      throw new TypeError('Invalid value for schema Array path `' + fullPath +\n        '`, got value \"' + val[0] + '\"');\n    }\n\n    if (!(isPOJO(val) || val instanceof SchemaTypeOptions)) {\n      // Special-case: Non-options definitely a path so leaf at this node\n      // Examples: Schema instances, SchemaType instances\n      if (prefix) {\n        this.nested[prefix.substring(0, prefix.length - 1)] = true;\n      }\n      this.path(prefix + key, val);\n      if (val[0] != null && !(val[0].instanceOfSchema) && utils.isPOJO(val[0].discriminators)) {\n        const schemaType = this.path(prefix + key);\n        for (const key in val[0].discriminators) {\n          schemaType.discriminator(key, val[0].discriminators[key]);\n        }\n      }\n    } else if (Object.keys(val).length < 1) {\n      // Special-case: {} always interpreted as Mixed path so leaf at this node\n      if (prefix) {\n        this.nested[prefix.substring(0, prefix.length - 1)] = true;\n      }\n      this.path(fullPath, val); // mixed type\n    } else if (!val[typeKey] || (typeKey === 'type' && isPOJO(val.type) && val.type.type)) {\n      // Special-case: POJO with no bona-fide type key - interpret as tree of deep paths so recurse\n      // nested object `{ last: { name: String } }`. Avoid functions with `.type` re: #10807 because\n      // NestJS sometimes adds `Date.type`.\n      this.nested[fullPath] = true;\n      this.add(val, fullPath + '.');\n    } else {\n      // There IS a bona-fide type key that may also be a POJO\n      const _typeDef = val[typeKey];\n      if (isPOJO(_typeDef) && Object.keys(_typeDef).length > 0) {\n        // If a POJO is the value of a type key, make it a subdocument\n        if (prefix) {\n          this.nested[prefix.substring(0, prefix.length - 1)] = true;\n        }\n\n        const childSchemaOptions = {};\n        if (this._userProvidedOptions.typeKey) {\n          childSchemaOptions.typeKey = this._userProvidedOptions.typeKey;\n        }\n        // propagate 'strict' option to child schema\n        if (this._userProvidedOptions.strict != null) {\n          childSchemaOptions.strict = this._userProvidedOptions.strict;\n        }\n        if (this._userProvidedOptions.toObject != null) {\n          childSchemaOptions.toObject = utils.omit(this._userProvidedOptions.toObject, ['transform']);\n        }\n        if (this._userProvidedOptions.toJSON != null) {\n          childSchemaOptions.toJSON = utils.omit(this._userProvidedOptions.toJSON, ['transform']);\n        }\n\n        const _schema = new Schema(_typeDef, childSchemaOptions);\n        _schema.$implicitlyCreated = true;\n        const schemaWrappedPath = Object.assign({}, val, { [typeKey]: _schema });\n        this.path(prefix + key, schemaWrappedPath);\n      } else {\n        // Either the type is non-POJO or we interpret it as Mixed anyway\n        if (prefix) {\n          this.nested[prefix.substring(0, prefix.length - 1)] = true;\n        }\n        this.path(prefix + key, val);\n        if (val != null && !(val.instanceOfSchema) && utils.isPOJO(val.discriminators)) {\n          const schemaType = this.path(prefix + key);\n          for (const key in val.discriminators) {\n            schemaType.discriminator(key, val.discriminators[key]);\n          }\n        }\n      }\n    }\n  }\n\n  const aliasObj = Object.fromEntries(\n    Object.entries(obj).map(([key]) => ([prefix + key, null]))\n  );\n  aliasFields(this, aliasObj);\n  return this;\n};\n\n/**\n * Add an alias for `path`. This means getting or setting the `alias`\n * is equivalent to getting or setting the `path`.\n *\n * #### Example:\n *\n *     const toySchema = new Schema({ n: String });\n *\n *     // Make 'name' an alias for 'n'\n *     toySchema.alias('n', 'name');\n *\n *     const Toy = mongoose.model('Toy', toySchema);\n *     const turboMan = new Toy({ n: 'Turbo Man' });\n *\n *     turboMan.name; // 'Turbo Man'\n *     turboMan.n; // 'Turbo Man'\n *\n *     turboMan.name = 'Turbo Man Action Figure';\n *     turboMan.n; // 'Turbo Man Action Figure'\n *\n *     await turboMan.save(); // Saves { _id: ..., n: 'Turbo Man Action Figure' }\n *\n *\n * @param {String} path real path to alias\n * @param {String|String[]} alias the path(s) to use as an alias for `path`\n * @return {Schema} the Schema instance\n * @api public\n */\n\nSchema.prototype.alias = function alias(path, alias) {\n  aliasFields(this, { [path]: alias });\n  return this;\n};\n\n/**\n * Remove an index by name or index specification.\n *\n * removeIndex only removes indexes from your schema object. Does **not** affect the indexes\n * in MongoDB.\n *\n * #### Example:\n *\n *     const ToySchema = new Schema({ name: String, color: String, price: Number });\n *\n *     // Add a new index on { name, color }\n *     ToySchema.index({ name: 1, color: 1 });\n *\n *     // Remove index on { name, color }\n *     // Keep in mind that order matters! `removeIndex({ color: 1, name: 1 })` won't remove the index\n *     ToySchema.removeIndex({ name: 1, color: 1 });\n *\n *     // Add an index with a custom name\n *     ToySchema.index({ color: 1 }, { name: 'my custom index name' });\n *     // Remove index by name\n *     ToySchema.removeIndex('my custom index name');\n *\n * @param {Object|string} index name or index specification\n * @return {Schema} the Schema instance\n * @api public\n */\n\nSchema.prototype.removeIndex = function removeIndex(index) {\n  if (arguments.length > 1) {\n    throw new Error('removeIndex() takes only 1 argument');\n  }\n\n  if (typeof index !== 'object' && typeof index !== 'string') {\n    throw new Error('removeIndex() may only take either an object or a string as an argument');\n  }\n\n  if (typeof index === 'object') {\n    for (let i = this._indexes.length - 1; i >= 0; --i) {\n      if (util.isDeepStrictEqual(this._indexes[i][0], index)) {\n        this._indexes.splice(i, 1);\n      }\n    }\n  } else {\n    for (let i = this._indexes.length - 1; i >= 0; --i) {\n      if (this._indexes[i][1] != null && this._indexes[i][1].name === index) {\n        this._indexes.splice(i, 1);\n      }\n    }\n  }\n\n  return this;\n};\n\n/**\n * Remove all indexes from this schema.\n *\n * clearIndexes only removes indexes from your schema object. Does **not** affect the indexes\n * in MongoDB.\n *\n * #### Example:\n *\n *     const ToySchema = new Schema({ name: String, color: String, price: Number });\n *     ToySchema.index({ name: 1 });\n *     ToySchema.index({ color: 1 });\n *\n *     // Remove all indexes on this schema\n *     ToySchema.clearIndexes();\n *\n *     ToySchema.indexes(); // []\n *\n * @return {Schema} the Schema instance\n * @api public\n */\n\nSchema.prototype.clearIndexes = function clearIndexes() {\n  this._indexes.length = 0;\n\n  return this;\n};\n\n/**\n * Add an [Atlas search index](https://www.mongodb.com/docs/atlas/atlas-search/create-index/) that Mongoose will create using `Model.createSearchIndex()`.\n * This function only works when connected to MongoDB Atlas.\n *\n * #### Example:\n *\n *     const ToySchema = new Schema({ name: String, color: String, price: Number });\n *     ToySchema.searchIndex({ name: 'test', definition: { mappings: { dynamic: true } } });\n *\n * @param {Object} description index options, including `name` and `definition`\n * @param {String} description.name\n * @param {Object} description.definition\n * @return {Schema} the Schema instance\n * @api public\n */\n\nSchema.prototype.searchIndex = function searchIndex(description) {\n  this._searchIndexes.push(description);\n\n  return this;\n};\n\n/**\n * Reserved document keys.\n *\n * Keys in this object are names that are warned in schema declarations\n * because they have the potential to break Mongoose/ Mongoose plugins functionality. If you create a schema\n * using `new Schema()` with one of these property names, Mongoose will log a warning.\n *\n * - _posts\n * - _pres\n * - collection\n  * - emit\n * - errors\n * - get\n * - init\n * - isModified\n * - isNew\n * - listeners\n * - modelName\n * - on\n * - once\n * - populated\n * - prototype\n * - remove\n * - removeListener\n * - save\n * - schema\n * - toObject\n * - validate\n *\n * _NOTE:_ Use of these terms as method names is permitted, but play at your own risk, as they may be existing mongoose document methods you are stomping on.\n *\n *      const schema = new Schema(..);\n *      schema.methods.init = function () {} // potentially breaking\n *\n * @property reserved\n * @memberOf Schema\n * @static\n */\n\nSchema.reserved = Object.create(null);\nSchema.prototype.reserved = Schema.reserved;\n\nconst reserved = Schema.reserved;\n// Core object\nreserved['prototype'] =\n// EventEmitter\nreserved.emit =\nreserved.listeners =\nreserved.removeListener =\n\n// document properties and functions\nreserved.collection =\nreserved.errors =\nreserved.get =\nreserved.init =\nreserved.isModified =\nreserved.isNew =\nreserved.populated =\nreserved.remove =\nreserved.save =\nreserved.toObject =\nreserved.validate = 1;\nreserved.collection = 1;\n\n/**\n * Gets/sets schema paths.\n *\n * Sets a path (if arity 2)\n * Gets a path (if arity 1)\n *\n * #### Example:\n *\n *     schema.path('name') // returns a SchemaType\n *     schema.path('name', Number) // changes the schemaType of `name` to Number\n *\n * @param {String} path The name of the Path to get / set\n * @param {Object} [obj] The Type to set the path to, if provided the path will be SET, otherwise the path will be GET\n * @api public\n */\n\nSchema.prototype.path = function(path, obj) {\n  if (obj === undefined) {\n    if (this.paths[path] != null) {\n      return this.paths[path];\n    }\n    // Convert to '.$' to check subpaths re: gh-6405\n    const cleanPath = _pathToPositionalSyntax(path);\n    let schematype = _getPath(this, path, cleanPath);\n    if (schematype != null) {\n      return schematype;\n    }\n\n    // Look for maps\n    const mapPath = getMapPath(this, path);\n    if (mapPath != null) {\n      return mapPath;\n    }\n\n    // Look if a parent of this path is mixed\n    schematype = this.hasMixedParent(cleanPath);\n    if (schematype != null) {\n      return schematype;\n    }\n\n    // subpaths?\n    return hasNumericSubpathRegex.test(path)\n      ? getPositionalPath(this, path, cleanPath)\n      : undefined;\n  }\n\n  // some path names conflict with document methods\n  const firstPieceOfPath = path.split('.')[0];\n  if (reserved[firstPieceOfPath] && !this.options.suppressReservedKeysWarning) {\n    const errorMessage = `\\`${firstPieceOfPath}\\` is a reserved schema pathname and may break some functionality. ` +\n      'You are allowed to use it, but use at your own risk. ' +\n      'To disable this warning pass `suppressReservedKeysWarning` as a schema option.';\n\n    utils.warn(errorMessage);\n  }\n\n  if (typeof obj === 'object' && utils.hasUserDefinedProperty(obj, 'ref')) {\n    validateRef(obj.ref, path);\n  }\n\n  // update the tree\n  const subpaths = path.split(/\\./);\n  const last = subpaths.pop();\n  let branch = this.tree;\n  let fullPath = '';\n\n  for (const sub of subpaths) {\n    if (utils.specialProperties.has(sub)) {\n      throw new Error('Cannot set special property `' + sub + '` on a schema');\n    }\n    fullPath = fullPath += (fullPath.length > 0 ? '.' : '') + sub;\n    if (!branch[sub]) {\n      this.nested[fullPath] = true;\n      branch[sub] = {};\n    }\n    if (typeof branch[sub] !== 'object') {\n      const msg = 'Cannot set nested path `' + path + '`. '\n          + 'Parent path `'\n          + fullPath\n          + '` already set to type ' + branch[sub].name\n          + '.';\n      throw new Error(msg);\n    }\n    branch = branch[sub];\n  }\n\n  branch[last] = clone(obj);\n\n  this.paths[path] = this.interpretAsType(path, obj, this.options);\n  const schemaType = this.paths[path];\n\n  if (schemaType.$isSchemaMap) {\n    // Maps can have arbitrary keys, so `$*` is internal shorthand for \"any key\"\n    // The '$' is to imply this path should never be stored in MongoDB so we\n    // can easily build a regexp out of this path, and '*' to imply \"any key.\"\n    const mapPath = path + '.$*';\n\n    this.paths[mapPath] = schemaType.$__schemaType;\n    this.mapPaths.push(this.paths[mapPath]);\n  }\n\n  if (schemaType.$isSingleNested) {\n    for (const key of Object.keys(schemaType.schema.paths)) {\n      this.singleNestedPaths[path + '.' + key] = schemaType.schema.paths[key];\n    }\n    for (const key of Object.keys(schemaType.schema.singleNestedPaths)) {\n      this.singleNestedPaths[path + '.' + key] =\n        schemaType.schema.singleNestedPaths[key];\n    }\n    for (const key of Object.keys(schemaType.schema.subpaths)) {\n      this.singleNestedPaths[path + '.' + key] =\n        schemaType.schema.subpaths[key];\n    }\n    for (const key of Object.keys(schemaType.schema.nested)) {\n      this.singleNestedPaths[path + '.' + key] = 'nested';\n    }\n\n    Object.defineProperty(schemaType.schema, 'base', {\n      configurable: true,\n      enumerable: false,\n      writable: false,\n      value: this.base\n    });\n\n    schemaType.caster.base = this.base;\n    this.childSchemas.push({\n      schema: schemaType.schema,\n      model: schemaType.caster\n    });\n  } else if (schemaType.$isMongooseDocumentArray) {\n    Object.defineProperty(schemaType.schema, 'base', {\n      configurable: true,\n      enumerable: false,\n      writable: false,\n      value: this.base\n    });\n\n    schemaType.casterConstructor.base = this.base;\n    this.childSchemas.push({\n      schema: schemaType.schema,\n      model: schemaType.casterConstructor\n    });\n  }\n\n  if (schemaType.$isMongooseArray && schemaType.caster instanceof SchemaType) {\n    let arrayPath = path;\n    let _schemaType = schemaType;\n\n    const toAdd = [];\n    while (_schemaType.$isMongooseArray) {\n      arrayPath = arrayPath + '.$';\n\n      // Skip arrays of document arrays\n      if (_schemaType.$isMongooseDocumentArray) {\n        _schemaType.$embeddedSchemaType._arrayPath = arrayPath;\n        _schemaType.$embeddedSchemaType._arrayParentPath = path;\n        _schemaType = _schemaType.$embeddedSchemaType;\n      } else {\n        _schemaType.caster._arrayPath = arrayPath;\n        _schemaType.caster._arrayParentPath = path;\n        _schemaType = _schemaType.caster;\n      }\n\n      this.subpaths[arrayPath] = _schemaType;\n    }\n\n    for (const _schemaType of toAdd) {\n      this.subpaths[_schemaType.path] = _schemaType;\n    }\n  }\n\n  if (schemaType.$isMongooseDocumentArray) {\n    for (const key of Object.keys(schemaType.schema.paths)) {\n      const _schemaType = schemaType.schema.paths[key];\n      this.subpaths[path + '.' + key] = _schemaType;\n      if (typeof _schemaType === 'object' && _schemaType != null && _schemaType.$parentSchemaDocArray == null) {\n        _schemaType.$parentSchemaDocArray = schemaType;\n      }\n    }\n    for (const key of Object.keys(schemaType.schema.subpaths)) {\n      const _schemaType = schemaType.schema.subpaths[key];\n      this.subpaths[path + '.' + key] = _schemaType;\n      if (typeof _schemaType === 'object' && _schemaType != null && _schemaType.$parentSchemaDocArray == null) {\n        _schemaType.$parentSchemaDocArray = schemaType;\n      }\n    }\n    for (const key of Object.keys(schemaType.schema.singleNestedPaths)) {\n      const _schemaType = schemaType.schema.singleNestedPaths[key];\n      this.subpaths[path + '.' + key] = _schemaType;\n      if (typeof _schemaType === 'object' && _schemaType != null && _schemaType.$parentSchemaDocArray == null) {\n        _schemaType.$parentSchemaDocArray = schemaType;\n      }\n    }\n  }\n\n  return this;\n};\n\n/*!\n * ignore\n */\n\nfunction gatherChildSchemas(schema) {\n  const childSchemas = [];\n\n  for (const path of Object.keys(schema.paths)) {\n    const schematype = schema.paths[path];\n    if (schematype.$isMongooseDocumentArray || schematype.$isSingleNested) {\n      childSchemas.push({ schema: schematype.schema, model: schematype.caster });\n    }\n  }\n\n  return childSchemas;\n}\n\n/*!\n * ignore\n */\n\nfunction _getPath(schema, path, cleanPath) {\n  if (schema.paths.hasOwnProperty(path)) {\n    return schema.paths[path];\n  }\n  if (schema.subpaths.hasOwnProperty(cleanPath)) {\n    const subpath = schema.subpaths[cleanPath];\n    if (subpath === 'nested') {\n      return undefined;\n    }\n    return subpath;\n  }\n  if (schema.singleNestedPaths.hasOwnProperty(cleanPath) && typeof schema.singleNestedPaths[cleanPath] === 'object') {\n    const singleNestedPath = schema.singleNestedPaths[cleanPath];\n    if (singleNestedPath === 'nested') {\n      return undefined;\n    }\n    return singleNestedPath;\n  }\n\n  return null;\n}\n\n/*!\n * ignore\n */\n\nfunction _pathToPositionalSyntax(path) {\n  if (!/\\.\\d+/.test(path)) {\n    return path;\n  }\n  return path.replace(/\\.\\d+\\./g, '.$.').replace(/\\.\\d+$/, '.$');\n}\n\n/*!\n * ignore\n */\n\nfunction getMapPath(schema, path) {\n  if (schema.mapPaths.length === 0) {\n    return null;\n  }\n  for (const val of schema.mapPaths) {\n    const _path = val.path;\n    const re = new RegExp('^' + _path.replace(/\\.\\$\\*/g, '\\\\.[^.]+') + '$');\n    if (re.test(path)) {\n      return schema.paths[_path];\n    }\n  }\n\n  return null;\n}\n\n/**\n * The Mongoose instance this schema is associated with\n *\n * @property base\n * @api private\n */\n\nObject.defineProperty(Schema.prototype, 'base', {\n  configurable: true,\n  enumerable: false,\n  writable: true,\n  value: null\n});\n\n/**\n * Converts type arguments into Mongoose Types.\n *\n * @param {String} path\n * @param {Object} obj constructor\n * @param {Object} options\n * @api private\n */\n\nSchema.prototype.interpretAsType = function(path, obj, options) {\n  if (obj instanceof SchemaType) {\n    if (obj.path === path) {\n      return obj;\n    }\n    const clone = obj.clone();\n    clone.path = path;\n    return clone;\n  }\n\n\n  // If this schema has an associated Mongoose object, use the Mongoose object's\n  // copy of SchemaTypes re: gh-7158 gh-6933\n  const MongooseTypes = this.base != null ? this.base.Schema.Types : Schema.Types;\n  const Types = this.base != null ? this.base.Types : __webpack_require__(/*! ./types */ \"./node_modules/mongoose/lib/types/index.js\");\n\n  if (!utils.isPOJO(obj) && !(obj instanceof SchemaTypeOptions)) {\n    const constructorName = utils.getFunctionName(obj.constructor);\n    if (constructorName !== 'Object') {\n      const oldObj = obj;\n      obj = {};\n      obj[options.typeKey] = oldObj;\n    }\n  }\n\n  // Get the type making sure to allow keys named \"type\"\n  // and default to mixed if not specified.\n  // { type: { type: String, default: 'freshcut' } }\n  let type = obj[options.typeKey] && (obj[options.typeKey] instanceof Function || options.typeKey !== 'type' || !obj.type.type)\n    ? obj[options.typeKey]\n    : {};\n  let name;\n\n  if (utils.isPOJO(type) || type === 'mixed') {\n    return new MongooseTypes.Mixed(path, obj);\n  }\n\n  if (Array.isArray(type) || type === Array || type === 'array' || type === MongooseTypes.Array) {\n    // if it was specified through { type } look for `cast`\n    let cast = (type === Array || type === 'array')\n      ? obj.cast || obj.of\n      : type[0];\n\n    // new Schema({ path: [new Schema({ ... })] })\n    if (cast && cast.instanceOfSchema) {\n      if (!(cast instanceof Schema)) {\n        if (this.options._isMerging) {\n          cast = new Schema(cast);\n        } else {\n          throw new TypeError('Schema for array path `' + path +\n            '` is from a different copy of the Mongoose module. ' +\n            'Please make sure you\\'re using the same version ' +\n            'of Mongoose everywhere with `npm list mongoose`. If you are still ' +\n            'getting this error, please add `new Schema()` around the path: ' +\n            `${path}: new Schema(...)`);\n        }\n      }\n      return new MongooseTypes.DocumentArray(path, cast, obj);\n    }\n    if (cast &&\n        cast[options.typeKey] &&\n        cast[options.typeKey].instanceOfSchema) {\n      if (!(cast[options.typeKey] instanceof Schema)) {\n        if (this.options._isMerging) {\n          cast[options.typeKey] = new Schema(cast[options.typeKey]);\n        } else {\n          throw new TypeError('Schema for array path `' + path +\n            '` is from a different copy of the Mongoose module. ' +\n            'Please make sure you\\'re using the same version ' +\n            'of Mongoose everywhere with `npm list mongoose`. If you are still ' +\n            'getting this error, please add `new Schema()` around the path: ' +\n            `${path}: new Schema(...)`);\n        }\n      }\n      return new MongooseTypes.DocumentArray(path, cast[options.typeKey], obj, cast);\n    }\n    if (typeof cast !== 'undefined') {\n      if (Array.isArray(cast) || cast.type === Array || cast.type == 'Array') {\n        if (cast && cast.type == 'Array') {\n          cast.type = Array;\n        }\n        return new MongooseTypes.Array(path, this.interpretAsType(path, cast, options), obj);\n      }\n    }\n\n    // Handle both `new Schema({ arr: [{ subpath: String }] })` and `new Schema({ arr: [{ type: { subpath: string } }] })`\n    const castFromTypeKey = (cast != null && cast[options.typeKey] && (options.typeKey !== 'type' || !cast.type.type)) ?\n      cast[options.typeKey] :\n      cast;\n    if (typeof cast === 'string') {\n      cast = MongooseTypes[cast.charAt(0).toUpperCase() + cast.substring(1)];\n    } else if (utils.isPOJO(castFromTypeKey)) {\n      if (Object.keys(castFromTypeKey).length) {\n        // The `minimize` and `typeKey` options propagate to child schemas\n        // declared inline, like `{ arr: [{ val: { $type: String } }] }`.\n        // See gh-3560\n        const childSchemaOptions = { minimize: options.minimize };\n        if (options.typeKey) {\n          childSchemaOptions.typeKey = options.typeKey;\n        }\n        // propagate 'strict' option to child schema\n        if (options.hasOwnProperty('strict')) {\n          childSchemaOptions.strict = options.strict;\n        }\n        if (options.hasOwnProperty('strictQuery')) {\n          childSchemaOptions.strictQuery = options.strictQuery;\n        }\n        if (options.hasOwnProperty('toObject')) {\n          childSchemaOptions.toObject = utils.omit(options.toObject, ['transform']);\n        }\n        if (options.hasOwnProperty('toJSON')) {\n          childSchemaOptions.toJSON = utils.omit(options.toJSON, ['transform']);\n        }\n\n        if (this._userProvidedOptions.hasOwnProperty('_id')) {\n          childSchemaOptions._id = this._userProvidedOptions._id;\n        } else if (Schema.Types.DocumentArray.defaultOptions._id != null) {\n          childSchemaOptions._id = Schema.Types.DocumentArray.defaultOptions._id;\n        }\n\n        const childSchema = new Schema(castFromTypeKey, childSchemaOptions);\n        childSchema.$implicitlyCreated = true;\n        return new MongooseTypes.DocumentArray(path, childSchema, obj);\n      } else {\n        // Special case: empty object becomes mixed\n        return new MongooseTypes.Array(path, MongooseTypes.Mixed, obj);\n      }\n    }\n\n    if (cast) {\n      type = cast[options.typeKey] && (options.typeKey !== 'type' || !cast.type.type)\n        ? cast[options.typeKey]\n        : cast;\n      if (Array.isArray(type)) {\n        return new MongooseTypes.Array(path, this.interpretAsType(path, type, options), obj);\n      }\n\n      name = typeof type === 'string'\n        ? type\n        : type.schemaName || utils.getFunctionName(type);\n\n      // For Jest 26+, see #10296\n      if (name === 'ClockDate') {\n        name = 'Date';\n      }\n\n      if (name === void 0) {\n        throw new TypeError('Invalid schema configuration: ' +\n          `Could not determine the embedded type for array \\`${path}\\`. ` +\n          'See https://mongoosejs.com/docs/guide.html#definition for more info on supported schema syntaxes.');\n      }\n      if (!MongooseTypes.hasOwnProperty(name)) {\n        throw new TypeError('Invalid schema configuration: ' +\n          `\\`${name}\\` is not a valid type within the array \\`${path}\\`.` +\n          'See https://bit.ly/mongoose-schematypes for a list of valid schema types.');\n      }\n    }\n\n    return new MongooseTypes.Array(path, cast || MongooseTypes.Mixed, obj, options);\n  }\n\n  if (type && type.instanceOfSchema) {\n    return new MongooseTypes.Subdocument(type, path, obj);\n  }\n\n  if (Buffer.isBuffer(type)) {\n    name = 'Buffer';\n  } else if (typeof type === 'function' || typeof type === 'object') {\n    name = type.schemaName || utils.getFunctionName(type);\n  } else if (type === Types.ObjectId) {\n    name = 'ObjectId';\n  } else if (type === Types.Decimal128) {\n    name = 'Decimal128';\n  } else {\n    name = type == null ? '' + type : type.toString();\n  }\n\n  if (name) {\n    name = name.charAt(0).toUpperCase() + name.substring(1);\n  }\n  // Special case re: gh-7049 because the bson `ObjectID` class' capitalization\n  // doesn't line up with Mongoose's.\n  if (name === 'ObjectID') {\n    name = 'ObjectId';\n  }\n  // For Jest 26+, see #10296\n  if (name === 'ClockDate') {\n    name = 'Date';\n  }\n\n  if (name === void 0) {\n    throw new TypeError(`Invalid schema configuration: \\`${path}\\` schematype definition is ` +\n      'invalid. See ' +\n      'https://mongoosejs.com/docs/guide.html#definition for more info on supported schema syntaxes.');\n  }\n  if (MongooseTypes[name] == null) {\n    throw new TypeError(`Invalid schema configuration: \\`${name}\\` is not ` +\n      `a valid type at path \\`${path}\\`. See ` +\n      'https://bit.ly/mongoose-schematypes for a list of valid schema types.');\n  }\n\n  const schemaType = new MongooseTypes[name](path, obj);\n\n  if (schemaType.$isSchemaMap) {\n    createMapNestedSchemaType(this, schemaType, path, obj, options);\n  }\n\n  return schemaType;\n};\n\n/*!\n * ignore\n */\n\nfunction createMapNestedSchemaType(schema, schemaType, path, obj, options) {\n  const mapPath = path + '.$*';\n  let _mapType = { type: {} };\n  if (utils.hasUserDefinedProperty(obj, 'of')) {\n    const isInlineSchema = utils.isPOJO(obj.of) &&\n      Object.keys(obj.of).length > 0 &&\n      !utils.hasUserDefinedProperty(obj.of, schema.options.typeKey);\n    if (isInlineSchema) {\n      _mapType = { [schema.options.typeKey]: new Schema(obj.of) };\n    } else if (utils.isPOJO(obj.of)) {\n      _mapType = Object.assign({}, obj.of);\n    } else {\n      _mapType = { [schema.options.typeKey]: obj.of };\n    }\n\n    if (_mapType[schema.options.typeKey] && _mapType[schema.options.typeKey].instanceOfSchema) {\n      const subdocumentSchema = _mapType[schema.options.typeKey];\n      subdocumentSchema.eachPath((subpath, type) => {\n        if (type.options.select === true || type.options.select === false) {\n          throw new MongooseError('Cannot use schema-level projections (`select: true` or `select: false`) within maps at path \"' + path + '.' + subpath + '\"');\n        }\n      });\n    }\n\n    if (utils.hasUserDefinedProperty(obj, 'ref')) {\n      _mapType.ref = obj.ref;\n    }\n  }\n  schemaType.$__schemaType = schema.interpretAsType(mapPath, _mapType, options);\n}\n\n/**\n * Iterates the schemas paths similar to Array#forEach.\n *\n * The callback is passed the pathname and the schemaType instance.\n *\n * #### Example:\n *\n *     const userSchema = new Schema({ name: String, registeredAt: Date });\n *     userSchema.eachPath((pathname, schematype) => {\n *       // Prints twice:\n *       // name SchemaString { ... }\n *       // registeredAt SchemaDate { ... }\n *       console.log(pathname, schematype);\n *     });\n *\n * @param {Function} fn callback function\n * @return {Schema} this\n * @api public\n */\n\nSchema.prototype.eachPath = function(fn) {\n  const keys = Object.keys(this.paths);\n  const len = keys.length;\n\n  for (let i = 0; i < len; ++i) {\n    fn(keys[i], this.paths[keys[i]]);\n  }\n\n  return this;\n};\n\n/**\n * Returns an Array of path strings that are required by this schema.\n *\n * #### Example:\n *\n *     const s = new Schema({\n *       name: { type: String, required: true },\n *       age: { type: String, required: true },\n *       notes: String\n *     });\n *     s.requiredPaths(); // [ 'age', 'name' ]\n *\n * @api public\n * @param {Boolean} invalidate Refresh the cache\n * @return {Array}\n */\n\nSchema.prototype.requiredPaths = function requiredPaths(invalidate) {\n  if (this._requiredpaths && !invalidate) {\n    return this._requiredpaths;\n  }\n\n  const paths = Object.keys(this.paths);\n  let i = paths.length;\n  const ret = [];\n\n  while (i--) {\n    const path = paths[i];\n    if (this.paths[path].isRequired) {\n      ret.push(path);\n    }\n  }\n  this._requiredpaths = ret;\n  return this._requiredpaths;\n};\n\n/**\n * Returns indexes from fields and schema-level indexes (cached).\n *\n * @api private\n * @return {Array}\n */\n\nSchema.prototype.indexedPaths = function indexedPaths() {\n  if (this._indexedpaths) {\n    return this._indexedpaths;\n  }\n  this._indexedpaths = this.indexes();\n  return this._indexedpaths;\n};\n\n/**\n * Returns the pathType of `path` for this schema.\n *\n * Given a path, returns whether it is a real, virtual, nested, or ad-hoc/undefined path.\n *\n * #### Example:\n *\n *     const s = new Schema({ name: String, nested: { foo: String } });\n *     s.virtual('foo').get(() => 42);\n *     s.pathType('name'); // \"real\"\n *     s.pathType('nested'); // \"nested\"\n *     s.pathType('foo'); // \"virtual\"\n *     s.pathType('fail'); // \"adhocOrUndefined\"\n *\n * @param {String} path\n * @return {String}\n * @api public\n */\n\nSchema.prototype.pathType = function(path) {\n  if (this.paths.hasOwnProperty(path)) {\n    return 'real';\n  }\n  if (this.virtuals.hasOwnProperty(path)) {\n    return 'virtual';\n  }\n  if (this.nested.hasOwnProperty(path)) {\n    return 'nested';\n  }\n\n  // Convert to '.$' to check subpaths re: gh-6405\n  const cleanPath = _pathToPositionalSyntax(path);\n\n  if (this.subpaths.hasOwnProperty(cleanPath) || this.subpaths.hasOwnProperty(path)) {\n    return 'real';\n  }\n\n  const singleNestedPath = this.singleNestedPaths.hasOwnProperty(cleanPath) || this.singleNestedPaths.hasOwnProperty(path);\n  if (singleNestedPath) {\n    return singleNestedPath === 'nested' ? 'nested' : 'real';\n  }\n\n  // Look for maps\n  const mapPath = getMapPath(this, path);\n  if (mapPath != null) {\n    return 'real';\n  }\n\n  if (/\\.\\d+\\.|\\.\\d+$/.test(path)) {\n    return getPositionalPathType(this, path, cleanPath);\n  }\n  return 'adhocOrUndefined';\n};\n\n/**\n * Returns true iff this path is a child of a mixed schema.\n *\n * @param {String} path\n * @return {Boolean}\n * @api private\n */\n\nSchema.prototype.hasMixedParent = function(path) {\n  const subpaths = path.split(/\\./g);\n  path = '';\n  for (let i = 0; i < subpaths.length; ++i) {\n    path = i > 0 ? path + '.' + subpaths[i] : subpaths[i];\n    if (this.paths.hasOwnProperty(path) &&\n        this.paths[path] instanceof MongooseTypes.Mixed) {\n      return this.paths[path];\n    }\n  }\n\n  return null;\n};\n\n/**\n * Setup updatedAt and createdAt timestamps to documents if enabled\n *\n * @param {Boolean|Object} timestamps timestamps options\n * @api private\n */\nSchema.prototype.setupTimestamp = function(timestamps) {\n  return setupTimestamps(this, timestamps);\n};\n\n/**\n * ignore. Deprecated re: #6405\n * @param {Any} self\n * @param {String} path\n * @api private\n */\n\nfunction getPositionalPathType(self, path, cleanPath) {\n  const subpaths = path.split(/\\.(\\d+)\\.|\\.(\\d+)$/).filter(Boolean);\n  if (subpaths.length < 2) {\n    return self.paths.hasOwnProperty(subpaths[0]) ?\n      self.paths[subpaths[0]] :\n      'adhocOrUndefined';\n  }\n\n  let val = self.path(subpaths[0]);\n  let isNested = false;\n  if (!val) {\n    return 'adhocOrUndefined';\n  }\n\n  const last = subpaths.length - 1;\n\n  for (let i = 1; i < subpaths.length; ++i) {\n    isNested = false;\n    const subpath = subpaths[i];\n\n    if (i === last && val && !/\\D/.test(subpath)) {\n      if (val.$isMongooseDocumentArray) {\n        val = val.$embeddedSchemaType;\n      } else if (val instanceof MongooseTypes.Array) {\n        // StringSchema, NumberSchema, etc\n        val = val.caster;\n      } else {\n        val = undefined;\n      }\n      break;\n    }\n\n    // ignore if its just a position segment: path.0.subpath\n    if (!/\\D/.test(subpath)) {\n      // Nested array\n      if (val instanceof MongooseTypes.Array && i !== last) {\n        val = val.caster;\n      }\n      continue;\n    }\n\n    if (!(val && val.schema)) {\n      val = undefined;\n      break;\n    }\n\n    const type = val.schema.pathType(subpath);\n    isNested = (type === 'nested');\n    val = val.schema.path(subpath);\n  }\n\n  self.subpaths[cleanPath] = val;\n  if (val) {\n    return 'real';\n  }\n  if (isNested) {\n    return 'nested';\n  }\n  return 'adhocOrUndefined';\n}\n\n\n/*!\n * ignore\n */\n\nfunction getPositionalPath(self, path, cleanPath) {\n  getPositionalPathType(self, path, cleanPath);\n  return self.subpaths[cleanPath];\n}\n\n/**\n * Adds a method call to the queue.\n *\n * #### Example:\n *\n *     schema.methods.print = function() { console.log(this); };\n *     schema.queue('print', []); // Print the doc every one is instantiated\n *\n *     const Model = mongoose.model('Test', schema);\n *     new Model({ name: 'test' }); // Prints '{\"_id\": ..., \"name\": \"test\" }'\n *\n * @param {String} name name of the document method to call later\n * @param {Array} args arguments to pass to the method\n * @api public\n */\n\nSchema.prototype.queue = function(name, args) {\n  this.callQueue.push([name, args]);\n  return this;\n};\n\n/**\n * Defines a pre hook for the model.\n *\n * #### Example:\n *\n *     const toySchema = new Schema({ name: String, created: Date });\n *\n *     toySchema.pre('save', function(next) {\n *       if (!this.created) this.created = new Date;\n *       next();\n *     });\n *\n *     toySchema.pre('validate', function(next) {\n *       if (this.name !== 'Woody') this.name = 'Woody';\n *       next();\n *     });\n *\n *     // Equivalent to calling `pre()` on `find`, `findOne`, `findOneAndUpdate`.\n *     toySchema.pre(/^find/, function(next) {\n *       console.log(this.getFilter());\n *     });\n *\n *     // Equivalent to calling `pre()` on `updateOne`, `findOneAndUpdate`.\n *     toySchema.pre(['updateOne', 'findOneAndUpdate'], function(next) {\n *       console.log(this.getFilter());\n *     });\n *\n *     toySchema.pre('deleteOne', function() {\n *       // Runs when you call `Toy.deleteOne()`\n *     });\n *\n *     toySchema.pre('deleteOne', { document: true }, function() {\n *       // Runs when you call `doc.deleteOne()`\n *     });\n *\n * @param {String|RegExp|String[]} methodName The method name or regular expression to match method name\n * @param {Object} [options]\n * @param {Boolean} [options.document] If `name` is a hook for both document and query middleware, set to `true` to run on document middleware. For example, set `options.document` to `true` to apply this hook to `Document#deleteOne()` rather than `Query#deleteOne()`.\n * @param {Boolean} [options.query] If `name` is a hook for both document and query middleware, set to `true` to run on query middleware.\n * @param {Function} callback\n * @api public\n */\n\nSchema.prototype.pre = function(name) {\n  if (name instanceof RegExp) {\n    const remainingArgs = Array.prototype.slice.call(arguments, 1);\n    for (const fn of hookNames) {\n      if (name.test(fn)) {\n        this.pre.apply(this, [fn].concat(remainingArgs));\n      }\n    }\n    return this;\n  }\n  if (Array.isArray(name)) {\n    const remainingArgs = Array.prototype.slice.call(arguments, 1);\n    for (const el of name) {\n      this.pre.apply(this, [el].concat(remainingArgs));\n    }\n    return this;\n  }\n  this.s.hooks.pre.apply(this.s.hooks, arguments);\n  return this;\n};\n\n/**\n * Defines a post hook for the document\n *\n *     const schema = new Schema(..);\n *     schema.post('save', function (doc) {\n *       console.log('this fired after a document was saved');\n *     });\n *\n *     schema.post('find', function(docs) {\n *       console.log('this fired after you ran a find query');\n *     });\n *\n *     schema.post(/Many$/, function(res) {\n *       console.log('this fired after you ran `updateMany()` or `deleteMany()`');\n *     });\n *\n *     const Model = mongoose.model('Model', schema);\n *\n *     const m = new Model(..);\n *     m.save(function(err) {\n *       console.log('this fires after the `post` hook');\n *     });\n *\n *     m.find(function(err, docs) {\n *       console.log('this fires after the post find hook');\n *     });\n *\n * @param {String|RegExp|String[]} methodName The method name or regular expression to match method name\n * @param {Object} [options]\n * @param {Boolean} [options.document] If `name` is a hook for both document and query middleware, set to `true` to run on document middleware.\n * @param {Boolean} [options.query] If `name` is a hook for both document and query middleware, set to `true` to run on query middleware.\n * @param {Function} fn callback\n * @see middleware https://mongoosejs.com/docs/middleware.html\n * @see kareem https://npmjs.org/package/kareem\n * @api public\n */\n\nSchema.prototype.post = function(name) {\n  if (name instanceof RegExp) {\n    const remainingArgs = Array.prototype.slice.call(arguments, 1);\n    for (const fn of hookNames) {\n      if (name.test(fn)) {\n        this.post.apply(this, [fn].concat(remainingArgs));\n      }\n    }\n    return this;\n  }\n  if (Array.isArray(name)) {\n    const remainingArgs = Array.prototype.slice.call(arguments, 1);\n    for (const el of name) {\n      this.post.apply(this, [el].concat(remainingArgs));\n    }\n    return this;\n  }\n  this.s.hooks.post.apply(this.s.hooks, arguments);\n  return this;\n};\n\n/**\n * Registers a plugin for this schema.\n *\n * #### Example:\n *\n *     const s = new Schema({ name: String });\n *     s.plugin(schema => console.log(schema.path('name').path));\n *     mongoose.model('Test', s); // Prints 'name'\n *\n * Or with Options:\n *\n *     const s = new Schema({ name: String });\n *     s.plugin((schema, opts) => console.log(opts.text, schema.path('name').path), { text: \"Schema Path Name:\" });\n *     mongoose.model('Test', s); // Prints 'Schema Path Name: name'\n *\n * @param {Function} plugin The Plugin's callback\n * @param {Object} [opts] Options to pass to the plugin\n * @param {Boolean} [opts.deduplicate=false] If true, ignore duplicate plugins (same `fn` argument using `===`)\n * @see plugins https://mongoosejs.com/docs/plugins.html\n * @api public\n */\n\nSchema.prototype.plugin = function(fn, opts) {\n  if (typeof fn !== 'function') {\n    throw new Error('First param to `schema.plugin()` must be a function, ' +\n      'got \"' + (typeof fn) + '\"');\n  }\n\n\n  if (opts && opts.deduplicate) {\n    for (const plugin of this.plugins) {\n      if (plugin.fn === fn) {\n        return this;\n      }\n    }\n  }\n  this.plugins.push({ fn: fn, opts: opts });\n\n  fn(this, opts);\n  return this;\n};\n\n/**\n * Adds an instance method to documents constructed from Models compiled from this schema.\n *\n * #### Example:\n *\n *     const schema = kittySchema = new Schema(..);\n *\n *     schema.method('meow', function () {\n *       console.log('meeeeeoooooooooooow');\n *     })\n *\n *     const Kitty = mongoose.model('Kitty', schema);\n *\n *     const fizz = new Kitty;\n *     fizz.meow(); // meeeeeooooooooooooow\n *\n * If a hash of name/fn pairs is passed as the only argument, each name/fn pair will be added as methods.\n *\n *     schema.method({\n *         purr: function () {}\n *       , scratch: function () {}\n *     });\n *\n *     // later\n *     const fizz = new Kitty;\n *     fizz.purr();\n *     fizz.scratch();\n *\n * NOTE: `Schema.method()` adds instance methods to the `Schema.methods` object. You can also add instance methods directly to the `Schema.methods` object as seen in the [guide](https://mongoosejs.com/docs/guide.html#methods)\n *\n * @param {String|Object} name The Method Name for a single function, or a Object of \"string-function\" pairs.\n * @param {Function} [fn] The Function in a single-function definition.\n * @api public\n */\n\nSchema.prototype.method = function(name, fn, options) {\n  if (typeof name !== 'string') {\n    for (const i in name) {\n      this.methods[i] = name[i];\n      this.methodOptions[i] = clone(options);\n    }\n  } else {\n    this.methods[name] = fn;\n    this.methodOptions[name] = clone(options);\n  }\n  return this;\n};\n\n/**\n * Adds static \"class\" methods to Models compiled from this schema.\n *\n * #### Example:\n *\n *     const schema = new Schema(..);\n *     // Equivalent to `schema.statics.findByName = function(name) {}`;\n *     schema.static('findByName', function(name) {\n *       return this.find({ name: name });\n *     });\n *\n *     const Drink = mongoose.model('Drink', schema);\n *     await Drink.findByName('LaCroix');\n *\n * If a hash of name/fn pairs is passed as the only argument, each name/fn pair will be added as methods.\n *\n *     schema.static({\n *         findByName: function () {..}\n *       , findByCost: function () {..}\n *     });\n *\n *     const Drink = mongoose.model('Drink', schema);\n *     await Drink.findByName('LaCroix');\n *     await Drink.findByCost(3);\n *\n * If a hash of name/fn pairs is passed as the only argument, each name/fn pair will be added as statics.\n *\n * @param {String|Object} name The Method Name for a single function, or a Object of \"string-function\" pairs.\n * @param {Function} [fn] The Function in a single-function definition.\n * @api public\n * @see Statics https://mongoosejs.com/docs/guide.html#statics\n */\n\nSchema.prototype.static = function(name, fn) {\n  if (typeof name !== 'string') {\n    for (const i in name) {\n      this.statics[i] = name[i];\n    }\n  } else {\n    this.statics[name] = fn;\n  }\n  return this;\n};\n\n/**\n * Defines an index (most likely compound) for this schema.\n *\n * #### Example:\n *\n *     schema.index({ first: 1, last: -1 })\n *\n * @param {Object} fields The Fields to index, with the order, available values: `1 | -1 | '2d' | '2dsphere' | 'geoHaystack' | 'hashed' | 'text'`\n * @param {Object} [options] Options to pass to [MongoDB driver's `createIndex()` function](https://mongodb.github.io/node-mongodb-native/4.9/classes/Collection.html#createIndex)\n * @param {String | number} [options.expires=null] Mongoose-specific syntactic sugar, uses [ms](https://www.npmjs.com/package/ms) to convert `expires` option into seconds for the `expireAfterSeconds` in the above link.\n * @param {String} [options.language_override=null] Tells mongodb to use the specified field instead of `language` for parsing text indexes.\n * @api public\n */\n\nSchema.prototype.index = function(fields, options) {\n  fields || (fields = {});\n  options || (options = {});\n\n  if (options.expires) {\n    utils.expires(options);\n  }\n  for (const key in fields) {\n    if (this.aliases[key]) {\n      fields = utils.renameObjKey(fields, key, this.aliases[key]);\n    }\n  }\n  for (const field of Object.keys(fields)) {\n    if (fields[field] === 'ascending' || fields[field] === 'asc') {\n      fields[field] = 1;\n    } else if (fields[field] === 'descending' || fields[field] === 'desc') {\n      fields[field] = -1;\n    }\n  }\n\n  this._indexes.push([fields, options]);\n  return this;\n};\n\n/**\n * Sets a schema option.\n *\n * #### Example:\n *\n *     schema.set('strict'); // 'true' by default\n *     schema.set('strict', false); // Sets 'strict' to false\n *     schema.set('strict'); // 'false'\n *\n * @param {String} key The name of the option to set the value to\n * @param {Object} [value] The value to set the option to, if not passed, the option will be reset to default\n * @param {Array<string>} [tags] tags to add to read preference if key === 'read'\n * @see Schema https://mongoosejs.com/docs/api/schema.html#Schema()\n * @api public\n */\n\nSchema.prototype.set = function(key, value, tags) {\n  if (arguments.length === 1) {\n    return this.options[key];\n  }\n\n  switch (key) {\n    case 'read':\n      if (typeof value === 'string') {\n        this.options[key] = { mode: handleReadPreferenceAliases(value), tags };\n      } else if (Array.isArray(value) && typeof value[0] === 'string') {\n        this.options[key] = {\n          mode: handleReadPreferenceAliases(value[0]),\n          tags: value[1]\n        };\n      } else {\n        this.options[key] = value;\n      }\n      this._userProvidedOptions[key] = this.options[key];\n      break;\n    case 'timestamps':\n      this.setupTimestamp(value);\n      this.options[key] = value;\n      this._userProvidedOptions[key] = this.options[key];\n      break;\n    case '_id':\n      this.options[key] = value;\n      this._userProvidedOptions[key] = this.options[key];\n\n      if (value && !this.paths['_id']) {\n        addAutoId(this);\n      } else if (!value && this.paths['_id'] != null && this.paths['_id'].auto) {\n        this.remove('_id');\n      }\n      break;\n    default:\n      this.options[key] = value;\n      this._userProvidedOptions[key] = this.options[key];\n      break;\n  }\n\n  // Propagate `strict` and `strictQuery` changes down to implicitly created schemas\n  if (key === 'strict') {\n    _propagateOptionsToImplicitlyCreatedSchemas(this, { strict: value });\n  }\n  if (key === 'strictQuery') {\n    _propagateOptionsToImplicitlyCreatedSchemas(this, { strictQuery: value });\n  }\n  if (key === 'toObject') {\n    value = { ...value };\n    // Avoid propagating transform to implicitly created schemas re: gh-3279\n    delete value.transform;\n    _propagateOptionsToImplicitlyCreatedSchemas(this, { toObject: value });\n  }\n  if (key === 'toJSON') {\n    value = { ...value };\n    // Avoid propagating transform to implicitly created schemas re: gh-3279\n    delete value.transform;\n    _propagateOptionsToImplicitlyCreatedSchemas(this, { toJSON: value });\n  }\n\n  return this;\n};\n\n/*!\n * Recursively set options on implicitly created schemas\n */\n\nfunction _propagateOptionsToImplicitlyCreatedSchemas(baseSchema, options) {\n  for (const { schema } of baseSchema.childSchemas) {\n    if (!schema.$implicitlyCreated) {\n      continue;\n    }\n    Object.assign(schema.options, options);\n    _propagateOptionsToImplicitlyCreatedSchemas(schema, options);\n  }\n}\n\n/**\n * Gets a schema option.\n *\n * #### Example:\n *\n *     schema.get('strict'); // true\n *     schema.set('strict', false);\n *     schema.get('strict'); // false\n *\n * @param {String} key The name of the Option to get the current value for\n * @api public\n * @return {Any} the option's value\n */\n\nSchema.prototype.get = function(key) {\n  return this.options[key];\n};\n\nconst indexTypes = '2d 2dsphere hashed text'.split(' ');\n\n/**\n * The allowed index types\n *\n * @property {String[]} indexTypes\n * @memberOf Schema\n * @static\n * @api public\n */\n\nObject.defineProperty(Schema, 'indexTypes', {\n  get: function() {\n    return indexTypes;\n  },\n  set: function() {\n    throw new Error('Cannot overwrite Schema.indexTypes');\n  }\n});\n\n/**\n * Returns a list of indexes that this schema declares, via `schema.index()` or by `index: true` in a path's options.\n * Indexes are expressed as an array `[spec, options]`.\n *\n * #### Example:\n *\n *     const userSchema = new Schema({\n *       email: { type: String, required: true, unique: true },\n *       registeredAt: { type: Date, index: true }\n *     });\n *\n *     // [ [ { email: 1 }, { unique: true, background: true } ],\n *     //   [ { registeredAt: 1 }, { background: true } ] ]\n *     userSchema.indexes();\n *\n * [Plugins](https://mongoosejs.com/docs/plugins.html) can use the return value of this function to modify a schema's indexes.\n * For example, the below plugin makes every index unique by default.\n *\n *     function myPlugin(schema) {\n *       for (const index of schema.indexes()) {\n *         if (index[1].unique === undefined) {\n *           index[1].unique = true;\n *         }\n *       }\n *     }\n *\n * @api public\n * @return {Array} list of indexes defined in the schema\n */\n\nSchema.prototype.indexes = function() {\n  return getIndexes(this);\n};\n\n/**\n * Creates a virtual type with the given name.\n *\n * @param {String} name The name of the Virtual\n * @param {Object} [options]\n * @param {String|Model} [options.ref] model name or model instance. Marks this as a [populate virtual](https://mongoosejs.com/docs/populate.html#populate-virtuals).\n * @param {String|Function} [options.localField] Required for populate virtuals. See [populate virtual docs](https://mongoosejs.com/docs/populate.html#populate-virtuals) for more information.\n * @param {String|Function} [options.foreignField] Required for populate virtuals. See [populate virtual docs](https://mongoosejs.com/docs/populate.html#populate-virtuals) for more information.\n * @param {Boolean|Function} [options.justOne=false] Only works with populate virtuals. If [truthy](https://masteringjs.io/tutorials/fundamentals/truthy), will be a single doc or `null`. Otherwise, the populate virtual will be an array.\n * @param {Boolean} [options.count=false] Only works with populate virtuals. If [truthy](https://masteringjs.io/tutorials/fundamentals/truthy), this populate virtual will contain the number of documents rather than the documents themselves when you `populate()`.\n * @param {Function|null} [options.get=null] Adds a [getter](https://mongoosejs.com/docs/tutorials/getters-setters.html) to this virtual to transform the populated doc.\n * @param {Object|Function} [options.match=null] Apply a default [`match` option to populate](https://mongoosejs.com/docs/populate.html#match), adding an additional filter to the populate query.\n * @return {VirtualType}\n */\n\nSchema.prototype.virtual = function(name, options) {\n  if (name instanceof VirtualType || getConstructorName(name) === 'VirtualType') {\n    return this.virtual(name.path, name.options);\n  }\n  options = new VirtualOptions(options);\n\n  if (utils.hasUserDefinedProperty(options, ['ref', 'refPath'])) {\n    if (options.localField == null) {\n      throw new Error('Reference virtuals require `localField` option');\n    }\n\n    if (options.foreignField == null) {\n      throw new Error('Reference virtuals require `foreignField` option');\n    }\n\n    const virtual = this.virtual(name);\n    virtual.options = options;\n\n    this.pre('init', function virtualPreInit(obj, opts) {\n      if (mpath.has(name, obj)) {\n        const _v = mpath.get(name, obj);\n        if (!this.$$populatedVirtuals) {\n          this.$$populatedVirtuals = {};\n        }\n\n        if (options.justOne || options.count) {\n          this.$$populatedVirtuals[name] = Array.isArray(_v) ?\n            _v[0] :\n            _v;\n        } else {\n          this.$$populatedVirtuals[name] = Array.isArray(_v) ?\n            _v :\n            _v == null ? [] : [_v];\n        }\n\n        if (opts?.hydratedPopulatedDocs && !options.count) {\n          const modelNames = virtual._getModelNamesForPopulate(this);\n          const populatedVal = this.$$populatedVirtuals[name];\n          if (!Array.isArray(populatedVal) && !populatedVal.$__ && modelNames?.length === 1) {\n            const PopulateModel = this.db.model(modelNames[0]);\n            this.$$populatedVirtuals[name] = PopulateModel.hydrate(populatedVal);\n          } else if (Array.isArray(populatedVal) && modelNames?.length === 1) {\n            const PopulateModel = this.db.model(modelNames[0]);\n            for (let i = 0; i < populatedVal.length; ++i) {\n              if (!populatedVal[i].$__) {\n                populatedVal[i] = PopulateModel.hydrate(populatedVal[i]);\n              }\n            }\n          }\n        }\n\n        mpath.unset(name, obj);\n      }\n    });\n\n    virtual.\n      set(function(v) {\n        if (!this.$$populatedVirtuals) {\n          this.$$populatedVirtuals = {};\n        }\n\n        return setPopulatedVirtualValue(\n          this.$$populatedVirtuals,\n          name,\n          v,\n          options\n        );\n      });\n\n    if (typeof options.get === 'function') {\n      virtual.get(options.get);\n    }\n\n    // Workaround for gh-8198: if virtual is under document array, make a fake\n    // virtual. See gh-8210, gh-13189\n    const parts = name.split('.');\n    let cur = parts[0];\n    for (let i = 0; i < parts.length - 1; ++i) {\n      if (this.paths[cur] == null) {\n        continue;\n      }\n\n      if (this.paths[cur].$isMongooseDocumentArray || this.paths[cur].$isSingleNested) {\n        const remnant = parts.slice(i + 1).join('.');\n        this.paths[cur].schema.virtual(remnant, options);\n        break;\n      }\n\n      cur += '.' + parts[i + 1];\n    }\n\n    return virtual;\n  }\n\n  const virtuals = this.virtuals;\n  const parts = name.split('.');\n\n  if (this.pathType(name) === 'real') {\n    throw new Error('Virtual path \"' + name + '\"' +\n      ' conflicts with a real path in the schema');\n  }\n\n  virtuals[name] = parts.reduce(function(mem, part, i) {\n    mem[part] || (mem[part] = (i === parts.length - 1)\n      ? new VirtualType(options, name)\n      : {});\n    return mem[part];\n  }, this.tree);\n\n  return virtuals[name];\n};\n\n/**\n * Returns the virtual type with the given `name`.\n *\n * @param {String} name The name of the Virtual to get\n * @return {VirtualType|null}\n */\n\nSchema.prototype.virtualpath = function(name) {\n  return this.virtuals.hasOwnProperty(name) ? this.virtuals[name] : null;\n};\n\n/**\n * Removes the given `path` (or [`paths`]).\n *\n * #### Example:\n *\n *     const schema = new Schema({ name: String, age: Number });\n *     schema.remove('name');\n *     schema.path('name'); // Undefined\n *     schema.path('age'); // SchemaNumber { ... }\n *\n * Or as a Array:\n *\n *     schema.remove(['name', 'age']);\n *     schema.path('name'); // Undefined\n *     schema.path('age'); // Undefined\n *\n * @param {String|Array} path The Path(s) to remove\n * @return {Schema} the Schema instance\n * @api public\n */\nSchema.prototype.remove = function(path) {\n  if (typeof path === 'string') {\n    path = [path];\n  }\n  if (Array.isArray(path)) {\n    path.forEach(function(name) {\n      if (this.path(name) == null && !this.nested[name]) {\n        return;\n      }\n      if (this.nested[name]) {\n        const allKeys = Object.keys(this.paths).\n          concat(Object.keys(this.nested));\n        for (const path of allKeys) {\n          if (path.startsWith(name + '.')) {\n            delete this.paths[path];\n            delete this.nested[path];\n            _deletePath(this, path);\n          }\n        }\n\n        delete this.nested[name];\n        _deletePath(this, name);\n        return;\n      }\n\n      delete this.paths[name];\n      _deletePath(this, name);\n    }, this);\n  }\n  return this;\n};\n\n/*!\n * ignore\n */\n\nfunction _deletePath(schema, name) {\n  const pieces = name.split('.');\n  const last = pieces.pop();\n\n  let branch = schema.tree;\n\n  for (const piece of pieces) {\n    branch = branch[piece];\n  }\n\n  delete branch[last];\n}\n\n/**\n * Removes the given virtual or virtuals from the schema.\n *\n * @param {String|Array} path The virutal path(s) to remove.\n * @returns {Schema} the Schema instance, or a mongoose error if the virtual does not exist.\n * @api public\n */\n\nSchema.prototype.removeVirtual = function(path) {\n  if (typeof path === 'string') {\n    path = [path];\n  }\n  if (Array.isArray(path)) {\n    for (const virtual of path) {\n      if (this.virtuals[virtual] == null) {\n        throw new MongooseError(`Attempting to remove virtual \"${virtual}\" that does not exist.`);\n      }\n    }\n\n    for (const virtual of path) {\n      delete this.paths[virtual];\n      delete this.virtuals[virtual];\n      if (virtual.indexOf('.') !== -1) {\n        mpath.unset(virtual, this.tree);\n      } else {\n        delete this.tree[virtual];\n      }\n    }\n  }\n  return this;\n};\n\n/**\n * Loads an ES6 class into a schema. Maps [setters](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Functions/set) + [getters](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Functions/get), [static methods](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Classes/static),\n * and [instance methods](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Classes#Class_body_and_method_definitions)\n * to schema [virtuals](https://mongoosejs.com/docs/guide.html#virtuals),\n * [statics](https://mongoosejs.com/docs/guide.html#statics), and\n * [methods](https://mongoosejs.com/docs/guide.html#methods).\n *\n * #### Example:\n *\n * ```javascript\n * const md5 = require('md5');\n * const userSchema = new Schema({ email: String });\n * class UserClass {\n *   // `gravatarImage` becomes a virtual\n *   get gravatarImage() {\n *     const hash = md5(this.email.toLowerCase());\n *     return `https://www.gravatar.com/avatar/${hash}`;\n *   }\n *\n *   // `getProfileUrl()` becomes a document method\n *   getProfileUrl() {\n *     return `https://mysite.com/${this.email}`;\n *   }\n *\n *   // `findByEmail()` becomes a static\n *   static findByEmail(email) {\n *     return this.findOne({ email });\n *   }\n * }\n *\n * // `schema` will now have a `gravatarImage` virtual, a `getProfileUrl()` method,\n * // and a `findByEmail()` static\n * userSchema.loadClass(UserClass);\n * ```\n *\n * @param {Function} model The Class to load\n * @param {Boolean} [virtualsOnly] if truthy, only pulls virtuals from the class, not methods or statics\n */\nSchema.prototype.loadClass = function(model, virtualsOnly) {\n  // Stop copying when hit certain base classes\n  if (model === Object.prototype ||\n      model === Function.prototype ||\n      model.prototype.hasOwnProperty('$isMongooseModelPrototype') ||\n      model.prototype.hasOwnProperty('$isMongooseDocumentPrototype')) {\n    return this;\n  }\n\n  this.loadClass(Object.getPrototypeOf(model), virtualsOnly);\n\n  // Add static methods\n  if (!virtualsOnly) {\n    Object.getOwnPropertyNames(model).forEach(function(name) {\n      if (name.match(/^(length|name|prototype|constructor|__proto__)$/)) {\n        return;\n      }\n      const prop = Object.getOwnPropertyDescriptor(model, name);\n      if (prop.hasOwnProperty('value')) {\n        this.static(name, prop.value);\n      }\n    }, this);\n  }\n\n  // Add methods and virtuals\n  Object.getOwnPropertyNames(model.prototype).forEach(function(name) {\n    if (name.match(/^(constructor)$/)) {\n      return;\n    }\n    const method = Object.getOwnPropertyDescriptor(model.prototype, name);\n    if (!virtualsOnly) {\n      if (typeof method.value === 'function') {\n        this.method(name, method.value);\n      }\n    }\n    if (typeof method.get === 'function') {\n      if (this.virtuals[name]) {\n        this.virtuals[name].getters = [];\n      }\n      this.virtual(name).get(method.get);\n    }\n    if (typeof method.set === 'function') {\n      if (this.virtuals[name]) {\n        this.virtuals[name].setters = [];\n      }\n      this.virtual(name).set(method.set);\n    }\n  }, this);\n\n  return this;\n};\n\n/*!\n * ignore\n */\n\nSchema.prototype._getSchema = function(path) {\n  const _this = this;\n  const pathschema = _this.path(path);\n  const resultPath = [];\n\n  if (pathschema) {\n    pathschema.$fullPath = path;\n    return pathschema;\n  }\n\n  function search(parts, schema) {\n    let p = parts.length + 1;\n    let foundschema;\n    let trypath;\n\n    while (p--) {\n      trypath = parts.slice(0, p).join('.');\n      foundschema = schema.path(trypath);\n      if (foundschema) {\n        resultPath.push(trypath);\n\n        if (foundschema.caster) {\n          // array of Mixed?\n          if (foundschema.caster instanceof MongooseTypes.Mixed) {\n            foundschema.caster.$fullPath = resultPath.join('.');\n            return foundschema.caster;\n          }\n\n          // Now that we found the array, we need to check if there\n          // are remaining document paths to look up for casting.\n          // Also we need to handle array.$.path since schema.path\n          // doesn't work for that.\n          // If there is no foundschema.schema we are dealing with\n          // a path like array.$\n          if (p !== parts.length) {\n            if (p + 1 === parts.length && foundschema.$embeddedSchemaType && (parts[p] === '$' || isArrayFilter(parts[p]))) {\n              return foundschema.$embeddedSchemaType;\n            }\n\n            if (foundschema.schema) {\n              let ret;\n              if (parts[p] === '$' || isArrayFilter(parts[p])) {\n                if (p + 1 === parts.length) {\n                  // comments.$\n                  return foundschema.$embeddedSchemaType;\n                }\n                // comments.$.comments.$.title\n                ret = search(parts.slice(p + 1), foundschema.schema);\n                if (ret) {\n                  ret.$parentSchemaDocArray = ret.$parentSchemaDocArray ||\n                    (foundschema.schema.$isSingleNested ? null : foundschema);\n                }\n                return ret;\n              }\n              // this is the last path of the selector\n              ret = search(parts.slice(p), foundschema.schema);\n              if (ret) {\n                ret.$parentSchemaDocArray = ret.$parentSchemaDocArray ||\n                  (foundschema.schema.$isSingleNested ? null : foundschema);\n              }\n              return ret;\n            }\n          }\n        } else if (foundschema.$isSchemaMap) {\n          if (p >= parts.length) {\n            return foundschema;\n          }\n          // Any path in the map will be an instance of the map's embedded schematype\n          if (p + 1 >= parts.length) {\n            return foundschema.$__schemaType;\n          }\n\n          if (foundschema.$__schemaType instanceof MongooseTypes.Mixed) {\n            return foundschema.$__schemaType;\n          }\n          if (foundschema.$__schemaType.schema != null) {\n            // Map of docs\n            const ret = search(parts.slice(p + 1), foundschema.$__schemaType.schema);\n            return ret;\n          }\n        }\n\n        foundschema.$fullPath = resultPath.join('.');\n\n        return foundschema;\n      }\n    }\n  }\n\n  // look for arrays\n  const parts = path.split('.');\n  for (let i = 0; i < parts.length; ++i) {\n    if (parts[i] === '$' || isArrayFilter(parts[i])) {\n      // Re: gh-5628, because `schema.path()` doesn't take $ into account.\n      parts[i] = '0';\n    }\n    if (numberRE.test(parts[i])) {\n      parts[i] = '$';\n    }\n  }\n  return search(parts, _this);\n};\n\n/*!\n * ignore\n */\n\nSchema.prototype._getPathType = function(path) {\n  const _this = this;\n  const pathschema = _this.path(path);\n\n  if (pathschema) {\n    return 'real';\n  }\n\n  function search(parts, schema) {\n    let p = parts.length + 1,\n        foundschema,\n        trypath;\n\n    while (p--) {\n      trypath = parts.slice(0, p).join('.');\n      foundschema = schema.path(trypath);\n      if (foundschema) {\n        if (foundschema.caster) {\n          // array of Mixed?\n          if (foundschema.caster instanceof MongooseTypes.Mixed) {\n            return { schema: foundschema, pathType: 'mixed' };\n          }\n\n          // Now that we found the array, we need to check if there\n          // are remaining document paths to look up for casting.\n          // Also we need to handle array.$.path since schema.path\n          // doesn't work for that.\n          // If there is no foundschema.schema we are dealing with\n          // a path like array.$\n          if (p !== parts.length && foundschema.schema) {\n            if (parts[p] === '$' || isArrayFilter(parts[p])) {\n              if (p === parts.length - 1) {\n                return { schema: foundschema, pathType: 'nested' };\n              }\n              // comments.$.comments.$.title\n              return search(parts.slice(p + 1), foundschema.schema);\n            }\n            // this is the last path of the selector\n            return search(parts.slice(p), foundschema.schema);\n          }\n          return {\n            schema: foundschema,\n            pathType: foundschema.$isSingleNested ? 'nested' : 'array'\n          };\n        }\n        return { schema: foundschema, pathType: 'real' };\n      } else if (p === parts.length && schema.nested[trypath]) {\n        return { schema: schema, pathType: 'nested' };\n      }\n    }\n    return { schema: foundschema || schema, pathType: 'undefined' };\n  }\n\n  // look for arrays\n  return search(path.split('.'), _this);\n};\n\n/*!\n * ignore\n */\n\nfunction isArrayFilter(piece) {\n  return piece.startsWith('$[') && piece.endsWith(']');\n}\n\n/**\n * Called by `compile()` _right before_ compiling. Good for making any changes to\n * the schema that should respect options set by plugins, like `id`\n * @method _preCompile\n * @memberOf Schema\n * @instance\n * @api private\n */\n\nSchema.prototype._preCompile = function _preCompile() {\n  this.plugin(idGetter, { deduplicate: true });\n};\n\n/*!\n * Module exports.\n */\n\nmodule.exports = exports = Schema;\n\n// require down here because of reference issues\n\n/**\n * The various built-in Mongoose Schema Types.\n *\n * #### Example:\n *\n *     const mongoose = require('mongoose');\n *     const ObjectId = mongoose.Schema.Types.ObjectId;\n *\n * #### Types:\n *\n * - [String](https://mongoosejs.com/docs/schematypes.html#strings)\n * - [Number](https://mongoosejs.com/docs/schematypes.html#numbers)\n * - [Boolean](https://mongoosejs.com/docs/schematypes.html#booleans) | Bool\n * - [Array](https://mongoosejs.com/docs/schematypes.html#arrays)\n * - [Buffer](https://mongoosejs.com/docs/schematypes.html#buffers)\n * - [Date](https://mongoosejs.com/docs/schematypes.html#dates)\n * - [ObjectId](https://mongoosejs.com/docs/schematypes.html#objectids) | Oid\n * - [Mixed](https://mongoosejs.com/docs/schematypes.html#mixed)\n * - [UUID](https://mongoosejs.com/docs/schematypes.html#uuid)\n * - [BigInt](https://mongoosejs.com/docs/schematypes.html#bigint)\n *\n * Using this exposed access to the `Mixed` SchemaType, we can use them in our schema.\n *\n *     const Mixed = mongoose.Schema.Types.Mixed;\n *     new mongoose.Schema({ _user: Mixed })\n *\n * @api public\n */\n\nSchema.Types = MongooseTypes = __webpack_require__(/*! ./schema/index */ \"./node_modules/mongoose/lib/schema/index.js\");\n\n/*!\n * ignore\n */\n\nexports.ObjectId = MongooseTypes.ObjectId;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schema.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schema/array.js":
/*!***************************************************!*\
  !*** ./node_modules/mongoose/lib/schema/array.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst $exists = __webpack_require__(/*! ./operators/exists */ \"./node_modules/mongoose/lib/schema/operators/exists.js\");\nconst $type = __webpack_require__(/*! ./operators/type */ \"./node_modules/mongoose/lib/schema/operators/type.js\");\nconst MongooseError = __webpack_require__(/*! ../error/mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\nconst SchemaArrayOptions = __webpack_require__(/*! ../options/schemaArrayOptions */ \"./node_modules/mongoose/lib/options/schemaArrayOptions.js\");\nconst SchemaType = __webpack_require__(/*! ../schemaType */ \"./node_modules/mongoose/lib/schemaType.js\");\nconst CastError = SchemaType.CastError;\nconst Mixed = __webpack_require__(/*! ./mixed */ \"./node_modules/mongoose/lib/schema/mixed.js\");\nconst arrayDepth = __webpack_require__(/*! ../helpers/arrayDepth */ \"./node_modules/mongoose/lib/helpers/arrayDepth.js\");\nconst cast = __webpack_require__(/*! ../cast */ \"./node_modules/mongoose/lib/cast.js\");\nconst clone = __webpack_require__(/*! ../helpers/clone */ \"./node_modules/mongoose/lib/helpers/clone.js\");\nconst isOperator = __webpack_require__(/*! ../helpers/query/isOperator */ \"./node_modules/mongoose/lib/helpers/query/isOperator.js\");\nconst util = __webpack_require__(/*! util */ \"util\");\nconst utils = __webpack_require__(/*! ../utils */ \"./node_modules/mongoose/lib/utils.js\");\nconst castToNumber = (__webpack_require__(/*! ./operators/helpers */ \"./node_modules/mongoose/lib/schema/operators/helpers.js\").castToNumber);\nconst geospatial = __webpack_require__(/*! ./operators/geospatial */ \"./node_modules/mongoose/lib/schema/operators/geospatial.js\");\nconst getDiscriminatorByValue = __webpack_require__(/*! ../helpers/discriminator/getDiscriminatorByValue */ \"./node_modules/mongoose/lib/helpers/discriminator/getDiscriminatorByValue.js\");\n\nlet MongooseArray;\nlet EmbeddedDoc;\n\nconst isNestedArraySymbol = Symbol('mongoose#isNestedArray');\nconst emptyOpts = Object.freeze({});\n\n/**\n * Array SchemaType constructor\n *\n * @param {String} key\n * @param {SchemaType} cast\n * @param {Object} options\n * @param {Object} schemaOptions\n * @inherits SchemaType\n * @api public\n */\n\nfunction SchemaArray(key, cast, options, schemaOptions) {\n  // lazy load\n  EmbeddedDoc || (EmbeddedDoc = (__webpack_require__(/*! ../types */ \"./node_modules/mongoose/lib/types/index.js\").Embedded));\n\n  let typeKey = 'type';\n  if (schemaOptions && schemaOptions.typeKey) {\n    typeKey = schemaOptions.typeKey;\n  }\n  this.schemaOptions = schemaOptions;\n\n  if (cast) {\n    let castOptions = {};\n\n    if (utils.isPOJO(cast)) {\n      if (cast[typeKey]) {\n        // support { type: Woot }\n        castOptions = clone(cast); // do not alter user arguments\n        delete castOptions[typeKey];\n        cast = cast[typeKey];\n      } else {\n        cast = Mixed;\n      }\n    }\n\n    if (options != null && options.ref != null && castOptions.ref == null) {\n      castOptions.ref = options.ref;\n    }\n\n    if (cast === Object) {\n      cast = Mixed;\n    }\n\n    // support { type: 'String' }\n    const name = typeof cast === 'string'\n      ? cast\n      : utils.getFunctionName(cast);\n\n    const Types = __webpack_require__(/*! ./index.js */ \"./node_modules/mongoose/lib/schema/index.js\");\n    const caster = Types.hasOwnProperty(name) ? Types[name] : cast;\n\n    this.casterConstructor = caster;\n\n    if (this.casterConstructor instanceof SchemaArray) {\n      this.casterConstructor[isNestedArraySymbol] = true;\n    }\n\n    if (typeof caster === 'function' &&\n        !caster.$isArraySubdocument &&\n        !caster.$isSchemaMap) {\n      const path = this.caster instanceof EmbeddedDoc ? null : key;\n      this.caster = new caster(path, castOptions);\n    } else {\n      this.caster = caster;\n      if (!(this.caster instanceof EmbeddedDoc)) {\n        this.caster.path = key;\n      }\n    }\n\n    this.$embeddedSchemaType = this.caster;\n  }\n\n  this.$isMongooseArray = true;\n\n  SchemaType.call(this, key, options, 'Array');\n\n  let defaultArr;\n  let fn;\n\n  if (this.defaultValue != null) {\n    defaultArr = this.defaultValue;\n    fn = typeof defaultArr === 'function';\n  }\n\n  if (!('defaultValue' in this) || this.defaultValue != null) {\n    const defaultFn = function() {\n      // Leave it up to `cast()` to convert the array\n      return fn\n        ? defaultArr.call(this)\n        : defaultArr != null\n          ? [].concat(defaultArr)\n          : [];\n    };\n    defaultFn.$runBeforeSetters = !fn;\n    this.default(defaultFn);\n  }\n}\n\n/**\n * This schema type's name, to defend against minifiers that mangle\n * function names.\n *\n * @api public\n */\nSchemaArray.schemaName = 'Array';\n\n\n/**\n * Options for all arrays.\n *\n * - `castNonArrays`: `true` by default. If `false`, Mongoose will throw a CastError when a value isn't an array. If `true`, Mongoose will wrap the provided value in an array before casting.\n *\n * @static\n * @api public\n */\n\nSchemaArray.options = { castNonArrays: true };\n\n/*!\n * ignore\n */\n\nSchemaArray.defaultOptions = {};\n\n/**\n * Sets a default option for all Array instances.\n *\n * #### Example:\n *\n *     // Make all Array instances have `required` of true by default.\n *     mongoose.Schema.Array.set('required', true);\n *\n *     const User = mongoose.model('User', new Schema({ test: Array }));\n *     new User({ }).validateSync().errors.test.message; // Path `test` is required.\n *\n * @param {String} option The option you'd like to set the value for\n * @param {Any} value value for option\n * @return {undefined}\n * @function set\n * @api public\n */\nSchemaArray.set = SchemaType.set;\n\nSchemaArray.setters = [];\n\n/**\n * Attaches a getter for all Array instances\n *\n * @param {Function} getter\n * @return {this}\n * @function get\n * @static\n * @api public\n */\n\nSchemaArray.get = SchemaType.get;\n\n/*!\n * Inherits from SchemaType.\n */\nSchemaArray.prototype = Object.create(SchemaType.prototype);\nSchemaArray.prototype.constructor = SchemaArray;\nSchemaArray.prototype.OptionsConstructor = SchemaArrayOptions;\n\n/*!\n * ignore\n */\n\nSchemaArray._checkRequired = SchemaType.prototype.checkRequired;\n\n/**\n * Override the function the required validator uses to check whether an array\n * passes the `required` check.\n *\n * #### Example:\n *\n *     // Require non-empty array to pass `required` check\n *     mongoose.Schema.Types.Array.checkRequired(v => Array.isArray(v) && v.length);\n *\n *     const M = mongoose.model({ arr: { type: Array, required: true } });\n *     new M({ arr: [] }).validateSync(); // `null`, validation fails!\n *\n * @param {Function} fn\n * @return {Function}\n * @function checkRequired\n * @api public\n */\n\nSchemaArray.checkRequired = SchemaType.checkRequired;\n\n/**\n * Check if the given value satisfies the `required` validator.\n *\n * @param {Any} value\n * @param {Document} doc\n * @return {Boolean}\n * @api public\n */\n\nSchemaArray.prototype.checkRequired = function checkRequired(value, doc) {\n  if (typeof value === 'object' && SchemaType._isRef(this, value, doc, true)) {\n    return !!value;\n  }\n\n  // `require('util').inherits()` does **not** copy static properties, and\n  // plugins like mongoose-float use `inherits()` for pre-ES6.\n  const _checkRequired = typeof this.constructor.checkRequired === 'function' ?\n    this.constructor.checkRequired() :\n    SchemaArray.checkRequired();\n\n  return _checkRequired(value);\n};\n\n/**\n * Adds an enum validator if this is an array of strings or numbers. Equivalent to\n * `SchemaString.prototype.enum()` or `SchemaNumber.prototype.enum()`\n *\n * @param {...String|Object} [args] enumeration values\n * @return {SchemaArray} this\n */\n\nSchemaArray.prototype.enum = function() {\n  let arr = this;\n  while (true) {\n    const instance = arr &&\n    arr.caster &&\n    arr.caster.instance;\n    if (instance === 'Array') {\n      arr = arr.caster;\n      continue;\n    }\n    if (instance !== 'String' && instance !== 'Number') {\n      throw new Error('`enum` can only be set on an array of strings or numbers ' +\n        ', not ' + instance);\n    }\n    break;\n  }\n\n  let enumArray = arguments;\n  if (!Array.isArray(arguments) && utils.isObject(arguments)) {\n    enumArray = utils.object.vals(enumArray);\n  }\n\n  arr.caster.enum.apply(arr.caster, enumArray);\n  return this;\n};\n\n/**\n * Overrides the getters application for the population special-case\n *\n * @param {Object} value\n * @param {Object} scope\n * @api private\n */\n\nSchemaArray.prototype.applyGetters = function(value, scope) {\n  if (scope != null && scope.$__ != null && scope.$populated(this.path)) {\n    // means the object id was populated\n    return value;\n  }\n\n  const ret = SchemaType.prototype.applyGetters.call(this, value, scope);\n  return ret;\n};\n\nSchemaArray.prototype._applySetters = function(value, scope, init, priorVal) {\n  if (this.casterConstructor.$isMongooseArray &&\n      SchemaArray.options.castNonArrays &&\n      !this[isNestedArraySymbol]) {\n    // Check nesting levels and wrap in array if necessary\n    let depth = 0;\n    let arr = this;\n    while (arr != null &&\n      arr.$isMongooseArray &&\n      !arr.$isMongooseDocumentArray) {\n      ++depth;\n      arr = arr.casterConstructor;\n    }\n\n    // No need to wrap empty arrays\n    if (value != null && value.length !== 0) {\n      const valueDepth = arrayDepth(value);\n      if (valueDepth.min === valueDepth.max && valueDepth.max < depth && valueDepth.containsNonArrayItem) {\n        for (let i = valueDepth.max; i < depth; ++i) {\n          value = [value];\n        }\n      }\n    }\n  }\n\n  return SchemaType.prototype._applySetters.call(this, value, scope, init, priorVal);\n};\n\n/**\n * Casts values for set().\n *\n * @param {Object} value\n * @param {Document} doc document that triggers the casting\n * @param {Boolean} init whether this is an initialization cast\n * @api private\n */\n\nSchemaArray.prototype.cast = function(value, doc, init, prev, options) {\n  // lazy load\n  MongooseArray || (MongooseArray = (__webpack_require__(/*! ../types */ \"./node_modules/mongoose/lib/types/index.js\").Array));\n\n  let i;\n  let l;\n\n  if (Array.isArray(value)) {\n    const len = value.length;\n    if (!len && doc) {\n      const indexes = doc.schema.indexedPaths();\n\n      const arrayPath = this.path;\n      for (i = 0, l = indexes.length; i < l; ++i) {\n        const pathIndex = indexes[i][0][arrayPath];\n        if (pathIndex === '2dsphere' || pathIndex === '2d') {\n          return;\n        }\n      }\n\n      // Special case: if this index is on the parent of what looks like\n      // GeoJSON, skip setting the default to empty array re: #1668, #3233\n      const arrayGeojsonPath = this.path.endsWith('.coordinates') ?\n        this.path.substring(0, this.path.lastIndexOf('.')) : null;\n      if (arrayGeojsonPath != null) {\n        for (i = 0, l = indexes.length; i < l; ++i) {\n          const pathIndex = indexes[i][0][arrayGeojsonPath];\n          if (pathIndex === '2dsphere') {\n            return;\n          }\n        }\n      }\n    }\n\n    options = options || emptyOpts;\n\n    let rawValue = utils.isMongooseArray(value) ? value.__array : value;\n    let path = options.path || this.path;\n    if (options.arrayPathIndex != null) {\n      path += '.' + options.arrayPathIndex;\n    }\n    value = MongooseArray(rawValue, path, doc, this);\n    rawValue = value.__array;\n\n    if (init && doc != null && doc.$__ != null && doc.$populated(this.path)) {\n      return value;\n    }\n\n    const caster = this.caster;\n    const isMongooseArray = caster.$isMongooseArray;\n    if (caster && this.casterConstructor !== Mixed) {\n      try {\n        const len = rawValue.length;\n        for (i = 0; i < len; i++) {\n          const opts = {};\n          // Perf: creating `arrayPath` is expensive for large arrays.\n          // We only need `arrayPath` if this is a nested array, so\n          // skip if possible.\n          if (isMongooseArray) {\n            if (options.arrayPath != null) {\n              opts.arrayPathIndex = i;\n            } else if (caster._arrayParentPath != null) {\n              opts.arrayPathIndex = i;\n            }\n          }\n          rawValue[i] = caster.applySetters(rawValue[i], doc, init, void 0, opts);\n        }\n      } catch (e) {\n        // rethrow\n        throw new CastError('[' + e.kind + ']', util.inspect(value), this.path + '.' + i, e, this);\n      }\n    }\n\n    return value;\n  }\n\n  const castNonArraysOption = this.options.castNonArrays != null ? this.options.castNonArrays : SchemaArray.options.castNonArrays;\n  if (init || castNonArraysOption) {\n    // gh-2442: if we're loading this from the db and its not an array, mark\n    // the whole array as modified.\n    if (!!doc && !!init) {\n      doc.markModified(this.path);\n    }\n    return this.cast([value], doc, init);\n  }\n\n  throw new CastError('Array', util.inspect(value), this.path, null, this);\n};\n\n/*!\n * ignore\n */\n\nSchemaArray.prototype._castForPopulate = function _castForPopulate(value, doc) {\n  // lazy load\n  MongooseArray || (MongooseArray = (__webpack_require__(/*! ../types */ \"./node_modules/mongoose/lib/types/index.js\").Array));\n\n  if (Array.isArray(value)) {\n    let i;\n    const rawValue = value.__array ? value.__array : value;\n    const len = rawValue.length;\n\n    const caster = this.caster;\n    if (caster && this.casterConstructor !== Mixed) {\n      try {\n        for (i = 0; i < len; i++) {\n          const opts = {};\n          // Perf: creating `arrayPath` is expensive for large arrays.\n          // We only need `arrayPath` if this is a nested array, so\n          // skip if possible.\n          if (caster.$isMongooseArray && caster._arrayParentPath != null) {\n            opts.arrayPathIndex = i;\n          }\n\n          rawValue[i] = caster.cast(rawValue[i], doc, false, void 0, opts);\n        }\n      } catch (e) {\n        // rethrow\n        throw new CastError('[' + e.kind + ']', util.inspect(value), this.path + '.' + i, e, this);\n      }\n    }\n\n    return value;\n  }\n\n  throw new CastError('Array', util.inspect(value), this.path, null, this);\n};\n\nSchemaArray.prototype.$toObject = SchemaArray.prototype.toObject;\n\n/*!\n * ignore\n */\n\nSchemaArray.prototype.discriminator = function(...args) {\n  let arr = this;\n  while (arr.$isMongooseArray && !arr.$isMongooseDocumentArray) {\n    arr = arr.casterConstructor;\n    if (arr == null || typeof arr === 'function') {\n      throw new MongooseError('You can only add an embedded discriminator on ' +\n        'a document array, ' + this.path + ' is a plain array');\n    }\n  }\n  return arr.discriminator(...args);\n};\n\n/*!\n * ignore\n */\n\nSchemaArray.prototype.clone = function() {\n  const options = Object.assign({}, this.options);\n  const schematype = new this.constructor(this.path, this.caster, options, this.schemaOptions);\n  schematype.validators = this.validators.slice();\n  if (this.requiredValidator !== undefined) {\n    schematype.requiredValidator = this.requiredValidator;\n  }\n  return schematype;\n};\n\nSchemaArray.prototype._castForQuery = function(val, context) {\n  let Constructor = this.casterConstructor;\n\n  if (val &&\n      Constructor.discriminators &&\n      Constructor.schema &&\n      Constructor.schema.options &&\n      Constructor.schema.options.discriminatorKey) {\n    if (typeof val[Constructor.schema.options.discriminatorKey] === 'string' &&\n        Constructor.discriminators[val[Constructor.schema.options.discriminatorKey]]) {\n      Constructor = Constructor.discriminators[val[Constructor.schema.options.discriminatorKey]];\n    } else {\n      const constructorByValue = getDiscriminatorByValue(Constructor.discriminators, val[Constructor.schema.options.discriminatorKey]);\n      if (constructorByValue) {\n        Constructor = constructorByValue;\n      }\n    }\n  }\n\n  const proto = this.casterConstructor.prototype;\n  const protoCastForQuery = proto && proto.castForQuery;\n  const protoCast = proto && proto.cast;\n  const constructorCastForQuery = Constructor.castForQuery;\n  const caster = this.caster;\n\n  if (Array.isArray(val)) {\n    this.setters.reverse().forEach(setter => {\n      val = setter.call(this, val, this);\n    });\n    val = val.map(function(v) {\n      if (utils.isObject(v) && v.$elemMatch) {\n        return v;\n      }\n      if (protoCastForQuery) {\n        v = protoCastForQuery.call(caster, null, v, context);\n        return v;\n      } else if (protoCast) {\n        v = protoCast.call(caster, v);\n        return v;\n      } else if (constructorCastForQuery) {\n        v = constructorCastForQuery.call(caster, null, v, context);\n        return v;\n      }\n      if (v != null) {\n        v = new Constructor(v);\n        return v;\n      }\n      return v;\n    });\n  } else if (protoCastForQuery) {\n    val = protoCastForQuery.call(caster, null, val, context);\n  } else if (protoCast) {\n    val = protoCast.call(caster, val);\n  } else if (constructorCastForQuery) {\n    val = constructorCastForQuery.call(caster, null, val, context);\n  } else if (val != null) {\n    val = new Constructor(val);\n  }\n\n  return val;\n};\n\n/**\n * Casts values for queries.\n *\n * @param {String} $conditional\n * @param {any} [value]\n * @api private\n */\n\nSchemaArray.prototype.castForQuery = function($conditional, val, context) {\n  let handler;\n\n  if ($conditional != null) {\n    handler = this.$conditionalHandlers[$conditional];\n\n    if (!handler) {\n      throw new Error('Can\\'t use ' + $conditional + ' with Array.');\n    }\n\n    return handler.call(this, val, context);\n  } else {\n    return this._castForQuery(val, context);\n  }\n};\n\nfunction cast$all(val, context) {\n  if (!Array.isArray(val)) {\n    val = [val];\n  }\n\n  val = val.map((v) => {\n    if (!utils.isObject(v)) {\n      return v;\n    }\n    if (v.$elemMatch != null) {\n      return { $elemMatch: cast(this.casterConstructor.schema, v.$elemMatch, null, this && this.$$context) };\n    }\n\n    const o = {};\n    o[this.path] = v;\n    return cast(this.casterConstructor.schema, o, null, this && this.$$context)[this.path];\n  }, this);\n\n  return this.castForQuery(null, val, context);\n}\n\nfunction cast$elemMatch(val, context) {\n  const keys = Object.keys(val);\n  const numKeys = keys.length;\n  for (let i = 0; i < numKeys; ++i) {\n    const key = keys[i];\n    const value = val[key];\n    if (isOperator(key) && value != null) {\n      val[key] = this.castForQuery(key, value, context);\n    }\n  }\n\n  return val;\n}\n\nconst handle = SchemaArray.prototype.$conditionalHandlers = {};\n\nhandle.$all = cast$all;\nhandle.$options = String;\nhandle.$elemMatch = cast$elemMatch;\nhandle.$geoIntersects = geospatial.cast$geoIntersects;\nhandle.$or = createLogicalQueryOperatorHandler('$or');\nhandle.$and = createLogicalQueryOperatorHandler('$and');\nhandle.$nor = createLogicalQueryOperatorHandler('$nor');\n\nfunction createLogicalQueryOperatorHandler(op) {\n  return function logicalQueryOperatorHandler(val, context) {\n    if (!Array.isArray(val)) {\n      throw new TypeError('conditional ' + op + ' requires an array');\n    }\n\n    const ret = [];\n    for (const obj of val) {\n      ret.push(cast(this.casterConstructor.schema ?? context.schema, obj, null, this && this.$$context));\n    }\n\n    return ret;\n  };\n}\n\nhandle.$near =\nhandle.$nearSphere = geospatial.cast$near;\n\nhandle.$within =\nhandle.$geoWithin = geospatial.cast$within;\n\nhandle.$size =\nhandle.$minDistance =\nhandle.$maxDistance = castToNumber;\n\nhandle.$exists = $exists;\nhandle.$type = $type;\n\nhandle.$eq =\nhandle.$gt =\nhandle.$gte =\nhandle.$lt =\nhandle.$lte =\nhandle.$not =\nhandle.$regex =\nhandle.$ne = SchemaArray.prototype._castForQuery;\n\n// `$in` is special because you can also include an empty array in the query\n// like `$in: [1, []]`, see gh-5913\nhandle.$nin = SchemaType.prototype.$conditionalHandlers.$nin;\nhandle.$in = SchemaType.prototype.$conditionalHandlers.$in;\n\n/*!\n * Module exports.\n */\n\nmodule.exports = SchemaArray;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schema/array.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schema/bigint.js":
/*!****************************************************!*\
  !*** ./node_modules/mongoose/lib/schema/bigint.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst CastError = __webpack_require__(/*! ../error/cast */ \"./node_modules/mongoose/lib/error/cast.js\");\nconst SchemaType = __webpack_require__(/*! ../schemaType */ \"./node_modules/mongoose/lib/schemaType.js\");\nconst castBigInt = __webpack_require__(/*! ../cast/bigint */ \"./node_modules/mongoose/lib/cast/bigint.js\");\n\n/**\n * BigInt SchemaType constructor.\n *\n * @param {String} path\n * @param {Object} options\n * @inherits SchemaType\n * @api public\n */\n\nfunction SchemaBigInt(path, options) {\n  SchemaType.call(this, path, options, 'BigInt');\n}\n\n/**\n * This schema type's name, to defend against minifiers that mangle\n * function names.\n *\n * @api public\n */\nSchemaBigInt.schemaName = 'BigInt';\n\nSchemaBigInt.defaultOptions = {};\n\n/*!\n * Inherits from SchemaType.\n */\nSchemaBigInt.prototype = Object.create(SchemaType.prototype);\nSchemaBigInt.prototype.constructor = SchemaBigInt;\n\n/*!\n * ignore\n */\n\nSchemaBigInt._cast = castBigInt;\n\n/**\n * Sets a default option for all BigInt instances.\n *\n * #### Example:\n *\n *     // Make all bigints required by default\n *     mongoose.Schema.BigInt.set('required', true);\n *\n * @param {String} option The option you'd like to set the value for\n * @param {Any} value value for option\n * @return {undefined}\n * @function set\n * @static\n * @api public\n */\n\nSchemaBigInt.set = SchemaType.set;\n\nSchemaBigInt.setters = [];\n\n/**\n * Attaches a getter for all BigInt instances\n *\n * #### Example:\n *\n *     // Convert bigints to numbers\n *     mongoose.Schema.BigInt.get(v => v == null ? v : Number(v));\n *\n * @param {Function} getter\n * @return {this}\n * @function get\n * @static\n * @api public\n */\n\nSchemaBigInt.get = SchemaType.get;\n\n/**\n * Get/set the function used to cast arbitrary values to booleans.\n *\n * #### Example:\n *\n *     // Make Mongoose cast empty string '' to false.\n *     const original = mongoose.Schema.BigInt.cast();\n *     mongoose.Schema.BigInt.cast(v => {\n *       if (v === '') {\n *         return false;\n *       }\n *       return original(v);\n *     });\n *\n *     // Or disable casting entirely\n *     mongoose.Schema.BigInt.cast(false);\n *\n * @param {Function} caster\n * @return {Function}\n * @function get\n * @static\n * @api public\n */\n\nSchemaBigInt.cast = function cast(caster) {\n  if (arguments.length === 0) {\n    return this._cast;\n  }\n  if (caster === false) {\n    caster = this._defaultCaster;\n  }\n  this._cast = caster;\n\n  return this._cast;\n};\n\n/*!\n * ignore\n */\n\nSchemaBigInt._checkRequired = v => v != null;\n\n/**\n * Override the function the required validator uses to check whether a value\n * passes the `required` check.\n *\n * @param {Function} fn\n * @return {Function}\n * @function checkRequired\n * @static\n * @api public\n */\n\nSchemaBigInt.checkRequired = SchemaType.checkRequired;\n\n/**\n * Check if the given value satisfies a required validator.\n *\n * @param {Any} value\n * @return {Boolean}\n * @api public\n */\n\nSchemaBigInt.prototype.checkRequired = function(value) {\n  return this.constructor._checkRequired(value);\n};\n\n/**\n * Casts to bigint\n *\n * @param {Object} value\n * @param {Object} model this value is optional\n * @api private\n */\n\nSchemaBigInt.prototype.cast = function(value) {\n  let castBigInt;\n  if (typeof this._castFunction === 'function') {\n    castBigInt = this._castFunction;\n  } else if (typeof this.constructor.cast === 'function') {\n    castBigInt = this.constructor.cast();\n  } else {\n    castBigInt = SchemaBigInt.cast();\n  }\n\n  try {\n    return castBigInt(value);\n  } catch (error) {\n    throw new CastError('BigInt', value, this.path, error, this);\n  }\n};\n\n/*!\n * ignore\n */\n\nSchemaBigInt.$conditionalHandlers = {\n  ...SchemaType.prototype.$conditionalHandlers,\n  $gt: handleSingle,\n  $gte: handleSingle,\n  $lt: handleSingle,\n  $lte: handleSingle\n};\n\n/*!\n * ignore\n */\n\nfunction handleSingle(val, context) {\n  return this.castForQuery(null, val, context);\n}\n\n/**\n * Casts contents for queries.\n *\n * @param {String} $conditional\n * @param {any} val\n * @api private\n */\n\nSchemaBigInt.prototype.castForQuery = function($conditional, val, context) {\n  let handler;\n  if ($conditional != null) {\n    handler = SchemaBigInt.$conditionalHandlers[$conditional];\n\n    if (handler) {\n      return handler.call(this, val);\n    }\n\n    return this.applySetters(null, val, context);\n  }\n\n  try {\n    return this.applySetters(val, context);\n  } catch (err) {\n    if (err instanceof CastError && err.path === this.path && this.$fullPath != null) {\n      err.path = this.$fullPath;\n    }\n    throw err;\n  }\n};\n\n/**\n *\n * @api private\n */\n\nSchemaBigInt.prototype._castNullish = function _castNullish(v) {\n  if (typeof v === 'undefined') {\n    return v;\n  }\n  const castBigInt = typeof this.constructor.cast === 'function' ?\n    this.constructor.cast() :\n    SchemaBigInt.cast();\n  if (castBigInt == null) {\n    return v;\n  }\n  return v;\n};\n\n/*!\n * Module exports.\n */\n\nmodule.exports = SchemaBigInt;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schema/bigint.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schema/boolean.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongoose/lib/schema/boolean.js ***!
  \*****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst CastError = __webpack_require__(/*! ../error/cast */ \"./node_modules/mongoose/lib/error/cast.js\");\nconst SchemaType = __webpack_require__(/*! ../schemaType */ \"./node_modules/mongoose/lib/schemaType.js\");\nconst castBoolean = __webpack_require__(/*! ../cast/boolean */ \"./node_modules/mongoose/lib/cast/boolean.js\");\n\n/**\n * Boolean SchemaType constructor.\n *\n * @param {String} path\n * @param {Object} options\n * @inherits SchemaType\n * @api public\n */\n\nfunction SchemaBoolean(path, options) {\n  SchemaType.call(this, path, options, 'Boolean');\n}\n\n/**\n * This schema type's name, to defend against minifiers that mangle\n * function names.\n *\n * @api public\n */\nSchemaBoolean.schemaName = 'Boolean';\n\nSchemaBoolean.defaultOptions = {};\n\n/*!\n * Inherits from SchemaType.\n */\nSchemaBoolean.prototype = Object.create(SchemaType.prototype);\nSchemaBoolean.prototype.constructor = SchemaBoolean;\n\n/*!\n * ignore\n */\n\nSchemaBoolean._cast = castBoolean;\n\n/**\n * Sets a default option for all Boolean instances.\n *\n * #### Example:\n *\n *     // Make all booleans have `default` of false.\n *     mongoose.Schema.Boolean.set('default', false);\n *\n *     const Order = mongoose.model('Order', new Schema({ isPaid: Boolean }));\n *     new Order({ }).isPaid; // false\n *\n * @param {String} option The option you'd like to set the value for\n * @param {Any} value value for option\n * @return {undefined}\n * @function set\n * @static\n * @api public\n */\n\nSchemaBoolean.set = SchemaType.set;\n\nSchemaBoolean.setters = [];\n\n/**\n * Attaches a getter for all Boolean instances\n *\n * #### Example:\n *\n *     mongoose.Schema.Boolean.get(v => v === true ? 'yes' : 'no');\n *\n *     const Order = mongoose.model('Order', new Schema({ isPaid: Boolean }));\n *     new Order({ isPaid: false }).isPaid; // 'no'\n *\n * @param {Function} getter\n * @return {this}\n * @function get\n * @static\n * @api public\n */\n\nSchemaBoolean.get = SchemaType.get;\n\n/**\n * Get/set the function used to cast arbitrary values to booleans.\n *\n * #### Example:\n *\n *     // Make Mongoose cast empty string '' to false.\n *     const original = mongoose.Schema.Boolean.cast();\n *     mongoose.Schema.Boolean.cast(v => {\n *       if (v === '') {\n *         return false;\n *       }\n *       return original(v);\n *     });\n *\n *     // Or disable casting entirely\n *     mongoose.Schema.Boolean.cast(false);\n *\n * @param {Function} caster\n * @return {Function}\n * @function get\n * @static\n * @api public\n */\n\nSchemaBoolean.cast = function cast(caster) {\n  if (arguments.length === 0) {\n    return this._cast;\n  }\n  if (caster === false) {\n    caster = this._defaultCaster;\n  }\n  this._cast = caster;\n\n  return this._cast;\n};\n\n/*!\n * ignore\n */\n\nSchemaBoolean._defaultCaster = v => {\n  if (v != null && typeof v !== 'boolean') {\n    throw new Error();\n  }\n  return v;\n};\n\n/*!\n * ignore\n */\n\nSchemaBoolean._checkRequired = v => v === true || v === false;\n\n/**\n * Override the function the required validator uses to check whether a boolean\n * passes the `required` check.\n *\n * @param {Function} fn\n * @return {Function}\n * @function checkRequired\n * @static\n * @api public\n */\n\nSchemaBoolean.checkRequired = SchemaType.checkRequired;\n\n/**\n * Check if the given value satisfies a required validator. For a boolean\n * to satisfy a required validator, it must be strictly equal to true or to\n * false.\n *\n * @param {Any} value\n * @return {Boolean}\n * @api public\n */\n\nSchemaBoolean.prototype.checkRequired = function(value) {\n  return this.constructor._checkRequired(value);\n};\n\n/**\n * Configure which values get casted to `true`.\n *\n * #### Example:\n *\n *     const M = mongoose.model('Test', new Schema({ b: Boolean }));\n *     new M({ b: 'affirmative' }).b; // undefined\n *     mongoose.Schema.Boolean.convertToTrue.add('affirmative');\n *     new M({ b: 'affirmative' }).b; // true\n *\n * @property convertToTrue\n * @static\n * @memberOf SchemaBoolean\n * @type {Set}\n * @api public\n */\n\nObject.defineProperty(SchemaBoolean, 'convertToTrue', {\n  get: () => castBoolean.convertToTrue,\n  set: v => { castBoolean.convertToTrue = v; }\n});\n\n/**\n * Configure which values get casted to `false`.\n *\n * #### Example:\n *\n *     const M = mongoose.model('Test', new Schema({ b: Boolean }));\n *     new M({ b: 'nay' }).b; // undefined\n *     mongoose.Schema.Types.Boolean.convertToFalse.add('nay');\n *     new M({ b: 'nay' }).b; // false\n *\n * @property convertToFalse\n * @static\n * @memberOf SchemaBoolean\n * @type {Set}\n * @api public\n */\n\nObject.defineProperty(SchemaBoolean, 'convertToFalse', {\n  get: () => castBoolean.convertToFalse,\n  set: v => { castBoolean.convertToFalse = v; }\n});\n\n/**\n * Casts to boolean\n *\n * @param {Object} value\n * @param {Object} model this value is optional\n * @api private\n */\n\nSchemaBoolean.prototype.cast = function(value) {\n  let castBoolean;\n  if (typeof this._castFunction === 'function') {\n    castBoolean = this._castFunction;\n  } else if (typeof this.constructor.cast === 'function') {\n    castBoolean = this.constructor.cast();\n  } else {\n    castBoolean = SchemaBoolean.cast();\n  }\n\n  try {\n    return castBoolean(value);\n  } catch (error) {\n    throw new CastError('Boolean', value, this.path, error, this);\n  }\n};\n\nSchemaBoolean.$conditionalHandlers = { ...SchemaType.prototype.$conditionalHandlers };\n\n/**\n * Casts contents for queries.\n *\n * @param {String} $conditional\n * @param {any} val\n * @api private\n */\n\nSchemaBoolean.prototype.castForQuery = function($conditional, val, context) {\n  let handler;\n  if ($conditional != null) {\n    handler = SchemaBoolean.$conditionalHandlers[$conditional];\n\n    if (handler) {\n      return handler.call(this, val);\n    }\n\n    return this.applySetters(null, val, context);\n  }\n\n  try {\n    return this.applySetters(val, context);\n  } catch (err) {\n    if (err instanceof CastError && err.path === this.path && this.$fullPath != null) {\n      err.path = this.$fullPath;\n    }\n    throw err;\n  }\n};\n\n/**\n *\n * @api private\n */\n\nSchemaBoolean.prototype._castNullish = function _castNullish(v) {\n  if (typeof v === 'undefined') {\n    return v;\n  }\n  const castBoolean = typeof this.constructor.cast === 'function' ?\n    this.constructor.cast() :\n    SchemaBoolean.cast();\n  if (castBoolean == null) {\n    return v;\n  }\n  if (castBoolean.convertToFalse instanceof Set && castBoolean.convertToFalse.has(v)) {\n    return false;\n  }\n  if (castBoolean.convertToTrue instanceof Set && castBoolean.convertToTrue.has(v)) {\n    return true;\n  }\n  return v;\n};\n\n/*!\n * Module exports.\n */\n\nmodule.exports = SchemaBoolean;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schema/boolean.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schema/buffer.js":
/*!****************************************************!*\
  !*** ./node_modules/mongoose/lib/schema/buffer.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module dependencies.\n */\n\n\n\nconst MongooseBuffer = __webpack_require__(/*! ../types/buffer */ \"./node_modules/mongoose/lib/types/buffer.js\");\nconst SchemaBufferOptions = __webpack_require__(/*! ../options/schemaBufferOptions */ \"./node_modules/mongoose/lib/options/schemaBufferOptions.js\");\nconst SchemaType = __webpack_require__(/*! ../schemaType */ \"./node_modules/mongoose/lib/schemaType.js\");\nconst handleBitwiseOperator = __webpack_require__(/*! ./operators/bitwise */ \"./node_modules/mongoose/lib/schema/operators/bitwise.js\");\nconst utils = __webpack_require__(/*! ../utils */ \"./node_modules/mongoose/lib/utils.js\");\n\nconst Binary = MongooseBuffer.Binary;\nconst CastError = SchemaType.CastError;\n\n/**\n * Buffer SchemaType constructor\n *\n * @param {String} key\n * @param {Object} options\n * @inherits SchemaType\n * @api public\n */\n\nfunction SchemaBuffer(key, options) {\n  SchemaType.call(this, key, options, 'Buffer');\n}\n\n/**\n * This schema type's name, to defend against minifiers that mangle\n * function names.\n *\n * @api public\n */\nSchemaBuffer.schemaName = 'Buffer';\n\nSchemaBuffer.defaultOptions = {};\n\n/*!\n * Inherits from SchemaType.\n */\nSchemaBuffer.prototype = Object.create(SchemaType.prototype);\nSchemaBuffer.prototype.constructor = SchemaBuffer;\nSchemaBuffer.prototype.OptionsConstructor = SchemaBufferOptions;\n\n/*!\n * ignore\n */\n\nSchemaBuffer._checkRequired = v => !!(v && v.length);\n\n/**\n * Sets a default option for all Buffer instances.\n *\n * #### Example:\n *\n *     // Make all buffers have `required` of true by default.\n *     mongoose.Schema.Buffer.set('required', true);\n *\n *     const User = mongoose.model('User', new Schema({ test: Buffer }));\n *     new User({ }).validateSync().errors.test.message; // Path `test` is required.\n *\n * @param {String} option The option you'd like to set the value for\n * @param {Any} value value for option\n * @return {undefined}\n * @function set\n * @static\n * @api public\n */\n\nSchemaBuffer.set = SchemaType.set;\n\nSchemaBuffer.setters = [];\n\n/**\n * Attaches a getter for all Buffer instances\n *\n * #### Example:\n *\n *     // Always convert to string when getting an ObjectId\n *     mongoose.Schema.Types.Buffer.get(v => v.toString('hex'));\n *\n *     const Model = mongoose.model('Test', new Schema({ buf: Buffer } }));\n *     typeof (new Model({ buf: Buffer.fromString('hello') }).buf); // 'string'\n *\n * @param {Function} getter\n * @return {this}\n * @function get\n * @static\n * @api public\n */\n\nSchemaBuffer.get = SchemaType.get;\n\n/**\n * Override the function the required validator uses to check whether a string\n * passes the `required` check.\n *\n * #### Example:\n *\n *     // Allow empty strings to pass `required` check\n *     mongoose.Schema.Types.String.checkRequired(v => v != null);\n *\n *     const M = mongoose.model({ buf: { type: Buffer, required: true } });\n *     new M({ buf: Buffer.from('') }).validateSync(); // validation passes!\n *\n * @param {Function} fn\n * @return {Function}\n * @function checkRequired\n * @static\n * @api public\n */\n\nSchemaBuffer.checkRequired = SchemaType.checkRequired;\n\n/**\n * Check if the given value satisfies a required validator. To satisfy a\n * required validator, a buffer must not be null or undefined and have\n * non-zero length.\n *\n * @param {Any} value\n * @param {Document} doc\n * @return {Boolean}\n * @api public\n */\n\nSchemaBuffer.prototype.checkRequired = function(value, doc) {\n  if (SchemaType._isRef(this, value, doc, true)) {\n    return !!value;\n  }\n  return this.constructor._checkRequired(value);\n};\n\n/**\n * Casts contents\n *\n * @param {Object} value\n * @param {Document} doc document that triggers the casting\n * @param {Boolean} init\n * @api private\n */\n\nSchemaBuffer.prototype.cast = function(value, doc, init) {\n  let ret;\n  if (SchemaType._isRef(this, value, doc, init)) {\n    if (value && value.isMongooseBuffer) {\n      return value;\n    }\n\n    if (Buffer.isBuffer(value)) {\n      if (!value || !value.isMongooseBuffer) {\n        value = new MongooseBuffer(value, [this.path, doc]);\n        if (this.options.subtype != null) {\n          value._subtype = this.options.subtype;\n        }\n      }\n      return value;\n    }\n\n    if (value instanceof Binary) {\n      ret = new MongooseBuffer(value.value(true), [this.path, doc]);\n      if (typeof value.sub_type !== 'number') {\n        throw new CastError('Buffer', value, this.path, null, this);\n      }\n      ret._subtype = value.sub_type;\n      return ret;\n    }\n\n    if (value == null || utils.isNonBuiltinObject(value)) {\n      return this._castRef(value, doc, init);\n    }\n  }\n\n  // documents\n  if (value && value._id) {\n    value = value._id;\n  }\n\n  if (value && value.isMongooseBuffer) {\n    return value;\n  }\n\n  if (Buffer.isBuffer(value)) {\n    if (!value || !value.isMongooseBuffer) {\n      value = new MongooseBuffer(value, [this.path, doc]);\n      if (this.options.subtype != null) {\n        value._subtype = this.options.subtype;\n      }\n    }\n    return value;\n  }\n\n  if (value instanceof Binary) {\n    ret = new MongooseBuffer(value.value(true), [this.path, doc]);\n    if (typeof value.sub_type !== 'number') {\n      throw new CastError('Buffer', value, this.path, null, this);\n    }\n    ret._subtype = value.sub_type;\n    return ret;\n  }\n\n  if (value === null) {\n    return value;\n  }\n\n\n  const type = typeof value;\n  if (\n    type === 'string' || type === 'number' || Array.isArray(value) ||\n    (type === 'object' && value.type === 'Buffer' && Array.isArray(value.data)) // gh-6863\n  ) {\n    if (type === 'number') {\n      value = [value];\n    }\n    ret = new MongooseBuffer(value, [this.path, doc]);\n    if (this.options.subtype != null) {\n      ret._subtype = this.options.subtype;\n    }\n    return ret;\n  }\n\n  throw new CastError('Buffer', value, this.path, null, this);\n};\n\n/**\n * Sets the default [subtype](https://studio3t.com/whats-new/best-practices-uuid-mongodb/)\n * for this buffer. You can find a [list of allowed subtypes here](https://api.mongodb.com/python/current/api/bson/binary.html).\n *\n * #### Example:\n *\n *     const s = new Schema({ uuid: { type: Buffer, subtype: 4 });\n *     const M = db.model('M', s);\n *     const m = new M({ uuid: 'test string' });\n *     m.uuid._subtype; // 4\n *\n * @param {Number} subtype the default subtype\n * @return {SchemaType} this\n * @api public\n */\n\nSchemaBuffer.prototype.subtype = function(subtype) {\n  this.options.subtype = subtype;\n  return this;\n};\n\n/*!\n * ignore\n */\nfunction handleSingle(val, context) {\n  return this.castForQuery(null, val, context);\n}\n\nSchemaBuffer.prototype.$conditionalHandlers = {\n  ...SchemaType.prototype.$conditionalHandlers,\n  $bitsAllClear: handleBitwiseOperator,\n  $bitsAnyClear: handleBitwiseOperator,\n  $bitsAllSet: handleBitwiseOperator,\n  $bitsAnySet: handleBitwiseOperator,\n  $gt: handleSingle,\n  $gte: handleSingle,\n  $lt: handleSingle,\n  $lte: handleSingle\n};\n\n/**\n * Casts contents for queries.\n *\n * @param {String} $conditional\n * @param {any} [value]\n * @api private\n */\n\nSchemaBuffer.prototype.castForQuery = function($conditional, val, context) {\n  let handler;\n  if ($conditional != null) {\n    handler = this.$conditionalHandlers[$conditional];\n    if (!handler) {\n      throw new Error('Can\\'t use ' + $conditional + ' with Buffer.');\n    }\n    return handler.call(this, val);\n  }\n\n  let casted;\n  try {\n    casted = this.applySetters(val, context);\n  } catch (err) {\n    if (err instanceof CastError && err.path === this.path && this.$fullPath != null) {\n      err.path = this.$fullPath;\n    }\n    throw err;\n  }\n  return casted ? casted.toObject({ transform: false, virtuals: false }) : casted;\n};\n\n/*!\n * Module exports.\n */\n\nmodule.exports = SchemaBuffer;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schema/buffer.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schema/date.js":
/*!**************************************************!*\
  !*** ./node_modules/mongoose/lib/schema/date.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module requirements.\n */\n\n\n\nconst MongooseError = __webpack_require__(/*! ../error/index */ \"./node_modules/mongoose/lib/error/index.js\");\nconst SchemaDateOptions = __webpack_require__(/*! ../options/schemaDateOptions */ \"./node_modules/mongoose/lib/options/schemaDateOptions.js\");\nconst SchemaType = __webpack_require__(/*! ../schemaType */ \"./node_modules/mongoose/lib/schemaType.js\");\nconst castDate = __webpack_require__(/*! ../cast/date */ \"./node_modules/mongoose/lib/cast/date.js\");\nconst getConstructorName = __webpack_require__(/*! ../helpers/getConstructorName */ \"./node_modules/mongoose/lib/helpers/getConstructorName.js\");\nconst utils = __webpack_require__(/*! ../utils */ \"./node_modules/mongoose/lib/utils.js\");\n\nconst CastError = SchemaType.CastError;\n\n/**\n * Date SchemaType constructor.\n *\n * @param {String} key\n * @param {Object} options\n * @inherits SchemaType\n * @api public\n */\n\nfunction SchemaDate(key, options) {\n  SchemaType.call(this, key, options, 'Date');\n}\n\n/**\n * This schema type's name, to defend against minifiers that mangle\n * function names.\n *\n * @api public\n */\nSchemaDate.schemaName = 'Date';\n\nSchemaDate.defaultOptions = {};\n\n/*!\n * Inherits from SchemaType.\n */\nSchemaDate.prototype = Object.create(SchemaType.prototype);\nSchemaDate.prototype.constructor = SchemaDate;\nSchemaDate.prototype.OptionsConstructor = SchemaDateOptions;\n\n/*!\n * ignore\n */\n\nSchemaDate._cast = castDate;\n\n/**\n * Sets a default option for all Date instances.\n *\n * #### Example:\n *\n *     // Make all dates have `required` of true by default.\n *     mongoose.Schema.Date.set('required', true);\n *\n *     const User = mongoose.model('User', new Schema({ test: Date }));\n *     new User({ }).validateSync().errors.test.message; // Path `test` is required.\n *\n * @param {String} option The option you'd like to set the value for\n * @param {Any} value value for option\n * @return {undefined}\n * @function set\n * @static\n * @api public\n */\n\nSchemaDate.set = SchemaType.set;\n\nSchemaDate.setters = [];\n\n/**\n * Attaches a getter for all Date instances\n *\n * #### Example:\n *\n *     // Always convert Dates to string\n *     mongoose.Date.get(v => v.toString());\n *\n *     const Model = mongoose.model('Test', new Schema({ date: { type: Date, default: () => new Date() } }));\n *     typeof (new Model({}).date); // 'string'\n *\n * @param {Function} getter\n * @return {this}\n * @function get\n * @static\n * @api public\n */\n\nSchemaDate.get = SchemaType.get;\n\n/**\n * Get/set the function used to cast arbitrary values to dates.\n *\n * #### Example:\n *\n *     // Mongoose converts empty string '' into `null` for date types. You\n *     // can create a custom caster to disable it.\n *     const original = mongoose.Schema.Types.Date.cast();\n *     mongoose.Schema.Types.Date.cast(v => {\n *       assert.ok(v !== '');\n *       return original(v);\n *     });\n *\n *     // Or disable casting entirely\n *     mongoose.Schema.Types.Date.cast(false);\n *\n * @param {Function} caster\n * @return {Function}\n * @function get\n * @static\n * @api public\n */\n\nSchemaDate.cast = function cast(caster) {\n  if (arguments.length === 0) {\n    return this._cast;\n  }\n  if (caster === false) {\n    caster = this._defaultCaster;\n  }\n  this._cast = caster;\n\n  return this._cast;\n};\n\n/*!\n * ignore\n */\n\nSchemaDate._defaultCaster = v => {\n  if (v != null && !(v instanceof Date)) {\n    throw new Error();\n  }\n  return v;\n};\n\n/**\n * Declares a TTL index (rounded to the nearest second) for _Date_ types only.\n *\n * This sets the `expireAfterSeconds` index option available in MongoDB >= 2.1.2.\n * This index type is only compatible with Date types.\n *\n * #### Example:\n *\n *     // expire in 24 hours\n *     new Schema({ createdAt: { type: Date, expires: 60*60*24 }});\n *\n * `expires` utilizes the `ms` module from [guille](https://github.com/guille/) allowing us to use a friendlier syntax:\n *\n * #### Example:\n *\n *     // expire in 24 hours\n *     new Schema({ createdAt: { type: Date, expires: '24h' }});\n *\n *     // expire in 1.5 hours\n *     new Schema({ createdAt: { type: Date, expires: '1.5h' }});\n *\n *     // expire in 7 days\n *     const schema = new Schema({ createdAt: Date });\n *     schema.path('createdAt').expires('7d');\n *\n * @param {Number|String} when\n * @added 3.0.0\n * @return {SchemaType} this\n * @api public\n */\n\nSchemaDate.prototype.expires = function(when) {\n  if (getConstructorName(this._index) !== 'Object') {\n    this._index = {};\n  }\n\n  this._index.expires = when;\n  utils.expires(this._index);\n  return this;\n};\n\n/*!\n * ignore\n */\n\nSchemaDate._checkRequired = v => v instanceof Date;\n\n/**\n * Override the function the required validator uses to check whether a string\n * passes the `required` check.\n *\n * #### Example:\n *\n *     // Allow empty strings to pass `required` check\n *     mongoose.Schema.Types.String.checkRequired(v => v != null);\n *\n *     const M = mongoose.model({ str: { type: String, required: true } });\n *     new M({ str: '' }).validateSync(); // `null`, validation passes!\n *\n * @param {Function} fn\n * @return {Function}\n * @function checkRequired\n * @static\n * @api public\n */\n\nSchemaDate.checkRequired = SchemaType.checkRequired;\n\n/**\n * Check if the given value satisfies a required validator. To satisfy\n * a required validator, the given value must be an instance of `Date`.\n *\n * @param {Any} value\n * @param {Document} doc\n * @return {Boolean}\n * @api public\n */\n\nSchemaDate.prototype.checkRequired = function(value, doc) {\n  if (typeof value === 'object' && SchemaType._isRef(this, value, doc, true)) {\n    return value != null;\n  }\n\n  // `require('util').inherits()` does **not** copy static properties, and\n  // plugins like mongoose-float use `inherits()` for pre-ES6.\n  const _checkRequired = typeof this.constructor.checkRequired === 'function' ?\n    this.constructor.checkRequired() :\n    SchemaDate.checkRequired();\n  return _checkRequired(value);\n};\n\n/**\n * Sets a minimum date validator.\n *\n * #### Example:\n *\n *     const s = new Schema({ d: { type: Date, min: Date('1970-01-01') })\n *     const M = db.model('M', s)\n *     const m = new M({ d: Date('1969-12-31') })\n *     m.save(function (err) {\n *       console.error(err) // validator error\n *       m.d = Date('2014-12-08');\n *       m.save() // success\n *     })\n *\n *     // custom error messages\n *     // We can also use the special {MIN} token which will be replaced with the invalid value\n *     const min = [Date('1970-01-01'), 'The value of path `{PATH}` ({VALUE}) is beneath the limit ({MIN}).'];\n *     const schema = new Schema({ d: { type: Date, min: min })\n *     const M = mongoose.model('M', schema);\n *     const s= new M({ d: Date('1969-12-31') });\n *     s.validate(function (err) {\n *       console.log(String(err)) // ValidationError: The value of path `d` (1969-12-31) is before the limit (1970-01-01).\n *     })\n *\n * @param {Date} value minimum date\n * @param {String} [message] optional custom error message\n * @return {SchemaType} this\n * @see Customized Error Messages https://mongoosejs.com/docs/api/error.html#Error.messages\n * @api public\n */\n\nSchemaDate.prototype.min = function(value, message) {\n  if (this.minValidator) {\n    this.validators = this.validators.filter(function(v) {\n      return v.validator !== this.minValidator;\n    }, this);\n  }\n\n  if (value) {\n    let msg = message || MongooseError.messages.Date.min;\n    if (typeof msg === 'string') {\n      msg = msg.replace(/{MIN}/, (value === Date.now ? 'Date.now()' : value.toString()));\n    }\n    const _this = this;\n    this.validators.push({\n      validator: this.minValidator = function(val) {\n        let _value = value;\n        if (typeof value === 'function' && value !== Date.now) {\n          _value = _value.call(this);\n        }\n        const min = (_value === Date.now ? _value() : _this.cast(_value));\n        return val === null || val.valueOf() >= min.valueOf();\n      },\n      message: msg,\n      type: 'min',\n      min: value\n    });\n  }\n\n  return this;\n};\n\n/**\n * Sets a maximum date validator.\n *\n * #### Example:\n *\n *     const s = new Schema({ d: { type: Date, max: Date('2014-01-01') })\n *     const M = db.model('M', s)\n *     const m = new M({ d: Date('2014-12-08') })\n *     m.save(function (err) {\n *       console.error(err) // validator error\n *       m.d = Date('2013-12-31');\n *       m.save() // success\n *     })\n *\n *     // custom error messages\n *     // We can also use the special {MAX} token which will be replaced with the invalid value\n *     const max = [Date('2014-01-01'), 'The value of path `{PATH}` ({VALUE}) exceeds the limit ({MAX}).'];\n *     const schema = new Schema({ d: { type: Date, max: max })\n *     const M = mongoose.model('M', schema);\n *     const s= new M({ d: Date('2014-12-08') });\n *     s.validate(function (err) {\n *       console.log(String(err)) // ValidationError: The value of path `d` (2014-12-08) exceeds the limit (2014-01-01).\n *     })\n *\n * @param {Date} maximum date\n * @param {String} [message] optional custom error message\n * @return {SchemaType} this\n * @see Customized Error Messages https://mongoosejs.com/docs/api/error.html#Error.messages\n * @api public\n */\n\nSchemaDate.prototype.max = function(value, message) {\n  if (this.maxValidator) {\n    this.validators = this.validators.filter(function(v) {\n      return v.validator !== this.maxValidator;\n    }, this);\n  }\n\n  if (value) {\n    let msg = message || MongooseError.messages.Date.max;\n    if (typeof msg === 'string') {\n      msg = msg.replace(/{MAX}/, (value === Date.now ? 'Date.now()' : value.toString()));\n    }\n    const _this = this;\n    this.validators.push({\n      validator: this.maxValidator = function(val) {\n        let _value = value;\n        if (typeof _value === 'function' && _value !== Date.now) {\n          _value = _value.call(this);\n        }\n        const max = (_value === Date.now ? _value() : _this.cast(_value));\n        return val === null || val.valueOf() <= max.valueOf();\n      },\n      message: msg,\n      type: 'max',\n      max: value\n    });\n  }\n\n  return this;\n};\n\n/**\n * Casts to date\n *\n * @param {Object} value to cast\n * @api private\n */\n\nSchemaDate.prototype.cast = function(value) {\n  let castDate;\n  if (typeof this._castFunction === 'function') {\n    castDate = this._castFunction;\n  } else if (typeof this.constructor.cast === 'function') {\n    castDate = this.constructor.cast();\n  } else {\n    castDate = SchemaDate.cast();\n  }\n\n  try {\n    return castDate(value);\n  } catch (error) {\n    throw new CastError('date', value, this.path, error, this);\n  }\n};\n\n/**\n * Date Query casting.\n *\n * @param {Any} val\n * @api private\n */\n\nfunction handleSingle(val) {\n  return this.cast(val);\n}\n\nSchemaDate.prototype.$conditionalHandlers = {\n  ...SchemaType.prototype.$conditionalHandlers,\n  $gt: handleSingle,\n  $gte: handleSingle,\n  $lt: handleSingle,\n  $lte: handleSingle\n};\n\n\n/**\n * Casts contents for queries.\n *\n * @param {String} $conditional\n * @param {any} [value]\n * @api private\n */\n\nSchemaDate.prototype.castForQuery = function($conditional, val, context) {\n  if ($conditional == null) {\n    try {\n      return this.applySetters(val, context);\n    } catch (err) {\n      if (err instanceof CastError && err.path === this.path && this.$fullPath != null) {\n        err.path = this.$fullPath;\n      }\n      throw err;\n    }\n  }\n\n  const handler = this.$conditionalHandlers[$conditional];\n\n  if (!handler) {\n    throw new Error('Can\\'t use ' + $conditional + ' with Date.');\n  }\n\n  return handler.call(this, val);\n};\n\n/*!\n * Module exports.\n */\n\nmodule.exports = SchemaDate;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schema/date.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schema/decimal128.js":
/*!********************************************************!*\
  !*** ./node_modules/mongoose/lib/schema/decimal128.js ***!
  \********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module dependencies.\n */\n\n\n\nconst SchemaType = __webpack_require__(/*! ../schemaType */ \"./node_modules/mongoose/lib/schemaType.js\");\nconst CastError = SchemaType.CastError;\nconst castDecimal128 = __webpack_require__(/*! ../cast/decimal128 */ \"./node_modules/mongoose/lib/cast/decimal128.js\");\nconst isBsonType = __webpack_require__(/*! ../helpers/isBsonType */ \"./node_modules/mongoose/lib/helpers/isBsonType.js\");\n\n/**\n * Decimal128 SchemaType constructor.\n *\n * @param {String} key\n * @param {Object} options\n * @inherits SchemaType\n * @api public\n */\n\nfunction SchemaDecimal128(key, options) {\n  SchemaType.call(this, key, options, 'Decimal128');\n}\n\n/**\n * This schema type's name, to defend against minifiers that mangle\n * function names.\n *\n * @api public\n */\nSchemaDecimal128.schemaName = 'Decimal128';\n\nSchemaDecimal128.defaultOptions = {};\n\n/*!\n * Inherits from SchemaType.\n */\nSchemaDecimal128.prototype = Object.create(SchemaType.prototype);\nSchemaDecimal128.prototype.constructor = SchemaDecimal128;\n\n/*!\n * ignore\n */\n\nSchemaDecimal128._cast = castDecimal128;\n\n/**\n * Sets a default option for all Decimal128 instances.\n *\n * #### Example:\n *\n *     // Make all decimal 128s have `required` of true by default.\n *     mongoose.Schema.Decimal128.set('required', true);\n *\n *     const User = mongoose.model('User', new Schema({ test: mongoose.Decimal128 }));\n *     new User({ }).validateSync().errors.test.message; // Path `test` is required.\n *\n * @param {String} option The option you'd like to set the value for\n * @param {Any} value value for option\n * @return {undefined}\n * @function set\n * @static\n * @api public\n */\n\nSchemaDecimal128.set = SchemaType.set;\n\nSchemaDecimal128.setters = [];\n\n/**\n * Attaches a getter for all Decimal128 instances\n *\n * #### Example:\n *\n *     // Automatically convert Decimal128s to Numbers\n *     mongoose.Schema.Decimal128.get(v => v == null ? v : Number(v));\n *\n * @param {Function} getter\n * @return {this}\n * @function get\n * @static\n * @api public\n */\n\nSchemaDecimal128.get = SchemaType.get;\n\n/**\n * Get/set the function used to cast arbitrary values to decimals.\n *\n * #### Example:\n *\n *     // Make Mongoose only refuse to cast numbers as decimal128\n *     const original = mongoose.Schema.Types.Decimal128.cast();\n *     mongoose.Decimal128.cast(v => {\n *       assert.ok(typeof v !== 'number');\n *       return original(v);\n *     });\n *\n *     // Or disable casting entirely\n *     mongoose.Decimal128.cast(false);\n *\n * @param {Function} [caster]\n * @return {Function}\n * @function get\n * @static\n * @api public\n */\n\nSchemaDecimal128.cast = function cast(caster) {\n  if (arguments.length === 0) {\n    return this._cast;\n  }\n  if (caster === false) {\n    caster = this._defaultCaster;\n  }\n  this._cast = caster;\n\n  return this._cast;\n};\n\n/*!\n * ignore\n */\n\nSchemaDecimal128._defaultCaster = v => {\n  if (v != null && !isBsonType(v, 'Decimal128')) {\n    throw new Error();\n  }\n  return v;\n};\n\n/*!\n * ignore\n */\n\nSchemaDecimal128._checkRequired = v => isBsonType(v, 'Decimal128');\n\n/**\n * Override the function the required validator uses to check whether a string\n * passes the `required` check.\n *\n * @param {Function} fn\n * @return {Function}\n * @function checkRequired\n * @static\n * @api public\n */\n\nSchemaDecimal128.checkRequired = SchemaType.checkRequired;\n\n/**\n * Check if the given value satisfies a required validator.\n *\n * @param {Any} value\n * @param {Document} doc\n * @return {Boolean}\n * @api public\n */\n\nSchemaDecimal128.prototype.checkRequired = function checkRequired(value, doc) {\n  if (SchemaType._isRef(this, value, doc, true)) {\n    return !!value;\n  }\n\n  // `require('util').inherits()` does **not** copy static properties, and\n  // plugins like mongoose-float use `inherits()` for pre-ES6.\n  const _checkRequired = typeof this.constructor.checkRequired === 'function' ?\n    this.constructor.checkRequired() :\n    SchemaDecimal128.checkRequired();\n\n  return _checkRequired(value);\n};\n\n/**\n * Casts to Decimal128\n *\n * @param {Object} value\n * @param {Object} doc\n * @param {Boolean} init whether this is an initialization cast\n * @api private\n */\n\nSchemaDecimal128.prototype.cast = function(value, doc, init) {\n  if (SchemaType._isRef(this, value, doc, init)) {\n    if (isBsonType(value, 'Decimal128')) {\n      return value;\n    }\n\n    return this._castRef(value, doc, init);\n  }\n\n  let castDecimal128;\n  if (typeof this._castFunction === 'function') {\n    castDecimal128 = this._castFunction;\n  } else if (typeof this.constructor.cast === 'function') {\n    castDecimal128 = this.constructor.cast();\n  } else {\n    castDecimal128 = SchemaDecimal128.cast();\n  }\n\n  try {\n    return castDecimal128(value);\n  } catch (error) {\n    throw new CastError('Decimal128', value, this.path, error, this);\n  }\n};\n\n/*!\n * ignore\n */\n\nfunction handleSingle(val) {\n  return this.cast(val);\n}\n\nSchemaDecimal128.prototype.$conditionalHandlers = {\n  ...SchemaType.prototype.$conditionalHandlers,\n  $gt: handleSingle,\n  $gte: handleSingle,\n  $lt: handleSingle,\n  $lte: handleSingle\n};\n\n/*!\n * Module exports.\n */\n\nmodule.exports = SchemaDecimal128;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schema/decimal128.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schema/documentArray.js":
/*!***********************************************************!*\
  !*** ./node_modules/mongoose/lib/schema/documentArray.js ***!
  \***********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst CastError = __webpack_require__(/*! ../error/cast */ \"./node_modules/mongoose/lib/error/cast.js\");\nconst DocumentArrayElement = __webpack_require__(/*! ./documentArrayElement */ \"./node_modules/mongoose/lib/schema/documentArrayElement.js\");\nconst EventEmitter = (__webpack_require__(/*! events */ \"events\").EventEmitter);\nconst SchemaArray = __webpack_require__(/*! ./array */ \"./node_modules/mongoose/lib/schema/array.js\");\nconst SchemaDocumentArrayOptions =\n  __webpack_require__(/*! ../options/schemaDocumentArrayOptions */ \"./node_modules/mongoose/lib/options/schemaDocumentArrayOptions.js\");\nconst SchemaType = __webpack_require__(/*! ../schemaType */ \"./node_modules/mongoose/lib/schemaType.js\");\nconst cast = __webpack_require__(/*! ../cast */ \"./node_modules/mongoose/lib/cast.js\");\nconst discriminator = __webpack_require__(/*! ../helpers/model/discriminator */ \"./node_modules/mongoose/lib/helpers/model/discriminator.js\");\nconst handleIdOption = __webpack_require__(/*! ../helpers/schema/handleIdOption */ \"./node_modules/mongoose/lib/helpers/schema/handleIdOption.js\");\nconst handleSpreadDoc = __webpack_require__(/*! ../helpers/document/handleSpreadDoc */ \"./node_modules/mongoose/lib/helpers/document/handleSpreadDoc.js\");\nconst isOperator = __webpack_require__(/*! ../helpers/query/isOperator */ \"./node_modules/mongoose/lib/helpers/query/isOperator.js\");\nconst utils = __webpack_require__(/*! ../utils */ \"./node_modules/mongoose/lib/utils.js\");\nconst getConstructor = __webpack_require__(/*! ../helpers/discriminator/getConstructor */ \"./node_modules/mongoose/lib/helpers/discriminator/getConstructor.js\");\nconst InvalidSchemaOptionError = __webpack_require__(/*! ../error/invalidSchemaOption */ \"./node_modules/mongoose/lib/error/invalidSchemaOption.js\");\n\nconst arrayAtomicsSymbol = (__webpack_require__(/*! ../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").arrayAtomicsSymbol);\nconst arrayPathSymbol = (__webpack_require__(/*! ../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").arrayPathSymbol);\nconst documentArrayParent = (__webpack_require__(/*! ../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").documentArrayParent);\n\nlet MongooseDocumentArray;\nlet Subdocument;\n\n/**\n * SubdocsArray SchemaType constructor\n *\n * @param {String} key\n * @param {Schema} schema\n * @param {Object} options\n * @param {Object} schemaOptions\n * @inherits SchemaArray\n * @api public\n */\n\nfunction SchemaDocumentArray(key, schema, options, schemaOptions) {\n  if (schema.options && schema.options.timeseries) {\n    throw new InvalidSchemaOptionError(key, 'timeseries');\n  }\n  const schemaTypeIdOption = SchemaDocumentArray.defaultOptions &&\n    SchemaDocumentArray.defaultOptions._id;\n  if (schemaTypeIdOption != null) {\n    schemaOptions = schemaOptions || {};\n    schemaOptions._id = schemaTypeIdOption;\n  }\n\n  if (schemaOptions != null && schemaOptions._id != null) {\n    schema = handleIdOption(schema, schemaOptions);\n  } else if (options != null && options._id != null) {\n    schema = handleIdOption(schema, options);\n  }\n\n  const EmbeddedDocument = _createConstructor(schema, options);\n  EmbeddedDocument.prototype.$basePath = key;\n\n  SchemaArray.call(this, key, EmbeddedDocument, options);\n\n  this.schema = schema;\n  this.schemaOptions = schemaOptions || {};\n  this.$isMongooseDocumentArray = true;\n  this.Constructor = EmbeddedDocument;\n\n  EmbeddedDocument.base = schema.base;\n\n  const fn = this.defaultValue;\n\n  if (!('defaultValue' in this) || fn != null) {\n    this.default(function() {\n      let arr = fn.call(this);\n      if (arr != null && !Array.isArray(arr)) {\n        arr = [arr];\n      }\n      // Leave it up to `cast()` to convert this to a documentarray\n      return arr;\n    });\n  }\n\n  const $parentSchemaType = this;\n  this.$embeddedSchemaType = new DocumentArrayElement(key + '.$', {\n    required: this &&\n      this.schemaOptions &&\n      this.schemaOptions.required || false,\n    $parentSchemaType\n  });\n\n  this.$embeddedSchemaType.caster = this.Constructor;\n  this.$embeddedSchemaType.schema = this.schema;\n}\n\n/**\n * This schema type's name, to defend against minifiers that mangle\n * function names.\n *\n * @api public\n */\nSchemaDocumentArray.schemaName = 'DocumentArray';\n\n/**\n * Options for all document arrays.\n *\n * - `castNonArrays`: `true` by default. If `false`, Mongoose will throw a CastError when a value isn't an array. If `true`, Mongoose will wrap the provided value in an array before casting.\n *\n * @api public\n */\n\nSchemaDocumentArray.options = { castNonArrays: true };\n\n/*!\n * Inherits from SchemaArray.\n */\nSchemaDocumentArray.prototype = Object.create(SchemaArray.prototype);\nSchemaDocumentArray.prototype.constructor = SchemaDocumentArray;\nSchemaDocumentArray.prototype.OptionsConstructor = SchemaDocumentArrayOptions;\nSchemaDocumentArray.prototype.$conditionalHandlers = { ...SchemaArray.prototype.$conditionalHandlers };\n\n/*!\n * ignore\n */\n\nfunction _createConstructor(schema, options, baseClass) {\n  Subdocument || (Subdocument = __webpack_require__(/*! ../types/arraySubdocument */ \"./node_modules/mongoose/lib/types/arraySubdocument.js\"));\n\n  // compile an embedded document for this schema\n  function EmbeddedDocument() {\n    Subdocument.apply(this, arguments);\n    if (this.__parentArray == null || this.__parentArray.getArrayParent() == null) {\n      return;\n    }\n    this.$session(this.__parentArray.getArrayParent().$session());\n  }\n\n  schema._preCompile();\n\n  const proto = baseClass != null ? baseClass.prototype : Subdocument.prototype;\n  EmbeddedDocument.prototype = Object.create(proto);\n  EmbeddedDocument.prototype.$__setSchema(schema);\n  EmbeddedDocument.schema = schema;\n  EmbeddedDocument.prototype.constructor = EmbeddedDocument;\n  EmbeddedDocument.$isArraySubdocument = true;\n  EmbeddedDocument.events = new EventEmitter();\n  EmbeddedDocument.base = schema.base;\n\n  // apply methods\n  for (const i in schema.methods) {\n    EmbeddedDocument.prototype[i] = schema.methods[i];\n  }\n\n  // apply statics\n  for (const i in schema.statics) {\n    EmbeddedDocument[i] = schema.statics[i];\n  }\n\n  for (const i in EventEmitter.prototype) {\n    EmbeddedDocument[i] = EventEmitter.prototype[i];\n  }\n\n  EmbeddedDocument.options = options;\n\n  return EmbeddedDocument;\n}\n\n/**\n * Adds a discriminator to this document array.\n *\n * #### Example:\n *\n *     const shapeSchema = Schema({ name: String }, { discriminatorKey: 'kind' });\n *     const schema = Schema({ shapes: [shapeSchema] });\n *\n *     const docArrayPath = parentSchema.path('shapes');\n *     docArrayPath.discriminator('Circle', Schema({ radius: Number }));\n *\n * @param {String} name\n * @param {Schema} schema fields to add to the schema for instances of this sub-class\n * @param {Object|string} [options] If string, same as `options.value`.\n * @param {String} [options.value] the string stored in the `discriminatorKey` property. If not specified, Mongoose uses the `name` parameter.\n * @param {Boolean} [options.clone=true] By default, `discriminator()` clones the given `schema`. Set to `false` to skip cloning.\n * @see discriminators https://mongoosejs.com/docs/discriminators.html\n * @return {Function} the constructor Mongoose will use for creating instances of this discriminator model\n * @api public\n */\n\nSchemaDocumentArray.prototype.discriminator = function(name, schema, options) {\n  if (typeof name === 'function') {\n    name = utils.getFunctionName(name);\n  }\n\n  options = options || {};\n  const tiedValue = utils.isPOJO(options) ? options.value : options;\n  const clone = typeof options.clone === 'boolean' ? options.clone : true;\n\n  if (schema.instanceOfSchema && clone) {\n    schema = schema.clone();\n  }\n\n  schema = discriminator(this.casterConstructor, name, schema, tiedValue, null, null, options?.overwriteExisting);\n\n  const EmbeddedDocument = _createConstructor(schema, null, this.casterConstructor);\n  EmbeddedDocument.baseCasterConstructor = this.casterConstructor;\n\n  try {\n    Object.defineProperty(EmbeddedDocument, 'name', {\n      value: name\n    });\n  } catch (error) {\n    // Ignore error, only happens on old versions of node\n  }\n\n  this.casterConstructor.discriminators[name] = EmbeddedDocument;\n\n  return this.casterConstructor.discriminators[name];\n};\n\n/**\n * Performs local validations first, then validations on each embedded doc\n *\n * @api private\n */\n\nSchemaDocumentArray.prototype.doValidate = function(array, fn, scope, options) {\n  // lazy load\n  MongooseDocumentArray || (MongooseDocumentArray = __webpack_require__(/*! ../types/documentArray */ \"./node_modules/mongoose/lib/types/documentArray/index.js\"));\n\n  const _this = this;\n  try {\n    SchemaType.prototype.doValidate.call(this, array, cb, scope);\n  } catch (err) {\n    return fn(err);\n  }\n\n  function cb(err) {\n    if (err) {\n      return fn(err);\n    }\n\n    let count = array && array.length;\n    let error;\n\n    if (!count) {\n      return fn();\n    }\n    if (options && options.updateValidator) {\n      return fn();\n    }\n    if (!utils.isMongooseDocumentArray(array)) {\n      array = new MongooseDocumentArray(array, _this.path, scope);\n    }\n\n    // handle sparse arrays, do not use array.forEach which does not\n    // iterate over sparse elements yet reports array.length including\n    // them :(\n\n    function callback(err) {\n      if (err != null) {\n        error = err;\n      }\n      --count || fn(error);\n    }\n\n    for (let i = 0, len = count; i < len; ++i) {\n      // sidestep sparse entries\n      let doc = array[i];\n      if (doc == null) {\n        --count || fn(error);\n        continue;\n      }\n\n      // If you set the array index directly, the doc might not yet be\n      // a full fledged mongoose subdoc, so make it into one.\n      if (!(doc instanceof Subdocument)) {\n        const Constructor = getConstructor(_this.casterConstructor, array[i]);\n        doc = array[i] = new Constructor(doc, array, undefined, undefined, i);\n      }\n\n      if (options != null && options.validateModifiedOnly && !doc.$isModified()) {\n        --count || fn(error);\n        continue;\n      }\n\n      doc.$__validate(null, options, callback);\n    }\n  }\n};\n\n/**\n * Performs local validations first, then validations on each embedded doc.\n *\n * #### Note:\n *\n * This method ignores the asynchronous validators.\n *\n * @return {MongooseError|undefined}\n * @api private\n */\n\nSchemaDocumentArray.prototype.doValidateSync = function(array, scope, options) {\n  const schemaTypeError = SchemaType.prototype.doValidateSync.call(this, array, scope);\n  if (schemaTypeError != null) {\n    return schemaTypeError;\n  }\n\n  const count = array && array.length;\n  let resultError = null;\n\n  if (!count) {\n    return;\n  }\n\n  // handle sparse arrays, do not use array.forEach which does not\n  // iterate over sparse elements yet reports array.length including\n  // them :(\n\n  for (let i = 0, len = count; i < len; ++i) {\n    // sidestep sparse entries\n    let doc = array[i];\n    if (!doc) {\n      continue;\n    }\n\n    // If you set the array index directly, the doc might not yet be\n    // a full fledged mongoose subdoc, so make it into one.\n    if (!(doc instanceof Subdocument)) {\n      const Constructor = getConstructor(this.casterConstructor, array[i]);\n      doc = array[i] = new Constructor(doc, array, undefined, undefined, i);\n    }\n\n    if (options != null && options.validateModifiedOnly && !doc.$isModified()) {\n      continue;\n    }\n\n    const subdocValidateError = doc.validateSync(options);\n\n    if (subdocValidateError && resultError == null) {\n      resultError = subdocValidateError;\n    }\n  }\n\n  return resultError;\n};\n\n/*!\n * ignore\n */\n\nSchemaDocumentArray.prototype.getDefault = function(scope, init, options) {\n  let ret = typeof this.defaultValue === 'function'\n    ? this.defaultValue.call(scope)\n    : this.defaultValue;\n\n  if (ret == null) {\n    return ret;\n  }\n\n  if (options && options.skipCast) {\n    return ret;\n  }\n\n  // lazy load\n  MongooseDocumentArray || (MongooseDocumentArray = __webpack_require__(/*! ../types/documentArray */ \"./node_modules/mongoose/lib/types/documentArray/index.js\"));\n\n  if (!Array.isArray(ret)) {\n    ret = [ret];\n  }\n\n  ret = new MongooseDocumentArray(ret, this.path, scope);\n\n  for (let i = 0; i < ret.length; ++i) {\n    const Constructor = getConstructor(this.casterConstructor, ret[i]);\n    const _subdoc = new Constructor({}, ret, undefined,\n      undefined, i);\n    _subdoc.$init(ret[i]);\n    _subdoc.isNew = true;\n\n    // Make sure all paths in the subdoc are set to `default` instead\n    // of `init` since we used `init`.\n    Object.assign(_subdoc.$__.activePaths.default, _subdoc.$__.activePaths.init);\n    _subdoc.$__.activePaths.init = {};\n\n    ret[i] = _subdoc;\n  }\n\n  return ret;\n};\n\nconst _toObjectOptions = Object.freeze({ transform: false, virtuals: false });\nconst initDocumentOptions = Object.freeze({ skipId: false, willInit: true });\n\n/**\n * Casts contents\n *\n * @param {Object} value\n * @param {Document} document that triggers the casting\n * @api private\n */\n\nSchemaDocumentArray.prototype.cast = function(value, doc, init, prev, options) {\n  // lazy load\n  MongooseDocumentArray || (MongooseDocumentArray = __webpack_require__(/*! ../types/documentArray */ \"./node_modules/mongoose/lib/types/documentArray/index.js\"));\n\n  // Skip casting if `value` is the same as the previous value, no need to cast. See gh-9266\n  if (value != null && value[arrayPathSymbol] != null && value === prev) {\n    return value;\n  }\n\n  let selected;\n  let subdoc;\n\n  options = options || {};\n\n  const path = options.path || this.path;\n\n  if (!Array.isArray(value)) {\n    if (!init && !SchemaDocumentArray.options.castNonArrays) {\n      throw new CastError('DocumentArray', value, this.path, null, this);\n    }\n    // gh-2442 mark whole array as modified if we're initializing a doc from\n    // the db and the path isn't an array in the document\n    if (!!doc && init) {\n      doc.markModified(path);\n    }\n    return this.cast([value], doc, init, prev, options);\n  }\n\n  // We need to create a new array, otherwise change tracking will\n  // update the old doc (gh-4449)\n  if (!options.skipDocumentArrayCast || utils.isMongooseDocumentArray(value)) {\n    value = new MongooseDocumentArray(value, path, doc);\n  }\n\n  if (prev != null) {\n    value[arrayAtomicsSymbol] = prev[arrayAtomicsSymbol] || {};\n  }\n\n  if (options.arrayPathIndex != null) {\n    value[arrayPathSymbol] = path + '.' + options.arrayPathIndex;\n  }\n\n  const rawArray = utils.isMongooseDocumentArray(value) ? value.__array : value;\n  const len = rawArray.length;\n\n  for (let i = 0; i < len; ++i) {\n    if (!rawArray[i]) {\n      continue;\n    }\n\n    const Constructor = getConstructor(this.casterConstructor, rawArray[i]);\n\n    const spreadDoc = handleSpreadDoc(rawArray[i], true);\n    if (rawArray[i] !== spreadDoc) {\n      rawArray[i] = spreadDoc;\n    }\n\n    if (rawArray[i] instanceof Subdocument) {\n      if (rawArray[i][documentArrayParent] !== doc) {\n        if (init) {\n          const subdoc = new Constructor(null, value, initDocumentOptions, selected, i);\n          rawArray[i] = subdoc.$init(rawArray[i]);\n        } else {\n          const subdoc = new Constructor(rawArray[i], value, undefined, undefined, i);\n          rawArray[i] = subdoc;\n        }\n      }\n      // Might not have the correct index yet, so ensure it does.\n      if (rawArray[i].__index == null) {\n        rawArray[i].$setIndex(i);\n      }\n    } else if (rawArray[i] != null) {\n      if (init) {\n        if (doc) {\n          selected || (selected = scopePaths(this, doc.$__.selected, init));\n        } else {\n          selected = true;\n        }\n\n        subdoc = new Constructor(null, value, initDocumentOptions, selected, i);\n        rawArray[i] = subdoc.$init(rawArray[i]);\n      } else {\n        if (prev && typeof prev.id === 'function') {\n          subdoc = prev.id(rawArray[i]._id);\n        }\n\n        if (prev && subdoc && utils.deepEqual(subdoc.toObject(_toObjectOptions), rawArray[i])) {\n          // handle resetting doc with existing id and same data\n          subdoc.set(rawArray[i]);\n          // if set() is hooked it will have no return value\n          // see gh-746\n          rawArray[i] = subdoc;\n        } else {\n          try {\n            subdoc = new Constructor(rawArray[i], value, undefined,\n              undefined, i);\n            // if set() is hooked it will have no return value\n            // see gh-746\n            rawArray[i] = subdoc;\n          } catch (error) {\n            throw new CastError('embedded', rawArray[i],\n              value[arrayPathSymbol], error, this);\n          }\n        }\n      }\n    }\n  }\n\n  return value;\n};\n\n/*!\n * ignore\n */\n\nSchemaDocumentArray.prototype.clone = function() {\n  const options = Object.assign({}, this.options);\n  const schematype = new this.constructor(this.path, this.schema, options, this.schemaOptions);\n  schematype.validators = this.validators.slice();\n  if (this.requiredValidator !== undefined) {\n    schematype.requiredValidator = this.requiredValidator;\n  }\n  schematype.Constructor.discriminators = Object.assign({},\n    this.Constructor.discriminators);\n  return schematype;\n};\n\n/*!\n * ignore\n */\n\nSchemaDocumentArray.prototype.applyGetters = function(value, scope) {\n  return SchemaType.prototype.applyGetters.call(this, value, scope);\n};\n\n/**\n * Scopes paths selected in a query to this array.\n * Necessary for proper default application of subdocument values.\n *\n * @param {DocumentArrayPath} array the array to scope `fields` paths\n * @param {Object|undefined} fields the root fields selected in the query\n * @param {Boolean|undefined} init if we are being created part of a query result\n * @api private\n */\n\nfunction scopePaths(array, fields, init) {\n  if (!(init && fields)) {\n    return undefined;\n  }\n\n  const path = array.path + '.';\n  const keys = Object.keys(fields);\n  let i = keys.length;\n  const selected = {};\n  let hasKeys;\n  let key;\n  let sub;\n\n  while (i--) {\n    key = keys[i];\n    if (key.startsWith(path)) {\n      sub = key.substring(path.length);\n      if (sub === '$') {\n        continue;\n      }\n      if (sub.startsWith('$.')) {\n        sub = sub.substring(2);\n      }\n      hasKeys || (hasKeys = true);\n      selected[sub] = fields[key];\n    }\n  }\n\n  return hasKeys && selected || undefined;\n}\n\n/*!\n * ignore\n */\n\nSchemaDocumentArray.defaultOptions = {};\n\n/**\n * Sets a default option for all DocumentArray instances.\n *\n * #### Example:\n *\n *     // Make all numbers have option `min` equal to 0.\n *     mongoose.Schema.DocumentArray.set('_id', false);\n *\n * @param {String} option The name of the option you'd like to set (e.g. trim, lowercase, etc...)\n * @param {Any} value The value of the option you'd like to set.\n * @return {void}\n * @function set\n * @static\n * @api public\n */\n\nSchemaDocumentArray.set = SchemaType.set;\n\nSchemaDocumentArray.setters = [];\n\n/**\n * Attaches a getter for all DocumentArrayPath instances\n *\n * @param {Function} getter\n * @return {this}\n * @function get\n * @static\n * @api public\n */\n\nSchemaDocumentArray.get = SchemaType.get;\n\n/*!\n * Handle casting $elemMatch operators\n */\n\nSchemaDocumentArray.prototype.$conditionalHandlers.$elemMatch = cast$elemMatch;\n\nfunction cast$elemMatch(val, context) {\n  const keys = Object.keys(val);\n  const numKeys = keys.length;\n  for (let i = 0; i < numKeys; ++i) {\n    const key = keys[i];\n    const value = val[key];\n    if (isOperator(key) && value != null) {\n      val[key] = this.castForQuery(key, value, context);\n    }\n  }\n\n  // Is this an embedded discriminator and is the discriminator key set?\n  // If so, use the discriminator schema. See gh-7449\n  const discriminatorKey = this &&\n    this.casterConstructor &&\n    this.casterConstructor.schema &&\n    this.casterConstructor.schema.options &&\n    this.casterConstructor.schema.options.discriminatorKey;\n  const discriminators = this &&\n  this.casterConstructor &&\n  this.casterConstructor.schema &&\n  this.casterConstructor.schema.discriminators || {};\n  if (discriminatorKey != null &&\n      val[discriminatorKey] != null &&\n      discriminators[val[discriminatorKey]] != null) {\n    return cast(discriminators[val[discriminatorKey]], val, null, this && this.$$context);\n  }\n\n  const schema = this.casterConstructor.schema ?? context.schema;\n  return cast(schema, val, null, this && this.$$context);\n}\n\n/*!\n * Module exports.\n */\n\nmodule.exports = SchemaDocumentArray;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schema/documentArray.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schema/documentArrayElement.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongoose/lib/schema/documentArrayElement.js ***!
  \******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module dependencies.\n */\n\n\n\nconst MongooseError = __webpack_require__(/*! ../error/mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\nconst SchemaType = __webpack_require__(/*! ../schemaType */ \"./node_modules/mongoose/lib/schemaType.js\");\nconst SchemaSubdocument = __webpack_require__(/*! ./subdocument */ \"./node_modules/mongoose/lib/schema/subdocument.js\");\nconst getConstructor = __webpack_require__(/*! ../helpers/discriminator/getConstructor */ \"./node_modules/mongoose/lib/helpers/discriminator/getConstructor.js\");\n\n/**\n * DocumentArrayElement SchemaType constructor.\n *\n * @param {String} path\n * @param {Object} options\n * @inherits SchemaType\n * @api public\n */\n\nfunction SchemaDocumentArrayElement(path, options) {\n  this.$parentSchemaType = options && options.$parentSchemaType;\n  if (!this.$parentSchemaType) {\n    throw new MongooseError('Cannot create DocumentArrayElement schematype without a parent');\n  }\n  delete options.$parentSchemaType;\n\n  SchemaType.call(this, path, options, 'DocumentArrayElement');\n\n  this.$isMongooseDocumentArrayElement = true;\n}\n\n/**\n * This schema type's name, to defend against minifiers that mangle\n * function names.\n *\n * @api public\n */\nSchemaDocumentArrayElement.schemaName = 'DocumentArrayElement';\n\nSchemaDocumentArrayElement.defaultOptions = {};\n\n/*!\n * Inherits from SchemaType.\n */\nSchemaDocumentArrayElement.prototype = Object.create(SchemaType.prototype);\nSchemaDocumentArrayElement.prototype.constructor = SchemaDocumentArrayElement;\n\n/**\n * Casts `val` for DocumentArrayElement.\n *\n * @param {Object} value to cast\n * @api private\n */\n\nSchemaDocumentArrayElement.prototype.cast = function(...args) {\n  return this.$parentSchemaType.cast(...args)[0];\n};\n\n/**\n * Casts contents for queries.\n *\n * @param {String} $cond\n * @param {any} [val]\n * @api private\n */\n\nSchemaDocumentArrayElement.prototype.doValidate = function(value, fn, scope, options) {\n  const Constructor = getConstructor(this.caster, value);\n\n  if (value && !(value instanceof Constructor)) {\n    value = new Constructor(value, scope, null, null, options && options.index != null ? options.index : null);\n  }\n\n  return SchemaSubdocument.prototype.doValidate.call(this, value, fn, scope, options);\n};\n\n/**\n * Clone the current SchemaType\n *\n * @return {DocumentArrayElement} The cloned instance\n * @api private\n */\n\nSchemaDocumentArrayElement.prototype.clone = function() {\n  this.options.$parentSchemaType = this.$parentSchemaType;\n  const ret = SchemaType.prototype.clone.apply(this, arguments);\n  delete this.options.$parentSchemaType;\n\n  ret.caster = this.caster;\n  ret.schema = this.schema;\n\n  return ret;\n};\n\n/*!\n * Module exports.\n */\n\nmodule.exports = SchemaDocumentArrayElement;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schema/documentArrayElement.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schema/index.js":
/*!***************************************************!*\
  !*** ./node_modules/mongoose/lib/schema/index.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n/*!\n * Module exports.\n */\n\n\n\nexports.Array = __webpack_require__(/*! ./array */ \"./node_modules/mongoose/lib/schema/array.js\");\nexports.BigInt = __webpack_require__(/*! ./bigint */ \"./node_modules/mongoose/lib/schema/bigint.js\");\nexports.Boolean = __webpack_require__(/*! ./boolean */ \"./node_modules/mongoose/lib/schema/boolean.js\");\nexports.Buffer = __webpack_require__(/*! ./buffer */ \"./node_modules/mongoose/lib/schema/buffer.js\");\nexports.Date = __webpack_require__(/*! ./date */ \"./node_modules/mongoose/lib/schema/date.js\");\nexports.Decimal128 = exports.Decimal = __webpack_require__(/*! ./decimal128 */ \"./node_modules/mongoose/lib/schema/decimal128.js\");\nexports.DocumentArray = __webpack_require__(/*! ./documentArray */ \"./node_modules/mongoose/lib/schema/documentArray.js\");\nexports.Map = __webpack_require__(/*! ./map */ \"./node_modules/mongoose/lib/schema/map.js\");\nexports.Mixed = __webpack_require__(/*! ./mixed */ \"./node_modules/mongoose/lib/schema/mixed.js\");\nexports.Number = __webpack_require__(/*! ./number */ \"./node_modules/mongoose/lib/schema/number.js\");\nexports.ObjectId = __webpack_require__(/*! ./objectId */ \"./node_modules/mongoose/lib/schema/objectId.js\");\nexports.String = __webpack_require__(/*! ./string */ \"./node_modules/mongoose/lib/schema/string.js\");\nexports.Subdocument = __webpack_require__(/*! ./subdocument */ \"./node_modules/mongoose/lib/schema/subdocument.js\");\nexports.UUID = __webpack_require__(/*! ./uuid */ \"./node_modules/mongoose/lib/schema/uuid.js\");\n\n// alias\n\nexports.Oid = exports.ObjectId;\nexports.Object = exports.Mixed;\nexports.Bool = exports.Boolean;\nexports.ObjectID = exports.ObjectId;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schema/index.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schema/map.js":
/*!*************************************************!*\
  !*** ./node_modules/mongoose/lib/schema/map.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * ignore\n */\n\nconst MongooseMap = __webpack_require__(/*! ../types/map */ \"./node_modules/mongoose/lib/types/map.js\");\nconst SchemaMapOptions = __webpack_require__(/*! ../options/schemaMapOptions */ \"./node_modules/mongoose/lib/options/schemaMapOptions.js\");\nconst SchemaType = __webpack_require__(/*! ../schemaType */ \"./node_modules/mongoose/lib/schemaType.js\");\n/*!\n * ignore\n */\n\nclass SchemaMap extends SchemaType {\n  constructor(key, options) {\n    super(key, options, 'Map');\n    this.$isSchemaMap = true;\n  }\n\n  set(option, value) {\n    return SchemaType.set(option, value);\n  }\n\n  cast(val, doc, init) {\n    if (val instanceof MongooseMap) {\n      return val;\n    }\n\n    const path = this.path;\n\n    if (init) {\n      const map = new MongooseMap({}, path, doc, this.$__schemaType);\n\n      if (val instanceof global.Map) {\n        for (const key of val.keys()) {\n          let _val = val.get(key);\n          if (_val == null) {\n            _val = map.$__schemaType._castNullish(_val);\n          } else {\n            _val = map.$__schemaType.cast(_val, doc, true, null, { path: path + '.' + key });\n          }\n          map.$init(key, _val);\n        }\n      } else {\n        for (const key of Object.keys(val)) {\n          let _val = val[key];\n          if (_val == null) {\n            _val = map.$__schemaType._castNullish(_val);\n          } else {\n            _val = map.$__schemaType.cast(_val, doc, true, null, { path: path + '.' + key });\n          }\n          map.$init(key, _val);\n        }\n      }\n\n      return map;\n    }\n\n    return new MongooseMap(val, path, doc, this.$__schemaType);\n  }\n\n  clone() {\n    const schematype = super.clone();\n\n    if (this.$__schemaType != null) {\n      schematype.$__schemaType = this.$__schemaType.clone();\n    }\n    return schematype;\n  }\n}\n\n/**\n * This schema type's name, to defend against minifiers that mangle\n * function names.\n *\n * @api public\n */\nSchemaMap.schemaName = 'Map';\n\nSchemaMap.prototype.OptionsConstructor = SchemaMapOptions;\n\nSchemaMap.defaultOptions = {};\n\nmodule.exports = SchemaMap;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schema/map.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schema/mixed.js":
/*!***************************************************!*\
  !*** ./node_modules/mongoose/lib/schema/mixed.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module dependencies.\n */\n\n\n\nconst SchemaType = __webpack_require__(/*! ../schemaType */ \"./node_modules/mongoose/lib/schemaType.js\");\nconst symbols = __webpack_require__(/*! ./symbols */ \"./node_modules/mongoose/lib/schema/symbols.js\");\nconst isObject = __webpack_require__(/*! ../helpers/isObject */ \"./node_modules/mongoose/lib/helpers/isObject.js\");\nconst utils = __webpack_require__(/*! ../utils */ \"./node_modules/mongoose/lib/utils.js\");\n\n/**\n * Mixed SchemaType constructor.\n *\n * @param {String} path\n * @param {Object} options\n * @inherits SchemaType\n * @api public\n */\n\nfunction SchemaMixed(path, options) {\n  if (options && options.default) {\n    const def = options.default;\n    if (Array.isArray(def) && def.length === 0) {\n      // make sure empty array defaults are handled\n      options.default = Array;\n    } else if (!options.shared && isObject(def) && Object.keys(def).length === 0) {\n      // prevent odd \"shared\" objects between documents\n      options.default = function() {\n        return {};\n      };\n    }\n  }\n\n  SchemaType.call(this, path, options, 'Mixed');\n\n  this[symbols.schemaMixedSymbol] = true;\n}\n\n/**\n * This schema type's name, to defend against minifiers that mangle\n * function names.\n *\n * @api public\n */\nSchemaMixed.schemaName = 'Mixed';\n\nSchemaMixed.defaultOptions = {};\n\n/*!\n * Inherits from SchemaType.\n */\nSchemaMixed.prototype = Object.create(SchemaType.prototype);\nSchemaMixed.prototype.constructor = SchemaMixed;\n\n/**\n * Attaches a getter for all Mixed paths.\n *\n * #### Example:\n *\n *     // Hide the 'hidden' path\n *     mongoose.Schema.Mixed.get(v => Object.assign({}, v, { hidden: null }));\n *\n *     const Model = mongoose.model('Test', new Schema({ test: {} }));\n *     new Model({ test: { hidden: 'Secret!' } }).test.hidden; // null\n *\n * @param {Function} getter\n * @return {this}\n * @function get\n * @static\n * @api public\n */\n\nSchemaMixed.get = SchemaType.get;\n\n/**\n * Sets a default option for all Mixed instances.\n *\n * #### Example:\n *\n *     // Make all mixed instances have `required` of true by default.\n *     mongoose.Schema.Mixed.set('required', true);\n *\n *     const User = mongoose.model('User', new Schema({ test: mongoose.Mixed }));\n *     new User({ }).validateSync().errors.test.message; // Path `test` is required.\n *\n * @param {String} option The option you'd like to set the value for\n * @param {Any} value value for option\n * @return {undefined}\n * @function set\n * @static\n * @api public\n */\n\nSchemaMixed.set = SchemaType.set;\n\nSchemaMixed.setters = [];\n\n/**\n * Casts `val` for Mixed.\n *\n * _this is a no-op_\n *\n * @param {Object} value to cast\n * @api private\n */\n\nSchemaMixed.prototype.cast = function(val) {\n  if (val instanceof Error) {\n    return utils.errorToPOJO(val);\n  }\n  return val;\n};\n\n/**\n * Casts contents for queries.\n *\n * @param {String} $cond\n * @param {any} [val]\n * @api private\n */\n\nSchemaMixed.prototype.castForQuery = function($cond, val) {\n  return val;\n};\n\n/*!\n * Module exports.\n */\n\nmodule.exports = SchemaMixed;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schema/mixed.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schema/number.js":
/*!****************************************************!*\
  !*** ./node_modules/mongoose/lib/schema/number.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module requirements.\n */\n\nconst MongooseError = __webpack_require__(/*! ../error/index */ \"./node_modules/mongoose/lib/error/index.js\");\nconst SchemaNumberOptions = __webpack_require__(/*! ../options/schemaNumberOptions */ \"./node_modules/mongoose/lib/options/schemaNumberOptions.js\");\nconst SchemaType = __webpack_require__(/*! ../schemaType */ \"./node_modules/mongoose/lib/schemaType.js\");\nconst castNumber = __webpack_require__(/*! ../cast/number */ \"./node_modules/mongoose/lib/cast/number.js\");\nconst handleBitwiseOperator = __webpack_require__(/*! ./operators/bitwise */ \"./node_modules/mongoose/lib/schema/operators/bitwise.js\");\nconst utils = __webpack_require__(/*! ../utils */ \"./node_modules/mongoose/lib/utils.js\");\n\nconst CastError = SchemaType.CastError;\n\n/**\n * Number SchemaType constructor.\n *\n * @param {String} key\n * @param {Object} options\n * @inherits SchemaType\n * @api public\n */\n\nfunction SchemaNumber(key, options) {\n  SchemaType.call(this, key, options, 'Number');\n}\n\n/**\n * Attaches a getter for all Number instances.\n *\n * #### Example:\n *\n *     // Make all numbers round down\n *     mongoose.Number.get(function(v) { return Math.floor(v); });\n *\n *     const Model = mongoose.model('Test', new Schema({ test: Number }));\n *     new Model({ test: 3.14 }).test; // 3\n *\n * @param {Function} getter\n * @return {this}\n * @function get\n * @static\n * @api public\n */\n\nSchemaNumber.get = SchemaType.get;\n\n/**\n * Sets a default option for all Number instances.\n *\n * #### Example:\n *\n *     // Make all numbers have option `min` equal to 0.\n *     mongoose.Schema.Number.set('min', 0);\n *\n *     const Order = mongoose.model('Order', new Schema({ amount: Number }));\n *     new Order({ amount: -10 }).validateSync().errors.amount.message; // Path `amount` must be larger than 0.\n *\n * @param {String} option The option you'd like to set the value for\n * @param {Any} value value for option\n * @return {undefined}\n * @function set\n * @static\n * @api public\n */\n\nSchemaNumber.set = SchemaType.set;\n\nSchemaNumber.setters = [];\n\n/*!\n * ignore\n */\n\nSchemaNumber._cast = castNumber;\n\n/**\n * Get/set the function used to cast arbitrary values to numbers.\n *\n * #### Example:\n *\n *     // Make Mongoose cast empty strings '' to 0 for paths declared as numbers\n *     const original = mongoose.Number.cast();\n *     mongoose.Number.cast(v => {\n *       if (v === '') { return 0; }\n *       return original(v);\n *     });\n *\n *     // Or disable casting entirely\n *     mongoose.Number.cast(false);\n *\n * @param {Function} caster\n * @return {Function}\n * @function get\n * @static\n * @api public\n */\n\nSchemaNumber.cast = function cast(caster) {\n  if (arguments.length === 0) {\n    return this._cast;\n  }\n  if (caster === false) {\n    caster = this._defaultCaster;\n  }\n  this._cast = caster;\n\n  return this._cast;\n};\n\n/*!\n * ignore\n */\n\nSchemaNumber._defaultCaster = v => {\n  if (typeof v !== 'number') {\n    throw new Error();\n  }\n  return v;\n};\n\n/**\n * This schema type's name, to defend against minifiers that mangle\n * function names.\n *\n * @api public\n */\nSchemaNumber.schemaName = 'Number';\n\nSchemaNumber.defaultOptions = {};\n\n/*!\n * Inherits from SchemaType.\n */\nSchemaNumber.prototype = Object.create(SchemaType.prototype);\nSchemaNumber.prototype.constructor = SchemaNumber;\nSchemaNumber.prototype.OptionsConstructor = SchemaNumberOptions;\n\n/*!\n * ignore\n */\n\nSchemaNumber._checkRequired = v => typeof v === 'number' || v instanceof Number;\n\n/**\n * Override the function the required validator uses to check whether a string\n * passes the `required` check.\n *\n * @param {Function} fn\n * @return {Function}\n * @function checkRequired\n * @static\n * @api public\n */\n\nSchemaNumber.checkRequired = SchemaType.checkRequired;\n\n/**\n * Check if the given value satisfies a required validator.\n *\n * @param {Any} value\n * @param {Document} doc\n * @return {Boolean}\n * @api public\n */\n\nSchemaNumber.prototype.checkRequired = function checkRequired(value, doc) {\n  if (typeof value === 'object' && SchemaType._isRef(this, value, doc, true)) {\n    return value != null;\n  }\n\n  // `require('util').inherits()` does **not** copy static properties, and\n  // plugins like mongoose-float use `inherits()` for pre-ES6.\n  const _checkRequired = typeof this.constructor.checkRequired === 'function' ?\n    this.constructor.checkRequired() :\n    SchemaNumber.checkRequired();\n\n  return _checkRequired(value);\n};\n\n/**\n * Sets a minimum number validator.\n *\n * #### Example:\n *\n *     const s = new Schema({ n: { type: Number, min: 10 })\n *     const M = db.model('M', s)\n *     const m = new M({ n: 9 })\n *     m.save(function (err) {\n *       console.error(err) // validator error\n *       m.n = 10;\n *       m.save() // success\n *     })\n *\n *     // custom error messages\n *     // We can also use the special {MIN} token which will be replaced with the invalid value\n *     const min = [10, 'The value of path `{PATH}` ({VALUE}) is beneath the limit ({MIN}).'];\n *     const schema = new Schema({ n: { type: Number, min: min })\n *     const M = mongoose.model('Measurement', schema);\n *     const s= new M({ n: 4 });\n *     s.validate(function (err) {\n *       console.log(String(err)) // ValidationError: The value of path `n` (4) is beneath the limit (10).\n *     })\n *\n * @param {Number} value minimum number\n * @param {String} [message] optional custom error message\n * @return {SchemaType} this\n * @see Customized Error Messages https://mongoosejs.com/docs/api/error.html#Error.messages\n * @api public\n */\n\nSchemaNumber.prototype.min = function(value, message) {\n  if (this.minValidator) {\n    this.validators = this.validators.filter(function(v) {\n      return v.validator !== this.minValidator;\n    }, this);\n  }\n\n  if (value !== null && value !== undefined) {\n    let msg = message || MongooseError.messages.Number.min;\n    msg = msg.replace(/{MIN}/, value);\n    this.validators.push({\n      validator: this.minValidator = function(v) {\n        return v == null || v >= value;\n      },\n      message: msg,\n      type: 'min',\n      min: value\n    });\n  }\n\n  return this;\n};\n\n/**\n * Sets a maximum number validator.\n *\n * #### Example:\n *\n *     const s = new Schema({ n: { type: Number, max: 10 })\n *     const M = db.model('M', s)\n *     const m = new M({ n: 11 })\n *     m.save(function (err) {\n *       console.error(err) // validator error\n *       m.n = 10;\n *       m.save() // success\n *     })\n *\n *     // custom error messages\n *     // We can also use the special {MAX} token which will be replaced with the invalid value\n *     const max = [10, 'The value of path `{PATH}` ({VALUE}) exceeds the limit ({MAX}).'];\n *     const schema = new Schema({ n: { type: Number, max: max })\n *     const M = mongoose.model('Measurement', schema);\n *     const s= new M({ n: 4 });\n *     s.validate(function (err) {\n *       console.log(String(err)) // ValidationError: The value of path `n` (4) exceeds the limit (10).\n *     })\n *\n * @param {Number} maximum number\n * @param {String} [message] optional custom error message\n * @return {SchemaType} this\n * @see Customized Error Messages https://mongoosejs.com/docs/api/error.html#Error.messages\n * @api public\n */\n\nSchemaNumber.prototype.max = function(value, message) {\n  if (this.maxValidator) {\n    this.validators = this.validators.filter(function(v) {\n      return v.validator !== this.maxValidator;\n    }, this);\n  }\n\n  if (value !== null && value !== undefined) {\n    let msg = message || MongooseError.messages.Number.max;\n    msg = msg.replace(/{MAX}/, value);\n    this.validators.push({\n      validator: this.maxValidator = function(v) {\n        return v == null || v <= value;\n      },\n      message: msg,\n      type: 'max',\n      max: value\n    });\n  }\n\n  return this;\n};\n\n/**\n * Sets a enum validator\n *\n * #### Example:\n *\n *     const s = new Schema({ n: { type: Number, enum: [1, 2, 3] });\n *     const M = db.model('M', s);\n *\n *     const m = new M({ n: 4 });\n *     await m.save(); // throws validation error\n *\n *     m.n = 3;\n *     await m.save(); // succeeds\n *\n * @param {Array} values allowed values\n * @param {String} [message] optional custom error message\n * @return {SchemaType} this\n * @see Customized Error Messages https://mongoosejs.com/docs/api/error.html#Error.messages\n * @api public\n */\n\nSchemaNumber.prototype.enum = function(values, message) {\n  if (this.enumValidator) {\n    this.validators = this.validators.filter(function(v) {\n      return v.validator !== this.enumValidator;\n    }, this);\n  }\n\n\n  if (!Array.isArray(values)) {\n    const isObjectSyntax = utils.isPOJO(values) && values.values != null;\n    if (isObjectSyntax) {\n      message = values.message;\n      values = values.values;\n    } else if (typeof values === 'number') {\n      values = Array.prototype.slice.call(arguments);\n      message = null;\n    }\n\n    if (utils.isPOJO(values)) {\n      values = Object.values(values);\n    }\n    message = message || MongooseError.messages.Number.enum;\n  }\n\n  message = message == null ? MongooseError.messages.Number.enum : message;\n\n  this.enumValidator = v => v == null || values.indexOf(v) !== -1;\n  this.validators.push({\n    validator: this.enumValidator,\n    message: message,\n    type: 'enum',\n    enumValues: values\n  });\n\n  return this;\n};\n\n/**\n * Casts to number\n *\n * @param {Object} value value to cast\n * @param {Document} doc document that triggers the casting\n * @param {Boolean} init\n * @api private\n */\n\nSchemaNumber.prototype.cast = function(value, doc, init) {\n  if (typeof value !== 'number' && SchemaType._isRef(this, value, doc, init)) {\n    if (value == null || utils.isNonBuiltinObject(value)) {\n      return this._castRef(value, doc, init);\n    }\n  }\n\n  const val = value && typeof value._id !== 'undefined' ?\n    value._id : // documents\n    value;\n\n  let castNumber;\n  if (typeof this._castFunction === 'function') {\n    castNumber = this._castFunction;\n  } else if (typeof this.constructor.cast === 'function') {\n    castNumber = this.constructor.cast();\n  } else {\n    castNumber = SchemaNumber.cast();\n  }\n\n  try {\n    return castNumber(val);\n  } catch (err) {\n    throw new CastError('Number', val, this.path, err, this);\n  }\n};\n\n/*!\n * ignore\n */\n\nfunction handleSingle(val) {\n  return this.cast(val);\n}\n\nfunction handleArray(val) {\n  const _this = this;\n  if (!Array.isArray(val)) {\n    return [this.cast(val)];\n  }\n  return val.map(function(m) {\n    return _this.cast(m);\n  });\n}\n\nSchemaNumber.prototype.$conditionalHandlers = {\n  ...SchemaType.prototype.$conditionalHandlers,\n  $bitsAllClear: handleBitwiseOperator,\n  $bitsAnyClear: handleBitwiseOperator,\n  $bitsAllSet: handleBitwiseOperator,\n  $bitsAnySet: handleBitwiseOperator,\n  $gt: handleSingle,\n  $gte: handleSingle,\n  $lt: handleSingle,\n  $lte: handleSingle,\n  $mod: handleArray\n};\n\n/**\n * Casts contents for queries.\n *\n * @param {String} $conditional\n * @param {any} [value]\n * @api private\n */\n\nSchemaNumber.prototype.castForQuery = function($conditional, val, context) {\n  let handler;\n  if ($conditional != null) {\n    handler = this.$conditionalHandlers[$conditional];\n    if (!handler) {\n      throw new CastError('number', val, this.path, null, this);\n    }\n    return handler.call(this, val, context);\n  }\n\n  try {\n    val = this.applySetters(val, context);\n  } catch (err) {\n    if (err instanceof CastError && err.path === this.path && this.$fullPath != null) {\n      err.path = this.$fullPath;\n    }\n    throw err;\n  }\n\n  return val;\n};\n\n/*!\n * Module exports.\n */\n\nmodule.exports = SchemaNumber;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schema/number.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schema/objectId.js":
/*!******************************************************!*\
  !*** ./node_modules/mongoose/lib/schema/objectId.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module dependencies.\n */\n\n\n\nconst SchemaObjectIdOptions = __webpack_require__(/*! ../options/schemaObjectIdOptions */ \"./node_modules/mongoose/lib/options/schemaObjectIdOptions.js\");\nconst SchemaType = __webpack_require__(/*! ../schemaType */ \"./node_modules/mongoose/lib/schemaType.js\");\nconst castObjectId = __webpack_require__(/*! ../cast/objectid */ \"./node_modules/mongoose/lib/cast/objectid.js\");\nconst getConstructorName = __webpack_require__(/*! ../helpers/getConstructorName */ \"./node_modules/mongoose/lib/helpers/getConstructorName.js\");\nconst oid = __webpack_require__(/*! ../types/objectid */ \"./node_modules/mongoose/lib/types/objectid.js\");\nconst isBsonType = __webpack_require__(/*! ../helpers/isBsonType */ \"./node_modules/mongoose/lib/helpers/isBsonType.js\");\nconst utils = __webpack_require__(/*! ../utils */ \"./node_modules/mongoose/lib/utils.js\");\n\nconst CastError = SchemaType.CastError;\nlet Document;\n\n/**\n * ObjectId SchemaType constructor.\n *\n * @param {String} key\n * @param {Object} options\n * @inherits SchemaType\n * @api public\n */\n\nfunction SchemaObjectId(key, options) {\n  const isKeyHexStr = typeof key === 'string' && key.length === 24 && /^[a-f0-9]+$/i.test(key);\n  const suppressWarning = options && options.suppressWarning;\n  if ((isKeyHexStr || typeof key === 'undefined') && !suppressWarning) {\n    utils.warn('mongoose: To create a new ObjectId please try ' +\n      '`Mongoose.Types.ObjectId` instead of using ' +\n      '`Mongoose.Schema.ObjectId`. Set the `suppressWarning` option if ' +\n      'you\\'re trying to create a hex char path in your schema.');\n  }\n  SchemaType.call(this, key, options, 'ObjectId');\n}\n\n/**\n * This schema type's name, to defend against minifiers that mangle\n * function names.\n *\n * @api public\n */\nSchemaObjectId.schemaName = 'ObjectId';\n\nSchemaObjectId.defaultOptions = {};\n\n/*!\n * Inherits from SchemaType.\n */\nSchemaObjectId.prototype = Object.create(SchemaType.prototype);\nSchemaObjectId.prototype.constructor = SchemaObjectId;\nSchemaObjectId.prototype.OptionsConstructor = SchemaObjectIdOptions;\n\n/**\n * Attaches a getter for all ObjectId instances\n *\n * #### Example:\n *\n *     // Always convert to string when getting an ObjectId\n *     mongoose.ObjectId.get(v => v.toString());\n *\n *     const Model = mongoose.model('Test', new Schema({}));\n *     typeof (new Model({})._id); // 'string'\n *\n * @param {Function} getter\n * @return {this}\n * @function get\n * @static\n * @api public\n */\n\nSchemaObjectId.get = SchemaType.get;\n\n/**\n * Sets a default option for all ObjectId instances.\n *\n * #### Example:\n *\n *     // Make all object ids have option `required` equal to true.\n *     mongoose.Schema.ObjectId.set('required', true);\n *\n *     const Order = mongoose.model('Order', new Schema({ userId: ObjectId }));\n *     new Order({ }).validateSync().errors.userId.message; // Path `userId` is required.\n *\n * @param {String} option The option you'd like to set the value for\n * @param {Any} value value for option\n * @return {undefined}\n * @function set\n * @static\n * @api public\n */\n\nSchemaObjectId.set = SchemaType.set;\n\nSchemaObjectId.setters = [];\n\n/**\n * Adds an auto-generated ObjectId default if turnOn is true.\n * @param {Boolean} turnOn auto generated ObjectId defaults\n * @api public\n * @return {SchemaType} this\n */\n\nSchemaObjectId.prototype.auto = function(turnOn) {\n  if (turnOn) {\n    this.default(defaultId);\n    this.set(resetId);\n  }\n\n  return this;\n};\n\n/*!\n * ignore\n */\n\nSchemaObjectId._checkRequired = v => isBsonType(v, 'ObjectId');\n\n/*!\n * ignore\n */\n\nSchemaObjectId._cast = castObjectId;\n\n/**\n * Get/set the function used to cast arbitrary values to objectids.\n *\n * #### Example:\n *\n *     // Make Mongoose only try to cast length 24 strings. By default, any 12\n *     // char string is a valid ObjectId.\n *     const original = mongoose.ObjectId.cast();\n *     mongoose.ObjectId.cast(v => {\n *       assert.ok(typeof v !== 'string' || v.length === 24);\n *       return original(v);\n *     });\n *\n *     // Or disable casting entirely\n *     mongoose.ObjectId.cast(false);\n *\n * @param {Function} caster\n * @return {Function}\n * @function get\n * @static\n * @api public\n */\n\nSchemaObjectId.cast = function cast(caster) {\n  if (arguments.length === 0) {\n    return this._cast;\n  }\n  if (caster === false) {\n    caster = this._defaultCaster;\n  }\n  this._cast = caster;\n\n  return this._cast;\n};\n\n/*!\n * ignore\n */\n\nSchemaObjectId._defaultCaster = v => {\n  if (!(isBsonType(v, 'ObjectId'))) {\n    throw new Error(v + ' is not an instance of ObjectId');\n  }\n  return v;\n};\n\n/**\n * Override the function the required validator uses to check whether a string\n * passes the `required` check.\n *\n * #### Example:\n *\n *     // Allow empty strings to pass `required` check\n *     mongoose.Schema.Types.String.checkRequired(v => v != null);\n *\n *     const M = mongoose.model({ str: { type: String, required: true } });\n *     new M({ str: '' }).validateSync(); // `null`, validation passes!\n *\n * @param {Function} fn\n * @return {Function}\n * @function checkRequired\n * @static\n * @api public\n */\n\nSchemaObjectId.checkRequired = SchemaType.checkRequired;\n\n/**\n * Check if the given value satisfies a required validator.\n *\n * @param {Any} value\n * @param {Document} doc\n * @return {Boolean}\n * @api public\n */\n\nSchemaObjectId.prototype.checkRequired = function checkRequired(value, doc) {\n  if (SchemaType._isRef(this, value, doc, true)) {\n    return !!value;\n  }\n\n  // `require('util').inherits()` does **not** copy static properties, and\n  // plugins like mongoose-float use `inherits()` for pre-ES6.\n  const _checkRequired = typeof this.constructor.checkRequired === 'function' ?\n    this.constructor.checkRequired() :\n    SchemaObjectId.checkRequired();\n\n  return _checkRequired(value);\n};\n\n/**\n * Casts to ObjectId\n *\n * @param {Object} value\n * @param {Object} doc\n * @param {Boolean} init whether this is an initialization cast\n * @api private\n */\n\nSchemaObjectId.prototype.cast = function(value, doc, init) {\n  if (!(isBsonType(value, 'ObjectId')) && SchemaType._isRef(this, value, doc, init)) {\n    // wait! we may need to cast this to a document\n    if ((getConstructorName(value) || '').toLowerCase() === 'objectid') {\n      return new oid(value.toHexString());\n    }\n\n    if (value == null || utils.isNonBuiltinObject(value)) {\n      return this._castRef(value, doc, init);\n    }\n  }\n\n  let castObjectId;\n  if (typeof this._castFunction === 'function') {\n    castObjectId = this._castFunction;\n  } else if (typeof this.constructor.cast === 'function') {\n    castObjectId = this.constructor.cast();\n  } else {\n    castObjectId = SchemaObjectId.cast();\n  }\n\n  try {\n    return castObjectId(value);\n  } catch (error) {\n    throw new CastError('ObjectId', value, this.path, error, this);\n  }\n};\n\n/*!\n * ignore\n */\n\nfunction handleSingle(val) {\n  return this.cast(val);\n}\n\nSchemaObjectId.prototype.$conditionalHandlers = {\n  ...SchemaType.prototype.$conditionalHandlers,\n  $gt: handleSingle,\n  $gte: handleSingle,\n  $lt: handleSingle,\n  $lte: handleSingle\n};\n\n/*!\n * ignore\n */\n\nfunction defaultId() {\n  return new oid();\n}\n\ndefaultId.$runBeforeSetters = true;\n\nfunction resetId(v) {\n  Document || (Document = __webpack_require__(/*! ../document */ \"./node_modules/mongoose/lib/document.js\"));\n\n  if (this instanceof Document) {\n    if (v === void 0) {\n      const _v = new oid();\n      return _v;\n    }\n  }\n\n  return v;\n}\n\n/*!\n * Module exports.\n */\n\nmodule.exports = SchemaObjectId;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schema/objectId.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schema/operators/bitwise.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongoose/lib/schema/operators/bitwise.js ***!
  \***************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module requirements.\n */\n\n\n\nconst CastError = __webpack_require__(/*! ../../error/cast */ \"./node_modules/mongoose/lib/error/cast.js\");\n\n/*!\n * ignore\n */\n\nfunction handleBitwiseOperator(val) {\n  const _this = this;\n  if (Array.isArray(val)) {\n    return val.map(function(v) {\n      return _castNumber(_this.path, v);\n    });\n  } else if (Buffer.isBuffer(val)) {\n    return val;\n  }\n  // Assume trying to cast to number\n  return _castNumber(_this.path, val);\n}\n\n/*!\n * ignore\n */\n\nfunction _castNumber(path, num) {\n  const v = Number(num);\n  if (isNaN(v)) {\n    throw new CastError('number', num, path);\n  }\n  return v;\n}\n\nmodule.exports = handleBitwiseOperator;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schema/operators/bitwise.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schema/operators/exists.js":
/*!**************************************************************!*\
  !*** ./node_modules/mongoose/lib/schema/operators/exists.js ***!
  \**************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst castBoolean = __webpack_require__(/*! ../../cast/boolean */ \"./node_modules/mongoose/lib/cast/boolean.js\");\n\n/*!\n * ignore\n */\n\nmodule.exports = function(val) {\n  const path = this != null ? this.path : null;\n  return castBoolean(val, path);\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schema/operators/exists.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schema/operators/geospatial.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongoose/lib/schema/operators/geospatial.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module requirements.\n */\n\n\n\nconst castArraysOfNumbers = (__webpack_require__(/*! ./helpers */ \"./node_modules/mongoose/lib/schema/operators/helpers.js\").castArraysOfNumbers);\nconst castToNumber = (__webpack_require__(/*! ./helpers */ \"./node_modules/mongoose/lib/schema/operators/helpers.js\").castToNumber);\n\n/*!\n * ignore\n */\n\nexports.cast$geoIntersects = cast$geoIntersects;\nexports.cast$near = cast$near;\nexports.cast$within = cast$within;\n\nfunction cast$near(val) {\n  const SchemaArray = __webpack_require__(/*! ../array */ \"./node_modules/mongoose/lib/schema/array.js\");\n\n  if (Array.isArray(val)) {\n    castArraysOfNumbers(val, this);\n    return val;\n  }\n\n  _castMinMaxDistance(this, val);\n\n  if (val && val.$geometry) {\n    return cast$geometry(val, this);\n  }\n\n  if (!Array.isArray(val)) {\n    throw new TypeError('$near must be either an array or an object ' +\n      'with a $geometry property');\n  }\n\n  return SchemaArray.prototype.castForQuery.call(this, null, val);\n}\n\nfunction cast$geometry(val, self) {\n  switch (val.$geometry.type) {\n    case 'Polygon':\n    case 'LineString':\n    case 'Point':\n      castArraysOfNumbers(val.$geometry.coordinates, self);\n      break;\n    default:\n      // ignore unknowns\n      break;\n  }\n\n  _castMinMaxDistance(self, val);\n\n  return val;\n}\n\nfunction cast$within(val) {\n  _castMinMaxDistance(this, val);\n\n  if (val.$box || val.$polygon) {\n    const type = val.$box ? '$box' : '$polygon';\n    val[type].forEach(arr => {\n      if (!Array.isArray(arr)) {\n        const msg = 'Invalid $within $box argument. '\n            + 'Expected an array, received ' + arr;\n        throw new TypeError(msg);\n      }\n      arr.forEach((v, i) => {\n        arr[i] = castToNumber.call(this, v);\n      });\n    });\n  } else if (val.$center || val.$centerSphere) {\n    const type = val.$center ? '$center' : '$centerSphere';\n    val[type].forEach((item, i) => {\n      if (Array.isArray(item)) {\n        item.forEach((v, j) => {\n          item[j] = castToNumber.call(this, v);\n        });\n      } else {\n        val[type][i] = castToNumber.call(this, item);\n      }\n    });\n  } else if (val.$geometry) {\n    cast$geometry(val, this);\n  }\n\n  return val;\n}\n\nfunction cast$geoIntersects(val) {\n  const geo = val.$geometry;\n  if (!geo) {\n    return;\n  }\n\n  cast$geometry(val, this);\n  return val;\n}\n\nfunction _castMinMaxDistance(self, val) {\n  if (val.$maxDistance) {\n    val.$maxDistance = castToNumber.call(self, val.$maxDistance);\n  }\n  if (val.$minDistance) {\n    val.$minDistance = castToNumber.call(self, val.$minDistance);\n  }\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schema/operators/geospatial.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schema/operators/helpers.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongoose/lib/schema/operators/helpers.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module requirements.\n */\n\nconst SchemaNumber = __webpack_require__(/*! ../number */ \"./node_modules/mongoose/lib/schema/number.js\");\n\n/*!\n * ignore\n */\n\nexports.castToNumber = castToNumber;\nexports.castArraysOfNumbers = castArraysOfNumbers;\n\n/*!\n * ignore\n */\n\nfunction castToNumber(val) {\n  return SchemaNumber.cast()(val);\n}\n\nfunction castArraysOfNumbers(arr, self) {\n  arr.forEach(function(v, i) {\n    if (Array.isArray(v)) {\n      castArraysOfNumbers(v, self);\n    } else {\n      arr[i] = castToNumber.call(self, v);\n    }\n  });\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schema/operators/helpers.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schema/operators/text.js":
/*!************************************************************!*\
  !*** ./node_modules/mongoose/lib/schema/operators/text.js ***!
  \************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst CastError = __webpack_require__(/*! ../../error/cast */ \"./node_modules/mongoose/lib/error/cast.js\");\nconst castBoolean = __webpack_require__(/*! ../../cast/boolean */ \"./node_modules/mongoose/lib/cast/boolean.js\");\nconst castString = __webpack_require__(/*! ../../cast/string */ \"./node_modules/mongoose/lib/cast/string.js\");\n\n/**\n * Casts val to an object suitable for `$text`. Throws an error if the object\n * can't be casted.\n *\n * @param {Any} val value to cast\n * @param {String} [path] path to associate with any errors that occured\n * @return {Object} casted object\n * @see https://www.mongodb.com/docs/manual/reference/operator/query/text/\n * @api private\n */\n\nmodule.exports = function(val, path) {\n  if (val == null || typeof val !== 'object') {\n    throw new CastError('$text', val, path);\n  }\n\n  if (val.$search != null) {\n    val.$search = castString(val.$search, path + '.$search');\n  }\n  if (val.$language != null) {\n    val.$language = castString(val.$language, path + '.$language');\n  }\n  if (val.$caseSensitive != null) {\n    val.$caseSensitive = castBoolean(val.$caseSensitive,\n      path + '.$castSensitive');\n  }\n  if (val.$diacriticSensitive != null) {\n    val.$diacriticSensitive = castBoolean(val.$diacriticSensitive,\n      path + '.$diacriticSensitive');\n  }\n\n  return val;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schema/operators/text.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schema/operators/type.js":
/*!************************************************************!*\
  !*** ./node_modules/mongoose/lib/schema/operators/type.js ***!
  \************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/*!\n * ignore\n */\n\nmodule.exports = function(val) {\n  if (Array.isArray(val)) {\n    if (!val.every(v => typeof v === 'number' || typeof v === 'string')) {\n      throw new Error('$type array values must be strings or numbers');\n    }\n    return val;\n  }\n\n  if (typeof val !== 'number' && typeof val !== 'string') {\n    throw new Error('$type parameter must be number, string, or array of numbers and strings');\n  }\n\n  return val;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schema/operators/type.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schema/string.js":
/*!****************************************************!*\
  !*** ./node_modules/mongoose/lib/schema/string.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst SchemaType = __webpack_require__(/*! ../schemaType */ \"./node_modules/mongoose/lib/schemaType.js\");\nconst MongooseError = __webpack_require__(/*! ../error/index */ \"./node_modules/mongoose/lib/error/index.js\");\nconst SchemaStringOptions = __webpack_require__(/*! ../options/schemaStringOptions */ \"./node_modules/mongoose/lib/options/schemaStringOptions.js\");\nconst castString = __webpack_require__(/*! ../cast/string */ \"./node_modules/mongoose/lib/cast/string.js\");\nconst utils = __webpack_require__(/*! ../utils */ \"./node_modules/mongoose/lib/utils.js\");\nconst isBsonType = __webpack_require__(/*! ../helpers/isBsonType */ \"./node_modules/mongoose/lib/helpers/isBsonType.js\");\n\nconst CastError = SchemaType.CastError;\n\n/**\n * String SchemaType constructor.\n *\n * @param {String} key\n * @param {Object} options\n * @inherits SchemaType\n * @api public\n */\n\nfunction SchemaString(key, options) {\n  this.enumValues = [];\n  this.regExp = null;\n  SchemaType.call(this, key, options, 'String');\n}\n\n/**\n * This schema type's name, to defend against minifiers that mangle\n * function names.\n *\n * @api public\n */\nSchemaString.schemaName = 'String';\n\nSchemaString.defaultOptions = {};\n\n/*!\n * Inherits from SchemaType.\n */\nSchemaString.prototype = Object.create(SchemaType.prototype);\nSchemaString.prototype.constructor = SchemaString;\nObject.defineProperty(SchemaString.prototype, 'OptionsConstructor', {\n  configurable: false,\n  enumerable: false,\n  writable: false,\n  value: SchemaStringOptions\n});\n\n/*!\n * ignore\n */\n\nSchemaString._cast = castString;\n\n/**\n * Get/set the function used to cast arbitrary values to strings.\n *\n * #### Example:\n *\n *     // Throw an error if you pass in an object. Normally, Mongoose allows\n *     // objects with custom `toString()` functions.\n *     const original = mongoose.Schema.Types.String.cast();\n *     mongoose.Schema.Types.String.cast(v => {\n *       assert.ok(v == null || typeof v !== 'object');\n *       return original(v);\n *     });\n *\n *     // Or disable casting entirely\n *     mongoose.Schema.Types.String.cast(false);\n *\n * @param {Function} caster\n * @return {Function}\n * @function get\n * @static\n * @api public\n */\n\nSchemaString.cast = function cast(caster) {\n  if (arguments.length === 0) {\n    return this._cast;\n  }\n  if (caster === false) {\n    caster = this._defaultCaster;\n  }\n  this._cast = caster;\n\n  return this._cast;\n};\n\n/*!\n * ignore\n */\n\nSchemaString._defaultCaster = v => {\n  if (v != null && typeof v !== 'string') {\n    throw new Error();\n  }\n  return v;\n};\n\n/**\n * Attaches a getter for all String instances.\n *\n * #### Example:\n *\n *     // Make all numbers round down\n *     mongoose.Schema.String.get(v => v.toLowerCase());\n *\n *     const Model = mongoose.model('Test', new Schema({ test: String }));\n *     new Model({ test: 'FOO' }).test; // 'foo'\n *\n * @param {Function} getter\n * @return {this}\n * @function get\n * @static\n * @api public\n */\n\nSchemaString.get = SchemaType.get;\n\n/**\n * Sets a default option for all String instances.\n *\n * #### Example:\n *\n *     // Make all strings have option `trim` equal to true.\n *     mongoose.Schema.String.set('trim', true);\n *\n *     const User = mongoose.model('User', new Schema({ name: String }));\n *     new User({ name: '   John Doe   ' }).name; // 'John Doe'\n *\n * @param {String} option The option you'd like to set the value for\n * @param {Any} value value for option\n * @return {undefined}\n * @function set\n * @static\n * @api public\n */\n\nSchemaString.set = SchemaType.set;\n\nSchemaString.setters = [];\n\n/*!\n * ignore\n */\n\nSchemaString._checkRequired = v => (v instanceof String || typeof v === 'string') && v.length;\n\n/**\n * Override the function the required validator uses to check whether a string\n * passes the `required` check.\n *\n * #### Example:\n *\n *     // Allow empty strings to pass `required` check\n *     mongoose.Schema.Types.String.checkRequired(v => v != null);\n *\n *     const M = mongoose.model({ str: { type: String, required: true } });\n *     new M({ str: '' }).validateSync(); // `null`, validation passes!\n *\n * @param {Function} fn\n * @return {Function}\n * @function checkRequired\n * @static\n * @api public\n */\n\nSchemaString.checkRequired = SchemaType.checkRequired;\n\n/**\n * Adds an enum validator\n *\n * #### Example:\n *\n *     const states = ['opening', 'open', 'closing', 'closed']\n *     const s = new Schema({ state: { type: String, enum: states }})\n *     const M = db.model('M', s)\n *     const m = new M({ state: 'invalid' })\n *     m.save(function (err) {\n *       console.error(String(err)) // ValidationError: `invalid` is not a valid enum value for path `state`.\n *       m.state = 'open'\n *       m.save(callback) // success\n *     })\n *\n *     // or with custom error messages\n *     const enum = {\n *       values: ['opening', 'open', 'closing', 'closed'],\n *       message: 'enum validator failed for path `{PATH}` with value `{VALUE}`'\n *     }\n *     const s = new Schema({ state: { type: String, enum: enum })\n *     const M = db.model('M', s)\n *     const m = new M({ state: 'invalid' })\n *     m.save(function (err) {\n *       console.error(String(err)) // ValidationError: enum validator failed for path `state` with value `invalid`\n *       m.state = 'open'\n *       m.save(callback) // success\n *     })\n *\n * @param {...String|Object} [args] enumeration values\n * @return {SchemaType} this\n * @see Customized Error Messages https://mongoosejs.com/docs/api/error.html#Error.messages\n * @see Enums in JavaScript https://masteringjs.io/tutorials/fundamentals/enum\n * @api public\n */\n\nSchemaString.prototype.enum = function() {\n  if (this.enumValidator) {\n    this.validators = this.validators.filter(function(v) {\n      return v.validator !== this.enumValidator;\n    }, this);\n    this.enumValidator = false;\n  }\n\n  if (arguments[0] === void 0 || arguments[0] === false) {\n    return this;\n  }\n\n  let values;\n  let errorMessage;\n\n  if (utils.isObject(arguments[0])) {\n    if (Array.isArray(arguments[0].values)) {\n      values = arguments[0].values;\n      errorMessage = arguments[0].message;\n    } else {\n      values = utils.object.vals(arguments[0]);\n      errorMessage = MongooseError.messages.String.enum;\n    }\n  } else {\n    values = arguments;\n    errorMessage = MongooseError.messages.String.enum;\n  }\n\n  for (const value of values) {\n    if (value !== undefined) {\n      this.enumValues.push(this.cast(value));\n    }\n  }\n\n  const vals = this.enumValues;\n  this.enumValidator = function(v) {\n    return null == v || ~vals.indexOf(v);\n  };\n  this.validators.push({\n    validator: this.enumValidator,\n    message: errorMessage,\n    type: 'enum',\n    enumValues: vals\n  });\n\n  return this;\n};\n\n/**\n * Adds a lowercase [setter](https://mongoosejs.com/docs/api/schematype.html#SchemaType.prototype.set()).\n *\n * #### Example:\n *\n *     const s = new Schema({ email: { type: String, lowercase: true }})\n *     const M = db.model('M', s);\n *     const m = new M({ email: 'SomeEmail@example.COM' });\n *     console.log(m.email) // someemail@example.com\n *     M.find({ email: 'SomeEmail@example.com' }); // Queries by 'someemail@example.com'\n *\n * Note that `lowercase` does **not** affect regular expression queries:\n *\n * #### Example:\n *\n *     // Still queries for documents whose `email` matches the regular\n *     // expression /SomeEmail/. Mongoose does **not** convert the RegExp\n *     // to lowercase.\n *     M.find({ email: /SomeEmail/ });\n *\n * @api public\n * @return {SchemaType} this\n */\n\nSchemaString.prototype.lowercase = function(shouldApply) {\n  if (arguments.length > 0 && !shouldApply) {\n    return this;\n  }\n  return this.set(v => {\n    if (typeof v !== 'string') {\n      v = this.cast(v);\n    }\n    if (v) {\n      return v.toLowerCase();\n    }\n    return v;\n  });\n};\n\n/**\n * Adds an uppercase [setter](https://mongoosejs.com/docs/api/schematype.html#SchemaType.prototype.set()).\n *\n * #### Example:\n *\n *     const s = new Schema({ caps: { type: String, uppercase: true }})\n *     const M = db.model('M', s);\n *     const m = new M({ caps: 'an example' });\n *     console.log(m.caps) // AN EXAMPLE\n *     M.find({ caps: 'an example' }) // Matches documents where caps = 'AN EXAMPLE'\n *\n * Note that `uppercase` does **not** affect regular expression queries:\n *\n * #### Example:\n *\n *     // Mongoose does **not** convert the RegExp to uppercase.\n *     M.find({ email: /an example/ });\n *\n * @api public\n * @return {SchemaType} this\n */\n\nSchemaString.prototype.uppercase = function(shouldApply) {\n  if (arguments.length > 0 && !shouldApply) {\n    return this;\n  }\n  return this.set(v => {\n    if (typeof v !== 'string') {\n      v = this.cast(v);\n    }\n    if (v) {\n      return v.toUpperCase();\n    }\n    return v;\n  });\n};\n\n/**\n * Adds a trim [setter](https://mongoosejs.com/docs/api/schematype.html#SchemaType.prototype.set()).\n *\n * The string value will be [trimmed](https://masteringjs.io/tutorials/fundamentals/trim-string) when set.\n *\n * #### Example:\n *\n *     const s = new Schema({ name: { type: String, trim: true }});\n *     const M = db.model('M', s);\n *     const string = ' some name ';\n *     console.log(string.length); // 11\n *     const m = new M({ name: string });\n *     console.log(m.name.length); // 9\n *\n *     // Equivalent to `findOne({ name: string.trim() })`\n *     M.findOne({ name: string });\n *\n * Note that `trim` does **not** affect regular expression queries:\n *\n * #### Example:\n *\n *     // Mongoose does **not** trim whitespace from the RegExp.\n *     M.find({ name: / some name / });\n *\n * @api public\n * @return {SchemaType} this\n */\n\nSchemaString.prototype.trim = function(shouldTrim) {\n  if (arguments.length > 0 && !shouldTrim) {\n    return this;\n  }\n  return this.set(v => {\n    if (typeof v !== 'string') {\n      v = this.cast(v);\n    }\n    if (v) {\n      return v.trim();\n    }\n    return v;\n  });\n};\n\n/**\n * Sets a minimum length validator.\n *\n * #### Example:\n *\n *     const schema = new Schema({ postalCode: { type: String, minlength: 5 })\n *     const Address = db.model('Address', schema)\n *     const address = new Address({ postalCode: '9512' })\n *     address.save(function (err) {\n *       console.error(err) // validator error\n *       address.postalCode = '95125';\n *       address.save() // success\n *     })\n *\n *     // custom error messages\n *     // We can also use the special {MINLENGTH} token which will be replaced with the minimum allowed length\n *     const minlength = [5, 'The value of path `{PATH}` (`{VALUE}`) is shorter than the minimum allowed length ({MINLENGTH}).'];\n *     const schema = new Schema({ postalCode: { type: String, minlength: minlength })\n *     const Address = mongoose.model('Address', schema);\n *     const address = new Address({ postalCode: '9512' });\n *     address.validate(function (err) {\n *       console.log(String(err)) // ValidationError: The value of path `postalCode` (`9512`) is shorter than the minimum length (5).\n *     })\n *\n * @param {Number} value minimum string length\n * @param {String} [message] optional custom error message\n * @return {SchemaType} this\n * @see Customized Error Messages https://mongoosejs.com/docs/api/error.html#Error.messages\n * @api public\n */\n\nSchemaString.prototype.minlength = function(value, message) {\n  if (this.minlengthValidator) {\n    this.validators = this.validators.filter(function(v) {\n      return v.validator !== this.minlengthValidator;\n    }, this);\n  }\n\n  if (value !== null && value !== undefined) {\n    let msg = message || MongooseError.messages.String.minlength;\n    msg = msg.replace(/{MINLENGTH}/, value);\n    this.validators.push({\n      validator: this.minlengthValidator = function(v) {\n        return v === null || v.length >= value;\n      },\n      message: msg,\n      type: 'minlength',\n      minlength: value\n    });\n  }\n\n  return this;\n};\n\nSchemaString.prototype.minLength = SchemaString.prototype.minlength;\n\n/**\n * Sets a maximum length validator.\n *\n * #### Example:\n *\n *     const schema = new Schema({ postalCode: { type: String, maxlength: 9 })\n *     const Address = db.model('Address', schema)\n *     const address = new Address({ postalCode: '9512512345' })\n *     address.save(function (err) {\n *       console.error(err) // validator error\n *       address.postalCode = '95125';\n *       address.save() // success\n *     })\n *\n *     // custom error messages\n *     // We can also use the special {MAXLENGTH} token which will be replaced with the maximum allowed length\n *     const maxlength = [9, 'The value of path `{PATH}` (`{VALUE}`) exceeds the maximum allowed length ({MAXLENGTH}).'];\n *     const schema = new Schema({ postalCode: { type: String, maxlength: maxlength })\n *     const Address = mongoose.model('Address', schema);\n *     const address = new Address({ postalCode: '9512512345' });\n *     address.validate(function (err) {\n *       console.log(String(err)) // ValidationError: The value of path `postalCode` (`9512512345`) exceeds the maximum allowed length (9).\n *     })\n *\n * @param {Number} value maximum string length\n * @param {String} [message] optional custom error message\n * @return {SchemaType} this\n * @see Customized Error Messages https://mongoosejs.com/docs/api/error.html#Error.messages\n * @api public\n */\n\nSchemaString.prototype.maxlength = function(value, message) {\n  if (this.maxlengthValidator) {\n    this.validators = this.validators.filter(function(v) {\n      return v.validator !== this.maxlengthValidator;\n    }, this);\n  }\n\n  if (value !== null && value !== undefined) {\n    let msg = message || MongooseError.messages.String.maxlength;\n    msg = msg.replace(/{MAXLENGTH}/, value);\n    this.validators.push({\n      validator: this.maxlengthValidator = function(v) {\n        return v === null || v.length <= value;\n      },\n      message: msg,\n      type: 'maxlength',\n      maxlength: value\n    });\n  }\n\n  return this;\n};\n\nSchemaString.prototype.maxLength = SchemaString.prototype.maxlength;\n\n/**\n * Sets a regexp validator.\n *\n * Any value that does not pass `regExp`.test(val) will fail validation.\n *\n * #### Example:\n *\n *     const s = new Schema({ name: { type: String, match: /^a/ }})\n *     const M = db.model('M', s)\n *     const m = new M({ name: 'I am invalid' })\n *     m.validate(function (err) {\n *       console.error(String(err)) // \"ValidationError: Path `name` is invalid (I am invalid).\"\n *       m.name = 'apples'\n *       m.validate(function (err) {\n *         assert.ok(err) // success\n *       })\n *     })\n *\n *     // using a custom error message\n *     const match = [ /\\.html$/, \"That file doesn't end in .html ({VALUE})\" ];\n *     const s = new Schema({ file: { type: String, match: match }})\n *     const M = db.model('M', s);\n *     const m = new M({ file: 'invalid' });\n *     m.validate(function (err) {\n *       console.log(String(err)) // \"ValidationError: That file doesn't end in .html (invalid)\"\n *     })\n *\n * Empty strings, `undefined`, and `null` values always pass the match validator. If you require these values, enable the `required` validator also.\n *\n *     const s = new Schema({ name: { type: String, match: /^a/, required: true }})\n *\n * @param {RegExp} regExp regular expression to test against\n * @param {String} [message] optional custom error message\n * @return {SchemaType} this\n * @see Customized Error Messages https://mongoosejs.com/docs/api/error.html#Error.messages\n * @api public\n */\n\nSchemaString.prototype.match = function match(regExp, message) {\n  // yes, we allow multiple match validators\n\n  const msg = message || MongooseError.messages.String.match;\n\n  const matchValidator = function(v) {\n    if (!regExp) {\n      return false;\n    }\n\n    // In case RegExp happens to have `/g` flag set, we need to reset the\n    // `lastIndex`, otherwise `match` will intermittently fail.\n    regExp.lastIndex = 0;\n\n    const ret = ((v != null && v !== '')\n      ? regExp.test(v)\n      : true);\n    return ret;\n  };\n\n  this.validators.push({\n    validator: matchValidator,\n    message: msg,\n    type: 'regexp',\n    regexp: regExp\n  });\n  return this;\n};\n\n/**\n * Check if the given value satisfies the `required` validator. The value is\n * considered valid if it is a string (that is, not `null` or `undefined`) and\n * has positive length. The `required` validator **will** fail for empty\n * strings.\n *\n * @param {Any} value\n * @param {Document} doc\n * @return {Boolean}\n * @api public\n */\n\nSchemaString.prototype.checkRequired = function checkRequired(value, doc) {\n  if (typeof value === 'object' && SchemaType._isRef(this, value, doc, true)) {\n    return value != null;\n  }\n\n  // `require('util').inherits()` does **not** copy static properties, and\n  // plugins like mongoose-float use `inherits()` for pre-ES6.\n  const _checkRequired = typeof this.constructor.checkRequired === 'function' ?\n    this.constructor.checkRequired() :\n    SchemaString.checkRequired();\n\n  return _checkRequired(value);\n};\n\n/**\n * Casts to String\n *\n * @api private\n */\n\nSchemaString.prototype.cast = function(value, doc, init) {\n  if (typeof value !== 'string' && SchemaType._isRef(this, value, doc, init)) {\n    return this._castRef(value, doc, init);\n  }\n\n  let castString;\n  if (typeof this._castFunction === 'function') {\n    castString = this._castFunction;\n  } else if (typeof this.constructor.cast === 'function') {\n    castString = this.constructor.cast();\n  } else {\n    castString = SchemaString.cast();\n  }\n\n  try {\n    return castString(value);\n  } catch (error) {\n    throw new CastError('string', value, this.path, null, this);\n  }\n};\n\n/*!\n * ignore\n */\n\nfunction handleSingle(val, context) {\n  return this.castForQuery(null, val, context);\n}\n\n/*!\n * ignore\n */\n\nfunction handleArray(val, context) {\n  const _this = this;\n  if (!Array.isArray(val)) {\n    return [this.castForQuery(null, val, context)];\n  }\n  return val.map(function(m) {\n    return _this.castForQuery(null, m, context);\n  });\n}\n\n/*!\n * ignore\n */\n\nfunction handleSingleNoSetters(val) {\n  if (val == null) {\n    return this._castNullish(val);\n  }\n\n  return this.cast(val, this);\n}\n\nconst $conditionalHandlers = {\n  ...SchemaType.prototype.$conditionalHandlers,\n  $all: handleArray,\n  $gt: handleSingle,\n  $gte: handleSingle,\n  $lt: handleSingle,\n  $lte: handleSingle,\n  $options: handleSingleNoSetters,\n  $regex: function handle$regex(val) {\n    if (Object.prototype.toString.call(val) === '[object RegExp]') {\n      return val;\n    }\n\n    return handleSingleNoSetters.call(this, val);\n  },\n  $not: handleSingle\n};\n\nObject.defineProperty(SchemaString.prototype, '$conditionalHandlers', {\n  configurable: false,\n  enumerable: false,\n  writable: false,\n  value: Object.freeze($conditionalHandlers)\n});\n\n/**\n * Casts contents for queries.\n *\n * @param {String} $conditional\n * @param {any} [val]\n * @api private\n */\n\nSchemaString.prototype.castForQuery = function($conditional, val, context) {\n  let handler;\n  if ($conditional != null) {\n    handler = this.$conditionalHandlers[$conditional];\n    if (!handler) {\n      throw new Error('Can\\'t use ' + $conditional + ' with String.');\n    }\n    return handler.call(this, val, context);\n  }\n\n  if (Object.prototype.toString.call(val) === '[object RegExp]' || isBsonType(val, 'BSONRegExp')) {\n    return val;\n  }\n\n  try {\n    return this.applySetters(val, context);\n  } catch (err) {\n    if (err instanceof CastError && err.path === this.path && this.$fullPath != null) {\n      err.path = this.$fullPath;\n    }\n    throw err;\n  }\n};\n\n/*!\n * Module exports.\n */\n\nmodule.exports = SchemaString;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schema/string.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schema/subdocument.js":
/*!*********************************************************!*\
  !*** ./node_modules/mongoose/lib/schema/subdocument.js ***!
  \*********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst CastError = __webpack_require__(/*! ../error/cast */ \"./node_modules/mongoose/lib/error/cast.js\");\nconst EventEmitter = (__webpack_require__(/*! events */ \"events\").EventEmitter);\nconst ObjectExpectedError = __webpack_require__(/*! ../error/objectExpected */ \"./node_modules/mongoose/lib/error/objectExpected.js\");\nconst SchemaSubdocumentOptions = __webpack_require__(/*! ../options/schemaSubdocumentOptions */ \"./node_modules/mongoose/lib/options/schemaSubdocumentOptions.js\");\nconst SchemaType = __webpack_require__(/*! ../schemaType */ \"./node_modules/mongoose/lib/schemaType.js\");\nconst applyDefaults = __webpack_require__(/*! ../helpers/document/applyDefaults */ \"./node_modules/mongoose/lib/helpers/document/applyDefaults.js\");\nconst $exists = __webpack_require__(/*! ./operators/exists */ \"./node_modules/mongoose/lib/schema/operators/exists.js\");\nconst castToNumber = (__webpack_require__(/*! ./operators/helpers */ \"./node_modules/mongoose/lib/schema/operators/helpers.js\").castToNumber);\nconst discriminator = __webpack_require__(/*! ../helpers/model/discriminator */ \"./node_modules/mongoose/lib/helpers/model/discriminator.js\");\nconst geospatial = __webpack_require__(/*! ./operators/geospatial */ \"./node_modules/mongoose/lib/schema/operators/geospatial.js\");\nconst getConstructor = __webpack_require__(/*! ../helpers/discriminator/getConstructor */ \"./node_modules/mongoose/lib/helpers/discriminator/getConstructor.js\");\nconst handleIdOption = __webpack_require__(/*! ../helpers/schema/handleIdOption */ \"./node_modules/mongoose/lib/helpers/schema/handleIdOption.js\");\nconst internalToObjectOptions = (__webpack_require__(/*! ../options */ \"./node_modules/mongoose/lib/options.js\").internalToObjectOptions);\nconst isExclusive = __webpack_require__(/*! ../helpers/projection/isExclusive */ \"./node_modules/mongoose/lib/helpers/projection/isExclusive.js\");\nconst utils = __webpack_require__(/*! ../utils */ \"./node_modules/mongoose/lib/utils.js\");\nconst InvalidSchemaOptionError = __webpack_require__(/*! ../error/invalidSchemaOption */ \"./node_modules/mongoose/lib/error/invalidSchemaOption.js\");\n\nlet SubdocumentType;\n\nmodule.exports = SchemaSubdocument;\n\n/**\n * Single nested subdocument SchemaType constructor.\n *\n * @param {Schema} schema\n * @param {String} path\n * @param {Object} options\n * @inherits SchemaType\n * @api public\n */\n\nfunction SchemaSubdocument(schema, path, options) {\n  if (schema.options.timeseries) {\n    throw new InvalidSchemaOptionError(path, 'timeseries');\n  }\n  const schemaTypeIdOption = SchemaSubdocument.defaultOptions &&\n    SchemaSubdocument.defaultOptions._id;\n  if (schemaTypeIdOption != null) {\n    options = options || {};\n    options._id = schemaTypeIdOption;\n  }\n\n  schema = handleIdOption(schema, options);\n\n  this.caster = _createConstructor(schema, null, options);\n  this.caster.path = path;\n  this.caster.prototype.$basePath = path;\n  this.schema = schema;\n  this.$isSingleNested = true;\n  this.base = schema.base;\n  SchemaType.call(this, path, options, 'Embedded');\n}\n\n/*!\n * ignore\n */\n\nSchemaSubdocument.prototype = Object.create(SchemaType.prototype);\nSchemaSubdocument.prototype.constructor = SchemaSubdocument;\nSchemaSubdocument.prototype.OptionsConstructor = SchemaSubdocumentOptions;\n\n/*!\n * ignore\n */\n\nfunction _createConstructor(schema, baseClass, options) {\n  // lazy load\n  SubdocumentType || (SubdocumentType = __webpack_require__(/*! ../types/subdocument */ \"./node_modules/mongoose/lib/types/subdocument.js\"));\n\n  const _embedded = function SingleNested(value, path, parent) {\n    this.$__parent = parent;\n    SubdocumentType.apply(this, arguments);\n\n    if (parent == null) {\n      return;\n    }\n    this.$session(parent.$session());\n  };\n\n  schema._preCompile();\n\n  const proto = baseClass != null ? baseClass.prototype : SubdocumentType.prototype;\n  _embedded.prototype = Object.create(proto);\n  _embedded.prototype.$__setSchema(schema);\n  _embedded.prototype.constructor = _embedded;\n  _embedded.$__required = options?.required;\n  _embedded.base = schema.base;\n  _embedded.schema = schema;\n  _embedded.$isSingleNested = true;\n  _embedded.events = new EventEmitter();\n  _embedded.prototype.toBSON = function() {\n    return this.toObject(internalToObjectOptions);\n  };\n\n  // apply methods\n  for (const i in schema.methods) {\n    _embedded.prototype[i] = schema.methods[i];\n  }\n\n  // apply statics\n  for (const i in schema.statics) {\n    _embedded[i] = schema.statics[i];\n  }\n\n  for (const i in EventEmitter.prototype) {\n    _embedded[i] = EventEmitter.prototype[i];\n  }\n\n  return _embedded;\n}\n\n/**\n * Special case for when users use a common location schema to represent\n * locations for use with $geoWithin.\n * https://www.mongodb.com/docs/manual/reference/operator/query/geoWithin/\n *\n * @param {Object} val\n * @api private\n */\n\nSchemaSubdocument.prototype.$conditionalHandlers.$geoWithin = function handle$geoWithin(val, context) {\n  return { $geometry: this.castForQuery(null, val.$geometry, context) };\n};\n\n/*!\n * ignore\n */\n\nSchemaSubdocument.prototype.$conditionalHandlers.$near =\nSchemaSubdocument.prototype.$conditionalHandlers.$nearSphere = geospatial.cast$near;\n\nSchemaSubdocument.prototype.$conditionalHandlers.$within =\nSchemaSubdocument.prototype.$conditionalHandlers.$geoWithin = geospatial.cast$within;\n\nSchemaSubdocument.prototype.$conditionalHandlers.$geoIntersects =\n  geospatial.cast$geoIntersects;\n\nSchemaSubdocument.prototype.$conditionalHandlers.$minDistance = castToNumber;\nSchemaSubdocument.prototype.$conditionalHandlers.$maxDistance = castToNumber;\n\nSchemaSubdocument.prototype.$conditionalHandlers.$exists = $exists;\n\n/**\n * Casts contents\n *\n * @param {Object} value\n * @api private\n */\n\nSchemaSubdocument.prototype.cast = function(val, doc, init, priorVal, options) {\n  if (val && val.$isSingleNested && val.parent === doc) {\n    return val;\n  }\n\n  if (val != null && (typeof val !== 'object' || Array.isArray(val))) {\n    throw new ObjectExpectedError(this.path, val);\n  }\n\n  const discriminatorKeyPath = this.schema.path(this.schema.options.discriminatorKey);\n  const defaultDiscriminatorValue = discriminatorKeyPath == null ? null : discriminatorKeyPath.getDefault(doc);\n  const Constructor = getConstructor(this.caster, val, defaultDiscriminatorValue);\n\n  let subdoc;\n\n  // Only pull relevant selected paths and pull out the base path\n  const parentSelected = doc && doc.$__ && doc.$__.selected;\n  const path = this.path;\n  const selected = parentSelected == null ? null : Object.keys(parentSelected).reduce((obj, key) => {\n    if (key.startsWith(path + '.')) {\n      obj = obj || {};\n      obj[key.substring(path.length + 1)] = parentSelected[key];\n    }\n    return obj;\n  }, null);\n  if (init) {\n    subdoc = new Constructor(void 0, selected, doc, false, { defaults: false });\n    delete subdoc.$__.defaults;\n    subdoc.$init(val);\n    const exclude = isExclusive(selected);\n    applyDefaults(subdoc, selected, exclude);\n  } else {\n    options = Object.assign({}, options, { priorDoc: priorVal });\n    if (Object.keys(val).length === 0) {\n      return new Constructor({}, selected, doc, undefined, options);\n    }\n\n    return new Constructor(val, selected, doc, undefined, options);\n  }\n\n  return subdoc;\n};\n\n/**\n * Casts contents for query\n *\n * @param {string} [$conditional] optional query operator (like `$eq` or `$in`)\n * @param {any} value\n * @api private\n */\n\nSchemaSubdocument.prototype.castForQuery = function($conditional, val, context, options) {\n  let handler;\n  if ($conditional != null) {\n    handler = this.$conditionalHandlers[$conditional];\n    if (!handler) {\n      throw new Error('Can\\'t use ' + $conditional);\n    }\n    return handler.call(this, val);\n  }\n  if (val == null) {\n    return val;\n  }\n\n  const Constructor = getConstructor(this.caster, val);\n  if (val instanceof Constructor) {\n    return val;\n  }\n\n  if (this.options.runSetters) {\n    val = this._applySetters(val, context);\n  }\n\n  const overrideStrict = options != null && options.strict != null ?\n    options.strict :\n    void 0;\n\n  try {\n    val = new Constructor(val, overrideStrict);\n  } catch (error) {\n    // Make sure we always wrap in a CastError (gh-6803)\n    if (!(error instanceof CastError)) {\n      throw new CastError('Embedded', val, this.path, error, this);\n    }\n    throw error;\n  }\n  return val;\n};\n\n/**\n * Async validation on this single nested doc.\n *\n * @api private\n */\n\nSchemaSubdocument.prototype.doValidate = function(value, fn, scope, options) {\n  const Constructor = getConstructor(this.caster, value);\n\n  if (value && !(value instanceof Constructor)) {\n    value = new Constructor(value, null, (scope != null && scope.$__ != null) ? scope : null);\n  }\n\n  if (options && options.skipSchemaValidators) {\n    if (!value) {\n      return fn(null);\n    }\n    return value.validate().then(() => fn(null), err => fn(err));\n  }\n\n  SchemaType.prototype.doValidate.call(this, value, function(error) {\n    if (error) {\n      return fn(error);\n    }\n    if (!value) {\n      return fn(null);\n    }\n\n    value.validate().then(() => fn(null), err => fn(err));\n  }, scope, options);\n};\n\n/**\n * Synchronously validate this single nested doc\n *\n * @api private\n */\n\nSchemaSubdocument.prototype.doValidateSync = function(value, scope, options) {\n  if (!options || !options.skipSchemaValidators) {\n    const schemaTypeError = SchemaType.prototype.doValidateSync.call(this, value, scope);\n    if (schemaTypeError) {\n      return schemaTypeError;\n    }\n  }\n  if (!value) {\n    return;\n  }\n  return value.validateSync();\n};\n\n/**\n * Adds a discriminator to this single nested subdocument.\n *\n * #### Example:\n *\n *     const shapeSchema = Schema({ name: String }, { discriminatorKey: 'kind' });\n *     const schema = Schema({ shape: shapeSchema });\n *\n *     const singleNestedPath = parentSchema.path('shape');\n *     singleNestedPath.discriminator('Circle', Schema({ radius: Number }));\n *\n * @param {String} name\n * @param {Schema} schema fields to add to the schema for instances of this sub-class\n * @param {Object|string} [options] If string, same as `options.value`.\n * @param {String} [options.value] the string stored in the `discriminatorKey` property. If not specified, Mongoose uses the `name` parameter.\n * @param {Boolean} [options.clone=true] By default, `discriminator()` clones the given `schema`. Set to `false` to skip cloning.\n * @return {Function} the constructor Mongoose will use for creating instances of this discriminator model\n * @see discriminators https://mongoosejs.com/docs/discriminators.html\n * @api public\n */\n\nSchemaSubdocument.prototype.discriminator = function(name, schema, options) {\n  options = options || {};\n  const value = utils.isPOJO(options) ? options.value : options;\n  const clone = typeof options.clone === 'boolean'\n    ? options.clone\n    : true;\n\n  if (schema.instanceOfSchema && clone) {\n    schema = schema.clone();\n  }\n\n  schema = discriminator(this.caster, name, schema, value, null, null, options.overwriteExisting);\n\n  this.caster.discriminators[name] = _createConstructor(schema, this.caster);\n\n  return this.caster.discriminators[name];\n};\n\n/*!\n * ignore\n */\n\nSchemaSubdocument.defaultOptions = {};\n\n/**\n * Sets a default option for all Subdocument instances.\n *\n * #### Example:\n *\n *     // Make all numbers have option `min` equal to 0.\n *     mongoose.Schema.Subdocument.set('required', true);\n *\n * @param {String} option The option you'd like to set the value for\n * @param {Any} value value for option\n * @return {void}\n * @function set\n * @static\n * @api public\n */\n\nSchemaSubdocument.set = SchemaType.set;\n\nSchemaSubdocument.setters = [];\n\n/**\n * Attaches a getter for all Subdocument instances\n *\n * @param {Function} getter\n * @return {this}\n * @function get\n * @static\n * @api public\n */\n\nSchemaSubdocument.get = SchemaType.get;\n\n/*!\n * ignore\n */\n\nSchemaSubdocument.prototype.toJSON = function toJSON() {\n  return { path: this.path, options: this.options };\n};\n\n/*!\n * ignore\n */\n\nSchemaSubdocument.prototype.clone = function() {\n  const schematype = new this.constructor(\n    this.schema,\n    this.path,\n    { ...this.options, _skipApplyDiscriminators: true }\n  );\n  schematype.validators = this.validators.slice();\n  if (this.requiredValidator !== undefined) {\n    schematype.requiredValidator = this.requiredValidator;\n  }\n  schematype.caster.discriminators = Object.assign({}, this.caster.discriminators);\n  return schematype;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schema/subdocument.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schema/symbols.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongoose/lib/schema/symbols.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nexports.schemaMixedSymbol = Symbol.for('mongoose:schema_mixed');\n\nexports.builtInMiddleware = Symbol.for('mongoose:built-in-middleware');\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schema/symbols.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schema/uuid.js":
/*!**************************************************!*\
  !*** ./node_modules/mongoose/lib/schema/uuid.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module dependencies.\n */\n\n\n\nconst MongooseBuffer = __webpack_require__(/*! ../types/buffer */ \"./node_modules/mongoose/lib/types/buffer.js\");\nconst SchemaType = __webpack_require__(/*! ../schemaType */ \"./node_modules/mongoose/lib/schemaType.js\");\nconst CastError = SchemaType.CastError;\nconst utils = __webpack_require__(/*! ../utils */ \"./node_modules/mongoose/lib/utils.js\");\nconst handleBitwiseOperator = __webpack_require__(/*! ./operators/bitwise */ \"./node_modules/mongoose/lib/schema/operators/bitwise.js\");\n\nconst UUID_FORMAT = /[0-9a-f]{8}-[0-9a-f]{4}-[0-9][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}/i;\nconst Binary = MongooseBuffer.Binary;\n\n/**\n * Helper function to convert the input hex-string to a buffer\n * @param {String} hex The hex string to convert\n * @returns {Buffer} The hex as buffer\n * @api private\n */\n\nfunction hex2buffer(hex) {\n  // use buffer built-in function to convert from hex-string to buffer\n  const buff = hex != null && Buffer.from(hex, 'hex');\n  return buff;\n}\n\n/**\n * Helper function to convert the buffer input to a string\n * @param {Buffer} buf The buffer to convert to a hex-string\n * @returns {String} The buffer as a hex-string\n * @api private\n */\n\nfunction binary2hex(buf) {\n  // use buffer built-in function to convert from buffer to hex-string\n  const hex = buf != null && buf.toString('hex');\n  return hex;\n}\n\n/**\n * Convert a String to Binary\n * @param {String} uuidStr The value to process\n * @returns {MongooseBuffer} The binary to store\n * @api private\n */\n\nfunction stringToBinary(uuidStr) {\n  // Protect against undefined & throwing err\n  if (typeof uuidStr !== 'string') uuidStr = '';\n  const hex = uuidStr.replace(/[{}-]/g, ''); // remove extra characters\n  const bytes = hex2buffer(hex);\n  const buff = new MongooseBuffer(bytes);\n  buff._subtype = 4;\n\n  return buff;\n}\n\n/**\n * Convert binary to a uuid string\n * @param {Buffer|Binary|String} uuidBin The value to process\n * @returns {String} The completed uuid-string\n * @api private\n */\nfunction binaryToString(uuidBin) {\n  // i(hasezoey) dont quite know why, but \"uuidBin\" may sometimes also be the already processed string\n  let hex;\n  if (typeof uuidBin !== 'string' && uuidBin != null) {\n    hex = binary2hex(uuidBin);\n    const uuidStr = hex.substring(0, 8) + '-' + hex.substring(8, 8 + 4) + '-' + hex.substring(12, 12 + 4) + '-' + hex.substring(16, 16 + 4) + '-' + hex.substring(20, 20 + 12);\n    return uuidStr;\n  }\n  return uuidBin;\n}\n\n/**\n * UUIDv1 SchemaType constructor.\n *\n * @param {String} key\n * @param {Object} options\n * @inherits SchemaType\n * @api public\n */\n\nfunction SchemaUUID(key, options) {\n  SchemaType.call(this, key, options, 'UUID');\n  this.getters.push(function(value) {\n    // For populated\n    if (value != null && value.$__ != null) {\n      return value;\n    }\n    return binaryToString(value);\n  });\n}\n\n/**\n * This schema type's name, to defend against minifiers that mangle\n * function names.\n *\n * @api public\n */\nSchemaUUID.schemaName = 'UUID';\n\nSchemaUUID.defaultOptions = {};\n\n/*!\n * Inherits from SchemaType.\n */\nSchemaUUID.prototype = Object.create(SchemaType.prototype);\nSchemaUUID.prototype.constructor = SchemaUUID;\n\n/*!\n * ignore\n */\n\nSchemaUUID._cast = function(value) {\n  if (value == null) {\n    return value;\n  }\n\n  function newBuffer(initbuff) {\n    const buff = new MongooseBuffer(initbuff);\n    buff._subtype = 4;\n    return buff;\n  }\n\n  if (typeof value === 'string') {\n    if (UUID_FORMAT.test(value)) {\n      return stringToBinary(value);\n    } else {\n      throw new CastError(SchemaUUID.schemaName, value, this.path);\n    }\n  }\n\n  if (Buffer.isBuffer(value)) {\n    return newBuffer(value);\n  }\n\n  if (value instanceof Binary) {\n    return newBuffer(value.value(true));\n  }\n\n  // Re: gh-647 and gh-3030, we're ok with casting using `toString()`\n  // **unless** its the default Object.toString, because \"[object Object]\"\n  // doesn't really qualify as useful data\n  if (value.toString && value.toString !== Object.prototype.toString) {\n    if (UUID_FORMAT.test(value.toString())) {\n      return stringToBinary(value.toString());\n    }\n  }\n\n  throw new CastError(SchemaUUID.schemaName, value, this.path);\n};\n\n/**\n * Attaches a getter for all UUID instances.\n *\n * #### Example:\n *\n *     // Note that `v` is a string by default\n *     mongoose.Schema.UUID.get(v => v.toUpperCase());\n *\n *     const Model = mongoose.model('Test', new Schema({ test: 'UUID' }));\n *     new Model({ test: uuid.v4() }).test; // UUID with all uppercase\n *\n * @param {Function} getter\n * @return {this}\n * @function get\n * @static\n * @api public\n */\n\nSchemaUUID.get = SchemaType.get;\n\n/**\n * Sets a default option for all UUID instances.\n *\n * #### Example:\n *\n *     // Make all UUIDs have `required` of true by default.\n *     mongoose.Schema.UUID.set('required', true);\n *\n *     const User = mongoose.model('User', new Schema({ test: mongoose.UUID }));\n *     new User({ }).validateSync().errors.test.message; // Path `test` is required.\n *\n * @param {String} option The option you'd like to set the value for\n * @param {Any} value value for option\n * @return {undefined}\n * @function set\n * @static\n * @api public\n */\n\nSchemaUUID.set = SchemaType.set;\n\nSchemaUUID.setters = [];\n\n/**\n * Get/set the function used to cast arbitrary values to UUIDs.\n *\n * #### Example:\n *\n *     // Make Mongoose refuse to cast UUIDs with 0 length\n *     const original = mongoose.Schema.Types.UUID.cast();\n *     mongoose.UUID.cast(v => {\n *       assert.ok(typeof v === \"string\" && v.length > 0);\n *       return original(v);\n *     });\n *\n *     // Or disable casting entirely\n *     mongoose.UUID.cast(false);\n *\n * @param {Function} [caster]\n * @return {Function}\n * @function get\n * @static\n * @api public\n */\n\nSchemaUUID.cast = function cast(caster) {\n  if (arguments.length === 0) {\n    return this._cast;\n  }\n  if (caster === false) {\n    caster = this._defaultCaster;\n  }\n  this._cast = caster;\n\n  return this._cast;\n};\n\n/*!\n * ignore\n */\n\nSchemaUUID._checkRequired = v => v != null;\n\n/**\n * Override the function the required validator uses to check whether a string\n * passes the `required` check.\n *\n * @param {Function} fn\n * @return {Function}\n * @function checkRequired\n * @static\n * @api public\n */\n\nSchemaUUID.checkRequired = SchemaType.checkRequired;\n\n/**\n * Check if the given value satisfies a required validator.\n *\n * @param {Any} value\n * @return {Boolean}\n * @api public\n */\n\nSchemaUUID.prototype.checkRequired = function checkRequired(value) {\n  if (Buffer.isBuffer(value)) {\n    value = binaryToString(value);\n  }\n  return value != null && UUID_FORMAT.test(value);\n};\n\n/**\n * Casts to UUID\n *\n * @param {Object} value\n * @param {Object} doc\n * @param {Boolean} init whether this is an initialization cast\n * @api private\n */\n\nSchemaUUID.prototype.cast = function(value, doc, init) {\n  if (utils.isNonBuiltinObject(value) &&\n      SchemaType._isRef(this, value, doc, init)) {\n    return this._castRef(value, doc, init);\n  }\n\n  let castFn;\n  if (typeof this._castFunction === 'function') {\n    castFn = this._castFunction;\n  } else if (typeof this.constructor.cast === 'function') {\n    castFn = this.constructor.cast();\n  } else {\n    castFn = SchemaUUID.cast();\n  }\n\n  try {\n    return castFn(value);\n  } catch (error) {\n    throw new CastError(SchemaUUID.schemaName, value, this.path, error, this);\n  }\n};\n\n/*!\n * ignore\n */\n\nfunction handleSingle(val) {\n  return this.cast(val);\n}\n\n/*!\n * ignore\n */\n\nfunction handleArray(val) {\n  return val.map((m) => {\n    return this.cast(m);\n  });\n}\n\nSchemaUUID.prototype.$conditionalHandlers = {\n  ...SchemaType.prototype.$conditionalHandlers,\n  $bitsAllClear: handleBitwiseOperator,\n  $bitsAnyClear: handleBitwiseOperator,\n  $bitsAllSet: handleBitwiseOperator,\n  $bitsAnySet: handleBitwiseOperator,\n  $all: handleArray,\n  $gt: handleSingle,\n  $gte: handleSingle,\n  $in: handleArray,\n  $lt: handleSingle,\n  $lte: handleSingle,\n  $ne: handleSingle,\n  $nin: handleArray\n};\n\n/**\n * Casts contents for queries.\n *\n * @param {String} $conditional\n * @param {any} val\n * @api private\n */\n\nSchemaUUID.prototype.castForQuery = function($conditional, val, context) {\n  let handler;\n  if ($conditional != null) {\n    handler = this.$conditionalHandlers[$conditional];\n    if (!handler)\n      throw new Error('Can\\'t use ' + $conditional + ' with UUID.');\n    return handler.call(this, val, context);\n  }\n\n  try {\n    return this.applySetters(val, context);\n  } catch (err) {\n    if (err instanceof CastError && err.path === this.path && this.$fullPath != null) {\n      err.path = this.$fullPath;\n    }\n    throw err;\n  }\n};\n\n/*!\n * Module exports.\n */\n\nmodule.exports = SchemaUUID;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schema/uuid.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/schemaType.js":
/*!*************************************************!*\
  !*** ./node_modules/mongoose/lib/schemaType.js ***!
  \*************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst MongooseError = __webpack_require__(/*! ./error/index */ \"./node_modules/mongoose/lib/error/index.js\");\nconst SchemaTypeOptions = __webpack_require__(/*! ./options/schemaTypeOptions */ \"./node_modules/mongoose/lib/options/schemaTypeOptions.js\");\nconst $exists = __webpack_require__(/*! ./schema/operators/exists */ \"./node_modules/mongoose/lib/schema/operators/exists.js\");\nconst $type = __webpack_require__(/*! ./schema/operators/type */ \"./node_modules/mongoose/lib/schema/operators/type.js\");\nconst clone = __webpack_require__(/*! ./helpers/clone */ \"./node_modules/mongoose/lib/helpers/clone.js\");\nconst handleImmutable = __webpack_require__(/*! ./helpers/schematype/handleImmutable */ \"./node_modules/mongoose/lib/helpers/schematype/handleImmutable.js\");\nconst isAsyncFunction = __webpack_require__(/*! ./helpers/isAsyncFunction */ \"./node_modules/mongoose/lib/helpers/isAsyncFunction.js\");\nconst isSimpleValidator = __webpack_require__(/*! ./helpers/isSimpleValidator */ \"./node_modules/mongoose/lib/helpers/isSimpleValidator.js\");\nconst immediate = __webpack_require__(/*! ./helpers/immediate */ \"./node_modules/mongoose/lib/helpers/immediate.js\");\nconst schemaTypeSymbol = (__webpack_require__(/*! ./helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").schemaTypeSymbol);\nconst utils = __webpack_require__(/*! ./utils */ \"./node_modules/mongoose/lib/utils.js\");\nconst validatorErrorSymbol = (__webpack_require__(/*! ./helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").validatorErrorSymbol);\nconst documentIsModified = (__webpack_require__(/*! ./helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").documentIsModified);\n\nconst populateModelSymbol = (__webpack_require__(/*! ./helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").populateModelSymbol);\n\nconst CastError = MongooseError.CastError;\nconst ValidatorError = MongooseError.ValidatorError;\n\nconst setOptionsForDefaults = { _skipMarkModified: true };\n\n/**\n * SchemaType constructor. Do **not** instantiate `SchemaType` directly.\n * Mongoose converts your schema paths into SchemaTypes automatically.\n *\n * #### Example:\n *\n *     const schema = new Schema({ name: String });\n *     schema.path('name') instanceof SchemaType; // true\n *\n * @param {String} path\n * @param {SchemaTypeOptions} [options] See [SchemaTypeOptions docs](https://mongoosejs.com/docs/api/schematypeoptions.html)\n * @param {String} [instance]\n * @api public\n */\n\nfunction SchemaType(path, options, instance) {\n  this[schemaTypeSymbol] = true;\n  this.path = path;\n  this.instance = instance;\n  this.validators = [];\n  this.getters = this.constructor.hasOwnProperty('getters') ?\n    this.constructor.getters.slice() :\n    [];\n  this.setters = this.constructor.hasOwnProperty('setters') ?\n    this.constructor.setters.slice() :\n    [];\n\n  this.splitPath();\n\n  options = options || {};\n  const defaultOptions = this.constructor.defaultOptions || {};\n  const defaultOptionsKeys = Object.keys(defaultOptions);\n\n  for (const option of defaultOptionsKeys) {\n    if (option === 'validate') {\n      this.validate(defaultOptions.validate);\n    } else if (defaultOptions.hasOwnProperty(option) && !Object.prototype.hasOwnProperty.call(options, option)) {\n      options[option] = defaultOptions[option];\n    }\n  }\n\n  if (options.select == null) {\n    delete options.select;\n  }\n\n  const Options = this.OptionsConstructor || SchemaTypeOptions;\n  this.options = new Options(options);\n  this._index = null;\n\n\n  if (utils.hasUserDefinedProperty(this.options, 'immutable')) {\n    this.$immutable = this.options.immutable;\n\n    handleImmutable(this);\n  }\n\n  const keys = Object.keys(this.options);\n  for (const prop of keys) {\n    if (prop === 'cast') {\n      if (Array.isArray(this.options[prop])) {\n        this.castFunction.apply(this, this.options[prop]);\n      } else {\n        this.castFunction(this.options[prop]);\n      }\n      continue;\n    }\n    if (utils.hasUserDefinedProperty(this.options, prop) && typeof this[prop] === 'function') {\n      // { unique: true, index: true }\n      if (prop === 'index' && this._index) {\n        if (options.index === false) {\n          const index = this._index;\n          if (typeof index === 'object' && index != null) {\n            if (index.unique) {\n              throw new Error('Path \"' + this.path + '\" may not have `index` ' +\n                'set to false and `unique` set to true');\n            }\n            if (index.sparse) {\n              throw new Error('Path \"' + this.path + '\" may not have `index` ' +\n                'set to false and `sparse` set to true');\n            }\n          }\n\n          this._index = false;\n        }\n        continue;\n      }\n\n      const val = options[prop];\n      // Special case so we don't screw up array defaults, see gh-5780\n      if (prop === 'default') {\n        this.default(val);\n        continue;\n      }\n\n      const opts = Array.isArray(val) ? val : [val];\n\n      this[prop].apply(this, opts);\n    }\n  }\n\n  Object.defineProperty(this, '$$context', {\n    enumerable: false,\n    configurable: false,\n    writable: true,\n    value: null\n  });\n}\n\n/**\n * The class that Mongoose uses internally to instantiate this SchemaType's `options` property.\n * @memberOf SchemaType\n * @instance\n * @api private\n */\n\nSchemaType.prototype.OptionsConstructor = SchemaTypeOptions;\n\n/**\n * The path to this SchemaType in a Schema.\n *\n * #### Example:\n *\n *     const schema = new Schema({ name: String });\n *     schema.path('name').path; // 'name'\n *\n * @property path\n * @api public\n * @memberOf SchemaType\n */\n\nSchemaType.prototype.path;\n\n/**\n * The validators that Mongoose should run to validate properties at this SchemaType's path.\n *\n * #### Example:\n *\n *     const schema = new Schema({ name: { type: String, required: true } });\n *     schema.path('name').validators.length; // 1, the `required` validator\n *\n * @property validators\n * @api public\n * @memberOf SchemaType\n */\n\nSchemaType.prototype.validators;\n\n/**\n * True if this SchemaType has a required validator. False otherwise.\n *\n * #### Example:\n *\n *     const schema = new Schema({ name: { type: String, required: true } });\n *     schema.path('name').isRequired; // true\n *\n *     schema.path('name').required(false);\n *     schema.path('name').isRequired; // false\n *\n * @property isRequired\n * @api public\n * @memberOf SchemaType\n */\n\nSchemaType.prototype.isRequired;\n\n/**\n * Split the current dottet path into segments\n *\n * @return {String[]|undefined}\n * @api private\n */\n\nSchemaType.prototype.splitPath = function() {\n  if (this._presplitPath != null) {\n    return this._presplitPath;\n  }\n  if (this.path == null) {\n    return undefined;\n  }\n\n  this._presplitPath = this.path.indexOf('.') === -1 ? [this.path] : this.path.split('.');\n  return this._presplitPath;\n};\n\n/**\n * Get/set the function used to cast arbitrary values to this type.\n *\n * #### Example:\n *\n *     // Disallow `null` for numbers, and don't try to cast any values to\n *     // numbers, so even strings like '123' will cause a CastError.\n *     mongoose.Number.cast(function(v) {\n *       assert.ok(v === undefined || typeof v === 'number');\n *       return v;\n *     });\n *\n * @param {Function|false} caster Function that casts arbitrary values to this type, or throws an error if casting failed\n * @return {Function}\n * @static\n * @memberOf SchemaType\n * @function cast\n * @api public\n */\n\nSchemaType.cast = function cast(caster) {\n  if (arguments.length === 0) {\n    return this._cast;\n  }\n  if (caster === false) {\n    caster = v => v;\n  }\n  this._cast = caster;\n\n  return this._cast;\n};\n\n/**\n * Get/set the function used to cast arbitrary values to this particular schematype instance.\n * Overrides `SchemaType.cast()`.\n *\n * #### Example:\n *\n *     // Disallow `null` for numbers, and don't try to cast any values to\n *     // numbers, so even strings like '123' will cause a CastError.\n *     const number = new mongoose.Number('mypath', {});\n *     number.cast(function(v) {\n *       assert.ok(v === undefined || typeof v === 'number');\n *       return v;\n *     });\n *\n * @param {Function|false} caster Function that casts arbitrary values to this type, or throws an error if casting failed\n * @return {Function}\n * @memberOf SchemaType\n * @api public\n */\n\nSchemaType.prototype.castFunction = function castFunction(caster, message) {\n  if (arguments.length === 0) {\n    return this._castFunction;\n  }\n\n  if (caster === false) {\n    caster = this.constructor._defaultCaster || (v => v);\n  }\n  if (typeof caster === 'string') {\n    this._castErrorMessage = caster;\n    return this._castFunction;\n  }\n  if (caster != null) {\n    this._castFunction = caster;\n  }\n  if (message != null) {\n    this._castErrorMessage = message;\n  }\n\n  return this._castFunction;\n};\n\n/**\n * The function that Mongoose calls to cast arbitrary values to this SchemaType.\n *\n * @param {Object} value value to cast\n * @param {Document} doc document that triggers the casting\n * @param {Boolean} init\n * @api public\n */\n\nSchemaType.prototype.cast = function cast() {\n  throw new Error('Base SchemaType class does not implement a `cast()` function');\n};\n\n/**\n * Sets a default option for this schema type.\n *\n * #### Example:\n *\n *     // Make all strings be trimmed by default\n *     mongoose.SchemaTypes.String.set('trim', true);\n *\n * @param {String} option The name of the option you'd like to set (e.g. trim, lowercase, etc...)\n * @param {Any} value The value of the option you'd like to set.\n * @return {void}\n * @static\n * @memberOf SchemaType\n * @function set\n * @api public\n */\n\nSchemaType.set = function set(option, value) {\n  if (!this.hasOwnProperty('defaultOptions')) {\n    this.defaultOptions = Object.assign({}, this.defaultOptions);\n  }\n  this.defaultOptions[option] = value;\n};\n\n/**\n * Attaches a getter for all instances of this schema type.\n *\n * #### Example:\n *\n *     // Make all numbers round down\n *     mongoose.Number.get(function(v) { return Math.floor(v); });\n *\n * @param {Function} getter\n * @return {this}\n * @static\n * @memberOf SchemaType\n * @function get\n * @api public\n */\n\nSchemaType.get = function(getter) {\n  this.getters = this.hasOwnProperty('getters') ? this.getters : [];\n  this.getters.push(getter);\n};\n\n/**\n * Sets a default value for this SchemaType.\n *\n * #### Example:\n *\n *     const schema = new Schema({ n: { type: Number, default: 10 })\n *     const M = db.model('M', schema)\n *     const m = new M;\n *     console.log(m.n) // 10\n *\n * Defaults can be either `functions` which return the value to use as the default or the literal value itself. Either way, the value will be cast based on its schema type before being set during document creation.\n *\n * #### Example:\n *\n *     // values are cast:\n *     const schema = new Schema({ aNumber: { type: Number, default: 4.815162342 }})\n *     const M = db.model('M', schema)\n *     const m = new M;\n *     console.log(m.aNumber) // 4.815162342\n *\n *     // default unique objects for Mixed types:\n *     const schema = new Schema({ mixed: Schema.Types.Mixed });\n *     schema.path('mixed').default(function () {\n *       return {};\n *     });\n *\n *     // if we don't use a function to return object literals for Mixed defaults,\n *     // each document will receive a reference to the same object literal creating\n *     // a \"shared\" object instance:\n *     const schema = new Schema({ mixed: Schema.Types.Mixed });\n *     schema.path('mixed').default({});\n *     const M = db.model('M', schema);\n *     const m1 = new M;\n *     m1.mixed.added = 1;\n *     console.log(m1.mixed); // { added: 1 }\n *     const m2 = new M;\n *     console.log(m2.mixed); // { added: 1 }\n *\n * @param {Function|any} val The default value to set\n * @return {Any|undefined} Returns the set default value.\n * @api public\n */\n\nSchemaType.prototype.default = function(val) {\n  if (arguments.length === 1) {\n    if (val === void 0) {\n      this.defaultValue = void 0;\n      return void 0;\n    }\n\n    if (val != null && val.instanceOfSchema) {\n      throw new MongooseError('Cannot set default value of path `' + this.path +\n        '` to a mongoose Schema instance.');\n    }\n\n    this.defaultValue = val;\n    return this.defaultValue;\n  } else if (arguments.length > 1) {\n    this.defaultValue = [...arguments];\n  }\n  return this.defaultValue;\n};\n\n/**\n * Declares the index options for this schematype.\n *\n * #### Example:\n *\n *     const s = new Schema({ name: { type: String, index: true })\n *     const s = new Schema({ name: { type: String, index: -1 })\n *     const s = new Schema({ loc: { type: [Number], index: 'hashed' })\n *     const s = new Schema({ loc: { type: [Number], index: '2d', sparse: true })\n *     const s = new Schema({ loc: { type: [Number], index: { type: '2dsphere', sparse: true }})\n *     const s = new Schema({ date: { type: Date, index: { unique: true, expires: '1d' }})\n *     s.path('my.path').index(true);\n *     s.path('my.date').index({ expires: 60 });\n *     s.path('my.path').index({ unique: true, sparse: true });\n *\n * #### Note:\n *\n * _Indexes are created [in the background](https://www.mongodb.com/docs/manual/core/index-creation/#index-creation-background)\n * by default. If `background` is set to `false`, MongoDB will not execute any\n * read/write operations you send until the index build.\n * Specify `background: false` to override Mongoose's default._\n *\n * @param {Object|Boolean|String|Number} options\n * @return {SchemaType} this\n * @api public\n */\n\nSchemaType.prototype.index = function(options) {\n  this._index = options;\n  utils.expires(this._index);\n  return this;\n};\n\n/**\n * Declares an unique index.\n *\n * #### Example:\n *\n *     const s = new Schema({ name: { type: String, unique: true } });\n *     s.path('name').index({ unique: true });\n *\n * _NOTE: violating the constraint returns an `E11000` error from MongoDB when saving, not a Mongoose validation error._\n *\n * @param {Boolean} bool\n * @return {SchemaType} this\n * @api public\n */\n\nSchemaType.prototype.unique = function(bool) {\n  if (this._index === false) {\n    if (!bool) {\n      return;\n    }\n    throw new Error('Path \"' + this.path + '\" may not have `index` set to ' +\n      'false and `unique` set to true');\n  }\n\n  if (!this.options.hasOwnProperty('index') && bool === false) {\n    return this;\n  }\n\n  if (this._index == null || this._index === true) {\n    this._index = {};\n  } else if (typeof this._index === 'string') {\n    this._index = { type: this._index };\n  }\n\n  this._index.unique = bool;\n  return this;\n};\n\n/**\n * Declares a full text index.\n *\n * ### Example:\n *\n *      const s = new Schema({ name : { type: String, text : true } })\n *      s.path('name').index({ text : true });\n *\n * @param {Boolean} bool\n * @return {SchemaType} this\n * @api public\n */\n\nSchemaType.prototype.text = function(bool) {\n  if (this._index === false) {\n    if (!bool) {\n      return this;\n    }\n    throw new Error('Path \"' + this.path + '\" may not have `index` set to ' +\n      'false and `text` set to true');\n  }\n\n  if (!this.options.hasOwnProperty('index') && bool === false) {\n    return this;\n  }\n\n  if (this._index === null || this._index === undefined ||\n    typeof this._index === 'boolean') {\n    this._index = {};\n  } else if (typeof this._index === 'string') {\n    this._index = { type: this._index };\n  }\n\n  this._index.text = bool;\n  return this;\n};\n\n/**\n * Declares a sparse index.\n *\n * #### Example:\n *\n *     const s = new Schema({ name: { type: String, sparse: true } });\n *     s.path('name').index({ sparse: true });\n *\n * @param {Boolean} bool\n * @return {SchemaType} this\n * @api public\n */\n\nSchemaType.prototype.sparse = function(bool) {\n  if (this._index === false) {\n    if (!bool) {\n      return this;\n    }\n    throw new Error('Path \"' + this.path + '\" may not have `index` set to ' +\n      'false and `sparse` set to true');\n  }\n\n  if (!this.options.hasOwnProperty('index') && bool === false) {\n    return this;\n  }\n\n  if (this._index == null || typeof this._index === 'boolean') {\n    this._index = {};\n  } else if (typeof this._index === 'string') {\n    this._index = { type: this._index };\n  }\n\n  this._index.sparse = bool;\n  return this;\n};\n\n/**\n * Defines this path as immutable. Mongoose prevents you from changing\n * immutable paths unless the parent document has [`isNew: true`](https://mongoosejs.com/docs/api/document.html#Document.prototype.isNew()).\n *\n * #### Example:\n *\n *     const schema = new Schema({\n *       name: { type: String, immutable: true },\n *       age: Number\n *     });\n *     const Model = mongoose.model('Test', schema);\n *\n *     await Model.create({ name: 'test' });\n *     const doc = await Model.findOne();\n *\n *     doc.isNew; // false\n *     doc.name = 'new name';\n *     doc.name; // 'test', because `name` is immutable\n *\n * Mongoose also prevents changing immutable properties using `updateOne()`\n * and `updateMany()` based on [strict mode](https://mongoosejs.com/docs/guide.html#strict).\n *\n * #### Example:\n *\n *     // Mongoose will strip out the `name` update, because `name` is immutable\n *     Model.updateOne({}, { $set: { name: 'test2' }, $inc: { age: 1 } });\n *\n *     // If `strict` is set to 'throw', Mongoose will throw an error if you\n *     // update `name`\n *     const err = await Model.updateOne({}, { name: 'test2' }, { strict: 'throw' }).\n *       then(() => null, err => err);\n *     err.name; // StrictModeError\n *\n *     // If `strict` is `false`, Mongoose allows updating `name` even though\n *     // the property is immutable.\n *     Model.updateOne({}, { name: 'test2' }, { strict: false });\n *\n * @param {Boolean} bool\n * @return {SchemaType} this\n * @see isNew https://mongoosejs.com/docs/api/document.html#Document.prototype.isNew()\n * @api public\n */\n\nSchemaType.prototype.immutable = function(bool) {\n  this.$immutable = bool;\n  handleImmutable(this);\n\n  return this;\n};\n\n/**\n * Defines a custom function for transforming this path when converting a document to JSON.\n *\n * Mongoose calls this function with one parameter: the current `value` of the path. Mongoose\n * then uses the return value in the JSON output.\n *\n * #### Example:\n *\n *     const schema = new Schema({\n *       date: { type: Date, transform: v => v.getFullYear() }\n *     });\n *     const Model = mongoose.model('Test', schema);\n *\n *     await Model.create({ date: new Date('2016-06-01') });\n *     const doc = await Model.findOne();\n *\n *     doc.date instanceof Date; // true\n *\n *     doc.toJSON().date; // 2016 as a number\n *     JSON.stringify(doc); // '{\"_id\":...,\"date\":2016}'\n *\n * @param {Function} fn\n * @return {SchemaType} this\n * @api public\n */\n\nSchemaType.prototype.transform = function(fn) {\n  this.options.transform = fn;\n\n  return this;\n};\n\n/**\n * Adds a setter to this schematype.\n *\n * #### Example:\n *\n *     function capitalize (val) {\n *       if (typeof val !== 'string') val = '';\n *       return val.charAt(0).toUpperCase() + val.substring(1);\n *     }\n *\n *     // defining within the schema\n *     const s = new Schema({ name: { type: String, set: capitalize }});\n *\n *     // or with the SchemaType\n *     const s = new Schema({ name: String })\n *     s.path('name').set(capitalize);\n *\n * Setters allow you to transform the data before it gets to the raw mongodb\n * document or query.\n *\n * Suppose you are implementing user registration for a website. Users provide\n * an email and password, which gets saved to mongodb. The email is a string\n * that you will want to normalize to lower case, in order to avoid one email\n * having more than one account -- e.g., otherwise, avenue@q.com can be registered for 2 accounts via avenue@q.com and AvEnUe@Q.CoM.\n *\n * You can set up email lower case normalization easily via a Mongoose setter.\n *\n *     function toLower(v) {\n *       return v.toLowerCase();\n *     }\n *\n *     const UserSchema = new Schema({\n *       email: { type: String, set: toLower }\n *     });\n *\n *     const User = db.model('User', UserSchema);\n *\n *     const user = new User({email: 'AVENUE@Q.COM'});\n *     console.log(user.email); // 'avenue@q.com'\n *\n *     // or\n *     const user = new User();\n *     user.email = 'Avenue@Q.com';\n *     console.log(user.email); // 'avenue@q.com'\n *     User.updateOne({ _id: _id }, { $set: { email: 'AVENUE@Q.COM' } }); // update to 'avenue@q.com'\n *\n * As you can see above, setters allow you to transform the data before it\n * stored in MongoDB, or before executing a query.\n *\n * _NOTE: we could have also just used the built-in `lowercase: true` SchemaType option instead of defining our own function._\n *\n *     new Schema({ email: { type: String, lowercase: true }})\n *\n * Setters are also passed a second argument, the schematype on which the setter was defined. This allows for tailored behavior based on options passed in the schema.\n *\n *     function inspector (val, priorValue, schematype) {\n *       if (schematype.options.required) {\n *         return schematype.path + ' is required';\n *       } else {\n *         return val;\n *       }\n *     }\n *\n *     const VirusSchema = new Schema({\n *       name: { type: String, required: true, set: inspector },\n *       taxonomy: { type: String, set: inspector }\n *     })\n *\n *     const Virus = db.model('Virus', VirusSchema);\n *     const v = new Virus({ name: 'Parvoviridae', taxonomy: 'Parvovirinae' });\n *\n *     console.log(v.name);     // name is required\n *     console.log(v.taxonomy); // Parvovirinae\n *\n * You can also use setters to modify other properties on the document. If\n * you're setting a property `name` on a document, the setter will run with\n * `this` as the document. Be careful, in mongoose 5 setters will also run\n * when querying by `name` with `this` as the query.\n *\n *     const nameSchema = new Schema({ name: String, keywords: [String] });\n *     nameSchema.path('name').set(function(v) {\n *       // Need to check if `this` is a document, because in mongoose 5\n *       // setters will also run on queries, in which case `this` will be a\n *       // mongoose query object.\n *       if (this instanceof Document && v != null) {\n *         this.keywords = v.split(' ');\n *       }\n *       return v;\n *     });\n *\n * @param {Function} fn\n * @return {SchemaType} this\n * @api public\n */\n\nSchemaType.prototype.set = function(fn) {\n  if (typeof fn !== 'function') {\n    throw new TypeError('A setter must be a function.');\n  }\n  this.setters.push(fn);\n  return this;\n};\n\n/**\n * Adds a getter to this schematype.\n *\n * #### Example:\n *\n *     function dob (val) {\n *       if (!val) return val;\n *       return (val.getMonth() + 1) + \"/\" + val.getDate() + \"/\" + val.getFullYear();\n *     }\n *\n *     // defining within the schema\n *     const s = new Schema({ born: { type: Date, get: dob })\n *\n *     // or by retreiving its SchemaType\n *     const s = new Schema({ born: Date })\n *     s.path('born').get(dob)\n *\n * Getters allow you to transform the representation of the data as it travels from the raw mongodb document to the value that you see.\n *\n * Suppose you are storing credit card numbers and you want to hide everything except the last 4 digits to the mongoose user. You can do so by defining a getter in the following way:\n *\n *     function obfuscate (cc) {\n *       return '****-****-****-' + cc.slice(cc.length-4, cc.length);\n *     }\n *\n *     const AccountSchema = new Schema({\n *       creditCardNumber: { type: String, get: obfuscate }\n *     });\n *\n *     const Account = db.model('Account', AccountSchema);\n *\n *     Account.findById(id, function (err, found) {\n *       console.log(found.creditCardNumber); // '****-****-****-1234'\n *     });\n *\n * Getters are also passed a second argument, the schematype on which the getter was defined. This allows for tailored behavior based on options passed in the schema.\n *\n *     function inspector (val, priorValue, schematype) {\n *       if (schematype.options.required) {\n *         return schematype.path + ' is required';\n *       } else {\n *         return schematype.path + ' is not';\n *       }\n *     }\n *\n *     const VirusSchema = new Schema({\n *       name: { type: String, required: true, get: inspector },\n *       taxonomy: { type: String, get: inspector }\n *     })\n *\n *     const Virus = db.model('Virus', VirusSchema);\n *\n *     Virus.findById(id, function (err, virus) {\n *       console.log(virus.name);     // name is required\n *       console.log(virus.taxonomy); // taxonomy is not\n *     })\n *\n * @param {Function} fn\n * @return {SchemaType} this\n * @api public\n */\n\nSchemaType.prototype.get = function(fn) {\n  if (typeof fn !== 'function') {\n    throw new TypeError('A getter must be a function.');\n  }\n  this.getters.push(fn);\n  return this;\n};\n\n/**\n * Adds multiple validators for this document path.\n * Calls `validate()` for every element in validators.\n *\n * @param {Array<RegExp|Function|Object>} validators\n * @returns this\n */\n\nSchemaType.prototype.validateAll = function(validators) {\n  for (let i = 0; i < validators.length; i++) {\n    this.validate(validators[i]);\n  }\n  return this;\n};\n\n/**\n * Adds validator(s) for this document path.\n *\n * Validators always receive the value to validate as their first argument and\n * must return `Boolean`. Returning `false` or throwing an error means\n * validation failed.\n *\n * The error message argument is optional. If not passed, the [default generic error message template](https://mongoosejs.com/docs/api/error.html#Error.messages) will be used.\n *\n * #### Example:\n *\n *     // make sure every value is equal to \"something\"\n *     function validator (val) {\n *       return val === 'something';\n *     }\n *     new Schema({ name: { type: String, validate: validator }});\n *\n *     // with a custom error message\n *\n *     const custom = [validator, 'Uh oh, {PATH} does not equal \"something\".']\n *     new Schema({ name: { type: String, validate: custom }});\n *\n *     // adding many validators at a time\n *\n *     const many = [\n *         { validator: validator, message: 'uh oh' }\n *       , { validator: anotherValidator, message: 'failed' }\n *     ]\n *     new Schema({ name: { type: String, validate: many }});\n *\n *     // or utilizing SchemaType methods directly:\n *\n *     const schema = new Schema({ name: 'string' });\n *     schema.path('name').validate(validator, 'validation of `{PATH}` failed with value `{VALUE}`');\n *\n * #### Error message templates:\n *\n * Below is a list of supported template keywords:\n *\n * - PATH: The schema path where the error is being triggered.\n * - VALUE: The value assigned to the PATH that is triggering the error.\n * - KIND: The validation property that triggered the error i.e. required.\n * - REASON: The error object that caused this error if there was one.\n *\n * If Mongoose's built-in error message templating isn't enough, Mongoose\n * supports setting the `message` property to a function.\n *\n *     schema.path('name').validate({\n *       validator: function(v) { return v.length > 5; },\n *       // `errors['name']` will be \"name must have length 5, got 'foo'\"\n *       message: function(props) {\n *         return `${props.path} must have length 5, got '${props.value}'`;\n *       }\n *     });\n *\n * To bypass Mongoose's error messages and just copy the error message that\n * the validator throws, do this:\n *\n *     schema.path('name').validate({\n *       validator: function() { throw new Error('Oops!'); },\n *       // `errors['name'].message` will be \"Oops!\"\n *       message: function(props) { return props.reason.message; }\n *     });\n *\n * #### Asynchronous validation:\n *\n * Mongoose supports validators that return a promise. A validator that returns\n * a promise is called an _async validator_. Async validators run in\n * parallel, and `validate()` will wait until all async validators have settled.\n *\n *     schema.path('name').validate({\n *       validator: function (value) {\n *         return new Promise(function (resolve, reject) {\n *           resolve(false); // validation failed\n *         });\n *       }\n *     });\n *\n * You might use asynchronous validators to retreive other documents from the database to validate against or to meet other I/O bound validation needs.\n *\n * Validation occurs `pre('save')` or whenever you manually execute [document#validate](https://mongoosejs.com/docs/api/document.html#Document.prototype.validate()).\n *\n * If validation fails during `pre('save')` and no callback was passed to receive the error, an `error` event will be emitted on your Models associated db [connection](https://mongoosejs.com/docs/api/connection.html#Connection()), passing the validation error object along.\n *\n *     const conn = mongoose.createConnection(..);\n *     conn.on('error', handleError);\n *\n *     const Product = conn.model('Product', yourSchema);\n *     const dvd = new Product(..);\n *     dvd.save(); // emits error on the `conn` above\n *\n * If you want to handle these errors at the Model level, add an `error`\n * listener to your Model as shown below.\n *\n *     // registering an error listener on the Model lets us handle errors more locally\n *     Product.on('error', handleError);\n *\n * @param {RegExp|Function|Object} obj validator function, or hash describing options\n * @param {Function} [obj.validator] validator function. If the validator function returns `undefined` or a truthy value, validation succeeds. If it returns [falsy](https://masteringjs.io/tutorials/fundamentals/falsy) (except `undefined`) or throws an error, validation fails.\n * @param {String|Function} [obj.message] optional error message. If function, should return the error message as a string\n * @param {Boolean} [obj.propsParameter=false] If true, Mongoose will pass the validator properties object (with the `validator` function, `message`, etc.) as the 2nd arg to the validator function. This is disabled by default because many validators [rely on positional args](https://github.com/chriso/validator.js#validators), so turning this on may cause unpredictable behavior in external validators.\n * @param {String|Function} [errorMsg] optional error message. If function, should return the error message as a string\n * @param {String} [type] optional validator type\n * @return {SchemaType} this\n * @api public\n */\n\nSchemaType.prototype.validate = function(obj, message, type) {\n  if (typeof obj === 'function' || obj && utils.getFunctionName(obj.constructor) === 'RegExp') {\n    let properties;\n    if (typeof message === 'function') {\n      properties = { validator: obj, message: message };\n      properties.type = type || 'user defined';\n    } else if (message instanceof Object && !type) {\n      properties = isSimpleValidator(message) ? Object.assign({}, message) : clone(message);\n      if (!properties.message) {\n        properties.message = properties.msg;\n      }\n      properties.validator = obj;\n      properties.type = properties.type || 'user defined';\n    } else {\n      if (message == null) {\n        message = MongooseError.messages.general.default;\n      }\n      if (!type) {\n        type = 'user defined';\n      }\n      properties = { message: message, type: type, validator: obj };\n    }\n\n    this.validators.push(properties);\n    return this;\n  }\n\n  let i;\n  let length;\n  let arg;\n\n  for (i = 0, length = arguments.length; i < length; i++) {\n    arg = arguments[i];\n    if (!utils.isPOJO(arg)) {\n      const msg = 'Invalid validator. Received (' + typeof arg + ') '\n        + arg\n        + '. See https://mongoosejs.com/docs/api/schematype.html#SchemaType.prototype.validate()';\n\n      throw new Error(msg);\n    }\n    this.validate(arg.validator, arg);\n  }\n\n  return this;\n};\n\n/**\n * Adds a required validator to this SchemaType. The validator gets added\n * to the front of this SchemaType's validators array using `unshift()`.\n *\n * #### Example:\n *\n *     const s = new Schema({ born: { type: Date, required: true })\n *\n *     // or with custom error message\n *\n *     const s = new Schema({ born: { type: Date, required: '{PATH} is required!' })\n *\n *     // or with a function\n *\n *     const s = new Schema({\n *       userId: ObjectId,\n *       username: {\n *         type: String,\n *         required: function() { return this.userId != null; }\n *       }\n *     })\n *\n *     // or with a function and a custom message\n *     const s = new Schema({\n *       userId: ObjectId,\n *       username: {\n *         type: String,\n *         required: [\n *           function() { return this.userId != null; },\n *           'username is required if id is specified'\n *         ]\n *       }\n *     })\n *\n *     // or through the path API\n *\n *     s.path('name').required(true);\n *\n *     // with custom error messaging\n *\n *     s.path('name').required(true, 'grrr :( ');\n *\n *     // or make a path conditionally required based on a function\n *     const isOver18 = function() { return this.age >= 18; };\n *     s.path('voterRegistrationId').required(isOver18);\n *\n * The required validator uses the SchemaType's `checkRequired` function to\n * determine whether a given value satisfies the required validator. By default,\n * a value satisfies the required validator if `val != null` (that is, if\n * the value is not null nor undefined). However, most built-in mongoose schema\n * types override the default `checkRequired` function:\n *\n * @param {Boolean|Function|Object} required enable/disable the validator, or function that returns required boolean, or options object\n * @param {Boolean|Function} [options.isRequired] enable/disable the validator, or function that returns required boolean\n * @param {Function} [options.ErrorConstructor] custom error constructor. The constructor receives 1 parameter, an object containing the validator properties.\n * @param {String} [message] optional custom error message\n * @return {SchemaType} this\n * @see Customized Error Messages https://mongoosejs.com/docs/api/error.html#Error.messages\n * @see SchemaArray#checkRequired https://mongoosejs.com/docs/api/schemaarray.html#SchemaArray.prototype.checkRequired()\n * @see SchemaBoolean#checkRequired https://mongoosejs.com/docs/api/schemaboolean.html#SchemaBoolean.prototype.checkRequired()\n * @see SchemaBuffer#checkRequired https://mongoosejs.com/docs/api/schemabuffer.html#SchemaBuffer.prototype.checkRequired()\n * @see SchemaNumber#checkRequired https://mongoosejs.com/docs/api/schemanumber.html#SchemaNumber.prototype.checkRequired()\n * @see SchemaObjectId#checkRequired https://mongoosejs.com/docs/api/schemaobjectid.html#ObjectId.prototype.checkRequired()\n * @see SchemaString#checkRequired https://mongoosejs.com/docs/api/schemastring.html#SchemaString.prototype.checkRequired()\n * @api public\n */\n\nSchemaType.prototype.required = function(required, message) {\n  let customOptions = {};\n\n  if (arguments.length > 0 && required == null) {\n    this.validators = this.validators.filter(function(v) {\n      return v.validator !== this.requiredValidator;\n    }, this);\n\n    this.isRequired = false;\n    delete this.originalRequiredValue;\n    return this;\n  }\n\n  if (typeof required === 'object') {\n    customOptions = required;\n    message = customOptions.message || message;\n    required = required.isRequired;\n  }\n\n  if (required === false) {\n    this.validators = this.validators.filter(function(v) {\n      return v.validator !== this.requiredValidator;\n    }, this);\n\n    this.isRequired = false;\n    delete this.originalRequiredValue;\n    return this;\n  }\n\n  const _this = this;\n  this.isRequired = true;\n\n  this.requiredValidator = function(v) {\n    const cachedRequired = this && this.$__ && this.$__.cachedRequired;\n\n    // no validation when this path wasn't selected in the query.\n    if (cachedRequired != null && !this.$__isSelected(_this.path) && !this[documentIsModified](_this.path)) {\n      return true;\n    }\n\n    // `$cachedRequired` gets set in `_evaluateRequiredFunctions()` so we\n    // don't call required functions multiple times in one validate call\n    // See gh-6801\n    if (cachedRequired != null && _this.path in cachedRequired) {\n      const res = cachedRequired[_this.path] ?\n        _this.checkRequired(v, this) :\n        true;\n      delete cachedRequired[_this.path];\n      return res;\n    } else if (typeof required === 'function') {\n      return required.apply(this) ? _this.checkRequired(v, this) : true;\n    }\n\n    return _this.checkRequired(v, this);\n  };\n  this.originalRequiredValue = required;\n\n  if (typeof required === 'string') {\n    message = required;\n    required = undefined;\n  }\n\n  const msg = message || MongooseError.messages.general.required;\n  this.validators.unshift(Object.assign({}, customOptions, {\n    validator: this.requiredValidator,\n    message: msg,\n    type: 'required'\n  }));\n\n  return this;\n};\n\n/**\n * Set the model that this path refers to. This is the option that [populate](https://mongoosejs.com/docs/populate.html)\n * looks at to determine the foreign collection it should query.\n *\n * #### Example:\n *\n *     const userSchema = new Schema({ name: String });\n *     const User = mongoose.model('User', userSchema);\n *\n *     const postSchema = new Schema({ user: mongoose.ObjectId });\n *     postSchema.path('user').ref('User'); // Can set ref to a model name\n *     postSchema.path('user').ref(User); // Or a model class\n *     postSchema.path('user').ref(() => 'User'); // Or a function that returns the model name\n *     postSchema.path('user').ref(() => User); // Or a function that returns the model class\n *\n *     // Or you can just declare the `ref` inline in your schema\n *     const postSchema2 = new Schema({\n *       user: { type: mongoose.ObjectId, ref: User }\n *     });\n *\n * @param {String|Model|Function} ref either a model name, a [Model](https://mongoosejs.com/docs/models.html), or a function that returns a model name or model.\n * @return {SchemaType} this\n * @api public\n */\n\nSchemaType.prototype.ref = function(ref) {\n  this.options.ref = ref;\n  return this;\n};\n\n/**\n * Gets the default value\n *\n * @param {Object} scope the scope which callback are executed\n * @param {Boolean} init\n * @return {Any} The Stored default value.\n * @api private\n */\n\nSchemaType.prototype.getDefault = function(scope, init, options) {\n  let ret;\n  if (typeof this.defaultValue === 'function') {\n    if (\n      this.defaultValue === Date.now ||\n      this.defaultValue === Array ||\n      this.defaultValue.name.toLowerCase() === 'objectid'\n    ) {\n      ret = this.defaultValue.call(scope);\n    } else {\n      ret = this.defaultValue.call(scope, scope);\n    }\n  } else {\n    ret = this.defaultValue;\n  }\n\n  if (ret !== null && ret !== undefined) {\n    if (typeof ret === 'object' && (!this.options || !this.options.shared)) {\n      ret = clone(ret);\n    }\n\n    if (options && options.skipCast) {\n      return this._applySetters(ret, scope);\n    }\n\n    const casted = this.applySetters(ret, scope, init, undefined, setOptionsForDefaults);\n    if (casted && !Array.isArray(casted) && casted.$isSingleNested) {\n      casted.$__parent = scope;\n    }\n    return casted;\n  }\n  return ret;\n};\n\n/**\n * Applies setters without casting\n *\n * @param {Any} value\n * @param {Any} scope\n * @param {Boolean} init\n * @param {Any} priorVal\n * @param {Object} [options]\n * @instance\n * @api private\n */\n\nSchemaType.prototype._applySetters = function(value, scope, init, priorVal, options) {\n  let v = value;\n  if (init) {\n    return v;\n  }\n  const setters = this.setters;\n\n  for (let i = setters.length - 1; i >= 0; i--) {\n    v = setters[i].call(scope, v, priorVal, this, options);\n  }\n\n  return v;\n};\n\n/*!\n * ignore\n */\n\nSchemaType.prototype._castNullish = function _castNullish(v) {\n  return v;\n};\n\n/**\n * Applies setters\n *\n * @param {Object} value\n * @param {Object} scope\n * @param {Boolean} init\n * @return {Any}\n * @api private\n */\n\nSchemaType.prototype.applySetters = function(value, scope, init, priorVal, options) {\n  let v = this._applySetters(value, scope, init, priorVal, options);\n  if (v == null) {\n    return this._castNullish(v);\n  }\n  // do not cast until all setters are applied #665\n  v = this.cast(v, scope, init, priorVal, options);\n\n  return v;\n};\n\n/**\n * Applies getters to a value\n *\n * @param {Object} value\n * @param {Object} scope\n * @return {Any}\n * @api private\n */\n\nSchemaType.prototype.applyGetters = function(value, scope) {\n  let v = value;\n  const getters = this.getters;\n  const len = getters.length;\n\n  if (len === 0) {\n    return v;\n  }\n\n  for (let i = 0; i < len; ++i) {\n    v = getters[i].call(scope, v, this);\n  }\n\n  return v;\n};\n\n/**\n * Sets default `select()` behavior for this path.\n *\n * Set to `true` if this path should always be included in the results, `false` if it should be excluded by default. This setting can be overridden at the query level.\n *\n * #### Example:\n *\n *     T = db.model('T', new Schema({ x: { type: String, select: true }}));\n *     T.find(..); // field x will always be selected ..\n *     // .. unless overridden;\n *     T.find().select('-x').exec(callback);\n *\n * @param {Boolean} val\n * @return {SchemaType} this\n * @api public\n */\n\nSchemaType.prototype.select = function select(val) {\n  this.selected = !!val;\n  return this;\n};\n\n/**\n * Performs a validation of `value` using the validators declared for this SchemaType.\n *\n * @param {Any} value\n * @param {Function} callback\n * @param {Object} scope\n * @param {Object} [options]\n * @param {String} [options.path]\n * @return {Any} If no validators, returns the output from calling `fn`, otherwise no return\n * @api public\n */\n\nSchemaType.prototype.doValidate = function(value, fn, scope, options) {\n  let err = false;\n  const path = this.path;\n  if (typeof fn !== 'function') {\n    throw new TypeError(`Must pass callback function to doValidate(), got ${typeof fn}`);\n  }\n\n  // Avoid non-object `validators`\n  const validators = this.validators.\n    filter(v => typeof v === 'object' && v !== null);\n\n  let count = validators.length;\n\n  if (!count) {\n    return fn(null);\n  }\n\n  for (let i = 0, len = validators.length; i < len; ++i) {\n    if (err) {\n      break;\n    }\n\n    const v = validators[i];\n    const validator = v.validator;\n    let ok;\n\n    const validatorProperties = isSimpleValidator(v) ? Object.assign({}, v) : clone(v);\n    validatorProperties.path = options && options.path ? options.path : path;\n    validatorProperties.fullPath = this.$fullPath;\n    validatorProperties.value = value;\n\n    if (validator instanceof RegExp) {\n      validate(validator.test(value), validatorProperties, scope);\n      continue;\n    }\n\n    if (typeof validator !== 'function') {\n      continue;\n    }\n\n    if (value === undefined && validator !== this.requiredValidator) {\n      validate(true, validatorProperties, scope);\n      continue;\n    }\n\n    try {\n      if (validatorProperties.propsParameter) {\n        ok = validator.call(scope, value, validatorProperties);\n      } else {\n        ok = validator.call(scope, value);\n      }\n    } catch (error) {\n      ok = false;\n      validatorProperties.reason = error;\n      if (error.message) {\n        validatorProperties.message = error.message;\n      }\n    }\n\n    if (ok != null && typeof ok.then === 'function') {\n      ok.then(\n        function(ok) { validate(ok, validatorProperties, scope); },\n        function(error) {\n          validatorProperties.reason = error;\n          validatorProperties.message = error.message;\n          ok = false;\n          validate(ok, validatorProperties, scope);\n        });\n    } else {\n      validate(ok, validatorProperties, scope);\n    }\n  }\n\n  function validate(ok, validatorProperties, scope) {\n    if (err) {\n      return;\n    }\n    if (ok === undefined || ok) {\n      if (--count <= 0) {\n        immediate(function() {\n          fn(null);\n        });\n      }\n    } else {\n      const ErrorConstructor = validatorProperties.ErrorConstructor || ValidatorError;\n      err = new ErrorConstructor(validatorProperties, scope);\n      err[validatorErrorSymbol] = true;\n      immediate(function() {\n        fn(err);\n      });\n    }\n  }\n};\n\n\nfunction _validate(ok, validatorProperties) {\n  if (ok !== undefined && !ok) {\n    const ErrorConstructor = validatorProperties.ErrorConstructor || ValidatorError;\n    const err = new ErrorConstructor(validatorProperties);\n    err[validatorErrorSymbol] = true;\n    return err;\n  }\n}\n\n/**\n * Performs a validation of `value` using the validators declared for this SchemaType.\n *\n * #### Note:\n *\n * This method ignores the asynchronous validators.\n *\n * @param {Any} value\n * @param {Object} scope\n * @param {Object} [options]\n * @param {Object} [options.path]\n * @return {MongooseError|null}\n * @api private\n */\n\nSchemaType.prototype.doValidateSync = function(value, scope, options) {\n  const path = this.path;\n  const count = this.validators.length;\n\n  if (!count) {\n    return null;\n  }\n\n  let validators = this.validators;\n  if (value === void 0) {\n    if (this.validators.length !== 0 && this.validators[0].type === 'required') {\n      validators = [this.validators[0]];\n    } else {\n      return null;\n    }\n  }\n\n  let err = null;\n  let i = 0;\n  const len = validators.length;\n  for (i = 0; i < len; ++i) {\n    const v = validators[i];\n\n    if (v === null || typeof v !== 'object') {\n      continue;\n    }\n\n    const validator = v.validator;\n    const validatorProperties = isSimpleValidator(v) ? Object.assign({}, v) : clone(v);\n    validatorProperties.path = options && options.path ? options.path : path;\n    validatorProperties.fullPath = this.$fullPath;\n    validatorProperties.value = value;\n    let ok = false;\n\n    // Skip any explicit async validators. Validators that return a promise\n    // will still run, but won't trigger any errors.\n    if (isAsyncFunction(validator)) {\n      continue;\n    }\n\n    if (validator instanceof RegExp) {\n      err = _validate(validator.test(value), validatorProperties);\n      continue;\n    }\n\n    if (typeof validator !== 'function') {\n      continue;\n    }\n\n    try {\n      if (validatorProperties.propsParameter) {\n        ok = validator.call(scope, value, validatorProperties);\n      } else {\n        ok = validator.call(scope, value);\n      }\n    } catch (error) {\n      ok = false;\n      validatorProperties.reason = error;\n    }\n\n    // Skip any validators that return a promise, we can't handle those\n    // synchronously\n    if (ok != null && typeof ok.then === 'function') {\n      continue;\n    }\n    err = _validate(ok, validatorProperties);\n    if (err) {\n      break;\n    }\n  }\n\n  return err;\n};\n\n/**\n * Determines if value is a valid Reference.\n *\n * @param {SchemaType} self\n * @param {Object} value\n * @param {Document} doc\n * @param {Boolean} init\n * @return {Boolean}\n * @api private\n */\n\nSchemaType._isRef = function(self, value, doc, init) {\n  // fast path\n  let ref = init && self.options && (self.options.ref || self.options.refPath);\n\n  if (!ref && doc && doc.$__ != null) {\n    // checks for\n    // - this populated with adhoc model and no ref was set in schema OR\n    // - setting / pushing values after population\n    const path = doc.$__fullPath(self.path, true);\n\n    const owner = doc.ownerDocument();\n    ref = (path != null && owner.$populated(path)) || doc.$populated(self.path);\n  }\n\n  if (ref) {\n    if (value == null) {\n      return true;\n    }\n    if (!Buffer.isBuffer(value) && // buffers are objects too\n      value._bsontype !== 'Binary' // raw binary value from the db\n      && utils.isObject(value) // might have deselected _id in population query\n    ) {\n      return true;\n    }\n\n    return init;\n  }\n\n  return false;\n};\n\n/*!\n * ignore\n */\n\nSchemaType.prototype._castRef = function _castRef(value, doc, init) {\n  if (value == null) {\n    return value;\n  }\n\n  if (value.$__ != null) {\n    value.$__.wasPopulated = value.$__.wasPopulated || { value: value._doc._id };\n    return value;\n  }\n\n  // setting a populated path\n  if (Buffer.isBuffer(value) || !utils.isObject(value)) {\n    if (init) {\n      return value;\n    }\n    throw new CastError(this.instance, value, this.path, null, this);\n  }\n\n  // Handle the case where user directly sets a populated\n  // path to a plain object; cast to the Model used in\n  // the population query.\n  const path = doc.$__fullPath(this.path, true);\n  const owner = doc.ownerDocument();\n  const pop = owner.$populated(path, true);\n\n  let ret = value;\n  if (!doc.$__.populated ||\n    !doc.$__.populated[path] ||\n    !doc.$__.populated[path].options ||\n    !doc.$__.populated[path].options.options ||\n    !doc.$__.populated[path].options.options.lean) {\n    ret = new pop.options[populateModelSymbol](value);\n    ret.$__.wasPopulated = { value: ret._doc._id };\n  }\n\n  return ret;\n};\n\n/*!\n * ignore\n */\n\nfunction handleSingle(val, context) {\n  return this.castForQuery(null, val, context);\n}\n\n/*!\n * ignore\n */\n\nfunction handleArray(val, context) {\n  const _this = this;\n  if (!Array.isArray(val)) {\n    return [this.castForQuery(null, val, context)];\n  }\n  return val.map(function(m) {\n    return _this.castForQuery(null, m, context);\n  });\n}\n\n/**\n * Just like handleArray, except also allows `[]` because surprisingly\n * `$in: [1, []]` works fine\n * @api private\n */\n\nfunction handle$in(val, context) {\n  const _this = this;\n  if (!Array.isArray(val)) {\n    return [this.castForQuery(null, val, context)];\n  }\n  return val.map(function(m) {\n    if (Array.isArray(m) && m.length === 0) {\n      return m;\n    }\n    return _this.castForQuery(null, m, context);\n  });\n}\n\n/*!\n * ignore\n */\n\nSchemaType.prototype.$conditionalHandlers = {\n  $all: handleArray,\n  $eq: handleSingle,\n  $in: handle$in,\n  $ne: handleSingle,\n  $nin: handle$in,\n  $exists: $exists,\n  $type: $type\n};\n\n/**\n * Cast the given value with the given optional query operator.\n *\n * @param {String} [$conditional] query operator, like `$eq` or `$in`\n * @param {Any} val\n * @param {Query} context\n * @return {Any}\n * @api private\n */\n\nSchemaType.prototype.castForQuery = function($conditional, val, context) {\n  let handler;\n  if ($conditional != null) {\n    handler = this.$conditionalHandlers[$conditional];\n    if (!handler) {\n      throw new Error('Can\\'t use ' + $conditional);\n    }\n    return handler.call(this, val, context);\n  }\n\n  try {\n    return this.applySetters(val, context);\n  } catch (err) {\n    if (err instanceof CastError && err.path === this.path && this.$fullPath != null) {\n      err.path = this.$fullPath;\n    }\n    throw err;\n  }\n};\n\n/**\n * Set & Get the `checkRequired` function\n * Override the function the required validator uses to check whether a value\n * passes the `required` check. Override this on the individual SchemaType.\n *\n * #### Example:\n *\n *     // Use this to allow empty strings to pass the `required` validator\n *     mongoose.Schema.Types.String.checkRequired(v => typeof v === 'string');\n *\n * @param {Function} [fn] If set, will overwrite the current set function\n * @return {Function} The input `fn` or the already set function\n * @static\n * @memberOf SchemaType\n * @function checkRequired\n * @api public\n */\n\nSchemaType.checkRequired = function(fn) {\n  if (arguments.length !== 0) {\n    this._checkRequired = fn;\n  }\n\n  return this._checkRequired;\n};\n\n/**\n * Default check for if this path satisfies the `required` validator.\n *\n * @param {Any} val\n * @return {Boolean} `true` when the value is not `null`, `false` otherwise\n * @api private\n */\n\nSchemaType.prototype.checkRequired = function(val) {\n  return val != null;\n};\n\n/**\n * Clone the current SchemaType\n *\n * @return {SchemaType} The cloned SchemaType instance\n * @api private\n */\n\nSchemaType.prototype.clone = function() {\n  const options = Object.assign({}, this.options);\n  const schematype = new this.constructor(this.path, options, this.instance);\n  schematype.validators = this.validators.slice();\n  if (this.requiredValidator !== undefined) schematype.requiredValidator = this.requiredValidator;\n  if (this.defaultValue !== undefined) schematype.defaultValue = this.defaultValue;\n  if (this.$immutable !== undefined && this.options.immutable === undefined) {\n    schematype.$immutable = this.$immutable;\n\n    handleImmutable(schematype);\n  }\n  if (this._index !== undefined) schematype._index = this._index;\n  if (this.selected !== undefined) schematype.selected = this.selected;\n  if (this.isRequired !== undefined) schematype.isRequired = this.isRequired;\n  if (this.originalRequiredValue !== undefined) schematype.originalRequiredValue = this.originalRequiredValue;\n  schematype.getters = this.getters.slice();\n  schematype.setters = this.setters.slice();\n  return schematype;\n};\n\n/*!\n * Module exports.\n */\n\nmodule.exports = exports = SchemaType;\n\nexports.CastError = CastError;\n\nexports.ValidatorError = ValidatorError;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/schemaType.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/stateMachine.js":
/*!***************************************************!*\
  !*** ./node_modules/mongoose/lib/stateMachine.js ***!
  \***************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n/*!\n * Module dependencies.\n */\n\n\n\nconst utils = __webpack_require__(/*! ./utils */ \"./node_modules/mongoose/lib/utils.js\"); // eslint-disable-line no-unused-vars\n\n/**\n * StateMachine represents a minimal `interface` for the\n * constructors it builds via StateMachine.ctor(...).\n *\n * @api private\n */\n\nconst StateMachine = module.exports = exports = function StateMachine() {\n};\n\n/**\n * StateMachine.ctor('state1', 'state2', ...)\n * A factory method for subclassing StateMachine.\n * The arguments are a list of states. For each state,\n * the constructor's prototype gets state transition\n * methods named after each state. These transition methods\n * place their path argument into the given state.\n *\n * @param {String} state\n * @param {String} [state]\n * @return {Function} subclass constructor\n * @api private\n */\n\nStateMachine.ctor = function() {\n  const states = [...arguments];\n\n  const ctor = function() {\n    StateMachine.apply(this, arguments);\n    this.paths = {};\n    this.states = {};\n  };\n\n  ctor.prototype = new StateMachine();\n  ctor.prototype.constructor = ctor;\n\n  ctor.prototype.stateNames = states;\n\n  states.forEach(function(state) {\n    // Changes the `path`'s state to `state`.\n    ctor.prototype[state] = function(path) {\n      this._changeState(path, state);\n    };\n  });\n\n  return ctor;\n};\n\n/**\n * This function is wrapped by the state change functions:\n *\n * - `require(path)`\n * - `modify(path)`\n * - `init(path)`\n *\n * @api private\n */\n\nStateMachine.prototype._changeState = function _changeState(path, nextState) {\n  const prevState = this.paths[path];\n  if (prevState === nextState) {\n    return;\n  }\n  const prevBucket = this.states[prevState];\n  if (prevBucket) delete prevBucket[path];\n\n  this.paths[path] = nextState;\n  this.states[nextState] = this.states[nextState] || {};\n  this.states[nextState][path] = true;\n};\n\n/*!\n * ignore\n */\n\nStateMachine.prototype.clear = function clear(state) {\n  if (this.states[state] == null) {\n    return;\n  }\n  const keys = Object.keys(this.states[state]);\n  let i = keys.length;\n  let path;\n\n  while (i--) {\n    path = keys[i];\n    delete this.states[state][path];\n    delete this.paths[path];\n  }\n};\n\n/*!\n * ignore\n */\n\nStateMachine.prototype.clearPath = function clearPath(path) {\n  const state = this.paths[path];\n  if (!state) {\n    return;\n  }\n  delete this.paths[path];\n  delete this.states[state][path];\n};\n\n/**\n * Gets the paths for the given state, or empty object `{}` if none.\n * @api private\n */\n\nStateMachine.prototype.getStatePaths = function getStatePaths(state) {\n  if (this.states[state] != null) {\n    return this.states[state];\n  }\n  return {};\n};\n\n/**\n * Checks to see if at least one path is in the states passed in via `arguments`\n * e.g., this.some('required', 'inited')\n *\n * @param {String} state that we want to check for.\n * @api private\n */\n\nStateMachine.prototype.some = function some() {\n  const _this = this;\n  const what = arguments.length ? arguments : this.stateNames;\n  return Array.prototype.some.call(what, function(state) {\n    if (_this.states[state] == null) {\n      return false;\n    }\n    return Object.keys(_this.states[state]).length;\n  });\n};\n\n/**\n * This function builds the functions that get assigned to `forEach` and `map`,\n * since both of those methods share a lot of the same logic.\n *\n * @param {String} iterMethod is either 'forEach' or 'map'\n * @return {Function}\n * @api private\n */\n\nStateMachine.prototype._iter = function _iter(iterMethod) {\n  return function() {\n    let states = [...arguments];\n    const callback = states.pop();\n\n    if (!states.length) states = this.stateNames;\n\n    const _this = this;\n\n    const paths = states.reduce(function(paths, state) {\n      if (_this.states[state] == null) {\n        return paths;\n      }\n      return paths.concat(Object.keys(_this.states[state]));\n    }, []);\n\n    return paths[iterMethod](function(path, i, paths) {\n      return callback(path, i, paths);\n    });\n  };\n};\n\n/**\n * Iterates over the paths that belong to one of the parameter states.\n *\n * The function profile can look like:\n * this.forEach(state1, fn);         // iterates over all paths in state1\n * this.forEach(state1, state2, fn); // iterates over all paths in state1 or state2\n * this.forEach(fn);                 // iterates over all paths in all states\n *\n * @param {String} [state]\n * @param {String} [state]\n * @param {Function} callback\n * @api private\n */\n\nStateMachine.prototype.forEach = function forEach() {\n  this.forEach = this._iter('forEach');\n  return this.forEach.apply(this, arguments);\n};\n\n/**\n * Maps over the paths that belong to one of the parameter states.\n *\n * The function profile can look like:\n * this.forEach(state1, fn);         // iterates over all paths in state1\n * this.forEach(state1, state2, fn); // iterates over all paths in state1 or state2\n * this.forEach(fn);                 // iterates over all paths in all states\n *\n * @param {String} [state]\n * @param {String} [state]\n * @param {Function} callback\n * @return {Array}\n * @api private\n */\n\nStateMachine.prototype.map = function map() {\n  this.map = this._iter('map');\n  return this.map.apply(this, arguments);\n};\n\n/**\n * Returns a copy of this state machine\n *\n * @param {Function} callback\n * @return {StateMachine}\n * @api private\n */\n\nStateMachine.prototype.clone = function clone() {\n  const result = new this.constructor();\n  result.paths = { ...this.paths };\n  for (const state of this.stateNames) {\n    if (!(state in this.states)) {\n      continue;\n    }\n    result.states[state] = this.states[state] == null ? this.states[state] : { ...this.states[state] };\n  }\n  return result;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/stateMachine.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/types/array/index.js":
/*!********************************************************!*\
  !*** ./node_modules/mongoose/lib/types/array/index.js ***!
  \********************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module dependencies.\n */\n\n\n\nconst Document = __webpack_require__(/*! ../../document */ \"./node_modules/mongoose/lib/document.js\");\nconst mongooseArrayMethods = __webpack_require__(/*! ./methods */ \"./node_modules/mongoose/lib/types/array/methods/index.js\");\n\nconst arrayAtomicsSymbol = (__webpack_require__(/*! ../../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").arrayAtomicsSymbol);\nconst arrayAtomicsBackupSymbol = (__webpack_require__(/*! ../../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").arrayAtomicsBackupSymbol);\nconst arrayParentSymbol = (__webpack_require__(/*! ../../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").arrayParentSymbol);\nconst arrayPathSymbol = (__webpack_require__(/*! ../../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").arrayPathSymbol);\nconst arraySchemaSymbol = (__webpack_require__(/*! ../../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").arraySchemaSymbol);\n\n/**\n * Mongoose Array constructor.\n *\n * #### Note:\n *\n * _Values always have to be passed to the constructor to initialize, otherwise `MongooseArray#push` will mark the array as modified._\n *\n * @param {Array} values\n * @param {String} path\n * @param {Document} doc parent document\n * @api private\n * @inherits Array https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array\n * @see https://bit.ly/f6CnZU\n */\nconst _basePush = Array.prototype.push;\nconst numberRE = /^\\d+$/;\n\nfunction MongooseArray(values, path, doc, schematype) {\n  let __array;\n\n  if (Array.isArray(values)) {\n    const len = values.length;\n\n    // Perf optimizations for small arrays: much faster to use `...` than `for` + `push`,\n    // but large arrays may cause stack overflows. And for arrays of length 0/1, just\n    // modifying the array is faster. Seems small, but adds up when you have a document\n    // with thousands of nested arrays.\n    if (len === 0) {\n      __array = new Array();\n    } else if (len === 1) {\n      __array = new Array(1);\n      __array[0] = values[0];\n    } else if (len < 10000) {\n      __array = new Array();\n      _basePush.apply(__array, values);\n    } else {\n      __array = new Array();\n      for (let i = 0; i < len; ++i) {\n        _basePush.call(__array, values[i]);\n      }\n    }\n  } else {\n    __array = [];\n  }\n\n  const internals = {\n    [arrayAtomicsSymbol]: {},\n    [arrayAtomicsBackupSymbol]: void 0,\n    [arrayPathSymbol]: path,\n    [arraySchemaSymbol]: schematype,\n    [arrayParentSymbol]: void 0,\n    isMongooseArray: true,\n    isMongooseArrayProxy: true,\n    __array: __array\n  };\n\n  if (values && values[arrayAtomicsSymbol] != null) {\n    internals[arrayAtomicsSymbol] = values[arrayAtomicsSymbol];\n  }\n\n  // Because doc comes from the context of another function, doc === global\n  // can happen if there was a null somewhere up the chain (see #3020)\n  // RB Jun 17, 2015 updated to check for presence of expected paths instead\n  // to make more proof against unusual node environments\n  if (doc != null && doc instanceof Document) {\n    internals[arrayParentSymbol] = doc;\n    internals[arraySchemaSymbol] = schematype || doc.schema.path(path);\n  }\n\n  const proxy = new Proxy(__array, {\n    get: function(target, prop) {\n      if (internals.hasOwnProperty(prop)) {\n        return internals[prop];\n      }\n      if (mongooseArrayMethods.hasOwnProperty(prop)) {\n        return mongooseArrayMethods[prop];\n      }\n      if (typeof prop === 'string' && numberRE.test(prop) && schematype?.$embeddedSchemaType != null) {\n        return schematype.$embeddedSchemaType.applyGetters(__array[prop], doc);\n      }\n\n      return __array[prop];\n    },\n    set: function(target, prop, value) {\n      if (typeof prop === 'string' && numberRE.test(prop)) {\n        mongooseArrayMethods.set.call(proxy, prop, value, false);\n      } else if (internals.hasOwnProperty(prop)) {\n        internals[prop] = value;\n      } else {\n        __array[prop] = value;\n      }\n\n      return true;\n    }\n  });\n\n  return proxy;\n}\n\n/*!\n * Module exports.\n */\n\nmodule.exports = exports = MongooseArray;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/types/array/index.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/types/array/isMongooseArray.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongoose/lib/types/array/isMongooseArray.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nexports.isMongooseArray = function(mongooseArray) {\n  return Array.isArray(mongooseArray) && mongooseArray.isMongooseArray;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/types/array/isMongooseArray.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/types/array/methods/index.js":
/*!****************************************************************!*\
  !*** ./node_modules/mongoose/lib/types/array/methods/index.js ***!
  \****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst Document = __webpack_require__(/*! ../../../document */ \"./node_modules/mongoose/lib/document.js\");\nconst ArraySubdocument = __webpack_require__(/*! ../../arraySubdocument */ \"./node_modules/mongoose/lib/types/arraySubdocument.js\");\nconst MongooseError = __webpack_require__(/*! ../../../error/mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\nconst cleanModifiedSubpaths = __webpack_require__(/*! ../../../helpers/document/cleanModifiedSubpaths */ \"./node_modules/mongoose/lib/helpers/document/cleanModifiedSubpaths.js\");\nconst clone = __webpack_require__(/*! ../../../helpers/clone */ \"./node_modules/mongoose/lib/helpers/clone.js\");\nconst internalToObjectOptions = (__webpack_require__(/*! ../../../options */ \"./node_modules/mongoose/lib/options.js\").internalToObjectOptions);\nconst mpath = __webpack_require__(/*! mpath */ \"./node_modules/mpath/index.js\");\nconst utils = __webpack_require__(/*! ../../../utils */ \"./node_modules/mongoose/lib/utils.js\");\nconst isBsonType = __webpack_require__(/*! ../../../helpers/isBsonType */ \"./node_modules/mongoose/lib/helpers/isBsonType.js\");\n\nconst arrayAtomicsSymbol = (__webpack_require__(/*! ../../../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").arrayAtomicsSymbol);\nconst arrayParentSymbol = (__webpack_require__(/*! ../../../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").arrayParentSymbol);\nconst arrayPathSymbol = (__webpack_require__(/*! ../../../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").arrayPathSymbol);\nconst arraySchemaSymbol = (__webpack_require__(/*! ../../../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").arraySchemaSymbol);\nconst populateModelSymbol = (__webpack_require__(/*! ../../../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").populateModelSymbol);\nconst slicedSymbol = Symbol('mongoose#Array#sliced');\n\nconst _basePush = Array.prototype.push;\n\n/*!\n * ignore\n */\n\nconst methods = {\n  /**\n   * Depopulates stored atomic operation values as necessary for direct insertion to MongoDB.\n   *\n   * If no atomics exist, we return all array values after conversion.\n   *\n   * @return {Array}\n   * @method $__getAtomics\n   * @memberOf MongooseArray\n   * @instance\n   * @api private\n   */\n\n  $__getAtomics() {\n    const ret = [];\n    const keys = Object.keys(this[arrayAtomicsSymbol] || {});\n    let i = keys.length;\n\n    const opts = Object.assign({}, internalToObjectOptions, { _isNested: true });\n\n    if (i === 0) {\n      ret[0] = ['$set', this.toObject(opts)];\n      return ret;\n    }\n\n    while (i--) {\n      const op = keys[i];\n      let val = this[arrayAtomicsSymbol][op];\n\n      // the atomic values which are arrays are not MongooseArrays. we\n      // need to convert their elements as if they were MongooseArrays\n      // to handle populated arrays versus DocumentArrays properly.\n      if (utils.isMongooseObject(val)) {\n        val = val.toObject(opts);\n      } else if (Array.isArray(val)) {\n        val = this.toObject.call(val, opts);\n      } else if (val != null && Array.isArray(val.$each)) {\n        val.$each = this.toObject.call(val.$each, opts);\n      } else if (val != null && typeof val.valueOf === 'function') {\n        val = val.valueOf();\n      }\n\n      if (op === '$addToSet') {\n        val = { $each: val };\n      }\n\n      ret.push([op, val]);\n    }\n\n    return ret;\n  },\n\n  /*!\n   * ignore\n   */\n\n  $atomics() {\n    return this[arrayAtomicsSymbol];\n  },\n\n  /*!\n   * ignore\n   */\n\n  $parent() {\n    return this[arrayParentSymbol];\n  },\n\n  /*!\n   * ignore\n   */\n\n  $path() {\n    return this[arrayPathSymbol];\n  },\n\n  /**\n   * Atomically shifts the array at most one time per document `save()`.\n   *\n   * #### Note:\n   *\n   * _Calling this multiple times on an array before saving sends the same command as calling it once._\n   * _This update is implemented using the MongoDB [$pop](https://www.mongodb.com/docs/manual/reference/operator/update/pop/) method which enforces this restriction._\n   *\n   *      doc.array = [1,2,3];\n   *\n   *      const shifted = doc.array.$shift();\n   *      console.log(shifted); // 1\n   *      console.log(doc.array); // [2,3]\n   *\n   *      // no affect\n   *      shifted = doc.array.$shift();\n   *      console.log(doc.array); // [2,3]\n   *\n   *      doc.save(function (err) {\n   *        if (err) return handleError(err);\n   *\n   *        // we saved, now $shift works again\n   *        shifted = doc.array.$shift();\n   *        console.log(shifted ); // 2\n   *        console.log(doc.array); // [3]\n   *      })\n   *\n   * @api public\n   * @memberOf MongooseArray\n   * @instance\n   * @method $shift\n   * @see mongodb https://www.mongodb.com/docs/manual/reference/operator/update/pop/\n   */\n\n  $shift() {\n    this._registerAtomic('$pop', -1);\n    this._markModified();\n\n    // only allow shifting once\n    const __array = this.__array;\n    if (__array._shifted) {\n      return;\n    }\n    __array._shifted = true;\n\n    return [].shift.call(__array);\n  },\n\n  /**\n   * Pops the array atomically at most one time per document `save()`.\n   *\n   * #### NOTE:\n   *\n   * _Calling this multiple times on an array before saving sends the same command as calling it once._\n   * _This update is implemented using the MongoDB [$pop](https://www.mongodb.com/docs/manual/reference/operator/update/pop/) method which enforces this restriction._\n   *\n   *      doc.array = [1,2,3];\n   *\n   *      const popped = doc.array.$pop();\n   *      console.log(popped); // 3\n   *      console.log(doc.array); // [1,2]\n   *\n   *      // no affect\n   *      popped = doc.array.$pop();\n   *      console.log(doc.array); // [1,2]\n   *\n   *      doc.save(function (err) {\n   *        if (err) return handleError(err);\n   *\n   *        // we saved, now $pop works again\n   *        popped = doc.array.$pop();\n   *        console.log(popped); // 2\n   *        console.log(doc.array); // [1]\n   *      })\n   *\n   * @api public\n   * @method $pop\n   * @memberOf MongooseArray\n   * @instance\n   * @see mongodb https://www.mongodb.com/docs/manual/reference/operator/update/pop/\n   * @method $pop\n   * @memberOf MongooseArray\n   */\n\n  $pop() {\n    this._registerAtomic('$pop', 1);\n    this._markModified();\n\n    // only allow popping once\n    if (this._popped) {\n      return;\n    }\n    this._popped = true;\n\n    return [].pop.call(this);\n  },\n\n  /*!\n   * ignore\n   */\n\n  $schema() {\n    return this[arraySchemaSymbol];\n  },\n\n  /**\n   * Casts a member based on this arrays schema.\n   *\n   * @param {any} value\n   * @return value the casted value\n   * @method _cast\n   * @api private\n   * @memberOf MongooseArray\n   */\n\n  _cast(value) {\n    let populated = false;\n    let Model;\n\n    const parent = this[arrayParentSymbol];\n    if (parent) {\n      populated = parent.$populated(this[arrayPathSymbol], true);\n    }\n\n    if (populated && value !== null && value !== undefined) {\n      // cast to the populated Models schema\n      Model = populated.options[populateModelSymbol];\n      if (Model == null) {\n        throw new MongooseError('No populated model found for path `' + this[arrayPathSymbol] + '`. This is likely a bug in Mongoose, please report an issue on github.com/Automattic/mongoose.');\n      }\n\n      // only objects are permitted so we can safely assume that\n      // non-objects are to be interpreted as _id\n      if (Buffer.isBuffer(value) ||\n          isBsonType(value, 'ObjectId') || !utils.isObject(value)) {\n        value = { _id: value };\n      }\n\n      // gh-2399\n      // we should cast model only when it's not a discriminator\n      const isDisc = value.schema && value.schema.discriminatorMapping &&\n          value.schema.discriminatorMapping.key !== undefined;\n      if (!isDisc) {\n        value = new Model(value);\n      }\n      return this[arraySchemaSymbol].caster.applySetters(value, parent, true);\n    }\n\n    return this[arraySchemaSymbol].caster.applySetters(value, parent, false);\n  },\n\n  /**\n   * Internal helper for .map()\n   *\n   * @api private\n   * @return {Number}\n   * @method _mapCast\n   * @memberOf MongooseArray\n   */\n\n  _mapCast(val, index) {\n    return this._cast(val, this.length + index);\n  },\n\n  /**\n   * Marks this array as modified.\n   *\n   * If it bubbles up from an embedded document change, then it takes the following arguments (otherwise, takes 0 arguments)\n   *\n   * @param {ArraySubdocument} subdoc the embedded doc that invoked this method on the Array\n   * @param {String} embeddedPath the path which changed in the subdoc\n   * @method _markModified\n   * @api private\n   * @memberOf MongooseArray\n   */\n\n  _markModified(elem) {\n    const parent = this[arrayParentSymbol];\n    let dirtyPath;\n\n    if (parent) {\n      dirtyPath = this[arrayPathSymbol];\n\n      if (arguments.length) {\n        dirtyPath = dirtyPath + '.' + elem;\n      }\n\n      if (dirtyPath != null && dirtyPath.endsWith('.$')) {\n        return this;\n      }\n\n      parent.markModified(dirtyPath, arguments.length !== 0 ? elem : parent);\n    }\n\n    return this;\n  },\n\n  /**\n   * Register an atomic operation with the parent.\n   *\n   * @param {Array} op operation\n   * @param {any} val\n   * @method _registerAtomic\n   * @api private\n   * @memberOf MongooseArray\n   */\n\n  _registerAtomic(op, val) {\n    if (this[slicedSymbol]) {\n      return;\n    }\n    if (op === '$set') {\n      // $set takes precedence over all other ops.\n      // mark entire array modified.\n      this[arrayAtomicsSymbol] = { $set: val };\n      cleanModifiedSubpaths(this[arrayParentSymbol], this[arrayPathSymbol]);\n      this._markModified();\n      return this;\n    }\n\n    const atomics = this[arrayAtomicsSymbol];\n\n    // reset pop/shift after save\n    if (op === '$pop' && !('$pop' in atomics)) {\n      const _this = this;\n      this[arrayParentSymbol].once('save', function() {\n        _this._popped = _this._shifted = null;\n      });\n    }\n\n    // check for impossible $atomic combos (Mongo denies more than one\n    // $atomic op on a single path\n    if (atomics.$set || Object.keys(atomics).length && !(op in atomics)) {\n      // a different op was previously registered.\n      // save the entire thing.\n      this[arrayAtomicsSymbol] = { $set: this };\n      return this;\n    }\n\n    let selector;\n\n    if (op === '$pullAll' || op === '$addToSet') {\n      atomics[op] || (atomics[op] = []);\n      atomics[op] = atomics[op].concat(val);\n    } else if (op === '$pullDocs') {\n      const pullOp = atomics['$pull'] || (atomics['$pull'] = {});\n      if (val[0] instanceof ArraySubdocument) {\n        selector = pullOp['$or'] || (pullOp['$or'] = []);\n        Array.prototype.push.apply(selector, val.map(v => {\n          return v.toObject({\n            transform: (doc, ret) => {\n              if (v == null || v.$__ == null) {\n                return ret;\n              }\n\n              Object.keys(v.$__.activePaths.getStatePaths('default')).forEach(path => {\n                mpath.unset(path, ret);\n\n                _minimizePath(ret, path);\n              });\n\n              return ret;\n            },\n            virtuals: false\n          });\n        }));\n      } else {\n        selector = pullOp['_id'] || (pullOp['_id'] = { $in: [] });\n        selector['$in'] = selector['$in'].concat(val);\n      }\n    } else if (op === '$push') {\n      atomics.$push = atomics.$push || { $each: [] };\n      if (val != null && utils.hasUserDefinedProperty(val, '$each')) {\n        atomics.$push = val;\n      } else {\n        if (val.length === 1) {\n          atomics.$push.$each.push(val[0]);\n        } else if (val.length < 10000) {\n          atomics.$push.$each.push(...val);\n        } else {\n          for (const v of val) {\n            atomics.$push.$each.push(v);\n          }\n        }\n      }\n    } else {\n      atomics[op] = val;\n    }\n\n    return this;\n  },\n\n  /**\n   * Adds values to the array if not already present.\n   *\n   * #### Example:\n   *\n   *     console.log(doc.array) // [2,3,4]\n   *     const added = doc.array.addToSet(4,5);\n   *     console.log(doc.array) // [2,3,4,5]\n   *     console.log(added)     // [5]\n   *\n   * @param {...any} [args]\n   * @return {Array} the values that were added\n   * @memberOf MongooseArray\n   * @api public\n   * @method addToSet\n   */\n\n  addToSet() {\n    _checkManualPopulation(this, arguments);\n\n    const values = [].map.call(arguments, this._mapCast, this);\n    const added = [];\n    let type = '';\n    if (values[0] instanceof ArraySubdocument) {\n      type = 'doc';\n    } else if (values[0] instanceof Date) {\n      type = 'date';\n    } else if (isBsonType(values[0], 'ObjectId')) {\n      type = 'ObjectId';\n    }\n\n    const rawValues = utils.isMongooseArray(values) ? values.__array : values;\n    const rawArray = utils.isMongooseArray(this) ? this.__array : this;\n\n    rawValues.forEach(function(v) {\n      let found;\n      const val = +v;\n      switch (type) {\n        case 'doc':\n          found = this.some(function(doc) {\n            return doc.equals(v);\n          });\n          break;\n        case 'date':\n          found = this.some(function(d) {\n            return +d === val;\n          });\n          break;\n        case 'ObjectId':\n          found = this.find(o => o.toString() === v.toString());\n          break;\n        default:\n          found = ~this.indexOf(v);\n          break;\n      }\n\n      if (!found) {\n        this._markModified();\n        rawArray.push(v);\n        this._registerAtomic('$addToSet', v);\n        [].push.call(added, v);\n      }\n    }, this);\n\n    return added;\n  },\n\n  /**\n   * Returns the number of pending atomic operations to send to the db for this array.\n   *\n   * @api private\n   * @return {Number}\n   * @method hasAtomics\n   * @memberOf MongooseArray\n   */\n\n  hasAtomics() {\n    if (!utils.isPOJO(this[arrayAtomicsSymbol])) {\n      return 0;\n    }\n\n    return Object.keys(this[arrayAtomicsSymbol]).length;\n  },\n\n  /**\n   * Return whether or not the `obj` is included in the array.\n   *\n   * @param {Object} obj the item to check\n   * @param {Number} fromIndex\n   * @return {Boolean}\n   * @api public\n   * @method includes\n   * @memberOf MongooseArray\n   */\n\n  includes(obj, fromIndex) {\n    const ret = this.indexOf(obj, fromIndex);\n    return ret !== -1;\n  },\n\n  /**\n   * Return the index of `obj` or `-1` if not found.\n   *\n   * @param {Object} obj the item to look for\n   * @param {Number} fromIndex\n   * @return {Number}\n   * @api public\n   * @method indexOf\n   * @memberOf MongooseArray\n   */\n\n  indexOf(obj, fromIndex) {\n    if (isBsonType(obj, 'ObjectId')) {\n      obj = obj.toString();\n    }\n\n    fromIndex = fromIndex == null ? 0 : fromIndex;\n    const len = this.length;\n    for (let i = fromIndex; i < len; ++i) {\n      if (obj == this[i]) {\n        return i;\n      }\n    }\n    return -1;\n  },\n\n  /**\n   * Helper for console.log\n   *\n   * @api public\n   * @method inspect\n   * @memberOf MongooseArray\n   */\n\n  inspect() {\n    return JSON.stringify(this);\n  },\n\n  /**\n   * Pushes items to the array non-atomically.\n   *\n   * #### Note:\n   *\n   * _marks the entire array as modified, which if saved, will store it as a `$set` operation, potentially overwritting any changes that happen between when you retrieved the object and when you save it._\n   *\n   * @param {...any} [args]\n   * @api public\n   * @method nonAtomicPush\n   * @memberOf MongooseArray\n   */\n\n  nonAtomicPush() {\n    const values = [].map.call(arguments, this._mapCast, this);\n    this._markModified();\n    const ret = [].push.apply(this, values);\n    this._registerAtomic('$set', this);\n    return ret;\n  },\n\n  /**\n   * Wraps [`Array#pop`](https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/Array/pop) with proper change tracking.\n   *\n   * #### Note:\n   *\n   * _marks the entire array as modified which will pass the entire thing to $set potentially overwriting any changes that happen between when you retrieved the object and when you save it._\n   *\n   * @see MongooseArray#$pop https://mongoosejs.com/docs/api/array.html#MongooseArray.prototype.$pop()\n   * @api public\n   * @method pop\n   * @memberOf MongooseArray\n   */\n\n  pop() {\n    this._markModified();\n    const ret = [].pop.call(this);\n    this._registerAtomic('$set', this);\n    return ret;\n  },\n\n  /**\n   * Pulls items from the array atomically. Equality is determined by casting\n   * the provided value to an embedded document and comparing using\n   * [the `Document.equals()` function.](https://mongoosejs.com/docs/api/document.html#Document.prototype.equals())\n   *\n   * #### Example:\n   *\n   *     doc.array.pull(ObjectId)\n   *     doc.array.pull({ _id: 'someId' })\n   *     doc.array.pull(36)\n   *     doc.array.pull('tag 1', 'tag 2')\n   *\n   * To remove a document from a subdocument array we may pass an object with a matching `_id`.\n   *\n   *     doc.subdocs.push({ _id: 4815162342 })\n   *     doc.subdocs.pull({ _id: 4815162342 }) // removed\n   *\n   * Or we may passing the _id directly and let mongoose take care of it.\n   *\n   *     doc.subdocs.push({ _id: 4815162342 })\n   *     doc.subdocs.pull(4815162342); // works\n   *\n   * The first pull call will result in a atomic operation on the database, if pull is called repeatedly without saving the document, a $set operation is used on the complete array instead, overwriting possible changes that happened on the database in the meantime.\n   *\n   * @param {...any} [args]\n   * @see mongodb https://www.mongodb.com/docs/manual/reference/operator/update/pull/\n   * @api public\n   * @method pull\n   * @memberOf MongooseArray\n   */\n\n  pull() {\n    const values = [].map.call(arguments, (v, i) => this._cast(v, i, { defaults: false }), this);\n    let cur = this[arrayParentSymbol].get(this[arrayPathSymbol]);\n    if (utils.isMongooseArray(cur)) {\n      cur = cur.__array;\n    }\n    let i = cur.length;\n    let mem;\n    this._markModified();\n\n    while (i--) {\n      mem = cur[i];\n      if (mem instanceof Document) {\n        const some = values.some(function(v) {\n          return mem.equals(v);\n        });\n        if (some) {\n          cur.splice(i, 1);\n        }\n      } else if (~this.indexOf.call(values, mem)) {\n        cur.splice(i, 1);\n      }\n    }\n\n    if (values[0] instanceof ArraySubdocument) {\n      this._registerAtomic('$pullDocs', values.map(function(v) {\n        const _id = v.$__getValue('_id');\n        if (_id === undefined || v.$isDefault('_id')) {\n          return v;\n        }\n        return _id;\n      }));\n    } else {\n      this._registerAtomic('$pullAll', values);\n    }\n\n\n    // Might have modified child paths and then pulled, like\n    // `doc.children[1].name = 'test';` followed by\n    // `doc.children.remove(doc.children[0]);`. In this case we fall back\n    // to a `$set` on the whole array. See #3511\n    if (cleanModifiedSubpaths(this[arrayParentSymbol], this[arrayPathSymbol]) > 0) {\n      this._registerAtomic('$set', this);\n    }\n\n    return this;\n  },\n\n  /**\n   * Wraps [`Array#push`](https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/Array/push) with proper change tracking.\n   *\n   * #### Example:\n   *\n   *     const schema = Schema({ nums: [Number] });\n   *     const Model = mongoose.model('Test', schema);\n   *\n   *     const doc = await Model.create({ nums: [3, 4] });\n   *     doc.nums.push(5); // Add 5 to the end of the array\n   *     await doc.save();\n   *\n   *     // You can also pass an object with `$each` as the\n   *     // first parameter to use MongoDB's `$position`\n   *     doc.nums.push({\n   *       $each: [1, 2],\n   *       $position: 0\n   *     });\n   *     doc.nums; // [1, 2, 3, 4, 5]\n   *\n   * @param {...Object} [args]\n   * @api public\n   * @method push\n   * @memberOf MongooseArray\n   */\n\n  push() {\n    let values = arguments;\n    let atomic = values;\n    const isOverwrite = values[0] != null &&\n      utils.hasUserDefinedProperty(values[0], '$each');\n    const arr = utils.isMongooseArray(this) ? this.__array : this;\n    if (isOverwrite) {\n      atomic = values[0];\n      values = values[0].$each;\n    }\n\n    if (this[arraySchemaSymbol] == null) {\n      return _basePush.apply(this, values);\n    }\n\n    _checkManualPopulation(this, values);\n\n    values = [].map.call(values, this._mapCast, this);\n    let ret;\n    const atomics = this[arrayAtomicsSymbol];\n    this._markModified();\n    if (isOverwrite) {\n      atomic.$each = values;\n\n      if ((atomics.$push && atomics.$push.$each && atomics.$push.$each.length || 0) !== 0 &&\n          atomics.$push.$position != atomic.$position) {\n        if (atomic.$position != null) {\n          [].splice.apply(arr, [atomic.$position, 0].concat(values));\n          ret = arr.length;\n        } else {\n          ret = [].push.apply(arr, values);\n        }\n\n        this._registerAtomic('$set', this);\n      } else if (atomic.$position != null) {\n        [].splice.apply(arr, [atomic.$position, 0].concat(values));\n        ret = this.length;\n      } else {\n        ret = [].push.apply(arr, values);\n      }\n    } else {\n      atomic = values;\n      ret = _basePush.apply(arr, values);\n    }\n\n    this._registerAtomic('$push', atomic);\n\n    return ret;\n  },\n\n  /**\n   * Alias of [pull](https://mongoosejs.com/docs/api/array.html#MongooseArray.prototype.pull())\n   *\n   * @see MongooseArray#pull https://mongoosejs.com/docs/api/array.html#MongooseArray.prototype.pull()\n   * @see mongodb https://www.mongodb.com/docs/manual/reference/operator/update/pull/\n   * @api public\n   * @memberOf MongooseArray\n   * @instance\n   * @method remove\n   */\n\n  remove() {\n    return this.pull.apply(this, arguments);\n  },\n\n  /**\n   * Sets the casted `val` at index `i` and marks the array modified.\n   *\n   * #### Example:\n   *\n   *     // given documents based on the following\n   *     const Doc = mongoose.model('Doc', new Schema({ array: [Number] }));\n   *\n   *     const doc = new Doc({ array: [2,3,4] })\n   *\n   *     console.log(doc.array) // [2,3,4]\n   *\n   *     doc.array.set(1,\"5\");\n   *     console.log(doc.array); // [2,5,4] // properly cast to number\n   *     doc.save() // the change is saved\n   *\n   *     // VS not using array#set\n   *     doc.array[1] = \"5\";\n   *     console.log(doc.array); // [2,\"5\",4] // no casting\n   *     doc.save() // change is not saved\n   *\n   * @return {Array} this\n   * @api public\n   * @method set\n   * @memberOf MongooseArray\n   */\n\n  set(i, val, skipModified) {\n    const arr = this.__array;\n    if (skipModified) {\n      arr[i] = val;\n      return this;\n    }\n    const value = methods._cast.call(this, val, i);\n    methods._markModified.call(this, i);\n    arr[i] = value;\n    return this;\n  },\n\n  /**\n   * Wraps [`Array#shift`](https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/Array/unshift) with proper change tracking.\n   *\n   * #### Example:\n   *\n   *     doc.array = [2,3];\n   *     const res = doc.array.shift();\n   *     console.log(res) // 2\n   *     console.log(doc.array) // [3]\n   *\n   * #### Note:\n   *\n   * _marks the entire array as modified, which if saved, will store it as a `$set` operation, potentially overwritting any changes that happen between when you retrieved the object and when you save it._\n   *\n   * @api public\n   * @method shift\n   * @memberOf MongooseArray\n   */\n\n  shift() {\n    const arr = utils.isMongooseArray(this) ? this.__array : this;\n    this._markModified();\n    const ret = [].shift.call(arr);\n    this._registerAtomic('$set', this);\n    return ret;\n  },\n\n  /**\n   * Wraps [`Array#sort`](https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/Array/sort) with proper change tracking.\n   *\n   * #### Note:\n   *\n   * _marks the entire array as modified, which if saved, will store it as a `$set` operation, potentially overwritting any changes that happen between when you retrieved the object and when you save it._\n   *\n   * @api public\n   * @method sort\n   * @memberOf MongooseArray\n   * @see MasteringJS: Array sort https://masteringjs.io/tutorials/fundamentals/array-sort\n   */\n\n  sort() {\n    const arr = utils.isMongooseArray(this) ? this.__array : this;\n    const ret = [].sort.apply(arr, arguments);\n    this._registerAtomic('$set', this);\n    return ret;\n  },\n\n  /**\n   * Wraps [`Array#splice`](https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/Array/splice) with proper change tracking and casting.\n   *\n   * #### Note:\n   *\n   * _marks the entire array as modified, which if saved, will store it as a `$set` operation, potentially overwritting any changes that happen between when you retrieved the object and when you save it._\n   *\n   * @api public\n   * @method splice\n   * @memberOf MongooseArray\n   * @see MasteringJS: Array splice https://masteringjs.io/tutorials/fundamentals/array-splice\n   */\n\n  splice() {\n    let ret;\n    const arr = utils.isMongooseArray(this) ? this.__array : this;\n\n    this._markModified();\n    _checkManualPopulation(this, Array.prototype.slice.call(arguments, 2));\n\n    if (arguments.length) {\n      let vals;\n      if (this[arraySchemaSymbol] == null) {\n        vals = arguments;\n      } else {\n        vals = [];\n        for (let i = 0; i < arguments.length; ++i) {\n          vals[i] = i < 2 ?\n            arguments[i] :\n            this._cast(arguments[i], arguments[0] + (i - 2));\n        }\n      }\n\n      ret = [].splice.apply(arr, vals);\n      this._registerAtomic('$set', this);\n    }\n\n    return ret;\n  },\n\n  /*!\n   * ignore\n   */\n\n  toBSON() {\n    return this.toObject(internalToObjectOptions);\n  },\n\n  /**\n   * Returns a native js Array.\n   *\n   * @param {Object} options\n   * @return {Array}\n   * @api public\n   * @method toObject\n   * @memberOf MongooseArray\n   */\n\n  toObject(options) {\n    const arr = utils.isMongooseArray(this) ? this.__array : this;\n    if (options && options.depopulate) {\n      options = clone(options);\n      options._isNested = true;\n      // Ensure return value is a vanilla array, because in Node.js 6+ `map()`\n      // is smart enough to use the inherited array's constructor.\n      return [].concat(arr).map(function(doc) {\n        return doc instanceof Document\n          ? doc.toObject(options)\n          : doc;\n      });\n    }\n\n    return [].concat(arr);\n  },\n\n  $toObject() {\n    return this.constructor.prototype.toObject.apply(this, arguments);\n  },\n  /**\n   * Wraps [`Array#unshift`](https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/Array/unshift) with proper change tracking.\n   *\n   * #### Note:\n   *\n   * _marks the entire array as modified, which if saved, will store it as a `$set` operation, potentially overwriting any changes that happen between when you retrieved the object and when you save it._\n   *\n   * @api public\n   * @method unshift\n   * @memberOf MongooseArray\n   */\n\n  unshift() {\n    _checkManualPopulation(this, arguments);\n\n    let values;\n    if (this[arraySchemaSymbol] == null) {\n      values = arguments;\n    } else {\n      values = [].map.call(arguments, this._cast, this);\n    }\n\n    const arr = utils.isMongooseArray(this) ? this.__array : this;\n    this._markModified();\n    [].unshift.apply(arr, values);\n    this._registerAtomic('$set', this);\n    return this.length;\n  }\n};\n\n/*!\n * ignore\n */\n\nfunction _isAllSubdocs(docs, ref) {\n  if (!ref) {\n    return false;\n  }\n\n  for (const arg of docs) {\n    if (arg == null) {\n      return false;\n    }\n    const model = arg.constructor;\n    if (!(arg instanceof Document) ||\n      (model.modelName !== ref && model.baseModelName !== ref)) {\n      return false;\n    }\n  }\n\n  return true;\n}\n\n/*!\n * Minimize _just_ empty objects along the path chain specified\n * by `parts`, ignoring all other paths. Useful in cases where\n * you want to minimize after unsetting a path.\n *\n * #### Example:\n *\n *     const obj = { foo: { bar: { baz: {} } }, a: {} };\n *     _minimizePath(obj, 'foo.bar.baz');\n *     obj; // { a: {} }\n */\n\nfunction _minimizePath(obj, parts, i) {\n  if (typeof parts === 'string') {\n    if (parts.indexOf('.') === -1) {\n      return;\n    }\n\n    parts = mpath.stringToParts(parts);\n  }\n  i = i || 0;\n  if (i >= parts.length) {\n    return;\n  }\n  if (obj == null || typeof obj !== 'object') {\n    return;\n  }\n\n  _minimizePath(obj[parts[0]], parts, i + 1);\n  if (obj[parts[0]] != null && typeof obj[parts[0]] === 'object' && Object.keys(obj[parts[0]]).length === 0) {\n    delete obj[parts[0]];\n  }\n}\n\n/*!\n * ignore\n */\n\nfunction _checkManualPopulation(arr, docs) {\n  const ref = arr == null ?\n    null :\n    arr[arraySchemaSymbol] && arr[arraySchemaSymbol].caster && arr[arraySchemaSymbol].caster.options && arr[arraySchemaSymbol].caster.options.ref || null;\n  if (arr.length === 0 &&\n      docs.length !== 0) {\n    if (_isAllSubdocs(docs, ref)) {\n      arr[arrayParentSymbol].$populated(arr[arrayPathSymbol], [], {\n        [populateModelSymbol]: docs[0].constructor\n      });\n    }\n  }\n}\n\nconst returnVanillaArrayMethods = [\n  'filter',\n  'flat',\n  'flatMap',\n  'map',\n  'slice'\n];\nfor (const method of returnVanillaArrayMethods) {\n  if (Array.prototype[method] == null) {\n    continue;\n  }\n\n  methods[method] = function() {\n    const _arr = utils.isMongooseArray(this) ? this.__array : this;\n    const arr = [].concat(_arr);\n\n    return arr[method].apply(arr, arguments);\n  };\n}\n\nmodule.exports = methods;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/types/array/methods/index.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/types/arraySubdocument.js":
/*!*************************************************************!*\
  !*** ./node_modules/mongoose/lib/types/arraySubdocument.js ***!
  \*************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module dependencies.\n */\n\n\n\nconst EventEmitter = (__webpack_require__(/*! events */ \"events\").EventEmitter);\nconst Subdocument = __webpack_require__(/*! ./subdocument */ \"./node_modules/mongoose/lib/types/subdocument.js\");\nconst utils = __webpack_require__(/*! ../utils */ \"./node_modules/mongoose/lib/utils.js\");\n\nconst documentArrayParent = (__webpack_require__(/*! ../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").documentArrayParent);\n\n/**\n * A constructor.\n *\n * @param {Object} obj js object returned from the db\n * @param {MongooseDocumentArray} parentArr the parent array of this document\n * @param {Boolean} skipId\n * @param {Object} fields\n * @param {Number} index\n * @inherits Document\n * @api private\n */\n\nfunction ArraySubdocument(obj, parentArr, skipId, fields, index) {\n  if (utils.isMongooseDocumentArray(parentArr)) {\n    this.__parentArray = parentArr;\n    this[documentArrayParent] = parentArr.$parent();\n  } else {\n    this.__parentArray = undefined;\n    this[documentArrayParent] = undefined;\n  }\n  this.$setIndex(index);\n  this.$__parent = this[documentArrayParent];\n\n  let options;\n  if (typeof skipId === 'object' && skipId != null) {\n    options = { isNew: true, ...skipId };\n    skipId = undefined;\n  } else {\n    options = { isNew: true };\n  }\n\n  Subdocument.call(this, obj, fields, this[documentArrayParent], skipId, options);\n}\n\n/*!\n * Inherit from Subdocument\n */\nArraySubdocument.prototype = Object.create(Subdocument.prototype);\nArraySubdocument.prototype.constructor = ArraySubdocument;\n\nObject.defineProperty(ArraySubdocument.prototype, '$isSingleNested', {\n  configurable: false,\n  writable: false,\n  value: false\n});\n\nObject.defineProperty(ArraySubdocument.prototype, '$isDocumentArrayElement', {\n  configurable: false,\n  writable: false,\n  value: true\n});\n\nfor (const i in EventEmitter.prototype) {\n  ArraySubdocument[i] = EventEmitter.prototype[i];\n}\n\n/*!\n * ignore\n */\n\nArraySubdocument.prototype.$setIndex = function(index) {\n  this.__index = index;\n\n  if (this.$__ != null && this.$__.validationError != null) {\n    const keys = Object.keys(this.$__.validationError.errors);\n    for (const key of keys) {\n      this.invalidate(key, this.$__.validationError.errors[key]);\n    }\n  }\n};\n\n/*!\n * ignore\n */\n\nArraySubdocument.prototype.populate = function() {\n  throw new Error('Mongoose does not support calling populate() on nested ' +\n    'docs. Instead of `doc.arr[0].populate(\"path\")`, use ' +\n    '`doc.populate(\"arr.0.path\")`');\n};\n\n/*!\n * ignore\n */\n\nArraySubdocument.prototype.$__removeFromParent = function() {\n  const _id = this._doc._id;\n  if (!_id) {\n    throw new Error('For your own good, Mongoose does not know ' +\n      'how to remove an ArraySubdocument that has no _id');\n  }\n  this.__parentArray.pull({ _id: _id });\n};\n\n/**\n * Returns the full path to this document. If optional `path` is passed, it is appended to the full path.\n *\n * @param {String} [path]\n * @param {Boolean} [skipIndex] Skip adding the array index. For example `arr.foo` instead of `arr.0.foo`.\n * @return {String}\n * @api private\n * @method $__fullPath\n * @memberOf ArraySubdocument\n * @instance\n */\n\nArraySubdocument.prototype.$__fullPath = function(path, skipIndex) {\n  if (this.__index == null) {\n    return null;\n  }\n  if (!this.$__.fullPath) {\n    this.ownerDocument();\n  }\n\n  if (skipIndex) {\n    return path ?\n      this.$__.fullPath + '.' + path :\n      this.$__.fullPath;\n  }\n\n  return path ?\n    this.$__.fullPath + '.' + this.__index + '.' + path :\n    this.$__.fullPath + '.' + this.__index;\n};\n\n/**\n * Given a path relative to this document, return the path relative\n * to the top-level document.\n * @method $__pathRelativeToParent\n * @memberOf ArraySubdocument\n * @instance\n * @api private\n */\n\nArraySubdocument.prototype.$__pathRelativeToParent = function(path, skipIndex) {\n  if (this.__index == null || (!this.__parentArray || !this.__parentArray.$path)) {\n    return null;\n  }\n  if (skipIndex) {\n    return path == null ? this.__parentArray.$path() : this.__parentArray.$path() + '.' + path;\n  }\n  if (path == null) {\n    return this.__parentArray.$path() + '.' + this.__index;\n  }\n  return this.__parentArray.$path() + '.' + this.__index + '.' + path;\n};\n\n/**\n * Returns this sub-documents parent document.\n * @method $parent\n * @memberOf ArraySubdocument\n * @instance\n * @api public\n */\n\nArraySubdocument.prototype.$parent = function() {\n  return this[documentArrayParent];\n};\n\n/**\n * Returns this subdocument's parent array.\n *\n * #### Example:\n *\n *     const Test = mongoose.model('Test', new Schema({\n *       docArr: [{ name: String }]\n *     }));\n *     const doc = new Test({ docArr: [{ name: 'test subdoc' }] });\n *\n *     doc.docArr[0].parentArray() === doc.docArr; // true\n *\n * @api public\n * @method parentArray\n * @returns DocumentArray\n */\n\nArraySubdocument.prototype.parentArray = function() {\n  return this.__parentArray;\n};\n\n/*!\n * Module exports.\n */\n\nmodule.exports = ArraySubdocument;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/types/arraySubdocument.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/types/buffer.js":
/*!***************************************************!*\
  !*** ./node_modules/mongoose/lib/types/buffer.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Module dependencies.\n */\n\n\n\nconst Binary = (__webpack_require__(/*! bson */ \"./node_modules/bson/lib/bson.cjs\").Binary);\nconst utils = __webpack_require__(/*! ../utils */ \"./node_modules/mongoose/lib/utils.js\");\n\n/**\n * Mongoose Buffer constructor.\n *\n * Values always have to be passed to the constructor to initialize.\n *\n * @param {Buffer} value\n * @param {String} encode\n * @param {Number} offset\n * @api private\n * @inherits Buffer https://nodejs.org/api/buffer.html\n * @see https://bit.ly/f6CnZU\n */\n\nfunction MongooseBuffer(value, encode, offset) {\n  let val = value;\n  if (value == null) {\n    val = 0;\n  }\n\n  let encoding;\n  let path;\n  let doc;\n\n  if (Array.isArray(encode)) {\n    // internal casting\n    path = encode[0];\n    doc = encode[1];\n  } else {\n    encoding = encode;\n  }\n\n  let buf;\n  if (typeof val === 'number' || val instanceof Number) {\n    buf = Buffer.alloc(val);\n  } else { // string, array or object { type: 'Buffer', data: [...] }\n    buf = Buffer.from(val, encoding, offset);\n  }\n  utils.decorate(buf, MongooseBuffer.mixin);\n  buf.isMongooseBuffer = true;\n\n  // make sure these internal props don't show up in Object.keys()\n  buf[MongooseBuffer.pathSymbol] = path;\n  buf[parentSymbol] = doc;\n\n  buf._subtype = 0;\n  return buf;\n}\n\nconst pathSymbol = Symbol.for('mongoose#Buffer#_path');\nconst parentSymbol = Symbol.for('mongoose#Buffer#_parent');\nMongooseBuffer.pathSymbol = pathSymbol;\n\n/*!\n * Inherit from Buffer.\n */\n\nMongooseBuffer.mixin = {\n\n  /**\n   * Default subtype for the Binary representing this Buffer\n   *\n   * @api private\n   * @property _subtype\n   * @memberOf MongooseBuffer.mixin\n   * @static\n   */\n\n  _subtype: undefined,\n\n  /**\n   * Marks this buffer as modified.\n   *\n   * @api private\n   * @method _markModified\n   * @memberOf MongooseBuffer.mixin\n   * @static\n   */\n\n  _markModified: function() {\n    const parent = this[parentSymbol];\n\n    if (parent) {\n      parent.markModified(this[MongooseBuffer.pathSymbol]);\n    }\n    return this;\n  },\n\n  /**\n   * Writes the buffer.\n   *\n   * @api public\n   * @method write\n   * @memberOf MongooseBuffer.mixin\n   * @static\n   */\n\n  write: function() {\n    const written = Buffer.prototype.write.apply(this, arguments);\n\n    if (written > 0) {\n      this._markModified();\n    }\n\n    return written;\n  },\n\n  /**\n   * Copies the buffer.\n   *\n   * #### Note:\n   *\n   * `Buffer#copy` does not mark `target` as modified so you must copy from a `MongooseBuffer` for it to work as expected. This is a work around since `copy` modifies the target, not this.\n   *\n   * @return {Number} The number of bytes copied.\n   * @param {Buffer} target\n   * @method copy\n   * @memberOf MongooseBuffer.mixin\n   * @static\n   */\n\n  copy: function(target) {\n    const ret = Buffer.prototype.copy.apply(this, arguments);\n\n    if (target && target.isMongooseBuffer) {\n      target._markModified();\n    }\n\n    return ret;\n  }\n};\n\n/*!\n * Compile other Buffer methods marking this buffer as modified.\n */\n\nutils.each(\n  [\n    // node < 0.5\n    'writeUInt8', 'writeUInt16', 'writeUInt32', 'writeInt8', 'writeInt16', 'writeInt32',\n    'writeFloat', 'writeDouble', 'fill',\n    'utf8Write', 'binaryWrite', 'asciiWrite', 'set',\n\n    // node >= 0.5\n    'writeUInt16LE', 'writeUInt16BE', 'writeUInt32LE', 'writeUInt32BE',\n    'writeInt16LE', 'writeInt16BE', 'writeInt32LE', 'writeInt32BE', 'writeFloatLE', 'writeFloatBE', 'writeDoubleLE', 'writeDoubleBE']\n  , function(method) {\n    if (!Buffer.prototype[method]) {\n      return;\n    }\n    MongooseBuffer.mixin[method] = function() {\n      const ret = Buffer.prototype[method].apply(this, arguments);\n      this._markModified();\n      return ret;\n    };\n  });\n\n/**\n * Converts this buffer to its Binary type representation.\n *\n * #### SubTypes:\n *\n *     const bson = require('bson')\n *     bson.BSON_BINARY_SUBTYPE_DEFAULT\n *     bson.BSON_BINARY_SUBTYPE_FUNCTION\n *     bson.BSON_BINARY_SUBTYPE_BYTE_ARRAY\n *     bson.BSON_BINARY_SUBTYPE_UUID\n *     bson.BSON_BINARY_SUBTYPE_MD5\n *     bson.BSON_BINARY_SUBTYPE_USER_DEFINED\n *     doc.buffer.toObject(bson.BSON_BINARY_SUBTYPE_USER_DEFINED);\n *\n * @see bsonspec https://bsonspec.org/#/specification\n * @param {Hex} [subtype]\n * @return {Binary}\n * @api public\n * @method toObject\n * @memberOf MongooseBuffer\n */\n\nMongooseBuffer.mixin.toObject = function(options) {\n  const subtype = typeof options === 'number'\n    ? options\n    : (this._subtype || 0);\n  return new Binary(Buffer.from(this), subtype);\n};\n\nMongooseBuffer.mixin.$toObject = MongooseBuffer.mixin.toObject;\n\n/**\n * Converts this buffer for storage in MongoDB, including subtype\n *\n * @return {Binary}\n * @api public\n * @method toBSON\n * @memberOf MongooseBuffer\n */\n\nMongooseBuffer.mixin.toBSON = function() {\n  return new Binary(this, this._subtype || 0);\n};\n\n/**\n * Determines if this buffer is equals to `other` buffer\n *\n * @param {Buffer} other\n * @return {Boolean}\n * @method equals\n * @memberOf MongooseBuffer\n */\n\nMongooseBuffer.mixin.equals = function(other) {\n  if (!Buffer.isBuffer(other)) {\n    return false;\n  }\n\n  if (this.length !== other.length) {\n    return false;\n  }\n\n  for (let i = 0; i < this.length; ++i) {\n    if (this[i] !== other[i]) {\n      return false;\n    }\n  }\n\n  return true;\n};\n\n/**\n * Sets the subtype option and marks the buffer modified.\n *\n * #### SubTypes:\n *\n *     const bson = require('bson')\n *     bson.BSON_BINARY_SUBTYPE_DEFAULT\n *     bson.BSON_BINARY_SUBTYPE_FUNCTION\n *     bson.BSON_BINARY_SUBTYPE_BYTE_ARRAY\n *     bson.BSON_BINARY_SUBTYPE_UUID\n *     bson.BSON_BINARY_SUBTYPE_MD5\n *     bson.BSON_BINARY_SUBTYPE_USER_DEFINED\n *\n *     doc.buffer.subtype(bson.BSON_BINARY_SUBTYPE_UUID);\n *\n * @see bsonspec https://bsonspec.org/#/specification\n * @param {Hex} subtype\n * @api public\n * @method subtype\n * @memberOf MongooseBuffer\n */\n\nMongooseBuffer.mixin.subtype = function(subtype) {\n  if (typeof subtype !== 'number') {\n    throw new TypeError('Invalid subtype. Expected a number');\n  }\n\n  if (this._subtype !== subtype) {\n    this._markModified();\n  }\n\n  this._subtype = subtype;\n};\n\n/*!\n * Module exports.\n */\n\nMongooseBuffer.Binary = Binary;\n\nmodule.exports = MongooseBuffer;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/types/buffer.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/types/decimal128.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongoose/lib/types/decimal128.js ***!
  \*******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/**\n * Decimal128 type constructor\n *\n * #### Example:\n *\n *     const id = new mongoose.Types.Decimal128('3.1415');\n *\n * @constructor Decimal128\n */\n\n\n\nmodule.exports = __webpack_require__(/*! bson */ \"./node_modules/bson/lib/bson.cjs\").Decimal128;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/types/decimal128.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/types/documentArray/index.js":
/*!****************************************************************!*\
  !*** ./node_modules/mongoose/lib/types/documentArray/index.js ***!
  \****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst ArrayMethods = __webpack_require__(/*! ../array/methods */ \"./node_modules/mongoose/lib/types/array/methods/index.js\");\nconst DocumentArrayMethods = __webpack_require__(/*! ./methods */ \"./node_modules/mongoose/lib/types/documentArray/methods/index.js\");\nconst Document = __webpack_require__(/*! ../../document */ \"./node_modules/mongoose/lib/document.js\");\n\nconst arrayAtomicsSymbol = (__webpack_require__(/*! ../../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").arrayAtomicsSymbol);\nconst arrayAtomicsBackupSymbol = (__webpack_require__(/*! ../../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").arrayAtomicsBackupSymbol);\nconst arrayParentSymbol = (__webpack_require__(/*! ../../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").arrayParentSymbol);\nconst arrayPathSymbol = (__webpack_require__(/*! ../../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").arrayPathSymbol);\nconst arraySchemaSymbol = (__webpack_require__(/*! ../../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").arraySchemaSymbol);\n\nconst _basePush = Array.prototype.push;\nconst numberRE = /^\\d+$/;\n/**\n * DocumentArray constructor\n *\n * @param {Array} values\n * @param {String} path the path to this array\n * @param {Document} doc parent document\n * @api private\n * @return {MongooseDocumentArray}\n * @inherits MongooseArray\n * @see https://bit.ly/f6CnZU\n */\n\nfunction MongooseDocumentArray(values, path, doc) {\n  const __array = [];\n\n  const internals = {\n    [arrayAtomicsSymbol]: {},\n    [arrayAtomicsBackupSymbol]: void 0,\n    [arrayPathSymbol]: path,\n    [arraySchemaSymbol]: void 0,\n    [arrayParentSymbol]: void 0\n  };\n\n  if (Array.isArray(values)) {\n    if (values[arrayPathSymbol] === path &&\n        values[arrayParentSymbol] === doc) {\n      internals[arrayAtomicsSymbol] = Object.assign({}, values[arrayAtomicsSymbol]);\n    }\n    values.forEach(v => {\n      _basePush.call(__array, v);\n    });\n  }\n  internals[arrayPathSymbol] = path;\n  internals.__array = __array;\n\n  // Because doc comes from the context of another function, doc === global\n  // can happen if there was a null somewhere up the chain (see #3020 && #3034)\n  // RB Jun 17, 2015 updated to check for presence of expected paths instead\n  // to make more proof against unusual node environments\n  if (doc && doc instanceof Document) {\n    internals[arrayParentSymbol] = doc;\n    internals[arraySchemaSymbol] = doc.$__schema.path(path);\n\n    // `schema.path()` doesn't drill into nested arrays properly yet, see\n    // gh-6398, gh-6602. This is a workaround because nested arrays are\n    // always plain non-document arrays, so once you get to a document array\n    // nesting is done. Matryoshka code.\n    while (internals[arraySchemaSymbol] != null &&\n        internals[arraySchemaSymbol].$isMongooseArray &&\n        !internals[arraySchemaSymbol].$isMongooseDocumentArray) {\n      internals[arraySchemaSymbol] = internals[arraySchemaSymbol].casterConstructor;\n    }\n  }\n\n  const proxy = new Proxy(__array, {\n    get: function(target, prop) {\n      if (prop === 'isMongooseArray' ||\n          prop === 'isMongooseArrayProxy' ||\n          prop === 'isMongooseDocumentArray' ||\n          prop === 'isMongooseDocumentArrayProxy') {\n        return true;\n      }\n      if (internals.hasOwnProperty(prop)) {\n        return internals[prop];\n      }\n      if (DocumentArrayMethods.hasOwnProperty(prop)) {\n        return DocumentArrayMethods[prop];\n      }\n      if (ArrayMethods.hasOwnProperty(prop)) {\n        return ArrayMethods[prop];\n      }\n\n      return __array[prop];\n    },\n    set: function(target, prop, value) {\n      if (typeof prop === 'string' && numberRE.test(prop)) {\n        DocumentArrayMethods.set.call(proxy, prop, value, false);\n      } else if (internals.hasOwnProperty(prop)) {\n        internals[prop] = value;\n      } else {\n        __array[prop] = value;\n      }\n\n      return true;\n    }\n  });\n\n  return proxy;\n}\n\n/*!\n * Module exports.\n */\n\nmodule.exports = MongooseDocumentArray;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/types/documentArray/index.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/types/documentArray/isMongooseDocumentArray.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/mongoose/lib/types/documentArray/isMongooseDocumentArray.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nexports.isMongooseDocumentArray = function(mongooseDocumentArray) {\n  return Array.isArray(mongooseDocumentArray) && mongooseDocumentArray.isMongooseDocumentArray;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/types/documentArray/isMongooseDocumentArray.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/types/documentArray/methods/index.js":
/*!************************************************************************!*\
  !*** ./node_modules/mongoose/lib/types/documentArray/methods/index.js ***!
  \************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst ArrayMethods = __webpack_require__(/*! ../../array/methods */ \"./node_modules/mongoose/lib/types/array/methods/index.js\");\nconst Document = __webpack_require__(/*! ../../../document */ \"./node_modules/mongoose/lib/document.js\");\nconst castObjectId = __webpack_require__(/*! ../../../cast/objectid */ \"./node_modules/mongoose/lib/cast/objectid.js\");\nconst getDiscriminatorByValue = __webpack_require__(/*! ../../../helpers/discriminator/getDiscriminatorByValue */ \"./node_modules/mongoose/lib/helpers/discriminator/getDiscriminatorByValue.js\");\nconst internalToObjectOptions = (__webpack_require__(/*! ../../../options */ \"./node_modules/mongoose/lib/options.js\").internalToObjectOptions);\nconst utils = __webpack_require__(/*! ../../../utils */ \"./node_modules/mongoose/lib/utils.js\");\nconst isBsonType = __webpack_require__(/*! ../../../helpers/isBsonType */ \"./node_modules/mongoose/lib/helpers/isBsonType.js\");\n\nconst arrayParentSymbol = (__webpack_require__(/*! ../../../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").arrayParentSymbol);\nconst arrayPathSymbol = (__webpack_require__(/*! ../../../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").arrayPathSymbol);\nconst arraySchemaSymbol = (__webpack_require__(/*! ../../../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").arraySchemaSymbol);\nconst documentArrayParent = (__webpack_require__(/*! ../../../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").documentArrayParent);\n\nconst _baseToString = Array.prototype.toString;\n\nconst methods = {\n  /*!\n   * ignore\n   */\n\n  toBSON() {\n    return this.toObject(internalToObjectOptions);\n  },\n\n  toString() {\n    return _baseToString.call(this.__array.map(subdoc => {\n      if (subdoc != null && subdoc.$__ != null) {\n        return subdoc.toString();\n      }\n      return subdoc;\n    }));\n  },\n\n  /*!\n   * ignore\n   */\n\n  getArrayParent() {\n    return this[arrayParentSymbol];\n  },\n\n  /**\n   * Overrides MongooseArray#cast\n   *\n   * @method _cast\n   * @api private\n   * @memberOf MongooseDocumentArray\n   */\n\n  _cast(value, index, options) {\n    if (this[arraySchemaSymbol] == null) {\n      return value;\n    }\n    let Constructor = this[arraySchemaSymbol].casterConstructor;\n    const isInstance = Constructor.$isMongooseDocumentArray ?\n      utils.isMongooseDocumentArray(value) :\n      value instanceof Constructor;\n    if (isInstance ||\n        // Hack re: #5001, see #5005\n        (value && value.constructor && value.constructor.baseCasterConstructor === Constructor)) {\n      if (!(value[documentArrayParent] && value.__parentArray)) {\n        // value may have been created using array.create()\n        value[documentArrayParent] = this[arrayParentSymbol];\n        value.__parentArray = this;\n      }\n      value.$setIndex(index);\n      return value;\n    }\n\n    if (value === undefined || value === null) {\n      return null;\n    }\n\n    // handle cast('string') or cast(ObjectId) etc.\n    // only objects are permitted so we can safely assume that\n    // non-objects are to be interpreted as _id\n    if (Buffer.isBuffer(value) ||\n        isBsonType(value, 'ObjectId') || !utils.isObject(value)) {\n      value = { _id: value };\n    }\n\n    if (value &&\n        Constructor.discriminators &&\n        Constructor.schema &&\n        Constructor.schema.options &&\n        Constructor.schema.options.discriminatorKey) {\n      if (typeof value[Constructor.schema.options.discriminatorKey] === 'string' &&\n          Constructor.discriminators[value[Constructor.schema.options.discriminatorKey]]) {\n        Constructor = Constructor.discriminators[value[Constructor.schema.options.discriminatorKey]];\n      } else {\n        const constructorByValue = getDiscriminatorByValue(Constructor.discriminators, value[Constructor.schema.options.discriminatorKey]);\n        if (constructorByValue) {\n          Constructor = constructorByValue;\n        }\n      }\n    }\n\n    if (Constructor.$isMongooseDocumentArray) {\n      return Constructor.cast(value, this, undefined, undefined, index);\n    }\n    const ret = new Constructor(value, this, options, undefined, index);\n    ret.isNew = true;\n    return ret;\n  },\n\n  /**\n   * Searches array items for the first document with a matching _id.\n   *\n   * #### Example:\n   *\n   *     const embeddedDoc = m.array.id(some_id);\n   *\n   * @return {EmbeddedDocument|null} the subdocument or null if not found.\n   * @param {ObjectId|String|Number|Buffer} id\n   * @TODO cast to the _id based on schema for proper comparison\n   * @method id\n   * @api public\n   * @memberOf MongooseDocumentArray\n   */\n\n  id(id) {\n    let casted;\n    let sid;\n    let _id;\n\n    try {\n      casted = castObjectId(id).toString();\n    } catch (e) {\n      casted = null;\n    }\n\n    for (const val of this) {\n      if (!val) {\n        continue;\n      }\n\n      _id = val.get('_id');\n\n      if (_id === null || typeof _id === 'undefined') {\n        continue;\n      } else if (_id instanceof Document) {\n        sid || (sid = String(id));\n        if (sid == _id._id) {\n          return val;\n        }\n      } else if (!isBsonType(id, 'ObjectId') && !isBsonType(_id, 'ObjectId')) {\n        if (id == _id || utils.deepEqual(id, _id)) {\n          return val;\n        }\n      } else if (casted == _id) {\n        return val;\n      }\n    }\n\n    return null;\n  },\n\n  /**\n   * Returns a native js Array of plain js objects\n   *\n   * #### Note:\n   *\n   * _Each sub-document is converted to a plain object by calling its `#toObject` method._\n   *\n   * @param {Object} [options] optional options to pass to each documents `toObject` method call during conversion\n   * @return {Array}\n   * @method toObject\n   * @api public\n   * @memberOf MongooseDocumentArray\n   */\n\n  toObject(options) {\n    // `[].concat` coerces the return value into a vanilla JS array, rather\n    // than a Mongoose array.\n    return [].concat(this.map(function(doc) {\n      if (doc == null) {\n        return null;\n      }\n      if (typeof doc.toObject !== 'function') {\n        return doc;\n      }\n      return doc.toObject(options);\n    }));\n  },\n\n  $toObject() {\n    return this.constructor.prototype.toObject.apply(this, arguments);\n  },\n\n  /**\n   * Wraps [`Array#push`](https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/Array/push) with proper change tracking.\n   *\n   * @param {...Object} [args]\n   * @api public\n   * @method push\n   * @memberOf MongooseDocumentArray\n   */\n\n  push() {\n    const ret = ArrayMethods.push.apply(this, arguments);\n\n    _updateParentPopulated(this);\n\n    return ret;\n  },\n\n  /**\n   * Pulls items from the array atomically.\n   *\n   * @param {...Object} [args]\n   * @api public\n   * @method pull\n   * @memberOf MongooseDocumentArray\n   */\n\n  pull() {\n    const ret = ArrayMethods.pull.apply(this, arguments);\n\n    _updateParentPopulated(this);\n\n    return ret;\n  },\n\n  /**\n   * Wraps [`Array#shift`](https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/Array/unshift) with proper change tracking.\n   * @api private\n   */\n\n  shift() {\n    const ret = ArrayMethods.shift.apply(this, arguments);\n\n    _updateParentPopulated(this);\n\n    return ret;\n  },\n\n  /**\n   * Wraps [`Array#splice`](https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/Array/splice) with proper change tracking and casting.\n   * @api private\n   */\n\n  splice() {\n    const ret = ArrayMethods.splice.apply(this, arguments);\n\n    _updateParentPopulated(this);\n\n    return ret;\n  },\n\n  /**\n   * Helper for console.log\n   *\n   * @method inspect\n   * @api public\n   * @memberOf MongooseDocumentArray\n   */\n\n  inspect() {\n    return this.toObject();\n  },\n\n  /**\n   * Creates a subdocument casted to this schema.\n   *\n   * This is the same subdocument constructor used for casting.\n   *\n   * @param {Object} obj the value to cast to this arrays SubDocument schema\n   * @method create\n   * @api public\n   * @memberOf MongooseDocumentArray\n   */\n\n  create(obj) {\n    let Constructor = this[arraySchemaSymbol].casterConstructor;\n    if (obj &&\n        Constructor.discriminators &&\n        Constructor.schema &&\n        Constructor.schema.options &&\n        Constructor.schema.options.discriminatorKey) {\n      if (typeof obj[Constructor.schema.options.discriminatorKey] === 'string' &&\n          Constructor.discriminators[obj[Constructor.schema.options.discriminatorKey]]) {\n        Constructor = Constructor.discriminators[obj[Constructor.schema.options.discriminatorKey]];\n      } else {\n        const constructorByValue = getDiscriminatorByValue(Constructor.discriminators, obj[Constructor.schema.options.discriminatorKey]);\n        if (constructorByValue) {\n          Constructor = constructorByValue;\n        }\n      }\n    }\n\n    return new Constructor(obj, this);\n  },\n\n  /*!\n   * ignore\n   */\n\n  notify(event) {\n    const _this = this;\n    return function notify(val, _arr) {\n      _arr = _arr || _this;\n      let i = _arr.length;\n      while (i--) {\n        if (_arr[i] == null) {\n          continue;\n        }\n        switch (event) {\n          // only swap for save event for now, we may change this to all event types later\n          case 'save':\n            val = _this[i];\n            break;\n          default:\n            // NO-OP\n            break;\n        }\n\n        if (utils.isMongooseArray(_arr[i])) {\n          notify(val, _arr[i]);\n        } else if (_arr[i]) {\n          _arr[i].emit(event, val);\n        }\n      }\n    };\n  },\n\n  set(i, val, skipModified) {\n    const arr = this.__array;\n    if (skipModified) {\n      arr[i] = val;\n      return this;\n    }\n    const value = methods._cast.call(this, val, i);\n    methods._markModified.call(this, i);\n    arr[i] = value;\n    return this;\n  },\n\n  _markModified(elem, embeddedPath) {\n    const parent = this[arrayParentSymbol];\n    let dirtyPath;\n\n    if (parent) {\n      dirtyPath = this[arrayPathSymbol];\n\n      if (arguments.length) {\n        if (embeddedPath != null) {\n          // an embedded doc bubbled up the change\n          const index = elem.__index;\n          dirtyPath = dirtyPath + '.' + index + '.' + embeddedPath;\n        } else {\n          // directly set an index\n          dirtyPath = dirtyPath + '.' + elem;\n        }\n      }\n\n      if (dirtyPath != null && dirtyPath.endsWith('.$')) {\n        return this;\n      }\n\n      parent.markModified(dirtyPath, arguments.length !== 0 ? elem : parent);\n    }\n\n    return this;\n  }\n};\n\nmodule.exports = methods;\n\n/**\n * If this is a document array, each element may contain single\n * populated paths, so we need to modify the top-level document's\n * populated cache. See gh-8247, gh-8265.\n * @param {Array} arr\n * @api private\n */\n\nfunction _updateParentPopulated(arr) {\n  const parent = arr[arrayParentSymbol];\n  if (!parent || parent.$__.populated == null) return;\n\n  const populatedPaths = Object.keys(parent.$__.populated).\n    filter(p => p.startsWith(arr[arrayPathSymbol] + '.'));\n\n  for (const path of populatedPaths) {\n    const remnant = path.slice((arr[arrayPathSymbol] + '.').length);\n    if (!Array.isArray(parent.$__.populated[path].value)) {\n      continue;\n    }\n\n    parent.$__.populated[path].value = arr.map(val => val.$populated(remnant));\n  }\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/types/documentArray/methods/index.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/types/index.js":
/*!**************************************************!*\
  !*** ./node_modules/mongoose/lib/types/index.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n/*!\n * Module exports.\n */\n\n\n\nexports.Array = __webpack_require__(/*! ./array */ \"./node_modules/mongoose/lib/types/array/index.js\");\nexports.Buffer = __webpack_require__(/*! ./buffer */ \"./node_modules/mongoose/lib/types/buffer.js\");\n\nexports.Document = // @deprecate\nexports.Embedded = __webpack_require__(/*! ./arraySubdocument */ \"./node_modules/mongoose/lib/types/arraySubdocument.js\");\n\nexports.DocumentArray = __webpack_require__(/*! ./documentArray */ \"./node_modules/mongoose/lib/types/documentArray/index.js\");\nexports.Decimal128 = __webpack_require__(/*! ./decimal128 */ \"./node_modules/mongoose/lib/types/decimal128.js\");\nexports.ObjectId = __webpack_require__(/*! ./objectid */ \"./node_modules/mongoose/lib/types/objectid.js\");\n\nexports.Map = __webpack_require__(/*! ./map */ \"./node_modules/mongoose/lib/types/map.js\");\n\nexports.Subdocument = __webpack_require__(/*! ./subdocument */ \"./node_modules/mongoose/lib/types/subdocument.js\");\n\nexports.UUID = __webpack_require__(/*! ./uuid */ \"./node_modules/mongoose/lib/types/uuid.js\");\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/types/index.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/types/map.js":
/*!************************************************!*\
  !*** ./node_modules/mongoose/lib/types/map.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst Mixed = __webpack_require__(/*! ../schema/mixed */ \"./node_modules/mongoose/lib/schema/mixed.js\");\nconst MongooseError = __webpack_require__(/*! ../error/mongooseError */ \"./node_modules/mongoose/lib/error/mongooseError.js\");\nconst clone = __webpack_require__(/*! ../helpers/clone */ \"./node_modules/mongoose/lib/helpers/clone.js\");\nconst deepEqual = (__webpack_require__(/*! ../utils */ \"./node_modules/mongoose/lib/utils.js\").deepEqual);\nconst getConstructorName = __webpack_require__(/*! ../helpers/getConstructorName */ \"./node_modules/mongoose/lib/helpers/getConstructorName.js\");\nconst handleSpreadDoc = __webpack_require__(/*! ../helpers/document/handleSpreadDoc */ \"./node_modules/mongoose/lib/helpers/document/handleSpreadDoc.js\");\nconst util = __webpack_require__(/*! util */ \"util\");\nconst specialProperties = __webpack_require__(/*! ../helpers/specialProperties */ \"./node_modules/mongoose/lib/helpers/specialProperties.js\");\nconst isBsonType = __webpack_require__(/*! ../helpers/isBsonType */ \"./node_modules/mongoose/lib/helpers/isBsonType.js\");\n\nconst populateModelSymbol = (__webpack_require__(/*! ../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").populateModelSymbol);\n\n/*!\n * ignore\n */\n\nclass MongooseMap extends Map {\n  constructor(v, path, doc, schemaType) {\n    if (getConstructorName(v) === 'Object') {\n      v = Object.keys(v).reduce((arr, key) => arr.concat([[key, v[key]]]), []);\n    }\n    super(v);\n    this.$__parent = doc != null && doc.$__ != null ? doc : null;\n    this.$__path = path;\n    this.$__schemaType = schemaType == null ? new Mixed(path) : schemaType;\n\n    this.$__runDeferred();\n  }\n\n  $init(key, value) {\n    checkValidKey(key);\n\n    super.set(key, value);\n\n    if (value != null && value.$isSingleNested) {\n      value.$basePath = this.$__path + '.' + key;\n    }\n  }\n\n  $__set(key, value) {\n    super.set(key, value);\n  }\n\n  /**\n   * Overwrites native Map's `get()` function to support Mongoose getters.\n   *\n   * @api public\n   * @method get\n   * @memberOf Map\n   */\n\n  get(key, options) {\n    if (isBsonType(key, 'ObjectId')) {\n      key = key.toString();\n    }\n\n    options = options || {};\n    if (options.getters === false) {\n      return super.get(key);\n    }\n    return this.$__schemaType.applyGetters(super.get(key), this.$__parent);\n  }\n\n  /**\n   * Overwrites native Map's `set()` function to support setters, `populate()`,\n   * and change tracking. Note that Mongoose maps _only_ support strings and\n   * ObjectIds as keys.\n   *\n   * Keys also cannot:\n   * - be named after special properties `prototype`, `constructor`, and `__proto__`\n   * - start with a dollar sign (`$`)\n   * - contain any dots (`.`)\n   *\n   * #### Example:\n   *\n   *     doc.myMap.set('test', 42); // works\n   *     doc.myMap.set({ obj: 42 }, 42); // Throws \"Mongoose maps only support string keys\"\n   *     doc.myMap.set(10, 42); // Throws \"Mongoose maps only support string keys\"\n   *     doc.myMap.set(\"$test\", 42); // Throws \"Mongoose maps do not support keys that start with \"$\", got \"$test\"\"\n   *\n   * @api public\n   * @method set\n   * @memberOf Map\n   */\n\n  set(key, value) {\n    if (isBsonType(key, 'ObjectId')) {\n      key = key.toString();\n    }\n\n    checkValidKey(key);\n    value = handleSpreadDoc(value);\n\n    // Weird, but because you can't assign to `this` before calling `super()`\n    // you can't get access to `$__schemaType` to cast in the initial call to\n    // `set()` from the `super()` constructor.\n\n    if (this.$__schemaType == null) {\n      this.$__deferred = this.$__deferred || [];\n      this.$__deferred.push({ key: key, value: value });\n      return;\n    }\n\n    let _fullPath;\n    const parent = this.$__parent;\n    const populated = parent != null && parent.$__ && parent.$__.populated ?\n      parent.$populated(fullPath.call(this), true) || parent.$populated(this.$__path, true) :\n      null;\n    const priorVal = this.get(key);\n\n    if (populated != null) {\n      if (this.$__schemaType.$isSingleNested) {\n        throw new MongooseError(\n          'Cannot manually populate single nested subdoc underneath Map ' +\n          `at path \"${this.$__path}\". Try using an array instead of a Map.`\n        );\n      }\n      if (Array.isArray(value) && this.$__schemaType.$isMongooseArray) {\n        value = value.map(v => {\n          if (v.$__ == null) {\n            v = new populated.options[populateModelSymbol](v);\n          }\n          // Doesn't support single nested \"in-place\" populate\n          v.$__.wasPopulated = { value: v._doc._id };\n          return v;\n        });\n      } else if (value != null) {\n        if (value.$__ == null) {\n          value = new populated.options[populateModelSymbol](value);\n        }\n        // Doesn't support single nested \"in-place\" populate\n        value.$__.wasPopulated = { value: value._doc._id };\n      }\n    } else {\n      try {\n        const options = this.$__schemaType.$isMongooseDocumentArray || this.$__schemaType.$isSingleNested ?\n          { path: fullPath.call(this) } :\n          null;\n        value = this.$__schemaType.applySetters(\n          value,\n          this.$__parent,\n          false,\n          this.get(key),\n          options\n        );\n      } catch (error) {\n        if (this.$__parent != null && this.$__parent.$__ != null) {\n          this.$__parent.invalidate(fullPath.call(this), error);\n          return;\n        }\n        throw error;\n      }\n    }\n\n    super.set(key, value);\n\n    if (parent != null && parent.$__ != null && !deepEqual(value, priorVal)) {\n      parent.markModified(fullPath.call(this));\n    }\n\n    // Delay calculating full path unless absolutely necessary, because string\n    // concatenation is a bottleneck re: #13171\n    function fullPath() {\n      if (_fullPath) {\n        return _fullPath;\n      }\n      _fullPath = this.$__path + '.' + key;\n      return _fullPath;\n    }\n  }\n\n  /**\n   * Overwrites native Map's `clear()` function to support change tracking.\n   *\n   * @api public\n   * @method clear\n   * @memberOf Map\n   */\n\n  clear() {\n    super.clear();\n    const parent = this.$__parent;\n    if (parent != null) {\n      parent.markModified(this.$__path);\n    }\n  }\n\n  /**\n   * Overwrites native Map's `delete()` function to support change tracking.\n   *\n   * @api public\n   * @method delete\n   * @memberOf Map\n   */\n\n  delete(key) {\n    if (isBsonType(key, 'ObjectId')) {\n      key = key.toString();\n    }\n\n    this.set(key, undefined);\n    return super.delete(key);\n  }\n\n  /**\n   * Converts this map to a native JavaScript Map so the MongoDB driver can serialize it.\n   *\n   * @api public\n   * @method toBSON\n   * @memberOf Map\n   */\n\n  toBSON() {\n    return new Map(this);\n  }\n\n  toObject(options) {\n    if (options && options.flattenMaps) {\n      const ret = {};\n      const keys = this.keys();\n      for (const key of keys) {\n        ret[key] = clone(this.get(key), options);\n      }\n      return ret;\n    }\n\n    return new Map(this);\n  }\n\n  $toObject() {\n    return this.constructor.prototype.toObject.apply(this, arguments);\n  }\n\n  /**\n   * Converts this map to a native JavaScript Map for `JSON.stringify()`. Set\n   * the `flattenMaps` option to convert this map to a POJO instead.\n   *\n   * #### Example:\n   *\n   *     doc.myMap.toJSON() instanceof Map; // true\n   *     doc.myMap.toJSON({ flattenMaps: true }) instanceof Map; // false\n   *\n   * @api public\n   * @method toJSON\n   * @param {Object} [options]\n   * @param {Boolean} [options.flattenMaps=false] set to `true` to convert the map to a POJO rather than a native JavaScript map\n   * @memberOf Map\n   */\n\n  toJSON(options) {\n    if (typeof (options && options.flattenMaps) === 'boolean' ? options.flattenMaps : true) {\n      const ret = {};\n      const keys = this.keys();\n      for (const key of keys) {\n        ret[key] = clone(this.get(key), options);\n      }\n      return ret;\n    }\n\n    return new Map(this);\n  }\n\n  inspect() {\n    return new Map(this);\n  }\n\n  $__runDeferred() {\n    if (!this.$__deferred) {\n      return;\n    }\n\n    for (const keyValueObject of this.$__deferred) {\n      this.set(keyValueObject.key, keyValueObject.value);\n    }\n\n    this.$__deferred = null;\n  }\n}\n\nif (util.inspect.custom) {\n  Object.defineProperty(MongooseMap.prototype, util.inspect.custom, {\n    enumerable: false,\n    writable: false,\n    configurable: false,\n    value: MongooseMap.prototype.inspect\n  });\n}\n\nObject.defineProperty(MongooseMap.prototype, '$__set', {\n  enumerable: false,\n  writable: true,\n  configurable: false\n});\n\nObject.defineProperty(MongooseMap.prototype, '$__parent', {\n  enumerable: false,\n  writable: true,\n  configurable: false\n});\n\nObject.defineProperty(MongooseMap.prototype, '$__path', {\n  enumerable: false,\n  writable: true,\n  configurable: false\n});\n\nObject.defineProperty(MongooseMap.prototype, '$__schemaType', {\n  enumerable: false,\n  writable: true,\n  configurable: false\n});\n\n/**\n * Set to `true` for all Mongoose map instances\n *\n * @api public\n * @property $isMongooseMap\n * @memberOf MongooseMap\n * @instance\n */\n\nObject.defineProperty(MongooseMap.prototype, '$isMongooseMap', {\n  enumerable: false,\n  writable: false,\n  configurable: false,\n  value: true\n});\n\nObject.defineProperty(MongooseMap.prototype, '$__deferredCalls', {\n  enumerable: false,\n  writable: false,\n  configurable: false,\n  value: true\n});\n\n/**\n * Since maps are stored as objects under the hood, keys must be strings\n * and can't contain any invalid characters\n * @param {String} key\n * @api private\n */\n\nfunction checkValidKey(key) {\n  const keyType = typeof key;\n  if (keyType !== 'string') {\n    throw new TypeError(`Mongoose maps only support string keys, got ${keyType}`);\n  }\n  if (key.startsWith('$')) {\n    throw new Error(`Mongoose maps do not support keys that start with \"$\", got \"${key}\"`);\n  }\n  if (key.includes('.')) {\n    throw new Error(`Mongoose maps do not support keys that contain \".\", got \"${key}\"`);\n  }\n  if (specialProperties.has(key)) {\n    throw new Error(`Mongoose maps do not support reserved key name \"${key}\"`);\n  }\n}\n\nmodule.exports = MongooseMap;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/types/map.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/types/objectid.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongoose/lib/types/objectid.js ***!
  \*****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/**\n * ObjectId type constructor\n *\n * #### Example:\n *\n *     const id = new mongoose.Types.ObjectId;\n *\n * @constructor ObjectId\n */\n\n\n\nconst ObjectId = (__webpack_require__(/*! bson */ \"./node_modules/bson/lib/bson.cjs\").ObjectId);\nconst objectIdSymbol = (__webpack_require__(/*! ../helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").objectIdSymbol);\n\n/**\n * Getter for convenience with populate, see gh-6115\n * @api private\n */\n\nObject.defineProperty(ObjectId.prototype, '_id', {\n  enumerable: false,\n  configurable: true,\n  get: function() {\n    return this;\n  }\n});\n\n/*!\n * Convenience `valueOf()` to allow comparing ObjectIds using double equals re: gh-7299\n */\n\nif (!ObjectId.prototype.hasOwnProperty('valueOf')) {\n  ObjectId.prototype.valueOf = function objectIdValueOf() {\n    return this.toString();\n  };\n}\n\nObjectId.prototype[objectIdSymbol] = true;\n\nmodule.exports = ObjectId;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/types/objectid.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/types/subdocument.js":
/*!********************************************************!*\
  !*** ./node_modules/mongoose/lib/types/subdocument.js ***!
  \********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst Document = __webpack_require__(/*! ../document */ \"./node_modules/mongoose/lib/document.js\");\nconst immediate = __webpack_require__(/*! ../helpers/immediate */ \"./node_modules/mongoose/lib/helpers/immediate.js\");\nconst internalToObjectOptions = (__webpack_require__(/*! ../options */ \"./node_modules/mongoose/lib/options.js\").internalToObjectOptions);\nconst util = __webpack_require__(/*! util */ \"util\");\nconst utils = __webpack_require__(/*! ../utils */ \"./node_modules/mongoose/lib/utils.js\");\n\nmodule.exports = Subdocument;\n\n/**\n * Subdocument constructor.\n *\n * @inherits Document\n * @api private\n */\n\nfunction Subdocument(value, fields, parent, skipId, options) {\n  if (typeof skipId === 'object' && skipId != null && options == null) {\n    options = skipId;\n    skipId = undefined;\n  }\n  if (parent != null) {\n    // If setting a nested path, should copy isNew from parent re: gh-7048\n    const parentOptions = { isNew: parent.isNew };\n    if ('defaults' in parent.$__) {\n      parentOptions.defaults = parent.$__.defaults;\n    }\n    options = Object.assign(parentOptions, options);\n  }\n  if (options != null && options.path != null) {\n    this.$basePath = options.path;\n  }\n  Document.call(this, value, fields, skipId, options);\n\n  delete this.$__.priorDoc;\n}\n\nSubdocument.prototype = Object.create(Document.prototype);\n\nObject.defineProperty(Subdocument.prototype, '$isSubdocument', {\n  configurable: false,\n  writable: false,\n  value: true\n});\n\nObject.defineProperty(Subdocument.prototype, '$isSingleNested', {\n  configurable: false,\n  writable: false,\n  value: true\n});\n\n/*!\n * ignore\n */\n\nSubdocument.prototype.toBSON = function() {\n  return this.toObject(internalToObjectOptions);\n};\n\n/**\n * Used as a stub for middleware\n *\n * #### Note:\n *\n * _This is a no-op. Does not actually save the doc to the db._\n *\n * @param {Function} [fn]\n * @return {Promise} resolved Promise\n * @api private\n */\n\nSubdocument.prototype.save = async function save(options) {\n  options = options || {};\n\n  if (!options.suppressWarning) {\n    utils.warn('mongoose: calling `save()` on a subdoc does **not** save ' +\n      'the document to MongoDB, it only runs save middleware. ' +\n      'Use `subdoc.save({ suppressWarning: true })` to hide this warning ' +\n      'if you\\'re sure this behavior is right for your app.');\n  }\n\n  return new Promise((resolve, reject) => {\n    this.$__save((err) => {\n      if (err != null) {\n        return reject(err);\n      }\n      resolve(this);\n    });\n  });\n};\n\n/**\n * Given a path relative to this document, return the path relative\n * to the top-level document.\n * @param {String} path\n * @method $__fullPath\n * @memberOf Subdocument\n * @instance\n * @returns {String}\n * @api private\n */\n\nSubdocument.prototype.$__fullPath = function(path) {\n  if (!this.$__.fullPath) {\n    this.ownerDocument();\n  }\n\n  return path ?\n    this.$__.fullPath + '.' + path :\n    this.$__.fullPath;\n};\n\n/**\n * Given a path relative to this document, return the path relative\n * to the parent document.\n * @param {String} p\n * @returns {String}\n * @method $__pathRelativeToParent\n * @memberOf Subdocument\n * @instance\n * @api private\n */\n\nSubdocument.prototype.$__pathRelativeToParent = function(p) {\n  if (p == null) {\n    return this.$basePath;\n  }\n  return [this.$basePath, p].join('.');\n};\n\n/**\n * Used as a stub for middleware\n *\n * #### Note:\n *\n * _This is a no-op. Does not actually save the doc to the db._\n *\n * @param {Function} [fn]\n * @method $__save\n * @api private\n */\n\nSubdocument.prototype.$__save = function(fn) {\n  return immediate(() => fn(null, this));\n};\n\n/*!\n * ignore\n */\n\nSubdocument.prototype.$isValid = function(path) {\n  const parent = this.$parent();\n  const fullPath = this.$__pathRelativeToParent(path);\n  if (parent != null && fullPath != null) {\n    return parent.$isValid(fullPath);\n  }\n  return Document.prototype.$isValid.call(this, path);\n};\n\n/*!\n * ignore\n */\n\nSubdocument.prototype.markModified = function(path) {\n  Document.prototype.markModified.call(this, path);\n  const parent = this.$parent();\n  const fullPath = this.$__pathRelativeToParent(path);\n\n  if (parent == null || fullPath == null) {\n    return;\n  }\n\n  const myPath = this.$__pathRelativeToParent().replace(/\\.$/, '');\n  if (parent.isDirectModified(myPath) || this.isNew) {\n    return;\n  }\n  this.$__parent.markModified(fullPath, this);\n};\n\n/*!\n * ignore\n */\n\nSubdocument.prototype.isModified = function(paths, options, modifiedPaths) {\n  const parent = this.$parent();\n  if (parent != null) {\n    if (Array.isArray(paths) || typeof paths === 'string') {\n      paths = (Array.isArray(paths) ? paths : paths.split(' '));\n      paths = paths.map(p => this.$__pathRelativeToParent(p)).filter(p => p != null);\n    } else if (!paths) {\n      paths = this.$__pathRelativeToParent();\n    }\n\n    return parent.$isModified(paths, options, modifiedPaths);\n  }\n\n  return Document.prototype.isModified.call(this, paths, options, modifiedPaths);\n};\n\n/**\n * Marks a path as valid, removing existing validation errors.\n *\n * @param {String} path the field to mark as valid\n * @api private\n * @method $markValid\n * @memberOf Subdocument\n */\n\nSubdocument.prototype.$markValid = function(path) {\n  Document.prototype.$markValid.call(this, path);\n  const parent = this.$parent();\n  const fullPath = this.$__pathRelativeToParent(path);\n  if (parent != null && fullPath != null) {\n    parent.$markValid(fullPath);\n  }\n};\n\n/*!\n * ignore\n */\n\nSubdocument.prototype.invalidate = function(path, err, val) {\n  Document.prototype.invalidate.call(this, path, err, val);\n\n  const parent = this.$parent();\n  const fullPath = this.$__pathRelativeToParent(path);\n  if (parent != null && fullPath != null) {\n    parent.invalidate(fullPath, err, val);\n  } else if (err.kind === 'cast' || err.name === 'CastError' || fullPath == null) {\n    throw err;\n  }\n\n  return this.ownerDocument().$__.validationError;\n};\n\n/*!\n * ignore\n */\n\nSubdocument.prototype.$ignore = function(path) {\n  Document.prototype.$ignore.call(this, path);\n  const parent = this.$parent();\n  const fullPath = this.$__pathRelativeToParent(path);\n  if (parent != null && fullPath != null) {\n    parent.$ignore(fullPath);\n  }\n};\n\n/**\n * Returns the top level document of this sub-document.\n *\n * @return {Document}\n */\n\nSubdocument.prototype.ownerDocument = function() {\n  if (this.$__.ownerDocument) {\n    return this.$__.ownerDocument;\n  }\n\n  let parent = this; // eslint-disable-line consistent-this\n  const paths = [];\n  const seenDocs = new Set([parent]);\n\n  while (true) {\n    if (typeof parent.$__pathRelativeToParent !== 'function') {\n      break;\n    }\n    paths.unshift(parent.$__pathRelativeToParent(void 0, true));\n    const _parent = parent.$parent();\n    if (_parent == null) {\n      break;\n    }\n    parent = _parent;\n    if (seenDocs.has(parent)) {\n      throw new Error('Infinite subdocument loop: subdoc with _id ' + parent._id + ' is a parent of itself');\n    }\n\n    seenDocs.add(parent);\n  }\n\n  this.$__.fullPath = paths.join('.');\n\n  this.$__.ownerDocument = parent;\n  return this.$__.ownerDocument;\n};\n\n/*!\n * ignore\n */\n\nSubdocument.prototype.$__fullPathWithIndexes = function() {\n  let parent = this; // eslint-disable-line consistent-this\n  const paths = [];\n  const seenDocs = new Set([parent]);\n\n  while (true) {\n    if (typeof parent.$__pathRelativeToParent !== 'function') {\n      break;\n    }\n    paths.unshift(parent.$__pathRelativeToParent(void 0, false));\n    const _parent = parent.$parent();\n    if (_parent == null) {\n      break;\n    }\n    parent = _parent;\n    if (seenDocs.has(parent)) {\n      throw new Error('Infinite subdocument loop: subdoc with _id ' + parent._id + ' is a parent of itself');\n    }\n\n    seenDocs.add(parent);\n  }\n\n  return paths.join('.');\n};\n\n/**\n * Returns this sub-documents parent document.\n *\n * @api public\n */\n\nSubdocument.prototype.parent = function() {\n  return this.$__parent;\n};\n\n/**\n * Returns this sub-documents parent document.\n *\n * @api public\n * @method $parent\n */\n\nSubdocument.prototype.$parent = Subdocument.prototype.parent;\n\n/**\n * no-op for hooks\n * @param {Function} cb\n * @method $__deleteOne\n * @memberOf Subdocument\n * @instance\n * @api private\n */\n\nSubdocument.prototype.$__deleteOne = function(cb) {\n  if (cb == null) {\n    return;\n  }\n  return cb(null, this);\n};\n\n/**\n * ignore\n * @method $__removeFromParent\n * @memberOf Subdocument\n * @instance\n * @api private\n */\n\nSubdocument.prototype.$__removeFromParent = function() {\n  this.$__parent.set(this.$basePath, null);\n};\n\n/**\n * Null-out this subdoc\n *\n * @param {Object} [options]\n * @param {Function} [callback] optional callback for compatibility with Document.prototype.remove\n */\n\nSubdocument.prototype.deleteOne = function(options, callback) {\n  if (typeof options === 'function') {\n    callback = options;\n    options = null;\n  }\n  registerRemoveListener(this);\n\n  // If removing entire doc, no need to remove subdoc\n  if (!options || !options.noop) {\n    this.$__removeFromParent();\n\n    const owner = this.ownerDocument();\n    owner.$__.removedSubdocs = owner.$__.removedSubdocs || [];\n    owner.$__.removedSubdocs.push(this);\n  }\n\n  return this.$__deleteOne(callback);\n};\n\n/*!\n * ignore\n */\n\nSubdocument.prototype.populate = function() {\n  throw new Error('Mongoose does not support calling populate() on nested ' +\n    'docs. Instead of `doc.nested.populate(\"path\")`, use ' +\n    '`doc.populate(\"nested.path\")`');\n};\n\n/**\n * Helper for console.log\n *\n * @api public\n */\n\nSubdocument.prototype.inspect = function() {\n  return this.toObject();\n};\n\nif (util.inspect.custom) {\n  // Avoid Node deprecation warning DEP0079\n  Subdocument.prototype[util.inspect.custom] = Subdocument.prototype.inspect;\n}\n\n/**\n * Registers remove event listeners for triggering\n * on subdocuments.\n *\n * @param {Subdocument} sub\n * @api private\n */\n\nfunction registerRemoveListener(sub) {\n  const owner = sub.ownerDocument();\n\n  function emitRemove() {\n    owner.$removeListener('save', emitRemove);\n    owner.$removeListener('deleteOne', emitRemove);\n    sub.emit('deleteOne', sub);\n    sub.constructor.emit('deleteOne', sub);\n  }\n\n  owner.$on('save', emitRemove);\n  owner.$on('deleteOne', emitRemove);\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/types/subdocument.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/types/uuid.js":
/*!*************************************************!*\
  !*** ./node_modules/mongoose/lib/types/uuid.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/**\n * UUID type constructor\n *\n * #### Example:\n *\n *     const id = new mongoose.Types.UUID();\n *\n * @constructor UUID\n */\n\n\n\nmodule.exports = __webpack_require__(/*! bson */ \"./node_modules/bson/lib/bson.cjs\").UUID;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/types/uuid.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/utils.js":
/*!********************************************!*\
  !*** ./node_modules/mongoose/lib/utils.js ***!
  \********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst UUID = (__webpack_require__(/*! bson */ \"./node_modules/bson/lib/bson.cjs\").UUID);\nconst ms = __webpack_require__(/*! ms */ \"./node_modules/mongoose/node_modules/ms/index.js\");\nconst mpath = __webpack_require__(/*! mpath */ \"./node_modules/mpath/index.js\");\nconst ObjectId = __webpack_require__(/*! ./types/objectid */ \"./node_modules/mongoose/lib/types/objectid.js\");\nconst PopulateOptions = __webpack_require__(/*! ./options/populateOptions */ \"./node_modules/mongoose/lib/options/populateOptions.js\");\nconst clone = __webpack_require__(/*! ./helpers/clone */ \"./node_modules/mongoose/lib/helpers/clone.js\");\nconst immediate = __webpack_require__(/*! ./helpers/immediate */ \"./node_modules/mongoose/lib/helpers/immediate.js\");\nconst isObject = __webpack_require__(/*! ./helpers/isObject */ \"./node_modules/mongoose/lib/helpers/isObject.js\");\nconst isMongooseArray = __webpack_require__(/*! ./types/array/isMongooseArray */ \"./node_modules/mongoose/lib/types/array/isMongooseArray.js\");\nconst isMongooseDocumentArray = __webpack_require__(/*! ./types/documentArray/isMongooseDocumentArray */ \"./node_modules/mongoose/lib/types/documentArray/isMongooseDocumentArray.js\");\nconst isBsonType = __webpack_require__(/*! ./helpers/isBsonType */ \"./node_modules/mongoose/lib/helpers/isBsonType.js\");\nconst isPOJO = __webpack_require__(/*! ./helpers/isPOJO */ \"./node_modules/mongoose/lib/helpers/isPOJO.js\");\nconst getFunctionName = __webpack_require__(/*! ./helpers/getFunctionName */ \"./node_modules/mongoose/lib/helpers/getFunctionName.js\");\nconst isMongooseObject = __webpack_require__(/*! ./helpers/isMongooseObject */ \"./node_modules/mongoose/lib/helpers/isMongooseObject.js\");\nconst promiseOrCallback = __webpack_require__(/*! ./helpers/promiseOrCallback */ \"./node_modules/mongoose/lib/helpers/promiseOrCallback.js\");\nconst schemaMerge = __webpack_require__(/*! ./helpers/schema/merge */ \"./node_modules/mongoose/lib/helpers/schema/merge.js\");\nconst specialProperties = __webpack_require__(/*! ./helpers/specialProperties */ \"./node_modules/mongoose/lib/helpers/specialProperties.js\");\nconst { trustedSymbol } = __webpack_require__(/*! ./helpers/query/trusted */ \"./node_modules/mongoose/lib/helpers/query/trusted.js\");\n\nlet Document;\n\nexports.specialProperties = specialProperties;\n\nexports.isMongooseArray = isMongooseArray.isMongooseArray;\nexports.isMongooseDocumentArray = isMongooseDocumentArray.isMongooseDocumentArray;\nexports.registerMongooseArray = isMongooseArray.registerMongooseArray;\nexports.registerMongooseDocumentArray = isMongooseDocumentArray.registerMongooseDocumentArray;\n\nconst oneSpaceRE = /\\s/;\nconst manySpaceRE = /\\s+/;\n\n/**\n * Produces a collection name from model `name`. By default, just returns\n * the model name\n *\n * @param {String} name a model name\n * @param {Function} pluralize function that pluralizes the collection name\n * @return {String} a collection name\n * @api private\n */\n\nexports.toCollectionName = function(name, pluralize) {\n  if (name === 'system.profile') {\n    return name;\n  }\n  if (name === 'system.indexes') {\n    return name;\n  }\n  if (typeof pluralize === 'function') {\n    return pluralize(name);\n  }\n  return name;\n};\n\n/**\n * Determines if `a` and `b` are deep equal.\n *\n * Modified from node/lib/assert.js\n *\n * @param {any} a a value to compare to `b`\n * @param {any} b a value to compare to `a`\n * @return {Boolean}\n * @api private\n */\n\nexports.deepEqual = function deepEqual(a, b) {\n  if (a === b) {\n    return true;\n  }\n\n  if (typeof a !== 'object' || typeof b !== 'object') {\n    return a === b;\n  }\n\n  if (a instanceof Date && b instanceof Date) {\n    return a.getTime() === b.getTime();\n  }\n\n  if ((isBsonType(a, 'ObjectId') && isBsonType(b, 'ObjectId')) ||\n      (isBsonType(a, 'Decimal128') && isBsonType(b, 'Decimal128'))) {\n    return a.toString() === b.toString();\n  }\n\n  if (a instanceof RegExp && b instanceof RegExp) {\n    return a.source === b.source &&\n        a.ignoreCase === b.ignoreCase &&\n        a.multiline === b.multiline &&\n        a.global === b.global &&\n        a.dotAll === b.dotAll &&\n        a.unicode === b.unicode &&\n        a.sticky === b.sticky &&\n        a.hasIndices === b.hasIndices;\n  }\n\n  if (a == null || b == null) {\n    return false;\n  }\n\n  if (a.prototype !== b.prototype) {\n    return false;\n  }\n\n  if (a instanceof Map || b instanceof Map) {\n    if (!(a instanceof Map) || !(b instanceof Map)) {\n      return false;\n    }\n    return deepEqual(Array.from(a.keys()), Array.from(b.keys())) &&\n      deepEqual(Array.from(a.values()), Array.from(b.values()));\n  }\n\n  // Handle MongooseNumbers\n  if (a instanceof Number && b instanceof Number) {\n    return a.valueOf() === b.valueOf();\n  }\n\n  if (Buffer.isBuffer(a)) {\n    return exports.buffer.areEqual(a, b);\n  }\n\n  if (Array.isArray(a) || Array.isArray(b)) {\n    if (!Array.isArray(a) || !Array.isArray(b)) {\n      return false;\n    }\n    const len = a.length;\n    if (len !== b.length) {\n      return false;\n    }\n    for (let i = 0; i < len; ++i) {\n      if (!deepEqual(a[i], b[i])) {\n        return false;\n      }\n    }\n    return true;\n  }\n\n  if (a.$__ != null) {\n    a = a._doc;\n  } else if (isMongooseObject(a)) {\n    a = a.toObject();\n  }\n\n  if (b.$__ != null) {\n    b = b._doc;\n  } else if (isMongooseObject(b)) {\n    b = b.toObject();\n  }\n\n  const ka = Object.keys(a);\n  const kb = Object.keys(b);\n  const kaLength = ka.length;\n\n  // having the same number of owned properties (keys incorporates\n  // hasOwnProperty)\n  if (kaLength !== kb.length) {\n    return false;\n  }\n\n  // ~~~cheap key test\n  for (let i = kaLength - 1; i >= 0; i--) {\n    if (ka[i] !== kb[i]) {\n      return false;\n    }\n  }\n\n  // equivalent values for every corresponding key, and\n  // ~~~possibly expensive deep test\n  for (const key of ka) {\n    if (!deepEqual(a[key], b[key])) {\n      return false;\n    }\n  }\n\n  return true;\n};\n\n/**\n * Get the last element of an array\n * @param {Array} arr\n */\n\nexports.last = function(arr) {\n  if (arr.length > 0) {\n    return arr[arr.length - 1];\n  }\n  return void 0;\n};\n\n/*!\n * ignore\n */\n\nexports.promiseOrCallback = promiseOrCallback;\n\n/*!\n * ignore\n */\n\nexports.cloneArrays = function cloneArrays(arr) {\n  if (!Array.isArray(arr)) {\n    return arr;\n  }\n\n  return arr.map(el => exports.cloneArrays(el));\n};\n\n/*!\n * ignore\n */\n\nexports.omit = function omit(obj, keys) {\n  if (keys == null) {\n    return Object.assign({}, obj);\n  }\n  if (!Array.isArray(keys)) {\n    keys = [keys];\n  }\n\n  const ret = Object.assign({}, obj);\n  for (const key of keys) {\n    delete ret[key];\n  }\n  return ret;\n};\n\n/**\n * Merges `from` into `to` without overwriting existing properties.\n *\n * @param {Object} to\n * @param {Object} from\n * @param {Object} [options]\n * @param {String} [path]\n * @api private\n */\n\nexports.merge = function merge(to, from, options, path) {\n  options = options || {};\n\n  const keys = Object.keys(from);\n  let i = 0;\n  const len = keys.length;\n  let key;\n\n  if (from[trustedSymbol]) {\n    to[trustedSymbol] = from[trustedSymbol];\n  }\n\n  path = path || '';\n  const omitNested = options.omitNested || {};\n\n  while (i < len) {\n    key = keys[i++];\n    if (options.omit && options.omit[key]) {\n      continue;\n    }\n    if (omitNested[path]) {\n      continue;\n    }\n    if (specialProperties.has(key)) {\n      continue;\n    }\n    if (to[key] == null) {\n      if (isPOJO(from[key])) {\n        to[key] = { ...from[key] };\n      } else if (Array.isArray(from[key])) {\n        to[key] = [...from[key]];\n      } else {\n        to[key] = from[key];\n      }\n    } else if (exports.isObject(from[key])) {\n      if (!exports.isObject(to[key])) {\n        to[key] = {};\n      }\n      if (from[key] != null) {\n        // Skip merging schemas if we're creating a discriminator schema and\n        // base schema has a given path as a single nested but discriminator schema\n        // has the path as a document array, or vice versa (gh-9534)\n        if (options.isDiscriminatorSchemaMerge &&\n            (from[key].$isSingleNested && to[key].$isMongooseDocumentArray) ||\n            (from[key].$isMongooseDocumentArray && to[key].$isSingleNested)) {\n          continue;\n        } else if (from[key].instanceOfSchema) {\n          if (to[key].instanceOfSchema) {\n            schemaMerge(to[key], from[key].clone(), options.isDiscriminatorSchemaMerge);\n          } else {\n            to[key] = from[key].clone();\n          }\n          continue;\n        } else if (isBsonType(from[key], 'ObjectId')) {\n          to[key] = new ObjectId(from[key]);\n          continue;\n        }\n      }\n      merge(to[key], from[key], options, path ? path + '.' + key : key);\n    } else if (options.overwrite) {\n      to[key] = from[key];\n    }\n  }\n};\n\n/**\n * Applies toObject recursively.\n *\n * @param {Document|Array|Object} obj\n * @return {Object}\n * @api private\n */\n\nexports.toObject = function toObject(obj) {\n  Document || (Document = __webpack_require__(/*! ./document */ \"./node_modules/mongoose/lib/document.js\"));\n  let ret;\n\n  if (obj == null) {\n    return obj;\n  }\n\n  if (obj instanceof Document) {\n    return obj.toObject();\n  }\n\n  if (Array.isArray(obj)) {\n    ret = [];\n\n    for (const doc of obj) {\n      ret.push(toObject(doc));\n    }\n\n    return ret;\n  }\n\n  if (exports.isPOJO(obj)) {\n    ret = {};\n\n    if (obj[trustedSymbol]) {\n      ret[trustedSymbol] = obj[trustedSymbol];\n    }\n\n    for (const k of Object.keys(obj)) {\n      if (specialProperties.has(k)) {\n        continue;\n      }\n      ret[k] = toObject(obj[k]);\n    }\n\n    return ret;\n  }\n\n  return obj;\n};\n\nexports.isObject = isObject;\n\n/**\n * Determines if `arg` is a plain old JavaScript object (POJO). Specifically,\n * `arg` must be an object but not an instance of any special class, like String,\n * ObjectId, etc.\n *\n * `Object.getPrototypeOf()` is part of ES5: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/getPrototypeOf\n *\n * @param {Object|Array|String|Function|RegExp|any} arg\n * @api private\n * @return {Boolean}\n */\n\nexports.isPOJO = __webpack_require__(/*! ./helpers/isPOJO */ \"./node_modules/mongoose/lib/helpers/isPOJO.js\");\n\n/**\n * Determines if `arg` is an object that isn't an instance of a built-in value\n * class, like Array, Buffer, ObjectId, etc.\n * @param {Any} val\n */\n\nexports.isNonBuiltinObject = function isNonBuiltinObject(val) {\n  return typeof val === 'object' &&\n    !exports.isNativeObject(val) &&\n    !exports.isMongooseType(val) &&\n    !(val instanceof UUID) &&\n    val != null;\n};\n\n/**\n * Determines if `obj` is a built-in object like an array, date, boolean,\n * etc.\n * @param {Any} arg\n */\n\nexports.isNativeObject = function(arg) {\n  return Array.isArray(arg) ||\n    arg instanceof Date ||\n    arg instanceof Boolean ||\n    arg instanceof Number ||\n    arg instanceof String;\n};\n\n/**\n * Determines if `val` is an object that has no own keys\n * @param {Any} val\n */\n\nexports.isEmptyObject = function(val) {\n  return val != null &&\n    typeof val === 'object' &&\n    Object.keys(val).length === 0;\n};\n\n/**\n * Search if `obj` or any POJOs nested underneath `obj` has a property named\n * `key`\n * @param {Object} obj\n * @param {String} key\n */\n\nexports.hasKey = function hasKey(obj, key) {\n  const props = Object.keys(obj);\n  for (const prop of props) {\n    if (prop === key) {\n      return true;\n    }\n    if (exports.isPOJO(obj[prop]) && exports.hasKey(obj[prop], key)) {\n      return true;\n    }\n  }\n  return false;\n};\n\n/**\n * process.nextTick helper.\n *\n * Wraps `callback` in a try/catch + nextTick.\n *\n * node-mongodb-native has a habit of state corruption when an error is immediately thrown from within a collection callback.\n *\n * @param {Function} callback\n * @api private\n */\n\nexports.tick = function tick(callback) {\n  if (typeof callback !== 'function') {\n    return;\n  }\n  return function() {\n    try {\n      callback.apply(this, arguments);\n    } catch (err) {\n      // only nextTick on err to get out of\n      // the event loop and avoid state corruption.\n      immediate(function() {\n        throw err;\n      });\n    }\n  };\n};\n\n/**\n * Returns true if `v` is an object that can be serialized as a primitive in\n * MongoDB\n * @param {Any} v\n */\n\nexports.isMongooseType = function(v) {\n  return isBsonType(v, 'ObjectId') || isBsonType(v, 'Decimal128') || v instanceof Buffer;\n};\n\nexports.isMongooseObject = isMongooseObject;\n\n/**\n * Converts `expires` options of index objects to `expiresAfterSeconds` options for MongoDB.\n *\n * @param {Object} object\n * @api private\n */\n\nexports.expires = function expires(object) {\n  if (!(object && object.constructor.name === 'Object')) {\n    return;\n  }\n  if (!('expires' in object)) {\n    return;\n  }\n\n  object.expireAfterSeconds = (typeof object.expires !== 'string')\n    ? object.expires\n    : Math.round(ms(object.expires) / 1000);\n  delete object.expires;\n};\n\n/**\n * populate helper\n * @param {String} path\n * @param {String} select\n * @param {Model} model\n * @param {Object} match\n * @param {Object} options\n * @param {Any} subPopulate\n * @param {Boolean} justOne\n * @param {Boolean} count\n */\n\nexports.populate = function populate(path, select, model, match, options, subPopulate, justOne, count) {\n  // might have passed an object specifying all arguments\n  let obj = null;\n  if (arguments.length === 1) {\n    if (path instanceof PopulateOptions) {\n      // If reusing old populate docs, avoid reusing `_docs` because that may\n      // lead to bugs and memory leaks. See gh-11641\n      path._docs = {};\n      path._childDocs = [];\n      return [path];\n    }\n\n    if (Array.isArray(path)) {\n      const singles = makeSingles(path);\n      return singles.map(o => exports.populate(o)[0]);\n    }\n\n    if (exports.isObject(path)) {\n      obj = Object.assign({}, path);\n    } else {\n      obj = { path: path };\n    }\n  } else if (typeof model === 'object') {\n    obj = {\n      path: path,\n      select: select,\n      match: model,\n      options: match\n    };\n  } else {\n    obj = {\n      path: path,\n      select: select,\n      model: model,\n      match: match,\n      options: options,\n      populate: subPopulate,\n      justOne: justOne,\n      count: count\n    };\n  }\n\n  if (typeof obj.path !== 'string') {\n    throw new TypeError('utils.populate: invalid path. Expected string. Got typeof `' + typeof path + '`');\n  }\n\n  return _populateObj(obj);\n\n  // The order of select/conditions args is opposite Model.find but\n  // necessary to keep backward compatibility (select could be\n  // an array, string, or object literal).\n  function makeSingles(arr) {\n    const ret = [];\n    arr.forEach(function(obj) {\n      if (oneSpaceRE.test(obj.path)) {\n        const paths = obj.path.split(manySpaceRE);\n        paths.forEach(function(p) {\n          const copy = Object.assign({}, obj);\n          copy.path = p;\n          ret.push(copy);\n        });\n      } else {\n        ret.push(obj);\n      }\n    });\n\n    return ret;\n  }\n};\n\nfunction _populateObj(obj) {\n  if (Array.isArray(obj.populate)) {\n    const ret = [];\n    obj.populate.forEach(function(obj) {\n      if (oneSpaceRE.test(obj.path)) {\n        const copy = Object.assign({}, obj);\n        const paths = copy.path.split(manySpaceRE);\n        paths.forEach(function(p) {\n          copy.path = p;\n          ret.push(exports.populate(copy)[0]);\n        });\n      } else {\n        ret.push(exports.populate(obj)[0]);\n      }\n    });\n    obj.populate = exports.populate(ret);\n  } else if (obj.populate != null && typeof obj.populate === 'object') {\n    obj.populate = exports.populate(obj.populate);\n  }\n\n  const ret = [];\n  const paths = oneSpaceRE.test(obj.path) ? obj.path.split(manySpaceRE) : [obj.path];\n  if (obj.options != null) {\n    obj.options = clone(obj.options);\n  }\n\n  for (const path of paths) {\n    ret.push(new PopulateOptions(Object.assign({}, obj, { path: path })));\n  }\n\n  return ret;\n}\n\n/**\n * Return the value of `obj` at the given `path`.\n *\n * @param {String} path\n * @param {Object} obj\n * @param {Any} map\n */\n\nexports.getValue = function(path, obj, map) {\n  return mpath.get(path, obj, getValueLookup, map);\n};\n\n/*!\n * ignore\n */\n\nconst mapGetterOptions = Object.freeze({ getters: false });\n\nfunction getValueLookup(obj, part) {\n  let _from = obj?._doc || obj;\n  if (_from != null && _from.isMongooseArrayProxy) {\n    _from = _from.__array;\n  }\n  return _from instanceof Map ?\n    _from.get(part, mapGetterOptions) :\n    _from[part];\n}\n\n/**\n * Sets the value of `obj` at the given `path`.\n *\n * @param {String} path\n * @param {Anything} val\n * @param {Object} obj\n * @param {Any} map\n * @param {Any} _copying\n */\n\nexports.setValue = function(path, val, obj, map, _copying) {\n  mpath.set(path, val, obj, '_doc', map, _copying);\n};\n\n/**\n * Returns an array of values from object `o`.\n *\n * @param {Object} o\n * @return {Array}\n * @api private\n */\n\nexports.object = {};\nexports.object.vals = function vals(o) {\n  const keys = Object.keys(o);\n  let i = keys.length;\n  const ret = [];\n\n  while (i--) {\n    ret.push(o[keys[i]]);\n  }\n\n  return ret;\n};\n\nconst hop = Object.prototype.hasOwnProperty;\n\n/**\n * Safer helper for hasOwnProperty checks\n *\n * @param {Object} obj\n * @param {String} prop\n */\n\nexports.object.hasOwnProperty = function(obj, prop) {\n  return hop.call(obj, prop);\n};\n\n/**\n * Determine if `val` is null or undefined\n *\n * @param {Any} val\n * @return {Boolean}\n */\n\nexports.isNullOrUndefined = function(val) {\n  return val === null || val === undefined;\n};\n\n/*!\n * ignore\n */\n\nexports.array = {};\n\n/**\n * Flattens an array.\n *\n * [ 1, [ 2, 3, [4] ]] -> [1,2,3,4]\n *\n * @param {Array} arr\n * @param {Function} [filter] If passed, will be invoked with each item in the array. If `filter` returns a falsy value, the item will not be included in the results.\n * @param {Array} ret\n * @return {Array}\n * @api private\n */\n\nexports.array.flatten = function flatten(arr, filter, ret) {\n  ret || (ret = []);\n\n  arr.forEach(function(item) {\n    if (Array.isArray(item)) {\n      flatten(item, filter, ret);\n    } else {\n      if (!filter || filter(item)) {\n        ret.push(item);\n      }\n    }\n  });\n\n  return ret;\n};\n\n/*!\n * ignore\n */\n\nconst _hasOwnProperty = Object.prototype.hasOwnProperty;\n\nexports.hasUserDefinedProperty = function(obj, key) {\n  if (obj == null) {\n    return false;\n  }\n\n  if (Array.isArray(key)) {\n    for (const k of key) {\n      if (exports.hasUserDefinedProperty(obj, k)) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  if (_hasOwnProperty.call(obj, key)) {\n    return true;\n  }\n  if (typeof obj === 'object' && key in obj) {\n    const v = obj[key];\n    return v !== Object.prototype[key] && v !== Array.prototype[key];\n  }\n\n  return false;\n};\n\n/*!\n * ignore\n */\n\nconst MAX_ARRAY_INDEX = Math.pow(2, 32) - 1;\n\nexports.isArrayIndex = function(val) {\n  if (typeof val === 'number') {\n    return val >= 0 && val <= MAX_ARRAY_INDEX;\n  }\n  if (typeof val === 'string') {\n    if (!/^\\d+$/.test(val)) {\n      return false;\n    }\n    val = +val;\n    return val >= 0 && val <= MAX_ARRAY_INDEX;\n  }\n\n  return false;\n};\n\n/**\n * Removes duplicate values from an array\n *\n * [1, 2, 3, 3, 5] => [1, 2, 3, 5]\n * [ ObjectId(\"550988ba0c19d57f697dc45e\"), ObjectId(\"550988ba0c19d57f697dc45e\") ]\n *    => [ObjectId(\"550988ba0c19d57f697dc45e\")]\n *\n * @param {Array} arr\n * @return {Array}\n * @api private\n */\n\nexports.array.unique = function(arr) {\n  const primitives = new Set();\n  const ids = new Set();\n  const ret = [];\n\n  for (const item of arr) {\n    if (typeof item === 'number' || typeof item === 'string' || item == null) {\n      if (primitives.has(item)) {\n        continue;\n      }\n      ret.push(item);\n      primitives.add(item);\n    } else if (isBsonType(item, 'ObjectId')) {\n      if (ids.has(item.toString())) {\n        continue;\n      }\n      ret.push(item);\n      ids.add(item.toString());\n    } else {\n      ret.push(item);\n    }\n  }\n\n  return ret;\n};\n\nexports.buffer = {};\n\n/**\n * Determines if two buffers are equal.\n *\n * @param {Buffer} a\n * @param {Object} b\n */\n\nexports.buffer.areEqual = function(a, b) {\n  if (!Buffer.isBuffer(a)) {\n    return false;\n  }\n  if (!Buffer.isBuffer(b)) {\n    return false;\n  }\n  if (a.length !== b.length) {\n    return false;\n  }\n  for (let i = 0, len = a.length; i < len; ++i) {\n    if (a[i] !== b[i]) {\n      return false;\n    }\n  }\n  return true;\n};\n\nexports.getFunctionName = getFunctionName;\n\n/**\n * Decorate buffers\n * @param {Object} destination\n * @param {Object} source\n */\n\nexports.decorate = function(destination, source) {\n  for (const key in source) {\n    if (specialProperties.has(key)) {\n      continue;\n    }\n    destination[key] = source[key];\n  }\n};\n\n/**\n * merges to with a copy of from\n *\n * @param {Object} to\n * @param {Object} fromObj\n * @api private\n */\n\nexports.mergeClone = function(to, fromObj) {\n  if (isMongooseObject(fromObj)) {\n    fromObj = fromObj.toObject({\n      transform: false,\n      virtuals: false,\n      depopulate: true,\n      getters: false,\n      flattenDecimals: false\n    });\n  }\n  const keys = Object.keys(fromObj);\n  const len = keys.length;\n  let i = 0;\n  let key;\n\n  while (i < len) {\n    key = keys[i++];\n    if (specialProperties.has(key)) {\n      continue;\n    }\n    if (typeof to[key] === 'undefined') {\n      to[key] = clone(fromObj[key], {\n        transform: false,\n        virtuals: false,\n        depopulate: true,\n        getters: false,\n        flattenDecimals: false\n      });\n    } else {\n      let val = fromObj[key];\n      if (val != null && val.valueOf && !(val instanceof Date)) {\n        val = val.valueOf();\n      }\n      if (exports.isObject(val)) {\n        let obj = val;\n        if (isMongooseObject(val) && !val.isMongooseBuffer) {\n          obj = obj.toObject({\n            transform: false,\n            virtuals: false,\n            depopulate: true,\n            getters: false,\n            flattenDecimals: false\n          });\n        }\n        if (val.isMongooseBuffer) {\n          obj = Buffer.from(obj);\n        }\n        exports.mergeClone(to[key], obj);\n      } else {\n        to[key] = clone(val, {\n          flattenDecimals: false\n        });\n      }\n    }\n  }\n};\n\n/**\n * Executes a function on each element of an array (like _.each)\n *\n * @param {Array} arr\n * @param {Function} fn\n * @api private\n */\n\nexports.each = function(arr, fn) {\n  for (const item of arr) {\n    fn(item);\n  }\n};\n\n/**\n * Rename an object key, while preserving its position in the object\n *\n * @param {Object} oldObj\n * @param {String|Number} oldKey\n * @param {String|Number} newKey\n * @api private\n */\nexports.renameObjKey = function(oldObj, oldKey, newKey) {\n  const keys = Object.keys(oldObj);\n  return keys.reduce(\n    (acc, val) => {\n      if (val === oldKey) {\n        acc[newKey] = oldObj[oldKey];\n      } else {\n        acc[val] = oldObj[val];\n      }\n      return acc;\n    },\n    {}\n  );\n};\n\n/*!\n * ignore\n */\n\nexports.getOption = function(name) {\n  const sources = Array.prototype.slice.call(arguments, 1);\n\n  for (const source of sources) {\n    if (source == null) {\n      continue;\n    }\n    if (source[name] != null) {\n      return source[name];\n    }\n  }\n\n  return null;\n};\n\n/*!\n * ignore\n */\n\nexports.noop = function() {};\n\nexports.errorToPOJO = function errorToPOJO(error) {\n  const isError = error instanceof Error;\n  if (!isError) {\n    throw new Error('`error` must be `instanceof Error`.');\n  }\n\n  const ret = {};\n  for (const properyName of Object.getOwnPropertyNames(error)) {\n    ret[properyName] = error[properyName];\n  }\n  return ret;\n};\n\n/*!\n * ignore\n */\n\nexports.warn = function warn(message) {\n  return process.emitWarning(message, { code: 'MONGOOSE' });\n};\n\n\nexports.injectTimestampsOption = function injectTimestampsOption(writeOperation, timestampsOption) {\n  if (timestampsOption == null) {\n    return;\n  }\n  writeOperation.timestamps = timestampsOption;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/utils.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/validOptions.js":
/*!***************************************************!*\
  !*** ./node_modules/mongoose/lib/validOptions.js ***!
  \***************************************************/
/***/ ((module) => {

"use strict";
eval("\n/*!\n * Valid mongoose options\n */\n\n\n\nconst VALID_OPTIONS = Object.freeze([\n  'allowDiskUse',\n  'applyPluginsToChildSchemas',\n  'applyPluginsToDiscriminators',\n  'autoCreate',\n  'autoIndex',\n  'autoSearchIndex',\n  'bufferCommands',\n  'bufferTimeoutMS',\n  'cloneSchemas',\n  'createInitialConnection',\n  'debug',\n  'id',\n  'timestamps.createdAt.immutable',\n  'maxTimeMS',\n  'objectIdGetter',\n  'overwriteModels',\n  'returnOriginal',\n  'runValidators',\n  'sanitizeFilter',\n  'sanitizeProjection',\n  'selectPopulatedPaths',\n  'setDefaultsOnInsert',\n  'strict',\n  'strictPopulate',\n  'strictQuery',\n  'toJSON',\n  'toObject',\n  'transactionAsyncLocalStorage',\n  'translateAliases'\n]);\n\nmodule.exports = VALID_OPTIONS;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/validOptions.js?");

/***/ }),

/***/ "./node_modules/mongoose/lib/virtualType.js":
/*!**************************************************!*\
  !*** ./node_modules/mongoose/lib/virtualType.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst modelNamesFromRefPath = __webpack_require__(/*! ./helpers/populate/modelNamesFromRefPath */ \"./node_modules/mongoose/lib/helpers/populate/modelNamesFromRefPath.js\");\nconst utils = __webpack_require__(/*! ./utils */ \"./node_modules/mongoose/lib/utils.js\");\n\nconst modelSymbol = (__webpack_require__(/*! ./helpers/symbols */ \"./node_modules/mongoose/lib/helpers/symbols.js\").modelSymbol);\n\n/**\n * VirtualType constructor\n *\n * This is what mongoose uses to define virtual attributes via `Schema.prototype.virtual`.\n *\n * #### Example:\n *\n *     const fullname = schema.virtual('fullname');\n *     fullname instanceof mongoose.VirtualType // true\n *\n * @param {Object} options\n * @param {String|Function} [options.ref] if `ref` is not nullish, this becomes a [populated virtual](https://mongoosejs.com/docs/populate.html#populate-virtuals)\n * @param {String|Function} [options.localField] the local field to populate on if this is a populated virtual.\n * @param {String|Function} [options.foreignField] the foreign field to populate on if this is a populated virtual.\n * @param {Boolean} [options.justOne=false] by default, a populated virtual is an array. If you set `justOne`, the populated virtual will be a single doc or `null`.\n * @param {Boolean} [options.getters=false] if you set this to `true`, Mongoose will call any custom getters you defined on this virtual\n * @param {Boolean} [options.count=false] if you set this to `true`, `populate()` will set this virtual to the number of populated documents, as opposed to the documents themselves, using [`Query#countDocuments()`](https://mongoosejs.com/docs/api/query.html#Query.prototype.countDocuments())\n * @param {Object|Function} [options.match=null] add an extra match condition to `populate()`\n * @param {Number} [options.limit=null] add a default `limit` to the `populate()` query\n * @param {Number} [options.skip=null] add a default `skip` to the `populate()` query\n * @param {Number} [options.perDocumentLimit=null] For legacy reasons, `limit` with `populate()` may give incorrect results because it only executes a single query for every document being populated. If you set `perDocumentLimit`, Mongoose will ensure correct `limit` per document by executing a separate query for each document to `populate()`. For example, `.find().populate({ path: 'test', perDocumentLimit: 2 })` will execute 2 additional queries if `.find()` returns 2 documents.\n * @param {Object} [options.options=null] Additional options like `limit` and `lean`.\n * @param {String} name\n * @api public\n */\n\nfunction VirtualType(options, name) {\n  this.path = name;\n  this.getters = [];\n  this.setters = [];\n  this.options = Object.assign({}, options);\n}\n\n/**\n * If no getters/setters, add a default\n *\n * @api private\n */\n\nVirtualType.prototype._applyDefaultGetters = function() {\n  if (this.getters.length > 0 || this.setters.length > 0) {\n    return;\n  }\n\n  const path = this.path;\n  const internalProperty = '$' + path;\n  this.getters.push(function() {\n    return this.$locals[internalProperty];\n  });\n  this.setters.push(function(v) {\n    this.$locals[internalProperty] = v;\n  });\n};\n\n/*!\n * ignore\n */\n\nVirtualType.prototype.clone = function() {\n  const clone = new VirtualType(this.options, this.path);\n  clone.getters = [].concat(this.getters);\n  clone.setters = [].concat(this.setters);\n  return clone;\n};\n\n/**\n * Adds a custom getter to this virtual.\n *\n * Mongoose calls the getter function with the below 3 parameters.\n *\n * - `value`: the value returned by the previous getter. If there is only one getter, `value` will be `undefined`.\n * - `virtual`: the virtual object you called `.get()` on.\n * - `doc`: the document this virtual is attached to. Equivalent to `this`.\n *\n * #### Example:\n *\n *     const virtual = schema.virtual('fullname');\n *     virtual.get(function(value, virtual, doc) {\n *       return this.name.first + ' ' + this.name.last;\n *     });\n *\n * @param {Function} fn\n * @return {VirtualType} this\n * @api public\n */\n\nVirtualType.prototype.get = function(fn) {\n  this.getters.push(fn);\n  return this;\n};\n\n/**\n * Adds a custom setter to this virtual.\n *\n * Mongoose calls the setter function with the below 3 parameters.\n *\n * - `value`: the value being set.\n * - `virtual`: the virtual object you're calling `.set()` on.\n * - `doc`: the document this virtual is attached to. Equivalent to `this`.\n *\n * #### Example:\n *\n *     const virtual = schema.virtual('fullname');\n *     virtual.set(function(value, virtual, doc) {\n *       const parts = value.split(' ');\n *       this.name.first = parts[0];\n *       this.name.last = parts[1];\n *     });\n *\n *     const Model = mongoose.model('Test', schema);\n *     const doc = new Model();\n *     // Calls the setter with `value = 'Jean-Luc Picard'`\n *     doc.fullname = 'Jean-Luc Picard';\n *     doc.name.first; // 'Jean-Luc'\n *     doc.name.last; // 'Picard'\n *\n * @param {Function} fn\n * @return {VirtualType} this\n * @api public\n */\n\nVirtualType.prototype.set = function(fn) {\n  this.setters.push(fn);\n  return this;\n};\n\n/**\n * Applies getters to `value`.\n *\n * @param {Object} value\n * @param {Document} doc The document this virtual is attached to\n * @return {Any} the value after applying all getters\n * @api public\n */\n\nVirtualType.prototype.applyGetters = function(value, doc) {\n  if (utils.hasUserDefinedProperty(this.options, ['ref', 'refPath']) &&\n      doc.$$populatedVirtuals &&\n      doc.$$populatedVirtuals.hasOwnProperty(this.path)) {\n    value = doc.$$populatedVirtuals[this.path];\n  }\n\n  let v = value;\n  for (const getter of this.getters) {\n    v = getter.call(doc, v, this, doc);\n  }\n  return v;\n};\n\n/**\n * Applies setters to `value`.\n *\n * @param {Object} value\n * @param {Document} doc\n * @return {Any} the value after applying all setters\n * @api public\n */\n\nVirtualType.prototype.applySetters = function(value, doc) {\n  let v = value;\n  for (const setter of this.setters) {\n    v = setter.call(doc, v, this, doc);\n  }\n  return v;\n};\n\n/**\n * Get the names of models used to populate this model given a doc\n *\n * @param {Document} doc\n * @return {Array<string> | null}\n * @api private\n */\n\nVirtualType.prototype._getModelNamesForPopulate = function _getModelNamesForPopulate(doc) {\n  if (this.options.refPath) {\n    return modelNamesFromRefPath(this.options.refPath, doc, this.path);\n  }\n\n  let normalizedRef = null;\n  if (typeof this.options.ref === 'function' && !this.options.ref[modelSymbol]) {\n    normalizedRef = this.options.ref.call(doc, doc);\n  } else {\n    normalizedRef = this.options.ref;\n  }\n  if (normalizedRef != null && !Array.isArray(normalizedRef)) {\n    return [normalizedRef];\n  }\n\n  return normalizedRef;\n};\n\n/*!\n * exports\n */\n\nmodule.exports = VirtualType;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/lib/virtualType.js?");

/***/ }),

/***/ "./node_modules/mongoose/node_modules/ms/index.js":
/*!********************************************************!*\
  !*** ./node_modules/mongoose/node_modules/ms/index.js ***!
  \********************************************************/
/***/ ((module) => {

eval("/**\n * Helpers.\n */\n\nvar s = 1000;\nvar m = s * 60;\nvar h = m * 60;\nvar d = h * 24;\nvar w = d * 7;\nvar y = d * 365.25;\n\n/**\n * Parse or format the given `val`.\n *\n * Options:\n *\n *  - `long` verbose formatting [false]\n *\n * @param {String|Number} val\n * @param {Object} [options]\n * @throws {Error} throw an error if val is not a non-empty string or a number\n * @return {String|Number}\n * @api public\n */\n\nmodule.exports = function (val, options) {\n  options = options || {};\n  var type = typeof val;\n  if (type === 'string' && val.length > 0) {\n    return parse(val);\n  } else if (type === 'number' && isFinite(val)) {\n    return options.long ? fmtLong(val) : fmtShort(val);\n  }\n  throw new Error(\n    'val is not a non-empty string or a valid number. val=' +\n      JSON.stringify(val)\n  );\n};\n\n/**\n * Parse the given `str` and return milliseconds.\n *\n * @param {String} str\n * @return {Number}\n * @api private\n */\n\nfunction parse(str) {\n  str = String(str);\n  if (str.length > 100) {\n    return;\n  }\n  var match = /^(-?(?:\\d+)?\\.?\\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$/i.exec(\n    str\n  );\n  if (!match) {\n    return;\n  }\n  var n = parseFloat(match[1]);\n  var type = (match[2] || 'ms').toLowerCase();\n  switch (type) {\n    case 'years':\n    case 'year':\n    case 'yrs':\n    case 'yr':\n    case 'y':\n      return n * y;\n    case 'weeks':\n    case 'week':\n    case 'w':\n      return n * w;\n    case 'days':\n    case 'day':\n    case 'd':\n      return n * d;\n    case 'hours':\n    case 'hour':\n    case 'hrs':\n    case 'hr':\n    case 'h':\n      return n * h;\n    case 'minutes':\n    case 'minute':\n    case 'mins':\n    case 'min':\n    case 'm':\n      return n * m;\n    case 'seconds':\n    case 'second':\n    case 'secs':\n    case 'sec':\n    case 's':\n      return n * s;\n    case 'milliseconds':\n    case 'millisecond':\n    case 'msecs':\n    case 'msec':\n    case 'ms':\n      return n;\n    default:\n      return undefined;\n  }\n}\n\n/**\n * Short format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtShort(ms) {\n  var msAbs = Math.abs(ms);\n  if (msAbs >= d) {\n    return Math.round(ms / d) + 'd';\n  }\n  if (msAbs >= h) {\n    return Math.round(ms / h) + 'h';\n  }\n  if (msAbs >= m) {\n    return Math.round(ms / m) + 'm';\n  }\n  if (msAbs >= s) {\n    return Math.round(ms / s) + 's';\n  }\n  return ms + 'ms';\n}\n\n/**\n * Long format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtLong(ms) {\n  var msAbs = Math.abs(ms);\n  if (msAbs >= d) {\n    return plural(ms, msAbs, d, 'day');\n  }\n  if (msAbs >= h) {\n    return plural(ms, msAbs, h, 'hour');\n  }\n  if (msAbs >= m) {\n    return plural(ms, msAbs, m, 'minute');\n  }\n  if (msAbs >= s) {\n    return plural(ms, msAbs, s, 'second');\n  }\n  return ms + ' ms';\n}\n\n/**\n * Pluralization helper.\n */\n\nfunction plural(ms, msAbs, n, name) {\n  var isPlural = msAbs >= n * 1.5;\n  return Math.round(ms / n) + ' ' + name + (isPlural ? 's' : '');\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/node_modules/ms/index.js?");

/***/ }),

/***/ "./node_modules/mpath/index.js":
/*!*************************************!*\
  !*** ./node_modules/mpath/index.js ***!
  \*************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = exports = __webpack_require__(/*! ./lib */ \"./node_modules/mpath/lib/index.js\");\n\n\n//# sourceURL=webpack://experimento/./node_modules/mpath/index.js?");

/***/ }),

/***/ "./node_modules/mpath/lib/index.js":
/*!*****************************************!*\
  !*** ./node_modules/mpath/lib/index.js ***!
  \*****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("/* eslint strict:off */\n/* eslint no-var: off */\n/* eslint no-redeclare: off */\n\nvar stringToParts = __webpack_require__(/*! ./stringToParts */ \"./node_modules/mpath/lib/stringToParts.js\");\n\n// These properties are special and can open client libraries to security\n// issues\nvar ignoreProperties = ['__proto__', 'constructor', 'prototype'];\n\n/**\n * Returns the value of object `o` at the given `path`.\n *\n * ####Example:\n *\n *     var obj = {\n *         comments: [\n *             { title: 'exciting!', _doc: { title: 'great!' }}\n *           , { title: 'number dos' }\n *         ]\n *     }\n *\n *     mpath.get('comments.0.title', o)         // 'exciting!'\n *     mpath.get('comments.0.title', o, '_doc') // 'great!'\n *     mpath.get('comments.title', o)           // ['exciting!', 'number dos']\n *\n *     // summary\n *     mpath.get(path, o)\n *     mpath.get(path, o, special)\n *     mpath.get(path, o, map)\n *     mpath.get(path, o, special, map)\n *\n * @param {String} path\n * @param {Object} o\n * @param {String} [special] When this property name is present on any object in the path, walking will continue on the value of this property.\n * @param {Function} [map] Optional function which receives each individual found value. The value returned from `map` is used in the original values place.\n */\n\nexports.get = function(path, o, special, map) {\n  var lookup;\n\n  if ('function' == typeof special) {\n    if (special.length < 2) {\n      map = special;\n      special = undefined;\n    } else {\n      lookup = special;\n      special = undefined;\n    }\n  }\n\n  map || (map = K);\n\n  var parts = 'string' == typeof path\n    ? stringToParts(path)\n    : path;\n\n  if (!Array.isArray(parts)) {\n    throw new TypeError('Invalid `path`. Must be either string or array');\n  }\n\n  var obj = o,\n      part;\n\n  for (var i = 0; i < parts.length; ++i) {\n    part = parts[i];\n    if (typeof parts[i] !== 'string' && typeof parts[i] !== 'number') {\n      throw new TypeError('Each segment of path to `get()` must be a string or number, got ' + typeof parts[i]);\n    }\n\n    if (Array.isArray(obj) && !/^\\d+$/.test(part)) {\n      // reading a property from the array items\n      var paths = parts.slice(i);\n\n      // Need to `concat()` to avoid `map()` calling a constructor of an array\n      // subclass\n      return [].concat(obj).map(function(item) {\n        return item\n          ? exports.get(paths, item, special || lookup, map)\n          : map(undefined);\n      });\n    }\n\n    if (lookup) {\n      obj = lookup(obj, part);\n    } else {\n      var _from = special && obj[special] ? obj[special] : obj;\n      obj = _from instanceof Map ?\n        _from.get(part) :\n        _from[part];\n    }\n\n    if (!obj) return map(obj);\n  }\n\n  return map(obj);\n};\n\n/**\n * Returns true if `in` returns true for every piece of the path\n *\n * @param {String} path\n * @param {Object} o\n */\n\nexports.has = function(path, o) {\n  var parts = typeof path === 'string' ?\n    stringToParts(path) :\n    path;\n\n  if (!Array.isArray(parts)) {\n    throw new TypeError('Invalid `path`. Must be either string or array');\n  }\n\n  var len = parts.length;\n  var cur = o;\n  for (var i = 0; i < len; ++i) {\n    if (typeof parts[i] !== 'string' && typeof parts[i] !== 'number') {\n      throw new TypeError('Each segment of path to `has()` must be a string or number, got ' + typeof parts[i]);\n    }\n    if (cur == null || typeof cur !== 'object' || !(parts[i] in cur)) {\n      return false;\n    }\n    cur = cur[parts[i]];\n  }\n\n  return true;\n};\n\n/**\n * Deletes the last piece of `path`\n *\n * @param {String} path\n * @param {Object} o\n */\n\nexports.unset = function(path, o) {\n  var parts = typeof path === 'string' ?\n    stringToParts(path) :\n    path;\n\n  if (!Array.isArray(parts)) {\n    throw new TypeError('Invalid `path`. Must be either string or array');\n  }\n\n  var len = parts.length;\n  var cur = o;\n  for (var i = 0; i < len; ++i) {\n    if (cur == null || typeof cur !== 'object' || !(parts[i] in cur)) {\n      return false;\n    }\n    if (typeof parts[i] !== 'string' && typeof parts[i] !== 'number') {\n      throw new TypeError('Each segment of path to `unset()` must be a string or number, got ' + typeof parts[i]);\n    }\n    // Disallow any updates to __proto__ or special properties.\n    if (ignoreProperties.indexOf(parts[i]) !== -1) {\n      return false;\n    }\n    if (i === len - 1) {\n      delete cur[parts[i]];\n      return true;\n    }\n    cur = cur instanceof Map ? cur.get(parts[i]) : cur[parts[i]];\n  }\n\n  return true;\n};\n\n/**\n * Sets the `val` at the given `path` of object `o`.\n *\n * @param {String} path\n * @param {Anything} val\n * @param {Object} o\n * @param {String} [special] When this property name is present on any object in the path, walking will continue on the value of this property.\n * @param {Function} [map] Optional function which is passed each individual value before setting it. The value returned from `map` is used in the original values place.\n */\n\nexports.set = function(path, val, o, special, map, _copying) {\n  var lookup;\n\n  if ('function' == typeof special) {\n    if (special.length < 2) {\n      map = special;\n      special = undefined;\n    } else {\n      lookup = special;\n      special = undefined;\n    }\n  }\n\n  map || (map = K);\n\n  var parts = 'string' == typeof path\n    ? stringToParts(path)\n    : path;\n\n  if (!Array.isArray(parts)) {\n    throw new TypeError('Invalid `path`. Must be either string or array');\n  }\n\n  if (null == o) return;\n\n  for (var i = 0; i < parts.length; ++i) {\n    if (typeof parts[i] !== 'string' && typeof parts[i] !== 'number') {\n      throw new TypeError('Each segment of path to `set()` must be a string or number, got ' + typeof parts[i]);\n    }\n    // Silently ignore any updates to `__proto__`, these are potentially\n    // dangerous if using mpath with unsanitized data.\n    if (ignoreProperties.indexOf(parts[i]) !== -1) {\n      return;\n    }\n  }\n\n  // the existance of $ in a path tells us if the user desires\n  // the copying of an array instead of setting each value of\n  // the array to the one by one to matching positions of the\n  // current array. Unless the user explicitly opted out by passing\n  // false, see Automattic/mongoose#6273\n  var copy = _copying || (/\\$/.test(path) && _copying !== false),\n      obj = o,\n      part;\n\n  for (var i = 0, len = parts.length - 1; i < len; ++i) {\n    part = parts[i];\n\n    if ('$' == part) {\n      if (i == len - 1) {\n        break;\n      } else {\n        continue;\n      }\n    }\n\n    if (Array.isArray(obj) && !/^\\d+$/.test(part)) {\n      var paths = parts.slice(i);\n      if (!copy && Array.isArray(val)) {\n        for (var j = 0; j < obj.length && j < val.length; ++j) {\n          // assignment of single values of array\n          exports.set(paths, val[j], obj[j], special || lookup, map, copy);\n        }\n      } else {\n        for (var j = 0; j < obj.length; ++j) {\n          // assignment of entire value\n          exports.set(paths, val, obj[j], special || lookup, map, copy);\n        }\n      }\n      return;\n    }\n\n    if (lookup) {\n      obj = lookup(obj, part);\n    } else {\n      var _to = special && obj[special] ? obj[special] : obj;\n      obj = _to instanceof Map ?\n        _to.get(part) :\n        _to[part];\n    }\n\n    if (!obj) return;\n  }\n\n  // process the last property of the path\n\n  part = parts[len];\n\n  // use the special property if exists\n  if (special && obj[special]) {\n    obj = obj[special];\n  }\n\n  // set the value on the last branch\n  if (Array.isArray(obj) && !/^\\d+$/.test(part)) {\n    if (!copy && Array.isArray(val)) {\n      _setArray(obj, val, part, lookup, special, map);\n    } else {\n      for (var j = 0; j < obj.length; ++j) {\n        var item = obj[j];\n        if (item) {\n          if (lookup) {\n            lookup(item, part, map(val));\n          } else {\n            if (item[special]) item = item[special];\n            item[part] = map(val);\n          }\n        }\n      }\n    }\n  } else {\n    if (lookup) {\n      lookup(obj, part, map(val));\n    } else if (obj instanceof Map) {\n      obj.set(part, map(val));\n    } else {\n      obj[part] = map(val);\n    }\n  }\n};\n\n/*!\n * Split a string path into components delimited by '.' or\n * '[\\d+]'\n *\n * #### Example:\n *     stringToParts('foo[0].bar.1'); // ['foo', '0', 'bar', '1']\n */\n\nexports.stringToParts = stringToParts;\n\n/*!\n * Recursively set nested arrays\n */\n\nfunction _setArray(obj, val, part, lookup, special, map) {\n  for (var item, j = 0; j < obj.length && j < val.length; ++j) {\n    item = obj[j];\n    if (Array.isArray(item) && Array.isArray(val[j])) {\n      _setArray(item, val[j], part, lookup, special, map);\n    } else if (item) {\n      if (lookup) {\n        lookup(item, part, map(val[j]));\n      } else {\n        if (item[special]) item = item[special];\n        item[part] = map(val[j]);\n      }\n    }\n  }\n}\n\n/*!\n * Returns the value passed to it.\n */\n\nfunction K(v) {\n  return v;\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mpath/lib/index.js?");

/***/ }),

/***/ "./node_modules/mpath/lib/stringToParts.js":
/*!*************************************************!*\
  !*** ./node_modules/mpath/lib/stringToParts.js ***!
  \*************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function stringToParts(str) {\n  const result = [];\n\n  let curPropertyName = '';\n  let state = 'DEFAULT';\n  for (let i = 0; i < str.length; ++i) {\n    // Fall back to treating as property name rather than bracket notation if\n    // square brackets contains something other than a number.\n    if (state === 'IN_SQUARE_BRACKETS' && !/\\d/.test(str[i]) && str[i] !== ']') {\n      state = 'DEFAULT';\n      curPropertyName = result[result.length - 1] + '[' + curPropertyName;\n      result.splice(result.length - 1, 1);\n    }\n\n    if (str[i] === '[') {\n      if (state !== 'IMMEDIATELY_AFTER_SQUARE_BRACKETS') {\n        result.push(curPropertyName);\n        curPropertyName = '';\n      }\n      state = 'IN_SQUARE_BRACKETS';\n    } else if (str[i] === ']') {\n      if (state === 'IN_SQUARE_BRACKETS') {\n        state = 'IMMEDIATELY_AFTER_SQUARE_BRACKETS';\n        result.push(curPropertyName);\n        curPropertyName = '';\n      } else {\n        state = 'DEFAULT';\n        curPropertyName += str[i];\n      }\n    } else if (str[i] === '.') {\n      if (state !== 'IMMEDIATELY_AFTER_SQUARE_BRACKETS') {\n        result.push(curPropertyName);\n        curPropertyName = '';\n      }\n      state = 'DEFAULT';\n    } else {\n      curPropertyName += str[i];\n    }\n  }\n\n  if (state !== 'IMMEDIATELY_AFTER_SQUARE_BRACKETS') {\n    result.push(curPropertyName);\n  }\n\n  return result;\n};\n\n//# sourceURL=webpack://experimento/./node_modules/mpath/lib/stringToParts.js?");

/***/ }),

/***/ "./node_modules/mquery/lib/collection/collection.js":
/*!**********************************************************!*\
  !*** ./node_modules/mquery/lib/collection/collection.js ***!
  \**********************************************************/
/***/ ((module, exports) => {

"use strict";
eval("\n\n/**\n * methods a collection must implement\n */\n\nconst methods = [\n  'find',\n  'findOne',\n  'updateMany',\n  'updateOne',\n  'replaceOne',\n  'count',\n  'distinct',\n  'findOneAndDelete',\n  'findOneAndUpdate',\n  'aggregate',\n  'findCursor',\n  'deleteOne',\n  'deleteMany'\n];\n\n/**\n * Collection base class from which implementations inherit\n */\n\nfunction Collection() {}\n\nfor (let i = 0, len = methods.length; i < len; ++i) {\n  const method = methods[i];\n  Collection.prototype[method] = notImplemented(method);\n}\n\nmodule.exports = exports = Collection;\nCollection.methods = methods;\n\n/**\n * creates a function which throws an implementation error\n */\n\nfunction notImplemented(method) {\n  return function() {\n    throw new Error('collection.' + method + ' not implemented');\n  };\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/mquery/lib/collection/collection.js?");

/***/ }),

/***/ "./node_modules/mquery/lib/collection/index.js":
/*!*****************************************************!*\
  !*** ./node_modules/mquery/lib/collection/index.js ***!
  \*****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst env = __webpack_require__(/*! ../env */ \"./node_modules/mquery/lib/env.js\");\n\nif ('unknown' == env.type) {\n  throw new Error('Unknown environment');\n}\n\nmodule.exports =\n  env.isNode ? __webpack_require__(/*! ./node */ \"./node_modules/mquery/lib/collection/node.js\") :\n    env.isMongo ? __webpack_require__(/*! ./collection */ \"./node_modules/mquery/lib/collection/collection.js\") :\n      __webpack_require__(/*! ./collection */ \"./node_modules/mquery/lib/collection/collection.js\");\n\n\n\n//# sourceURL=webpack://experimento/./node_modules/mquery/lib/collection/index.js?");

/***/ }),

/***/ "./node_modules/mquery/lib/collection/node.js":
/*!****************************************************!*\
  !*** ./node_modules/mquery/lib/collection/node.js ***!
  \****************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\n/**\n * Module dependencies\n */\n\nconst Collection = __webpack_require__(/*! ./collection */ \"./node_modules/mquery/lib/collection/collection.js\");\n\nclass NodeCollection extends Collection {\n  constructor(col) {\n    super();\n\n    this.collection = col;\n    this.collectionName = col.collectionName;\n  }\n\n  /**\n   * find(match, options)\n   */\n  async find(match, options) {\n    const cursor = this.collection.find(match, options);\n\n    return cursor.toArray();\n  }\n\n  /**\n   * findOne(match, options)\n   */\n  async findOne(match, options) {\n    return this.collection.findOne(match, options);\n  }\n\n  /**\n   * count(match, options)\n   */\n  async count(match, options) {\n    return this.collection.count(match, options);\n  }\n\n  /**\n   * distinct(prop, match, options)\n   */\n  async distinct(prop, match, options) {\n    return this.collection.distinct(prop, match, options);\n  }\n\n  /**\n   * updateMany(match, update, options)\n   */\n  async updateMany(match, update, options) {\n    return this.collection.updateMany(match, update, options);\n  }\n\n  /**\n   * updateOne(match, update, options)\n   */\n  async updateOne(match, update, options) {\n    return this.collection.updateOne(match, update, options);\n  }\n\n  /**\n   * replaceOne(match, update, options)\n   */\n  async replaceOne(match, update, options) {\n    return this.collection.replaceOne(match, update, options);\n  }\n\n  /**\n   * deleteOne(match, options)\n   */\n  async deleteOne(match, options) {\n    return this.collection.deleteOne(match, options);\n  }\n\n  /**\n   * deleteMany(match, options)\n   */\n  async deleteMany(match, options) {\n    return this.collection.deleteMany(match, options);\n  }\n\n  /**\n   * findOneAndDelete(match, options, function(err[, result])\n   */\n  async findOneAndDelete(match, options) {\n    return this.collection.findOneAndDelete(match, options);\n  }\n\n  /**\n   * findOneAndUpdate(match, update, options)\n   */\n  async findOneAndUpdate(match, update, options) {\n    return this.collection.findOneAndUpdate(match, update, options);\n  }\n\n  /**\n   * var cursor = findCursor(match, options)\n   */\n  findCursor(match, options) {\n    return this.collection.find(match, options);\n  }\n\n  /**\n   * aggregation(operators...)\n   * TODO\n   */\n}\n\n\n/**\n * Expose\n */\n\nmodule.exports = exports = NodeCollection;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mquery/lib/collection/node.js?");

/***/ }),

/***/ "./node_modules/mquery/lib/env.js":
/*!****************************************!*\
  !*** ./node_modules/mquery/lib/env.js ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nexports.isNode = 'undefined' != typeof process\n           && 'object' == \"object\"\n           && 'object' == typeof global\n           && 'function' == typeof Buffer\n           && process.argv;\n\nexports.isMongo = !exports.isNode\n           && 'function' == typeof printjson\n           && 'function' == typeof ObjectId\n           && 'function' == typeof rs\n           && 'function' == typeof sh;\n\nexports.isBrowser = !exports.isNode\n                 && !exports.isMongo\n                 && 'undefined' != typeof window;\n\nexports.type = exports.isNode ? 'node'\n  : exports.isMongo ? 'mongo'\n    : exports.isBrowser ? 'browser'\n      : 'unknown';\n\n\n//# sourceURL=webpack://experimento/./node_modules/mquery/lib/env.js?");

/***/ }),

/***/ "./node_modules/mquery/lib/mquery.js":
/*!*******************************************!*\
  !*** ./node_modules/mquery/lib/mquery.js ***!
  \*******************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\n/**\n * Dependencies\n */\n\nconst assert = __webpack_require__(/*! assert */ \"assert\");\nconst util = __webpack_require__(/*! util */ \"util\");\nconst utils = __webpack_require__(/*! ./utils */ \"./node_modules/mquery/lib/utils.js\");\nconst debug = __webpack_require__(/*! debug */ \"./node_modules/debug/src/index.js\")('mquery');\n\n/**\n * Query constructor used for building queries.\n *\n * #### Example:\n *\n *     var query = new Query({ name: 'mquery' });\n *     query.setOptions({ collection: moduleCollection })\n *     await query.where('age').gte(21).exec();\n *\n * @param {Object} [criteria] criteria for the query OR the collection instance to use\n * @param {Object} [options]\n * @api public\n */\n\nfunction Query(criteria, options) {\n  if (!(this instanceof Query))\n    return new Query(criteria, options);\n\n  const proto = this.constructor.prototype;\n\n  this.op = proto.op || undefined;\n\n  this.options = Object.assign({}, proto.options);\n\n  this._conditions = proto._conditions\n    ? utils.clone(proto._conditions)\n    : {};\n\n  this._fields = proto._fields\n    ? utils.clone(proto._fields)\n    : undefined;\n\n  this._updateDoc = proto._updateDoc\n    ? utils.clone(proto._updateDoc)\n    : undefined;\n\n  this._path = proto._path || undefined;\n  this._distinctDoc = proto._distinctDoc || undefined;\n  this._collection = proto._collection || undefined;\n  this._traceFunction = proto._traceFunction || undefined;\n\n  if (options) {\n    this.setOptions(options);\n  }\n\n  if (criteria) {\n    this.find(criteria);\n  }\n}\n\n/**\n * This is a parameter that the user can set which determines if mquery\n * uses $within or $geoWithin for queries. It defaults to true which\n * means $geoWithin will be used. If using MongoDB < 2.4 you should\n * set this to false.\n *\n * @api public\n * @property use$geoWithin\n */\n\nlet $withinCmd = '$geoWithin';\nObject.defineProperty(Query, 'use$geoWithin', {\n  get: function() { return $withinCmd == '$geoWithin'; },\n  set: function(v) {\n    if (true === v) {\n      // mongodb >= 2.4\n      $withinCmd = '$geoWithin';\n    } else {\n      $withinCmd = '$within';\n    }\n  }\n});\n\n/**\n * Converts this query to a constructor function with all arguments and options retained.\n *\n * #### Example:\n *\n *     // Create a query that will read documents with a \"video\" category from\n *     // `aCollection` on the primary node in the replica-set unless it is down,\n *     // in which case we'll read from a secondary node.\n *     var query = mquery({ category: 'video' })\n *     query.setOptions({ collection: aCollection, read: 'primaryPreferred' });\n *\n *     // create a constructor based off these settings\n *     var Video = query.toConstructor();\n *\n *     // Video is now a subclass of mquery() and works the same way but with the\n *     // default query parameters and options set.\n *\n *     // run a query with the previous settings but filter for movies with names\n *     // that start with \"Life\".\n *     Video().where({ name: /^Life/ }).exec(cb);\n *\n * @return {Query} new Query\n * @api public\n */\n\nQuery.prototype.toConstructor = function toConstructor() {\n  function CustomQuery(criteria, options) {\n    if (!(this instanceof CustomQuery))\n      return new CustomQuery(criteria, options);\n    Query.call(this, criteria, options);\n  }\n\n  utils.inherits(CustomQuery, Query);\n\n  // set inherited defaults\n  const p = CustomQuery.prototype;\n\n  p.options = {};\n  p.setOptions(this.options);\n\n  p.op = this.op;\n  p._conditions = utils.clone(this._conditions);\n  p._fields = utils.clone(this._fields);\n  p._updateDoc = utils.clone(this._updateDoc);\n  p._path = this._path;\n  p._distinctDoc = this._distinctDoc;\n  p._collection = this._collection;\n  p._traceFunction = this._traceFunction;\n\n  return CustomQuery;\n};\n\n/**\n * Sets query options.\n *\n * #### Options:\n *\n * - [tailable](http://www.mongodb.org/display/DOCS/Tailable+Cursors) *\n * - [sort](http://www.mongodb.org/display/DOCS/Advanced+Queries#AdvancedQueries-%7B%7Bsort(\\)%7D%7D) *\n * - [limit](http://www.mongodb.org/display/DOCS/Advanced+Queries#AdvancedQueries-%7B%7Blimit%28%29%7D%7D) *\n * - [skip](http://www.mongodb.org/display/DOCS/Advanced+Queries#AdvancedQueries-%7B%7Bskip%28%29%7D%7D) *\n * - [maxTime](http://docs.mongodb.org/manual/reference/operator/meta/maxTimeMS/#op._S_maxTimeMS) *\n * - [batchSize](http://www.mongodb.org/display/DOCS/Advanced+Queries#AdvancedQueries-%7B%7BbatchSize%28%29%7D%7D) *\n * - [comment](http://www.mongodb.org/display/DOCS/Advanced+Queries#AdvancedQueries-%24comment) *\n * - [hint](http://www.mongodb.org/display/DOCS/Advanced+Queries#AdvancedQueries-%24hint) *\n * - [slaveOk](http://docs.mongodb.org/manual/applications/replication/#read-preference) *\n * - [safe](http://www.mongodb.org/display/DOCS/getLastError+Command)\n * - collection the collection to query against\n *\n * _* denotes a query helper method is also available_\n *\n * @param {Object} options\n * @api public\n */\n\nQuery.prototype.setOptions = function(options) {\n  if (!(options && utils.isObject(options)))\n    return this;\n\n  // set arbitrary options\n  const methods = utils.keys(options);\n  let method;\n\n  for (let i = 0; i < methods.length; ++i) {\n    method = methods[i];\n\n    // use methods if exist (safer option manipulation)\n    if ('function' == typeof this[method]) {\n      const args = Array.isArray(options[method])\n        ? options[method]\n        : [options[method]];\n      this[method].apply(this, args);\n    } else {\n      this.options[method] = options[method];\n    }\n  }\n\n  return this;\n};\n\n/**\n * Sets this Querys collection.\n *\n * @param {Collection} coll\n * @return {Query} this\n */\n\nQuery.prototype.collection = function collection(coll) {\n  this._collection = new Query.Collection(coll);\n\n  return this;\n};\n\n/**\n * Adds a collation to this op (MongoDB 3.4 and up)\n *\n * #### Example:\n *\n *     query.find().collation({ locale: \"en_US\", strength: 1 })\n *\n * @param {Object} value\n * @return {Query} this\n * @see MongoDB docs https://docs.mongodb.com/manual/reference/method/cursor.collation/#cursor.collation\n * @api public\n */\n\nQuery.prototype.collation = function(value) {\n  this.options.collation = value;\n  return this;\n};\n\n/**\n * Specifies a `$where` condition\n *\n * Use `$where` when you need to select documents using a JavaScript expression.\n *\n * #### Example:\n *\n *     query.$where('this.comments.length > 10 || this.name.length > 5')\n *\n *     query.$where(function () {\n *       return this.comments.length > 10 || this.name.length > 5;\n *     })\n *\n * @param {String|Function} js javascript string or function\n * @return {Query} this\n * @memberOf Query\n * @method $where\n * @api public\n */\n\nQuery.prototype.$where = function(js) {\n  this._conditions.$where = js;\n  return this;\n};\n\n/**\n * Specifies a `path` for use with chaining.\n *\n * #### Example:\n *\n *     // instead of writing:\n *     await User.find({age: {$gte: 21, $lte: 65}});\n *\n *     // we can instead write:\n *     User.where('age').gte(21).lte(65);\n *\n *     // passing query conditions is permitted\n *     User.find().where({ name: 'vonderful' })\n *\n *     // chaining\n *     await User\n *       .where('age').gte(21).lte(65)\n *       .where('name', /^vonderful/i)\n *       .where('friends').slice(10)\n *       .exec()\n *\n * @param {String} [path]\n * @param {Object} [val]\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.where = function() {\n  if (!arguments.length) return this;\n  if (!this.op) this.op = 'find';\n\n  const type = typeof arguments[0];\n\n  if ('string' == type) {\n    this._path = arguments[0];\n\n    if (2 === arguments.length) {\n      this._conditions[this._path] = arguments[1];\n    }\n\n    return this;\n  }\n\n  if ('object' == type && !Array.isArray(arguments[0])) {\n    return this.merge(arguments[0]);\n  }\n\n  throw new TypeError('path must be a string or object');\n};\n\n/**\n * Specifies the complementary comparison value for paths specified with `where()`\n *\n * #### Example:\n *\n *     User.where('age').equals(49);\n *\n *     // is the same as\n *\n *     User.where('age', 49);\n *\n * @param {Object} val\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.equals = function equals(val) {\n  this._ensurePath('equals');\n  const path = this._path;\n  this._conditions[path] = val;\n  return this;\n};\n\n/**\n * Specifies the complementary comparison value for paths specified with `where()`\n * This is alias of `equals`\n *\n * #### Example:\n *\n *     User.where('age').eq(49);\n *\n *     // is the same as\n *\n *     User.shere('age').equals(49);\n *\n *     // is the same as\n *\n *     User.where('age', 49);\n *\n * @param {Object} val\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.eq = function eq(val) {\n  this._ensurePath('eq');\n  const path = this._path;\n  this._conditions[path] = val;\n  return this;\n};\n\n/**\n * Specifies arguments for an `$or` condition.\n *\n * #### Example:\n *\n *     query.or([{ color: 'red' }, { status: 'emergency' }])\n *\n * @param {Array} array array of conditions\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.or = function or(array) {\n  const or = this._conditions.$or || (this._conditions.$or = []);\n  if (!Array.isArray(array)) array = [array];\n  or.push.apply(or, array);\n  return this;\n};\n\n/**\n * Specifies arguments for a `$nor` condition.\n *\n * #### Example:\n *\n *     query.nor([{ color: 'green' }, { status: 'ok' }])\n *\n * @param {Array} array array of conditions\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.nor = function nor(array) {\n  const nor = this._conditions.$nor || (this._conditions.$nor = []);\n  if (!Array.isArray(array)) array = [array];\n  nor.push.apply(nor, array);\n  return this;\n};\n\n/**\n * Specifies arguments for a `$and` condition.\n *\n * #### Example:\n *\n *     query.and([{ color: 'green' }, { status: 'ok' }])\n *\n * @see $and http://docs.mongodb.org/manual/reference/operator/and/\n * @param {Array} array array of conditions\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.and = function and(array) {\n  const and = this._conditions.$and || (this._conditions.$and = []);\n  if (!Array.isArray(array)) array = [array];\n  and.push.apply(and, array);\n  return this;\n};\n\n/**\n * Specifies a $gt query condition.\n *\n * When called with one argument, the most recent path passed to `where()` is used.\n *\n * #### Example:\n *\n *     Thing.find().where('age').gt(21)\n *\n *     // or\n *     Thing.find().gt('age', 21)\n *\n * @method gt\n * @memberOf Query\n * @param {String} [path]\n * @param {Number} val\n * @api public\n */\n\n/**\n * Specifies a $gte query condition.\n *\n * When called with one argument, the most recent path passed to `where()` is used.\n *\n * @method gte\n * @memberOf Query\n * @param {String} [path]\n * @param {Number} val\n * @api public\n */\n\n/**\n * Specifies a $lt query condition.\n *\n * When called with one argument, the most recent path passed to `where()` is used.\n *\n * @method lt\n * @memberOf Query\n * @param {String} [path]\n * @param {Number} val\n * @api public\n */\n\n/**\n * Specifies a $lte query condition.\n *\n * When called with one argument, the most recent path passed to `where()` is used.\n *\n * @method lte\n * @memberOf Query\n * @param {String} [path]\n * @param {Number} val\n * @api public\n */\n\n/**\n * Specifies a $ne query condition.\n *\n * When called with one argument, the most recent path passed to `where()` is used.\n *\n * @method ne\n * @memberOf Query\n * @param {String} [path]\n * @param {Number} val\n * @api public\n */\n\n/**\n * Specifies an $in query condition.\n *\n * When called with one argument, the most recent path passed to `where()` is used.\n *\n * @method in\n * @memberOf Query\n * @param {String} [path]\n * @param {Number} val\n * @api public\n */\n\n/**\n * Specifies an $nin query condition.\n *\n * When called with one argument, the most recent path passed to `where()` is used.\n *\n * @method nin\n * @memberOf Query\n * @param {String} [path]\n * @param {Number} val\n * @api public\n */\n\n/**\n * Specifies an $all query condition.\n *\n * When called with one argument, the most recent path passed to `where()` is used.\n *\n * @method all\n * @memberOf Query\n * @param {String} [path]\n * @param {Number} val\n * @api public\n */\n\n/**\n * Specifies a $size query condition.\n *\n * When called with one argument, the most recent path passed to `where()` is used.\n *\n * @method size\n * @memberOf Query\n * @param {String} [path]\n * @param {Number} val\n * @api public\n */\n\n/**\n * Specifies a $regex query condition.\n *\n * When called with one argument, the most recent path passed to `where()` is used.\n *\n * @method regex\n * @memberOf Query\n * @param {String} [path]\n * @param {String|RegExp} val\n * @api public\n */\n\n/**\n * Specifies a $maxDistance query condition.\n *\n * When called with one argument, the most recent path passed to `where()` is used.\n *\n * @method maxDistance\n * @memberOf Query\n * @param {String} [path]\n * @param {Number} val\n * @api public\n */\n\n/*!\n * gt, gte, lt, lte, ne, in, nin, all, regex, size, maxDistance\n *\n *     Thing.where('type').nin(array)\n */\n\n'gt gte lt lte ne in nin all regex size maxDistance minDistance'.split(' ').forEach(function($conditional) {\n  Query.prototype[$conditional] = function() {\n    let path, val;\n\n    if (1 === arguments.length) {\n      this._ensurePath($conditional);\n      val = arguments[0];\n      path = this._path;\n    } else {\n      val = arguments[1];\n      path = arguments[0];\n    }\n\n    const conds = this._conditions[path] === null || typeof this._conditions[path] === 'object' ?\n      this._conditions[path] :\n      (this._conditions[path] = {});\n    conds['$' + $conditional] = val;\n    return this;\n  };\n});\n\n/**\n * Specifies a `$mod` condition\n *\n * @param {String} [path]\n * @param {Number} val\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.mod = function() {\n  let val, path;\n\n  if (1 === arguments.length) {\n    this._ensurePath('mod');\n    val = arguments[0];\n    path = this._path;\n  } else if (2 === arguments.length && !Array.isArray(arguments[1])) {\n    this._ensurePath('mod');\n    val = [arguments[0], arguments[1]];\n    path = this._path;\n  } else if (3 === arguments.length) {\n    val = [arguments[1], arguments[2]];\n    path = arguments[0];\n  } else {\n    val = arguments[1];\n    path = arguments[0];\n  }\n\n  const conds = this._conditions[path] || (this._conditions[path] = {});\n  conds.$mod = val;\n  return this;\n};\n\n/**\n * Specifies an `$exists` condition\n *\n * #### Example:\n *\n *     // { name: { $exists: true }}\n *     Thing.where('name').exists()\n *     Thing.where('name').exists(true)\n *     Thing.find().exists('name')\n *\n *     // { name: { $exists: false }}\n *     Thing.where('name').exists(false);\n *     Thing.find().exists('name', false);\n *\n * @param {String} [path]\n * @param {Number} val\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.exists = function() {\n  let path, val;\n\n  if (0 === arguments.length) {\n    this._ensurePath('exists');\n    path = this._path;\n    val = true;\n  } else if (1 === arguments.length) {\n    if ('boolean' === typeof arguments[0]) {\n      this._ensurePath('exists');\n      path = this._path;\n      val = arguments[0];\n    } else {\n      path = arguments[0];\n      val = true;\n    }\n  } else if (2 === arguments.length) {\n    path = arguments[0];\n    val = arguments[1];\n  }\n\n  const conds = this._conditions[path] || (this._conditions[path] = {});\n  conds.$exists = val;\n  return this;\n};\n\n/**\n * Specifies an `$elemMatch` condition\n *\n * #### Example:\n *\n *     query.elemMatch('comment', { author: 'autobot', votes: {$gte: 5}})\n *\n *     query.where('comment').elemMatch({ author: 'autobot', votes: {$gte: 5}})\n *\n *     query.elemMatch('comment', function (elem) {\n *       elem.where('author').equals('autobot');\n *       elem.where('votes').gte(5);\n *     })\n *\n *     query.where('comment').elemMatch(function (elem) {\n *       elem.where({ author: 'autobot' });\n *       elem.where('votes').gte(5);\n *     })\n *\n * @param {String|Object|Function} path\n * @param {Object|Function} criteria\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.elemMatch = function() {\n  if (null == arguments[0])\n    throw new TypeError('Invalid argument');\n\n  let fn, path, criteria;\n\n  if ('function' === typeof arguments[0]) {\n    this._ensurePath('elemMatch');\n    path = this._path;\n    fn = arguments[0];\n  } else if (utils.isObject(arguments[0])) {\n    this._ensurePath('elemMatch');\n    path = this._path;\n    criteria = arguments[0];\n  } else if ('function' === typeof arguments[1]) {\n    path = arguments[0];\n    fn = arguments[1];\n  } else if (arguments[1] && utils.isObject(arguments[1])) {\n    path = arguments[0];\n    criteria = arguments[1];\n  } else {\n    throw new TypeError('Invalid argument');\n  }\n\n  if (fn) {\n    criteria = new Query;\n    fn(criteria);\n    criteria = criteria._conditions;\n  }\n\n  const conds = this._conditions[path] || (this._conditions[path] = {});\n  conds.$elemMatch = criteria;\n  return this;\n};\n\n// Spatial queries\n\n/**\n * Sugar for geo-spatial queries.\n *\n * #### Example:\n *\n *     query.within().box()\n *     query.within().circle()\n *     query.within().geometry()\n *\n *     query.where('loc').within({ center: [50,50], radius: 10, unique: true, spherical: true });\n *     query.where('loc').within({ box: [[40.73, -73.9], [40.7, -73.988]] });\n *     query.where('loc').within({ polygon: [[],[],[],[]] });\n *\n *     query.where('loc').within([], [], []) // polygon\n *     query.where('loc').within([], []) // box\n *     query.where('loc').within({ type: 'LineString', coordinates: [...] }); // geometry\n *\n * #### Note:\n *\n * Must be used after `where()`.\n *\n * @memberOf Query\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.within = function within() {\n  // opinionated, must be used after where\n  this._ensurePath('within');\n  this._geoComparison = $withinCmd;\n\n  if (0 === arguments.length) {\n    return this;\n  }\n\n  if (2 === arguments.length) {\n    return this.box.apply(this, arguments);\n  } else if (2 < arguments.length) {\n    return this.polygon.apply(this, arguments);\n  }\n\n  const area = arguments[0];\n\n  if (!area)\n    throw new TypeError('Invalid argument');\n\n  if (area.center)\n    return this.circle(area);\n\n  if (area.box)\n    return this.box.apply(this, area.box);\n\n  if (area.polygon)\n    return this.polygon.apply(this, area.polygon);\n\n  if (area.type && area.coordinates)\n    return this.geometry(area);\n\n  throw new TypeError('Invalid argument');\n};\n\n/**\n * Specifies a $box condition\n *\n * #### Example:\n *\n *     var lowerLeft = [40.73083, -73.99756]\n *     var upperRight= [40.741404,  -73.988135]\n *\n *     query.where('loc').within().box(lowerLeft, upperRight)\n *     query.box('loc', lowerLeft, upperRight )\n *\n * @see http://www.mongodb.org/display/DOCS/Geospatial+Indexing\n * @see Query#within #query_Query-within\n * @param {String} path\n * @param {Object} val\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.box = function() {\n  let path, box;\n\n  if (3 === arguments.length) {\n    // box('loc', [], [])\n    path = arguments[0];\n    box = [arguments[1], arguments[2]];\n  } else if (2 === arguments.length) {\n    // box([], [])\n    this._ensurePath('box');\n    path = this._path;\n    box = [arguments[0], arguments[1]];\n  } else {\n    throw new TypeError('Invalid argument');\n  }\n\n  const conds = this._conditions[path] || (this._conditions[path] = {});\n  conds[this._geoComparison || $withinCmd] = { $box: box };\n  return this;\n};\n\n/**\n * Specifies a $polygon condition\n *\n * #### Example:\n *\n *     query.where('loc').within().polygon([10,20], [13, 25], [7,15])\n *     query.polygon('loc', [10,20], [13, 25], [7,15])\n *\n * @param {String|Array} [path]\n * @param {Array|Object} [val]\n * @return {Query} this\n * @see http://www.mongodb.org/display/DOCS/Geospatial+Indexing\n * @api public\n */\n\nQuery.prototype.polygon = function() {\n  let val, path;\n\n  if ('string' == typeof arguments[0]) {\n    // polygon('loc', [],[],[])\n    val = Array.from(arguments);\n    path = val.shift();\n  } else {\n    // polygon([],[],[])\n    this._ensurePath('polygon');\n    path = this._path;\n    val = Array.from(arguments);\n  }\n\n  const conds = this._conditions[path] || (this._conditions[path] = {});\n  conds[this._geoComparison || $withinCmd] = { $polygon: val };\n  return this;\n};\n\n/**\n * Specifies a $center or $centerSphere condition.\n *\n * #### Example:\n *\n *     var area = { center: [50, 50], radius: 10, unique: true }\n *     query.where('loc').within().circle(area)\n *     query.center('loc', area);\n *\n *     // for spherical calculations\n *     var area = { center: [50, 50], radius: 10, unique: true, spherical: true }\n *     query.where('loc').within().circle(area)\n *     query.center('loc', area);\n *\n * @param {String} [path]\n * @param {Object} area\n * @return {Query} this\n * @see http://www.mongodb.org/display/DOCS/Geospatial+Indexing\n * @api public\n */\n\nQuery.prototype.circle = function() {\n  let path, val;\n\n  if (1 === arguments.length) {\n    this._ensurePath('circle');\n    path = this._path;\n    val = arguments[0];\n  } else if (2 === arguments.length) {\n    path = arguments[0];\n    val = arguments[1];\n  } else {\n    throw new TypeError('Invalid argument');\n  }\n\n  if (!('radius' in val && val.center))\n    throw new Error('center and radius are required');\n\n  const conds = this._conditions[path] || (this._conditions[path] = {});\n\n  const type = val.spherical\n    ? '$centerSphere'\n    : '$center';\n\n  const wKey = this._geoComparison || $withinCmd;\n  conds[wKey] = {};\n  conds[wKey][type] = [val.center, val.radius];\n\n  if ('unique' in val)\n    conds[wKey].$uniqueDocs = !!val.unique;\n\n  return this;\n};\n\n/**\n * Specifies a `$near` or `$nearSphere` condition\n *\n * These operators return documents sorted by distance.\n *\n * #### Example:\n *\n *     query.where('loc').near({ center: [10, 10] });\n *     query.where('loc').near({ center: [10, 10], maxDistance: 5 });\n *     query.where('loc').near({ center: [10, 10], maxDistance: 5, spherical: true });\n *     query.near('loc', { center: [10, 10], maxDistance: 5 });\n *     query.near({ center: { type: 'Point', coordinates: [..] }})\n *     query.near().geometry({ type: 'Point', coordinates: [..] })\n *\n * @param {String} [path]\n * @param {Object} val\n * @return {Query} this\n * @see http://www.mongodb.org/display/DOCS/Geospatial+Indexing\n * @api public\n */\n\nQuery.prototype.near = function near() {\n  let path, val;\n\n  this._geoComparison = '$near';\n\n  if (0 === arguments.length) {\n    return this;\n  } else if (1 === arguments.length) {\n    this._ensurePath('near');\n    path = this._path;\n    val = arguments[0];\n  } else if (2 === arguments.length) {\n    path = arguments[0];\n    val = arguments[1];\n  } else {\n    throw new TypeError('Invalid argument');\n  }\n\n  if (!val.center) {\n    throw new Error('center is required');\n  }\n\n  const conds = this._conditions[path] || (this._conditions[path] = {});\n\n  const type = val.spherical\n    ? '$nearSphere'\n    : '$near';\n\n  // center could be a GeoJSON object or an Array\n  if (Array.isArray(val.center)) {\n    conds[type] = val.center;\n\n    const radius = 'maxDistance' in val\n      ? val.maxDistance\n      : null;\n\n    if (null != radius) {\n      conds.$maxDistance = radius;\n    }\n    if (null != val.minDistance) {\n      conds.$minDistance = val.minDistance;\n    }\n  } else {\n    // GeoJSON?\n    if (val.center.type != 'Point' || !Array.isArray(val.center.coordinates)) {\n      throw new Error(util.format('Invalid GeoJSON specified for %s', type));\n    }\n    conds[type] = { $geometry: val.center };\n\n    // MongoDB 2.6 insists on maxDistance being in $near / $nearSphere\n    if ('maxDistance' in val) {\n      conds[type]['$maxDistance'] = val.maxDistance;\n    }\n    if ('minDistance' in val) {\n      conds[type]['$minDistance'] = val.minDistance;\n    }\n  }\n\n  return this;\n};\n\n/**\n * Declares an intersects query for `geometry()`.\n *\n * #### Example:\n *\n *     query.where('path').intersects().geometry({\n *         type: 'LineString'\n *       , coordinates: [[180.0, 11.0], [180, 9.0]]\n *     })\n *\n *     query.where('path').intersects({\n *         type: 'LineString'\n *       , coordinates: [[180.0, 11.0], [180, 9.0]]\n *     })\n *\n * @param {Object} [arg]\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.intersects = function intersects() {\n  // opinionated, must be used after where\n  this._ensurePath('intersects');\n\n  this._geoComparison = '$geoIntersects';\n\n  if (0 === arguments.length) {\n    return this;\n  }\n\n  const area = arguments[0];\n\n  if (null != area && area.type && area.coordinates)\n    return this.geometry(area);\n\n  throw new TypeError('Invalid argument');\n};\n\n/**\n * Specifies a `$geometry` condition\n *\n * #### Example:\n *\n *     var polyA = [[[ 10, 20 ], [ 10, 40 ], [ 30, 40 ], [ 30, 20 ]]]\n *     query.where('loc').within().geometry({ type: 'Polygon', coordinates: polyA })\n *\n *     // or\n *     var polyB = [[ 0, 0 ], [ 1, 1 ]]\n *     query.where('loc').within().geometry({ type: 'LineString', coordinates: polyB })\n *\n *     // or\n *     var polyC = [ 0, 0 ]\n *     query.where('loc').within().geometry({ type: 'Point', coordinates: polyC })\n *\n *     // or\n *     query.where('loc').intersects().geometry({ type: 'Point', coordinates: polyC })\n *\n * #### Note:\n *\n * `geometry()` **must** come after either `intersects()` or `within()`.\n *\n * The `object` argument must contain `type` and `coordinates` properties.\n * - type {String}\n * - coordinates {Array}\n *\n * The most recent path passed to `where()` is used.\n *\n * @param {Object} object Must contain a `type` property which is a String and a `coordinates` property which is an Array. See the examples.\n * @return {Query} this\n * @see http://docs.mongodb.org/manual/release-notes/2.4/#new-geospatial-indexes-with-geojson-and-improved-spherical-geometry\n * @see http://www.mongodb.org/display/DOCS/Geospatial+Indexing\n * @see $geometry http://docs.mongodb.org/manual/reference/operator/geometry/\n * @api public\n */\n\nQuery.prototype.geometry = function geometry() {\n  if (!('$within' == this._geoComparison ||\n        '$geoWithin' == this._geoComparison ||\n        '$near' == this._geoComparison ||\n        '$geoIntersects' == this._geoComparison)) {\n    throw new Error('geometry() must come after `within()`, `intersects()`, or `near()');\n  }\n\n  let val, path;\n\n  if (1 === arguments.length) {\n    this._ensurePath('geometry');\n    path = this._path;\n    val = arguments[0];\n  } else {\n    throw new TypeError('Invalid argument');\n  }\n\n  if (!(val.type && Array.isArray(val.coordinates))) {\n    throw new TypeError('Invalid argument');\n  }\n\n  const conds = this._conditions[path] || (this._conditions[path] = {});\n  conds[this._geoComparison] = { $geometry: val };\n\n  return this;\n};\n\n// end spatial\n\n/**\n * Specifies which document fields to include or exclude\n *\n * #### String syntax\n *\n * When passing a string, prefixing a path with `-` will flag that path as excluded. When a path does not have the `-` prefix, it is included.\n *\n * #### Example:\n *\n *     // include a and b, exclude c\n *     query.select('a b -c');\n *\n *     // or you may use object notation, useful when\n *     // you have keys already prefixed with a \"-\"\n *     query.select({a: 1, b: 1, c: 0});\n *\n * #### Note:\n *\n * Cannot be used with `distinct()`\n *\n * @param {Object|String} arg\n * @return {Query} this\n * @see SchemaType\n * @api public\n */\n\nQuery.prototype.select = function select() {\n  let arg = arguments[0];\n  if (!arg) return this;\n\n  if (arguments.length !== 1) {\n    throw new Error('Invalid select: select only takes 1 argument');\n  }\n\n  this._validate('select');\n\n  const fields = this._fields || (this._fields = {});\n  const type = typeof arg;\n  let i, len;\n\n  if (('string' == type || utils.isArgumentsObject(arg)) &&\n    'number' == typeof arg.length || Array.isArray(arg)) {\n    if ('string' == type)\n      arg = arg.split(/\\s+/);\n\n    for (i = 0, len = arg.length; i < len; ++i) {\n      let field = arg[i];\n      if (!field) continue;\n      const include = '-' == field[0] ? 0 : 1;\n      if (include === 0) field = field.substring(1);\n      fields[field] = include;\n    }\n\n    return this;\n  }\n\n  if (utils.isObject(arg)) {\n    const keys = utils.keys(arg);\n    for (i = 0; i < keys.length; ++i) {\n      fields[keys[i]] = arg[keys[i]];\n    }\n    return this;\n  }\n\n  throw new TypeError('Invalid select() argument. Must be string or object.');\n};\n\n/**\n * Specifies a $slice condition for a `path`\n *\n * #### Example:\n *\n *     query.slice('comments', 5)\n *     query.slice('comments', -5)\n *     query.slice('comments', [10, 5])\n *     query.where('comments').slice(5)\n *     query.where('comments').slice([-10, 5])\n *\n * @param {String} [path]\n * @param {Number} val number/range of elements to slice\n * @return {Query} this\n * @see mongodb http://www.mongodb.org/display/DOCS/Retrieving+a+Subset+of+Fields#RetrievingaSubsetofFields-RetrievingaSubrangeofArrayElements\n * @api public\n */\n\nQuery.prototype.slice = function() {\n  if (0 === arguments.length)\n    return this;\n\n  this._validate('slice');\n\n  let path, val;\n\n  if (1 === arguments.length) {\n    const arg = arguments[0];\n    if (typeof arg === 'object' && !Array.isArray(arg)) {\n      const keys = Object.keys(arg);\n      const numKeys = keys.length;\n      for (let i = 0; i < numKeys; ++i) {\n        this.slice(keys[i], arg[keys[i]]);\n      }\n      return this;\n    }\n    this._ensurePath('slice');\n    path = this._path;\n    val = arguments[0];\n  } else if (2 === arguments.length) {\n    if ('number' === typeof arguments[0]) {\n      this._ensurePath('slice');\n      path = this._path;\n      val = [arguments[0], arguments[1]];\n    } else {\n      path = arguments[0];\n      val = arguments[1];\n    }\n  } else if (3 === arguments.length) {\n    path = arguments[0];\n    val = [arguments[1], arguments[2]];\n  }\n\n  const myFields = this._fields || (this._fields = {});\n  myFields[path] = { $slice: val };\n  return this;\n};\n\n/**\n * Sets the sort order\n *\n * If an object is passed, values allowed are 'asc', 'desc', 'ascending', 'descending', 1, and -1.\n *\n * If a string is passed, it must be a space delimited list of path names. The sort order of each path is ascending unless the path name is prefixed with `-` which will be treated as descending.\n *\n * #### Example:\n *\n *     // these are equivalent\n *     query.sort({ field: 'asc', test: -1 });\n *     query.sort('field -test');\n *     query.sort([['field', 1], ['test', -1]]);\n *\n * #### Note:\n *\n *  - The array syntax `.sort([['field', 1], ['test', -1]])` can only be used with [mongodb driver >= 2.0.46](https://github.com/mongodb/node-mongodb-native/blob/2.1/HISTORY.md#2046-2015-10-15).\n *  - Cannot be used with `distinct()`\n *\n * @param {Object|String|Array} arg\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.sort = function(arg) {\n  if (!arg) return this;\n  let i, len, field;\n\n  this._validate('sort');\n\n  const type = typeof arg;\n\n  // .sort([['field', 1], ['test', -1]])\n  if (Array.isArray(arg)) {\n    len = arg.length;\n    for (i = 0; i < arg.length; ++i) {\n      if (!Array.isArray(arg[i])) {\n        throw new Error('Invalid sort() argument, must be array of arrays');\n      }\n      _pushArr(this.options, arg[i][0], arg[i][1]);\n    }\n    return this;\n  }\n\n  // .sort('field -test')\n  if (1 === arguments.length && 'string' == type) {\n    arg = arg.split(/\\s+/);\n    len = arg.length;\n    for (i = 0; i < len; ++i) {\n      field = arg[i];\n      if (!field) continue;\n      const ascend = '-' == field[0] ? -1 : 1;\n      if (ascend === -1) field = field.substring(1);\n      push(this.options, field, ascend);\n    }\n\n    return this;\n  }\n\n  // .sort({ field: 1, test: -1 })\n  if (utils.isObject(arg)) {\n    const keys = utils.keys(arg);\n    for (i = 0; i < keys.length; ++i) {\n      field = keys[i];\n      push(this.options, field, arg[field]);\n    }\n\n    return this;\n  }\n\n  if (typeof Map !== 'undefined' && arg instanceof Map) {\n    _pushMap(this.options, arg);\n    return this;\n  }\n  throw new TypeError('Invalid sort() argument. Must be a string, object, or array.');\n};\n\n/*!\n * @ignore\n */\n\nconst _validSortValue = {\n  1: 1,\n  '-1': -1,\n  asc: 1,\n  ascending: 1,\n  desc: -1,\n  descending: -1\n};\n\nfunction push(opts, field, value) {\n  if (Array.isArray(opts.sort)) {\n    throw new TypeError('Can\\'t mix sort syntaxes. Use either array or object:' +\n      '\\n- `.sort([[\\'field\\', 1], [\\'test\\', -1]])`' +\n      '\\n- `.sort({ field: 1, test: -1 })`');\n  }\n\n  let s;\n  if (value && value.$meta) {\n    s = opts.sort || (opts.sort = {});\n    s[field] = { $meta: value.$meta };\n    return;\n  }\n\n  s = opts.sort || (opts.sort = {});\n  let val = String(value || 1).toLowerCase();\n  val = _validSortValue[val];\n  if (!val) throw new TypeError('Invalid sort value: { ' + field + ': ' + value + ' }');\n\n  s[field] = val;\n}\n\nfunction _pushArr(opts, field, value) {\n  opts.sort = opts.sort || [];\n  if (!Array.isArray(opts.sort)) {\n    throw new TypeError('Can\\'t mix sort syntaxes. Use either array or object:' +\n      '\\n- `.sort([[\\'field\\', 1], [\\'test\\', -1]])`' +\n      '\\n- `.sort({ field: 1, test: -1 })`');\n  }\n\n  let val = String(value || 1).toLowerCase();\n  val = _validSortValue[val];\n  if (!val) throw new TypeError('Invalid sort value: [ ' + field + ', ' + value + ' ]');\n\n  opts.sort.push([field, val]);\n}\n\nfunction _pushMap(opts, map) {\n  opts.sort = opts.sort || new Map();\n  if (!(opts.sort instanceof Map)) {\n    throw new TypeError('Can\\'t mix sort syntaxes. Use either array or ' +\n      'object or map consistently');\n  }\n  map.forEach(function(value, key) {\n    let val = String(value || 1).toLowerCase();\n    val = _validSortValue[val];\n    if (!val) throw new TypeError('Invalid sort value: < ' + key + ': ' + value + ' >');\n\n    opts.sort.set(key, val);\n  });\n}\n\n\n/**\n * Specifies the limit option.\n *\n * #### Example:\n *\n *     query.limit(20)\n *\n * #### Note:\n *\n * Cannot be used with `distinct()`\n *\n * @method limit\n * @memberOf Query\n * @param {Number} val\n * @see mongodb http://www.mongodb.org/display/DOCS/Advanced+Queries#AdvancedQueries-%7B%7Blimit%28%29%7D%7D\n * @api public\n */\n/**\n * Specifies the skip option.\n *\n * #### Example:\n *\n *     query.skip(100).limit(20)\n *\n * #### Note:\n *\n * Cannot be used with `distinct()`\n *\n * @method skip\n * @memberOf Query\n * @param {Number} val\n * @see mongodb http://www.mongodb.org/display/DOCS/Advanced+Queries#AdvancedQueries-%7B%7Bskip%28%29%7D%7D\n * @api public\n */\n/**\n * Specifies the batchSize option.\n *\n * #### Example:\n *\n *     query.batchSize(100)\n *\n * #### Note:\n *\n * Cannot be used with `distinct()`\n *\n * @method batchSize\n * @memberOf Query\n * @param {Number} val\n * @see mongodb http://www.mongodb.org/display/DOCS/Advanced+Queries#AdvancedQueries-%7B%7BbatchSize%28%29%7D%7D\n * @api public\n */\n/**\n * Specifies the `comment` option.\n *\n * #### Example:\n *\n *     query.comment('login query')\n *\n * #### Note:\n *\n * Cannot be used with `distinct()`\n *\n * @method comment\n * @memberOf Query\n * @param {Number} val\n * @see mongodb http://www.mongodb.org/display/DOCS/Advanced+Queries#AdvancedQueries-%24comment\n * @api public\n */\n\n/*!\n * limit, skip, batchSize, comment\n *\n * Sets these associated options.\n *\n *     query.comment('feed query');\n */\n\n['limit', 'skip', 'batchSize', 'comment'].forEach(function(method) {\n  Query.prototype[method] = function(v) {\n    this._validate(method);\n    this.options[method] = v;\n    return this;\n  };\n});\n\n/**\n * Specifies the maxTimeMS option.\n *\n * #### Example:\n *\n *     query.maxTime(100)\n *     query.maxTimeMS(100)\n *\n * @method maxTime\n * @memberOf Query\n * @param {Number} ms\n * @see mongodb http://docs.mongodb.org/manual/reference/operator/meta/maxTimeMS/#op._S_maxTimeMS\n * @api public\n */\n\nQuery.prototype.maxTime = Query.prototype.maxTimeMS = function(ms) {\n  this._validate('maxTime');\n  this.options.maxTimeMS = ms;\n  return this;\n};\n\n/**\n * Sets query hints.\n *\n * #### Example:\n *\n *     query.hint({ indexA: 1, indexB: -1});\n *     query.hint('indexA_1_indexB_1');\n *\n * #### Note:\n *\n * Cannot be used with `distinct()`\n *\n * @param {Object|string} val a hint object or the index name\n * @return {Query} this\n * @see mongodb http://www.mongodb.org/display/DOCS/Advanced+Queries#AdvancedQueries-%24hint\n * @api public\n */\n\nQuery.prototype.hint = function() {\n  if (0 === arguments.length) return this;\n\n  this._validate('hint');\n\n  const arg = arguments[0];\n  if (utils.isObject(arg)) {\n    const hint = this.options.hint || (this.options.hint = {});\n\n    // must keep object keys in order so don't use Object.keys()\n    for (const k in arg) {\n      hint[k] = arg[k];\n    }\n\n    return this;\n  }\n  if (typeof arg === 'string') {\n    this.options.hint = arg;\n    return this;\n  }\n\n  throw new TypeError('Invalid hint. ' + arg);\n};\n\n/**\n * Requests acknowledgement that this operation has been persisted to MongoDB's\n * on-disk journal.\n * This option is only valid for operations that write to the database:\n *\n * - `deleteOne()`\n * - `deleteMany()`\n * - `findOneAndDelete()`\n * - `findOneAndUpdate()`\n * - `updateOne()`\n * - `updateMany()`\n *\n * Defaults to the `j` value if it is specified in writeConcern options\n *\n * #### Example:\n *\n *     mquery().w(2).j(true).wtimeout(2000);\n *\n * @method j\n * @memberOf Query\n * @instance\n * @param {boolean} val\n * @see mongodb https://docs.mongodb.com/manual/reference/write-concern/#j-option\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.j = function j(val) {\n  this.options.j = val;\n  return this;\n};\n\n/**\n * Sets the slaveOk option. _Deprecated_ in MongoDB 2.2 in favor of read preferences.\n *\n * #### Example:\n *\n *     query.slaveOk() // true\n *     query.slaveOk(true)\n *     query.slaveOk(false)\n *\n * @deprecated use read() preferences instead if on mongodb >= 2.2\n * @param {Boolean} v defaults to true\n * @see mongodb http://docs.mongodb.org/manual/applications/replication/#read-preference\n * @see read()\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.slaveOk = function(v) {\n  this.options.slaveOk = arguments.length ? !!v : true;\n  return this;\n};\n\n/**\n * Sets the readPreference option for the query.\n *\n * #### Example:\n *\n *     new Query().read('primary')\n *     new Query().read('p')  // same as primary\n *\n *     new Query().read('primaryPreferred')\n *     new Query().read('pp') // same as primaryPreferred\n *\n *     new Query().read('secondary')\n *     new Query().read('s')  // same as secondary\n *\n *     new Query().read('secondaryPreferred')\n *     new Query().read('sp') // same as secondaryPreferred\n *\n *     new Query().read('nearest')\n *     new Query().read('n')  // same as nearest\n *\n *     // you can also use mongodb.ReadPreference class to also specify tags\n *     new Query().read(mongodb.ReadPreference('secondary', [{ dc:'sf', s: 1 },{ dc:'ma', s: 2 }]))\n *\n *     new Query().setReadPreference('primary') // alias of .read()\n *\n * #### Preferences:\n *\n *     primary - (default)  Read from primary only. Operations will produce an error if primary is unavailable. Cannot be combined with tags.\n *     secondary            Read from secondary if available, otherwise error.\n *     primaryPreferred     Read from primary if available, otherwise a secondary.\n *     secondaryPreferred   Read from a secondary if available, otherwise read from the primary.\n *     nearest              All operations read from among the nearest candidates, but unlike other modes, this option will include both the primary and all secondaries in the random selection.\n *\n * Aliases\n *\n *     p   primary\n *     pp  primaryPreferred\n *     s   secondary\n *     sp  secondaryPreferred\n *     n   nearest\n *\n * Read more about how to use read preferences [here](http://docs.mongodb.org/manual/applications/replication/#read-preference) and [here](http://mongodb.github.com/node-mongodb-native/driver-articles/anintroductionto1_1and2_2.html#read-preferences).\n *\n * @param {String|ReadPreference} pref one of the listed preference options or their aliases\n * @see mongodb http://docs.mongodb.org/manual/applications/replication/#read-preference\n * @see driver http://mongodb.github.com/node-mongodb-native/driver-articles/anintroductionto1_1and2_2.html#read-preferences\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.read = Query.prototype.setReadPreference = function(pref) {\n  if (arguments.length > 1 && !Query.prototype.read.deprecationWarningIssued) {\n    console.error('Deprecation warning: \\'tags\\' argument is not supported anymore in Query.read() method. Please use mongodb.ReadPreference object instead.');\n    Query.prototype.read.deprecationWarningIssued = true;\n  }\n  this.options.readPreference = utils.readPref(pref);\n  return this;\n};\n\n/**\n * Sets the readConcern option for the query.\n *\n * #### Example:\n *\n *     new Query().readConcern('local')\n *     new Query().readConcern('l')  // same as local\n *\n *     new Query().readConcern('available')\n *     new Query().readConcern('a')  // same as available\n *\n *     new Query().readConcern('majority')\n *     new Query().readConcern('m')  // same as majority\n *\n *     new Query().readConcern('linearizable')\n *     new Query().readConcern('lz') // same as linearizable\n *\n *     new Query().readConcern('snapshot')\n *     new Query().readConcern('s')  // same as snapshot\n *\n *     new Query().r('s') // r is alias of readConcern\n *\n *\n * #### Read Concern Level:\n *\n *     local         MongoDB 3.2+ The query returns from the instance with no guarantee guarantee that the data has been written to a majority of the replica set members (i.e. may be rolled back).\n *     available     MongoDB 3.6+ The query returns from the instance with no guarantee guarantee that the data has been written to a majority of the replica set members (i.e. may be rolled back).\n *     majority      MongoDB 3.2+ The query returns the data that has been acknowledged by a majority of the replica set members. The documents returned by the read operation are durable, even in the event of failure.\n *     linearizable  MongoDB 3.4+ The query returns data that reflects all successful majority-acknowledged writes that completed prior to the start of the read operation. The query may wait for concurrently executing writes to propagate to a majority of replica set members before returning results.\n *     snapshot      MongoDB 4.0+ Only available for operations within multi-document transactions. Upon transaction commit with write concern \"majority\", the transaction operations are guaranteed to have read from a snapshot of majority-committed data.\n *\n * Aliases\n *\n *     l   local\n *     a   available\n *     m   majority\n *     lz  linearizable\n *     s   snapshot\n *\n * Read more about how to use read concern [here](https://docs.mongodb.com/manual/reference/read-concern/).\n *\n * @param {String} level one of the listed read concern level or their aliases\n * @see mongodb https://docs.mongodb.com/manual/reference/read-concern/\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.readConcern = Query.prototype.r = function(level) {\n  this.options.readConcern = utils.readConcern(level);\n  return this;\n};\n\n/**\n * Sets tailable option.\n *\n * #### Example:\n *\n *     query.tailable() <== true\n *     query.tailable(true)\n *     query.tailable(false)\n *\n * #### Note:\n *\n * Cannot be used with `distinct()`\n *\n * @param {Boolean} v defaults to true\n * @see mongodb http://www.mongodb.org/display/DOCS/Tailable+Cursors\n * @api public\n */\n\nQuery.prototype.tailable = function() {\n  this._validate('tailable');\n\n  this.options.tailable = arguments.length\n    ? !!arguments[0]\n    : true;\n\n  return this;\n};\n\n/**\n * Sets the specified number of `mongod` servers, or tag set of `mongod` servers,\n * that must acknowledge this write before this write is considered successful.\n * This option is only valid for operations that write to the database:\n *\n * - `deleteOne()`\n * - `deleteMany()`\n * - `findOneAndDelete()`\n * - `findOneAndUpdate()`\n * - `updateOne()`\n * - `updateMany()`\n *\n * Defaults to the `w` value if it is specified in writeConcern options\n *\n * #### Example:\n *\n *     mquery().writeConcern(0)\n *     mquery().writeConcern(1)\n *     mquery().writeConcern({ w: 1, j: true, wtimeout: 2000 })\n *     mquery().writeConcern('majority')\n *     mquery().writeConcern('m') // same as majority\n *     mquery().writeConcern('tagSetName') // if the tag set is 'm', use .writeConcern({ w: 'm' }) instead\n *     mquery().w(1) // w is alias of writeConcern\n *\n * @method writeConcern\n * @memberOf Query\n * @instance\n * @param {String|number|object} concern 0 for fire-and-forget, 1 for acknowledged by one server, 'majority' for majority of the replica set, or [any of the more advanced options](https://docs.mongodb.com/manual/reference/write-concern/#w-option).\n * @see mongodb https://docs.mongodb.com/manual/reference/write-concern/#w-option\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.writeConcern = Query.prototype.w = function writeConcern(concern) {\n  if ('object' === typeof concern) {\n    if ('undefined' !== typeof concern.j) this.options.j = concern.j;\n    if ('undefined' !== typeof concern.w) this.options.w = concern.w;\n    if ('undefined' !== typeof concern.wtimeout) this.options.wtimeout = concern.wtimeout;\n  } else {\n    this.options.w = 'm' === concern ? 'majority' : concern;\n  }\n  return this;\n};\n\n/**\n * Specifies a time limit, in milliseconds, for the write concern.\n * If `ms > 1`, it is maximum amount of time to wait for this write\n * to propagate through the replica set before this operation fails.\n * The default is `0`, which means no timeout.\n *\n * This option is only valid for operations that write to the database:\n *\n * - `deleteOne()`\n * - `deleteMany()`\n * - `findOneAndDelete()`\n * - `findOneAndUpdate()`\n * - `updateOne()`\n * - `updateMany()`\n *\n * Defaults to `wtimeout` value if it is specified in writeConcern\n *\n * #### Example:\n *\n *     mquery().w(2).j(true).wtimeout(2000)\n *\n * @method wtimeout\n * @memberOf Query\n * @instance\n * @param {number} ms number of milliseconds to wait\n * @see mongodb https://docs.mongodb.com/manual/reference/write-concern/#wtimeout\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.wtimeout = Query.prototype.wTimeout = function wtimeout(ms) {\n  this.options.wtimeout = ms;\n  return this;\n};\n\n/**\n * Merges another Query or conditions object into this one.\n *\n * When a Query is passed, conditions, field selection and options are merged.\n *\n * @param {Query|Object} source\n * @return {Query} this\n */\n\nQuery.prototype.merge = function(source) {\n  if (!source)\n    return this;\n\n  if (!Query.canMerge(source))\n    throw new TypeError('Invalid argument. Expected instanceof mquery or plain object');\n\n  if (source instanceof Query) {\n    // if source has a feature, apply it to ourselves\n\n    if (source._conditions) {\n      utils.merge(this._conditions, source._conditions);\n    }\n\n    if (source._fields) {\n      this._fields || (this._fields = {});\n      utils.merge(this._fields, source._fields);\n    }\n\n    if (source.options) {\n      this.options || (this.options = {});\n      utils.merge(this.options, source.options);\n    }\n\n    if (source._updateDoc) {\n      this._updateDoc || (this._updateDoc = {});\n      utils.mergeClone(this._updateDoc, source._updateDoc);\n    }\n\n    if (source._distinctDoc) {\n      this._distinctDoc = source._distinctDoc;\n    }\n\n    return this;\n  }\n\n  // plain object\n  utils.merge(this._conditions, source);\n\n  return this;\n};\n\n/**\n * Finds documents.\n *\n * #### Example:\n *\n *     query.find()\n *     await query.find()\n *     await query.find({ name: 'Burning Lights' })\n *\n * @param {Object} [criteria] mongodb selector\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.find = function(criteria) {\n  this.op = 'find';\n\n  if (Query.canMerge(criteria)) {\n    this.merge(criteria);\n  }\n\n  return this;\n};\n\n/**\n * Executes a `find` Query\n * @returns the result\n */\nQuery.prototype._find = async function _find() {\n  const conds = this._conditions;\n  const options = this._optionsForExec();\n\n  if (this.$useProjection) {\n    options.projection = this._fieldsForExec();\n  } else {\n    options.fields = this._fieldsForExec();\n  }\n\n  debug('_find', this._collection.collectionName, conds, options);\n\n  return this._collection.find(conds, options);\n};\n\n/**\n * Returns the query cursor\n *\n * #### Examples:\n *\n *     query.find().cursor();\n *     query.cursor({ name: 'Burning Lights' });\n *\n * @param {Object} [criteria] mongodb selector\n * @return {Object} cursor\n * @api public\n */\n\nQuery.prototype.cursor = function cursor(criteria) {\n  if (this.op) {\n    if (this.op !== 'find') {\n      throw new TypeError('.cursor only support .find method');\n    }\n  } else {\n    this.find(criteria);\n  }\n\n  const conds = this._conditions;\n  const options = this._optionsForExec();\n\n  if (this.$useProjection) {\n    options.projection = this._fieldsForExec();\n  } else {\n    options.fields = this._fieldsForExec();\n  }\n\n  debug('findCursor', this._collection.collectionName, conds, options);\n  return this._collection.findCursor(conds, options);\n};\n\n/**\n * Executes the query as a findOne() operation.\n *\n * #### Example:\n *\n *     query.findOne().where('name', /^Burning/);\n *\n *     query.findOne({ name: /^Burning/ })\n *\n *     await query.findOne({ name: /^Burning/ }); // executes\n *\n * @param {Object|Query} [criteria] mongodb selector\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.findOne = function(criteria) {\n  this.op = 'findOne';\n\n  if (Query.canMerge(criteria)) {\n    this.merge(criteria);\n  }\n\n  return this;\n};\n\n/**\n * Executes a `findOne` Query\n * @returns the results\n */\nQuery.prototype._findOne = async function _findOne() {\n  const conds = this._conditions;\n  const options = this._optionsForExec();\n\n  if (this.$useProjection) {\n    options.projection = this._fieldsForExec();\n  } else {\n    options.fields = this._fieldsForExec();\n  }\n\n  debug('findOne', this._collection.collectionName, conds, options);\n\n  return this._collection.findOne(conds, options);\n};\n\n/**\n * Exectues the query as a count() operation.\n *\n * #### Example:\n *\n *     query.count().where('color', 'black').exec();\n *\n *     query.count({ color: 'black' })\n *\n *     await query.count({ color: 'black' });\n *\n *     const doc = await query.where('color', 'black').count();\n *     console.log('there are %d kittens', count);\n *\n * @param {Object} [criteria] mongodb selector\n * @return {Query} this\n * @see mongodb http://www.mongodb.org/display/DOCS/Aggregation#Aggregation-Count\n * @api public\n */\n\nQuery.prototype.count = function(criteria) {\n  this.op = 'count';\n  this._validate();\n\n  if (Query.canMerge(criteria)) {\n    this.merge(criteria);\n  }\n\n  return this;\n};\n\n/**\n * Executes a `count` Query\n * @returns the results\n */\nQuery.prototype._count = async function _count() {\n  const conds = this._conditions,\n      options = this._optionsForExec();\n\n  debug('count', this._collection.collectionName, conds, options);\n\n  return this._collection.count(conds, options);\n};\n\n/**\n * Declares or executes a distinct() operation.\n *\n * #### Example:\n *\n *     await distinct(criteria, field)\n *     distinct(criteria, field)\n *     await distinct(field)\n *     distinct(field)\n *     await distinct()\n *     distinct()\n *\n * @param {Object|Query} [criteria]\n * @param {String} [field]\n * @return {Query} this\n * @see mongodb http://www.mongodb.org/display/DOCS/Aggregation#Aggregation-Distinct\n * @api public\n */\n\nQuery.prototype.distinct = function(criteria, field) {\n  this.op = 'distinct';\n  this._validate();\n\n  if (!field && typeof criteria === 'string') {\n    field = criteria;\n    criteria = undefined;\n  }\n\n  if ('string' == typeof field) {\n    this._distinctDoc = field;\n  }\n\n  if (Query.canMerge(criteria)) {\n    this.merge(criteria);\n  }\n\n  return this;\n};\n\n/**\n * Executes a `distinct` Query\n * @returns the results\n */\nQuery.prototype._distinct = async function _distinct() {\n  if (!this._distinctDoc) {\n    throw new Error('No value for `distinct` has been declared');\n  }\n\n  const conds = this._conditions,\n      options = this._optionsForExec();\n\n  debug('distinct', this._collection.collectionName, conds, options);\n\n  return this._collection.distinct(this._distinctDoc, conds, options);\n};\n\n/**\n * Declare and/or execute this query as an `updateMany()` operation. This function will update _all_ documents that match\n * `criteria`, rather than just the first one.\n *\n * _All paths passed that are not $atomic operations will become $set ops._\n *\n * #### Example:\n *\n *     // Update every document whose `title` contains 'test'\n *     mquery().updateMany({ title: /test/ }, { year: 2017 })\n *\n * @param {Object} [criteria]\n * @param {Object} [doc] the update command\n * @param {Object} [options]\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.updateMany = function updateMany(criteria, doc, options) {\n  if (arguments.length === 1) {\n    doc = criteria;\n    criteria = options = undefined;\n  }\n\n  return _update(this, 'updateMany', criteria, doc, options);\n};\n\n/**\n * Executes a `updateMany` Query\n * @returns the results\n */\nQuery.prototype._updateMany = async function() {\n  return _updateExec(this, 'updateMany');\n};\n\n/**\n * Declare and/or execute this query as an `updateOne()` operation. This function will _always_ update just one document,\n * regardless of the `multi` option.\n *\n * _All paths passed that are not $atomic operations will become $set ops._\n *\n * #### Example:\n *\n *     // Update the first document whose `title` contains 'test'\n *     mquery().updateMany({ title: /test/ }, { year: 2017 })\n *\n * @param {Object} [criteria]\n * @param {Object} [doc] the update command\n * @param {Object} [options]\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.updateOne = function updateOne(criteria, doc, options) {\n  if (arguments.length === 1) {\n    doc = criteria;\n    criteria = options = undefined;\n  }\n\n  return _update(this, 'updateOne', criteria, doc, options);\n};\n\n/**\n * Executes a `updateOne` Query\n * @returns the results\n */\nQuery.prototype._updateOne = async function() {\n  return _updateExec(this, 'updateOne');\n};\n\n/**\n * Declare and/or execute this query as an `replaceOne()` operation. Similar\n * to `updateOne()`, except `replaceOne()` is not allowed to use atomic\n * modifiers (`$set`, `$push`, etc.). Calling `replaceOne()` will always\n * replace the existing doc.\n *\n * #### Example:\n *\n *     // Replace the document with `_id` 1 with `{ _id: 1, year: 2017 }`\n *     mquery().replaceOne({ _id: 1 }, { year: 2017 })\n *\n * @param {Object} [criteria]\n * @param {Object} [doc] the update command\n * @param {Object} [options]\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.replaceOne = function replaceOne(criteria, doc, options) {\n  if (arguments.length === 1) {\n    doc = criteria;\n    criteria = options = undefined;\n  }\n\n  this.setOptions({ overwrite: true });\n  return _update(this, 'replaceOne', criteria, doc, options);\n};\n\n/**\n * Executes a `replaceOne` Query\n * @returns the results\n */\nQuery.prototype._replaceOne = async function() {\n  return _updateExec(this, 'replaceOne');\n};\n\n/*!\n * Internal helper for updateMany, updateOne\n */\n\nfunction _update(query, op, criteria, doc, options) {\n  query.op = op;\n\n  if (Query.canMerge(criteria)) {\n    query.merge(criteria);\n  }\n\n  if (doc) {\n    query._mergeUpdate(doc);\n  }\n\n  if (utils.isObject(options)) {\n    // { overwrite: true }\n    query.setOptions(options);\n  }\n\n  return query;\n}\n\n/**\n * Helper for de-duplicating \"update*\" functions\n * @param {Query} query The Query Object (replacement for \"this\")\n * @param {String} op The Operation to be done\n * @returns the results\n */\nasync function _updateExec(query, op) {\n  const options = query._optionsForExec();\n\n  const criteria = query._conditions;\n  const doc = query._updateForExec();\n\n  debug('update', query._collection.collectionName, criteria, doc, options);\n\n  return query._collection[op](criteria, doc, options);\n}\n\n/**\n * Declare and/or execute this query as a `deleteOne()` operation.\n *\n * #### Example:\n *\n *     await mquery(collection).deleteOne({ artist: 'Anne Murray' })\n *\n * @param {Object|Query} [criteria] mongodb selector\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.deleteOne = function(criteria) {\n  this.op = 'deleteOne';\n\n  if (Query.canMerge(criteria)) {\n    this.merge(criteria);\n  }\n\n  return this;\n};\n\n/**\n * Executes a `deleteOne` Query\n * @returns the results\n */\nQuery.prototype._deleteOne = async function() {\n  const options = this._optionsForExec();\n  delete options.justOne;\n\n  const conds = this._conditions;\n\n  debug('deleteOne', this._collection.collectionName, conds, options);\n\n  return this._collection.deleteOne(conds, options);\n};\n\n/**\n * Declare and/or execute this query as a `deleteMany()` operation. Always deletes\n * _every_ document that matches `criteria`.\n *\n * #### Example:\n *\n *     await mquery(collection).deleteMany({ artist: 'Anne Murray' })\n *\n * @param {Object|Query} [criteria] mongodb selector\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.deleteMany = function(criteria) {\n  this.op = 'deleteMany';\n\n  if (Query.canMerge(criteria)) {\n    this.merge(criteria);\n  }\n\n  return this;\n};\n\n/**\n * Executes a `deleteMany` Query\n * @returns the results\n */\nQuery.prototype._deleteMany = async function() {\n  const options = this._optionsForExec();\n  delete options.justOne;\n\n  const conds = this._conditions;\n\n  debug('deleteOne', this._collection.collectionName, conds, options);\n\n  return this._collection.deleteMany(conds, options);\n};\n\n/**\n * Issues a mongodb [findAndModify](http://www.mongodb.org/display/DOCS/findAndModify+Command) update command.\n *\n * Finds a matching document, updates it according to the `update` arg, passing any `options`, and returns the found document (if any).\n *\n * #### Available options\n *\n * - `new`: bool - true to return the modified document rather than the original. defaults to true\n * - `upsert`: bool - creates the object if it doesn't exist. defaults to false.\n * - `sort`: if multiple docs are found by the conditions, sets the sort order to choose which doc to update\n *\n * #### Examples:\n *\n *     await query.findOneAndUpdate(conditions, update, options) // executes\n *     query.findOneAndUpdate(conditions, update, options)  // returns Query\n *     await query.findOneAndUpdate(conditions, update) // executes\n *     query.findOneAndUpdate(conditions, update)           // returns Query\n *     await query.findOneAndUpdate(update)             // returns Query\n *     query.findOneAndUpdate(update)                       // returns Query\n *     await query.findOneAndUpdate()                     // executes\n *     query.findOneAndUpdate()                             // returns Query\n *\n * @param {Object|Query} [query]\n * @param {Object} [doc]\n * @param {Object} [options]\n * @see mongodb http://www.mongodb.org/display/DOCS/findAndModify+Command\n * @return {Query} this\n * @api public\n */\n\nQuery.prototype.findOneAndUpdate = function(criteria, doc, options) {\n  this.op = 'findOneAndUpdate';\n  this._validate();\n\n  if (arguments.length === 1) {\n    doc = criteria;\n    criteria = options = undefined;\n  }\n\n  if (Query.canMerge(criteria)) {\n    this.merge(criteria);\n  }\n\n  // apply doc\n  if (doc) {\n    this._mergeUpdate(doc);\n  }\n\n  options && this.setOptions(options);\n\n  return this;\n};\n\n/**\n * Executes a `findOneAndUpdate` Query\n * @returns the results\n */\nQuery.prototype._findOneAndUpdate = async function() {\n  const conds = this._conditions;\n  const update = this._updateForExec();\n  const options = this._optionsForExec();\n\n  return this._collection.findOneAndUpdate(conds, update, options);\n};\n\n/**\n * Issues a mongodb [findAndModify](http://www.mongodb.org/display/DOCS/findAndModify+Command) remove command.\n *\n * Finds a matching document, removes it, returning the found document (if any).\n *\n * #### Available options\n *\n * - `sort`: if multiple docs are found by the conditions, sets the sort order to choose which doc to update\n *\n * #### Examples:\n *\n *     await A.where().findOneAndRemove(conditions, options) // executes\n *     A.where().findOneAndRemove(conditions, options)  // return Query\n *     await A.where().findOneAndRemove(conditions) // executes\n *     A.where().findOneAndRemove(conditions) // returns Query\n *     await A.where().findOneAndRemove()   // executes\n *     A.where().findOneAndRemove()           // returns Query\n *     A.where().findOneAndDelete()           // alias of .findOneAndRemove()\n *\n * @param {Object} [conditions]\n * @param {Object} [options]\n * @return {Query} this\n * @see mongodb http://www.mongodb.org/display/DOCS/findAndModify+Command\n * @api public\n */\n\nQuery.prototype.findOneAndRemove = Query.prototype.findOneAndDelete = function(conditions, options) {\n  this.op = 'findOneAndRemove';\n  this._validate();\n\n  // apply conditions\n  if (Query.canMerge(conditions)) {\n    this.merge(conditions);\n  }\n\n  // apply options\n  options && this.setOptions(options);\n\n  return this;\n};\n\n/**\n * Executes a `findOneAndRemove` Query\n * @returns the results\n */\nQuery.prototype._findOneAndRemove = async function() {\n  const options = this._optionsForExec();\n  const conds = this._conditions;\n\n  return this._collection.findOneAndDelete(conds, options);\n};\n\n/**\n * Add trace function that gets called when the query is executed.\n * The function will be called with (method, queryInfo, query) and\n * should return a callback function which will be called\n * with (err, result, millis) when the query is complete.\n *\n * queryInfo is an object containing: {\n *   collectionName: <name of the collection>,\n *   conditions: <query criteria>,\n *   options: <comment, fields, readPreference, etc>,\n *   doc: [document to update, if applicable]\n * }\n *\n * NOTE: Does not trace stream queries.\n *\n * @param {Function} traceFunction\n * @return {Query} this\n * @api public\n */\nQuery.prototype.setTraceFunction = function(traceFunction) {\n  this._traceFunction = traceFunction;\n  return this;\n};\n\n/**\n * Executes the query\n *\n * #### Examples:\n *\n *     query.exec();\n *     await query.exec();\n *     query.exec('update');\n *     await query.exec('find');\n *\n * @param {String|Function} [operation]\n * @api public\n */\n\nQuery.prototype.exec = async function exec(op) {\n  if (typeof op === 'string') {\n    this.op = op;\n  }\n\n  assert.ok(this.op, 'Missing query type: (find, etc)');\n\n  const fnName = '_' + this.op;\n\n  // better error, because default would list it as \"this[fnName] is not a function\"\n  if (typeof this[fnName] !== 'function') {\n    throw new TypeError(`this[${fnName}] is not a function`);\n  }\n\n  return this[fnName]();\n};\n\n/**\n * Executes the query returning a `Promise` which will be\n * resolved with either the doc(s) or rejected with the error.\n *\n * @param {Function} [resolve]\n * @param {Function} [reject]\n * @return {Promise}\n * @api public\n */\n\nQuery.prototype.then = async function(res, rej) {\n  return this.exec().then(res, rej);\n};\n\n/**\n * Returns a cursor for the given `find` query.\n *\n * @throws Error if operation is not a find\n * @returns {Cursor} MongoDB driver cursor\n */\n\nQuery.prototype.cursor = function() {\n  if ('find' != this.op)\n    throw new Error('cursor() is only available for find');\n\n  const conds = this._conditions;\n\n  const options = this._optionsForExec();\n  if (this.$useProjection) {\n    options.projection = this._fieldsForExec();\n  } else {\n    options.fields = this._fieldsForExec();\n  }\n\n  debug('cursor', this._collection.collectionName, conds, options);\n\n  return this._collection.findCursor(conds, options);\n};\n\n/**\n * Determines if field selection has been made.\n *\n * @return {Boolean}\n * @api public\n */\n\nQuery.prototype.selected = function selected() {\n  return !!(this._fields && Object.keys(this._fields).length > 0);\n};\n\n/**\n * Determines if inclusive field selection has been made.\n *\n *     query.selectedInclusively() // false\n *     query.select('name')\n *     query.selectedInclusively() // true\n *     query.selectedExlusively() // false\n *\n * @returns {Boolean}\n */\n\nQuery.prototype.selectedInclusively = function selectedInclusively() {\n  if (!this._fields) return false;\n\n  const keys = Object.keys(this._fields);\n  if (0 === keys.length) return false;\n\n  for (let i = 0; i < keys.length; ++i) {\n    const key = keys[i];\n    if (0 === this._fields[key]) return false;\n    if (this._fields[key] &&\n        typeof this._fields[key] === 'object' &&\n        this._fields[key].$meta) {\n      return false;\n    }\n  }\n\n  return true;\n};\n\n/**\n * Determines if exclusive field selection has been made.\n *\n *     query.selectedExlusively() // false\n *     query.select('-name')\n *     query.selectedExlusively() // true\n *     query.selectedInclusively() // false\n *\n * @returns {Boolean}\n */\n\nQuery.prototype.selectedExclusively = function selectedExclusively() {\n  if (!this._fields) return false;\n\n  const keys = Object.keys(this._fields);\n  if (0 === keys.length) return false;\n\n  for (let i = 0; i < keys.length; ++i) {\n    const key = keys[i];\n    if (0 === this._fields[key]) return true;\n  }\n\n  return false;\n};\n\n/**\n * Merges `doc` with the current update object.\n *\n * @param {Object} doc\n */\n\nQuery.prototype._mergeUpdate = function(doc) {\n  if (!this._updateDoc) this._updateDoc = {};\n  if (doc instanceof Query) {\n    if (doc._updateDoc) {\n      utils.mergeClone(this._updateDoc, doc._updateDoc);\n    }\n  } else {\n    utils.mergeClone(this._updateDoc, doc);\n  }\n};\n\n/**\n * Returns default options.\n *\n * @return {Object}\n * @api private\n */\n\nQuery.prototype._optionsForExec = function() {\n  const options = utils.clone(this.options);\n  return options;\n};\n\n/**\n * Returns fields selection for this query.\n *\n * @return {Object}\n * @api private\n */\n\nQuery.prototype._fieldsForExec = function() {\n  return utils.clone(this._fields);\n};\n\n/**\n * Return an update document with corrected $set operations.\n *\n * @api private\n */\n\nQuery.prototype._updateForExec = function() {\n  const update = utils.clone(this._updateDoc);\n  const ops = utils.keys(update);\n  const ret = {};\n\n  for (const op of ops) {\n    if (this.options.overwrite) {\n      ret[op] = update[op];\n      continue;\n    }\n\n    if ('$' !== op[0]) {\n      // fix up $set sugar\n      if (!ret.$set) {\n        if (update.$set) {\n          ret.$set = update.$set;\n        } else {\n          ret.$set = {};\n        }\n      }\n      ret.$set[op] = update[op];\n      if (!~ops.indexOf('$set')) ops.push('$set');\n    } else if ('$set' === op) {\n      if (!ret.$set) {\n        ret[op] = update[op];\n      }\n    } else {\n      ret[op] = update[op];\n    }\n  }\n\n  this._compiledUpdate = ret;\n  return ret;\n};\n\n/**\n * Make sure _path is set.\n *\n * @parmam {String} method\n */\n\nQuery.prototype._ensurePath = function(method) {\n  if (!this._path) {\n    const msg = method + '() must be used after where() '\n                     + 'when called with these arguments';\n    throw new Error(msg);\n  }\n};\n\n/*!\n * Permissions\n */\n\nQuery.permissions = __webpack_require__(/*! ./permissions */ \"./node_modules/mquery/lib/permissions.js\");\n\nQuery._isPermitted = function(a, b) {\n  const denied = Query.permissions[b];\n  if (!denied) return true;\n  return true !== denied[a];\n};\n\nQuery.prototype._validate = function(action) {\n  let fail;\n  let validator;\n\n  if (undefined === action) {\n\n    validator = Query.permissions[this.op];\n    if ('function' != typeof validator) return true;\n\n    fail = validator(this);\n\n  } else if (!Query._isPermitted(action, this.op)) {\n    fail = action;\n  }\n\n  if (fail) {\n    throw new Error(fail + ' cannot be used with ' + this.op);\n  }\n};\n\n/**\n * Determines if `conds` can be merged using `mquery().merge()`\n *\n * @param {Object} conds\n * @return {Boolean}\n */\n\nQuery.canMerge = function(conds) {\n  return conds instanceof Query || utils.isObject(conds);\n};\n\n/**\n * Set a trace function that will get called whenever a\n * query is executed.\n *\n * See `setTraceFunction()` for details.\n *\n * @param {Object} conds\n * @return {Boolean}\n */\nQuery.setGlobalTraceFunction = function(traceFunction) {\n  Query.traceFunction = traceFunction;\n};\n\n/*!\n * Exports.\n */\n\nQuery.utils = utils;\nQuery.env = __webpack_require__(/*! ./env */ \"./node_modules/mquery/lib/env.js\");\nQuery.Collection = __webpack_require__(/*! ./collection */ \"./node_modules/mquery/lib/collection/index.js\");\nQuery.BaseCollection = __webpack_require__(/*! ./collection/collection */ \"./node_modules/mquery/lib/collection/collection.js\");\nmodule.exports = exports = Query;\n\n// TODO\n// test utils\n\n\n//# sourceURL=webpack://experimento/./node_modules/mquery/lib/mquery.js?");

/***/ }),

/***/ "./node_modules/mquery/lib/permissions.js":
/*!************************************************!*\
  !*** ./node_modules/mquery/lib/permissions.js ***!
  \************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nconst denied = exports;\n\ndenied.distinct = function(self) {\n  if (self._fields && Object.keys(self._fields).length > 0) {\n    return 'field selection and slice';\n  }\n\n  const keys = Object.keys(denied.distinct);\n  let err;\n\n  keys.every(function(option) {\n    if (self.options[option]) {\n      err = option;\n      return false;\n    }\n    return true;\n  });\n\n  return err;\n};\ndenied.distinct.select =\ndenied.distinct.slice =\ndenied.distinct.sort =\ndenied.distinct.limit =\ndenied.distinct.skip =\ndenied.distinct.batchSize =\ndenied.distinct.hint =\ndenied.distinct.tailable = true;\n\n\n// aggregation integration\n\n\ndenied.findOneAndUpdate =\ndenied.findOneAndRemove = function(self) {\n  const keys = Object.keys(denied.findOneAndUpdate);\n  let err;\n\n  keys.every(function(option) {\n    if (self.options[option]) {\n      err = option;\n      return false;\n    }\n    return true;\n  });\n\n  return err;\n};\ndenied.findOneAndUpdate.limit =\ndenied.findOneAndUpdate.skip =\ndenied.findOneAndUpdate.batchSize =\ndenied.findOneAndUpdate.tailable = true;\n\n\ndenied.count = function(self) {\n  if (self._fields && Object.keys(self._fields).length > 0) {\n    return 'field selection and slice';\n  }\n\n  const keys = Object.keys(denied.count);\n  let err;\n\n  keys.every(function(option) {\n    if (self.options[option]) {\n      err = option;\n      return false;\n    }\n    return true;\n  });\n\n  return err;\n};\n\ndenied.count.slice =\ndenied.count.batchSize =\ndenied.count.tailable = true;\n\n\n//# sourceURL=webpack://experimento/./node_modules/mquery/lib/permissions.js?");

/***/ }),

/***/ "./node_modules/mquery/lib/utils.js":
/*!******************************************!*\
  !*** ./node_modules/mquery/lib/utils.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\n/*!\n * Module dependencies.\n */\n\nconst specialProperties = ['__proto__', 'constructor', 'prototype'];\n\n/**\n * Clones objects\n *\n * @param {Object} obj the object to clone\n * @param {Object} options\n * @return {Object} the cloned object\n * @api private\n */\n\nconst clone = exports.clone = function clone(obj, options) {\n  if (obj === undefined || obj === null)\n    return obj;\n\n  if (Array.isArray(obj))\n    return exports.cloneArray(obj, options);\n\n  if (obj.constructor) {\n    if (/ObjectI[dD]$/.test(obj.constructor.name)) {\n      return 'function' == typeof obj.clone\n        ? obj.clone()\n        : new obj.constructor(obj.id);\n    }\n\n    if (obj.constructor.name === 'ReadPreference') {\n      return new obj.constructor(obj.mode, clone(obj.tags, options));\n    }\n\n    if ('Binary' == obj._bsontype && obj.buffer && obj.value) {\n      return 'function' == typeof obj.clone\n        ? obj.clone()\n        : new obj.constructor(obj.value(true), obj.sub_type);\n    }\n\n    if ('Date' === obj.constructor.name || 'Function' === obj.constructor.name)\n      return new obj.constructor(+obj);\n\n    if ('RegExp' === obj.constructor.name)\n      return new RegExp(obj);\n\n    if ('Buffer' === obj.constructor.name)\n      return Buffer.from(obj);\n  }\n\n  if (isObject(obj))\n    return exports.cloneObject(obj, options);\n\n  if (obj.valueOf)\n    return obj.valueOf();\n};\n\n/*!\n * ignore\n */\n\nexports.cloneObject = function cloneObject(obj, options) {\n  const minimize = options && options.minimize,\n      ret = {},\n      keys = Object.keys(obj),\n      len = keys.length;\n  let hasKeys = false,\n      val,\n      k = '',\n      i = 0;\n\n  for (i = 0; i < len; ++i) {\n    k = keys[i];\n    // Not technically prototype pollution because this wouldn't merge properties\n    // onto `Object.prototype`, but avoid properties like __proto__ as a precaution.\n    if (specialProperties.indexOf(k) !== -1) {\n      continue;\n    }\n\n    val = clone(obj[k], options);\n\n    if (!minimize || ('undefined' !== typeof val)) {\n      hasKeys || (hasKeys = true);\n      ret[k] = val;\n    }\n  }\n\n  return minimize\n    ? hasKeys && ret\n    : ret;\n};\n\nexports.cloneArray = function cloneArray(arr, options) {\n  const ret = [],\n      l = arr.length;\n  let i = 0;\n  for (; i < l; i++)\n    ret.push(clone(arr[i], options));\n  return ret;\n};\n\n/**\n * Merges `from` into `to` without overwriting existing properties.\n *\n * @param {Object} to\n * @param {Object} from\n * @api private\n */\n\nexports.merge = function merge(to, from) {\n  const keys = Object.keys(from);\n\n  for (const key of keys) {\n    if (specialProperties.indexOf(key) !== -1) {\n      continue;\n    }\n    if ('undefined' === typeof to[key]) {\n      to[key] = from[key];\n    } else {\n      if (exports.isObject(from[key])) {\n        merge(to[key], from[key]);\n      } else {\n        to[key] = from[key];\n      }\n    }\n  }\n};\n\n/**\n * Same as merge but clones the assigned values.\n *\n * @param {Object} to\n * @param {Object} from\n * @api private\n */\n\nexports.mergeClone = function mergeClone(to, from) {\n  const keys = Object.keys(from);\n\n  for (const key of keys) {\n    if (specialProperties.indexOf(key) !== -1) {\n      continue;\n    }\n    if ('undefined' === typeof to[key]) {\n      to[key] = clone(from[key]);\n    } else {\n      if (exports.isObject(from[key])) {\n        mergeClone(to[key], from[key]);\n      } else {\n        to[key] = clone(from[key]);\n      }\n    }\n  }\n};\n\n/**\n * Read pref helper (mongo 2.2 drivers support this)\n *\n * Allows using aliases instead of full preference names:\n *\n *     p   primary\n *     pp  primaryPreferred\n *     s   secondary\n *     sp  secondaryPreferred\n *     n   nearest\n *\n * @param {String} pref\n */\n\nexports.readPref = function readPref(pref) {\n  switch (pref) {\n    case 'p':\n      pref = 'primary';\n      break;\n    case 'pp':\n      pref = 'primaryPreferred';\n      break;\n    case 's':\n      pref = 'secondary';\n      break;\n    case 'sp':\n      pref = 'secondaryPreferred';\n      break;\n    case 'n':\n      pref = 'nearest';\n      break;\n  }\n\n  return pref;\n};\n\n\n/**\n * Read Concern helper (mongo 3.2 drivers support this)\n *\n * Allows using string to specify read concern level:\n *\n *     local          3.2+\n *     available      3.6+\n *     majority       3.2+\n *     linearizable   3.4+\n *     snapshot       4.0+\n *\n * @param {String|Object} concern\n */\n\nexports.readConcern = function readConcern(concern) {\n  if ('string' === typeof concern) {\n    switch (concern) {\n      case 'l':\n        concern = 'local';\n        break;\n      case 'a':\n        concern = 'available';\n        break;\n      case 'm':\n        concern = 'majority';\n        break;\n      case 'lz':\n        concern = 'linearizable';\n        break;\n      case 's':\n        concern = 'snapshot';\n        break;\n    }\n    concern = { level: concern };\n  }\n  return concern;\n};\n\n/**\n * Object.prototype.toString.call helper\n */\n\nconst _toString = Object.prototype.toString;\nexports.toString = function(arg) {\n  return _toString.call(arg);\n};\n\n/**\n * Determines if `arg` is an object.\n *\n * @param {Object|Array|String|Function|RegExp|any} arg\n * @return {Boolean}\n */\n\nconst isObject = exports.isObject = function(arg) {\n  return '[object Object]' == exports.toString(arg);\n};\n\n/**\n * Object.keys helper\n */\n\nexports.keys = Object.keys;\n\n/**\n * Basic Object.create polyfill.\n * Only one argument is supported.\n *\n * Based on https://developer.mozilla.org/en-US/docs/JavaScript/Reference/Global_Objects/Object/create\n */\n\nexports.create = 'function' == typeof Object.create\n  ? Object.create\n  : create;\n\nfunction create(proto) {\n  if (arguments.length > 1) {\n    throw new Error('Adding properties is not supported');\n  }\n\n  function F() { }\n  F.prototype = proto;\n  return new F;\n}\n\n/**\n * inheritance\n */\n\nexports.inherits = function(ctor, superCtor) {\n  ctor.prototype = exports.create(superCtor.prototype);\n  ctor.prototype.constructor = ctor;\n};\n\n/**\n * Check if this object is an arguments object\n *\n * @param {Any} v\n * @return {Boolean}\n */\n\nexports.isArgumentsObject = function(v) {\n  return Object.prototype.toString.call(v) === '[object Arguments]';\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/mquery/lib/utils.js?");

/***/ }),

/***/ "./node_modules/ms/index.js":
/*!**********************************!*\
  !*** ./node_modules/ms/index.js ***!
  \**********************************/
/***/ ((module) => {

eval("/**\n * Helpers.\n */\n\nvar s = 1000;\nvar m = s * 60;\nvar h = m * 60;\nvar d = h * 24;\nvar w = d * 7;\nvar y = d * 365.25;\n\n/**\n * Parse or format the given `val`.\n *\n * Options:\n *\n *  - `long` verbose formatting [false]\n *\n * @param {String|Number} val\n * @param {Object} [options]\n * @throws {Error} throw an error if val is not a non-empty string or a number\n * @return {String|Number}\n * @api public\n */\n\nmodule.exports = function(val, options) {\n  options = options || {};\n  var type = typeof val;\n  if (type === 'string' && val.length > 0) {\n    return parse(val);\n  } else if (type === 'number' && isFinite(val)) {\n    return options.long ? fmtLong(val) : fmtShort(val);\n  }\n  throw new Error(\n    'val is not a non-empty string or a valid number. val=' +\n      JSON.stringify(val)\n  );\n};\n\n/**\n * Parse the given `str` and return milliseconds.\n *\n * @param {String} str\n * @return {Number}\n * @api private\n */\n\nfunction parse(str) {\n  str = String(str);\n  if (str.length > 100) {\n    return;\n  }\n  var match = /^(-?(?:\\d+)?\\.?\\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$/i.exec(\n    str\n  );\n  if (!match) {\n    return;\n  }\n  var n = parseFloat(match[1]);\n  var type = (match[2] || 'ms').toLowerCase();\n  switch (type) {\n    case 'years':\n    case 'year':\n    case 'yrs':\n    case 'yr':\n    case 'y':\n      return n * y;\n    case 'weeks':\n    case 'week':\n    case 'w':\n      return n * w;\n    case 'days':\n    case 'day':\n    case 'd':\n      return n * d;\n    case 'hours':\n    case 'hour':\n    case 'hrs':\n    case 'hr':\n    case 'h':\n      return n * h;\n    case 'minutes':\n    case 'minute':\n    case 'mins':\n    case 'min':\n    case 'm':\n      return n * m;\n    case 'seconds':\n    case 'second':\n    case 'secs':\n    case 'sec':\n    case 's':\n      return n * s;\n    case 'milliseconds':\n    case 'millisecond':\n    case 'msecs':\n    case 'msec':\n    case 'ms':\n      return n;\n    default:\n      return undefined;\n  }\n}\n\n/**\n * Short format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtShort(ms) {\n  var msAbs = Math.abs(ms);\n  if (msAbs >= d) {\n    return Math.round(ms / d) + 'd';\n  }\n  if (msAbs >= h) {\n    return Math.round(ms / h) + 'h';\n  }\n  if (msAbs >= m) {\n    return Math.round(ms / m) + 'm';\n  }\n  if (msAbs >= s) {\n    return Math.round(ms / s) + 's';\n  }\n  return ms + 'ms';\n}\n\n/**\n * Long format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtLong(ms) {\n  var msAbs = Math.abs(ms);\n  if (msAbs >= d) {\n    return plural(ms, msAbs, d, 'day');\n  }\n  if (msAbs >= h) {\n    return plural(ms, msAbs, h, 'hour');\n  }\n  if (msAbs >= m) {\n    return plural(ms, msAbs, m, 'minute');\n  }\n  if (msAbs >= s) {\n    return plural(ms, msAbs, s, 'second');\n  }\n  return ms + ' ms';\n}\n\n/**\n * Pluralization helper.\n */\n\nfunction plural(ms, msAbs, n, name) {\n  var isPlural = msAbs >= n * 1.5;\n  return Math.round(ms / n) + ' ' + name + (isPlural ? 's' : '');\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/ms/index.js?");

/***/ }),

/***/ "./node_modules/punycode/punycode.es6.js":
/*!***********************************************!*\
  !*** ./node_modules/punycode/punycode.es6.js ***!
  \***********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   decode: () => (/* binding */ decode),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__),\n/* harmony export */   encode: () => (/* binding */ encode),\n/* harmony export */   toASCII: () => (/* binding */ toASCII),\n/* harmony export */   toUnicode: () => (/* binding */ toUnicode),\n/* harmony export */   ucs2decode: () => (/* binding */ ucs2decode),\n/* harmony export */   ucs2encode: () => (/* binding */ ucs2encode)\n/* harmony export */ });\n\n\n/** Highest positive signed 32-bit float value */\nconst maxInt = 2147483647; // aka. 0x7FFFFFFF or 2^31-1\n\n/** Bootstring parameters */\nconst base = 36;\nconst tMin = 1;\nconst tMax = 26;\nconst skew = 38;\nconst damp = 700;\nconst initialBias = 72;\nconst initialN = 128; // 0x80\nconst delimiter = '-'; // '\\x2D'\n\n/** Regular expressions */\nconst regexPunycode = /^xn--/;\nconst regexNonASCII = /[^\\0-\\x7F]/; // Note: U+007F DEL is excluded too.\nconst regexSeparators = /[\\x2E\\u3002\\uFF0E\\uFF61]/g; // RFC 3490 separators\n\n/** Error messages */\nconst errors = {\n\t'overflow': 'Overflow: input needs wider integers to process',\n\t'not-basic': 'Illegal input >= 0x80 (not a basic code point)',\n\t'invalid-input': 'Invalid input'\n};\n\n/** Convenience shortcuts */\nconst baseMinusTMin = base - tMin;\nconst floor = Math.floor;\nconst stringFromCharCode = String.fromCharCode;\n\n/*--------------------------------------------------------------------------*/\n\n/**\n * A generic error utility function.\n * @private\n * @param {String} type The error type.\n * @returns {Error} Throws a `RangeError` with the applicable error message.\n */\nfunction error(type) {\n\tthrow new RangeError(errors[type]);\n}\n\n/**\n * A generic `Array#map` utility function.\n * @private\n * @param {Array} array The array to iterate over.\n * @param {Function} callback The function that gets called for every array\n * item.\n * @returns {Array} A new array of values returned by the callback function.\n */\nfunction map(array, callback) {\n\tconst result = [];\n\tlet length = array.length;\n\twhile (length--) {\n\t\tresult[length] = callback(array[length]);\n\t}\n\treturn result;\n}\n\n/**\n * A simple `Array#map`-like wrapper to work with domain name strings or email\n * addresses.\n * @private\n * @param {String} domain The domain name or email address.\n * @param {Function} callback The function that gets called for every\n * character.\n * @returns {String} A new string of characters returned by the callback\n * function.\n */\nfunction mapDomain(domain, callback) {\n\tconst parts = domain.split('@');\n\tlet result = '';\n\tif (parts.length > 1) {\n\t\t// In email addresses, only the domain name should be punycoded. Leave\n\t\t// the local part (i.e. everything up to `@`) intact.\n\t\tresult = parts[0] + '@';\n\t\tdomain = parts[1];\n\t}\n\t// Avoid `split(regex)` for IE8 compatibility. See #17.\n\tdomain = domain.replace(regexSeparators, '\\x2E');\n\tconst labels = domain.split('.');\n\tconst encoded = map(labels, callback).join('.');\n\treturn result + encoded;\n}\n\n/**\n * Creates an array containing the numeric code points of each Unicode\n * character in the string. While JavaScript uses UCS-2 internally,\n * this function will convert a pair of surrogate halves (each of which\n * UCS-2 exposes as separate characters) into a single code point,\n * matching UTF-16.\n * @see `punycode.ucs2.encode`\n * @see <https://mathiasbynens.be/notes/javascript-encoding>\n * @memberOf punycode.ucs2\n * @name decode\n * @param {String} string The Unicode input string (UCS-2).\n * @returns {Array} The new array of code points.\n */\nfunction ucs2decode(string) {\n\tconst output = [];\n\tlet counter = 0;\n\tconst length = string.length;\n\twhile (counter < length) {\n\t\tconst value = string.charCodeAt(counter++);\n\t\tif (value >= 0xD800 && value <= 0xDBFF && counter < length) {\n\t\t\t// It's a high surrogate, and there is a next character.\n\t\t\tconst extra = string.charCodeAt(counter++);\n\t\t\tif ((extra & 0xFC00) == 0xDC00) { // Low surrogate.\n\t\t\t\toutput.push(((value & 0x3FF) << 10) + (extra & 0x3FF) + 0x10000);\n\t\t\t} else {\n\t\t\t\t// It's an unmatched surrogate; only append this code unit, in case the\n\t\t\t\t// next code unit is the high surrogate of a surrogate pair.\n\t\t\t\toutput.push(value);\n\t\t\t\tcounter--;\n\t\t\t}\n\t\t} else {\n\t\t\toutput.push(value);\n\t\t}\n\t}\n\treturn output;\n}\n\n/**\n * Creates a string based on an array of numeric code points.\n * @see `punycode.ucs2.decode`\n * @memberOf punycode.ucs2\n * @name encode\n * @param {Array} codePoints The array of numeric code points.\n * @returns {String} The new Unicode string (UCS-2).\n */\nconst ucs2encode = codePoints => String.fromCodePoint(...codePoints);\n\n/**\n * Converts a basic code point into a digit/integer.\n * @see `digitToBasic()`\n * @private\n * @param {Number} codePoint The basic numeric code point value.\n * @returns {Number} The numeric value of a basic code point (for use in\n * representing integers) in the range `0` to `base - 1`, or `base` if\n * the code point does not represent a value.\n */\nconst basicToDigit = function(codePoint) {\n\tif (codePoint >= 0x30 && codePoint < 0x3A) {\n\t\treturn 26 + (codePoint - 0x30);\n\t}\n\tif (codePoint >= 0x41 && codePoint < 0x5B) {\n\t\treturn codePoint - 0x41;\n\t}\n\tif (codePoint >= 0x61 && codePoint < 0x7B) {\n\t\treturn codePoint - 0x61;\n\t}\n\treturn base;\n};\n\n/**\n * Converts a digit/integer into a basic code point.\n * @see `basicToDigit()`\n * @private\n * @param {Number} digit The numeric value of a basic code point.\n * @returns {Number} The basic code point whose value (when used for\n * representing integers) is `digit`, which needs to be in the range\n * `0` to `base - 1`. If `flag` is non-zero, the uppercase form is\n * used; else, the lowercase form is used. The behavior is undefined\n * if `flag` is non-zero and `digit` has no uppercase form.\n */\nconst digitToBasic = function(digit, flag) {\n\t//  0..25 map to ASCII a..z or A..Z\n\t// 26..35 map to ASCII 0..9\n\treturn digit + 22 + 75 * (digit < 26) - ((flag != 0) << 5);\n};\n\n/**\n * Bias adaptation function as per section 3.4 of RFC 3492.\n * https://tools.ietf.org/html/rfc3492#section-3.4\n * @private\n */\nconst adapt = function(delta, numPoints, firstTime) {\n\tlet k = 0;\n\tdelta = firstTime ? floor(delta / damp) : delta >> 1;\n\tdelta += floor(delta / numPoints);\n\tfor (/* no initialization */; delta > baseMinusTMin * tMax >> 1; k += base) {\n\t\tdelta = floor(delta / baseMinusTMin);\n\t}\n\treturn floor(k + (baseMinusTMin + 1) * delta / (delta + skew));\n};\n\n/**\n * Converts a Punycode string of ASCII-only symbols to a string of Unicode\n * symbols.\n * @memberOf punycode\n * @param {String} input The Punycode string of ASCII-only symbols.\n * @returns {String} The resulting string of Unicode symbols.\n */\nconst decode = function(input) {\n\t// Don't use UCS-2.\n\tconst output = [];\n\tconst inputLength = input.length;\n\tlet i = 0;\n\tlet n = initialN;\n\tlet bias = initialBias;\n\n\t// Handle the basic code points: let `basic` be the number of input code\n\t// points before the last delimiter, or `0` if there is none, then copy\n\t// the first basic code points to the output.\n\n\tlet basic = input.lastIndexOf(delimiter);\n\tif (basic < 0) {\n\t\tbasic = 0;\n\t}\n\n\tfor (let j = 0; j < basic; ++j) {\n\t\t// if it's not a basic code point\n\t\tif (input.charCodeAt(j) >= 0x80) {\n\t\t\terror('not-basic');\n\t\t}\n\t\toutput.push(input.charCodeAt(j));\n\t}\n\n\t// Main decoding loop: start just after the last delimiter if any basic code\n\t// points were copied; start at the beginning otherwise.\n\n\tfor (let index = basic > 0 ? basic + 1 : 0; index < inputLength; /* no final expression */) {\n\n\t\t// `index` is the index of the next character to be consumed.\n\t\t// Decode a generalized variable-length integer into `delta`,\n\t\t// which gets added to `i`. The overflow checking is easier\n\t\t// if we increase `i` as we go, then subtract off its starting\n\t\t// value at the end to obtain `delta`.\n\t\tconst oldi = i;\n\t\tfor (let w = 1, k = base; /* no condition */; k += base) {\n\n\t\t\tif (index >= inputLength) {\n\t\t\t\terror('invalid-input');\n\t\t\t}\n\n\t\t\tconst digit = basicToDigit(input.charCodeAt(index++));\n\n\t\t\tif (digit >= base) {\n\t\t\t\terror('invalid-input');\n\t\t\t}\n\t\t\tif (digit > floor((maxInt - i) / w)) {\n\t\t\t\terror('overflow');\n\t\t\t}\n\n\t\t\ti += digit * w;\n\t\t\tconst t = k <= bias ? tMin : (k >= bias + tMax ? tMax : k - bias);\n\n\t\t\tif (digit < t) {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tconst baseMinusT = base - t;\n\t\t\tif (w > floor(maxInt / baseMinusT)) {\n\t\t\t\terror('overflow');\n\t\t\t}\n\n\t\t\tw *= baseMinusT;\n\n\t\t}\n\n\t\tconst out = output.length + 1;\n\t\tbias = adapt(i - oldi, out, oldi == 0);\n\n\t\t// `i` was supposed to wrap around from `out` to `0`,\n\t\t// incrementing `n` each time, so we'll fix that now:\n\t\tif (floor(i / out) > maxInt - n) {\n\t\t\terror('overflow');\n\t\t}\n\n\t\tn += floor(i / out);\n\t\ti %= out;\n\n\t\t// Insert `n` at position `i` of the output.\n\t\toutput.splice(i++, 0, n);\n\n\t}\n\n\treturn String.fromCodePoint(...output);\n};\n\n/**\n * Converts a string of Unicode symbols (e.g. a domain name label) to a\n * Punycode string of ASCII-only symbols.\n * @memberOf punycode\n * @param {String} input The string of Unicode symbols.\n * @returns {String} The resulting Punycode string of ASCII-only symbols.\n */\nconst encode = function(input) {\n\tconst output = [];\n\n\t// Convert the input in UCS-2 to an array of Unicode code points.\n\tinput = ucs2decode(input);\n\n\t// Cache the length.\n\tconst inputLength = input.length;\n\n\t// Initialize the state.\n\tlet n = initialN;\n\tlet delta = 0;\n\tlet bias = initialBias;\n\n\t// Handle the basic code points.\n\tfor (const currentValue of input) {\n\t\tif (currentValue < 0x80) {\n\t\t\toutput.push(stringFromCharCode(currentValue));\n\t\t}\n\t}\n\n\tconst basicLength = output.length;\n\tlet handledCPCount = basicLength;\n\n\t// `handledCPCount` is the number of code points that have been handled;\n\t// `basicLength` is the number of basic code points.\n\n\t// Finish the basic string with a delimiter unless it's empty.\n\tif (basicLength) {\n\t\toutput.push(delimiter);\n\t}\n\n\t// Main encoding loop:\n\twhile (handledCPCount < inputLength) {\n\n\t\t// All non-basic code points < n have been handled already. Find the next\n\t\t// larger one:\n\t\tlet m = maxInt;\n\t\tfor (const currentValue of input) {\n\t\t\tif (currentValue >= n && currentValue < m) {\n\t\t\t\tm = currentValue;\n\t\t\t}\n\t\t}\n\n\t\t// Increase `delta` enough to advance the decoder's <n,i> state to <m,0>,\n\t\t// but guard against overflow.\n\t\tconst handledCPCountPlusOne = handledCPCount + 1;\n\t\tif (m - n > floor((maxInt - delta) / handledCPCountPlusOne)) {\n\t\t\terror('overflow');\n\t\t}\n\n\t\tdelta += (m - n) * handledCPCountPlusOne;\n\t\tn = m;\n\n\t\tfor (const currentValue of input) {\n\t\t\tif (currentValue < n && ++delta > maxInt) {\n\t\t\t\terror('overflow');\n\t\t\t}\n\t\t\tif (currentValue === n) {\n\t\t\t\t// Represent delta as a generalized variable-length integer.\n\t\t\t\tlet q = delta;\n\t\t\t\tfor (let k = base; /* no condition */; k += base) {\n\t\t\t\t\tconst t = k <= bias ? tMin : (k >= bias + tMax ? tMax : k - bias);\n\t\t\t\t\tif (q < t) {\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tconst qMinusT = q - t;\n\t\t\t\t\tconst baseMinusT = base - t;\n\t\t\t\t\toutput.push(\n\t\t\t\t\t\tstringFromCharCode(digitToBasic(t + qMinusT % baseMinusT, 0))\n\t\t\t\t\t);\n\t\t\t\t\tq = floor(qMinusT / baseMinusT);\n\t\t\t\t}\n\n\t\t\t\toutput.push(stringFromCharCode(digitToBasic(q, 0)));\n\t\t\t\tbias = adapt(delta, handledCPCountPlusOne, handledCPCount === basicLength);\n\t\t\t\tdelta = 0;\n\t\t\t\t++handledCPCount;\n\t\t\t}\n\t\t}\n\n\t\t++delta;\n\t\t++n;\n\n\t}\n\treturn output.join('');\n};\n\n/**\n * Converts a Punycode string representing a domain name or an email address\n * to Unicode. Only the Punycoded parts of the input will be converted, i.e.\n * it doesn't matter if you call it on a string that has already been\n * converted to Unicode.\n * @memberOf punycode\n * @param {String} input The Punycoded domain name or email address to\n * convert to Unicode.\n * @returns {String} The Unicode representation of the given Punycode\n * string.\n */\nconst toUnicode = function(input) {\n\treturn mapDomain(input, function(string) {\n\t\treturn regexPunycode.test(string)\n\t\t\t? decode(string.slice(4).toLowerCase())\n\t\t\t: string;\n\t});\n};\n\n/**\n * Converts a Unicode string representing a domain name or an email address to\n * Punycode. Only the non-ASCII parts of the domain name will be converted,\n * i.e. it doesn't matter if you call it with a domain that's already in\n * ASCII.\n * @memberOf punycode\n * @param {String} input The domain name or email address to convert, as a\n * Unicode string.\n * @returns {String} The Punycode representation of the given domain name or\n * email address.\n */\nconst toASCII = function(input) {\n\treturn mapDomain(input, function(string) {\n\t\treturn regexNonASCII.test(string)\n\t\t\t? 'xn--' + encode(string)\n\t\t\t: string;\n\t});\n};\n\n/*--------------------------------------------------------------------------*/\n\n/** Define the public API */\nconst punycode = {\n\t/**\n\t * A string representing the current Punycode.js version number.\n\t * @memberOf punycode\n\t * @type String\n\t */\n\t'version': '2.3.1',\n\t/**\n\t * An object of methods to convert from JavaScript's internal character\n\t * representation (UCS-2) to Unicode code points, and back.\n\t * @see <https://mathiasbynens.be/notes/javascript-encoding>\n\t * @memberOf punycode\n\t * @type Object\n\t */\n\t'ucs2': {\n\t\t'decode': ucs2decode,\n\t\t'encode': ucs2encode\n\t},\n\t'decode': decode,\n\t'encode': encode,\n\t'toASCII': toASCII,\n\t'toUnicode': toUnicode\n};\n\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (punycode);\n\n\n//# sourceURL=webpack://experimento/./node_modules/punycode/punycode.es6.js?");

/***/ }),

/***/ "./node_modules/sift/es5m/index.js":
/*!*****************************************!*\
  !*** ./node_modules/sift/es5m/index.js ***!
  \*****************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   $Size: () => (/* binding */ $Size),\n/* harmony export */   $all: () => (/* binding */ $all),\n/* harmony export */   $and: () => (/* binding */ $and),\n/* harmony export */   $elemMatch: () => (/* binding */ $elemMatch),\n/* harmony export */   $eq: () => (/* binding */ $eq),\n/* harmony export */   $exists: () => (/* binding */ $exists),\n/* harmony export */   $gt: () => (/* binding */ $gt),\n/* harmony export */   $gte: () => (/* binding */ $gte),\n/* harmony export */   $in: () => (/* binding */ $in),\n/* harmony export */   $lt: () => (/* binding */ $lt),\n/* harmony export */   $lte: () => (/* binding */ $lte),\n/* harmony export */   $mod: () => (/* binding */ $mod),\n/* harmony export */   $ne: () => (/* binding */ $ne),\n/* harmony export */   $nin: () => (/* binding */ $nin),\n/* harmony export */   $nor: () => (/* binding */ $nor),\n/* harmony export */   $not: () => (/* binding */ $not),\n/* harmony export */   $options: () => (/* binding */ $options),\n/* harmony export */   $or: () => (/* binding */ $or),\n/* harmony export */   $regex: () => (/* binding */ $regex),\n/* harmony export */   $size: () => (/* binding */ $size),\n/* harmony export */   $type: () => (/* binding */ $type),\n/* harmony export */   $where: () => (/* binding */ $where),\n/* harmony export */   EqualsOperation: () => (/* binding */ EqualsOperation),\n/* harmony export */   createDefaultQueryOperation: () => (/* binding */ createDefaultQueryOperation),\n/* harmony export */   createEqualsOperation: () => (/* binding */ createEqualsOperation),\n/* harmony export */   createOperationTester: () => (/* binding */ createOperationTester),\n/* harmony export */   createQueryOperation: () => (/* binding */ createQueryOperation),\n/* harmony export */   createQueryTester: () => (/* binding */ createQueryTester),\n/* harmony export */   \"default\": () => (/* binding */ createDefaultQueryTester)\n/* harmony export */ });\n/******************************************************************************\r\nCopyright (c) Microsoft Corporation.\r\n\r\nPermission to use, copy, modify, and/or distribute this software for any\r\npurpose with or without fee is hereby granted.\r\n\r\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\r\nREGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY\r\nAND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\r\nINDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM\r\nLOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR\r\nOTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\r\nPERFORMANCE OF THIS SOFTWARE.\r\n***************************************************************************** */\r\n/* global Reflect, Promise, SuppressedError, Symbol */\r\n\r\nvar extendStatics = function(d, b) {\r\n    extendStatics = Object.setPrototypeOf ||\r\n        ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\r\n        function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };\r\n    return extendStatics(d, b);\r\n};\r\n\r\nfunction __extends(d, b) {\r\n    if (typeof b !== \"function\" && b !== null)\r\n        throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\r\n    extendStatics(d, b);\r\n    function __() { this.constructor = d; }\r\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\r\n}\r\n\r\ntypeof SuppressedError === \"function\" ? SuppressedError : function (error, suppressed, message) {\r\n    var e = new Error(message);\r\n    return e.name = \"SuppressedError\", e.error = error, e.suppressed = suppressed, e;\r\n};\n\nvar typeChecker = function (type) {\n    var typeString = \"[object \" + type + \"]\";\n    return function (value) {\n        return getClassName(value) === typeString;\n    };\n};\nvar getClassName = function (value) { return Object.prototype.toString.call(value); };\nvar comparable = function (value) {\n    if (value instanceof Date) {\n        return value.getTime();\n    }\n    else if (isArray(value)) {\n        return value.map(comparable);\n    }\n    else if (value && typeof value.toJSON === \"function\") {\n        return value.toJSON();\n    }\n    return value;\n};\nvar coercePotentiallyNull = function (value) {\n    return value == null ? null : value;\n};\nvar isArray = typeChecker(\"Array\");\nvar isObject = typeChecker(\"Object\");\nvar isFunction = typeChecker(\"Function\");\nvar isProperty = function (item, key) {\n    return item.hasOwnProperty(key) && !isFunction(item[key]);\n};\nvar isVanillaObject = function (value) {\n    return (value &&\n        (value.constructor === Object ||\n            value.constructor === Array ||\n            value.constructor.toString() === \"function Object() { [native code] }\" ||\n            value.constructor.toString() === \"function Array() { [native code] }\") &&\n        !value.toJSON);\n};\nvar equals = function (a, b) {\n    if (a == null && a == b) {\n        return true;\n    }\n    if (a === b) {\n        return true;\n    }\n    if (Object.prototype.toString.call(a) !== Object.prototype.toString.call(b)) {\n        return false;\n    }\n    if (isArray(a)) {\n        if (a.length !== b.length) {\n            return false;\n        }\n        for (var i = 0, length_1 = a.length; i < length_1; i++) {\n            if (!equals(a[i], b[i]))\n                return false;\n        }\n        return true;\n    }\n    else if (isObject(a)) {\n        if (Object.keys(a).length !== Object.keys(b).length) {\n            return false;\n        }\n        for (var key in a) {\n            if (!equals(a[key], b[key]))\n                return false;\n        }\n        return true;\n    }\n    return false;\n};\n\n/**\n * Walks through each value given the context - used for nested operations. E.g:\n * { \"person.address\": { $eq: \"blarg\" }}\n */\nvar walkKeyPathValues = function (item, keyPath, next, depth, key, owner) {\n    var currentKey = keyPath[depth];\n    // if array, then try matching. Might fall through for cases like:\n    // { $eq: [1, 2, 3] }, [ 1, 2, 3 ].\n    if (isArray(item) &&\n        isNaN(Number(currentKey)) &&\n        !isProperty(item, currentKey)) {\n        for (var i = 0, length_1 = item.length; i < length_1; i++) {\n            // if FALSE is returned, then terminate walker. For operations, this simply\n            // means that the search critera was met.\n            if (!walkKeyPathValues(item[i], keyPath, next, depth, i, item)) {\n                return false;\n            }\n        }\n    }\n    if (depth === keyPath.length || item == null) {\n        return next(item, key, owner, depth === 0, depth === keyPath.length);\n    }\n    return walkKeyPathValues(item[currentKey], keyPath, next, depth + 1, currentKey, item);\n};\nvar BaseOperation = /** @class */ (function () {\n    function BaseOperation(params, owneryQuery, options, name) {\n        this.params = params;\n        this.owneryQuery = owneryQuery;\n        this.options = options;\n        this.name = name;\n        this.init();\n    }\n    BaseOperation.prototype.init = function () { };\n    BaseOperation.prototype.reset = function () {\n        this.done = false;\n        this.keep = false;\n    };\n    return BaseOperation;\n}());\nvar GroupOperation = /** @class */ (function (_super) {\n    __extends(GroupOperation, _super);\n    function GroupOperation(params, owneryQuery, options, children) {\n        var _this = _super.call(this, params, owneryQuery, options) || this;\n        _this.children = children;\n        return _this;\n    }\n    /**\n     */\n    GroupOperation.prototype.reset = function () {\n        this.keep = false;\n        this.done = false;\n        for (var i = 0, length_2 = this.children.length; i < length_2; i++) {\n            this.children[i].reset();\n        }\n    };\n    /**\n     */\n    GroupOperation.prototype.childrenNext = function (item, key, owner, root, leaf) {\n        var done = true;\n        var keep = true;\n        for (var i = 0, length_3 = this.children.length; i < length_3; i++) {\n            var childOperation = this.children[i];\n            if (!childOperation.done) {\n                childOperation.next(item, key, owner, root, leaf);\n            }\n            if (!childOperation.keep) {\n                keep = false;\n            }\n            if (childOperation.done) {\n                if (!childOperation.keep) {\n                    break;\n                }\n            }\n            else {\n                done = false;\n            }\n        }\n        this.done = done;\n        this.keep = keep;\n    };\n    return GroupOperation;\n}(BaseOperation));\nvar NamedGroupOperation = /** @class */ (function (_super) {\n    __extends(NamedGroupOperation, _super);\n    function NamedGroupOperation(params, owneryQuery, options, children, name) {\n        var _this = _super.call(this, params, owneryQuery, options, children) || this;\n        _this.name = name;\n        return _this;\n    }\n    return NamedGroupOperation;\n}(GroupOperation));\nvar QueryOperation = /** @class */ (function (_super) {\n    __extends(QueryOperation, _super);\n    function QueryOperation() {\n        var _this = _super !== null && _super.apply(this, arguments) || this;\n        _this.propop = true;\n        return _this;\n    }\n    /**\n     */\n    QueryOperation.prototype.next = function (item, key, parent, root) {\n        this.childrenNext(item, key, parent, root);\n    };\n    return QueryOperation;\n}(GroupOperation));\nvar NestedOperation = /** @class */ (function (_super) {\n    __extends(NestedOperation, _super);\n    function NestedOperation(keyPath, params, owneryQuery, options, children) {\n        var _this = _super.call(this, params, owneryQuery, options, children) || this;\n        _this.keyPath = keyPath;\n        _this.propop = true;\n        /**\n         */\n        _this._nextNestedValue = function (value, key, owner, root, leaf) {\n            _this.childrenNext(value, key, owner, root, leaf);\n            return !_this.done;\n        };\n        return _this;\n    }\n    /**\n     */\n    NestedOperation.prototype.next = function (item, key, parent) {\n        walkKeyPathValues(item, this.keyPath, this._nextNestedValue, 0, key, parent);\n    };\n    return NestedOperation;\n}(GroupOperation));\nvar createTester = function (a, compare) {\n    if (a instanceof Function) {\n        return a;\n    }\n    if (a instanceof RegExp) {\n        return function (b) {\n            var result = typeof b === \"string\" && a.test(b);\n            a.lastIndex = 0;\n            return result;\n        };\n    }\n    var comparableA = comparable(a);\n    return function (b) { return compare(comparableA, comparable(b)); };\n};\nvar EqualsOperation = /** @class */ (function (_super) {\n    __extends(EqualsOperation, _super);\n    function EqualsOperation() {\n        var _this = _super !== null && _super.apply(this, arguments) || this;\n        _this.propop = true;\n        return _this;\n    }\n    EqualsOperation.prototype.init = function () {\n        this._test = createTester(this.params, this.options.compare);\n    };\n    EqualsOperation.prototype.next = function (item, key, parent) {\n        if (!Array.isArray(parent) || parent.hasOwnProperty(key)) {\n            if (this._test(item, key, parent)) {\n                this.done = true;\n                this.keep = true;\n            }\n        }\n    };\n    return EqualsOperation;\n}(BaseOperation));\nvar createEqualsOperation = function (params, owneryQuery, options) { return new EqualsOperation(params, owneryQuery, options); };\nvar numericalOperationCreator = function (createNumericalOperation) {\n    return function (params, owneryQuery, options, name) {\n        return createNumericalOperation(params, owneryQuery, options, name);\n    };\n};\nvar numericalOperation = function (createTester) {\n    return numericalOperationCreator(function (params, owneryQuery, options, name) {\n        var typeofParams = typeof comparable(params);\n        var test = createTester(params);\n        return new EqualsOperation(function (b) {\n            var actualValue = coercePotentiallyNull(b);\n            return (typeof comparable(actualValue) === typeofParams && test(actualValue));\n        }, owneryQuery, options, name);\n    });\n};\nvar createNamedOperation = function (name, params, parentQuery, options) {\n    var operationCreator = options.operations[name];\n    if (!operationCreator) {\n        throwUnsupportedOperation(name);\n    }\n    return operationCreator(params, parentQuery, options, name);\n};\nvar throwUnsupportedOperation = function (name) {\n    throw new Error(\"Unsupported operation: \".concat(name));\n};\nvar containsOperation = function (query, options) {\n    for (var key in query) {\n        if (options.operations.hasOwnProperty(key) || key.charAt(0) === \"$\")\n            return true;\n    }\n    return false;\n};\nvar createNestedOperation = function (keyPath, nestedQuery, parentKey, owneryQuery, options) {\n    if (containsOperation(nestedQuery, options)) {\n        var _a = createQueryOperations(nestedQuery, parentKey, options), selfOperations = _a[0], nestedOperations = _a[1];\n        if (nestedOperations.length) {\n            throw new Error(\"Property queries must contain only operations, or exact objects.\");\n        }\n        return new NestedOperation(keyPath, nestedQuery, owneryQuery, options, selfOperations);\n    }\n    return new NestedOperation(keyPath, nestedQuery, owneryQuery, options, [\n        new EqualsOperation(nestedQuery, owneryQuery, options),\n    ]);\n};\nvar createQueryOperation = function (query, owneryQuery, _a) {\n    if (owneryQuery === void 0) { owneryQuery = null; }\n    var _b = _a === void 0 ? {} : _a, compare = _b.compare, operations = _b.operations;\n    var options = {\n        compare: compare || equals,\n        operations: Object.assign({}, operations || {}),\n    };\n    var _c = createQueryOperations(query, null, options), selfOperations = _c[0], nestedOperations = _c[1];\n    var ops = [];\n    if (selfOperations.length) {\n        ops.push(new NestedOperation([], query, owneryQuery, options, selfOperations));\n    }\n    ops.push.apply(ops, nestedOperations);\n    if (ops.length === 1) {\n        return ops[0];\n    }\n    return new QueryOperation(query, owneryQuery, options, ops);\n};\nvar createQueryOperations = function (query, parentKey, options) {\n    var selfOperations = [];\n    var nestedOperations = [];\n    if (!isVanillaObject(query)) {\n        selfOperations.push(new EqualsOperation(query, query, options));\n        return [selfOperations, nestedOperations];\n    }\n    for (var key in query) {\n        if (options.operations.hasOwnProperty(key)) {\n            var op = createNamedOperation(key, query[key], query, options);\n            if (op) {\n                if (!op.propop && parentKey && !options.operations[parentKey]) {\n                    throw new Error(\"Malformed query. \".concat(key, \" cannot be matched against property.\"));\n                }\n            }\n            // probably just a flag for another operation (like $options)\n            if (op != null) {\n                selfOperations.push(op);\n            }\n        }\n        else if (key.charAt(0) === \"$\") {\n            throwUnsupportedOperation(key);\n        }\n        else {\n            nestedOperations.push(createNestedOperation(key.split(\".\"), query[key], key, query, options));\n        }\n    }\n    return [selfOperations, nestedOperations];\n};\nvar createOperationTester = function (operation) {\n    return function (item, key, owner) {\n        operation.reset();\n        operation.next(item, key, owner);\n        return operation.keep;\n    };\n};\nvar createQueryTester = function (query, options) {\n    if (options === void 0) { options = {}; }\n    return createOperationTester(createQueryOperation(query, null, options));\n};\n\nvar $Ne = /** @class */ (function (_super) {\n    __extends($Ne, _super);\n    function $Ne() {\n        var _this = _super !== null && _super.apply(this, arguments) || this;\n        _this.propop = true;\n        return _this;\n    }\n    $Ne.prototype.init = function () {\n        this._test = createTester(this.params, this.options.compare);\n    };\n    $Ne.prototype.reset = function () {\n        _super.prototype.reset.call(this);\n        this.keep = true;\n    };\n    $Ne.prototype.next = function (item) {\n        if (this._test(item)) {\n            this.done = true;\n            this.keep = false;\n        }\n    };\n    return $Ne;\n}(BaseOperation));\n// https://docs.mongodb.com/manual/reference/operator/query/elemMatch/\nvar $ElemMatch = /** @class */ (function (_super) {\n    __extends($ElemMatch, _super);\n    function $ElemMatch() {\n        var _this = _super !== null && _super.apply(this, arguments) || this;\n        _this.propop = true;\n        return _this;\n    }\n    $ElemMatch.prototype.init = function () {\n        if (!this.params || typeof this.params !== \"object\") {\n            throw new Error(\"Malformed query. $elemMatch must by an object.\");\n        }\n        this._queryOperation = createQueryOperation(this.params, this.owneryQuery, this.options);\n    };\n    $ElemMatch.prototype.reset = function () {\n        _super.prototype.reset.call(this);\n        this._queryOperation.reset();\n    };\n    $ElemMatch.prototype.next = function (item) {\n        if (isArray(item)) {\n            for (var i = 0, length_1 = item.length; i < length_1; i++) {\n                // reset query operation since item being tested needs to pass _all_ query\n                // operations for it to be a success\n                this._queryOperation.reset();\n                var child = item[i];\n                this._queryOperation.next(child, i, item, false);\n                this.keep = this.keep || this._queryOperation.keep;\n            }\n            this.done = true;\n        }\n        else {\n            this.done = false;\n            this.keep = false;\n        }\n    };\n    return $ElemMatch;\n}(BaseOperation));\nvar $Not = /** @class */ (function (_super) {\n    __extends($Not, _super);\n    function $Not() {\n        var _this = _super !== null && _super.apply(this, arguments) || this;\n        _this.propop = true;\n        return _this;\n    }\n    $Not.prototype.init = function () {\n        this._queryOperation = createQueryOperation(this.params, this.owneryQuery, this.options);\n    };\n    $Not.prototype.reset = function () {\n        _super.prototype.reset.call(this);\n        this._queryOperation.reset();\n    };\n    $Not.prototype.next = function (item, key, owner, root) {\n        this._queryOperation.next(item, key, owner, root);\n        this.done = this._queryOperation.done;\n        this.keep = !this._queryOperation.keep;\n    };\n    return $Not;\n}(BaseOperation));\nvar $Size = /** @class */ (function (_super) {\n    __extends($Size, _super);\n    function $Size() {\n        var _this = _super !== null && _super.apply(this, arguments) || this;\n        _this.propop = true;\n        return _this;\n    }\n    $Size.prototype.init = function () { };\n    $Size.prototype.next = function (item) {\n        if (isArray(item) && item.length === this.params) {\n            this.done = true;\n            this.keep = true;\n        }\n        // if (parent && parent.length === this.params) {\n        //   this.done = true;\n        //   this.keep = true;\n        // }\n    };\n    return $Size;\n}(BaseOperation));\nvar assertGroupNotEmpty = function (values) {\n    if (values.length === 0) {\n        throw new Error(\"$and/$or/$nor must be a nonempty array\");\n    }\n};\nvar $Or = /** @class */ (function (_super) {\n    __extends($Or, _super);\n    function $Or() {\n        var _this = _super !== null && _super.apply(this, arguments) || this;\n        _this.propop = false;\n        return _this;\n    }\n    $Or.prototype.init = function () {\n        var _this = this;\n        assertGroupNotEmpty(this.params);\n        this._ops = this.params.map(function (op) {\n            return createQueryOperation(op, null, _this.options);\n        });\n    };\n    $Or.prototype.reset = function () {\n        this.done = false;\n        this.keep = false;\n        for (var i = 0, length_2 = this._ops.length; i < length_2; i++) {\n            this._ops[i].reset();\n        }\n    };\n    $Or.prototype.next = function (item, key, owner) {\n        var done = false;\n        var success = false;\n        for (var i = 0, length_3 = this._ops.length; i < length_3; i++) {\n            var op = this._ops[i];\n            op.next(item, key, owner);\n            if (op.keep) {\n                done = true;\n                success = op.keep;\n                break;\n            }\n        }\n        this.keep = success;\n        this.done = done;\n    };\n    return $Or;\n}(BaseOperation));\nvar $Nor = /** @class */ (function (_super) {\n    __extends($Nor, _super);\n    function $Nor() {\n        var _this = _super !== null && _super.apply(this, arguments) || this;\n        _this.propop = false;\n        return _this;\n    }\n    $Nor.prototype.next = function (item, key, owner) {\n        _super.prototype.next.call(this, item, key, owner);\n        this.keep = !this.keep;\n    };\n    return $Nor;\n}($Or));\nvar $In = /** @class */ (function (_super) {\n    __extends($In, _super);\n    function $In() {\n        var _this = _super !== null && _super.apply(this, arguments) || this;\n        _this.propop = true;\n        return _this;\n    }\n    $In.prototype.init = function () {\n        var _this = this;\n        var params = Array.isArray(this.params) ? this.params : [this.params];\n        this._testers = params.map(function (value) {\n            if (containsOperation(value, _this.options)) {\n                throw new Error(\"cannot nest $ under \".concat(_this.name.toLowerCase()));\n            }\n            return createTester(value, _this.options.compare);\n        });\n    };\n    $In.prototype.next = function (item, key, owner) {\n        var done = false;\n        var success = false;\n        for (var i = 0, length_4 = this._testers.length; i < length_4; i++) {\n            var test = this._testers[i];\n            if (test(item)) {\n                done = true;\n                success = true;\n                break;\n            }\n        }\n        this.keep = success;\n        this.done = done;\n    };\n    return $In;\n}(BaseOperation));\nvar $Nin = /** @class */ (function (_super) {\n    __extends($Nin, _super);\n    function $Nin(params, ownerQuery, options, name) {\n        var _this = _super.call(this, params, ownerQuery, options, name) || this;\n        _this.propop = true;\n        _this._in = new $In(params, ownerQuery, options, name);\n        return _this;\n    }\n    $Nin.prototype.next = function (item, key, owner, root) {\n        this._in.next(item, key, owner);\n        if (isArray(owner) && !root) {\n            if (this._in.keep) {\n                this.keep = false;\n                this.done = true;\n            }\n            else if (key == owner.length - 1) {\n                this.keep = true;\n                this.done = true;\n            }\n        }\n        else {\n            this.keep = !this._in.keep;\n            this.done = true;\n        }\n    };\n    $Nin.prototype.reset = function () {\n        _super.prototype.reset.call(this);\n        this._in.reset();\n    };\n    return $Nin;\n}(BaseOperation));\nvar $Exists = /** @class */ (function (_super) {\n    __extends($Exists, _super);\n    function $Exists() {\n        var _this = _super !== null && _super.apply(this, arguments) || this;\n        _this.propop = true;\n        return _this;\n    }\n    $Exists.prototype.next = function (item, key, owner, root, leaf) {\n        if (!leaf) {\n            this.done = true;\n            this.keep = !this.params;\n        }\n        else if (owner.hasOwnProperty(key) === this.params) {\n            this.done = true;\n            this.keep = true;\n        }\n    };\n    return $Exists;\n}(BaseOperation));\nvar $And = /** @class */ (function (_super) {\n    __extends($And, _super);\n    function $And(params, owneryQuery, options, name) {\n        var _this = _super.call(this, params, owneryQuery, options, params.map(function (query) { return createQueryOperation(query, owneryQuery, options); }), name) || this;\n        _this.propop = false;\n        assertGroupNotEmpty(params);\n        return _this;\n    }\n    $And.prototype.next = function (item, key, owner, root) {\n        this.childrenNext(item, key, owner, root);\n    };\n    return $And;\n}(NamedGroupOperation));\nvar $All = /** @class */ (function (_super) {\n    __extends($All, _super);\n    function $All(params, owneryQuery, options, name) {\n        var _this = _super.call(this, params, owneryQuery, options, params.map(function (query) { return createQueryOperation(query, owneryQuery, options); }), name) || this;\n        _this.propop = true;\n        return _this;\n    }\n    $All.prototype.next = function (item, key, owner, root) {\n        this.childrenNext(item, key, owner, root);\n    };\n    return $All;\n}(NamedGroupOperation));\nvar $eq = function (params, owneryQuery, options) {\n    return new EqualsOperation(params, owneryQuery, options);\n};\nvar $ne = function (params, owneryQuery, options, name) { return new $Ne(params, owneryQuery, options, name); };\nvar $or = function (params, owneryQuery, options, name) { return new $Or(params, owneryQuery, options, name); };\nvar $nor = function (params, owneryQuery, options, name) { return new $Nor(params, owneryQuery, options, name); };\nvar $elemMatch = function (params, owneryQuery, options, name) { return new $ElemMatch(params, owneryQuery, options, name); };\nvar $nin = function (params, owneryQuery, options, name) { return new $Nin(params, owneryQuery, options, name); };\nvar $in = function (params, owneryQuery, options, name) {\n    return new $In(params, owneryQuery, options, name);\n};\nvar $lt = numericalOperation(function (params) { return function (b) {\n    return b != null && b < params;\n}; });\nvar $lte = numericalOperation(function (params) { return function (b) {\n    return b === params || b <= params;\n}; });\nvar $gt = numericalOperation(function (params) { return function (b) {\n    return b != null && b > params;\n}; });\nvar $gte = numericalOperation(function (params) { return function (b) {\n    return b === params || b >= params;\n}; });\nvar $mod = function (_a, owneryQuery, options) {\n    var mod = _a[0], equalsValue = _a[1];\n    return new EqualsOperation(function (b) { return comparable(b) % mod === equalsValue; }, owneryQuery, options);\n};\nvar $exists = function (params, owneryQuery, options, name) { return new $Exists(params, owneryQuery, options, name); };\nvar $regex = function (pattern, owneryQuery, options) {\n    return new EqualsOperation(new RegExp(pattern, owneryQuery.$options), owneryQuery, options);\n};\nvar $not = function (params, owneryQuery, options, name) { return new $Not(params, owneryQuery, options, name); };\nvar typeAliases = {\n    number: function (v) { return typeof v === \"number\"; },\n    string: function (v) { return typeof v === \"string\"; },\n    bool: function (v) { return typeof v === \"boolean\"; },\n    array: function (v) { return Array.isArray(v); },\n    null: function (v) { return v === null; },\n    timestamp: function (v) { return v instanceof Date; },\n};\nvar $type = function (clazz, owneryQuery, options) {\n    return new EqualsOperation(function (b) {\n        if (typeof clazz === \"string\") {\n            if (!typeAliases[clazz]) {\n                throw new Error(\"Type alias does not exist\");\n            }\n            return typeAliases[clazz](b);\n        }\n        return b != null ? b instanceof clazz || b.constructor === clazz : false;\n    }, owneryQuery, options);\n};\nvar $and = function (params, ownerQuery, options, name) { return new $And(params, ownerQuery, options, name); };\nvar $all = function (params, ownerQuery, options, name) { return new $All(params, ownerQuery, options, name); };\nvar $size = function (params, ownerQuery, options) { return new $Size(params, ownerQuery, options, \"$size\"); };\nvar $options = function () { return null; };\nvar $where = function (params, ownerQuery, options) {\n    var test;\n    if (isFunction(params)) {\n        test = params;\n    }\n    else if (!process.env.CSP_ENABLED) {\n        test = new Function(\"obj\", \"return \" + params);\n    }\n    else {\n        throw new Error(\"In CSP mode, sift does not support strings in \\\"$where\\\" condition\");\n    }\n    return new EqualsOperation(function (b) { return test.bind(b)(b); }, ownerQuery, options);\n};\n\nvar defaultOperations = /*#__PURE__*/Object.freeze({\n    __proto__: null,\n    $Size: $Size,\n    $all: $all,\n    $and: $and,\n    $elemMatch: $elemMatch,\n    $eq: $eq,\n    $exists: $exists,\n    $gt: $gt,\n    $gte: $gte,\n    $in: $in,\n    $lt: $lt,\n    $lte: $lte,\n    $mod: $mod,\n    $ne: $ne,\n    $nin: $nin,\n    $nor: $nor,\n    $not: $not,\n    $options: $options,\n    $or: $or,\n    $regex: $regex,\n    $size: $size,\n    $type: $type,\n    $where: $where\n});\n\nvar createDefaultQueryOperation = function (query, ownerQuery, _a) {\n    var _b = _a === void 0 ? {} : _a, compare = _b.compare, operations = _b.operations;\n    return createQueryOperation(query, ownerQuery, {\n        compare: compare,\n        operations: Object.assign({}, defaultOperations, operations || {}),\n    });\n};\nvar createDefaultQueryTester = function (query, options) {\n    if (options === void 0) { options = {}; }\n    var op = createDefaultQueryOperation(query, null, options);\n    return createOperationTester(op);\n};\n\n\n//# sourceMappingURL=index.js.map\n\n\n//# sourceURL=webpack://experimento/./node_modules/sift/es5m/index.js?");

/***/ }),

/***/ "./node_modules/sparse-bitfield/index.js":
/*!***********************************************!*\
  !*** ./node_modules/sparse-bitfield/index.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var pager = __webpack_require__(/*! memory-pager */ \"./node_modules/memory-pager/index.js\")\n\nmodule.exports = Bitfield\n\nfunction Bitfield (opts) {\n  if (!(this instanceof Bitfield)) return new Bitfield(opts)\n  if (!opts) opts = {}\n  if (Buffer.isBuffer(opts)) opts = {buffer: opts}\n\n  this.pageOffset = opts.pageOffset || 0\n  this.pageSize = opts.pageSize || 1024\n  this.pages = opts.pages || pager(this.pageSize)\n\n  this.byteLength = this.pages.length * this.pageSize\n  this.length = 8 * this.byteLength\n\n  if (!powerOfTwo(this.pageSize)) throw new Error('The page size should be a power of two')\n\n  this._trackUpdates = !!opts.trackUpdates\n  this._pageMask = this.pageSize - 1\n\n  if (opts.buffer) {\n    for (var i = 0; i < opts.buffer.length; i += this.pageSize) {\n      this.pages.set(i / this.pageSize, opts.buffer.slice(i, i + this.pageSize))\n    }\n    this.byteLength = opts.buffer.length\n    this.length = 8 * this.byteLength\n  }\n}\n\nBitfield.prototype.get = function (i) {\n  var o = i & 7\n  var j = (i - o) / 8\n\n  return !!(this.getByte(j) & (128 >> o))\n}\n\nBitfield.prototype.getByte = function (i) {\n  var o = i & this._pageMask\n  var j = (i - o) / this.pageSize\n  var page = this.pages.get(j, true)\n\n  return page ? page.buffer[o + this.pageOffset] : 0\n}\n\nBitfield.prototype.set = function (i, v) {\n  var o = i & 7\n  var j = (i - o) / 8\n  var b = this.getByte(j)\n\n  return this.setByte(j, v ? b | (128 >> o) : b & (255 ^ (128 >> o)))\n}\n\nBitfield.prototype.toBuffer = function () {\n  var all = alloc(this.pages.length * this.pageSize)\n\n  for (var i = 0; i < this.pages.length; i++) {\n    var next = this.pages.get(i, true)\n    var allOffset = i * this.pageSize\n    if (next) next.buffer.copy(all, allOffset, this.pageOffset, this.pageOffset + this.pageSize)\n  }\n\n  return all\n}\n\nBitfield.prototype.setByte = function (i, b) {\n  var o = i & this._pageMask\n  var j = (i - o) / this.pageSize\n  var page = this.pages.get(j, false)\n\n  o += this.pageOffset\n\n  if (page.buffer[o] === b) return false\n  page.buffer[o] = b\n\n  if (i >= this.byteLength) {\n    this.byteLength = i + 1\n    this.length = this.byteLength * 8\n  }\n\n  if (this._trackUpdates) this.pages.updated(page)\n\n  return true\n}\n\nfunction alloc (n) {\n  if (Buffer.alloc) return Buffer.alloc(n)\n  var b = new Buffer(n)\n  b.fill(0)\n  return b\n}\n\nfunction powerOfTwo (x) {\n  return !(x & (x - 1))\n}\n\n\n//# sourceURL=webpack://experimento/./node_modules/sparse-bitfield/index.js?");

/***/ }),

/***/ "./node_modules/supports-color/index.js":
/*!**********************************************!*\
  !*** ./node_modules/supports-color/index.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst os = __webpack_require__(/*! os */ \"os\");\nconst hasFlag = __webpack_require__(/*! has-flag */ \"./node_modules/has-flag/index.js\");\n\nconst env = process.env;\n\nlet forceColor;\nif (hasFlag('no-color') ||\n\thasFlag('no-colors') ||\n\thasFlag('color=false')) {\n\tforceColor = false;\n} else if (hasFlag('color') ||\n\thasFlag('colors') ||\n\thasFlag('color=true') ||\n\thasFlag('color=always')) {\n\tforceColor = true;\n}\nif ('FORCE_COLOR' in env) {\n\tforceColor = env.FORCE_COLOR.length === 0 || parseInt(env.FORCE_COLOR, 10) !== 0;\n}\n\nfunction translateLevel(level) {\n\tif (level === 0) {\n\t\treturn false;\n\t}\n\n\treturn {\n\t\tlevel,\n\t\thasBasic: true,\n\t\thas256: level >= 2,\n\t\thas16m: level >= 3\n\t};\n}\n\nfunction supportsColor(stream) {\n\tif (forceColor === false) {\n\t\treturn 0;\n\t}\n\n\tif (hasFlag('color=16m') ||\n\t\thasFlag('color=full') ||\n\t\thasFlag('color=truecolor')) {\n\t\treturn 3;\n\t}\n\n\tif (hasFlag('color=256')) {\n\t\treturn 2;\n\t}\n\n\tif (stream && !stream.isTTY && forceColor !== true) {\n\t\treturn 0;\n\t}\n\n\tconst min = forceColor ? 1 : 0;\n\n\tif (process.platform === 'win32') {\n\t\t// Node.js 7.5.0 is the first version of Node.js to include a patch to\n\t\t// libuv that enables 256 color output on Windows. Anything earlier and it\n\t\t// won't work. However, here we target Node.js 8 at minimum as it is an LTS\n\t\t// release, and Node.js 7 is not. Windows 10 build 10586 is the first Windows\n\t\t// release that supports 256 colors. Windows 10 build 14931 is the first release\n\t\t// that supports 16m/TrueColor.\n\t\tconst osRelease = os.release().split('.');\n\t\tif (\n\t\t\tNumber(process.versions.node.split('.')[0]) >= 8 &&\n\t\t\tNumber(osRelease[0]) >= 10 &&\n\t\t\tNumber(osRelease[2]) >= 10586\n\t\t) {\n\t\t\treturn Number(osRelease[2]) >= 14931 ? 3 : 2;\n\t\t}\n\n\t\treturn 1;\n\t}\n\n\tif ('CI' in env) {\n\t\tif (['TRAVIS', 'CIRCLECI', 'APPVEYOR', 'GITLAB_CI'].some(sign => sign in env) || env.CI_NAME === 'codeship') {\n\t\t\treturn 1;\n\t\t}\n\n\t\treturn min;\n\t}\n\n\tif ('TEAMCITY_VERSION' in env) {\n\t\treturn /^(9\\.(0*[1-9]\\d*)\\.|\\d{2,}\\.)/.test(env.TEAMCITY_VERSION) ? 1 : 0;\n\t}\n\n\tif (env.COLORTERM === 'truecolor') {\n\t\treturn 3;\n\t}\n\n\tif ('TERM_PROGRAM' in env) {\n\t\tconst version = parseInt((env.TERM_PROGRAM_VERSION || '').split('.')[0], 10);\n\n\t\tswitch (env.TERM_PROGRAM) {\n\t\t\tcase 'iTerm.app':\n\t\t\t\treturn version >= 3 ? 3 : 2;\n\t\t\tcase 'Apple_Terminal':\n\t\t\t\treturn 2;\n\t\t\t// No default\n\t\t}\n\t}\n\n\tif (/-256(color)?$/i.test(env.TERM)) {\n\t\treturn 2;\n\t}\n\n\tif (/^screen|^xterm|^vt100|^vt220|^rxvt|color|ansi|cygwin|linux/i.test(env.TERM)) {\n\t\treturn 1;\n\t}\n\n\tif ('COLORTERM' in env) {\n\t\treturn 1;\n\t}\n\n\tif (env.TERM === 'dumb') {\n\t\treturn min;\n\t}\n\n\treturn min;\n}\n\nfunction getSupportLevel(stream) {\n\tconst level = supportsColor(stream);\n\treturn translateLevel(level);\n}\n\nmodule.exports = {\n\tsupportsColor: getSupportLevel,\n\tstdout: getSupportLevel(process.stdout),\n\tstderr: getSupportLevel(process.stderr)\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/supports-color/index.js?");

/***/ }),

/***/ "./node_modules/tr46/index.js":
/*!************************************!*\
  !*** ./node_modules/tr46/index.js ***!
  \************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst punycode = __webpack_require__(/*! punycode/ */ \"./node_modules/punycode/punycode.es6.js\");\nconst regexes = __webpack_require__(/*! ./lib/regexes.js */ \"./node_modules/tr46/lib/regexes.js\");\nconst mappingTable = __webpack_require__(/*! ./lib/mappingTable.json */ \"./node_modules/tr46/lib/mappingTable.json\");\nconst { STATUS_MAPPING } = __webpack_require__(/*! ./lib/statusMapping.js */ \"./node_modules/tr46/lib/statusMapping.js\");\n\nfunction containsNonASCII(str) {\n  return /[^\\x00-\\x7F]/u.test(str);\n}\n\nfunction findStatus(val, { useSTD3ASCIIRules }) {\n  let start = 0;\n  let end = mappingTable.length - 1;\n\n  while (start <= end) {\n    const mid = Math.floor((start + end) / 2);\n\n    const target = mappingTable[mid];\n    const min = Array.isArray(target[0]) ? target[0][0] : target[0];\n    const max = Array.isArray(target[0]) ? target[0][1] : target[0];\n\n    if (min <= val && max >= val) {\n      if (useSTD3ASCIIRules &&\n          (target[1] === STATUS_MAPPING.disallowed_STD3_valid || target[1] === STATUS_MAPPING.disallowed_STD3_mapped)) {\n        return [STATUS_MAPPING.disallowed, ...target.slice(2)];\n      } else if (target[1] === STATUS_MAPPING.disallowed_STD3_valid) {\n        return [STATUS_MAPPING.valid, ...target.slice(2)];\n      } else if (target[1] === STATUS_MAPPING.disallowed_STD3_mapped) {\n        return [STATUS_MAPPING.mapped, ...target.slice(2)];\n      }\n\n      return target.slice(1);\n    } else if (min > val) {\n      end = mid - 1;\n    } else {\n      start = mid + 1;\n    }\n  }\n\n  return null;\n}\n\nfunction mapChars(domainName, { useSTD3ASCIIRules, processingOption }) {\n  let hasError = false;\n  let processed = \"\";\n\n  for (const ch of domainName) {\n    const [status, mapping] = findStatus(ch.codePointAt(0), { useSTD3ASCIIRules });\n\n    switch (status) {\n      case STATUS_MAPPING.disallowed:\n        hasError = true;\n        processed += ch;\n        break;\n      case STATUS_MAPPING.ignored:\n        break;\n      case STATUS_MAPPING.mapped:\n        processed += mapping;\n        break;\n      case STATUS_MAPPING.deviation:\n        if (processingOption === \"transitional\") {\n          processed += mapping;\n        } else {\n          processed += ch;\n        }\n        break;\n      case STATUS_MAPPING.valid:\n        processed += ch;\n        break;\n    }\n  }\n\n  return {\n    string: processed,\n    error: hasError\n  };\n}\n\nfunction validateLabel(label, { checkHyphens, checkBidi, checkJoiners, processingOption, useSTD3ASCIIRules }) {\n  if (label.normalize(\"NFC\") !== label) {\n    return false;\n  }\n\n  const codePoints = Array.from(label);\n\n  if (checkHyphens) {\n    if ((codePoints[2] === \"-\" && codePoints[3] === \"-\") ||\n        (label.startsWith(\"-\") || label.endsWith(\"-\"))) {\n      return false;\n    }\n  }\n\n  if (label.includes(\".\") ||\n      (codePoints.length > 0 && regexes.combiningMarks.test(codePoints[0]))) {\n    return false;\n  }\n\n  for (const ch of codePoints) {\n    const [status] = findStatus(ch.codePointAt(0), { useSTD3ASCIIRules });\n    if ((processingOption === \"transitional\" && status !== STATUS_MAPPING.valid) ||\n        (processingOption === \"nontransitional\" &&\n         status !== STATUS_MAPPING.valid && status !== STATUS_MAPPING.deviation)) {\n      return false;\n    }\n  }\n\n  // https://tools.ietf.org/html/rfc5892#appendix-A\n  if (checkJoiners) {\n    let last = 0;\n    for (const [i, ch] of codePoints.entries()) {\n      if (ch === \"\\u200C\" || ch === \"\\u200D\") {\n        if (i > 0) {\n          if (regexes.combiningClassVirama.test(codePoints[i - 1])) {\n            continue;\n          }\n          if (ch === \"\\u200C\") {\n            // TODO: make this more efficient\n            const next = codePoints.indexOf(\"\\u200C\", i + 1);\n            const test = next < 0 ? codePoints.slice(last) : codePoints.slice(last, next);\n            if (regexes.validZWNJ.test(test.join(\"\"))) {\n              last = i + 1;\n              continue;\n            }\n          }\n        }\n        return false;\n      }\n    }\n  }\n\n  // https://tools.ietf.org/html/rfc5893#section-2\n  // For the codePoints length check, see discussion in https://github.com/jsdom/whatwg-url/pull/250 and the second item\n  // in https://github.com/whatwg/url/issues/744.\n  if (checkBidi && codePoints.length > 0) {\n    let rtl;\n\n    // 1\n    if (regexes.bidiS1LTR.test(codePoints[0])) {\n      rtl = false;\n    } else if (regexes.bidiS1RTL.test(codePoints[0])) {\n      rtl = true;\n    } else {\n      return false;\n    }\n\n    if (rtl) {\n      // 2-4\n      if (!regexes.bidiS2.test(label) ||\n          !regexes.bidiS3.test(label) ||\n          (regexes.bidiS4EN.test(label) && regexes.bidiS4AN.test(label))) {\n        return false;\n      }\n    } else if (!regexes.bidiS5.test(label) ||\n               !regexes.bidiS6.test(label)) { // 5-6\n      return false;\n    }\n  }\n\n  return true;\n}\n\nfunction isBidiDomain(labels) {\n  const domain = labels.map(label => {\n    if (label.startsWith(\"xn--\")) {\n      try {\n        return punycode.decode(label.substring(4));\n      } catch (err) {\n        return \"\";\n      }\n    }\n    return label;\n  }).join(\".\");\n  return regexes.bidiDomain.test(domain);\n}\n\nfunction processing(domainName, options) {\n  const { processingOption } = options;\n\n  // 1. Map.\n  let { string, error } = mapChars(domainName, options);\n\n  // 2. Normalize.\n  string = string.normalize(\"NFC\");\n\n  // 3. Break.\n  const labels = string.split(\".\");\n  const isBidi = isBidiDomain(labels);\n\n  // 4. Convert/Validate.\n  for (const [i, origLabel] of labels.entries()) {\n    let label = origLabel;\n    let curProcessing = processingOption;\n    if (label.startsWith(\"xn--\")) {\n      try {\n        label = punycode.decode(label.substring(4));\n        labels[i] = label;\n      } catch (err) {\n        error = true;\n        continue;\n      }\n      curProcessing = \"nontransitional\";\n    }\n\n    // No need to validate if we already know there is an error.\n    if (error) {\n      continue;\n    }\n    const validation = validateLabel(label, {\n      ...options,\n      processingOption: curProcessing,\n      checkBidi: options.checkBidi && isBidi\n    });\n    if (!validation) {\n      error = true;\n    }\n  }\n\n  return {\n    string: labels.join(\".\"),\n    error\n  };\n}\n\nfunction toASCII(domainName, {\n  checkHyphens = false,\n  checkBidi = false,\n  checkJoiners = false,\n  useSTD3ASCIIRules = false,\n  processingOption = \"nontransitional\",\n  verifyDNSLength = false\n} = {}) {\n  if (processingOption !== \"transitional\" && processingOption !== \"nontransitional\") {\n    throw new RangeError(\"processingOption must be either transitional or nontransitional\");\n  }\n\n  const result = processing(domainName, {\n    processingOption,\n    checkHyphens,\n    checkBidi,\n    checkJoiners,\n    useSTD3ASCIIRules\n  });\n  let labels = result.string.split(\".\");\n  labels = labels.map(l => {\n    if (containsNonASCII(l)) {\n      try {\n        return `xn--${punycode.encode(l)}`;\n      } catch (e) {\n        result.error = true;\n      }\n    }\n    return l;\n  });\n\n  if (verifyDNSLength) {\n    const total = labels.join(\".\").length;\n    if (total > 253 || total === 0) {\n      result.error = true;\n    }\n\n    for (let i = 0; i < labels.length; ++i) {\n      if (labels[i].length > 63 || labels[i].length === 0) {\n        result.error = true;\n        break;\n      }\n    }\n  }\n\n  if (result.error) {\n    return null;\n  }\n  return labels.join(\".\");\n}\n\nfunction toUnicode(domainName, {\n  checkHyphens = false,\n  checkBidi = false,\n  checkJoiners = false,\n  useSTD3ASCIIRules = false,\n  processingOption = \"nontransitional\"\n} = {}) {\n  const result = processing(domainName, {\n    processingOption,\n    checkHyphens,\n    checkBidi,\n    checkJoiners,\n    useSTD3ASCIIRules\n  });\n\n  return {\n    domain: result.string,\n    error: result.error\n  };\n}\n\nmodule.exports = {\n  toASCII,\n  toUnicode\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/tr46/index.js?");

/***/ }),

/***/ "./node_modules/tr46/lib/regexes.js":
/*!******************************************!*\
  !*** ./node_modules/tr46/lib/regexes.js ***!
  \******************************************/
/***/ ((module) => {

"use strict";
eval("\n\nconst combiningMarks = /[\\u0300-\\u036F\\u0483-\\u0489\\u0591-\\u05BD\\u05BF\\u05C1\\u05C2\\u05C4\\u05C5\\u05C7\\u0610-\\u061A\\u064B-\\u065F\\u0670\\u06D6-\\u06DC\\u06DF-\\u06E4\\u06E7\\u06E8\\u06EA-\\u06ED\\u0711\\u0730-\\u074A\\u07A6-\\u07B0\\u07EB-\\u07F3\\u07FD\\u0816-\\u0819\\u081B-\\u0823\\u0825-\\u0827\\u0829-\\u082D\\u0859-\\u085B\\u0898-\\u089F\\u08CA-\\u08E1\\u08E3-\\u0903\\u093A-\\u093C\\u093E-\\u094F\\u0951-\\u0957\\u0962\\u0963\\u0981-\\u0983\\u09BC\\u09BE-\\u09C4\\u09C7\\u09C8\\u09CB-\\u09CD\\u09D7\\u09E2\\u09E3\\u09FE\\u0A01-\\u0A03\\u0A3C\\u0A3E-\\u0A42\\u0A47\\u0A48\\u0A4B-\\u0A4D\\u0A51\\u0A70\\u0A71\\u0A75\\u0A81-\\u0A83\\u0ABC\\u0ABE-\\u0AC5\\u0AC7-\\u0AC9\\u0ACB-\\u0ACD\\u0AE2\\u0AE3\\u0AFA-\\u0AFF\\u0B01-\\u0B03\\u0B3C\\u0B3E-\\u0B44\\u0B47\\u0B48\\u0B4B-\\u0B4D\\u0B55-\\u0B57\\u0B62\\u0B63\\u0B82\\u0BBE-\\u0BC2\\u0BC6-\\u0BC8\\u0BCA-\\u0BCD\\u0BD7\\u0C00-\\u0C04\\u0C3C\\u0C3E-\\u0C44\\u0C46-\\u0C48\\u0C4A-\\u0C4D\\u0C55\\u0C56\\u0C62\\u0C63\\u0C81-\\u0C83\\u0CBC\\u0CBE-\\u0CC4\\u0CC6-\\u0CC8\\u0CCA-\\u0CCD\\u0CD5\\u0CD6\\u0CE2\\u0CE3\\u0CF3\\u0D00-\\u0D03\\u0D3B\\u0D3C\\u0D3E-\\u0D44\\u0D46-\\u0D48\\u0D4A-\\u0D4D\\u0D57\\u0D62\\u0D63\\u0D81-\\u0D83\\u0DCA\\u0DCF-\\u0DD4\\u0DD6\\u0DD8-\\u0DDF\\u0DF2\\u0DF3\\u0E31\\u0E34-\\u0E3A\\u0E47-\\u0E4E\\u0EB1\\u0EB4-\\u0EBC\\u0EC8-\\u0ECE\\u0F18\\u0F19\\u0F35\\u0F37\\u0F39\\u0F3E\\u0F3F\\u0F71-\\u0F84\\u0F86\\u0F87\\u0F8D-\\u0F97\\u0F99-\\u0FBC\\u0FC6\\u102B-\\u103E\\u1056-\\u1059\\u105E-\\u1060\\u1062-\\u1064\\u1067-\\u106D\\u1071-\\u1074\\u1082-\\u108D\\u108F\\u109A-\\u109D\\u135D-\\u135F\\u1712-\\u1715\\u1732-\\u1734\\u1752\\u1753\\u1772\\u1773\\u17B4-\\u17D3\\u17DD\\u180B-\\u180D\\u180F\\u1885\\u1886\\u18A9\\u1920-\\u192B\\u1930-\\u193B\\u1A17-\\u1A1B\\u1A55-\\u1A5E\\u1A60-\\u1A7C\\u1A7F\\u1AB0-\\u1ACE\\u1B00-\\u1B04\\u1B34-\\u1B44\\u1B6B-\\u1B73\\u1B80-\\u1B82\\u1BA1-\\u1BAD\\u1BE6-\\u1BF3\\u1C24-\\u1C37\\u1CD0-\\u1CD2\\u1CD4-\\u1CE8\\u1CED\\u1CF4\\u1CF7-\\u1CF9\\u1DC0-\\u1DFF\\u20D0-\\u20F0\\u2CEF-\\u2CF1\\u2D7F\\u2DE0-\\u2DFF\\u302A-\\u302F\\u3099\\u309A\\uA66F-\\uA672\\uA674-\\uA67D\\uA69E\\uA69F\\uA6F0\\uA6F1\\uA802\\uA806\\uA80B\\uA823-\\uA827\\uA82C\\uA880\\uA881\\uA8B4-\\uA8C5\\uA8E0-\\uA8F1\\uA8FF\\uA926-\\uA92D\\uA947-\\uA953\\uA980-\\uA983\\uA9B3-\\uA9C0\\uA9E5\\uAA29-\\uAA36\\uAA43\\uAA4C\\uAA4D\\uAA7B-\\uAA7D\\uAAB0\\uAAB2-\\uAAB4\\uAAB7\\uAAB8\\uAABE\\uAABF\\uAAC1\\uAAEB-\\uAAEF\\uAAF5\\uAAF6\\uABE3-\\uABEA\\uABEC\\uABED\\uFB1E\\uFE00-\\uFE0F\\uFE20-\\uFE2F\\u{101FD}\\u{102E0}\\u{10376}-\\u{1037A}\\u{10A01}-\\u{10A03}\\u{10A05}\\u{10A06}\\u{10A0C}-\\u{10A0F}\\u{10A38}-\\u{10A3A}\\u{10A3F}\\u{10AE5}\\u{10AE6}\\u{10D24}-\\u{10D27}\\u{10EAB}\\u{10EAC}\\u{10EFD}-\\u{10EFF}\\u{10F46}-\\u{10F50}\\u{10F82}-\\u{10F85}\\u{11000}-\\u{11002}\\u{11038}-\\u{11046}\\u{11070}\\u{11073}\\u{11074}\\u{1107F}-\\u{11082}\\u{110B0}-\\u{110BA}\\u{110C2}\\u{11100}-\\u{11102}\\u{11127}-\\u{11134}\\u{11145}\\u{11146}\\u{11173}\\u{11180}-\\u{11182}\\u{111B3}-\\u{111C0}\\u{111C9}-\\u{111CC}\\u{111CE}\\u{111CF}\\u{1122C}-\\u{11237}\\u{1123E}\\u{11241}\\u{112DF}-\\u{112EA}\\u{11300}-\\u{11303}\\u{1133B}\\u{1133C}\\u{1133E}-\\u{11344}\\u{11347}\\u{11348}\\u{1134B}-\\u{1134D}\\u{11357}\\u{11362}\\u{11363}\\u{11366}-\\u{1136C}\\u{11370}-\\u{11374}\\u{11435}-\\u{11446}\\u{1145E}\\u{114B0}-\\u{114C3}\\u{115AF}-\\u{115B5}\\u{115B8}-\\u{115C0}\\u{115DC}\\u{115DD}\\u{11630}-\\u{11640}\\u{116AB}-\\u{116B7}\\u{1171D}-\\u{1172B}\\u{1182C}-\\u{1183A}\\u{11930}-\\u{11935}\\u{11937}\\u{11938}\\u{1193B}-\\u{1193E}\\u{11940}\\u{11942}\\u{11943}\\u{119D1}-\\u{119D7}\\u{119DA}-\\u{119E0}\\u{119E4}\\u{11A01}-\\u{11A0A}\\u{11A33}-\\u{11A39}\\u{11A3B}-\\u{11A3E}\\u{11A47}\\u{11A51}-\\u{11A5B}\\u{11A8A}-\\u{11A99}\\u{11C2F}-\\u{11C36}\\u{11C38}-\\u{11C3F}\\u{11C92}-\\u{11CA7}\\u{11CA9}-\\u{11CB6}\\u{11D31}-\\u{11D36}\\u{11D3A}\\u{11D3C}\\u{11D3D}\\u{11D3F}-\\u{11D45}\\u{11D47}\\u{11D8A}-\\u{11D8E}\\u{11D90}\\u{11D91}\\u{11D93}-\\u{11D97}\\u{11EF3}-\\u{11EF6}\\u{11F00}\\u{11F01}\\u{11F03}\\u{11F34}-\\u{11F3A}\\u{11F3E}-\\u{11F42}\\u{13440}\\u{13447}-\\u{13455}\\u{16AF0}-\\u{16AF4}\\u{16B30}-\\u{16B36}\\u{16F4F}\\u{16F51}-\\u{16F87}\\u{16F8F}-\\u{16F92}\\u{16FE4}\\u{16FF0}\\u{16FF1}\\u{1BC9D}\\u{1BC9E}\\u{1CF00}-\\u{1CF2D}\\u{1CF30}-\\u{1CF46}\\u{1D165}-\\u{1D169}\\u{1D16D}-\\u{1D172}\\u{1D17B}-\\u{1D182}\\u{1D185}-\\u{1D18B}\\u{1D1AA}-\\u{1D1AD}\\u{1D242}-\\u{1D244}\\u{1DA00}-\\u{1DA36}\\u{1DA3B}-\\u{1DA6C}\\u{1DA75}\\u{1DA84}\\u{1DA9B}-\\u{1DA9F}\\u{1DAA1}-\\u{1DAAF}\\u{1E000}-\\u{1E006}\\u{1E008}-\\u{1E018}\\u{1E01B}-\\u{1E021}\\u{1E023}\\u{1E024}\\u{1E026}-\\u{1E02A}\\u{1E08F}\\u{1E130}-\\u{1E136}\\u{1E2AE}\\u{1E2EC}-\\u{1E2EF}\\u{1E4EC}-\\u{1E4EF}\\u{1E8D0}-\\u{1E8D6}\\u{1E944}-\\u{1E94A}\\u{E0100}-\\u{E01EF}]/u;\nconst combiningClassVirama = /[\\u094D\\u09CD\\u0A4D\\u0ACD\\u0B4D\\u0BCD\\u0C4D\\u0CCD\\u0D3B\\u0D3C\\u0D4D\\u0DCA\\u0E3A\\u0EBA\\u0F84\\u1039\\u103A\\u1714\\u1734\\u17D2\\u1A60\\u1B44\\u1BAA\\u1BAB\\u1BF2\\u1BF3\\u2D7F\\uA806\\uA8C4\\uA953\\uA9C0\\uAAF6\\uABED\\u{10A3F}\\u{11046}\\u{1107F}\\u{110B9}\\u{11133}\\u{11134}\\u{111C0}\\u{11235}\\u{112EA}\\u{1134D}\\u{11442}\\u{114C2}\\u{115BF}\\u{1163F}\\u{116B6}\\u{1172B}\\u{11839}\\u{119E0}\\u{11A34}\\u{11A47}\\u{11A99}\\u{11C3F}\\u{11D44}\\u{11D45}\\u{11D97}]/u;\nconst validZWNJ = /[\\u0620\\u0626\\u0628\\u062A-\\u062E\\u0633-\\u063F\\u0641-\\u0647\\u0649\\u064A\\u066E\\u066F\\u0678-\\u0687\\u069A-\\u06BF\\u06C1\\u06C2\\u06CC\\u06CE\\u06D0\\u06D1\\u06FA-\\u06FC\\u06FF\\u0712-\\u0714\\u071A-\\u071D\\u071F-\\u0727\\u0729\\u072B\\u072D\\u072E\\u074E-\\u0758\\u075C-\\u076A\\u076D-\\u0770\\u0772\\u0775-\\u0777\\u077A-\\u077F\\u07CA-\\u07EA\\u0841-\\u0845\\u0848\\u084A-\\u0853\\u0855\\u0860\\u0862-\\u0865\\u0868\\u08A0-\\u08A9\\u08AF\\u08B0\\u08B3\\u08B4\\u08B6-\\u08B8\\u08BA-\\u08BD\\u1807\\u1820-\\u1878\\u1887-\\u18A8\\u18AA\\uA840-\\uA872\\u{10AC0}-\\u{10AC4}\\u{10ACD}\\u{10AD3}-\\u{10ADC}\\u{10ADE}-\\u{10AE0}\\u{10AEB}-\\u{10AEE}\\u{10B80}\\u{10B82}\\u{10B86}-\\u{10B88}\\u{10B8A}\\u{10B8B}\\u{10B8D}\\u{10B90}\\u{10BAD}\\u{10BAE}\\u{10D00}-\\u{10D21}\\u{10D23}\\u{10F30}-\\u{10F32}\\u{10F34}-\\u{10F44}\\u{10F51}-\\u{10F53}\\u{1E900}-\\u{1E943}][\\xAD\\u0300-\\u036F\\u0483-\\u0489\\u0591-\\u05BD\\u05BF\\u05C1\\u05C2\\u05C4\\u05C5\\u05C7\\u0610-\\u061A\\u061C\\u064B-\\u065F\\u0670\\u06D6-\\u06DC\\u06DF-\\u06E4\\u06E7\\u06E8\\u06EA-\\u06ED\\u070F\\u0711\\u0730-\\u074A\\u07A6-\\u07B0\\u07EB-\\u07F3\\u07FD\\u0816-\\u0819\\u081B-\\u0823\\u0825-\\u0827\\u0829-\\u082D\\u0859-\\u085B\\u08D3-\\u08E1\\u08E3-\\u0902\\u093A\\u093C\\u0941-\\u0948\\u094D\\u0951-\\u0957\\u0962\\u0963\\u0981\\u09BC\\u09C1-\\u09C4\\u09CD\\u09E2\\u09E3\\u09FE\\u0A01\\u0A02\\u0A3C\\u0A41\\u0A42\\u0A47\\u0A48\\u0A4B-\\u0A4D\\u0A51\\u0A70\\u0A71\\u0A75\\u0A81\\u0A82\\u0ABC\\u0AC1-\\u0AC5\\u0AC7\\u0AC8\\u0ACD\\u0AE2\\u0AE3\\u0AFA-\\u0AFF\\u0B01\\u0B3C\\u0B3F\\u0B41-\\u0B44\\u0B4D\\u0B56\\u0B62\\u0B63\\u0B82\\u0BC0\\u0BCD\\u0C00\\u0C04\\u0C3E-\\u0C40\\u0C46-\\u0C48\\u0C4A-\\u0C4D\\u0C55\\u0C56\\u0C62\\u0C63\\u0C81\\u0CBC\\u0CBF\\u0CC6\\u0CCC\\u0CCD\\u0CE2\\u0CE3\\u0D00\\u0D01\\u0D3B\\u0D3C\\u0D41-\\u0D44\\u0D4D\\u0D62\\u0D63\\u0DCA\\u0DD2-\\u0DD4\\u0DD6\\u0E31\\u0E34-\\u0E3A\\u0E47-\\u0E4E\\u0EB1\\u0EB4-\\u0EBC\\u0EC8-\\u0ECD\\u0F18\\u0F19\\u0F35\\u0F37\\u0F39\\u0F71-\\u0F7E\\u0F80-\\u0F84\\u0F86\\u0F87\\u0F8D-\\u0F97\\u0F99-\\u0FBC\\u0FC6\\u102D-\\u1030\\u1032-\\u1037\\u1039\\u103A\\u103D\\u103E\\u1058\\u1059\\u105E-\\u1060\\u1071-\\u1074\\u1082\\u1085\\u1086\\u108D\\u109D\\u135D-\\u135F\\u1712-\\u1714\\u1732-\\u1734\\u1752\\u1753\\u1772\\u1773\\u17B4\\u17B5\\u17B7-\\u17BD\\u17C6\\u17C9-\\u17D3\\u17DD\\u180B-\\u180D\\u1885\\u1886\\u18A9\\u1920-\\u1922\\u1927\\u1928\\u1932\\u1939-\\u193B\\u1A17\\u1A18\\u1A1B\\u1A56\\u1A58-\\u1A5E\\u1A60\\u1A62\\u1A65-\\u1A6C\\u1A73-\\u1A7C\\u1A7F\\u1AB0-\\u1ABE\\u1B00-\\u1B03\\u1B34\\u1B36-\\u1B3A\\u1B3C\\u1B42\\u1B6B-\\u1B73\\u1B80\\u1B81\\u1BA2-\\u1BA5\\u1BA8\\u1BA9\\u1BAB-\\u1BAD\\u1BE6\\u1BE8\\u1BE9\\u1BED\\u1BEF-\\u1BF1\\u1C2C-\\u1C33\\u1C36\\u1C37\\u1CD0-\\u1CD2\\u1CD4-\\u1CE0\\u1CE2-\\u1CE8\\u1CED\\u1CF4\\u1CF8\\u1CF9\\u1DC0-\\u1DF9\\u1DFB-\\u1DFF\\u200B\\u200E\\u200F\\u202A-\\u202E\\u2060-\\u2064\\u206A-\\u206F\\u20D0-\\u20F0\\u2CEF-\\u2CF1\\u2D7F\\u2DE0-\\u2DFF\\u302A-\\u302D\\u3099\\u309A\\uA66F-\\uA672\\uA674-\\uA67D\\uA69E\\uA69F\\uA6F0\\uA6F1\\uA802\\uA806\\uA80B\\uA825\\uA826\\uA8C4\\uA8C5\\uA8E0-\\uA8F1\\uA8FF\\uA926-\\uA92D\\uA947-\\uA951\\uA980-\\uA982\\uA9B3\\uA9B6-\\uA9B9\\uA9BC\\uA9BD\\uA9E5\\uAA29-\\uAA2E\\uAA31\\uAA32\\uAA35\\uAA36\\uAA43\\uAA4C\\uAA7C\\uAAB0\\uAAB2-\\uAAB4\\uAAB7\\uAAB8\\uAABE\\uAABF\\uAAC1\\uAAEC\\uAAED\\uAAF6\\uABE5\\uABE8\\uABED\\uFB1E\\uFE00-\\uFE0F\\uFE20-\\uFE2F\\uFEFF\\uFFF9-\\uFFFB\\u{101FD}\\u{102E0}\\u{10376}-\\u{1037A}\\u{10A01}-\\u{10A03}\\u{10A05}\\u{10A06}\\u{10A0C}-\\u{10A0F}\\u{10A38}-\\u{10A3A}\\u{10A3F}\\u{10AE5}\\u{10AE6}\\u{10D24}-\\u{10D27}\\u{10F46}-\\u{10F50}\\u{11001}\\u{11038}-\\u{11046}\\u{1107F}-\\u{11081}\\u{110B3}-\\u{110B6}\\u{110B9}\\u{110BA}\\u{11100}-\\u{11102}\\u{11127}-\\u{1112B}\\u{1112D}-\\u{11134}\\u{11173}\\u{11180}\\u{11181}\\u{111B6}-\\u{111BE}\\u{111C9}-\\u{111CC}\\u{1122F}-\\u{11231}\\u{11234}\\u{11236}\\u{11237}\\u{1123E}\\u{112DF}\\u{112E3}-\\u{112EA}\\u{11300}\\u{11301}\\u{1133B}\\u{1133C}\\u{11340}\\u{11366}-\\u{1136C}\\u{11370}-\\u{11374}\\u{11438}-\\u{1143F}\\u{11442}-\\u{11444}\\u{11446}\\u{1145E}\\u{114B3}-\\u{114B8}\\u{114BA}\\u{114BF}\\u{114C0}\\u{114C2}\\u{114C3}\\u{115B2}-\\u{115B5}\\u{115BC}\\u{115BD}\\u{115BF}\\u{115C0}\\u{115DC}\\u{115DD}\\u{11633}-\\u{1163A}\\u{1163D}\\u{1163F}\\u{11640}\\u{116AB}\\u{116AD}\\u{116B0}-\\u{116B5}\\u{116B7}\\u{1171D}-\\u{1171F}\\u{11722}-\\u{11725}\\u{11727}-\\u{1172B}\\u{1182F}-\\u{11837}\\u{11839}\\u{1183A}\\u{119D4}-\\u{119D7}\\u{119DA}\\u{119DB}\\u{119E0}\\u{11A01}-\\u{11A0A}\\u{11A33}-\\u{11A38}\\u{11A3B}-\\u{11A3E}\\u{11A47}\\u{11A51}-\\u{11A56}\\u{11A59}-\\u{11A5B}\\u{11A8A}-\\u{11A96}\\u{11A98}\\u{11A99}\\u{11C30}-\\u{11C36}\\u{11C38}-\\u{11C3D}\\u{11C3F}\\u{11C92}-\\u{11CA7}\\u{11CAA}-\\u{11CB0}\\u{11CB2}\\u{11CB3}\\u{11CB5}\\u{11CB6}\\u{11D31}-\\u{11D36}\\u{11D3A}\\u{11D3C}\\u{11D3D}\\u{11D3F}-\\u{11D45}\\u{11D47}\\u{11D90}\\u{11D91}\\u{11D95}\\u{11D97}\\u{11EF3}\\u{11EF4}\\u{13430}-\\u{13438}\\u{16AF0}-\\u{16AF4}\\u{16B30}-\\u{16B36}\\u{16F4F}\\u{16F8F}-\\u{16F92}\\u{1BC9D}\\u{1BC9E}\\u{1BCA0}-\\u{1BCA3}\\u{1D167}-\\u{1D169}\\u{1D173}-\\u{1D182}\\u{1D185}-\\u{1D18B}\\u{1D1AA}-\\u{1D1AD}\\u{1D242}-\\u{1D244}\\u{1DA00}-\\u{1DA36}\\u{1DA3B}-\\u{1DA6C}\\u{1DA75}\\u{1DA84}\\u{1DA9B}-\\u{1DA9F}\\u{1DAA1}-\\u{1DAAF}\\u{1E000}-\\u{1E006}\\u{1E008}-\\u{1E018}\\u{1E01B}-\\u{1E021}\\u{1E023}\\u{1E024}\\u{1E026}-\\u{1E02A}\\u{1E130}-\\u{1E136}\\u{1E2EC}-\\u{1E2EF}\\u{1E8D0}-\\u{1E8D6}\\u{1E944}-\\u{1E94B}\\u{E0001}\\u{E0020}-\\u{E007F}\\u{E0100}-\\u{E01EF}]*\\u200C[\\xAD\\u0300-\\u036F\\u0483-\\u0489\\u0591-\\u05BD\\u05BF\\u05C1\\u05C2\\u05C4\\u05C5\\u05C7\\u0610-\\u061A\\u061C\\u064B-\\u065F\\u0670\\u06D6-\\u06DC\\u06DF-\\u06E4\\u06E7\\u06E8\\u06EA-\\u06ED\\u070F\\u0711\\u0730-\\u074A\\u07A6-\\u07B0\\u07EB-\\u07F3\\u07FD\\u0816-\\u0819\\u081B-\\u0823\\u0825-\\u0827\\u0829-\\u082D\\u0859-\\u085B\\u08D3-\\u08E1\\u08E3-\\u0902\\u093A\\u093C\\u0941-\\u0948\\u094D\\u0951-\\u0957\\u0962\\u0963\\u0981\\u09BC\\u09C1-\\u09C4\\u09CD\\u09E2\\u09E3\\u09FE\\u0A01\\u0A02\\u0A3C\\u0A41\\u0A42\\u0A47\\u0A48\\u0A4B-\\u0A4D\\u0A51\\u0A70\\u0A71\\u0A75\\u0A81\\u0A82\\u0ABC\\u0AC1-\\u0AC5\\u0AC7\\u0AC8\\u0ACD\\u0AE2\\u0AE3\\u0AFA-\\u0AFF\\u0B01\\u0B3C\\u0B3F\\u0B41-\\u0B44\\u0B4D\\u0B56\\u0B62\\u0B63\\u0B82\\u0BC0\\u0BCD\\u0C00\\u0C04\\u0C3E-\\u0C40\\u0C46-\\u0C48\\u0C4A-\\u0C4D\\u0C55\\u0C56\\u0C62\\u0C63\\u0C81\\u0CBC\\u0CBF\\u0CC6\\u0CCC\\u0CCD\\u0CE2\\u0CE3\\u0D00\\u0D01\\u0D3B\\u0D3C\\u0D41-\\u0D44\\u0D4D\\u0D62\\u0D63\\u0DCA\\u0DD2-\\u0DD4\\u0DD6\\u0E31\\u0E34-\\u0E3A\\u0E47-\\u0E4E\\u0EB1\\u0EB4-\\u0EBC\\u0EC8-\\u0ECD\\u0F18\\u0F19\\u0F35\\u0F37\\u0F39\\u0F71-\\u0F7E\\u0F80-\\u0F84\\u0F86\\u0F87\\u0F8D-\\u0F97\\u0F99-\\u0FBC\\u0FC6\\u102D-\\u1030\\u1032-\\u1037\\u1039\\u103A\\u103D\\u103E\\u1058\\u1059\\u105E-\\u1060\\u1071-\\u1074\\u1082\\u1085\\u1086\\u108D\\u109D\\u135D-\\u135F\\u1712-\\u1714\\u1732-\\u1734\\u1752\\u1753\\u1772\\u1773\\u17B4\\u17B5\\u17B7-\\u17BD\\u17C6\\u17C9-\\u17D3\\u17DD\\u180B-\\u180D\\u1885\\u1886\\u18A9\\u1920-\\u1922\\u1927\\u1928\\u1932\\u1939-\\u193B\\u1A17\\u1A18\\u1A1B\\u1A56\\u1A58-\\u1A5E\\u1A60\\u1A62\\u1A65-\\u1A6C\\u1A73-\\u1A7C\\u1A7F\\u1AB0-\\u1ABE\\u1B00-\\u1B03\\u1B34\\u1B36-\\u1B3A\\u1B3C\\u1B42\\u1B6B-\\u1B73\\u1B80\\u1B81\\u1BA2-\\u1BA5\\u1BA8\\u1BA9\\u1BAB-\\u1BAD\\u1BE6\\u1BE8\\u1BE9\\u1BED\\u1BEF-\\u1BF1\\u1C2C-\\u1C33\\u1C36\\u1C37\\u1CD0-\\u1CD2\\u1CD4-\\u1CE0\\u1CE2-\\u1CE8\\u1CED\\u1CF4\\u1CF8\\u1CF9\\u1DC0-\\u1DF9\\u1DFB-\\u1DFF\\u200B\\u200E\\u200F\\u202A-\\u202E\\u2060-\\u2064\\u206A-\\u206F\\u20D0-\\u20F0\\u2CEF-\\u2CF1\\u2D7F\\u2DE0-\\u2DFF\\u302A-\\u302D\\u3099\\u309A\\uA66F-\\uA672\\uA674-\\uA67D\\uA69E\\uA69F\\uA6F0\\uA6F1\\uA802\\uA806\\uA80B\\uA825\\uA826\\uA8C4\\uA8C5\\uA8E0-\\uA8F1\\uA8FF\\uA926-\\uA92D\\uA947-\\uA951\\uA980-\\uA982\\uA9B3\\uA9B6-\\uA9B9\\uA9BC\\uA9BD\\uA9E5\\uAA29-\\uAA2E\\uAA31\\uAA32\\uAA35\\uAA36\\uAA43\\uAA4C\\uAA7C\\uAAB0\\uAAB2-\\uAAB4\\uAAB7\\uAAB8\\uAABE\\uAABF\\uAAC1\\uAAEC\\uAAED\\uAAF6\\uABE5\\uABE8\\uABED\\uFB1E\\uFE00-\\uFE0F\\uFE20-\\uFE2F\\uFEFF\\uFFF9-\\uFFFB\\u{101FD}\\u{102E0}\\u{10376}-\\u{1037A}\\u{10A01}-\\u{10A03}\\u{10A05}\\u{10A06}\\u{10A0C}-\\u{10A0F}\\u{10A38}-\\u{10A3A}\\u{10A3F}\\u{10AE5}\\u{10AE6}\\u{10D24}-\\u{10D27}\\u{10F46}-\\u{10F50}\\u{11001}\\u{11038}-\\u{11046}\\u{1107F}-\\u{11081}\\u{110B3}-\\u{110B6}\\u{110B9}\\u{110BA}\\u{11100}-\\u{11102}\\u{11127}-\\u{1112B}\\u{1112D}-\\u{11134}\\u{11173}\\u{11180}\\u{11181}\\u{111B6}-\\u{111BE}\\u{111C9}-\\u{111CC}\\u{1122F}-\\u{11231}\\u{11234}\\u{11236}\\u{11237}\\u{1123E}\\u{112DF}\\u{112E3}-\\u{112EA}\\u{11300}\\u{11301}\\u{1133B}\\u{1133C}\\u{11340}\\u{11366}-\\u{1136C}\\u{11370}-\\u{11374}\\u{11438}-\\u{1143F}\\u{11442}-\\u{11444}\\u{11446}\\u{1145E}\\u{114B3}-\\u{114B8}\\u{114BA}\\u{114BF}\\u{114C0}\\u{114C2}\\u{114C3}\\u{115B2}-\\u{115B5}\\u{115BC}\\u{115BD}\\u{115BF}\\u{115C0}\\u{115DC}\\u{115DD}\\u{11633}-\\u{1163A}\\u{1163D}\\u{1163F}\\u{11640}\\u{116AB}\\u{116AD}\\u{116B0}-\\u{116B5}\\u{116B7}\\u{1171D}-\\u{1171F}\\u{11722}-\\u{11725}\\u{11727}-\\u{1172B}\\u{1182F}-\\u{11837}\\u{11839}\\u{1183A}\\u{119D4}-\\u{119D7}\\u{119DA}\\u{119DB}\\u{119E0}\\u{11A01}-\\u{11A0A}\\u{11A33}-\\u{11A38}\\u{11A3B}-\\u{11A3E}\\u{11A47}\\u{11A51}-\\u{11A56}\\u{11A59}-\\u{11A5B}\\u{11A8A}-\\u{11A96}\\u{11A98}\\u{11A99}\\u{11C30}-\\u{11C36}\\u{11C38}-\\u{11C3D}\\u{11C3F}\\u{11C92}-\\u{11CA7}\\u{11CAA}-\\u{11CB0}\\u{11CB2}\\u{11CB3}\\u{11CB5}\\u{11CB6}\\u{11D31}-\\u{11D36}\\u{11D3A}\\u{11D3C}\\u{11D3D}\\u{11D3F}-\\u{11D45}\\u{11D47}\\u{11D90}\\u{11D91}\\u{11D95}\\u{11D97}\\u{11EF3}\\u{11EF4}\\u{13430}-\\u{13438}\\u{16AF0}-\\u{16AF4}\\u{16B30}-\\u{16B36}\\u{16F4F}\\u{16F8F}-\\u{16F92}\\u{1BC9D}\\u{1BC9E}\\u{1BCA0}-\\u{1BCA3}\\u{1D167}-\\u{1D169}\\u{1D173}-\\u{1D182}\\u{1D185}-\\u{1D18B}\\u{1D1AA}-\\u{1D1AD}\\u{1D242}-\\u{1D244}\\u{1DA00}-\\u{1DA36}\\u{1DA3B}-\\u{1DA6C}\\u{1DA75}\\u{1DA84}\\u{1DA9B}-\\u{1DA9F}\\u{1DAA1}-\\u{1DAAF}\\u{1E000}-\\u{1E006}\\u{1E008}-\\u{1E018}\\u{1E01B}-\\u{1E021}\\u{1E023}\\u{1E024}\\u{1E026}-\\u{1E02A}\\u{1E130}-\\u{1E136}\\u{1E2EC}-\\u{1E2EF}\\u{1E8D0}-\\u{1E8D6}\\u{1E944}-\\u{1E94B}\\u{E0001}\\u{E0020}-\\u{E007F}\\u{E0100}-\\u{E01EF}]*[\\u0620\\u0622-\\u063F\\u0641-\\u064A\\u066E\\u066F\\u0671-\\u0673\\u0675-\\u06D3\\u06D5\\u06EE\\u06EF\\u06FA-\\u06FC\\u06FF\\u0710\\u0712-\\u072F\\u074D-\\u077F\\u07CA-\\u07EA\\u0840-\\u0855\\u0860\\u0862-\\u0865\\u0867-\\u086A\\u08A0-\\u08AC\\u08AE-\\u08B4\\u08B6-\\u08BD\\u1807\\u1820-\\u1878\\u1887-\\u18A8\\u18AA\\uA840-\\uA871\\u{10AC0}-\\u{10AC5}\\u{10AC7}\\u{10AC9}\\u{10ACA}\\u{10ACE}-\\u{10AD6}\\u{10AD8}-\\u{10AE1}\\u{10AE4}\\u{10AEB}-\\u{10AEF}\\u{10B80}-\\u{10B91}\\u{10BA9}-\\u{10BAE}\\u{10D01}-\\u{10D23}\\u{10F30}-\\u{10F44}\\u{10F51}-\\u{10F54}\\u{1E900}-\\u{1E943}]/u;\nconst bidiDomain = /[\\u05BE\\u05C0\\u05C3\\u05C6\\u05D0-\\u05EA\\u05EF-\\u05F4\\u0600-\\u0605\\u0608\\u060B\\u060D\\u061B-\\u064A\\u0660-\\u0669\\u066B-\\u066F\\u0671-\\u06D5\\u06DD\\u06E5\\u06E6\\u06EE\\u06EF\\u06FA-\\u070D\\u070F\\u0710\\u0712-\\u072F\\u074D-\\u07A5\\u07B1\\u07C0-\\u07EA\\u07F4\\u07F5\\u07FA\\u07FE-\\u0815\\u081A\\u0824\\u0828\\u0830-\\u083E\\u0840-\\u0858\\u085E\\u0860-\\u086A\\u0870-\\u088E\\u0890\\u0891\\u08A0-\\u08C9\\u08E2\\u200F\\uFB1D\\uFB1F-\\uFB28\\uFB2A-\\uFB36\\uFB38-\\uFB3C\\uFB3E\\uFB40\\uFB41\\uFB43\\uFB44\\uFB46-\\uFBC2\\uFBD3-\\uFD3D\\uFD50-\\uFD8F\\uFD92-\\uFDC7\\uFDF0-\\uFDFC\\uFE70-\\uFE74\\uFE76-\\uFEFC\\u{10800}-\\u{10805}\\u{10808}\\u{1080A}-\\u{10835}\\u{10837}\\u{10838}\\u{1083C}\\u{1083F}-\\u{10855}\\u{10857}-\\u{1089E}\\u{108A7}-\\u{108AF}\\u{108E0}-\\u{108F2}\\u{108F4}\\u{108F5}\\u{108FB}-\\u{1091B}\\u{10920}-\\u{10939}\\u{1093F}\\u{10980}-\\u{109B7}\\u{109BC}-\\u{109CF}\\u{109D2}-\\u{10A00}\\u{10A10}-\\u{10A13}\\u{10A15}-\\u{10A17}\\u{10A19}-\\u{10A35}\\u{10A40}-\\u{10A48}\\u{10A50}-\\u{10A58}\\u{10A60}-\\u{10A9F}\\u{10AC0}-\\u{10AE4}\\u{10AEB}-\\u{10AF6}\\u{10B00}-\\u{10B35}\\u{10B40}-\\u{10B55}\\u{10B58}-\\u{10B72}\\u{10B78}-\\u{10B91}\\u{10B99}-\\u{10B9C}\\u{10BA9}-\\u{10BAF}\\u{10C00}-\\u{10C48}\\u{10C80}-\\u{10CB2}\\u{10CC0}-\\u{10CF2}\\u{10CFA}-\\u{10D23}\\u{10D30}-\\u{10D39}\\u{10E60}-\\u{10E7E}\\u{10E80}-\\u{10EA9}\\u{10EAD}\\u{10EB0}\\u{10EB1}\\u{10F00}-\\u{10F27}\\u{10F30}-\\u{10F45}\\u{10F51}-\\u{10F59}\\u{10F70}-\\u{10F81}\\u{10F86}-\\u{10F89}\\u{10FB0}-\\u{10FCB}\\u{10FE0}-\\u{10FF6}\\u{1E800}-\\u{1E8C4}\\u{1E8C7}-\\u{1E8CF}\\u{1E900}-\\u{1E943}\\u{1E94B}\\u{1E950}-\\u{1E959}\\u{1E95E}\\u{1E95F}\\u{1EC71}-\\u{1ECB4}\\u{1ED01}-\\u{1ED3D}\\u{1EE00}-\\u{1EE03}\\u{1EE05}-\\u{1EE1F}\\u{1EE21}\\u{1EE22}\\u{1EE24}\\u{1EE27}\\u{1EE29}-\\u{1EE32}\\u{1EE34}-\\u{1EE37}\\u{1EE39}\\u{1EE3B}\\u{1EE42}\\u{1EE47}\\u{1EE49}\\u{1EE4B}\\u{1EE4D}-\\u{1EE4F}\\u{1EE51}\\u{1EE52}\\u{1EE54}\\u{1EE57}\\u{1EE59}\\u{1EE5B}\\u{1EE5D}\\u{1EE5F}\\u{1EE61}\\u{1EE62}\\u{1EE64}\\u{1EE67}-\\u{1EE6A}\\u{1EE6C}-\\u{1EE72}\\u{1EE74}-\\u{1EE77}\\u{1EE79}-\\u{1EE7C}\\u{1EE7E}\\u{1EE80}-\\u{1EE89}\\u{1EE8B}-\\u{1EE9B}\\u{1EEA1}-\\u{1EEA3}\\u{1EEA5}-\\u{1EEA9}\\u{1EEAB}-\\u{1EEBB}]/u;\nconst bidiS1LTR = /[A-Za-z\\xAA\\xB5\\xBA\\xC0-\\xD6\\xD8-\\xF6\\xF8-\\u02B8\\u02BB-\\u02C1\\u02D0\\u02D1\\u02E0-\\u02E4\\u02EE\\u0370-\\u0373\\u0376\\u0377\\u037A-\\u037D\\u037F\\u0386\\u0388-\\u038A\\u038C\\u038E-\\u03A1\\u03A3-\\u03F5\\u03F7-\\u0482\\u048A-\\u052F\\u0531-\\u0556\\u0559-\\u0589\\u0903-\\u0939\\u093B\\u093D-\\u0940\\u0949-\\u094C\\u094E-\\u0950\\u0958-\\u0961\\u0964-\\u0980\\u0982\\u0983\\u0985-\\u098C\\u098F\\u0990\\u0993-\\u09A8\\u09AA-\\u09B0\\u09B2\\u09B6-\\u09B9\\u09BD-\\u09C0\\u09C7\\u09C8\\u09CB\\u09CC\\u09CE\\u09D7\\u09DC\\u09DD\\u09DF-\\u09E1\\u09E6-\\u09F1\\u09F4-\\u09FA\\u09FC\\u09FD\\u0A03\\u0A05-\\u0A0A\\u0A0F\\u0A10\\u0A13-\\u0A28\\u0A2A-\\u0A30\\u0A32\\u0A33\\u0A35\\u0A36\\u0A38\\u0A39\\u0A3E-\\u0A40\\u0A59-\\u0A5C\\u0A5E\\u0A66-\\u0A6F\\u0A72-\\u0A74\\u0A76\\u0A83\\u0A85-\\u0A8D\\u0A8F-\\u0A91\\u0A93-\\u0AA8\\u0AAA-\\u0AB0\\u0AB2\\u0AB3\\u0AB5-\\u0AB9\\u0ABD-\\u0AC0\\u0AC9\\u0ACB\\u0ACC\\u0AD0\\u0AE0\\u0AE1\\u0AE6-\\u0AF0\\u0AF9\\u0B02\\u0B03\\u0B05-\\u0B0C\\u0B0F\\u0B10\\u0B13-\\u0B28\\u0B2A-\\u0B30\\u0B32\\u0B33\\u0B35-\\u0B39\\u0B3D\\u0B3E\\u0B40\\u0B47\\u0B48\\u0B4B\\u0B4C\\u0B57\\u0B5C\\u0B5D\\u0B5F-\\u0B61\\u0B66-\\u0B77\\u0B83\\u0B85-\\u0B8A\\u0B8E-\\u0B90\\u0B92-\\u0B95\\u0B99\\u0B9A\\u0B9C\\u0B9E\\u0B9F\\u0BA3\\u0BA4\\u0BA8-\\u0BAA\\u0BAE-\\u0BB9\\u0BBE\\u0BBF\\u0BC1\\u0BC2\\u0BC6-\\u0BC8\\u0BCA-\\u0BCC\\u0BD0\\u0BD7\\u0BE6-\\u0BF2\\u0C01-\\u0C03\\u0C05-\\u0C0C\\u0C0E-\\u0C10\\u0C12-\\u0C28\\u0C2A-\\u0C39\\u0C3D\\u0C41-\\u0C44\\u0C58-\\u0C5A\\u0C5D\\u0C60\\u0C61\\u0C66-\\u0C6F\\u0C77\\u0C7F\\u0C80\\u0C82-\\u0C8C\\u0C8E-\\u0C90\\u0C92-\\u0CA8\\u0CAA-\\u0CB3\\u0CB5-\\u0CB9\\u0CBD-\\u0CC4\\u0CC6-\\u0CC8\\u0CCA\\u0CCB\\u0CD5\\u0CD6\\u0CDD\\u0CDE\\u0CE0\\u0CE1\\u0CE6-\\u0CEF\\u0CF1-\\u0CF3\\u0D02-\\u0D0C\\u0D0E-\\u0D10\\u0D12-\\u0D3A\\u0D3D-\\u0D40\\u0D46-\\u0D48\\u0D4A-\\u0D4C\\u0D4E\\u0D4F\\u0D54-\\u0D61\\u0D66-\\u0D7F\\u0D82\\u0D83\\u0D85-\\u0D96\\u0D9A-\\u0DB1\\u0DB3-\\u0DBB\\u0DBD\\u0DC0-\\u0DC6\\u0DCF-\\u0DD1\\u0DD8-\\u0DDF\\u0DE6-\\u0DEF\\u0DF2-\\u0DF4\\u0E01-\\u0E30\\u0E32\\u0E33\\u0E40-\\u0E46\\u0E4F-\\u0E5B\\u0E81\\u0E82\\u0E84\\u0E86-\\u0E8A\\u0E8C-\\u0EA3\\u0EA5\\u0EA7-\\u0EB0\\u0EB2\\u0EB3\\u0EBD\\u0EC0-\\u0EC4\\u0EC6\\u0ED0-\\u0ED9\\u0EDC-\\u0EDF\\u0F00-\\u0F17\\u0F1A-\\u0F34\\u0F36\\u0F38\\u0F3E-\\u0F47\\u0F49-\\u0F6C\\u0F7F\\u0F85\\u0F88-\\u0F8C\\u0FBE-\\u0FC5\\u0FC7-\\u0FCC\\u0FCE-\\u0FDA\\u1000-\\u102C\\u1031\\u1038\\u103B\\u103C\\u103F-\\u1057\\u105A-\\u105D\\u1061-\\u1070\\u1075-\\u1081\\u1083\\u1084\\u1087-\\u108C\\u108E-\\u109C\\u109E-\\u10C5\\u10C7\\u10CD\\u10D0-\\u1248\\u124A-\\u124D\\u1250-\\u1256\\u1258\\u125A-\\u125D\\u1260-\\u1288\\u128A-\\u128D\\u1290-\\u12B0\\u12B2-\\u12B5\\u12B8-\\u12BE\\u12C0\\u12C2-\\u12C5\\u12C8-\\u12D6\\u12D8-\\u1310\\u1312-\\u1315\\u1318-\\u135A\\u1360-\\u137C\\u1380-\\u138F\\u13A0-\\u13F5\\u13F8-\\u13FD\\u1401-\\u167F\\u1681-\\u169A\\u16A0-\\u16F8\\u1700-\\u1711\\u1715\\u171F-\\u1731\\u1734-\\u1736\\u1740-\\u1751\\u1760-\\u176C\\u176E-\\u1770\\u1780-\\u17B3\\u17B6\\u17BE-\\u17C5\\u17C7\\u17C8\\u17D4-\\u17DA\\u17DC\\u17E0-\\u17E9\\u1810-\\u1819\\u1820-\\u1878\\u1880-\\u1884\\u1887-\\u18A8\\u18AA\\u18B0-\\u18F5\\u1900-\\u191E\\u1923-\\u1926\\u1929-\\u192B\\u1930\\u1931\\u1933-\\u1938\\u1946-\\u196D\\u1970-\\u1974\\u1980-\\u19AB\\u19B0-\\u19C9\\u19D0-\\u19DA\\u1A00-\\u1A16\\u1A19\\u1A1A\\u1A1E-\\u1A55\\u1A57\\u1A61\\u1A63\\u1A64\\u1A6D-\\u1A72\\u1A80-\\u1A89\\u1A90-\\u1A99\\u1AA0-\\u1AAD\\u1B04-\\u1B33\\u1B35\\u1B3B\\u1B3D-\\u1B41\\u1B43-\\u1B4C\\u1B50-\\u1B6A\\u1B74-\\u1B7E\\u1B82-\\u1BA1\\u1BA6\\u1BA7\\u1BAA\\u1BAE-\\u1BE5\\u1BE7\\u1BEA-\\u1BEC\\u1BEE\\u1BF2\\u1BF3\\u1BFC-\\u1C2B\\u1C34\\u1C35\\u1C3B-\\u1C49\\u1C4D-\\u1C88\\u1C90-\\u1CBA\\u1CBD-\\u1CC7\\u1CD3\\u1CE1\\u1CE9-\\u1CEC\\u1CEE-\\u1CF3\\u1CF5-\\u1CF7\\u1CFA\\u1D00-\\u1DBF\\u1E00-\\u1F15\\u1F18-\\u1F1D\\u1F20-\\u1F45\\u1F48-\\u1F4D\\u1F50-\\u1F57\\u1F59\\u1F5B\\u1F5D\\u1F5F-\\u1F7D\\u1F80-\\u1FB4\\u1FB6-\\u1FBC\\u1FBE\\u1FC2-\\u1FC4\\u1FC6-\\u1FCC\\u1FD0-\\u1FD3\\u1FD6-\\u1FDB\\u1FE0-\\u1FEC\\u1FF2-\\u1FF4\\u1FF6-\\u1FFC\\u200E\\u2071\\u207F\\u2090-\\u209C\\u2102\\u2107\\u210A-\\u2113\\u2115\\u2119-\\u211D\\u2124\\u2126\\u2128\\u212A-\\u212D\\u212F-\\u2139\\u213C-\\u213F\\u2145-\\u2149\\u214E\\u214F\\u2160-\\u2188\\u2336-\\u237A\\u2395\\u249C-\\u24E9\\u26AC\\u2800-\\u28FF\\u2C00-\\u2CE4\\u2CEB-\\u2CEE\\u2CF2\\u2CF3\\u2D00-\\u2D25\\u2D27\\u2D2D\\u2D30-\\u2D67\\u2D6F\\u2D70\\u2D80-\\u2D96\\u2DA0-\\u2DA6\\u2DA8-\\u2DAE\\u2DB0-\\u2DB6\\u2DB8-\\u2DBE\\u2DC0-\\u2DC6\\u2DC8-\\u2DCE\\u2DD0-\\u2DD6\\u2DD8-\\u2DDE\\u3005-\\u3007\\u3021-\\u3029\\u302E\\u302F\\u3031-\\u3035\\u3038-\\u303C\\u3041-\\u3096\\u309D-\\u309F\\u30A1-\\u30FA\\u30FC-\\u30FF\\u3105-\\u312F\\u3131-\\u318E\\u3190-\\u31BF\\u31F0-\\u321C\\u3220-\\u324F\\u3260-\\u327B\\u327F-\\u32B0\\u32C0-\\u32CB\\u32D0-\\u3376\\u337B-\\u33DD\\u33E0-\\u33FE\\u3400-\\u4DBF\\u4E00-\\uA48C\\uA4D0-\\uA60C\\uA610-\\uA62B\\uA640-\\uA66E\\uA680-\\uA69D\\uA6A0-\\uA6EF\\uA6F2-\\uA6F7\\uA722-\\uA787\\uA789-\\uA7CA\\uA7D0\\uA7D1\\uA7D3\\uA7D5-\\uA7D9\\uA7F2-\\uA801\\uA803-\\uA805\\uA807-\\uA80A\\uA80C-\\uA824\\uA827\\uA830-\\uA837\\uA840-\\uA873\\uA880-\\uA8C3\\uA8CE-\\uA8D9\\uA8F2-\\uA8FE\\uA900-\\uA925\\uA92E-\\uA946\\uA952\\uA953\\uA95F-\\uA97C\\uA983-\\uA9B2\\uA9B4\\uA9B5\\uA9BA\\uA9BB\\uA9BE-\\uA9CD\\uA9CF-\\uA9D9\\uA9DE-\\uA9E4\\uA9E6-\\uA9FE\\uAA00-\\uAA28\\uAA2F\\uAA30\\uAA33\\uAA34\\uAA40-\\uAA42\\uAA44-\\uAA4B\\uAA4D\\uAA50-\\uAA59\\uAA5C-\\uAA7B\\uAA7D-\\uAAAF\\uAAB1\\uAAB5\\uAAB6\\uAAB9-\\uAABD\\uAAC0\\uAAC2\\uAADB-\\uAAEB\\uAAEE-\\uAAF5\\uAB01-\\uAB06\\uAB09-\\uAB0E\\uAB11-\\uAB16\\uAB20-\\uAB26\\uAB28-\\uAB2E\\uAB30-\\uAB69\\uAB70-\\uABE4\\uABE6\\uABE7\\uABE9-\\uABEC\\uABF0-\\uABF9\\uAC00-\\uD7A3\\uD7B0-\\uD7C6\\uD7CB-\\uD7FB\\uD800-\\uFA6D\\uFA70-\\uFAD9\\uFB00-\\uFB06\\uFB13-\\uFB17\\uFF21-\\uFF3A\\uFF41-\\uFF5A\\uFF66-\\uFFBE\\uFFC2-\\uFFC7\\uFFCA-\\uFFCF\\uFFD2-\\uFFD7\\uFFDA-\\uFFDC\\u{10000}-\\u{1000B}\\u{1000D}-\\u{10026}\\u{10028}-\\u{1003A}\\u{1003C}\\u{1003D}\\u{1003F}-\\u{1004D}\\u{10050}-\\u{1005D}\\u{10080}-\\u{100FA}\\u{10100}\\u{10102}\\u{10107}-\\u{10133}\\u{10137}-\\u{1013F}\\u{1018D}\\u{1018E}\\u{101D0}-\\u{101FC}\\u{10280}-\\u{1029C}\\u{102A0}-\\u{102D0}\\u{10300}-\\u{10323}\\u{1032D}-\\u{1034A}\\u{10350}-\\u{10375}\\u{10380}-\\u{1039D}\\u{1039F}-\\u{103C3}\\u{103C8}-\\u{103D5}\\u{10400}-\\u{1049D}\\u{104A0}-\\u{104A9}\\u{104B0}-\\u{104D3}\\u{104D8}-\\u{104FB}\\u{10500}-\\u{10527}\\u{10530}-\\u{10563}\\u{1056F}-\\u{1057A}\\u{1057C}-\\u{1058A}\\u{1058C}-\\u{10592}\\u{10594}\\u{10595}\\u{10597}-\\u{105A1}\\u{105A3}-\\u{105B1}\\u{105B3}-\\u{105B9}\\u{105BB}\\u{105BC}\\u{10600}-\\u{10736}\\u{10740}-\\u{10755}\\u{10760}-\\u{10767}\\u{10780}-\\u{10785}\\u{10787}-\\u{107B0}\\u{107B2}-\\u{107BA}\\u{11000}\\u{11002}-\\u{11037}\\u{11047}-\\u{1104D}\\u{11066}-\\u{1106F}\\u{11071}\\u{11072}\\u{11075}\\u{11082}-\\u{110B2}\\u{110B7}\\u{110B8}\\u{110BB}-\\u{110C1}\\u{110CD}\\u{110D0}-\\u{110E8}\\u{110F0}-\\u{110F9}\\u{11103}-\\u{11126}\\u{1112C}\\u{11136}-\\u{11147}\\u{11150}-\\u{11172}\\u{11174}-\\u{11176}\\u{11182}-\\u{111B5}\\u{111BF}-\\u{111C8}\\u{111CD}\\u{111CE}\\u{111D0}-\\u{111DF}\\u{111E1}-\\u{111F4}\\u{11200}-\\u{11211}\\u{11213}-\\u{1122E}\\u{11232}\\u{11233}\\u{11235}\\u{11238}-\\u{1123D}\\u{1123F}\\u{11240}\\u{11280}-\\u{11286}\\u{11288}\\u{1128A}-\\u{1128D}\\u{1128F}-\\u{1129D}\\u{1129F}-\\u{112A9}\\u{112B0}-\\u{112DE}\\u{112E0}-\\u{112E2}\\u{112F0}-\\u{112F9}\\u{11302}\\u{11303}\\u{11305}-\\u{1130C}\\u{1130F}\\u{11310}\\u{11313}-\\u{11328}\\u{1132A}-\\u{11330}\\u{11332}\\u{11333}\\u{11335}-\\u{11339}\\u{1133D}-\\u{1133F}\\u{11341}-\\u{11344}\\u{11347}\\u{11348}\\u{1134B}-\\u{1134D}\\u{11350}\\u{11357}\\u{1135D}-\\u{11363}\\u{11400}-\\u{11437}\\u{11440}\\u{11441}\\u{11445}\\u{11447}-\\u{1145B}\\u{1145D}\\u{1145F}-\\u{11461}\\u{11480}-\\u{114B2}\\u{114B9}\\u{114BB}-\\u{114BE}\\u{114C1}\\u{114C4}-\\u{114C7}\\u{114D0}-\\u{114D9}\\u{11580}-\\u{115B1}\\u{115B8}-\\u{115BB}\\u{115BE}\\u{115C1}-\\u{115DB}\\u{11600}-\\u{11632}\\u{1163B}\\u{1163C}\\u{1163E}\\u{11641}-\\u{11644}\\u{11650}-\\u{11659}\\u{11680}-\\u{116AA}\\u{116AC}\\u{116AE}\\u{116AF}\\u{116B6}\\u{116B8}\\u{116B9}\\u{116C0}-\\u{116C9}\\u{11700}-\\u{1171A}\\u{11720}\\u{11721}\\u{11726}\\u{11730}-\\u{11746}\\u{11800}-\\u{1182E}\\u{11838}\\u{1183B}\\u{118A0}-\\u{118F2}\\u{118FF}-\\u{11906}\\u{11909}\\u{1190C}-\\u{11913}\\u{11915}\\u{11916}\\u{11918}-\\u{11935}\\u{11937}\\u{11938}\\u{1193D}\\u{1193F}-\\u{11942}\\u{11944}-\\u{11946}\\u{11950}-\\u{11959}\\u{119A0}-\\u{119A7}\\u{119AA}-\\u{119D3}\\u{119DC}-\\u{119DF}\\u{119E1}-\\u{119E4}\\u{11A00}\\u{11A07}\\u{11A08}\\u{11A0B}-\\u{11A32}\\u{11A39}\\u{11A3A}\\u{11A3F}-\\u{11A46}\\u{11A50}\\u{11A57}\\u{11A58}\\u{11A5C}-\\u{11A89}\\u{11A97}\\u{11A9A}-\\u{11AA2}\\u{11AB0}-\\u{11AF8}\\u{11B00}-\\u{11B09}\\u{11C00}-\\u{11C08}\\u{11C0A}-\\u{11C2F}\\u{11C3E}-\\u{11C45}\\u{11C50}-\\u{11C6C}\\u{11C70}-\\u{11C8F}\\u{11CA9}\\u{11CB1}\\u{11CB4}\\u{11D00}-\\u{11D06}\\u{11D08}\\u{11D09}\\u{11D0B}-\\u{11D30}\\u{11D46}\\u{11D50}-\\u{11D59}\\u{11D60}-\\u{11D65}\\u{11D67}\\u{11D68}\\u{11D6A}-\\u{11D8E}\\u{11D93}\\u{11D94}\\u{11D96}\\u{11D98}\\u{11DA0}-\\u{11DA9}\\u{11EE0}-\\u{11EF2}\\u{11EF5}-\\u{11EF8}\\u{11F02}-\\u{11F10}\\u{11F12}-\\u{11F35}\\u{11F3E}\\u{11F3F}\\u{11F41}\\u{11F43}-\\u{11F59}\\u{11FB0}\\u{11FC0}-\\u{11FD4}\\u{11FFF}-\\u{12399}\\u{12400}-\\u{1246E}\\u{12470}-\\u{12474}\\u{12480}-\\u{12543}\\u{12F90}-\\u{12FF2}\\u{13000}-\\u{1343F}\\u{13441}-\\u{13446}\\u{14400}-\\u{14646}\\u{16800}-\\u{16A38}\\u{16A40}-\\u{16A5E}\\u{16A60}-\\u{16A69}\\u{16A6E}-\\u{16ABE}\\u{16AC0}-\\u{16AC9}\\u{16AD0}-\\u{16AED}\\u{16AF5}\\u{16B00}-\\u{16B2F}\\u{16B37}-\\u{16B45}\\u{16B50}-\\u{16B59}\\u{16B5B}-\\u{16B61}\\u{16B63}-\\u{16B77}\\u{16B7D}-\\u{16B8F}\\u{16E40}-\\u{16E9A}\\u{16F00}-\\u{16F4A}\\u{16F50}-\\u{16F87}\\u{16F93}-\\u{16F9F}\\u{16FE0}\\u{16FE1}\\u{16FE3}\\u{16FF0}\\u{16FF1}\\u{17000}-\\u{187F7}\\u{18800}-\\u{18CD5}\\u{18D00}-\\u{18D08}\\u{1AFF0}-\\u{1AFF3}\\u{1AFF5}-\\u{1AFFB}\\u{1AFFD}\\u{1AFFE}\\u{1B000}-\\u{1B122}\\u{1B132}\\u{1B150}-\\u{1B152}\\u{1B155}\\u{1B164}-\\u{1B167}\\u{1B170}-\\u{1B2FB}\\u{1BC00}-\\u{1BC6A}\\u{1BC70}-\\u{1BC7C}\\u{1BC80}-\\u{1BC88}\\u{1BC90}-\\u{1BC99}\\u{1BC9C}\\u{1BC9F}\\u{1CF50}-\\u{1CFC3}\\u{1D000}-\\u{1D0F5}\\u{1D100}-\\u{1D126}\\u{1D129}-\\u{1D166}\\u{1D16A}-\\u{1D172}\\u{1D183}\\u{1D184}\\u{1D18C}-\\u{1D1A9}\\u{1D1AE}-\\u{1D1E8}\\u{1D2C0}-\\u{1D2D3}\\u{1D2E0}-\\u{1D2F3}\\u{1D360}-\\u{1D378}\\u{1D400}-\\u{1D454}\\u{1D456}-\\u{1D49C}\\u{1D49E}\\u{1D49F}\\u{1D4A2}\\u{1D4A5}\\u{1D4A6}\\u{1D4A9}-\\u{1D4AC}\\u{1D4AE}-\\u{1D4B9}\\u{1D4BB}\\u{1D4BD}-\\u{1D4C3}\\u{1D4C5}-\\u{1D505}\\u{1D507}-\\u{1D50A}\\u{1D50D}-\\u{1D514}\\u{1D516}-\\u{1D51C}\\u{1D51E}-\\u{1D539}\\u{1D53B}-\\u{1D53E}\\u{1D540}-\\u{1D544}\\u{1D546}\\u{1D54A}-\\u{1D550}\\u{1D552}-\\u{1D6A5}\\u{1D6A8}-\\u{1D6DA}\\u{1D6DC}-\\u{1D714}\\u{1D716}-\\u{1D74E}\\u{1D750}-\\u{1D788}\\u{1D78A}-\\u{1D7C2}\\u{1D7C4}-\\u{1D7CB}\\u{1D800}-\\u{1D9FF}\\u{1DA37}-\\u{1DA3A}\\u{1DA6D}-\\u{1DA74}\\u{1DA76}-\\u{1DA83}\\u{1DA85}-\\u{1DA8B}\\u{1DF00}-\\u{1DF1E}\\u{1DF25}-\\u{1DF2A}\\u{1E030}-\\u{1E06D}\\u{1E100}-\\u{1E12C}\\u{1E137}-\\u{1E13D}\\u{1E140}-\\u{1E149}\\u{1E14E}\\u{1E14F}\\u{1E290}-\\u{1E2AD}\\u{1E2C0}-\\u{1E2EB}\\u{1E2F0}-\\u{1E2F9}\\u{1E4D0}-\\u{1E4EB}\\u{1E4F0}-\\u{1E4F9}\\u{1E7E0}-\\u{1E7E6}\\u{1E7E8}-\\u{1E7EB}\\u{1E7ED}\\u{1E7EE}\\u{1E7F0}-\\u{1E7FE}\\u{1F110}-\\u{1F12E}\\u{1F130}-\\u{1F169}\\u{1F170}-\\u{1F1AC}\\u{1F1E6}-\\u{1F202}\\u{1F210}-\\u{1F23B}\\u{1F240}-\\u{1F248}\\u{1F250}\\u{1F251}\\u{20000}-\\u{2A6DF}\\u{2A700}-\\u{2B739}\\u{2B740}-\\u{2B81D}\\u{2B820}-\\u{2CEA1}\\u{2CEB0}-\\u{2EBE0}\\u{2F800}-\\u{2FA1D}\\u{30000}-\\u{3134A}\\u{31350}-\\u{323AF}\\u{F0000}-\\u{FFFFD}\\u{100000}-\\u{10FFFD}]/u;\nconst bidiS1RTL = /[\\u05BE\\u05C0\\u05C3\\u05C6\\u05D0-\\u05EA\\u05EF-\\u05F4\\u0608\\u060B\\u060D\\u061B-\\u064A\\u066D-\\u066F\\u0671-\\u06D5\\u06E5\\u06E6\\u06EE\\u06EF\\u06FA-\\u070D\\u070F\\u0710\\u0712-\\u072F\\u074D-\\u07A5\\u07B1\\u07C0-\\u07EA\\u07F4\\u07F5\\u07FA\\u07FE-\\u0815\\u081A\\u0824\\u0828\\u0830-\\u083E\\u0840-\\u0858\\u085E\\u0860-\\u086A\\u0870-\\u088E\\u08A0-\\u08C9\\u200F\\uFB1D\\uFB1F-\\uFB28\\uFB2A-\\uFB36\\uFB38-\\uFB3C\\uFB3E\\uFB40\\uFB41\\uFB43\\uFB44\\uFB46-\\uFBC2\\uFBD3-\\uFD3D\\uFD50-\\uFD8F\\uFD92-\\uFDC7\\uFDF0-\\uFDFC\\uFE70-\\uFE74\\uFE76-\\uFEFC\\u{10800}-\\u{10805}\\u{10808}\\u{1080A}-\\u{10835}\\u{10837}\\u{10838}\\u{1083C}\\u{1083F}-\\u{10855}\\u{10857}-\\u{1089E}\\u{108A7}-\\u{108AF}\\u{108E0}-\\u{108F2}\\u{108F4}\\u{108F5}\\u{108FB}-\\u{1091B}\\u{10920}-\\u{10939}\\u{1093F}\\u{10980}-\\u{109B7}\\u{109BC}-\\u{109CF}\\u{109D2}-\\u{10A00}\\u{10A10}-\\u{10A13}\\u{10A15}-\\u{10A17}\\u{10A19}-\\u{10A35}\\u{10A40}-\\u{10A48}\\u{10A50}-\\u{10A58}\\u{10A60}-\\u{10A9F}\\u{10AC0}-\\u{10AE4}\\u{10AEB}-\\u{10AF6}\\u{10B00}-\\u{10B35}\\u{10B40}-\\u{10B55}\\u{10B58}-\\u{10B72}\\u{10B78}-\\u{10B91}\\u{10B99}-\\u{10B9C}\\u{10BA9}-\\u{10BAF}\\u{10C00}-\\u{10C48}\\u{10C80}-\\u{10CB2}\\u{10CC0}-\\u{10CF2}\\u{10CFA}-\\u{10D23}\\u{10E80}-\\u{10EA9}\\u{10EAD}\\u{10EB0}\\u{10EB1}\\u{10F00}-\\u{10F27}\\u{10F30}-\\u{10F45}\\u{10F51}-\\u{10F59}\\u{10F70}-\\u{10F81}\\u{10F86}-\\u{10F89}\\u{10FB0}-\\u{10FCB}\\u{10FE0}-\\u{10FF6}\\u{1E800}-\\u{1E8C4}\\u{1E8C7}-\\u{1E8CF}\\u{1E900}-\\u{1E943}\\u{1E94B}\\u{1E950}-\\u{1E959}\\u{1E95E}\\u{1E95F}\\u{1EC71}-\\u{1ECB4}\\u{1ED01}-\\u{1ED3D}\\u{1EE00}-\\u{1EE03}\\u{1EE05}-\\u{1EE1F}\\u{1EE21}\\u{1EE22}\\u{1EE24}\\u{1EE27}\\u{1EE29}-\\u{1EE32}\\u{1EE34}-\\u{1EE37}\\u{1EE39}\\u{1EE3B}\\u{1EE42}\\u{1EE47}\\u{1EE49}\\u{1EE4B}\\u{1EE4D}-\\u{1EE4F}\\u{1EE51}\\u{1EE52}\\u{1EE54}\\u{1EE57}\\u{1EE59}\\u{1EE5B}\\u{1EE5D}\\u{1EE5F}\\u{1EE61}\\u{1EE62}\\u{1EE64}\\u{1EE67}-\\u{1EE6A}\\u{1EE6C}-\\u{1EE72}\\u{1EE74}-\\u{1EE77}\\u{1EE79}-\\u{1EE7C}\\u{1EE7E}\\u{1EE80}-\\u{1EE89}\\u{1EE8B}-\\u{1EE9B}\\u{1EEA1}-\\u{1EEA3}\\u{1EEA5}-\\u{1EEA9}\\u{1EEAB}-\\u{1EEBB}]/u;\nconst bidiS2 = /^[\\0-\\x08\\x0E-\\x1B!-@\\[-`\\{-\\x84\\x86-\\xA9\\xAB-\\xB4\\xB6-\\xB9\\xBB-\\xBF\\xD7\\xF7\\u02B9\\u02BA\\u02C2-\\u02CF\\u02D2-\\u02DF\\u02E5-\\u02ED\\u02EF-\\u036F\\u0374\\u0375\\u037E\\u0384\\u0385\\u0387\\u03F6\\u0483-\\u0489\\u058A\\u058D-\\u058F\\u0591-\\u05C7\\u05D0-\\u05EA\\u05EF-\\u05F4\\u0600-\\u070D\\u070F-\\u074A\\u074D-\\u07B1\\u07C0-\\u07FA\\u07FD-\\u082D\\u0830-\\u083E\\u0840-\\u085B\\u085E\\u0860-\\u086A\\u0870-\\u088E\\u0890\\u0891\\u0898-\\u0902\\u093A\\u093C\\u0941-\\u0948\\u094D\\u0951-\\u0957\\u0962\\u0963\\u0981\\u09BC\\u09C1-\\u09C4\\u09CD\\u09E2\\u09E3\\u09F2\\u09F3\\u09FB\\u09FE\\u0A01\\u0A02\\u0A3C\\u0A41\\u0A42\\u0A47\\u0A48\\u0A4B-\\u0A4D\\u0A51\\u0A70\\u0A71\\u0A75\\u0A81\\u0A82\\u0ABC\\u0AC1-\\u0AC5\\u0AC7\\u0AC8\\u0ACD\\u0AE2\\u0AE3\\u0AF1\\u0AFA-\\u0AFF\\u0B01\\u0B3C\\u0B3F\\u0B41-\\u0B44\\u0B4D\\u0B55\\u0B56\\u0B62\\u0B63\\u0B82\\u0BC0\\u0BCD\\u0BF3-\\u0BFA\\u0C00\\u0C04\\u0C3C\\u0C3E-\\u0C40\\u0C46-\\u0C48\\u0C4A-\\u0C4D\\u0C55\\u0C56\\u0C62\\u0C63\\u0C78-\\u0C7E\\u0C81\\u0CBC\\u0CCC\\u0CCD\\u0CE2\\u0CE3\\u0D00\\u0D01\\u0D3B\\u0D3C\\u0D41-\\u0D44\\u0D4D\\u0D62\\u0D63\\u0D81\\u0DCA\\u0DD2-\\u0DD4\\u0DD6\\u0E31\\u0E34-\\u0E3A\\u0E3F\\u0E47-\\u0E4E\\u0EB1\\u0EB4-\\u0EBC\\u0EC8-\\u0ECE\\u0F18\\u0F19\\u0F35\\u0F37\\u0F39-\\u0F3D\\u0F71-\\u0F7E\\u0F80-\\u0F84\\u0F86\\u0F87\\u0F8D-\\u0F97\\u0F99-\\u0FBC\\u0FC6\\u102D-\\u1030\\u1032-\\u1037\\u1039\\u103A\\u103D\\u103E\\u1058\\u1059\\u105E-\\u1060\\u1071-\\u1074\\u1082\\u1085\\u1086\\u108D\\u109D\\u135D-\\u135F\\u1390-\\u1399\\u1400\\u169B\\u169C\\u1712-\\u1714\\u1732\\u1733\\u1752\\u1753\\u1772\\u1773\\u17B4\\u17B5\\u17B7-\\u17BD\\u17C6\\u17C9-\\u17D3\\u17DB\\u17DD\\u17F0-\\u17F9\\u1800-\\u180F\\u1885\\u1886\\u18A9\\u1920-\\u1922\\u1927\\u1928\\u1932\\u1939-\\u193B\\u1940\\u1944\\u1945\\u19DE-\\u19FF\\u1A17\\u1A18\\u1A1B\\u1A56\\u1A58-\\u1A5E\\u1A60\\u1A62\\u1A65-\\u1A6C\\u1A73-\\u1A7C\\u1A7F\\u1AB0-\\u1ACE\\u1B00-\\u1B03\\u1B34\\u1B36-\\u1B3A\\u1B3C\\u1B42\\u1B6B-\\u1B73\\u1B80\\u1B81\\u1BA2-\\u1BA5\\u1BA8\\u1BA9\\u1BAB-\\u1BAD\\u1BE6\\u1BE8\\u1BE9\\u1BED\\u1BEF-\\u1BF1\\u1C2C-\\u1C33\\u1C36\\u1C37\\u1CD0-\\u1CD2\\u1CD4-\\u1CE0\\u1CE2-\\u1CE8\\u1CED\\u1CF4\\u1CF8\\u1CF9\\u1DC0-\\u1DFF\\u1FBD\\u1FBF-\\u1FC1\\u1FCD-\\u1FCF\\u1FDD-\\u1FDF\\u1FED-\\u1FEF\\u1FFD\\u1FFE\\u200B-\\u200D\\u200F-\\u2027\\u202F-\\u205E\\u2060-\\u2064\\u206A-\\u2070\\u2074-\\u207E\\u2080-\\u208E\\u20A0-\\u20C0\\u20D0-\\u20F0\\u2100\\u2101\\u2103-\\u2106\\u2108\\u2109\\u2114\\u2116-\\u2118\\u211E-\\u2123\\u2125\\u2127\\u2129\\u212E\\u213A\\u213B\\u2140-\\u2144\\u214A-\\u214D\\u2150-\\u215F\\u2189-\\u218B\\u2190-\\u2335\\u237B-\\u2394\\u2396-\\u2426\\u2440-\\u244A\\u2460-\\u249B\\u24EA-\\u26AB\\u26AD-\\u27FF\\u2900-\\u2B73\\u2B76-\\u2B95\\u2B97-\\u2BFF\\u2CE5-\\u2CEA\\u2CEF-\\u2CF1\\u2CF9-\\u2CFF\\u2D7F\\u2DE0-\\u2E5D\\u2E80-\\u2E99\\u2E9B-\\u2EF3\\u2F00-\\u2FD5\\u2FF0-\\u2FFB\\u3001-\\u3004\\u3008-\\u3020\\u302A-\\u302D\\u3030\\u3036\\u3037\\u303D-\\u303F\\u3099-\\u309C\\u30A0\\u30FB\\u31C0-\\u31E3\\u321D\\u321E\\u3250-\\u325F\\u327C-\\u327E\\u32B1-\\u32BF\\u32CC-\\u32CF\\u3377-\\u337A\\u33DE\\u33DF\\u33FF\\u4DC0-\\u4DFF\\uA490-\\uA4C6\\uA60D-\\uA60F\\uA66F-\\uA67F\\uA69E\\uA69F\\uA6F0\\uA6F1\\uA700-\\uA721\\uA788\\uA802\\uA806\\uA80B\\uA825\\uA826\\uA828-\\uA82C\\uA838\\uA839\\uA874-\\uA877\\uA8C4\\uA8C5\\uA8E0-\\uA8F1\\uA8FF\\uA926-\\uA92D\\uA947-\\uA951\\uA980-\\uA982\\uA9B3\\uA9B6-\\uA9B9\\uA9BC\\uA9BD\\uA9E5\\uAA29-\\uAA2E\\uAA31\\uAA32\\uAA35\\uAA36\\uAA43\\uAA4C\\uAA7C\\uAAB0\\uAAB2-\\uAAB4\\uAAB7\\uAAB8\\uAABE\\uAABF\\uAAC1\\uAAEC\\uAAED\\uAAF6\\uAB6A\\uAB6B\\uABE5\\uABE8\\uABED\\uFB1D-\\uFB36\\uFB38-\\uFB3C\\uFB3E\\uFB40\\uFB41\\uFB43\\uFB44\\uFB46-\\uFBC2\\uFBD3-\\uFD8F\\uFD92-\\uFDC7\\uFDCF\\uFDF0-\\uFE19\\uFE20-\\uFE52\\uFE54-\\uFE66\\uFE68-\\uFE6B\\uFE70-\\uFE74\\uFE76-\\uFEFC\\uFEFF\\uFF01-\\uFF20\\uFF3B-\\uFF40\\uFF5B-\\uFF65\\uFFE0-\\uFFE6\\uFFE8-\\uFFEE\\uFFF9-\\uFFFD\\u{10101}\\u{10140}-\\u{1018C}\\u{10190}-\\u{1019C}\\u{101A0}\\u{101FD}\\u{102E0}-\\u{102FB}\\u{10376}-\\u{1037A}\\u{10800}-\\u{10805}\\u{10808}\\u{1080A}-\\u{10835}\\u{10837}\\u{10838}\\u{1083C}\\u{1083F}-\\u{10855}\\u{10857}-\\u{1089E}\\u{108A7}-\\u{108AF}\\u{108E0}-\\u{108F2}\\u{108F4}\\u{108F5}\\u{108FB}-\\u{1091B}\\u{1091F}-\\u{10939}\\u{1093F}\\u{10980}-\\u{109B7}\\u{109BC}-\\u{109CF}\\u{109D2}-\\u{10A03}\\u{10A05}\\u{10A06}\\u{10A0C}-\\u{10A13}\\u{10A15}-\\u{10A17}\\u{10A19}-\\u{10A35}\\u{10A38}-\\u{10A3A}\\u{10A3F}-\\u{10A48}\\u{10A50}-\\u{10A58}\\u{10A60}-\\u{10A9F}\\u{10AC0}-\\u{10AE6}\\u{10AEB}-\\u{10AF6}\\u{10B00}-\\u{10B35}\\u{10B39}-\\u{10B55}\\u{10B58}-\\u{10B72}\\u{10B78}-\\u{10B91}\\u{10B99}-\\u{10B9C}\\u{10BA9}-\\u{10BAF}\\u{10C00}-\\u{10C48}\\u{10C80}-\\u{10CB2}\\u{10CC0}-\\u{10CF2}\\u{10CFA}-\\u{10D27}\\u{10D30}-\\u{10D39}\\u{10E60}-\\u{10E7E}\\u{10E80}-\\u{10EA9}\\u{10EAB}-\\u{10EAD}\\u{10EB0}\\u{10EB1}\\u{10EFD}-\\u{10F27}\\u{10F30}-\\u{10F59}\\u{10F70}-\\u{10F89}\\u{10FB0}-\\u{10FCB}\\u{10FE0}-\\u{10FF6}\\u{11001}\\u{11038}-\\u{11046}\\u{11052}-\\u{11065}\\u{11070}\\u{11073}\\u{11074}\\u{1107F}-\\u{11081}\\u{110B3}-\\u{110B6}\\u{110B9}\\u{110BA}\\u{110C2}\\u{11100}-\\u{11102}\\u{11127}-\\u{1112B}\\u{1112D}-\\u{11134}\\u{11173}\\u{11180}\\u{11181}\\u{111B6}-\\u{111BE}\\u{111C9}-\\u{111CC}\\u{111CF}\\u{1122F}-\\u{11231}\\u{11234}\\u{11236}\\u{11237}\\u{1123E}\\u{11241}\\u{112DF}\\u{112E3}-\\u{112EA}\\u{11300}\\u{11301}\\u{1133B}\\u{1133C}\\u{11340}\\u{11366}-\\u{1136C}\\u{11370}-\\u{11374}\\u{11438}-\\u{1143F}\\u{11442}-\\u{11444}\\u{11446}\\u{1145E}\\u{114B3}-\\u{114B8}\\u{114BA}\\u{114BF}\\u{114C0}\\u{114C2}\\u{114C3}\\u{115B2}-\\u{115B5}\\u{115BC}\\u{115BD}\\u{115BF}\\u{115C0}\\u{115DC}\\u{115DD}\\u{11633}-\\u{1163A}\\u{1163D}\\u{1163F}\\u{11640}\\u{11660}-\\u{1166C}\\u{116AB}\\u{116AD}\\u{116B0}-\\u{116B5}\\u{116B7}\\u{1171D}-\\u{1171F}\\u{11722}-\\u{11725}\\u{11727}-\\u{1172B}\\u{1182F}-\\u{11837}\\u{11839}\\u{1183A}\\u{1193B}\\u{1193C}\\u{1193E}\\u{11943}\\u{119D4}-\\u{119D7}\\u{119DA}\\u{119DB}\\u{119E0}\\u{11A01}-\\u{11A06}\\u{11A09}\\u{11A0A}\\u{11A33}-\\u{11A38}\\u{11A3B}-\\u{11A3E}\\u{11A47}\\u{11A51}-\\u{11A56}\\u{11A59}-\\u{11A5B}\\u{11A8A}-\\u{11A96}\\u{11A98}\\u{11A99}\\u{11C30}-\\u{11C36}\\u{11C38}-\\u{11C3D}\\u{11C92}-\\u{11CA7}\\u{11CAA}-\\u{11CB0}\\u{11CB2}\\u{11CB3}\\u{11CB5}\\u{11CB6}\\u{11D31}-\\u{11D36}\\u{11D3A}\\u{11D3C}\\u{11D3D}\\u{11D3F}-\\u{11D45}\\u{11D47}\\u{11D90}\\u{11D91}\\u{11D95}\\u{11D97}\\u{11EF3}\\u{11EF4}\\u{11F00}\\u{11F01}\\u{11F36}-\\u{11F3A}\\u{11F40}\\u{11F42}\\u{11FD5}-\\u{11FF1}\\u{13440}\\u{13447}-\\u{13455}\\u{16AF0}-\\u{16AF4}\\u{16B30}-\\u{16B36}\\u{16F4F}\\u{16F8F}-\\u{16F92}\\u{16FE2}\\u{16FE4}\\u{1BC9D}\\u{1BC9E}\\u{1BCA0}-\\u{1BCA3}\\u{1CF00}-\\u{1CF2D}\\u{1CF30}-\\u{1CF46}\\u{1D167}-\\u{1D169}\\u{1D173}-\\u{1D182}\\u{1D185}-\\u{1D18B}\\u{1D1AA}-\\u{1D1AD}\\u{1D1E9}\\u{1D1EA}\\u{1D200}-\\u{1D245}\\u{1D300}-\\u{1D356}\\u{1D6DB}\\u{1D715}\\u{1D74F}\\u{1D789}\\u{1D7C3}\\u{1D7CE}-\\u{1D7FF}\\u{1DA00}-\\u{1DA36}\\u{1DA3B}-\\u{1DA6C}\\u{1DA75}\\u{1DA84}\\u{1DA9B}-\\u{1DA9F}\\u{1DAA1}-\\u{1DAAF}\\u{1E000}-\\u{1E006}\\u{1E008}-\\u{1E018}\\u{1E01B}-\\u{1E021}\\u{1E023}\\u{1E024}\\u{1E026}-\\u{1E02A}\\u{1E08F}\\u{1E130}-\\u{1E136}\\u{1E2AE}\\u{1E2EC}-\\u{1E2EF}\\u{1E2FF}\\u{1E4EC}-\\u{1E4EF}\\u{1E800}-\\u{1E8C4}\\u{1E8C7}-\\u{1E8D6}\\u{1E900}-\\u{1E94B}\\u{1E950}-\\u{1E959}\\u{1E95E}\\u{1E95F}\\u{1EC71}-\\u{1ECB4}\\u{1ED01}-\\u{1ED3D}\\u{1EE00}-\\u{1EE03}\\u{1EE05}-\\u{1EE1F}\\u{1EE21}\\u{1EE22}\\u{1EE24}\\u{1EE27}\\u{1EE29}-\\u{1EE32}\\u{1EE34}-\\u{1EE37}\\u{1EE39}\\u{1EE3B}\\u{1EE42}\\u{1EE47}\\u{1EE49}\\u{1EE4B}\\u{1EE4D}-\\u{1EE4F}\\u{1EE51}\\u{1EE52}\\u{1EE54}\\u{1EE57}\\u{1EE59}\\u{1EE5B}\\u{1EE5D}\\u{1EE5F}\\u{1EE61}\\u{1EE62}\\u{1EE64}\\u{1EE67}-\\u{1EE6A}\\u{1EE6C}-\\u{1EE72}\\u{1EE74}-\\u{1EE77}\\u{1EE79}-\\u{1EE7C}\\u{1EE7E}\\u{1EE80}-\\u{1EE89}\\u{1EE8B}-\\u{1EE9B}\\u{1EEA1}-\\u{1EEA3}\\u{1EEA5}-\\u{1EEA9}\\u{1EEAB}-\\u{1EEBB}\\u{1EEF0}\\u{1EEF1}\\u{1F000}-\\u{1F02B}\\u{1F030}-\\u{1F093}\\u{1F0A0}-\\u{1F0AE}\\u{1F0B1}-\\u{1F0BF}\\u{1F0C1}-\\u{1F0CF}\\u{1F0D1}-\\u{1F0F5}\\u{1F100}-\\u{1F10F}\\u{1F12F}\\u{1F16A}-\\u{1F16F}\\u{1F1AD}\\u{1F260}-\\u{1F265}\\u{1F300}-\\u{1F6D7}\\u{1F6DC}-\\u{1F6EC}\\u{1F6F0}-\\u{1F6FC}\\u{1F700}-\\u{1F776}\\u{1F77B}-\\u{1F7D9}\\u{1F7E0}-\\u{1F7EB}\\u{1F7F0}\\u{1F800}-\\u{1F80B}\\u{1F810}-\\u{1F847}\\u{1F850}-\\u{1F859}\\u{1F860}-\\u{1F887}\\u{1F890}-\\u{1F8AD}\\u{1F8B0}\\u{1F8B1}\\u{1F900}-\\u{1FA53}\\u{1FA60}-\\u{1FA6D}\\u{1FA70}-\\u{1FA7C}\\u{1FA80}-\\u{1FA88}\\u{1FA90}-\\u{1FABD}\\u{1FABF}-\\u{1FAC5}\\u{1FACE}-\\u{1FADB}\\u{1FAE0}-\\u{1FAE8}\\u{1FAF0}-\\u{1FAF8}\\u{1FB00}-\\u{1FB92}\\u{1FB94}-\\u{1FBCA}\\u{1FBF0}-\\u{1FBF9}\\u{E0001}\\u{E0020}-\\u{E007F}\\u{E0100}-\\u{E01EF}]*$/u;\nconst bidiS3 = /[0-9\\xB2\\xB3\\xB9\\u05BE\\u05C0\\u05C3\\u05C6\\u05D0-\\u05EA\\u05EF-\\u05F4\\u0600-\\u0605\\u0608\\u060B\\u060D\\u061B-\\u064A\\u0660-\\u0669\\u066B-\\u066F\\u0671-\\u06D5\\u06DD\\u06E5\\u06E6\\u06EE-\\u070D\\u070F\\u0710\\u0712-\\u072F\\u074D-\\u07A5\\u07B1\\u07C0-\\u07EA\\u07F4\\u07F5\\u07FA\\u07FE-\\u0815\\u081A\\u0824\\u0828\\u0830-\\u083E\\u0840-\\u0858\\u085E\\u0860-\\u086A\\u0870-\\u088E\\u0890\\u0891\\u08A0-\\u08C9\\u08E2\\u200F\\u2070\\u2074-\\u2079\\u2080-\\u2089\\u2488-\\u249B\\uFB1D\\uFB1F-\\uFB28\\uFB2A-\\uFB36\\uFB38-\\uFB3C\\uFB3E\\uFB40\\uFB41\\uFB43\\uFB44\\uFB46-\\uFBC2\\uFBD3-\\uFD3D\\uFD50-\\uFD8F\\uFD92-\\uFDC7\\uFDF0-\\uFDFC\\uFE70-\\uFE74\\uFE76-\\uFEFC\\uFF10-\\uFF19\\u{102E1}-\\u{102FB}\\u{10800}-\\u{10805}\\u{10808}\\u{1080A}-\\u{10835}\\u{10837}\\u{10838}\\u{1083C}\\u{1083F}-\\u{10855}\\u{10857}-\\u{1089E}\\u{108A7}-\\u{108AF}\\u{108E0}-\\u{108F2}\\u{108F4}\\u{108F5}\\u{108FB}-\\u{1091B}\\u{10920}-\\u{10939}\\u{1093F}\\u{10980}-\\u{109B7}\\u{109BC}-\\u{109CF}\\u{109D2}-\\u{10A00}\\u{10A10}-\\u{10A13}\\u{10A15}-\\u{10A17}\\u{10A19}-\\u{10A35}\\u{10A40}-\\u{10A48}\\u{10A50}-\\u{10A58}\\u{10A60}-\\u{10A9F}\\u{10AC0}-\\u{10AE4}\\u{10AEB}-\\u{10AF6}\\u{10B00}-\\u{10B35}\\u{10B40}-\\u{10B55}\\u{10B58}-\\u{10B72}\\u{10B78}-\\u{10B91}\\u{10B99}-\\u{10B9C}\\u{10BA9}-\\u{10BAF}\\u{10C00}-\\u{10C48}\\u{10C80}-\\u{10CB2}\\u{10CC0}-\\u{10CF2}\\u{10CFA}-\\u{10D23}\\u{10D30}-\\u{10D39}\\u{10E60}-\\u{10E7E}\\u{10E80}-\\u{10EA9}\\u{10EAD}\\u{10EB0}\\u{10EB1}\\u{10F00}-\\u{10F27}\\u{10F30}-\\u{10F45}\\u{10F51}-\\u{10F59}\\u{10F70}-\\u{10F81}\\u{10F86}-\\u{10F89}\\u{10FB0}-\\u{10FCB}\\u{10FE0}-\\u{10FF6}\\u{1D7CE}-\\u{1D7FF}\\u{1E800}-\\u{1E8C4}\\u{1E8C7}-\\u{1E8CF}\\u{1E900}-\\u{1E943}\\u{1E94B}\\u{1E950}-\\u{1E959}\\u{1E95E}\\u{1E95F}\\u{1EC71}-\\u{1ECB4}\\u{1ED01}-\\u{1ED3D}\\u{1EE00}-\\u{1EE03}\\u{1EE05}-\\u{1EE1F}\\u{1EE21}\\u{1EE22}\\u{1EE24}\\u{1EE27}\\u{1EE29}-\\u{1EE32}\\u{1EE34}-\\u{1EE37}\\u{1EE39}\\u{1EE3B}\\u{1EE42}\\u{1EE47}\\u{1EE49}\\u{1EE4B}\\u{1EE4D}-\\u{1EE4F}\\u{1EE51}\\u{1EE52}\\u{1EE54}\\u{1EE57}\\u{1EE59}\\u{1EE5B}\\u{1EE5D}\\u{1EE5F}\\u{1EE61}\\u{1EE62}\\u{1EE64}\\u{1EE67}-\\u{1EE6A}\\u{1EE6C}-\\u{1EE72}\\u{1EE74}-\\u{1EE77}\\u{1EE79}-\\u{1EE7C}\\u{1EE7E}\\u{1EE80}-\\u{1EE89}\\u{1EE8B}-\\u{1EE9B}\\u{1EEA1}-\\u{1EEA3}\\u{1EEA5}-\\u{1EEA9}\\u{1EEAB}-\\u{1EEBB}\\u{1F100}-\\u{1F10A}\\u{1FBF0}-\\u{1FBF9}][\\u0300-\\u036F\\u0483-\\u0489\\u0591-\\u05BD\\u05BF\\u05C1\\u05C2\\u05C4\\u05C5\\u05C7\\u0610-\\u061A\\u064B-\\u065F\\u0670\\u06D6-\\u06DC\\u06DF-\\u06E4\\u06E7\\u06E8\\u06EA-\\u06ED\\u0711\\u0730-\\u074A\\u07A6-\\u07B0\\u07EB-\\u07F3\\u07FD\\u0816-\\u0819\\u081B-\\u0823\\u0825-\\u0827\\u0829-\\u082D\\u0859-\\u085B\\u0898-\\u089F\\u08CA-\\u08E1\\u08E3-\\u0902\\u093A\\u093C\\u0941-\\u0948\\u094D\\u0951-\\u0957\\u0962\\u0963\\u0981\\u09BC\\u09C1-\\u09C4\\u09CD\\u09E2\\u09E3\\u09FE\\u0A01\\u0A02\\u0A3C\\u0A41\\u0A42\\u0A47\\u0A48\\u0A4B-\\u0A4D\\u0A51\\u0A70\\u0A71\\u0A75\\u0A81\\u0A82\\u0ABC\\u0AC1-\\u0AC5\\u0AC7\\u0AC8\\u0ACD\\u0AE2\\u0AE3\\u0AFA-\\u0AFF\\u0B01\\u0B3C\\u0B3F\\u0B41-\\u0B44\\u0B4D\\u0B55\\u0B56\\u0B62\\u0B63\\u0B82\\u0BC0\\u0BCD\\u0C00\\u0C04\\u0C3C\\u0C3E-\\u0C40\\u0C46-\\u0C48\\u0C4A-\\u0C4D\\u0C55\\u0C56\\u0C62\\u0C63\\u0C81\\u0CBC\\u0CCC\\u0CCD\\u0CE2\\u0CE3\\u0D00\\u0D01\\u0D3B\\u0D3C\\u0D41-\\u0D44\\u0D4D\\u0D62\\u0D63\\u0D81\\u0DCA\\u0DD2-\\u0DD4\\u0DD6\\u0E31\\u0E34-\\u0E3A\\u0E47-\\u0E4E\\u0EB1\\u0EB4-\\u0EBC\\u0EC8-\\u0ECE\\u0F18\\u0F19\\u0F35\\u0F37\\u0F39\\u0F71-\\u0F7E\\u0F80-\\u0F84\\u0F86\\u0F87\\u0F8D-\\u0F97\\u0F99-\\u0FBC\\u0FC6\\u102D-\\u1030\\u1032-\\u1037\\u1039\\u103A\\u103D\\u103E\\u1058\\u1059\\u105E-\\u1060\\u1071-\\u1074\\u1082\\u1085\\u1086\\u108D\\u109D\\u135D-\\u135F\\u1712-\\u1714\\u1732\\u1733\\u1752\\u1753\\u1772\\u1773\\u17B4\\u17B5\\u17B7-\\u17BD\\u17C6\\u17C9-\\u17D3\\u17DD\\u180B-\\u180D\\u180F\\u1885\\u1886\\u18A9\\u1920-\\u1922\\u1927\\u1928\\u1932\\u1939-\\u193B\\u1A17\\u1A18\\u1A1B\\u1A56\\u1A58-\\u1A5E\\u1A60\\u1A62\\u1A65-\\u1A6C\\u1A73-\\u1A7C\\u1A7F\\u1AB0-\\u1ACE\\u1B00-\\u1B03\\u1B34\\u1B36-\\u1B3A\\u1B3C\\u1B42\\u1B6B-\\u1B73\\u1B80\\u1B81\\u1BA2-\\u1BA5\\u1BA8\\u1BA9\\u1BAB-\\u1BAD\\u1BE6\\u1BE8\\u1BE9\\u1BED\\u1BEF-\\u1BF1\\u1C2C-\\u1C33\\u1C36\\u1C37\\u1CD0-\\u1CD2\\u1CD4-\\u1CE0\\u1CE2-\\u1CE8\\u1CED\\u1CF4\\u1CF8\\u1CF9\\u1DC0-\\u1DFF\\u20D0-\\u20F0\\u2CEF-\\u2CF1\\u2D7F\\u2DE0-\\u2DFF\\u302A-\\u302D\\u3099\\u309A\\uA66F-\\uA672\\uA674-\\uA67D\\uA69E\\uA69F\\uA6F0\\uA6F1\\uA802\\uA806\\uA80B\\uA825\\uA826\\uA82C\\uA8C4\\uA8C5\\uA8E0-\\uA8F1\\uA8FF\\uA926-\\uA92D\\uA947-\\uA951\\uA980-\\uA982\\uA9B3\\uA9B6-\\uA9B9\\uA9BC\\uA9BD\\uA9E5\\uAA29-\\uAA2E\\uAA31\\uAA32\\uAA35\\uAA36\\uAA43\\uAA4C\\uAA7C\\uAAB0\\uAAB2-\\uAAB4\\uAAB7\\uAAB8\\uAABE\\uAABF\\uAAC1\\uAAEC\\uAAED\\uAAF6\\uABE5\\uABE8\\uABED\\uFB1E\\uFE00-\\uFE0F\\uFE20-\\uFE2F\\u{101FD}\\u{102E0}\\u{10376}-\\u{1037A}\\u{10A01}-\\u{10A03}\\u{10A05}\\u{10A06}\\u{10A0C}-\\u{10A0F}\\u{10A38}-\\u{10A3A}\\u{10A3F}\\u{10AE5}\\u{10AE6}\\u{10D24}-\\u{10D27}\\u{10EAB}\\u{10EAC}\\u{10EFD}-\\u{10EFF}\\u{10F46}-\\u{10F50}\\u{10F82}-\\u{10F85}\\u{11001}\\u{11038}-\\u{11046}\\u{11070}\\u{11073}\\u{11074}\\u{1107F}-\\u{11081}\\u{110B3}-\\u{110B6}\\u{110B9}\\u{110BA}\\u{110C2}\\u{11100}-\\u{11102}\\u{11127}-\\u{1112B}\\u{1112D}-\\u{11134}\\u{11173}\\u{11180}\\u{11181}\\u{111B6}-\\u{111BE}\\u{111C9}-\\u{111CC}\\u{111CF}\\u{1122F}-\\u{11231}\\u{11234}\\u{11236}\\u{11237}\\u{1123E}\\u{11241}\\u{112DF}\\u{112E3}-\\u{112EA}\\u{11300}\\u{11301}\\u{1133B}\\u{1133C}\\u{11340}\\u{11366}-\\u{1136C}\\u{11370}-\\u{11374}\\u{11438}-\\u{1143F}\\u{11442}-\\u{11444}\\u{11446}\\u{1145E}\\u{114B3}-\\u{114B8}\\u{114BA}\\u{114BF}\\u{114C0}\\u{114C2}\\u{114C3}\\u{115B2}-\\u{115B5}\\u{115BC}\\u{115BD}\\u{115BF}\\u{115C0}\\u{115DC}\\u{115DD}\\u{11633}-\\u{1163A}\\u{1163D}\\u{1163F}\\u{11640}\\u{116AB}\\u{116AD}\\u{116B0}-\\u{116B5}\\u{116B7}\\u{1171D}-\\u{1171F}\\u{11722}-\\u{11725}\\u{11727}-\\u{1172B}\\u{1182F}-\\u{11837}\\u{11839}\\u{1183A}\\u{1193B}\\u{1193C}\\u{1193E}\\u{11943}\\u{119D4}-\\u{119D7}\\u{119DA}\\u{119DB}\\u{119E0}\\u{11A01}-\\u{11A06}\\u{11A09}\\u{11A0A}\\u{11A33}-\\u{11A38}\\u{11A3B}-\\u{11A3E}\\u{11A47}\\u{11A51}-\\u{11A56}\\u{11A59}-\\u{11A5B}\\u{11A8A}-\\u{11A96}\\u{11A98}\\u{11A99}\\u{11C30}-\\u{11C36}\\u{11C38}-\\u{11C3D}\\u{11C92}-\\u{11CA7}\\u{11CAA}-\\u{11CB0}\\u{11CB2}\\u{11CB3}\\u{11CB5}\\u{11CB6}\\u{11D31}-\\u{11D36}\\u{11D3A}\\u{11D3C}\\u{11D3D}\\u{11D3F}-\\u{11D45}\\u{11D47}\\u{11D90}\\u{11D91}\\u{11D95}\\u{11D97}\\u{11EF3}\\u{11EF4}\\u{11F00}\\u{11F01}\\u{11F36}-\\u{11F3A}\\u{11F40}\\u{11F42}\\u{13440}\\u{13447}-\\u{13455}\\u{16AF0}-\\u{16AF4}\\u{16B30}-\\u{16B36}\\u{16F4F}\\u{16F8F}-\\u{16F92}\\u{16FE4}\\u{1BC9D}\\u{1BC9E}\\u{1CF00}-\\u{1CF2D}\\u{1CF30}-\\u{1CF46}\\u{1D167}-\\u{1D169}\\u{1D17B}-\\u{1D182}\\u{1D185}-\\u{1D18B}\\u{1D1AA}-\\u{1D1AD}\\u{1D242}-\\u{1D244}\\u{1DA00}-\\u{1DA36}\\u{1DA3B}-\\u{1DA6C}\\u{1DA75}\\u{1DA84}\\u{1DA9B}-\\u{1DA9F}\\u{1DAA1}-\\u{1DAAF}\\u{1E000}-\\u{1E006}\\u{1E008}-\\u{1E018}\\u{1E01B}-\\u{1E021}\\u{1E023}\\u{1E024}\\u{1E026}-\\u{1E02A}\\u{1E08F}\\u{1E130}-\\u{1E136}\\u{1E2AE}\\u{1E2EC}-\\u{1E2EF}\\u{1E4EC}-\\u{1E4EF}\\u{1E8D0}-\\u{1E8D6}\\u{1E944}-\\u{1E94A}\\u{E0100}-\\u{E01EF}]*$/u;\nconst bidiS4EN = /[0-9\\xB2\\xB3\\xB9\\u06F0-\\u06F9\\u2070\\u2074-\\u2079\\u2080-\\u2089\\u2488-\\u249B\\uFF10-\\uFF19\\u{102E1}-\\u{102FB}\\u{1D7CE}-\\u{1D7FF}\\u{1F100}-\\u{1F10A}\\u{1FBF0}-\\u{1FBF9}]/u;\nconst bidiS4AN = /[\\u0600-\\u0605\\u0660-\\u0669\\u066B\\u066C\\u06DD\\u0890\\u0891\\u08E2\\u{10D30}-\\u{10D39}\\u{10E60}-\\u{10E7E}]/u;\nconst bidiS5 = /^[\\0-\\x08\\x0E-\\x1B!-\\x84\\x86-\\u0377\\u037A-\\u037F\\u0384-\\u038A\\u038C\\u038E-\\u03A1\\u03A3-\\u052F\\u0531-\\u0556\\u0559-\\u058A\\u058D-\\u058F\\u0591-\\u05BD\\u05BF\\u05C1\\u05C2\\u05C4\\u05C5\\u05C7\\u0606\\u0607\\u0609\\u060A\\u060C\\u060E-\\u061A\\u064B-\\u065F\\u066A\\u0670\\u06D6-\\u06DC\\u06DE-\\u06E4\\u06E7-\\u06ED\\u06F0-\\u06F9\\u0711\\u0730-\\u074A\\u07A6-\\u07B0\\u07EB-\\u07F3\\u07F6-\\u07F9\\u07FD\\u0816-\\u0819\\u081B-\\u0823\\u0825-\\u0827\\u0829-\\u082D\\u0859-\\u085B\\u0898-\\u089F\\u08CA-\\u08E1\\u08E3-\\u0983\\u0985-\\u098C\\u098F\\u0990\\u0993-\\u09A8\\u09AA-\\u09B0\\u09B2\\u09B6-\\u09B9\\u09BC-\\u09C4\\u09C7\\u09C8\\u09CB-\\u09CE\\u09D7\\u09DC\\u09DD\\u09DF-\\u09E3\\u09E6-\\u09FE\\u0A01-\\u0A03\\u0A05-\\u0A0A\\u0A0F\\u0A10\\u0A13-\\u0A28\\u0A2A-\\u0A30\\u0A32\\u0A33\\u0A35\\u0A36\\u0A38\\u0A39\\u0A3C\\u0A3E-\\u0A42\\u0A47\\u0A48\\u0A4B-\\u0A4D\\u0A51\\u0A59-\\u0A5C\\u0A5E\\u0A66-\\u0A76\\u0A81-\\u0A83\\u0A85-\\u0A8D\\u0A8F-\\u0A91\\u0A93-\\u0AA8\\u0AAA-\\u0AB0\\u0AB2\\u0AB3\\u0AB5-\\u0AB9\\u0ABC-\\u0AC5\\u0AC7-\\u0AC9\\u0ACB-\\u0ACD\\u0AD0\\u0AE0-\\u0AE3\\u0AE6-\\u0AF1\\u0AF9-\\u0AFF\\u0B01-\\u0B03\\u0B05-\\u0B0C\\u0B0F\\u0B10\\u0B13-\\u0B28\\u0B2A-\\u0B30\\u0B32\\u0B33\\u0B35-\\u0B39\\u0B3C-\\u0B44\\u0B47\\u0B48\\u0B4B-\\u0B4D\\u0B55-\\u0B57\\u0B5C\\u0B5D\\u0B5F-\\u0B63\\u0B66-\\u0B77\\u0B82\\u0B83\\u0B85-\\u0B8A\\u0B8E-\\u0B90\\u0B92-\\u0B95\\u0B99\\u0B9A\\u0B9C\\u0B9E\\u0B9F\\u0BA3\\u0BA4\\u0BA8-\\u0BAA\\u0BAE-\\u0BB9\\u0BBE-\\u0BC2\\u0BC6-\\u0BC8\\u0BCA-\\u0BCD\\u0BD0\\u0BD7\\u0BE6-\\u0BFA\\u0C00-\\u0C0C\\u0C0E-\\u0C10\\u0C12-\\u0C28\\u0C2A-\\u0C39\\u0C3C-\\u0C44\\u0C46-\\u0C48\\u0C4A-\\u0C4D\\u0C55\\u0C56\\u0C58-\\u0C5A\\u0C5D\\u0C60-\\u0C63\\u0C66-\\u0C6F\\u0C77-\\u0C8C\\u0C8E-\\u0C90\\u0C92-\\u0CA8\\u0CAA-\\u0CB3\\u0CB5-\\u0CB9\\u0CBC-\\u0CC4\\u0CC6-\\u0CC8\\u0CCA-\\u0CCD\\u0CD5\\u0CD6\\u0CDD\\u0CDE\\u0CE0-\\u0CE3\\u0CE6-\\u0CEF\\u0CF1-\\u0CF3\\u0D00-\\u0D0C\\u0D0E-\\u0D10\\u0D12-\\u0D44\\u0D46-\\u0D48\\u0D4A-\\u0D4F\\u0D54-\\u0D63\\u0D66-\\u0D7F\\u0D81-\\u0D83\\u0D85-\\u0D96\\u0D9A-\\u0DB1\\u0DB3-\\u0DBB\\u0DBD\\u0DC0-\\u0DC6\\u0DCA\\u0DCF-\\u0DD4\\u0DD6\\u0DD8-\\u0DDF\\u0DE6-\\u0DEF\\u0DF2-\\u0DF4\\u0E01-\\u0E3A\\u0E3F-\\u0E5B\\u0E81\\u0E82\\u0E84\\u0E86-\\u0E8A\\u0E8C-\\u0EA3\\u0EA5\\u0EA7-\\u0EBD\\u0EC0-\\u0EC4\\u0EC6\\u0EC8-\\u0ECE\\u0ED0-\\u0ED9\\u0EDC-\\u0EDF\\u0F00-\\u0F47\\u0F49-\\u0F6C\\u0F71-\\u0F97\\u0F99-\\u0FBC\\u0FBE-\\u0FCC\\u0FCE-\\u0FDA\\u1000-\\u10C5\\u10C7\\u10CD\\u10D0-\\u1248\\u124A-\\u124D\\u1250-\\u1256\\u1258\\u125A-\\u125D\\u1260-\\u1288\\u128A-\\u128D\\u1290-\\u12B0\\u12B2-\\u12B5\\u12B8-\\u12BE\\u12C0\\u12C2-\\u12C5\\u12C8-\\u12D6\\u12D8-\\u1310\\u1312-\\u1315\\u1318-\\u135A\\u135D-\\u137C\\u1380-\\u1399\\u13A0-\\u13F5\\u13F8-\\u13FD\\u1400-\\u167F\\u1681-\\u169C\\u16A0-\\u16F8\\u1700-\\u1715\\u171F-\\u1736\\u1740-\\u1753\\u1760-\\u176C\\u176E-\\u1770\\u1772\\u1773\\u1780-\\u17DD\\u17E0-\\u17E9\\u17F0-\\u17F9\\u1800-\\u1819\\u1820-\\u1878\\u1880-\\u18AA\\u18B0-\\u18F5\\u1900-\\u191E\\u1920-\\u192B\\u1930-\\u193B\\u1940\\u1944-\\u196D\\u1970-\\u1974\\u1980-\\u19AB\\u19B0-\\u19C9\\u19D0-\\u19DA\\u19DE-\\u1A1B\\u1A1E-\\u1A5E\\u1A60-\\u1A7C\\u1A7F-\\u1A89\\u1A90-\\u1A99\\u1AA0-\\u1AAD\\u1AB0-\\u1ACE\\u1B00-\\u1B4C\\u1B50-\\u1B7E\\u1B80-\\u1BF3\\u1BFC-\\u1C37\\u1C3B-\\u1C49\\u1C4D-\\u1C88\\u1C90-\\u1CBA\\u1CBD-\\u1CC7\\u1CD0-\\u1CFA\\u1D00-\\u1F15\\u1F18-\\u1F1D\\u1F20-\\u1F45\\u1F48-\\u1F4D\\u1F50-\\u1F57\\u1F59\\u1F5B\\u1F5D\\u1F5F-\\u1F7D\\u1F80-\\u1FB4\\u1FB6-\\u1FC4\\u1FC6-\\u1FD3\\u1FD6-\\u1FDB\\u1FDD-\\u1FEF\\u1FF2-\\u1FF4\\u1FF6-\\u1FFE\\u200B-\\u200E\\u2010-\\u2027\\u202F-\\u205E\\u2060-\\u2064\\u206A-\\u2071\\u2074-\\u208E\\u2090-\\u209C\\u20A0-\\u20C0\\u20D0-\\u20F0\\u2100-\\u218B\\u2190-\\u2426\\u2440-\\u244A\\u2460-\\u2B73\\u2B76-\\u2B95\\u2B97-\\u2CF3\\u2CF9-\\u2D25\\u2D27\\u2D2D\\u2D30-\\u2D67\\u2D6F\\u2D70\\u2D7F-\\u2D96\\u2DA0-\\u2DA6\\u2DA8-\\u2DAE\\u2DB0-\\u2DB6\\u2DB8-\\u2DBE\\u2DC0-\\u2DC6\\u2DC8-\\u2DCE\\u2DD0-\\u2DD6\\u2DD8-\\u2DDE\\u2DE0-\\u2E5D\\u2E80-\\u2E99\\u2E9B-\\u2EF3\\u2F00-\\u2FD5\\u2FF0-\\u2FFB\\u3001-\\u303F\\u3041-\\u3096\\u3099-\\u30FF\\u3105-\\u312F\\u3131-\\u318E\\u3190-\\u31E3\\u31F0-\\u321E\\u3220-\\uA48C\\uA490-\\uA4C6\\uA4D0-\\uA62B\\uA640-\\uA6F7\\uA700-\\uA7CA\\uA7D0\\uA7D1\\uA7D3\\uA7D5-\\uA7D9\\uA7F2-\\uA82C\\uA830-\\uA839\\uA840-\\uA877\\uA880-\\uA8C5\\uA8CE-\\uA8D9\\uA8E0-\\uA953\\uA95F-\\uA97C\\uA980-\\uA9CD\\uA9CF-\\uA9D9\\uA9DE-\\uA9FE\\uAA00-\\uAA36\\uAA40-\\uAA4D\\uAA50-\\uAA59\\uAA5C-\\uAAC2\\uAADB-\\uAAF6\\uAB01-\\uAB06\\uAB09-\\uAB0E\\uAB11-\\uAB16\\uAB20-\\uAB26\\uAB28-\\uAB2E\\uAB30-\\uAB6B\\uAB70-\\uABED\\uABF0-\\uABF9\\uAC00-\\uD7A3\\uD7B0-\\uD7C6\\uD7CB-\\uD7FB\\uD800-\\uFA6D\\uFA70-\\uFAD9\\uFB00-\\uFB06\\uFB13-\\uFB17\\uFB1E\\uFB29\\uFD3E-\\uFD4F\\uFDCF\\uFDFD-\\uFE19\\uFE20-\\uFE52\\uFE54-\\uFE66\\uFE68-\\uFE6B\\uFEFF\\uFF01-\\uFFBE\\uFFC2-\\uFFC7\\uFFCA-\\uFFCF\\uFFD2-\\uFFD7\\uFFDA-\\uFFDC\\uFFE0-\\uFFE6\\uFFE8-\\uFFEE\\uFFF9-\\uFFFD\\u{10000}-\\u{1000B}\\u{1000D}-\\u{10026}\\u{10028}-\\u{1003A}\\u{1003C}\\u{1003D}\\u{1003F}-\\u{1004D}\\u{10050}-\\u{1005D}\\u{10080}-\\u{100FA}\\u{10100}-\\u{10102}\\u{10107}-\\u{10133}\\u{10137}-\\u{1018E}\\u{10190}-\\u{1019C}\\u{101A0}\\u{101D0}-\\u{101FD}\\u{10280}-\\u{1029C}\\u{102A0}-\\u{102D0}\\u{102E0}-\\u{102FB}\\u{10300}-\\u{10323}\\u{1032D}-\\u{1034A}\\u{10350}-\\u{1037A}\\u{10380}-\\u{1039D}\\u{1039F}-\\u{103C3}\\u{103C8}-\\u{103D5}\\u{10400}-\\u{1049D}\\u{104A0}-\\u{104A9}\\u{104B0}-\\u{104D3}\\u{104D8}-\\u{104FB}\\u{10500}-\\u{10527}\\u{10530}-\\u{10563}\\u{1056F}-\\u{1057A}\\u{1057C}-\\u{1058A}\\u{1058C}-\\u{10592}\\u{10594}\\u{10595}\\u{10597}-\\u{105A1}\\u{105A3}-\\u{105B1}\\u{105B3}-\\u{105B9}\\u{105BB}\\u{105BC}\\u{10600}-\\u{10736}\\u{10740}-\\u{10755}\\u{10760}-\\u{10767}\\u{10780}-\\u{10785}\\u{10787}-\\u{107B0}\\u{107B2}-\\u{107BA}\\u{1091F}\\u{10A01}-\\u{10A03}\\u{10A05}\\u{10A06}\\u{10A0C}-\\u{10A0F}\\u{10A38}-\\u{10A3A}\\u{10A3F}\\u{10AE5}\\u{10AE6}\\u{10B39}-\\u{10B3F}\\u{10D24}-\\u{10D27}\\u{10EAB}\\u{10EAC}\\u{10EFD}-\\u{10EFF}\\u{10F46}-\\u{10F50}\\u{10F82}-\\u{10F85}\\u{11000}-\\u{1104D}\\u{11052}-\\u{11075}\\u{1107F}-\\u{110C2}\\u{110CD}\\u{110D0}-\\u{110E8}\\u{110F0}-\\u{110F9}\\u{11100}-\\u{11134}\\u{11136}-\\u{11147}\\u{11150}-\\u{11176}\\u{11180}-\\u{111DF}\\u{111E1}-\\u{111F4}\\u{11200}-\\u{11211}\\u{11213}-\\u{11241}\\u{11280}-\\u{11286}\\u{11288}\\u{1128A}-\\u{1128D}\\u{1128F}-\\u{1129D}\\u{1129F}-\\u{112A9}\\u{112B0}-\\u{112EA}\\u{112F0}-\\u{112F9}\\u{11300}-\\u{11303}\\u{11305}-\\u{1130C}\\u{1130F}\\u{11310}\\u{11313}-\\u{11328}\\u{1132A}-\\u{11330}\\u{11332}\\u{11333}\\u{11335}-\\u{11339}\\u{1133B}-\\u{11344}\\u{11347}\\u{11348}\\u{1134B}-\\u{1134D}\\u{11350}\\u{11357}\\u{1135D}-\\u{11363}\\u{11366}-\\u{1136C}\\u{11370}-\\u{11374}\\u{11400}-\\u{1145B}\\u{1145D}-\\u{11461}\\u{11480}-\\u{114C7}\\u{114D0}-\\u{114D9}\\u{11580}-\\u{115B5}\\u{115B8}-\\u{115DD}\\u{11600}-\\u{11644}\\u{11650}-\\u{11659}\\u{11660}-\\u{1166C}\\u{11680}-\\u{116B9}\\u{116C0}-\\u{116C9}\\u{11700}-\\u{1171A}\\u{1171D}-\\u{1172B}\\u{11730}-\\u{11746}\\u{11800}-\\u{1183B}\\u{118A0}-\\u{118F2}\\u{118FF}-\\u{11906}\\u{11909}\\u{1190C}-\\u{11913}\\u{11915}\\u{11916}\\u{11918}-\\u{11935}\\u{11937}\\u{11938}\\u{1193B}-\\u{11946}\\u{11950}-\\u{11959}\\u{119A0}-\\u{119A7}\\u{119AA}-\\u{119D7}\\u{119DA}-\\u{119E4}\\u{11A00}-\\u{11A47}\\u{11A50}-\\u{11AA2}\\u{11AB0}-\\u{11AF8}\\u{11B00}-\\u{11B09}\\u{11C00}-\\u{11C08}\\u{11C0A}-\\u{11C36}\\u{11C38}-\\u{11C45}\\u{11C50}-\\u{11C6C}\\u{11C70}-\\u{11C8F}\\u{11C92}-\\u{11CA7}\\u{11CA9}-\\u{11CB6}\\u{11D00}-\\u{11D06}\\u{11D08}\\u{11D09}\\u{11D0B}-\\u{11D36}\\u{11D3A}\\u{11D3C}\\u{11D3D}\\u{11D3F}-\\u{11D47}\\u{11D50}-\\u{11D59}\\u{11D60}-\\u{11D65}\\u{11D67}\\u{11D68}\\u{11D6A}-\\u{11D8E}\\u{11D90}\\u{11D91}\\u{11D93}-\\u{11D98}\\u{11DA0}-\\u{11DA9}\\u{11EE0}-\\u{11EF8}\\u{11F00}-\\u{11F10}\\u{11F12}-\\u{11F3A}\\u{11F3E}-\\u{11F59}\\u{11FB0}\\u{11FC0}-\\u{11FF1}\\u{11FFF}-\\u{12399}\\u{12400}-\\u{1246E}\\u{12470}-\\u{12474}\\u{12480}-\\u{12543}\\u{12F90}-\\u{12FF2}\\u{13000}-\\u{13455}\\u{14400}-\\u{14646}\\u{16800}-\\u{16A38}\\u{16A40}-\\u{16A5E}\\u{16A60}-\\u{16A69}\\u{16A6E}-\\u{16ABE}\\u{16AC0}-\\u{16AC9}\\u{16AD0}-\\u{16AED}\\u{16AF0}-\\u{16AF5}\\u{16B00}-\\u{16B45}\\u{16B50}-\\u{16B59}\\u{16B5B}-\\u{16B61}\\u{16B63}-\\u{16B77}\\u{16B7D}-\\u{16B8F}\\u{16E40}-\\u{16E9A}\\u{16F00}-\\u{16F4A}\\u{16F4F}-\\u{16F87}\\u{16F8F}-\\u{16F9F}\\u{16FE0}-\\u{16FE4}\\u{16FF0}\\u{16FF1}\\u{17000}-\\u{187F7}\\u{18800}-\\u{18CD5}\\u{18D00}-\\u{18D08}\\u{1AFF0}-\\u{1AFF3}\\u{1AFF5}-\\u{1AFFB}\\u{1AFFD}\\u{1AFFE}\\u{1B000}-\\u{1B122}\\u{1B132}\\u{1B150}-\\u{1B152}\\u{1B155}\\u{1B164}-\\u{1B167}\\u{1B170}-\\u{1B2FB}\\u{1BC00}-\\u{1BC6A}\\u{1BC70}-\\u{1BC7C}\\u{1BC80}-\\u{1BC88}\\u{1BC90}-\\u{1BC99}\\u{1BC9C}-\\u{1BCA3}\\u{1CF00}-\\u{1CF2D}\\u{1CF30}-\\u{1CF46}\\u{1CF50}-\\u{1CFC3}\\u{1D000}-\\u{1D0F5}\\u{1D100}-\\u{1D126}\\u{1D129}-\\u{1D1EA}\\u{1D200}-\\u{1D245}\\u{1D2C0}-\\u{1D2D3}\\u{1D2E0}-\\u{1D2F3}\\u{1D300}-\\u{1D356}\\u{1D360}-\\u{1D378}\\u{1D400}-\\u{1D454}\\u{1D456}-\\u{1D49C}\\u{1D49E}\\u{1D49F}\\u{1D4A2}\\u{1D4A5}\\u{1D4A6}\\u{1D4A9}-\\u{1D4AC}\\u{1D4AE}-\\u{1D4B9}\\u{1D4BB}\\u{1D4BD}-\\u{1D4C3}\\u{1D4C5}-\\u{1D505}\\u{1D507}-\\u{1D50A}\\u{1D50D}-\\u{1D514}\\u{1D516}-\\u{1D51C}\\u{1D51E}-\\u{1D539}\\u{1D53B}-\\u{1D53E}\\u{1D540}-\\u{1D544}\\u{1D546}\\u{1D54A}-\\u{1D550}\\u{1D552}-\\u{1D6A5}\\u{1D6A8}-\\u{1D7CB}\\u{1D7CE}-\\u{1DA8B}\\u{1DA9B}-\\u{1DA9F}\\u{1DAA1}-\\u{1DAAF}\\u{1DF00}-\\u{1DF1E}\\u{1DF25}-\\u{1DF2A}\\u{1E000}-\\u{1E006}\\u{1E008}-\\u{1E018}\\u{1E01B}-\\u{1E021}\\u{1E023}\\u{1E024}\\u{1E026}-\\u{1E02A}\\u{1E030}-\\u{1E06D}\\u{1E08F}\\u{1E100}-\\u{1E12C}\\u{1E130}-\\u{1E13D}\\u{1E140}-\\u{1E149}\\u{1E14E}\\u{1E14F}\\u{1E290}-\\u{1E2AE}\\u{1E2C0}-\\u{1E2F9}\\u{1E2FF}\\u{1E4D0}-\\u{1E4F9}\\u{1E7E0}-\\u{1E7E6}\\u{1E7E8}-\\u{1E7EB}\\u{1E7ED}\\u{1E7EE}\\u{1E7F0}-\\u{1E7FE}\\u{1E8D0}-\\u{1E8D6}\\u{1E944}-\\u{1E94A}\\u{1EEF0}\\u{1EEF1}\\u{1F000}-\\u{1F02B}\\u{1F030}-\\u{1F093}\\u{1F0A0}-\\u{1F0AE}\\u{1F0B1}-\\u{1F0BF}\\u{1F0C1}-\\u{1F0CF}\\u{1F0D1}-\\u{1F0F5}\\u{1F100}-\\u{1F1AD}\\u{1F1E6}-\\u{1F202}\\u{1F210}-\\u{1F23B}\\u{1F240}-\\u{1F248}\\u{1F250}\\u{1F251}\\u{1F260}-\\u{1F265}\\u{1F300}-\\u{1F6D7}\\u{1F6DC}-\\u{1F6EC}\\u{1F6F0}-\\u{1F6FC}\\u{1F700}-\\u{1F776}\\u{1F77B}-\\u{1F7D9}\\u{1F7E0}-\\u{1F7EB}\\u{1F7F0}\\u{1F800}-\\u{1F80B}\\u{1F810}-\\u{1F847}\\u{1F850}-\\u{1F859}\\u{1F860}-\\u{1F887}\\u{1F890}-\\u{1F8AD}\\u{1F8B0}\\u{1F8B1}\\u{1F900}-\\u{1FA53}\\u{1FA60}-\\u{1FA6D}\\u{1FA70}-\\u{1FA7C}\\u{1FA80}-\\u{1FA88}\\u{1FA90}-\\u{1FABD}\\u{1FABF}-\\u{1FAC5}\\u{1FACE}-\\u{1FADB}\\u{1FAE0}-\\u{1FAE8}\\u{1FAF0}-\\u{1FAF8}\\u{1FB00}-\\u{1FB92}\\u{1FB94}-\\u{1FBCA}\\u{1FBF0}-\\u{1FBF9}\\u{20000}-\\u{2A6DF}\\u{2A700}-\\u{2B739}\\u{2B740}-\\u{2B81D}\\u{2B820}-\\u{2CEA1}\\u{2CEB0}-\\u{2EBE0}\\u{2F800}-\\u{2FA1D}\\u{30000}-\\u{3134A}\\u{31350}-\\u{323AF}\\u{E0001}\\u{E0020}-\\u{E007F}\\u{E0100}-\\u{E01EF}\\u{F0000}-\\u{FFFFD}\\u{100000}-\\u{10FFFD}]*$/u;\nconst bidiS6 = /[0-9A-Za-z\\xAA\\xB2\\xB3\\xB5\\xB9\\xBA\\xC0-\\xD6\\xD8-\\xF6\\xF8-\\u02B8\\u02BB-\\u02C1\\u02D0\\u02D1\\u02E0-\\u02E4\\u02EE\\u0370-\\u0373\\u0376\\u0377\\u037A-\\u037D\\u037F\\u0386\\u0388-\\u038A\\u038C\\u038E-\\u03A1\\u03A3-\\u03F5\\u03F7-\\u0482\\u048A-\\u052F\\u0531-\\u0556\\u0559-\\u0589\\u06F0-\\u06F9\\u0903-\\u0939\\u093B\\u093D-\\u0940\\u0949-\\u094C\\u094E-\\u0950\\u0958-\\u0961\\u0964-\\u0980\\u0982\\u0983\\u0985-\\u098C\\u098F\\u0990\\u0993-\\u09A8\\u09AA-\\u09B0\\u09B2\\u09B6-\\u09B9\\u09BD-\\u09C0\\u09C7\\u09C8\\u09CB\\u09CC\\u09CE\\u09D7\\u09DC\\u09DD\\u09DF-\\u09E1\\u09E6-\\u09F1\\u09F4-\\u09FA\\u09FC\\u09FD\\u0A03\\u0A05-\\u0A0A\\u0A0F\\u0A10\\u0A13-\\u0A28\\u0A2A-\\u0A30\\u0A32\\u0A33\\u0A35\\u0A36\\u0A38\\u0A39\\u0A3E-\\u0A40\\u0A59-\\u0A5C\\u0A5E\\u0A66-\\u0A6F\\u0A72-\\u0A74\\u0A76\\u0A83\\u0A85-\\u0A8D\\u0A8F-\\u0A91\\u0A93-\\u0AA8\\u0AAA-\\u0AB0\\u0AB2\\u0AB3\\u0AB5-\\u0AB9\\u0ABD-\\u0AC0\\u0AC9\\u0ACB\\u0ACC\\u0AD0\\u0AE0\\u0AE1\\u0AE6-\\u0AF0\\u0AF9\\u0B02\\u0B03\\u0B05-\\u0B0C\\u0B0F\\u0B10\\u0B13-\\u0B28\\u0B2A-\\u0B30\\u0B32\\u0B33\\u0B35-\\u0B39\\u0B3D\\u0B3E\\u0B40\\u0B47\\u0B48\\u0B4B\\u0B4C\\u0B57\\u0B5C\\u0B5D\\u0B5F-\\u0B61\\u0B66-\\u0B77\\u0B83\\u0B85-\\u0B8A\\u0B8E-\\u0B90\\u0B92-\\u0B95\\u0B99\\u0B9A\\u0B9C\\u0B9E\\u0B9F\\u0BA3\\u0BA4\\u0BA8-\\u0BAA\\u0BAE-\\u0BB9\\u0BBE\\u0BBF\\u0BC1\\u0BC2\\u0BC6-\\u0BC8\\u0BCA-\\u0BCC\\u0BD0\\u0BD7\\u0BE6-\\u0BF2\\u0C01-\\u0C03\\u0C05-\\u0C0C\\u0C0E-\\u0C10\\u0C12-\\u0C28\\u0C2A-\\u0C39\\u0C3D\\u0C41-\\u0C44\\u0C58-\\u0C5A\\u0C5D\\u0C60\\u0C61\\u0C66-\\u0C6F\\u0C77\\u0C7F\\u0C80\\u0C82-\\u0C8C\\u0C8E-\\u0C90\\u0C92-\\u0CA8\\u0CAA-\\u0CB3\\u0CB5-\\u0CB9\\u0CBD-\\u0CC4\\u0CC6-\\u0CC8\\u0CCA\\u0CCB\\u0CD5\\u0CD6\\u0CDD\\u0CDE\\u0CE0\\u0CE1\\u0CE6-\\u0CEF\\u0CF1-\\u0CF3\\u0D02-\\u0D0C\\u0D0E-\\u0D10\\u0D12-\\u0D3A\\u0D3D-\\u0D40\\u0D46-\\u0D48\\u0D4A-\\u0D4C\\u0D4E\\u0D4F\\u0D54-\\u0D61\\u0D66-\\u0D7F\\u0D82\\u0D83\\u0D85-\\u0D96\\u0D9A-\\u0DB1\\u0DB3-\\u0DBB\\u0DBD\\u0DC0-\\u0DC6\\u0DCF-\\u0DD1\\u0DD8-\\u0DDF\\u0DE6-\\u0DEF\\u0DF2-\\u0DF4\\u0E01-\\u0E30\\u0E32\\u0E33\\u0E40-\\u0E46\\u0E4F-\\u0E5B\\u0E81\\u0E82\\u0E84\\u0E86-\\u0E8A\\u0E8C-\\u0EA3\\u0EA5\\u0EA7-\\u0EB0\\u0EB2\\u0EB3\\u0EBD\\u0EC0-\\u0EC4\\u0EC6\\u0ED0-\\u0ED9\\u0EDC-\\u0EDF\\u0F00-\\u0F17\\u0F1A-\\u0F34\\u0F36\\u0F38\\u0F3E-\\u0F47\\u0F49-\\u0F6C\\u0F7F\\u0F85\\u0F88-\\u0F8C\\u0FBE-\\u0FC5\\u0FC7-\\u0FCC\\u0FCE-\\u0FDA\\u1000-\\u102C\\u1031\\u1038\\u103B\\u103C\\u103F-\\u1057\\u105A-\\u105D\\u1061-\\u1070\\u1075-\\u1081\\u1083\\u1084\\u1087-\\u108C\\u108E-\\u109C\\u109E-\\u10C5\\u10C7\\u10CD\\u10D0-\\u1248\\u124A-\\u124D\\u1250-\\u1256\\u1258\\u125A-\\u125D\\u1260-\\u1288\\u128A-\\u128D\\u1290-\\u12B0\\u12B2-\\u12B5\\u12B8-\\u12BE\\u12C0\\u12C2-\\u12C5\\u12C8-\\u12D6\\u12D8-\\u1310\\u1312-\\u1315\\u1318-\\u135A\\u1360-\\u137C\\u1380-\\u138F\\u13A0-\\u13F5\\u13F8-\\u13FD\\u1401-\\u167F\\u1681-\\u169A\\u16A0-\\u16F8\\u1700-\\u1711\\u1715\\u171F-\\u1731\\u1734-\\u1736\\u1740-\\u1751\\u1760-\\u176C\\u176E-\\u1770\\u1780-\\u17B3\\u17B6\\u17BE-\\u17C5\\u17C7\\u17C8\\u17D4-\\u17DA\\u17DC\\u17E0-\\u17E9\\u1810-\\u1819\\u1820-\\u1878\\u1880-\\u1884\\u1887-\\u18A8\\u18AA\\u18B0-\\u18F5\\u1900-\\u191E\\u1923-\\u1926\\u1929-\\u192B\\u1930\\u1931\\u1933-\\u1938\\u1946-\\u196D\\u1970-\\u1974\\u1980-\\u19AB\\u19B0-\\u19C9\\u19D0-\\u19DA\\u1A00-\\u1A16\\u1A19\\u1A1A\\u1A1E-\\u1A55\\u1A57\\u1A61\\u1A63\\u1A64\\u1A6D-\\u1A72\\u1A80-\\u1A89\\u1A90-\\u1A99\\u1AA0-\\u1AAD\\u1B04-\\u1B33\\u1B35\\u1B3B\\u1B3D-\\u1B41\\u1B43-\\u1B4C\\u1B50-\\u1B6A\\u1B74-\\u1B7E\\u1B82-\\u1BA1\\u1BA6\\u1BA7\\u1BAA\\u1BAE-\\u1BE5\\u1BE7\\u1BEA-\\u1BEC\\u1BEE\\u1BF2\\u1BF3\\u1BFC-\\u1C2B\\u1C34\\u1C35\\u1C3B-\\u1C49\\u1C4D-\\u1C88\\u1C90-\\u1CBA\\u1CBD-\\u1CC7\\u1CD3\\u1CE1\\u1CE9-\\u1CEC\\u1CEE-\\u1CF3\\u1CF5-\\u1CF7\\u1CFA\\u1D00-\\u1DBF\\u1E00-\\u1F15\\u1F18-\\u1F1D\\u1F20-\\u1F45\\u1F48-\\u1F4D\\u1F50-\\u1F57\\u1F59\\u1F5B\\u1F5D\\u1F5F-\\u1F7D\\u1F80-\\u1FB4\\u1FB6-\\u1FBC\\u1FBE\\u1FC2-\\u1FC4\\u1FC6-\\u1FCC\\u1FD0-\\u1FD3\\u1FD6-\\u1FDB\\u1FE0-\\u1FEC\\u1FF2-\\u1FF4\\u1FF6-\\u1FFC\\u200E\\u2070\\u2071\\u2074-\\u2079\\u207F-\\u2089\\u2090-\\u209C\\u2102\\u2107\\u210A-\\u2113\\u2115\\u2119-\\u211D\\u2124\\u2126\\u2128\\u212A-\\u212D\\u212F-\\u2139\\u213C-\\u213F\\u2145-\\u2149\\u214E\\u214F\\u2160-\\u2188\\u2336-\\u237A\\u2395\\u2488-\\u24E9\\u26AC\\u2800-\\u28FF\\u2C00-\\u2CE4\\u2CEB-\\u2CEE\\u2CF2\\u2CF3\\u2D00-\\u2D25\\u2D27\\u2D2D\\u2D30-\\u2D67\\u2D6F\\u2D70\\u2D80-\\u2D96\\u2DA0-\\u2DA6\\u2DA8-\\u2DAE\\u2DB0-\\u2DB6\\u2DB8-\\u2DBE\\u2DC0-\\u2DC6\\u2DC8-\\u2DCE\\u2DD0-\\u2DD6\\u2DD8-\\u2DDE\\u3005-\\u3007\\u3021-\\u3029\\u302E\\u302F\\u3031-\\u3035\\u3038-\\u303C\\u3041-\\u3096\\u309D-\\u309F\\u30A1-\\u30FA\\u30FC-\\u30FF\\u3105-\\u312F\\u3131-\\u318E\\u3190-\\u31BF\\u31F0-\\u321C\\u3220-\\u324F\\u3260-\\u327B\\u327F-\\u32B0\\u32C0-\\u32CB\\u32D0-\\u3376\\u337B-\\u33DD\\u33E0-\\u33FE\\u3400-\\u4DBF\\u4E00-\\uA48C\\uA4D0-\\uA60C\\uA610-\\uA62B\\uA640-\\uA66E\\uA680-\\uA69D\\uA6A0-\\uA6EF\\uA6F2-\\uA6F7\\uA722-\\uA787\\uA789-\\uA7CA\\uA7D0\\uA7D1\\uA7D3\\uA7D5-\\uA7D9\\uA7F2-\\uA801\\uA803-\\uA805\\uA807-\\uA80A\\uA80C-\\uA824\\uA827\\uA830-\\uA837\\uA840-\\uA873\\uA880-\\uA8C3\\uA8CE-\\uA8D9\\uA8F2-\\uA8FE\\uA900-\\uA925\\uA92E-\\uA946\\uA952\\uA953\\uA95F-\\uA97C\\uA983-\\uA9B2\\uA9B4\\uA9B5\\uA9BA\\uA9BB\\uA9BE-\\uA9CD\\uA9CF-\\uA9D9\\uA9DE-\\uA9E4\\uA9E6-\\uA9FE\\uAA00-\\uAA28\\uAA2F\\uAA30\\uAA33\\uAA34\\uAA40-\\uAA42\\uAA44-\\uAA4B\\uAA4D\\uAA50-\\uAA59\\uAA5C-\\uAA7B\\uAA7D-\\uAAAF\\uAAB1\\uAAB5\\uAAB6\\uAAB9-\\uAABD\\uAAC0\\uAAC2\\uAADB-\\uAAEB\\uAAEE-\\uAAF5\\uAB01-\\uAB06\\uAB09-\\uAB0E\\uAB11-\\uAB16\\uAB20-\\uAB26\\uAB28-\\uAB2E\\uAB30-\\uAB69\\uAB70-\\uABE4\\uABE6\\uABE7\\uABE9-\\uABEC\\uABF0-\\uABF9\\uAC00-\\uD7A3\\uD7B0-\\uD7C6\\uD7CB-\\uD7FB\\uD800-\\uFA6D\\uFA70-\\uFAD9\\uFB00-\\uFB06\\uFB13-\\uFB17\\uFF10-\\uFF19\\uFF21-\\uFF3A\\uFF41-\\uFF5A\\uFF66-\\uFFBE\\uFFC2-\\uFFC7\\uFFCA-\\uFFCF\\uFFD2-\\uFFD7\\uFFDA-\\uFFDC\\u{10000}-\\u{1000B}\\u{1000D}-\\u{10026}\\u{10028}-\\u{1003A}\\u{1003C}\\u{1003D}\\u{1003F}-\\u{1004D}\\u{10050}-\\u{1005D}\\u{10080}-\\u{100FA}\\u{10100}\\u{10102}\\u{10107}-\\u{10133}\\u{10137}-\\u{1013F}\\u{1018D}\\u{1018E}\\u{101D0}-\\u{101FC}\\u{10280}-\\u{1029C}\\u{102A0}-\\u{102D0}\\u{102E1}-\\u{102FB}\\u{10300}-\\u{10323}\\u{1032D}-\\u{1034A}\\u{10350}-\\u{10375}\\u{10380}-\\u{1039D}\\u{1039F}-\\u{103C3}\\u{103C8}-\\u{103D5}\\u{10400}-\\u{1049D}\\u{104A0}-\\u{104A9}\\u{104B0}-\\u{104D3}\\u{104D8}-\\u{104FB}\\u{10500}-\\u{10527}\\u{10530}-\\u{10563}\\u{1056F}-\\u{1057A}\\u{1057C}-\\u{1058A}\\u{1058C}-\\u{10592}\\u{10594}\\u{10595}\\u{10597}-\\u{105A1}\\u{105A3}-\\u{105B1}\\u{105B3}-\\u{105B9}\\u{105BB}\\u{105BC}\\u{10600}-\\u{10736}\\u{10740}-\\u{10755}\\u{10760}-\\u{10767}\\u{10780}-\\u{10785}\\u{10787}-\\u{107B0}\\u{107B2}-\\u{107BA}\\u{11000}\\u{11002}-\\u{11037}\\u{11047}-\\u{1104D}\\u{11066}-\\u{1106F}\\u{11071}\\u{11072}\\u{11075}\\u{11082}-\\u{110B2}\\u{110B7}\\u{110B8}\\u{110BB}-\\u{110C1}\\u{110CD}\\u{110D0}-\\u{110E8}\\u{110F0}-\\u{110F9}\\u{11103}-\\u{11126}\\u{1112C}\\u{11136}-\\u{11147}\\u{11150}-\\u{11172}\\u{11174}-\\u{11176}\\u{11182}-\\u{111B5}\\u{111BF}-\\u{111C8}\\u{111CD}\\u{111CE}\\u{111D0}-\\u{111DF}\\u{111E1}-\\u{111F4}\\u{11200}-\\u{11211}\\u{11213}-\\u{1122E}\\u{11232}\\u{11233}\\u{11235}\\u{11238}-\\u{1123D}\\u{1123F}\\u{11240}\\u{11280}-\\u{11286}\\u{11288}\\u{1128A}-\\u{1128D}\\u{1128F}-\\u{1129D}\\u{1129F}-\\u{112A9}\\u{112B0}-\\u{112DE}\\u{112E0}-\\u{112E2}\\u{112F0}-\\u{112F9}\\u{11302}\\u{11303}\\u{11305}-\\u{1130C}\\u{1130F}\\u{11310}\\u{11313}-\\u{11328}\\u{1132A}-\\u{11330}\\u{11332}\\u{11333}\\u{11335}-\\u{11339}\\u{1133D}-\\u{1133F}\\u{11341}-\\u{11344}\\u{11347}\\u{11348}\\u{1134B}-\\u{1134D}\\u{11350}\\u{11357}\\u{1135D}-\\u{11363}\\u{11400}-\\u{11437}\\u{11440}\\u{11441}\\u{11445}\\u{11447}-\\u{1145B}\\u{1145D}\\u{1145F}-\\u{11461}\\u{11480}-\\u{114B2}\\u{114B9}\\u{114BB}-\\u{114BE}\\u{114C1}\\u{114C4}-\\u{114C7}\\u{114D0}-\\u{114D9}\\u{11580}-\\u{115B1}\\u{115B8}-\\u{115BB}\\u{115BE}\\u{115C1}-\\u{115DB}\\u{11600}-\\u{11632}\\u{1163B}\\u{1163C}\\u{1163E}\\u{11641}-\\u{11644}\\u{11650}-\\u{11659}\\u{11680}-\\u{116AA}\\u{116AC}\\u{116AE}\\u{116AF}\\u{116B6}\\u{116B8}\\u{116B9}\\u{116C0}-\\u{116C9}\\u{11700}-\\u{1171A}\\u{11720}\\u{11721}\\u{11726}\\u{11730}-\\u{11746}\\u{11800}-\\u{1182E}\\u{11838}\\u{1183B}\\u{118A0}-\\u{118F2}\\u{118FF}-\\u{11906}\\u{11909}\\u{1190C}-\\u{11913}\\u{11915}\\u{11916}\\u{11918}-\\u{11935}\\u{11937}\\u{11938}\\u{1193D}\\u{1193F}-\\u{11942}\\u{11944}-\\u{11946}\\u{11950}-\\u{11959}\\u{119A0}-\\u{119A7}\\u{119AA}-\\u{119D3}\\u{119DC}-\\u{119DF}\\u{119E1}-\\u{119E4}\\u{11A00}\\u{11A07}\\u{11A08}\\u{11A0B}-\\u{11A32}\\u{11A39}\\u{11A3A}\\u{11A3F}-\\u{11A46}\\u{11A50}\\u{11A57}\\u{11A58}\\u{11A5C}-\\u{11A89}\\u{11A97}\\u{11A9A}-\\u{11AA2}\\u{11AB0}-\\u{11AF8}\\u{11B00}-\\u{11B09}\\u{11C00}-\\u{11C08}\\u{11C0A}-\\u{11C2F}\\u{11C3E}-\\u{11C45}\\u{11C50}-\\u{11C6C}\\u{11C70}-\\u{11C8F}\\u{11CA9}\\u{11CB1}\\u{11CB4}\\u{11D00}-\\u{11D06}\\u{11D08}\\u{11D09}\\u{11D0B}-\\u{11D30}\\u{11D46}\\u{11D50}-\\u{11D59}\\u{11D60}-\\u{11D65}\\u{11D67}\\u{11D68}\\u{11D6A}-\\u{11D8E}\\u{11D93}\\u{11D94}\\u{11D96}\\u{11D98}\\u{11DA0}-\\u{11DA9}\\u{11EE0}-\\u{11EF2}\\u{11EF5}-\\u{11EF8}\\u{11F02}-\\u{11F10}\\u{11F12}-\\u{11F35}\\u{11F3E}\\u{11F3F}\\u{11F41}\\u{11F43}-\\u{11F59}\\u{11FB0}\\u{11FC0}-\\u{11FD4}\\u{11FFF}-\\u{12399}\\u{12400}-\\u{1246E}\\u{12470}-\\u{12474}\\u{12480}-\\u{12543}\\u{12F90}-\\u{12FF2}\\u{13000}-\\u{1343F}\\u{13441}-\\u{13446}\\u{14400}-\\u{14646}\\u{16800}-\\u{16A38}\\u{16A40}-\\u{16A5E}\\u{16A60}-\\u{16A69}\\u{16A6E}-\\u{16ABE}\\u{16AC0}-\\u{16AC9}\\u{16AD0}-\\u{16AED}\\u{16AF5}\\u{16B00}-\\u{16B2F}\\u{16B37}-\\u{16B45}\\u{16B50}-\\u{16B59}\\u{16B5B}-\\u{16B61}\\u{16B63}-\\u{16B77}\\u{16B7D}-\\u{16B8F}\\u{16E40}-\\u{16E9A}\\u{16F00}-\\u{16F4A}\\u{16F50}-\\u{16F87}\\u{16F93}-\\u{16F9F}\\u{16FE0}\\u{16FE1}\\u{16FE3}\\u{16FF0}\\u{16FF1}\\u{17000}-\\u{187F7}\\u{18800}-\\u{18CD5}\\u{18D00}-\\u{18D08}\\u{1AFF0}-\\u{1AFF3}\\u{1AFF5}-\\u{1AFFB}\\u{1AFFD}\\u{1AFFE}\\u{1B000}-\\u{1B122}\\u{1B132}\\u{1B150}-\\u{1B152}\\u{1B155}\\u{1B164}-\\u{1B167}\\u{1B170}-\\u{1B2FB}\\u{1BC00}-\\u{1BC6A}\\u{1BC70}-\\u{1BC7C}\\u{1BC80}-\\u{1BC88}\\u{1BC90}-\\u{1BC99}\\u{1BC9C}\\u{1BC9F}\\u{1CF50}-\\u{1CFC3}\\u{1D000}-\\u{1D0F5}\\u{1D100}-\\u{1D126}\\u{1D129}-\\u{1D166}\\u{1D16A}-\\u{1D172}\\u{1D183}\\u{1D184}\\u{1D18C}-\\u{1D1A9}\\u{1D1AE}-\\u{1D1E8}\\u{1D2C0}-\\u{1D2D3}\\u{1D2E0}-\\u{1D2F3}\\u{1D360}-\\u{1D378}\\u{1D400}-\\u{1D454}\\u{1D456}-\\u{1D49C}\\u{1D49E}\\u{1D49F}\\u{1D4A2}\\u{1D4A5}\\u{1D4A6}\\u{1D4A9}-\\u{1D4AC}\\u{1D4AE}-\\u{1D4B9}\\u{1D4BB}\\u{1D4BD}-\\u{1D4C3}\\u{1D4C5}-\\u{1D505}\\u{1D507}-\\u{1D50A}\\u{1D50D}-\\u{1D514}\\u{1D516}-\\u{1D51C}\\u{1D51E}-\\u{1D539}\\u{1D53B}-\\u{1D53E}\\u{1D540}-\\u{1D544}\\u{1D546}\\u{1D54A}-\\u{1D550}\\u{1D552}-\\u{1D6A5}\\u{1D6A8}-\\u{1D6DA}\\u{1D6DC}-\\u{1D714}\\u{1D716}-\\u{1D74E}\\u{1D750}-\\u{1D788}\\u{1D78A}-\\u{1D7C2}\\u{1D7C4}-\\u{1D7CB}\\u{1D7CE}-\\u{1D9FF}\\u{1DA37}-\\u{1DA3A}\\u{1DA6D}-\\u{1DA74}\\u{1DA76}-\\u{1DA83}\\u{1DA85}-\\u{1DA8B}\\u{1DF00}-\\u{1DF1E}\\u{1DF25}-\\u{1DF2A}\\u{1E030}-\\u{1E06D}\\u{1E100}-\\u{1E12C}\\u{1E137}-\\u{1E13D}\\u{1E140}-\\u{1E149}\\u{1E14E}\\u{1E14F}\\u{1E290}-\\u{1E2AD}\\u{1E2C0}-\\u{1E2EB}\\u{1E2F0}-\\u{1E2F9}\\u{1E4D0}-\\u{1E4EB}\\u{1E4F0}-\\u{1E4F9}\\u{1E7E0}-\\u{1E7E6}\\u{1E7E8}-\\u{1E7EB}\\u{1E7ED}\\u{1E7EE}\\u{1E7F0}-\\u{1E7FE}\\u{1F100}-\\u{1F10A}\\u{1F110}-\\u{1F12E}\\u{1F130}-\\u{1F169}\\u{1F170}-\\u{1F1AC}\\u{1F1E6}-\\u{1F202}\\u{1F210}-\\u{1F23B}\\u{1F240}-\\u{1F248}\\u{1F250}\\u{1F251}\\u{1FBF0}-\\u{1FBF9}\\u{20000}-\\u{2A6DF}\\u{2A700}-\\u{2B739}\\u{2B740}-\\u{2B81D}\\u{2B820}-\\u{2CEA1}\\u{2CEB0}-\\u{2EBE0}\\u{2F800}-\\u{2FA1D}\\u{30000}-\\u{3134A}\\u{31350}-\\u{323AF}\\u{F0000}-\\u{FFFFD}\\u{100000}-\\u{10FFFD}][\\u0300-\\u036F\\u0483-\\u0489\\u0591-\\u05BD\\u05BF\\u05C1\\u05C2\\u05C4\\u05C5\\u05C7\\u0610-\\u061A\\u064B-\\u065F\\u0670\\u06D6-\\u06DC\\u06DF-\\u06E4\\u06E7\\u06E8\\u06EA-\\u06ED\\u0711\\u0730-\\u074A\\u07A6-\\u07B0\\u07EB-\\u07F3\\u07FD\\u0816-\\u0819\\u081B-\\u0823\\u0825-\\u0827\\u0829-\\u082D\\u0859-\\u085B\\u0898-\\u089F\\u08CA-\\u08E1\\u08E3-\\u0902\\u093A\\u093C\\u0941-\\u0948\\u094D\\u0951-\\u0957\\u0962\\u0963\\u0981\\u09BC\\u09C1-\\u09C4\\u09CD\\u09E2\\u09E3\\u09FE\\u0A01\\u0A02\\u0A3C\\u0A41\\u0A42\\u0A47\\u0A48\\u0A4B-\\u0A4D\\u0A51\\u0A70\\u0A71\\u0A75\\u0A81\\u0A82\\u0ABC\\u0AC1-\\u0AC5\\u0AC7\\u0AC8\\u0ACD\\u0AE2\\u0AE3\\u0AFA-\\u0AFF\\u0B01\\u0B3C\\u0B3F\\u0B41-\\u0B44\\u0B4D\\u0B55\\u0B56\\u0B62\\u0B63\\u0B82\\u0BC0\\u0BCD\\u0C00\\u0C04\\u0C3C\\u0C3E-\\u0C40\\u0C46-\\u0C48\\u0C4A-\\u0C4D\\u0C55\\u0C56\\u0C62\\u0C63\\u0C81\\u0CBC\\u0CCC\\u0CCD\\u0CE2\\u0CE3\\u0D00\\u0D01\\u0D3B\\u0D3C\\u0D41-\\u0D44\\u0D4D\\u0D62\\u0D63\\u0D81\\u0DCA\\u0DD2-\\u0DD4\\u0DD6\\u0E31\\u0E34-\\u0E3A\\u0E47-\\u0E4E\\u0EB1\\u0EB4-\\u0EBC\\u0EC8-\\u0ECE\\u0F18\\u0F19\\u0F35\\u0F37\\u0F39\\u0F71-\\u0F7E\\u0F80-\\u0F84\\u0F86\\u0F87\\u0F8D-\\u0F97\\u0F99-\\u0FBC\\u0FC6\\u102D-\\u1030\\u1032-\\u1037\\u1039\\u103A\\u103D\\u103E\\u1058\\u1059\\u105E-\\u1060\\u1071-\\u1074\\u1082\\u1085\\u1086\\u108D\\u109D\\u135D-\\u135F\\u1712-\\u1714\\u1732\\u1733\\u1752\\u1753\\u1772\\u1773\\u17B4\\u17B5\\u17B7-\\u17BD\\u17C6\\u17C9-\\u17D3\\u17DD\\u180B-\\u180D\\u180F\\u1885\\u1886\\u18A9\\u1920-\\u1922\\u1927\\u1928\\u1932\\u1939-\\u193B\\u1A17\\u1A18\\u1A1B\\u1A56\\u1A58-\\u1A5E\\u1A60\\u1A62\\u1A65-\\u1A6C\\u1A73-\\u1A7C\\u1A7F\\u1AB0-\\u1ACE\\u1B00-\\u1B03\\u1B34\\u1B36-\\u1B3A\\u1B3C\\u1B42\\u1B6B-\\u1B73\\u1B80\\u1B81\\u1BA2-\\u1BA5\\u1BA8\\u1BA9\\u1BAB-\\u1BAD\\u1BE6\\u1BE8\\u1BE9\\u1BED\\u1BEF-\\u1BF1\\u1C2C-\\u1C33\\u1C36\\u1C37\\u1CD0-\\u1CD2\\u1CD4-\\u1CE0\\u1CE2-\\u1CE8\\u1CED\\u1CF4\\u1CF8\\u1CF9\\u1DC0-\\u1DFF\\u20D0-\\u20F0\\u2CEF-\\u2CF1\\u2D7F\\u2DE0-\\u2DFF\\u302A-\\u302D\\u3099\\u309A\\uA66F-\\uA672\\uA674-\\uA67D\\uA69E\\uA69F\\uA6F0\\uA6F1\\uA802\\uA806\\uA80B\\uA825\\uA826\\uA82C\\uA8C4\\uA8C5\\uA8E0-\\uA8F1\\uA8FF\\uA926-\\uA92D\\uA947-\\uA951\\uA980-\\uA982\\uA9B3\\uA9B6-\\uA9B9\\uA9BC\\uA9BD\\uA9E5\\uAA29-\\uAA2E\\uAA31\\uAA32\\uAA35\\uAA36\\uAA43\\uAA4C\\uAA7C\\uAAB0\\uAAB2-\\uAAB4\\uAAB7\\uAAB8\\uAABE\\uAABF\\uAAC1\\uAAEC\\uAAED\\uAAF6\\uABE5\\uABE8\\uABED\\uFB1E\\uFE00-\\uFE0F\\uFE20-\\uFE2F\\u{101FD}\\u{102E0}\\u{10376}-\\u{1037A}\\u{10A01}-\\u{10A03}\\u{10A05}\\u{10A06}\\u{10A0C}-\\u{10A0F}\\u{10A38}-\\u{10A3A}\\u{10A3F}\\u{10AE5}\\u{10AE6}\\u{10D24}-\\u{10D27}\\u{10EAB}\\u{10EAC}\\u{10EFD}-\\u{10EFF}\\u{10F46}-\\u{10F50}\\u{10F82}-\\u{10F85}\\u{11001}\\u{11038}-\\u{11046}\\u{11070}\\u{11073}\\u{11074}\\u{1107F}-\\u{11081}\\u{110B3}-\\u{110B6}\\u{110B9}\\u{110BA}\\u{110C2}\\u{11100}-\\u{11102}\\u{11127}-\\u{1112B}\\u{1112D}-\\u{11134}\\u{11173}\\u{11180}\\u{11181}\\u{111B6}-\\u{111BE}\\u{111C9}-\\u{111CC}\\u{111CF}\\u{1122F}-\\u{11231}\\u{11234}\\u{11236}\\u{11237}\\u{1123E}\\u{11241}\\u{112DF}\\u{112E3}-\\u{112EA}\\u{11300}\\u{11301}\\u{1133B}\\u{1133C}\\u{11340}\\u{11366}-\\u{1136C}\\u{11370}-\\u{11374}\\u{11438}-\\u{1143F}\\u{11442}-\\u{11444}\\u{11446}\\u{1145E}\\u{114B3}-\\u{114B8}\\u{114BA}\\u{114BF}\\u{114C0}\\u{114C2}\\u{114C3}\\u{115B2}-\\u{115B5}\\u{115BC}\\u{115BD}\\u{115BF}\\u{115C0}\\u{115DC}\\u{115DD}\\u{11633}-\\u{1163A}\\u{1163D}\\u{1163F}\\u{11640}\\u{116AB}\\u{116AD}\\u{116B0}-\\u{116B5}\\u{116B7}\\u{1171D}-\\u{1171F}\\u{11722}-\\u{11725}\\u{11727}-\\u{1172B}\\u{1182F}-\\u{11837}\\u{11839}\\u{1183A}\\u{1193B}\\u{1193C}\\u{1193E}\\u{11943}\\u{119D4}-\\u{119D7}\\u{119DA}\\u{119DB}\\u{119E0}\\u{11A01}-\\u{11A06}\\u{11A09}\\u{11A0A}\\u{11A33}-\\u{11A38}\\u{11A3B}-\\u{11A3E}\\u{11A47}\\u{11A51}-\\u{11A56}\\u{11A59}-\\u{11A5B}\\u{11A8A}-\\u{11A96}\\u{11A98}\\u{11A99}\\u{11C30}-\\u{11C36}\\u{11C38}-\\u{11C3D}\\u{11C92}-\\u{11CA7}\\u{11CAA}-\\u{11CB0}\\u{11CB2}\\u{11CB3}\\u{11CB5}\\u{11CB6}\\u{11D31}-\\u{11D36}\\u{11D3A}\\u{11D3C}\\u{11D3D}\\u{11D3F}-\\u{11D45}\\u{11D47}\\u{11D90}\\u{11D91}\\u{11D95}\\u{11D97}\\u{11EF3}\\u{11EF4}\\u{11F00}\\u{11F01}\\u{11F36}-\\u{11F3A}\\u{11F40}\\u{11F42}\\u{13440}\\u{13447}-\\u{13455}\\u{16AF0}-\\u{16AF4}\\u{16B30}-\\u{16B36}\\u{16F4F}\\u{16F8F}-\\u{16F92}\\u{16FE4}\\u{1BC9D}\\u{1BC9E}\\u{1CF00}-\\u{1CF2D}\\u{1CF30}-\\u{1CF46}\\u{1D167}-\\u{1D169}\\u{1D17B}-\\u{1D182}\\u{1D185}-\\u{1D18B}\\u{1D1AA}-\\u{1D1AD}\\u{1D242}-\\u{1D244}\\u{1DA00}-\\u{1DA36}\\u{1DA3B}-\\u{1DA6C}\\u{1DA75}\\u{1DA84}\\u{1DA9B}-\\u{1DA9F}\\u{1DAA1}-\\u{1DAAF}\\u{1E000}-\\u{1E006}\\u{1E008}-\\u{1E018}\\u{1E01B}-\\u{1E021}\\u{1E023}\\u{1E024}\\u{1E026}-\\u{1E02A}\\u{1E08F}\\u{1E130}-\\u{1E136}\\u{1E2AE}\\u{1E2EC}-\\u{1E2EF}\\u{1E4EC}-\\u{1E4EF}\\u{1E8D0}-\\u{1E8D6}\\u{1E944}-\\u{1E94A}\\u{E0100}-\\u{E01EF}]*$/u;\n\nmodule.exports = {\n  combiningMarks,\n  combiningClassVirama,\n  validZWNJ,\n  bidiDomain,\n  bidiS1LTR,\n  bidiS1RTL,\n  bidiS2,\n  bidiS3,\n  bidiS4EN,\n  bidiS4AN,\n  bidiS5,\n  bidiS6\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/tr46/lib/regexes.js?");

/***/ }),

/***/ "./node_modules/tr46/lib/statusMapping.js":
/*!************************************************!*\
  !*** ./node_modules/tr46/lib/statusMapping.js ***!
  \************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports.STATUS_MAPPING = {\n  mapped: 1,\n  valid: 2,\n  disallowed: 3,\n  disallowed_STD3_valid: 4,\n  disallowed_STD3_mapped: 5,\n  deviation: 6,\n  ignored: 7\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/tr46/lib/statusMapping.js?");

/***/ }),

/***/ "./db/db.ts":
/*!******************!*\
  !*** ./db/db.ts ***!
  \******************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   connectDB: () => (/* binding */ connectDB)\n/* harmony export */ });\n/* harmony import */ var mongoose__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! mongoose */ \"./node_modules/mongoose/index.js\");\n/* harmony import */ var mongoose__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(mongoose__WEBPACK_IMPORTED_MODULE_0__);\n\nconst connectDB = async () => {\n    try {\n        const conn = await mongoose__WEBPACK_IMPORTED_MODULE_0___default().connect(\"mongodb+srv://kikiondo:kikiondo_20@cluster0.z6ae7.mongodb.net/logs?retryWrites=true&w=majority&appName=Cluster0\");\n        console.log(\"MongoDB Connected\");\n    }\n    catch (err) {\n        console.log(\"ERROR :c\", err);\n        process.exit(1);\n    }\n};\n\n\n//# sourceURL=webpack://experimento/./db/db.ts?");

/***/ }),

/***/ "./db/index.ts":
/*!*********************!*\
  !*** ./db/index.ts ***!
  \*********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   connectDB: () => (/* reexport safe */ _db__WEBPACK_IMPORTED_MODULE_0__.connectDB)\n/* harmony export */ });\n/* harmony import */ var _db__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./db */ \"./db/db.ts\");\n\n\n\n//# sourceURL=webpack://experimento/./db/index.ts?");

/***/ }),

/***/ "./models/Log.ts":
/*!***********************!*\
  !*** ./models/Log.ts ***!
  \***********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   LogModel: () => (/* binding */ LogModel)\n/* harmony export */ });\n/* harmony import */ var mongoose__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! mongoose */ \"./node_modules/mongoose/index.js\");\n/* harmony import */ var mongoose__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(mongoose__WEBPACK_IMPORTED_MODULE_0__);\n\nconst LogSchema = new (mongoose__WEBPACK_IMPORTED_MODULE_0___default().Schema)({\n    text: {\n        type: String,\n        trim: true,\n        required: [true, \"Log text is required\"],\n    },\n    priority: {\n        type: String,\n        default: \"Low\",\n        enum: [\"Low\", \"Moderate\", \"High\"],\n    },\n    user: {\n        type: String,\n        trim: true,\n        required: [true, \"User is required\"],\n    },\n    created: {\n        type: Date,\n        default: Date.now,\n    },\n});\nconst LogModel = mongoose__WEBPACK_IMPORTED_MODULE_0___default().model(\"Log\", LogSchema);\n\n\n//# sourceURL=webpack://experimento/./models/Log.ts?");

/***/ }),

/***/ "./src/main/main.ts":
/*!**************************!*\
  !*** ./src/main/main.ts ***!
  \**************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _db__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../db */ \"./db/index.ts\");\n/* harmony import */ var electron__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! electron */ \"electron\");\n/* harmony import */ var electron__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(electron__WEBPACK_IMPORTED_MODULE_1__);\n/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! path */ \"path\");\n/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(path__WEBPACK_IMPORTED_MODULE_2__);\n/* harmony import */ var http__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! http */ \"http\");\n/* harmony import */ var http__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(http__WEBPACK_IMPORTED_MODULE_3__);\n/* harmony import */ var _utils_logs__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./utils/logs */ \"./src/main/utils/logs.ts\");\n\n\n\n\n\n// ! Connectamos a nuestra DB\n(0,_db__WEBPACK_IMPORTED_MODULE_0__.connectDB)();\nlet mainWindow;\nlet isDev = false;\nconst isMac = process.platform === \"darwin\" ? true : false;\nconst createWindow = () => {\n    mainWindow = new electron__WEBPACK_IMPORTED_MODULE_1__.BrowserWindow({\n        width: 800,\n        height: 800,\n        webPreferences: {\n            // preload: path.join(__dirname, \"preload.js\"),\n            // contextIsolation: true,\n            // nodeIntegration: false,\n            // !Solucion para el error de global en el window, pero no es la mejor la mejor es el preload.js\n            nodeIntegration: true, // Habilita la integracin de Node.js en el renderer\n            contextIsolation: false, // Deshabilita el aislamiento de contexto\n        },\n    });\n    if (isDev) {\n        const startURL = \"http://localhost:3000\";\n        const checkServer = () => {\n            http__WEBPACK_IMPORTED_MODULE_3__.get(startURL, (res) => {\n                if (res.statusCode === 200) {\n                    mainWindow.loadURL(startURL);\n                    mainWindow.show();\n                    mainWindow.webContents.openDevTools();\n                }\n                else {\n                    setTimeout(checkServer, 1000); // Reintentar despus de 1 segundo si no est listo\n                }\n            })\n                .on(\"error\", () => {\n                setTimeout(checkServer, 1000); // Reintentar si hay un error de conexin\n            });\n        };\n        mainWindow.hide(); // Ocultar la ventana hasta que el contenido est listo\n        checkServer(); // Comenzar a verificar si el servidor est listo\n    }\n    else {\n        const mainHtml = path__WEBPACK_IMPORTED_MODULE_2__.resolve(__dirname, \"index.html\");\n        mainWindow.loadFile(mainHtml);\n    }\n};\nelectron__WEBPACK_IMPORTED_MODULE_1__.app.on(\"ready\", () => {\n    createWindow();\n    const mainMenu = electron__WEBPACK_IMPORTED_MODULE_1__.Menu.buildFromTemplate(menu);\n    electron__WEBPACK_IMPORTED_MODULE_1__.Menu.setApplicationMenu(mainMenu);\n});\nconst menu = [\n    ...(isMac ? [{ role: \"appMenu\" }] : []),\n    { role: \"fileMenu\" },\n    { role: \"editMenu\" },\n    {\n        label: \"Logs\",\n        submenu: [{ label: \"Clear Logs\", click: () => (0,_utils_logs__WEBPACK_IMPORTED_MODULE_4__.clearLogs)(mainWindow) }],\n    },\n    ...(isDev\n        ? [\n            {\n                label: \"Developer\",\n                submenu: [\n                    { role: \"reload\" },\n                    { role: \"forcereload\" },\n                    { type: \"separator\" },\n                    { role: \"toggledevtools\" },\n                ],\n            },\n        ]\n        : []),\n];\n// ! Load Logs\nelectron__WEBPACK_IMPORTED_MODULE_1__.ipcMain.on(\"logs:load\", () => (0,_utils_logs__WEBPACK_IMPORTED_MODULE_4__.sendLogs)(mainWindow));\n// ! Create log \nelectron__WEBPACK_IMPORTED_MODULE_1__.ipcMain.on(\"logs:add\", (event, item) => (0,_utils_logs__WEBPACK_IMPORTED_MODULE_4__.addLog)(event, item, mainWindow));\n// ! Delete log\nelectron__WEBPACK_IMPORTED_MODULE_1__.ipcMain.on(\"logs:delete\", (event, id) => (0,_utils_logs__WEBPACK_IMPORTED_MODULE_4__.deleteLog)(event, id, mainWindow));\nelectron__WEBPACK_IMPORTED_MODULE_1__.app.on(\"window-all-closed\", () => {\n    if (process.platform !== \"darwin\") {\n        electron__WEBPACK_IMPORTED_MODULE_1__.app.quit();\n    }\n});\nelectron__WEBPACK_IMPORTED_MODULE_1__.app.on(\"activate\", () => {\n    if (electron__WEBPACK_IMPORTED_MODULE_1__.BrowserWindow.getAllWindows().length === 0) {\n        createWindow();\n    }\n});\n\n\n//# sourceURL=webpack://experimento/./src/main/main.ts?");

/***/ }),

/***/ "./src/main/utils/logs.ts":
/*!********************************!*\
  !*** ./src/main/utils/logs.ts ***!
  \********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   addLog: () => (/* binding */ addLog),\n/* harmony export */   clearLogs: () => (/* binding */ clearLogs),\n/* harmony export */   deleteLog: () => (/* binding */ deleteLog),\n/* harmony export */   sendLogs: () => (/* binding */ sendLogs)\n/* harmony export */ });\n/* harmony import */ var _models_Log__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../models/Log */ \"./models/Log.ts\");\n\nconst sendLogs = async (mainWindow) => {\n    try {\n        const logs = await _models_Log__WEBPACK_IMPORTED_MODULE_0__.LogModel.find().sort({ created: 1 });\n        mainWindow.webContents.send(\"logs:get\", JSON.stringify(logs));\n    }\n    catch (err) {\n        console.log(\"ERROR :C\", err);\n    }\n};\nconst addLog = async (event, item, mainWindow) => {\n    try {\n        await _models_Log__WEBPACK_IMPORTED_MODULE_0__.LogModel.create(item);\n        sendLogs(mainWindow);\n    }\n    catch (error) {\n        console.log(\"error\", error);\n    }\n};\nconst deleteLog = async (event, id, mainWindow) => {\n    try {\n        await _models_Log__WEBPACK_IMPORTED_MODULE_0__.LogModel.findOneAndDelete({ _id: id });\n        sendLogs(mainWindow);\n    }\n    catch (error) {\n        console.log(\"error\", error);\n    }\n};\nconst clearLogs = async (mainWindow) => {\n    try {\n        await _models_Log__WEBPACK_IMPORTED_MODULE_0__.LogModel.deleteMany({});\n        mainWindow.webContents.send(\"logs:clear\");\n    }\n    catch (error) {\n        console.log(\"error\", error);\n    }\n};\n\n\n//# sourceURL=webpack://experimento/./src/main/utils/logs.ts?");

/***/ }),

/***/ "./node_modules/webidl-conversions/lib/index.js":
/*!******************************************************!*\
  !*** ./node_modules/webidl-conversions/lib/index.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nfunction makeException(ErrorType, message, options) {\n  if (options.globals) {\n    ErrorType = options.globals[ErrorType.name];\n  }\n  return new ErrorType(`${options.context ? options.context : \"Value\"} ${message}.`);\n}\n\nfunction toNumber(value, options) {\n  if (typeof value === \"bigint\") {\n    throw makeException(TypeError, \"is a BigInt which cannot be converted to a number\", options);\n  }\n  if (!options.globals) {\n    return Number(value);\n  }\n  return options.globals.Number(value);\n}\n\n// Round x to the nearest integer, choosing the even integer if it lies halfway between two.\nfunction evenRound(x) {\n  // There are four cases for numbers with fractional part being .5:\n  //\n  // case |     x     | floor(x) | round(x) | expected | x <> 0 | x % 1 | x & 1 |   example\n  //   1  |  2n + 0.5 |  2n      |  2n + 1  |  2n      |   >    |  0.5  |   0   |  0.5 ->  0\n  //   2  |  2n + 1.5 |  2n + 1  |  2n + 2  |  2n + 2  |   >    |  0.5  |   1   |  1.5 ->  2\n  //   3  | -2n - 0.5 | -2n - 1  | -2n      | -2n      |   <    | -0.5  |   0   | -0.5 ->  0\n  //   4  | -2n - 1.5 | -2n - 2  | -2n - 1  | -2n - 2  |   <    | -0.5  |   1   | -1.5 -> -2\n  // (where n is a non-negative integer)\n  //\n  // Branch here for cases 1 and 4\n  if ((x > 0 && (x % 1) === +0.5 && (x & 1) === 0) ||\n        (x < 0 && (x % 1) === -0.5 && (x & 1) === 1)) {\n    return censorNegativeZero(Math.floor(x));\n  }\n\n  return censorNegativeZero(Math.round(x));\n}\n\nfunction integerPart(n) {\n  return censorNegativeZero(Math.trunc(n));\n}\n\nfunction sign(x) {\n  return x < 0 ? -1 : 1;\n}\n\nfunction modulo(x, y) {\n  // https://tc39.github.io/ecma262/#eqn-modulo\n  // Note that http://stackoverflow.com/a/4467559/3191 does NOT work for large modulos\n  const signMightNotMatch = x % y;\n  if (sign(y) !== sign(signMightNotMatch)) {\n    return signMightNotMatch + y;\n  }\n  return signMightNotMatch;\n}\n\nfunction censorNegativeZero(x) {\n  return x === 0 ? 0 : x;\n}\n\nfunction createIntegerConversion(bitLength, { unsigned }) {\n  let lowerBound, upperBound;\n  if (unsigned) {\n    lowerBound = 0;\n    upperBound = 2 ** bitLength - 1;\n  } else {\n    lowerBound = -(2 ** (bitLength - 1));\n    upperBound = 2 ** (bitLength - 1) - 1;\n  }\n\n  const twoToTheBitLength = 2 ** bitLength;\n  const twoToOneLessThanTheBitLength = 2 ** (bitLength - 1);\n\n  return (value, options = {}) => {\n    let x = toNumber(value, options);\n    x = censorNegativeZero(x);\n\n    if (options.enforceRange) {\n      if (!Number.isFinite(x)) {\n        throw makeException(TypeError, \"is not a finite number\", options);\n      }\n\n      x = integerPart(x);\n\n      if (x < lowerBound || x > upperBound) {\n        throw makeException(\n          TypeError,\n          `is outside the accepted range of ${lowerBound} to ${upperBound}, inclusive`,\n          options\n        );\n      }\n\n      return x;\n    }\n\n    if (!Number.isNaN(x) && options.clamp) {\n      x = Math.min(Math.max(x, lowerBound), upperBound);\n      x = evenRound(x);\n      return x;\n    }\n\n    if (!Number.isFinite(x) || x === 0) {\n      return 0;\n    }\n    x = integerPart(x);\n\n    // Math.pow(2, 64) is not accurately representable in JavaScript, so try to avoid these per-spec operations if\n    // possible. Hopefully it's an optimization for the non-64-bitLength cases too.\n    if (x >= lowerBound && x <= upperBound) {\n      return x;\n    }\n\n    // These will not work great for bitLength of 64, but oh well. See the README for more details.\n    x = modulo(x, twoToTheBitLength);\n    if (!unsigned && x >= twoToOneLessThanTheBitLength) {\n      return x - twoToTheBitLength;\n    }\n    return x;\n  };\n}\n\nfunction createLongLongConversion(bitLength, { unsigned }) {\n  const upperBound = Number.MAX_SAFE_INTEGER;\n  const lowerBound = unsigned ? 0 : Number.MIN_SAFE_INTEGER;\n  const asBigIntN = unsigned ? BigInt.asUintN : BigInt.asIntN;\n\n  return (value, options = {}) => {\n    let x = toNumber(value, options);\n    x = censorNegativeZero(x);\n\n    if (options.enforceRange) {\n      if (!Number.isFinite(x)) {\n        throw makeException(TypeError, \"is not a finite number\", options);\n      }\n\n      x = integerPart(x);\n\n      if (x < lowerBound || x > upperBound) {\n        throw makeException(\n          TypeError,\n          `is outside the accepted range of ${lowerBound} to ${upperBound}, inclusive`,\n          options\n        );\n      }\n\n      return x;\n    }\n\n    if (!Number.isNaN(x) && options.clamp) {\n      x = Math.min(Math.max(x, lowerBound), upperBound);\n      x = evenRound(x);\n      return x;\n    }\n\n    if (!Number.isFinite(x) || x === 0) {\n      return 0;\n    }\n\n    let xBigInt = BigInt(integerPart(x));\n    xBigInt = asBigIntN(bitLength, xBigInt);\n    return Number(xBigInt);\n  };\n}\n\nexports.any = value => {\n  return value;\n};\n\nexports.undefined = () => {\n  return undefined;\n};\n\nexports.boolean = value => {\n  return Boolean(value);\n};\n\nexports.byte = createIntegerConversion(8, { unsigned: false });\nexports.octet = createIntegerConversion(8, { unsigned: true });\n\nexports.short = createIntegerConversion(16, { unsigned: false });\nexports[\"unsigned short\"] = createIntegerConversion(16, { unsigned: true });\n\nexports.long = createIntegerConversion(32, { unsigned: false });\nexports[\"unsigned long\"] = createIntegerConversion(32, { unsigned: true });\n\nexports[\"long long\"] = createLongLongConversion(64, { unsigned: false });\nexports[\"unsigned long long\"] = createLongLongConversion(64, { unsigned: true });\n\nexports.double = (value, options = {}) => {\n  const x = toNumber(value, options);\n\n  if (!Number.isFinite(x)) {\n    throw makeException(TypeError, \"is not a finite floating-point value\", options);\n  }\n\n  return x;\n};\n\nexports[\"unrestricted double\"] = (value, options = {}) => {\n  const x = toNumber(value, options);\n\n  return x;\n};\n\nexports.float = (value, options = {}) => {\n  const x = toNumber(value, options);\n\n  if (!Number.isFinite(x)) {\n    throw makeException(TypeError, \"is not a finite floating-point value\", options);\n  }\n\n  if (Object.is(x, -0)) {\n    return x;\n  }\n\n  const y = Math.fround(x);\n\n  if (!Number.isFinite(y)) {\n    throw makeException(TypeError, \"is outside the range of a single-precision floating-point value\", options);\n  }\n\n  return y;\n};\n\nexports[\"unrestricted float\"] = (value, options = {}) => {\n  const x = toNumber(value, options);\n\n  if (isNaN(x)) {\n    return x;\n  }\n\n  if (Object.is(x, -0)) {\n    return x;\n  }\n\n  return Math.fround(x);\n};\n\nexports.DOMString = (value, options = {}) => {\n  if (options.treatNullAsEmptyString && value === null) {\n    return \"\";\n  }\n\n  if (typeof value === \"symbol\") {\n    throw makeException(TypeError, \"is a symbol, which cannot be converted to a string\", options);\n  }\n\n  const StringCtor = options.globals ? options.globals.String : String;\n  return StringCtor(value);\n};\n\nexports.ByteString = (value, options = {}) => {\n  const x = exports.DOMString(value, options);\n  let c;\n  for (let i = 0; (c = x.codePointAt(i)) !== undefined; ++i) {\n    if (c > 255) {\n      throw makeException(TypeError, \"is not a valid ByteString\", options);\n    }\n  }\n\n  return x;\n};\n\nexports.USVString = (value, options = {}) => {\n  const S = exports.DOMString(value, options);\n  const n = S.length;\n  const U = [];\n  for (let i = 0; i < n; ++i) {\n    const c = S.charCodeAt(i);\n    if (c < 0xD800 || c > 0xDFFF) {\n      U.push(String.fromCodePoint(c));\n    } else if (0xDC00 <= c && c <= 0xDFFF) {\n      U.push(String.fromCodePoint(0xFFFD));\n    } else if (i === n - 1) {\n      U.push(String.fromCodePoint(0xFFFD));\n    } else {\n      const d = S.charCodeAt(i + 1);\n      if (0xDC00 <= d && d <= 0xDFFF) {\n        const a = c & 0x3FF;\n        const b = d & 0x3FF;\n        U.push(String.fromCodePoint((2 << 15) + ((2 << 9) * a) + b));\n        ++i;\n      } else {\n        U.push(String.fromCodePoint(0xFFFD));\n      }\n    }\n  }\n\n  return U.join(\"\");\n};\n\nexports.object = (value, options = {}) => {\n  if (value === null || (typeof value !== \"object\" && typeof value !== \"function\")) {\n    throw makeException(TypeError, \"is not an object\", options);\n  }\n\n  return value;\n};\n\nconst abByteLengthGetter =\n    Object.getOwnPropertyDescriptor(ArrayBuffer.prototype, \"byteLength\").get;\nconst sabByteLengthGetter =\n    typeof SharedArrayBuffer === \"function\" ?\n      Object.getOwnPropertyDescriptor(SharedArrayBuffer.prototype, \"byteLength\").get :\n      null;\n\nfunction isNonSharedArrayBuffer(value) {\n  try {\n    // This will throw on SharedArrayBuffers, but not detached ArrayBuffers.\n    // (The spec says it should throw, but the spec conflicts with implementations: https://github.com/tc39/ecma262/issues/678)\n    abByteLengthGetter.call(value);\n\n    return true;\n  } catch {\n    return false;\n  }\n}\n\nfunction isSharedArrayBuffer(value) {\n  try {\n    sabByteLengthGetter.call(value);\n    return true;\n  } catch {\n    return false;\n  }\n}\n\nfunction isArrayBufferDetached(value) {\n  try {\n    // eslint-disable-next-line no-new\n    new Uint8Array(value);\n    return false;\n  } catch {\n    return true;\n  }\n}\n\nexports.ArrayBuffer = (value, options = {}) => {\n  if (!isNonSharedArrayBuffer(value)) {\n    if (options.allowShared && !isSharedArrayBuffer(value)) {\n      throw makeException(TypeError, \"is not an ArrayBuffer or SharedArrayBuffer\", options);\n    }\n    throw makeException(TypeError, \"is not an ArrayBuffer\", options);\n  }\n  if (isArrayBufferDetached(value)) {\n    throw makeException(TypeError, \"is a detached ArrayBuffer\", options);\n  }\n\n  return value;\n};\n\nconst dvByteLengthGetter =\n    Object.getOwnPropertyDescriptor(DataView.prototype, \"byteLength\").get;\nexports.DataView = (value, options = {}) => {\n  try {\n    dvByteLengthGetter.call(value);\n  } catch (e) {\n    throw makeException(TypeError, \"is not a DataView\", options);\n  }\n\n  if (!options.allowShared && isSharedArrayBuffer(value.buffer)) {\n    throw makeException(TypeError, \"is backed by a SharedArrayBuffer, which is not allowed\", options);\n  }\n  if (isArrayBufferDetached(value.buffer)) {\n    throw makeException(TypeError, \"is backed by a detached ArrayBuffer\", options);\n  }\n\n  return value;\n};\n\n// Returns the unforgeable `TypedArray` constructor name or `undefined`,\n// if the `this` value isn't a valid `TypedArray` object.\n//\n// https://tc39.es/ecma262/#sec-get-%typedarray%.prototype-@@tostringtag\nconst typedArrayNameGetter = Object.getOwnPropertyDescriptor(\n  Object.getPrototypeOf(Uint8Array).prototype,\n  Symbol.toStringTag\n).get;\n[\n  Int8Array,\n  Int16Array,\n  Int32Array,\n  Uint8Array,\n  Uint16Array,\n  Uint32Array,\n  Uint8ClampedArray,\n  Float32Array,\n  Float64Array\n].forEach(func => {\n  const { name } = func;\n  const article = /^[AEIOU]/u.test(name) ? \"an\" : \"a\";\n  exports[name] = (value, options = {}) => {\n    if (!ArrayBuffer.isView(value) || typedArrayNameGetter.call(value) !== name) {\n      throw makeException(TypeError, `is not ${article} ${name} object`, options);\n    }\n    if (!options.allowShared && isSharedArrayBuffer(value.buffer)) {\n      throw makeException(TypeError, \"is a view on a SharedArrayBuffer, which is not allowed\", options);\n    }\n    if (isArrayBufferDetached(value.buffer)) {\n      throw makeException(TypeError, \"is a view on a detached ArrayBuffer\", options);\n    }\n\n    return value;\n  };\n});\n\n// Common definitions\n\nexports.ArrayBufferView = (value, options = {}) => {\n  if (!ArrayBuffer.isView(value)) {\n    throw makeException(TypeError, \"is not a view on an ArrayBuffer or SharedArrayBuffer\", options);\n  }\n\n  if (!options.allowShared && isSharedArrayBuffer(value.buffer)) {\n    throw makeException(TypeError, \"is a view on a SharedArrayBuffer, which is not allowed\", options);\n  }\n\n  if (isArrayBufferDetached(value.buffer)) {\n    throw makeException(TypeError, \"is a view on a detached ArrayBuffer\", options);\n  }\n  return value;\n};\n\nexports.BufferSource = (value, options = {}) => {\n  if (ArrayBuffer.isView(value)) {\n    if (!options.allowShared && isSharedArrayBuffer(value.buffer)) {\n      throw makeException(TypeError, \"is a view on a SharedArrayBuffer, which is not allowed\", options);\n    }\n\n    if (isArrayBufferDetached(value.buffer)) {\n      throw makeException(TypeError, \"is a view on a detached ArrayBuffer\", options);\n    }\n    return value;\n  }\n\n  if (!options.allowShared && !isNonSharedArrayBuffer(value)) {\n    throw makeException(TypeError, \"is not an ArrayBuffer or a view on one\", options);\n  }\n  if (options.allowShared && !isSharedArrayBuffer(value) && !isNonSharedArrayBuffer(value)) {\n    throw makeException(TypeError, \"is not an ArrayBuffer, SharedArrayBuffer, or a view on one\", options);\n  }\n  if (isArrayBufferDetached(value)) {\n    throw makeException(TypeError, \"is a detached ArrayBuffer\", options);\n  }\n\n  return value;\n};\n\nexports.DOMTimeStamp = exports[\"unsigned long long\"];\n\n\n//# sourceURL=webpack://experimento/./node_modules/webidl-conversions/lib/index.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/index.js":
/*!******************************************!*\
  !*** ./node_modules/whatwg-url/index.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nconst { URL, URLSearchParams } = __webpack_require__(/*! ./webidl2js-wrapper */ \"./node_modules/whatwg-url/webidl2js-wrapper.js\");\nconst urlStateMachine = __webpack_require__(/*! ./lib/url-state-machine */ \"./node_modules/whatwg-url/lib/url-state-machine.js\");\nconst percentEncoding = __webpack_require__(/*! ./lib/percent-encoding */ \"./node_modules/whatwg-url/lib/percent-encoding.js\");\n\nconst sharedGlobalObject = { Array, Object, Promise, String, TypeError };\nURL.install(sharedGlobalObject, [\"Window\"]);\nURLSearchParams.install(sharedGlobalObject, [\"Window\"]);\n\nexports.URL = sharedGlobalObject.URL;\nexports.URLSearchParams = sharedGlobalObject.URLSearchParams;\n\nexports.parseURL = urlStateMachine.parseURL;\nexports.basicURLParse = urlStateMachine.basicURLParse;\nexports.serializeURL = urlStateMachine.serializeURL;\nexports.serializePath = urlStateMachine.serializePath;\nexports.serializeHost = urlStateMachine.serializeHost;\nexports.serializeInteger = urlStateMachine.serializeInteger;\nexports.serializeURLOrigin = urlStateMachine.serializeURLOrigin;\nexports.setTheUsername = urlStateMachine.setTheUsername;\nexports.setThePassword = urlStateMachine.setThePassword;\nexports.cannotHaveAUsernamePasswordPort = urlStateMachine.cannotHaveAUsernamePasswordPort;\nexports.hasAnOpaquePath = urlStateMachine.hasAnOpaquePath;\n\nexports.percentDecodeString = percentEncoding.percentDecodeString;\nexports.percentDecodeBytes = percentEncoding.percentDecodeBytes;\n\n\n//# sourceURL=webpack://experimento/./node_modules/whatwg-url/index.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/lib/Function.js":
/*!*************************************************!*\
  !*** ./node_modules/whatwg-url/lib/Function.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nconst conversions = __webpack_require__(/*! webidl-conversions */ \"./node_modules/webidl-conversions/lib/index.js\");\nconst utils = __webpack_require__(/*! ./utils.js */ \"./node_modules/whatwg-url/lib/utils.js\");\n\nexports.convert = (globalObject, value, { context = \"The provided value\" } = {}) => {\n  if (typeof value !== \"function\") {\n    throw new globalObject.TypeError(context + \" is not a function\");\n  }\n\n  function invokeTheCallbackFunction(...args) {\n    const thisArg = utils.tryWrapperForImpl(this);\n    let callResult;\n\n    for (let i = 0; i < args.length; i++) {\n      args[i] = utils.tryWrapperForImpl(args[i]);\n    }\n\n    callResult = Reflect.apply(value, thisArg, args);\n\n    callResult = conversions[\"any\"](callResult, { context: context, globals: globalObject });\n\n    return callResult;\n  }\n\n  invokeTheCallbackFunction.construct = (...args) => {\n    for (let i = 0; i < args.length; i++) {\n      args[i] = utils.tryWrapperForImpl(args[i]);\n    }\n\n    let callResult = Reflect.construct(value, args);\n\n    callResult = conversions[\"any\"](callResult, { context: context, globals: globalObject });\n\n    return callResult;\n  };\n\n  invokeTheCallbackFunction[utils.wrapperSymbol] = value;\n  invokeTheCallbackFunction.objectReference = value;\n\n  return invokeTheCallbackFunction;\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/whatwg-url/lib/Function.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/lib/URL-impl.js":
/*!*************************************************!*\
  !*** ./node_modules/whatwg-url/lib/URL-impl.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nconst usm = __webpack_require__(/*! ./url-state-machine */ \"./node_modules/whatwg-url/lib/url-state-machine.js\");\nconst urlencoded = __webpack_require__(/*! ./urlencoded */ \"./node_modules/whatwg-url/lib/urlencoded.js\");\nconst URLSearchParams = __webpack_require__(/*! ./URLSearchParams */ \"./node_modules/whatwg-url/lib/URLSearchParams.js\");\n\nexports.implementation = class URLImpl {\n  // Unlike the spec, we duplicate some code between the constructor and canParse, because we want to give useful error\n  // messages in the constructor that distinguish between the different causes of failure.\n  constructor(globalObject, constructorArgs) {\n    const url = constructorArgs[0];\n    const base = constructorArgs[1];\n\n    let parsedBase = null;\n    if (base !== undefined) {\n      parsedBase = usm.basicURLParse(base);\n      if (parsedBase === null) {\n        throw new TypeError(`Invalid base URL: ${base}`);\n      }\n    }\n\n    const parsedURL = usm.basicURLParse(url, { baseURL: parsedBase });\n    if (parsedURL === null) {\n      throw new TypeError(`Invalid URL: ${url}`);\n    }\n\n    const query = parsedURL.query !== null ? parsedURL.query : \"\";\n\n    this._url = parsedURL;\n\n    // We cannot invoke the \"new URLSearchParams object\" algorithm without going through the constructor, which strips\n    // question mark by default. Therefore the doNotStripQMark hack is used.\n    this._query = URLSearchParams.createImpl(globalObject, [query], { doNotStripQMark: true });\n    this._query._url = this;\n  }\n\n  static canParse(url, base) {\n    let parsedBase = null;\n    if (base !== undefined) {\n      parsedBase = usm.basicURLParse(base);\n      if (parsedBase === null) {\n        return false;\n      }\n    }\n\n    const parsedURL = usm.basicURLParse(url, { baseURL: parsedBase });\n    if (parsedURL === null) {\n      return false;\n    }\n\n    return true;\n  }\n\n  get href() {\n    return usm.serializeURL(this._url);\n  }\n\n  set href(v) {\n    const parsedURL = usm.basicURLParse(v);\n    if (parsedURL === null) {\n      throw new TypeError(`Invalid URL: ${v}`);\n    }\n\n    this._url = parsedURL;\n\n    this._query._list.splice(0);\n    const { query } = parsedURL;\n    if (query !== null) {\n      this._query._list = urlencoded.parseUrlencodedString(query);\n    }\n  }\n\n  get origin() {\n    return usm.serializeURLOrigin(this._url);\n  }\n\n  get protocol() {\n    return `${this._url.scheme}:`;\n  }\n\n  set protocol(v) {\n    usm.basicURLParse(`${v}:`, { url: this._url, stateOverride: \"scheme start\" });\n  }\n\n  get username() {\n    return this._url.username;\n  }\n\n  set username(v) {\n    if (usm.cannotHaveAUsernamePasswordPort(this._url)) {\n      return;\n    }\n\n    usm.setTheUsername(this._url, v);\n  }\n\n  get password() {\n    return this._url.password;\n  }\n\n  set password(v) {\n    if (usm.cannotHaveAUsernamePasswordPort(this._url)) {\n      return;\n    }\n\n    usm.setThePassword(this._url, v);\n  }\n\n  get host() {\n    const url = this._url;\n\n    if (url.host === null) {\n      return \"\";\n    }\n\n    if (url.port === null) {\n      return usm.serializeHost(url.host);\n    }\n\n    return `${usm.serializeHost(url.host)}:${usm.serializeInteger(url.port)}`;\n  }\n\n  set host(v) {\n    if (usm.hasAnOpaquePath(this._url)) {\n      return;\n    }\n\n    usm.basicURLParse(v, { url: this._url, stateOverride: \"host\" });\n  }\n\n  get hostname() {\n    if (this._url.host === null) {\n      return \"\";\n    }\n\n    return usm.serializeHost(this._url.host);\n  }\n\n  set hostname(v) {\n    if (usm.hasAnOpaquePath(this._url)) {\n      return;\n    }\n\n    usm.basicURLParse(v, { url: this._url, stateOverride: \"hostname\" });\n  }\n\n  get port() {\n    if (this._url.port === null) {\n      return \"\";\n    }\n\n    return usm.serializeInteger(this._url.port);\n  }\n\n  set port(v) {\n    if (usm.cannotHaveAUsernamePasswordPort(this._url)) {\n      return;\n    }\n\n    if (v === \"\") {\n      this._url.port = null;\n    } else {\n      usm.basicURLParse(v, { url: this._url, stateOverride: \"port\" });\n    }\n  }\n\n  get pathname() {\n    return usm.serializePath(this._url);\n  }\n\n  set pathname(v) {\n    if (usm.hasAnOpaquePath(this._url)) {\n      return;\n    }\n\n    this._url.path = [];\n    usm.basicURLParse(v, { url: this._url, stateOverride: \"path start\" });\n  }\n\n  get search() {\n    if (this._url.query === null || this._url.query === \"\") {\n      return \"\";\n    }\n\n    return `?${this._url.query}`;\n  }\n\n  set search(v) {\n    const url = this._url;\n\n    if (v === \"\") {\n      url.query = null;\n      this._query._list = [];\n      this._potentiallyStripTrailingSpacesFromAnOpaquePath();\n      return;\n    }\n\n    const input = v[0] === \"?\" ? v.substring(1) : v;\n    url.query = \"\";\n    usm.basicURLParse(input, { url, stateOverride: \"query\" });\n    this._query._list = urlencoded.parseUrlencodedString(input);\n  }\n\n  get searchParams() {\n    return this._query;\n  }\n\n  get hash() {\n    if (this._url.fragment === null || this._url.fragment === \"\") {\n      return \"\";\n    }\n\n    return `#${this._url.fragment}`;\n  }\n\n  set hash(v) {\n    if (v === \"\") {\n      this._url.fragment = null;\n      this._potentiallyStripTrailingSpacesFromAnOpaquePath();\n      return;\n    }\n\n    const input = v[0] === \"#\" ? v.substring(1) : v;\n    this._url.fragment = \"\";\n    usm.basicURLParse(input, { url: this._url, stateOverride: \"fragment\" });\n  }\n\n  toJSON() {\n    return this.href;\n  }\n\n  _potentiallyStripTrailingSpacesFromAnOpaquePath() {\n    if (!usm.hasAnOpaquePath(this._url)) {\n      return;\n    }\n\n    if (this._url.fragment !== null) {\n      return;\n    }\n\n    if (this._url.query !== null) {\n      return;\n    }\n\n    this._url.path = this._url.path.replace(/\\u0020+$/u, \"\");\n  }\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/whatwg-url/lib/URL-impl.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/lib/URL.js":
/*!********************************************!*\
  !*** ./node_modules/whatwg-url/lib/URL.js ***!
  \********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nconst conversions = __webpack_require__(/*! webidl-conversions */ \"./node_modules/webidl-conversions/lib/index.js\");\nconst utils = __webpack_require__(/*! ./utils.js */ \"./node_modules/whatwg-url/lib/utils.js\");\n\nconst implSymbol = utils.implSymbol;\nconst ctorRegistrySymbol = utils.ctorRegistrySymbol;\n\nconst interfaceName = \"URL\";\n\nexports.is = value => {\n  return utils.isObject(value) && utils.hasOwn(value, implSymbol) && value[implSymbol] instanceof Impl.implementation;\n};\nexports.isImpl = value => {\n  return utils.isObject(value) && value instanceof Impl.implementation;\n};\nexports.convert = (globalObject, value, { context = \"The provided value\" } = {}) => {\n  if (exports.is(value)) {\n    return utils.implForWrapper(value);\n  }\n  throw new globalObject.TypeError(`${context} is not of type 'URL'.`);\n};\n\nfunction makeWrapper(globalObject, newTarget) {\n  let proto;\n  if (newTarget !== undefined) {\n    proto = newTarget.prototype;\n  }\n\n  if (!utils.isObject(proto)) {\n    proto = globalObject[ctorRegistrySymbol][\"URL\"].prototype;\n  }\n\n  return Object.create(proto);\n}\n\nexports.create = (globalObject, constructorArgs, privateData) => {\n  const wrapper = makeWrapper(globalObject);\n  return exports.setup(wrapper, globalObject, constructorArgs, privateData);\n};\n\nexports.createImpl = (globalObject, constructorArgs, privateData) => {\n  const wrapper = exports.create(globalObject, constructorArgs, privateData);\n  return utils.implForWrapper(wrapper);\n};\n\nexports._internalSetup = (wrapper, globalObject) => {};\n\nexports.setup = (wrapper, globalObject, constructorArgs = [], privateData = {}) => {\n  privateData.wrapper = wrapper;\n\n  exports._internalSetup(wrapper, globalObject);\n  Object.defineProperty(wrapper, implSymbol, {\n    value: new Impl.implementation(globalObject, constructorArgs, privateData),\n    configurable: true\n  });\n\n  wrapper[implSymbol][utils.wrapperSymbol] = wrapper;\n  if (Impl.init) {\n    Impl.init(wrapper[implSymbol]);\n  }\n  return wrapper;\n};\n\nexports[\"new\"] = (globalObject, newTarget) => {\n  const wrapper = makeWrapper(globalObject, newTarget);\n\n  exports._internalSetup(wrapper, globalObject);\n  Object.defineProperty(wrapper, implSymbol, {\n    value: Object.create(Impl.implementation.prototype),\n    configurable: true\n  });\n\n  wrapper[implSymbol][utils.wrapperSymbol] = wrapper;\n  if (Impl.init) {\n    Impl.init(wrapper[implSymbol]);\n  }\n  return wrapper[implSymbol];\n};\n\nconst exposed = new Set([\"Window\", \"Worker\"]);\n\nexports.install = (globalObject, globalNames) => {\n  if (!globalNames.some(globalName => exposed.has(globalName))) {\n    return;\n  }\n\n  const ctorRegistry = utils.initCtorRegistry(globalObject);\n  class URL {\n    constructor(url) {\n      if (arguments.length < 1) {\n        throw new globalObject.TypeError(\n          `Failed to construct 'URL': 1 argument required, but only ${arguments.length} present.`\n        );\n      }\n      const args = [];\n      {\n        let curArg = arguments[0];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to construct 'URL': parameter 1\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      {\n        let curArg = arguments[1];\n        if (curArg !== undefined) {\n          curArg = conversions[\"USVString\"](curArg, {\n            context: \"Failed to construct 'URL': parameter 2\",\n            globals: globalObject\n          });\n        }\n        args.push(curArg);\n      }\n      return exports.setup(Object.create(new.target.prototype), globalObject, args);\n    }\n\n    toJSON() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'toJSON' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol].toJSON();\n    }\n\n    get href() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get href' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"href\"];\n    }\n\n    set href(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set href' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'href' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"href\"] = V;\n    }\n\n    toString() {\n      const esValue = this;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'toString' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"href\"];\n    }\n\n    get origin() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get origin' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"origin\"];\n    }\n\n    get protocol() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get protocol' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"protocol\"];\n    }\n\n    set protocol(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set protocol' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'protocol' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"protocol\"] = V;\n    }\n\n    get username() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get username' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"username\"];\n    }\n\n    set username(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set username' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'username' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"username\"] = V;\n    }\n\n    get password() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get password' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"password\"];\n    }\n\n    set password(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set password' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'password' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"password\"] = V;\n    }\n\n    get host() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get host' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"host\"];\n    }\n\n    set host(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set host' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'host' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"host\"] = V;\n    }\n\n    get hostname() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get hostname' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"hostname\"];\n    }\n\n    set hostname(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set hostname' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'hostname' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"hostname\"] = V;\n    }\n\n    get port() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get port' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"port\"];\n    }\n\n    set port(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set port' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'port' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"port\"] = V;\n    }\n\n    get pathname() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get pathname' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"pathname\"];\n    }\n\n    set pathname(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set pathname' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'pathname' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"pathname\"] = V;\n    }\n\n    get search() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get search' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"search\"];\n    }\n\n    set search(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set search' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'search' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"search\"] = V;\n    }\n\n    get searchParams() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get searchParams' called on an object that is not a valid instance of URL.\");\n      }\n\n      return utils.getSameObject(this, \"searchParams\", () => {\n        return utils.tryWrapperForImpl(esValue[implSymbol][\"searchParams\"]);\n      });\n    }\n\n    get hash() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get hash' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"hash\"];\n    }\n\n    set hash(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set hash' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'hash' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"hash\"] = V;\n    }\n\n    static canParse(url) {\n      if (arguments.length < 1) {\n        throw new globalObject.TypeError(\n          `Failed to execute 'canParse' on 'URL': 1 argument required, but only ${arguments.length} present.`\n        );\n      }\n      const args = [];\n      {\n        let curArg = arguments[0];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'canParse' on 'URL': parameter 1\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      {\n        let curArg = arguments[1];\n        if (curArg !== undefined) {\n          curArg = conversions[\"USVString\"](curArg, {\n            context: \"Failed to execute 'canParse' on 'URL': parameter 2\",\n            globals: globalObject\n          });\n        }\n        args.push(curArg);\n      }\n      return Impl.implementation.canParse(...args);\n    }\n  }\n  Object.defineProperties(URL.prototype, {\n    toJSON: { enumerable: true },\n    href: { enumerable: true },\n    toString: { enumerable: true },\n    origin: { enumerable: true },\n    protocol: { enumerable: true },\n    username: { enumerable: true },\n    password: { enumerable: true },\n    host: { enumerable: true },\n    hostname: { enumerable: true },\n    port: { enumerable: true },\n    pathname: { enumerable: true },\n    search: { enumerable: true },\n    searchParams: { enumerable: true },\n    hash: { enumerable: true },\n    [Symbol.toStringTag]: { value: \"URL\", configurable: true }\n  });\n  Object.defineProperties(URL, { canParse: { enumerable: true } });\n  ctorRegistry[interfaceName] = URL;\n\n  Object.defineProperty(globalObject, interfaceName, {\n    configurable: true,\n    writable: true,\n    value: URL\n  });\n\n  if (globalNames.includes(\"Window\")) {\n    Object.defineProperty(globalObject, \"webkitURL\", {\n      configurable: true,\n      writable: true,\n      value: URL\n    });\n  }\n};\n\nconst Impl = __webpack_require__(/*! ./URL-impl.js */ \"./node_modules/whatwg-url/lib/URL-impl.js\");\n\n\n//# sourceURL=webpack://experimento/./node_modules/whatwg-url/lib/URL.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/lib/URLSearchParams-impl.js":
/*!*************************************************************!*\
  !*** ./node_modules/whatwg-url/lib/URLSearchParams-impl.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nconst urlencoded = __webpack_require__(/*! ./urlencoded */ \"./node_modules/whatwg-url/lib/urlencoded.js\");\n\nexports.implementation = class URLSearchParamsImpl {\n  constructor(globalObject, constructorArgs, { doNotStripQMark = false }) {\n    let init = constructorArgs[0];\n    this._list = [];\n    this._url = null;\n\n    if (!doNotStripQMark && typeof init === \"string\" && init[0] === \"?\") {\n      init = init.slice(1);\n    }\n\n    if (Array.isArray(init)) {\n      for (const pair of init) {\n        if (pair.length !== 2) {\n          throw new TypeError(\"Failed to construct 'URLSearchParams': parameter 1 sequence's element does not \" +\n                              \"contain exactly two elements.\");\n        }\n        this._list.push([pair[0], pair[1]]);\n      }\n    } else if (typeof init === \"object\" && Object.getPrototypeOf(init) === null) {\n      for (const name of Object.keys(init)) {\n        const value = init[name];\n        this._list.push([name, value]);\n      }\n    } else {\n      this._list = urlencoded.parseUrlencodedString(init);\n    }\n  }\n\n  _updateSteps() {\n    if (this._url !== null) {\n      let serializedQuery = urlencoded.serializeUrlencoded(this._list);\n      if (serializedQuery === \"\") {\n        serializedQuery = null;\n      }\n\n      this._url._url.query = serializedQuery;\n\n      if (serializedQuery === null) {\n        this._url._potentiallyStripTrailingSpacesFromAnOpaquePath();\n      }\n    }\n  }\n\n  get size() {\n    return this._list.length;\n  }\n\n  append(name, value) {\n    this._list.push([name, value]);\n    this._updateSteps();\n  }\n\n  delete(name, value) {\n    let i = 0;\n    while (i < this._list.length) {\n      if (this._list[i][0] === name && (value === undefined || this._list[i][1] === value)) {\n        this._list.splice(i, 1);\n      } else {\n        i++;\n      }\n    }\n    this._updateSteps();\n  }\n\n  get(name) {\n    for (const tuple of this._list) {\n      if (tuple[0] === name) {\n        return tuple[1];\n      }\n    }\n    return null;\n  }\n\n  getAll(name) {\n    const output = [];\n    for (const tuple of this._list) {\n      if (tuple[0] === name) {\n        output.push(tuple[1]);\n      }\n    }\n    return output;\n  }\n\n  has(name, value) {\n    for (const tuple of this._list) {\n      if (tuple[0] === name && (value === undefined || tuple[1] === value)) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  set(name, value) {\n    let found = false;\n    let i = 0;\n    while (i < this._list.length) {\n      if (this._list[i][0] === name) {\n        if (found) {\n          this._list.splice(i, 1);\n        } else {\n          found = true;\n          this._list[i][1] = value;\n          i++;\n        }\n      } else {\n        i++;\n      }\n    }\n    if (!found) {\n      this._list.push([name, value]);\n    }\n    this._updateSteps();\n  }\n\n  sort() {\n    this._list.sort((a, b) => {\n      if (a[0] < b[0]) {\n        return -1;\n      }\n      if (a[0] > b[0]) {\n        return 1;\n      }\n      return 0;\n    });\n\n    this._updateSteps();\n  }\n\n  [Symbol.iterator]() {\n    return this._list[Symbol.iterator]();\n  }\n\n  toString() {\n    return urlencoded.serializeUrlencoded(this._list);\n  }\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/whatwg-url/lib/URLSearchParams-impl.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/lib/URLSearchParams.js":
/*!********************************************************!*\
  !*** ./node_modules/whatwg-url/lib/URLSearchParams.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nconst conversions = __webpack_require__(/*! webidl-conversions */ \"./node_modules/webidl-conversions/lib/index.js\");\nconst utils = __webpack_require__(/*! ./utils.js */ \"./node_modules/whatwg-url/lib/utils.js\");\n\nconst Function = __webpack_require__(/*! ./Function.js */ \"./node_modules/whatwg-url/lib/Function.js\");\nconst newObjectInRealm = utils.newObjectInRealm;\nconst implSymbol = utils.implSymbol;\nconst ctorRegistrySymbol = utils.ctorRegistrySymbol;\n\nconst interfaceName = \"URLSearchParams\";\n\nexports.is = value => {\n  return utils.isObject(value) && utils.hasOwn(value, implSymbol) && value[implSymbol] instanceof Impl.implementation;\n};\nexports.isImpl = value => {\n  return utils.isObject(value) && value instanceof Impl.implementation;\n};\nexports.convert = (globalObject, value, { context = \"The provided value\" } = {}) => {\n  if (exports.is(value)) {\n    return utils.implForWrapper(value);\n  }\n  throw new globalObject.TypeError(`${context} is not of type 'URLSearchParams'.`);\n};\n\nexports.createDefaultIterator = (globalObject, target, kind) => {\n  const ctorRegistry = globalObject[ctorRegistrySymbol];\n  const iteratorPrototype = ctorRegistry[\"URLSearchParams Iterator\"];\n  const iterator = Object.create(iteratorPrototype);\n  Object.defineProperty(iterator, utils.iterInternalSymbol, {\n    value: { target, kind, index: 0 },\n    configurable: true\n  });\n  return iterator;\n};\n\nfunction makeWrapper(globalObject, newTarget) {\n  let proto;\n  if (newTarget !== undefined) {\n    proto = newTarget.prototype;\n  }\n\n  if (!utils.isObject(proto)) {\n    proto = globalObject[ctorRegistrySymbol][\"URLSearchParams\"].prototype;\n  }\n\n  return Object.create(proto);\n}\n\nexports.create = (globalObject, constructorArgs, privateData) => {\n  const wrapper = makeWrapper(globalObject);\n  return exports.setup(wrapper, globalObject, constructorArgs, privateData);\n};\n\nexports.createImpl = (globalObject, constructorArgs, privateData) => {\n  const wrapper = exports.create(globalObject, constructorArgs, privateData);\n  return utils.implForWrapper(wrapper);\n};\n\nexports._internalSetup = (wrapper, globalObject) => {};\n\nexports.setup = (wrapper, globalObject, constructorArgs = [], privateData = {}) => {\n  privateData.wrapper = wrapper;\n\n  exports._internalSetup(wrapper, globalObject);\n  Object.defineProperty(wrapper, implSymbol, {\n    value: new Impl.implementation(globalObject, constructorArgs, privateData),\n    configurable: true\n  });\n\n  wrapper[implSymbol][utils.wrapperSymbol] = wrapper;\n  if (Impl.init) {\n    Impl.init(wrapper[implSymbol]);\n  }\n  return wrapper;\n};\n\nexports[\"new\"] = (globalObject, newTarget) => {\n  const wrapper = makeWrapper(globalObject, newTarget);\n\n  exports._internalSetup(wrapper, globalObject);\n  Object.defineProperty(wrapper, implSymbol, {\n    value: Object.create(Impl.implementation.prototype),\n    configurable: true\n  });\n\n  wrapper[implSymbol][utils.wrapperSymbol] = wrapper;\n  if (Impl.init) {\n    Impl.init(wrapper[implSymbol]);\n  }\n  return wrapper[implSymbol];\n};\n\nconst exposed = new Set([\"Window\", \"Worker\"]);\n\nexports.install = (globalObject, globalNames) => {\n  if (!globalNames.some(globalName => exposed.has(globalName))) {\n    return;\n  }\n\n  const ctorRegistry = utils.initCtorRegistry(globalObject);\n  class URLSearchParams {\n    constructor() {\n      const args = [];\n      {\n        let curArg = arguments[0];\n        if (curArg !== undefined) {\n          if (utils.isObject(curArg)) {\n            if (curArg[Symbol.iterator] !== undefined) {\n              if (!utils.isObject(curArg)) {\n                throw new globalObject.TypeError(\n                  \"Failed to construct 'URLSearchParams': parameter 1\" + \" sequence\" + \" is not an iterable object.\"\n                );\n              } else {\n                const V = [];\n                const tmp = curArg;\n                for (let nextItem of tmp) {\n                  if (!utils.isObject(nextItem)) {\n                    throw new globalObject.TypeError(\n                      \"Failed to construct 'URLSearchParams': parameter 1\" +\n                        \" sequence\" +\n                        \"'s element\" +\n                        \" is not an iterable object.\"\n                    );\n                  } else {\n                    const V = [];\n                    const tmp = nextItem;\n                    for (let nextItem of tmp) {\n                      nextItem = conversions[\"USVString\"](nextItem, {\n                        context:\n                          \"Failed to construct 'URLSearchParams': parameter 1\" +\n                          \" sequence\" +\n                          \"'s element\" +\n                          \"'s element\",\n                        globals: globalObject\n                      });\n\n                      V.push(nextItem);\n                    }\n                    nextItem = V;\n                  }\n\n                  V.push(nextItem);\n                }\n                curArg = V;\n              }\n            } else {\n              if (!utils.isObject(curArg)) {\n                throw new globalObject.TypeError(\n                  \"Failed to construct 'URLSearchParams': parameter 1\" + \" record\" + \" is not an object.\"\n                );\n              } else {\n                const result = Object.create(null);\n                for (const key of Reflect.ownKeys(curArg)) {\n                  const desc = Object.getOwnPropertyDescriptor(curArg, key);\n                  if (desc && desc.enumerable) {\n                    let typedKey = key;\n\n                    typedKey = conversions[\"USVString\"](typedKey, {\n                      context: \"Failed to construct 'URLSearchParams': parameter 1\" + \" record\" + \"'s key\",\n                      globals: globalObject\n                    });\n\n                    let typedValue = curArg[key];\n\n                    typedValue = conversions[\"USVString\"](typedValue, {\n                      context: \"Failed to construct 'URLSearchParams': parameter 1\" + \" record\" + \"'s value\",\n                      globals: globalObject\n                    });\n\n                    result[typedKey] = typedValue;\n                  }\n                }\n                curArg = result;\n              }\n            }\n          } else {\n            curArg = conversions[\"USVString\"](curArg, {\n              context: \"Failed to construct 'URLSearchParams': parameter 1\",\n              globals: globalObject\n            });\n          }\n        } else {\n          curArg = \"\";\n        }\n        args.push(curArg);\n      }\n      return exports.setup(Object.create(new.target.prototype), globalObject, args);\n    }\n\n    append(name, value) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\n          \"'append' called on an object that is not a valid instance of URLSearchParams.\"\n        );\n      }\n\n      if (arguments.length < 2) {\n        throw new globalObject.TypeError(\n          `Failed to execute 'append' on 'URLSearchParams': 2 arguments required, but only ${arguments.length} present.`\n        );\n      }\n      const args = [];\n      {\n        let curArg = arguments[0];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'append' on 'URLSearchParams': parameter 1\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      {\n        let curArg = arguments[1];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'append' on 'URLSearchParams': parameter 2\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      return utils.tryWrapperForImpl(esValue[implSymbol].append(...args));\n    }\n\n    delete(name) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\n          \"'delete' called on an object that is not a valid instance of URLSearchParams.\"\n        );\n      }\n\n      if (arguments.length < 1) {\n        throw new globalObject.TypeError(\n          `Failed to execute 'delete' on 'URLSearchParams': 1 argument required, but only ${arguments.length} present.`\n        );\n      }\n      const args = [];\n      {\n        let curArg = arguments[0];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'delete' on 'URLSearchParams': parameter 1\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      {\n        let curArg = arguments[1];\n        if (curArg !== undefined) {\n          curArg = conversions[\"USVString\"](curArg, {\n            context: \"Failed to execute 'delete' on 'URLSearchParams': parameter 2\",\n            globals: globalObject\n          });\n        }\n        args.push(curArg);\n      }\n      return utils.tryWrapperForImpl(esValue[implSymbol].delete(...args));\n    }\n\n    get(name) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get' called on an object that is not a valid instance of URLSearchParams.\");\n      }\n\n      if (arguments.length < 1) {\n        throw new globalObject.TypeError(\n          `Failed to execute 'get' on 'URLSearchParams': 1 argument required, but only ${arguments.length} present.`\n        );\n      }\n      const args = [];\n      {\n        let curArg = arguments[0];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'get' on 'URLSearchParams': parameter 1\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      return esValue[implSymbol].get(...args);\n    }\n\n    getAll(name) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\n          \"'getAll' called on an object that is not a valid instance of URLSearchParams.\"\n        );\n      }\n\n      if (arguments.length < 1) {\n        throw new globalObject.TypeError(\n          `Failed to execute 'getAll' on 'URLSearchParams': 1 argument required, but only ${arguments.length} present.`\n        );\n      }\n      const args = [];\n      {\n        let curArg = arguments[0];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'getAll' on 'URLSearchParams': parameter 1\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      return utils.tryWrapperForImpl(esValue[implSymbol].getAll(...args));\n    }\n\n    has(name) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'has' called on an object that is not a valid instance of URLSearchParams.\");\n      }\n\n      if (arguments.length < 1) {\n        throw new globalObject.TypeError(\n          `Failed to execute 'has' on 'URLSearchParams': 1 argument required, but only ${arguments.length} present.`\n        );\n      }\n      const args = [];\n      {\n        let curArg = arguments[0];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'has' on 'URLSearchParams': parameter 1\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      {\n        let curArg = arguments[1];\n        if (curArg !== undefined) {\n          curArg = conversions[\"USVString\"](curArg, {\n            context: \"Failed to execute 'has' on 'URLSearchParams': parameter 2\",\n            globals: globalObject\n          });\n        }\n        args.push(curArg);\n      }\n      return esValue[implSymbol].has(...args);\n    }\n\n    set(name, value) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set' called on an object that is not a valid instance of URLSearchParams.\");\n      }\n\n      if (arguments.length < 2) {\n        throw new globalObject.TypeError(\n          `Failed to execute 'set' on 'URLSearchParams': 2 arguments required, but only ${arguments.length} present.`\n        );\n      }\n      const args = [];\n      {\n        let curArg = arguments[0];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'set' on 'URLSearchParams': parameter 1\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      {\n        let curArg = arguments[1];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'set' on 'URLSearchParams': parameter 2\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      return utils.tryWrapperForImpl(esValue[implSymbol].set(...args));\n    }\n\n    sort() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'sort' called on an object that is not a valid instance of URLSearchParams.\");\n      }\n\n      return utils.tryWrapperForImpl(esValue[implSymbol].sort());\n    }\n\n    toString() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\n          \"'toString' called on an object that is not a valid instance of URLSearchParams.\"\n        );\n      }\n\n      return esValue[implSymbol].toString();\n    }\n\n    keys() {\n      if (!exports.is(this)) {\n        throw new globalObject.TypeError(\"'keys' called on an object that is not a valid instance of URLSearchParams.\");\n      }\n      return exports.createDefaultIterator(globalObject, this, \"key\");\n    }\n\n    values() {\n      if (!exports.is(this)) {\n        throw new globalObject.TypeError(\n          \"'values' called on an object that is not a valid instance of URLSearchParams.\"\n        );\n      }\n      return exports.createDefaultIterator(globalObject, this, \"value\");\n    }\n\n    entries() {\n      if (!exports.is(this)) {\n        throw new globalObject.TypeError(\n          \"'entries' called on an object that is not a valid instance of URLSearchParams.\"\n        );\n      }\n      return exports.createDefaultIterator(globalObject, this, \"key+value\");\n    }\n\n    forEach(callback) {\n      if (!exports.is(this)) {\n        throw new globalObject.TypeError(\n          \"'forEach' called on an object that is not a valid instance of URLSearchParams.\"\n        );\n      }\n      if (arguments.length < 1) {\n        throw new globalObject.TypeError(\n          \"Failed to execute 'forEach' on 'iterable': 1 argument required, but only 0 present.\"\n        );\n      }\n      callback = Function.convert(globalObject, callback, {\n        context: \"Failed to execute 'forEach' on 'iterable': The callback provided as parameter 1\"\n      });\n      const thisArg = arguments[1];\n      let pairs = Array.from(this[implSymbol]);\n      let i = 0;\n      while (i < pairs.length) {\n        const [key, value] = pairs[i].map(utils.tryWrapperForImpl);\n        callback.call(thisArg, value, key, this);\n        pairs = Array.from(this[implSymbol]);\n        i++;\n      }\n    }\n\n    get size() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\n          \"'get size' called on an object that is not a valid instance of URLSearchParams.\"\n        );\n      }\n\n      return esValue[implSymbol][\"size\"];\n    }\n  }\n  Object.defineProperties(URLSearchParams.prototype, {\n    append: { enumerable: true },\n    delete: { enumerable: true },\n    get: { enumerable: true },\n    getAll: { enumerable: true },\n    has: { enumerable: true },\n    set: { enumerable: true },\n    sort: { enumerable: true },\n    toString: { enumerable: true },\n    keys: { enumerable: true },\n    values: { enumerable: true },\n    entries: { enumerable: true },\n    forEach: { enumerable: true },\n    size: { enumerable: true },\n    [Symbol.toStringTag]: { value: \"URLSearchParams\", configurable: true },\n    [Symbol.iterator]: { value: URLSearchParams.prototype.entries, configurable: true, writable: true }\n  });\n  ctorRegistry[interfaceName] = URLSearchParams;\n\n  ctorRegistry[\"URLSearchParams Iterator\"] = Object.create(ctorRegistry[\"%IteratorPrototype%\"], {\n    [Symbol.toStringTag]: {\n      configurable: true,\n      value: \"URLSearchParams Iterator\"\n    }\n  });\n  utils.define(ctorRegistry[\"URLSearchParams Iterator\"], {\n    next() {\n      const internal = this && this[utils.iterInternalSymbol];\n      if (!internal) {\n        throw new globalObject.TypeError(\"next() called on a value that is not a URLSearchParams iterator object\");\n      }\n\n      const { target, kind, index } = internal;\n      const values = Array.from(target[implSymbol]);\n      const len = values.length;\n      if (index >= len) {\n        return newObjectInRealm(globalObject, { value: undefined, done: true });\n      }\n\n      const pair = values[index];\n      internal.index = index + 1;\n      return newObjectInRealm(globalObject, utils.iteratorResult(pair.map(utils.tryWrapperForImpl), kind));\n    }\n  });\n\n  Object.defineProperty(globalObject, interfaceName, {\n    configurable: true,\n    writable: true,\n    value: URLSearchParams\n  });\n};\n\nconst Impl = __webpack_require__(/*! ./URLSearchParams-impl.js */ \"./node_modules/whatwg-url/lib/URLSearchParams-impl.js\");\n\n\n//# sourceURL=webpack://experimento/./node_modules/whatwg-url/lib/URLSearchParams.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/lib/encoding.js":
/*!*************************************************!*\
  !*** ./node_modules/whatwg-url/lib/encoding.js ***!
  \*************************************************/
/***/ ((module) => {

"use strict";
eval("\nconst utf8Encoder = new TextEncoder();\nconst utf8Decoder = new TextDecoder(\"utf-8\", { ignoreBOM: true });\n\nfunction utf8Encode(string) {\n  return utf8Encoder.encode(string);\n}\n\nfunction utf8DecodeWithoutBOM(bytes) {\n  return utf8Decoder.decode(bytes);\n}\n\nmodule.exports = {\n  utf8Encode,\n  utf8DecodeWithoutBOM\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/whatwg-url/lib/encoding.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/lib/infra.js":
/*!**********************************************!*\
  !*** ./node_modules/whatwg-url/lib/infra.js ***!
  \**********************************************/
/***/ ((module) => {

"use strict";
eval("\n\n// Note that we take code points as JS numbers, not JS strings.\n\nfunction isASCIIDigit(c) {\n  return c >= 0x30 && c <= 0x39;\n}\n\nfunction isASCIIAlpha(c) {\n  return (c >= 0x41 && c <= 0x5A) || (c >= 0x61 && c <= 0x7A);\n}\n\nfunction isASCIIAlphanumeric(c) {\n  return isASCIIAlpha(c) || isASCIIDigit(c);\n}\n\nfunction isASCIIHex(c) {\n  return isASCIIDigit(c) || (c >= 0x41 && c <= 0x46) || (c >= 0x61 && c <= 0x66);\n}\n\nmodule.exports = {\n  isASCIIDigit,\n  isASCIIAlpha,\n  isASCIIAlphanumeric,\n  isASCIIHex\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/whatwg-url/lib/infra.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/lib/percent-encoding.js":
/*!*********************************************************!*\
  !*** ./node_modules/whatwg-url/lib/percent-encoding.js ***!
  \*********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst { isASCIIHex } = __webpack_require__(/*! ./infra */ \"./node_modules/whatwg-url/lib/infra.js\");\nconst { utf8Encode } = __webpack_require__(/*! ./encoding */ \"./node_modules/whatwg-url/lib/encoding.js\");\n\nfunction p(char) {\n  return char.codePointAt(0);\n}\n\n// https://url.spec.whatwg.org/#percent-encode\nfunction percentEncode(c) {\n  let hex = c.toString(16).toUpperCase();\n  if (hex.length === 1) {\n    hex = `0${hex}`;\n  }\n\n  return `%${hex}`;\n}\n\n// https://url.spec.whatwg.org/#percent-decode\nfunction percentDecodeBytes(input) {\n  const output = new Uint8Array(input.byteLength);\n  let outputIndex = 0;\n  for (let i = 0; i < input.byteLength; ++i) {\n    const byte = input[i];\n    if (byte !== 0x25) {\n      output[outputIndex++] = byte;\n    } else if (byte === 0x25 && (!isASCIIHex(input[i + 1]) || !isASCIIHex(input[i + 2]))) {\n      output[outputIndex++] = byte;\n    } else {\n      const bytePoint = parseInt(String.fromCodePoint(input[i + 1], input[i + 2]), 16);\n      output[outputIndex++] = bytePoint;\n      i += 2;\n    }\n  }\n\n  return output.slice(0, outputIndex);\n}\n\n// https://url.spec.whatwg.org/#string-percent-decode\nfunction percentDecodeString(input) {\n  const bytes = utf8Encode(input);\n  return percentDecodeBytes(bytes);\n}\n\n// https://url.spec.whatwg.org/#c0-control-percent-encode-set\nfunction isC0ControlPercentEncode(c) {\n  return c <= 0x1F || c > 0x7E;\n}\n\n// https://url.spec.whatwg.org/#fragment-percent-encode-set\nconst extraFragmentPercentEncodeSet = new Set([p(\" \"), p(\"\\\"\"), p(\"<\"), p(\">\"), p(\"`\")]);\nfunction isFragmentPercentEncode(c) {\n  return isC0ControlPercentEncode(c) || extraFragmentPercentEncodeSet.has(c);\n}\n\n// https://url.spec.whatwg.org/#query-percent-encode-set\nconst extraQueryPercentEncodeSet = new Set([p(\" \"), p(\"\\\"\"), p(\"#\"), p(\"<\"), p(\">\")]);\nfunction isQueryPercentEncode(c) {\n  return isC0ControlPercentEncode(c) || extraQueryPercentEncodeSet.has(c);\n}\n\n// https://url.spec.whatwg.org/#special-query-percent-encode-set\nfunction isSpecialQueryPercentEncode(c) {\n  return isQueryPercentEncode(c) || c === p(\"'\");\n}\n\n// https://url.spec.whatwg.org/#path-percent-encode-set\nconst extraPathPercentEncodeSet = new Set([p(\"?\"), p(\"`\"), p(\"{\"), p(\"}\")]);\nfunction isPathPercentEncode(c) {\n  return isQueryPercentEncode(c) || extraPathPercentEncodeSet.has(c);\n}\n\n// https://url.spec.whatwg.org/#userinfo-percent-encode-set\nconst extraUserinfoPercentEncodeSet =\n  new Set([p(\"/\"), p(\":\"), p(\";\"), p(\"=\"), p(\"@\"), p(\"[\"), p(\"\\\\\"), p(\"]\"), p(\"^\"), p(\"|\")]);\nfunction isUserinfoPercentEncode(c) {\n  return isPathPercentEncode(c) || extraUserinfoPercentEncodeSet.has(c);\n}\n\n// https://url.spec.whatwg.org/#component-percent-encode-set\nconst extraComponentPercentEncodeSet = new Set([p(\"$\"), p(\"%\"), p(\"&\"), p(\"+\"), p(\",\")]);\nfunction isComponentPercentEncode(c) {\n  return isUserinfoPercentEncode(c) || extraComponentPercentEncodeSet.has(c);\n}\n\n// https://url.spec.whatwg.org/#application-x-www-form-urlencoded-percent-encode-set\nconst extraURLEncodedPercentEncodeSet = new Set([p(\"!\"), p(\"'\"), p(\"(\"), p(\")\"), p(\"~\")]);\nfunction isURLEncodedPercentEncode(c) {\n  return isComponentPercentEncode(c) || extraURLEncodedPercentEncodeSet.has(c);\n}\n\n// https://url.spec.whatwg.org/#code-point-percent-encode-after-encoding\n// https://url.spec.whatwg.org/#utf-8-percent-encode\n// Assuming encoding is always utf-8 allows us to trim one of the logic branches. TODO: support encoding.\n// The \"-Internal\" variant here has code points as JS strings. The external version used by other files has code points\n// as JS numbers, like the rest of the codebase.\nfunction utf8PercentEncodeCodePointInternal(codePoint, percentEncodePredicate) {\n  const bytes = utf8Encode(codePoint);\n  let output = \"\";\n  for (const byte of bytes) {\n    // Our percentEncodePredicate operates on bytes, not code points, so this is slightly different from the spec.\n    if (!percentEncodePredicate(byte)) {\n      output += String.fromCharCode(byte);\n    } else {\n      output += percentEncode(byte);\n    }\n  }\n\n  return output;\n}\n\nfunction utf8PercentEncodeCodePoint(codePoint, percentEncodePredicate) {\n  return utf8PercentEncodeCodePointInternal(String.fromCodePoint(codePoint), percentEncodePredicate);\n}\n\n// https://url.spec.whatwg.org/#string-percent-encode-after-encoding\n// https://url.spec.whatwg.org/#string-utf-8-percent-encode\nfunction utf8PercentEncodeString(input, percentEncodePredicate, spaceAsPlus = false) {\n  let output = \"\";\n  for (const codePoint of input) {\n    if (spaceAsPlus && codePoint === \" \") {\n      output += \"+\";\n    } else {\n      output += utf8PercentEncodeCodePointInternal(codePoint, percentEncodePredicate);\n    }\n  }\n  return output;\n}\n\nmodule.exports = {\n  isC0ControlPercentEncode,\n  isFragmentPercentEncode,\n  isQueryPercentEncode,\n  isSpecialQueryPercentEncode,\n  isPathPercentEncode,\n  isUserinfoPercentEncode,\n  isURLEncodedPercentEncode,\n  percentDecodeString,\n  percentDecodeBytes,\n  utf8PercentEncodeString,\n  utf8PercentEncodeCodePoint\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/whatwg-url/lib/percent-encoding.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/lib/url-state-machine.js":
/*!**********************************************************!*\
  !*** ./node_modules/whatwg-url/lib/url-state-machine.js ***!
  \**********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst tr46 = __webpack_require__(/*! tr46 */ \"./node_modules/tr46/index.js\");\n\nconst infra = __webpack_require__(/*! ./infra */ \"./node_modules/whatwg-url/lib/infra.js\");\nconst { utf8DecodeWithoutBOM } = __webpack_require__(/*! ./encoding */ \"./node_modules/whatwg-url/lib/encoding.js\");\nconst { percentDecodeString, utf8PercentEncodeCodePoint, utf8PercentEncodeString, isC0ControlPercentEncode,\n  isFragmentPercentEncode, isQueryPercentEncode, isSpecialQueryPercentEncode, isPathPercentEncode,\n  isUserinfoPercentEncode } = __webpack_require__(/*! ./percent-encoding */ \"./node_modules/whatwg-url/lib/percent-encoding.js\");\n\nfunction p(char) {\n  return char.codePointAt(0);\n}\n\nconst specialSchemes = {\n  ftp: 21,\n  file: null,\n  http: 80,\n  https: 443,\n  ws: 80,\n  wss: 443\n};\n\nconst failure = Symbol(\"failure\");\n\nfunction countSymbols(str) {\n  return [...str].length;\n}\n\nfunction at(input, idx) {\n  const c = input[idx];\n  return isNaN(c) ? undefined : String.fromCodePoint(c);\n}\n\nfunction isSingleDot(buffer) {\n  return buffer === \".\" || buffer.toLowerCase() === \"%2e\";\n}\n\nfunction isDoubleDot(buffer) {\n  buffer = buffer.toLowerCase();\n  return buffer === \"..\" || buffer === \"%2e.\" || buffer === \".%2e\" || buffer === \"%2e%2e\";\n}\n\nfunction isWindowsDriveLetterCodePoints(cp1, cp2) {\n  return infra.isASCIIAlpha(cp1) && (cp2 === p(\":\") || cp2 === p(\"|\"));\n}\n\nfunction isWindowsDriveLetterString(string) {\n  return string.length === 2 && infra.isASCIIAlpha(string.codePointAt(0)) && (string[1] === \":\" || string[1] === \"|\");\n}\n\nfunction isNormalizedWindowsDriveLetterString(string) {\n  return string.length === 2 && infra.isASCIIAlpha(string.codePointAt(0)) && string[1] === \":\";\n}\n\nfunction containsForbiddenHostCodePoint(string) {\n  return string.search(/\\u0000|\\u0009|\\u000A|\\u000D|\\u0020|#|\\/|:|<|>|\\?|@|\\[|\\\\|\\]|\\^|\\|/u) !== -1;\n}\n\nfunction containsForbiddenDomainCodePoint(string) {\n  return containsForbiddenHostCodePoint(string) || string.search(/[\\u0000-\\u001F]|%|\\u007F/u) !== -1;\n}\n\nfunction isSpecialScheme(scheme) {\n  return specialSchemes[scheme] !== undefined;\n}\n\nfunction isSpecial(url) {\n  return isSpecialScheme(url.scheme);\n}\n\nfunction isNotSpecial(url) {\n  return !isSpecialScheme(url.scheme);\n}\n\nfunction defaultPort(scheme) {\n  return specialSchemes[scheme];\n}\n\nfunction parseIPv4Number(input) {\n  if (input === \"\") {\n    return failure;\n  }\n\n  let R = 10;\n\n  if (input.length >= 2 && input.charAt(0) === \"0\" && input.charAt(1).toLowerCase() === \"x\") {\n    input = input.substring(2);\n    R = 16;\n  } else if (input.length >= 2 && input.charAt(0) === \"0\") {\n    input = input.substring(1);\n    R = 8;\n  }\n\n  if (input === \"\") {\n    return 0;\n  }\n\n  let regex = /[^0-7]/u;\n  if (R === 10) {\n    regex = /[^0-9]/u;\n  }\n  if (R === 16) {\n    regex = /[^0-9A-Fa-f]/u;\n  }\n\n  if (regex.test(input)) {\n    return failure;\n  }\n\n  return parseInt(input, R);\n}\n\nfunction parseIPv4(input) {\n  const parts = input.split(\".\");\n  if (parts[parts.length - 1] === \"\") {\n    if (parts.length > 1) {\n      parts.pop();\n    }\n  }\n\n  if (parts.length > 4) {\n    return failure;\n  }\n\n  const numbers = [];\n  for (const part of parts) {\n    const n = parseIPv4Number(part);\n    if (n === failure) {\n      return failure;\n    }\n\n    numbers.push(n);\n  }\n\n  for (let i = 0; i < numbers.length - 1; ++i) {\n    if (numbers[i] > 255) {\n      return failure;\n    }\n  }\n  if (numbers[numbers.length - 1] >= 256 ** (5 - numbers.length)) {\n    return failure;\n  }\n\n  let ipv4 = numbers.pop();\n  let counter = 0;\n\n  for (const n of numbers) {\n    ipv4 += n * 256 ** (3 - counter);\n    ++counter;\n  }\n\n  return ipv4;\n}\n\nfunction serializeIPv4(address) {\n  let output = \"\";\n  let n = address;\n\n  for (let i = 1; i <= 4; ++i) {\n    output = String(n % 256) + output;\n    if (i !== 4) {\n      output = `.${output}`;\n    }\n    n = Math.floor(n / 256);\n  }\n\n  return output;\n}\n\nfunction parseIPv6(input) {\n  const address = [0, 0, 0, 0, 0, 0, 0, 0];\n  let pieceIndex = 0;\n  let compress = null;\n  let pointer = 0;\n\n  input = Array.from(input, c => c.codePointAt(0));\n\n  if (input[pointer] === p(\":\")) {\n    if (input[pointer + 1] !== p(\":\")) {\n      return failure;\n    }\n\n    pointer += 2;\n    ++pieceIndex;\n    compress = pieceIndex;\n  }\n\n  while (pointer < input.length) {\n    if (pieceIndex === 8) {\n      return failure;\n    }\n\n    if (input[pointer] === p(\":\")) {\n      if (compress !== null) {\n        return failure;\n      }\n      ++pointer;\n      ++pieceIndex;\n      compress = pieceIndex;\n      continue;\n    }\n\n    let value = 0;\n    let length = 0;\n\n    while (length < 4 && infra.isASCIIHex(input[pointer])) {\n      value = value * 0x10 + parseInt(at(input, pointer), 16);\n      ++pointer;\n      ++length;\n    }\n\n    if (input[pointer] === p(\".\")) {\n      if (length === 0) {\n        return failure;\n      }\n\n      pointer -= length;\n\n      if (pieceIndex > 6) {\n        return failure;\n      }\n\n      let numbersSeen = 0;\n\n      while (input[pointer] !== undefined) {\n        let ipv4Piece = null;\n\n        if (numbersSeen > 0) {\n          if (input[pointer] === p(\".\") && numbersSeen < 4) {\n            ++pointer;\n          } else {\n            return failure;\n          }\n        }\n\n        if (!infra.isASCIIDigit(input[pointer])) {\n          return failure;\n        }\n\n        while (infra.isASCIIDigit(input[pointer])) {\n          const number = parseInt(at(input, pointer));\n          if (ipv4Piece === null) {\n            ipv4Piece = number;\n          } else if (ipv4Piece === 0) {\n            return failure;\n          } else {\n            ipv4Piece = ipv4Piece * 10 + number;\n          }\n          if (ipv4Piece > 255) {\n            return failure;\n          }\n          ++pointer;\n        }\n\n        address[pieceIndex] = address[pieceIndex] * 0x100 + ipv4Piece;\n\n        ++numbersSeen;\n\n        if (numbersSeen === 2 || numbersSeen === 4) {\n          ++pieceIndex;\n        }\n      }\n\n      if (numbersSeen !== 4) {\n        return failure;\n      }\n\n      break;\n    } else if (input[pointer] === p(\":\")) {\n      ++pointer;\n      if (input[pointer] === undefined) {\n        return failure;\n      }\n    } else if (input[pointer] !== undefined) {\n      return failure;\n    }\n\n    address[pieceIndex] = value;\n    ++pieceIndex;\n  }\n\n  if (compress !== null) {\n    let swaps = pieceIndex - compress;\n    pieceIndex = 7;\n    while (pieceIndex !== 0 && swaps > 0) {\n      const temp = address[compress + swaps - 1];\n      address[compress + swaps - 1] = address[pieceIndex];\n      address[pieceIndex] = temp;\n      --pieceIndex;\n      --swaps;\n    }\n  } else if (compress === null && pieceIndex !== 8) {\n    return failure;\n  }\n\n  return address;\n}\n\nfunction serializeIPv6(address) {\n  let output = \"\";\n  const compress = findLongestZeroSequence(address);\n  let ignore0 = false;\n\n  for (let pieceIndex = 0; pieceIndex <= 7; ++pieceIndex) {\n    if (ignore0 && address[pieceIndex] === 0) {\n      continue;\n    } else if (ignore0) {\n      ignore0 = false;\n    }\n\n    if (compress === pieceIndex) {\n      const separator = pieceIndex === 0 ? \"::\" : \":\";\n      output += separator;\n      ignore0 = true;\n      continue;\n    }\n\n    output += address[pieceIndex].toString(16);\n\n    if (pieceIndex !== 7) {\n      output += \":\";\n    }\n  }\n\n  return output;\n}\n\nfunction parseHost(input, isNotSpecialArg = false) {\n  if (input[0] === \"[\") {\n    if (input[input.length - 1] !== \"]\") {\n      return failure;\n    }\n\n    return parseIPv6(input.substring(1, input.length - 1));\n  }\n\n  if (isNotSpecialArg) {\n    return parseOpaqueHost(input);\n  }\n\n  const domain = utf8DecodeWithoutBOM(percentDecodeString(input));\n  const asciiDomain = domainToASCII(domain);\n  if (asciiDomain === failure) {\n    return failure;\n  }\n\n  if (containsForbiddenDomainCodePoint(asciiDomain)) {\n    return failure;\n  }\n\n  if (endsInANumber(asciiDomain)) {\n    return parseIPv4(asciiDomain);\n  }\n\n  return asciiDomain;\n}\n\nfunction endsInANumber(input) {\n  const parts = input.split(\".\");\n  if (parts[parts.length - 1] === \"\") {\n    if (parts.length === 1) {\n      return false;\n    }\n    parts.pop();\n  }\n\n  const last = parts[parts.length - 1];\n  if (parseIPv4Number(last) !== failure) {\n    return true;\n  }\n\n  if (/^[0-9]+$/u.test(last)) {\n    return true;\n  }\n\n  return false;\n}\n\nfunction parseOpaqueHost(input) {\n  if (containsForbiddenHostCodePoint(input)) {\n    return failure;\n  }\n\n  return utf8PercentEncodeString(input, isC0ControlPercentEncode);\n}\n\nfunction findLongestZeroSequence(arr) {\n  let maxIdx = null;\n  let maxLen = 1; // only find elements > 1\n  let currStart = null;\n  let currLen = 0;\n\n  for (let i = 0; i < arr.length; ++i) {\n    if (arr[i] !== 0) {\n      if (currLen > maxLen) {\n        maxIdx = currStart;\n        maxLen = currLen;\n      }\n\n      currStart = null;\n      currLen = 0;\n    } else {\n      if (currStart === null) {\n        currStart = i;\n      }\n      ++currLen;\n    }\n  }\n\n  // if trailing zeros\n  if (currLen > maxLen) {\n    return currStart;\n  }\n\n  return maxIdx;\n}\n\nfunction serializeHost(host) {\n  if (typeof host === \"number\") {\n    return serializeIPv4(host);\n  }\n\n  // IPv6 serializer\n  if (host instanceof Array) {\n    return `[${serializeIPv6(host)}]`;\n  }\n\n  return host;\n}\n\nfunction domainToASCII(domain, beStrict = false) {\n  const result = tr46.toASCII(domain, {\n    checkBidi: true,\n    checkHyphens: false,\n    checkJoiners: true,\n    useSTD3ASCIIRules: beStrict,\n    verifyDNSLength: beStrict\n  });\n  if (result === null || result === \"\") {\n    return failure;\n  }\n  return result;\n}\n\nfunction trimControlChars(url) {\n  return url.replace(/^[\\u0000-\\u001F\\u0020]+|[\\u0000-\\u001F\\u0020]+$/ug, \"\");\n}\n\nfunction trimTabAndNewline(url) {\n  return url.replace(/\\u0009|\\u000A|\\u000D/ug, \"\");\n}\n\nfunction shortenPath(url) {\n  const { path } = url;\n  if (path.length === 0) {\n    return;\n  }\n  if (url.scheme === \"file\" && path.length === 1 && isNormalizedWindowsDriveLetter(path[0])) {\n    return;\n  }\n\n  path.pop();\n}\n\nfunction includesCredentials(url) {\n  return url.username !== \"\" || url.password !== \"\";\n}\n\nfunction cannotHaveAUsernamePasswordPort(url) {\n  return url.host === null || url.host === \"\" || url.scheme === \"file\";\n}\n\nfunction hasAnOpaquePath(url) {\n  return typeof url.path === \"string\";\n}\n\nfunction isNormalizedWindowsDriveLetter(string) {\n  return /^[A-Za-z]:$/u.test(string);\n}\n\nfunction URLStateMachine(input, base, encodingOverride, url, stateOverride) {\n  this.pointer = 0;\n  this.input = input;\n  this.base = base || null;\n  this.encodingOverride = encodingOverride || \"utf-8\";\n  this.stateOverride = stateOverride;\n  this.url = url;\n  this.failure = false;\n  this.parseError = false;\n\n  if (!this.url) {\n    this.url = {\n      scheme: \"\",\n      username: \"\",\n      password: \"\",\n      host: null,\n      port: null,\n      path: [],\n      query: null,\n      fragment: null\n    };\n\n    const res = trimControlChars(this.input);\n    if (res !== this.input) {\n      this.parseError = true;\n    }\n    this.input = res;\n  }\n\n  const res = trimTabAndNewline(this.input);\n  if (res !== this.input) {\n    this.parseError = true;\n  }\n  this.input = res;\n\n  this.state = stateOverride || \"scheme start\";\n\n  this.buffer = \"\";\n  this.atFlag = false;\n  this.arrFlag = false;\n  this.passwordTokenSeenFlag = false;\n\n  this.input = Array.from(this.input, c => c.codePointAt(0));\n\n  for (; this.pointer <= this.input.length; ++this.pointer) {\n    const c = this.input[this.pointer];\n    const cStr = isNaN(c) ? undefined : String.fromCodePoint(c);\n\n    // exec state machine\n    const ret = this[`parse ${this.state}`](c, cStr);\n    if (!ret) {\n      break; // terminate algorithm\n    } else if (ret === failure) {\n      this.failure = true;\n      break;\n    }\n  }\n}\n\nURLStateMachine.prototype[\"parse scheme start\"] = function parseSchemeStart(c, cStr) {\n  if (infra.isASCIIAlpha(c)) {\n    this.buffer += cStr.toLowerCase();\n    this.state = \"scheme\";\n  } else if (!this.stateOverride) {\n    this.state = \"no scheme\";\n    --this.pointer;\n  } else {\n    this.parseError = true;\n    return failure;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse scheme\"] = function parseScheme(c, cStr) {\n  if (infra.isASCIIAlphanumeric(c) || c === p(\"+\") || c === p(\"-\") || c === p(\".\")) {\n    this.buffer += cStr.toLowerCase();\n  } else if (c === p(\":\")) {\n    if (this.stateOverride) {\n      if (isSpecial(this.url) && !isSpecialScheme(this.buffer)) {\n        return false;\n      }\n\n      if (!isSpecial(this.url) && isSpecialScheme(this.buffer)) {\n        return false;\n      }\n\n      if ((includesCredentials(this.url) || this.url.port !== null) && this.buffer === \"file\") {\n        return false;\n      }\n\n      if (this.url.scheme === \"file\" && this.url.host === \"\") {\n        return false;\n      }\n    }\n    this.url.scheme = this.buffer;\n    if (this.stateOverride) {\n      if (this.url.port === defaultPort(this.url.scheme)) {\n        this.url.port = null;\n      }\n      return false;\n    }\n    this.buffer = \"\";\n    if (this.url.scheme === \"file\") {\n      if (this.input[this.pointer + 1] !== p(\"/\") || this.input[this.pointer + 2] !== p(\"/\")) {\n        this.parseError = true;\n      }\n      this.state = \"file\";\n    } else if (isSpecial(this.url) && this.base !== null && this.base.scheme === this.url.scheme) {\n      this.state = \"special relative or authority\";\n    } else if (isSpecial(this.url)) {\n      this.state = \"special authority slashes\";\n    } else if (this.input[this.pointer + 1] === p(\"/\")) {\n      this.state = \"path or authority\";\n      ++this.pointer;\n    } else {\n      this.url.path = \"\";\n      this.state = \"opaque path\";\n    }\n  } else if (!this.stateOverride) {\n    this.buffer = \"\";\n    this.state = \"no scheme\";\n    this.pointer = -1;\n  } else {\n    this.parseError = true;\n    return failure;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse no scheme\"] = function parseNoScheme(c) {\n  if (this.base === null || (hasAnOpaquePath(this.base) && c !== p(\"#\"))) {\n    return failure;\n  } else if (hasAnOpaquePath(this.base) && c === p(\"#\")) {\n    this.url.scheme = this.base.scheme;\n    this.url.path = this.base.path;\n    this.url.query = this.base.query;\n    this.url.fragment = \"\";\n    this.state = \"fragment\";\n  } else if (this.base.scheme === \"file\") {\n    this.state = \"file\";\n    --this.pointer;\n  } else {\n    this.state = \"relative\";\n    --this.pointer;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse special relative or authority\"] = function parseSpecialRelativeOrAuthority(c) {\n  if (c === p(\"/\") && this.input[this.pointer + 1] === p(\"/\")) {\n    this.state = \"special authority ignore slashes\";\n    ++this.pointer;\n  } else {\n    this.parseError = true;\n    this.state = \"relative\";\n    --this.pointer;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse path or authority\"] = function parsePathOrAuthority(c) {\n  if (c === p(\"/\")) {\n    this.state = \"authority\";\n  } else {\n    this.state = \"path\";\n    --this.pointer;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse relative\"] = function parseRelative(c) {\n  this.url.scheme = this.base.scheme;\n  if (c === p(\"/\")) {\n    this.state = \"relative slash\";\n  } else if (isSpecial(this.url) && c === p(\"\\\\\")) {\n    this.parseError = true;\n    this.state = \"relative slash\";\n  } else {\n    this.url.username = this.base.username;\n    this.url.password = this.base.password;\n    this.url.host = this.base.host;\n    this.url.port = this.base.port;\n    this.url.path = this.base.path.slice();\n    this.url.query = this.base.query;\n    if (c === p(\"?\")) {\n      this.url.query = \"\";\n      this.state = \"query\";\n    } else if (c === p(\"#\")) {\n      this.url.fragment = \"\";\n      this.state = \"fragment\";\n    } else if (!isNaN(c)) {\n      this.url.query = null;\n      this.url.path.pop();\n      this.state = \"path\";\n      --this.pointer;\n    }\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse relative slash\"] = function parseRelativeSlash(c) {\n  if (isSpecial(this.url) && (c === p(\"/\") || c === p(\"\\\\\"))) {\n    if (c === p(\"\\\\\")) {\n      this.parseError = true;\n    }\n    this.state = \"special authority ignore slashes\";\n  } else if (c === p(\"/\")) {\n    this.state = \"authority\";\n  } else {\n    this.url.username = this.base.username;\n    this.url.password = this.base.password;\n    this.url.host = this.base.host;\n    this.url.port = this.base.port;\n    this.state = \"path\";\n    --this.pointer;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse special authority slashes\"] = function parseSpecialAuthoritySlashes(c) {\n  if (c === p(\"/\") && this.input[this.pointer + 1] === p(\"/\")) {\n    this.state = \"special authority ignore slashes\";\n    ++this.pointer;\n  } else {\n    this.parseError = true;\n    this.state = \"special authority ignore slashes\";\n    --this.pointer;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse special authority ignore slashes\"] = function parseSpecialAuthorityIgnoreSlashes(c) {\n  if (c !== p(\"/\") && c !== p(\"\\\\\")) {\n    this.state = \"authority\";\n    --this.pointer;\n  } else {\n    this.parseError = true;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse authority\"] = function parseAuthority(c, cStr) {\n  if (c === p(\"@\")) {\n    this.parseError = true;\n    if (this.atFlag) {\n      this.buffer = `%40${this.buffer}`;\n    }\n    this.atFlag = true;\n\n    // careful, this is based on buffer and has its own pointer (this.pointer != pointer) and inner chars\n    const len = countSymbols(this.buffer);\n    for (let pointer = 0; pointer < len; ++pointer) {\n      const codePoint = this.buffer.codePointAt(pointer);\n\n      if (codePoint === p(\":\") && !this.passwordTokenSeenFlag) {\n        this.passwordTokenSeenFlag = true;\n        continue;\n      }\n      const encodedCodePoints = utf8PercentEncodeCodePoint(codePoint, isUserinfoPercentEncode);\n      if (this.passwordTokenSeenFlag) {\n        this.url.password += encodedCodePoints;\n      } else {\n        this.url.username += encodedCodePoints;\n      }\n    }\n    this.buffer = \"\";\n  } else if (isNaN(c) || c === p(\"/\") || c === p(\"?\") || c === p(\"#\") ||\n             (isSpecial(this.url) && c === p(\"\\\\\"))) {\n    if (this.atFlag && this.buffer === \"\") {\n      this.parseError = true;\n      return failure;\n    }\n    this.pointer -= countSymbols(this.buffer) + 1;\n    this.buffer = \"\";\n    this.state = \"host\";\n  } else {\n    this.buffer += cStr;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse hostname\"] =\nURLStateMachine.prototype[\"parse host\"] = function parseHostName(c, cStr) {\n  if (this.stateOverride && this.url.scheme === \"file\") {\n    --this.pointer;\n    this.state = \"file host\";\n  } else if (c === p(\":\") && !this.arrFlag) {\n    if (this.buffer === \"\") {\n      this.parseError = true;\n      return failure;\n    }\n\n    if (this.stateOverride === \"hostname\") {\n      return false;\n    }\n\n    const host = parseHost(this.buffer, isNotSpecial(this.url));\n    if (host === failure) {\n      return failure;\n    }\n\n    this.url.host = host;\n    this.buffer = \"\";\n    this.state = \"port\";\n  } else if (isNaN(c) || c === p(\"/\") || c === p(\"?\") || c === p(\"#\") ||\n             (isSpecial(this.url) && c === p(\"\\\\\"))) {\n    --this.pointer;\n    if (isSpecial(this.url) && this.buffer === \"\") {\n      this.parseError = true;\n      return failure;\n    } else if (this.stateOverride && this.buffer === \"\" &&\n               (includesCredentials(this.url) || this.url.port !== null)) {\n      this.parseError = true;\n      return false;\n    }\n\n    const host = parseHost(this.buffer, isNotSpecial(this.url));\n    if (host === failure) {\n      return failure;\n    }\n\n    this.url.host = host;\n    this.buffer = \"\";\n    this.state = \"path start\";\n    if (this.stateOverride) {\n      return false;\n    }\n  } else {\n    if (c === p(\"[\")) {\n      this.arrFlag = true;\n    } else if (c === p(\"]\")) {\n      this.arrFlag = false;\n    }\n    this.buffer += cStr;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse port\"] = function parsePort(c, cStr) {\n  if (infra.isASCIIDigit(c)) {\n    this.buffer += cStr;\n  } else if (isNaN(c) || c === p(\"/\") || c === p(\"?\") || c === p(\"#\") ||\n             (isSpecial(this.url) && c === p(\"\\\\\")) ||\n             this.stateOverride) {\n    if (this.buffer !== \"\") {\n      const port = parseInt(this.buffer);\n      if (port > 2 ** 16 - 1) {\n        this.parseError = true;\n        return failure;\n      }\n      this.url.port = port === defaultPort(this.url.scheme) ? null : port;\n      this.buffer = \"\";\n    }\n    if (this.stateOverride) {\n      return false;\n    }\n    this.state = \"path start\";\n    --this.pointer;\n  } else {\n    this.parseError = true;\n    return failure;\n  }\n\n  return true;\n};\n\nconst fileOtherwiseCodePoints = new Set([p(\"/\"), p(\"\\\\\"), p(\"?\"), p(\"#\")]);\n\nfunction startsWithWindowsDriveLetter(input, pointer) {\n  const length = input.length - pointer;\n  return length >= 2 &&\n    isWindowsDriveLetterCodePoints(input[pointer], input[pointer + 1]) &&\n    (length === 2 || fileOtherwiseCodePoints.has(input[pointer + 2]));\n}\n\nURLStateMachine.prototype[\"parse file\"] = function parseFile(c) {\n  this.url.scheme = \"file\";\n  this.url.host = \"\";\n\n  if (c === p(\"/\") || c === p(\"\\\\\")) {\n    if (c === p(\"\\\\\")) {\n      this.parseError = true;\n    }\n    this.state = \"file slash\";\n  } else if (this.base !== null && this.base.scheme === \"file\") {\n    this.url.host = this.base.host;\n    this.url.path = this.base.path.slice();\n    this.url.query = this.base.query;\n    if (c === p(\"?\")) {\n      this.url.query = \"\";\n      this.state = \"query\";\n    } else if (c === p(\"#\")) {\n      this.url.fragment = \"\";\n      this.state = \"fragment\";\n    } else if (!isNaN(c)) {\n      this.url.query = null;\n      if (!startsWithWindowsDriveLetter(this.input, this.pointer)) {\n        shortenPath(this.url);\n      } else {\n        this.parseError = true;\n        this.url.path = [];\n      }\n\n      this.state = \"path\";\n      --this.pointer;\n    }\n  } else {\n    this.state = \"path\";\n    --this.pointer;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse file slash\"] = function parseFileSlash(c) {\n  if (c === p(\"/\") || c === p(\"\\\\\")) {\n    if (c === p(\"\\\\\")) {\n      this.parseError = true;\n    }\n    this.state = \"file host\";\n  } else {\n    if (this.base !== null && this.base.scheme === \"file\") {\n      if (!startsWithWindowsDriveLetter(this.input, this.pointer) &&\n          isNormalizedWindowsDriveLetterString(this.base.path[0])) {\n        this.url.path.push(this.base.path[0]);\n      }\n      this.url.host = this.base.host;\n    }\n    this.state = \"path\";\n    --this.pointer;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse file host\"] = function parseFileHost(c, cStr) {\n  if (isNaN(c) || c === p(\"/\") || c === p(\"\\\\\") || c === p(\"?\") || c === p(\"#\")) {\n    --this.pointer;\n    if (!this.stateOverride && isWindowsDriveLetterString(this.buffer)) {\n      this.parseError = true;\n      this.state = \"path\";\n    } else if (this.buffer === \"\") {\n      this.url.host = \"\";\n      if (this.stateOverride) {\n        return false;\n      }\n      this.state = \"path start\";\n    } else {\n      let host = parseHost(this.buffer, isNotSpecial(this.url));\n      if (host === failure) {\n        return failure;\n      }\n      if (host === \"localhost\") {\n        host = \"\";\n      }\n      this.url.host = host;\n\n      if (this.stateOverride) {\n        return false;\n      }\n\n      this.buffer = \"\";\n      this.state = \"path start\";\n    }\n  } else {\n    this.buffer += cStr;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse path start\"] = function parsePathStart(c) {\n  if (isSpecial(this.url)) {\n    if (c === p(\"\\\\\")) {\n      this.parseError = true;\n    }\n    this.state = \"path\";\n\n    if (c !== p(\"/\") && c !== p(\"\\\\\")) {\n      --this.pointer;\n    }\n  } else if (!this.stateOverride && c === p(\"?\")) {\n    this.url.query = \"\";\n    this.state = \"query\";\n  } else if (!this.stateOverride && c === p(\"#\")) {\n    this.url.fragment = \"\";\n    this.state = \"fragment\";\n  } else if (c !== undefined) {\n    this.state = \"path\";\n    if (c !== p(\"/\")) {\n      --this.pointer;\n    }\n  } else if (this.stateOverride && this.url.host === null) {\n    this.url.path.push(\"\");\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse path\"] = function parsePath(c) {\n  if (isNaN(c) || c === p(\"/\") || (isSpecial(this.url) && c === p(\"\\\\\")) ||\n      (!this.stateOverride && (c === p(\"?\") || c === p(\"#\")))) {\n    if (isSpecial(this.url) && c === p(\"\\\\\")) {\n      this.parseError = true;\n    }\n\n    if (isDoubleDot(this.buffer)) {\n      shortenPath(this.url);\n      if (c !== p(\"/\") && !(isSpecial(this.url) && c === p(\"\\\\\"))) {\n        this.url.path.push(\"\");\n      }\n    } else if (isSingleDot(this.buffer) && c !== p(\"/\") &&\n               !(isSpecial(this.url) && c === p(\"\\\\\"))) {\n      this.url.path.push(\"\");\n    } else if (!isSingleDot(this.buffer)) {\n      if (this.url.scheme === \"file\" && this.url.path.length === 0 && isWindowsDriveLetterString(this.buffer)) {\n        this.buffer = `${this.buffer[0]}:`;\n      }\n      this.url.path.push(this.buffer);\n    }\n    this.buffer = \"\";\n    if (c === p(\"?\")) {\n      this.url.query = \"\";\n      this.state = \"query\";\n    }\n    if (c === p(\"#\")) {\n      this.url.fragment = \"\";\n      this.state = \"fragment\";\n    }\n  } else {\n    // TODO: If c is not a URL code point and not \"%\", parse error.\n\n    if (c === p(\"%\") &&\n      (!infra.isASCIIHex(this.input[this.pointer + 1]) ||\n        !infra.isASCIIHex(this.input[this.pointer + 2]))) {\n      this.parseError = true;\n    }\n\n    this.buffer += utf8PercentEncodeCodePoint(c, isPathPercentEncode);\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse opaque path\"] = function parseOpaquePath(c) {\n  if (c === p(\"?\")) {\n    this.url.query = \"\";\n    this.state = \"query\";\n  } else if (c === p(\"#\")) {\n    this.url.fragment = \"\";\n    this.state = \"fragment\";\n  } else {\n    // TODO: Add: not a URL code point\n    if (!isNaN(c) && c !== p(\"%\")) {\n      this.parseError = true;\n    }\n\n    if (c === p(\"%\") &&\n        (!infra.isASCIIHex(this.input[this.pointer + 1]) ||\n         !infra.isASCIIHex(this.input[this.pointer + 2]))) {\n      this.parseError = true;\n    }\n\n    if (!isNaN(c)) {\n      this.url.path += utf8PercentEncodeCodePoint(c, isC0ControlPercentEncode);\n    }\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse query\"] = function parseQuery(c, cStr) {\n  if (!isSpecial(this.url) || this.url.scheme === \"ws\" || this.url.scheme === \"wss\") {\n    this.encodingOverride = \"utf-8\";\n  }\n\n  if ((!this.stateOverride && c === p(\"#\")) || isNaN(c)) {\n    const queryPercentEncodePredicate = isSpecial(this.url) ? isSpecialQueryPercentEncode : isQueryPercentEncode;\n    this.url.query += utf8PercentEncodeString(this.buffer, queryPercentEncodePredicate);\n\n    this.buffer = \"\";\n\n    if (c === p(\"#\")) {\n      this.url.fragment = \"\";\n      this.state = \"fragment\";\n    }\n  } else if (!isNaN(c)) {\n    // TODO: If c is not a URL code point and not \"%\", parse error.\n\n    if (c === p(\"%\") &&\n      (!infra.isASCIIHex(this.input[this.pointer + 1]) ||\n        !infra.isASCIIHex(this.input[this.pointer + 2]))) {\n      this.parseError = true;\n    }\n\n    this.buffer += cStr;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse fragment\"] = function parseFragment(c) {\n  if (!isNaN(c)) {\n    // TODO: If c is not a URL code point and not \"%\", parse error.\n    if (c === p(\"%\") &&\n      (!infra.isASCIIHex(this.input[this.pointer + 1]) ||\n        !infra.isASCIIHex(this.input[this.pointer + 2]))) {\n      this.parseError = true;\n    }\n\n    this.url.fragment += utf8PercentEncodeCodePoint(c, isFragmentPercentEncode);\n  }\n\n  return true;\n};\n\nfunction serializeURL(url, excludeFragment) {\n  let output = `${url.scheme}:`;\n  if (url.host !== null) {\n    output += \"//\";\n\n    if (url.username !== \"\" || url.password !== \"\") {\n      output += url.username;\n      if (url.password !== \"\") {\n        output += `:${url.password}`;\n      }\n      output += \"@\";\n    }\n\n    output += serializeHost(url.host);\n\n    if (url.port !== null) {\n      output += `:${url.port}`;\n    }\n  }\n\n  if (url.host === null && !hasAnOpaquePath(url) && url.path.length > 1 && url.path[0] === \"\") {\n    output += \"/.\";\n  }\n  output += serializePath(url);\n\n  if (url.query !== null) {\n    output += `?${url.query}`;\n  }\n\n  if (!excludeFragment && url.fragment !== null) {\n    output += `#${url.fragment}`;\n  }\n\n  return output;\n}\n\nfunction serializeOrigin(tuple) {\n  let result = `${tuple.scheme}://`;\n  result += serializeHost(tuple.host);\n\n  if (tuple.port !== null) {\n    result += `:${tuple.port}`;\n  }\n\n  return result;\n}\n\nfunction serializePath(url) {\n  if (hasAnOpaquePath(url)) {\n    return url.path;\n  }\n\n  let output = \"\";\n  for (const segment of url.path) {\n    output += `/${segment}`;\n  }\n  return output;\n}\n\nmodule.exports.serializeURL = serializeURL;\n\nmodule.exports.serializePath = serializePath;\n\nmodule.exports.serializeURLOrigin = function (url) {\n  // https://url.spec.whatwg.org/#concept-url-origin\n  switch (url.scheme) {\n    case \"blob\": {\n      const pathURL = module.exports.parseURL(serializePath(url));\n      if (pathURL === null) {\n        return \"null\";\n      }\n      if (pathURL.scheme !== \"http\" && pathURL.scheme !== \"https\") {\n        return \"null\";\n      }\n      return module.exports.serializeURLOrigin(pathURL);\n    }\n    case \"ftp\":\n    case \"http\":\n    case \"https\":\n    case \"ws\":\n    case \"wss\":\n      return serializeOrigin({\n        scheme: url.scheme,\n        host: url.host,\n        port: url.port\n      });\n    case \"file\":\n      // The spec says:\n      // > Unfortunate as it is, this is left as an exercise to the reader. When in doubt, return a new opaque origin.\n      // Browsers tested so far:\n      // - Chrome says \"file://\", but treats file: URLs as cross-origin for most (all?) purposes; see e.g.\n      //   https://bugs.chromium.org/p/chromium/issues/detail?id=37586\n      // - Firefox says \"null\", but treats file: URLs as same-origin sometimes based on directory stuff; see\n      //   https://developer.mozilla.org/en-US/docs/Archive/Misc_top_level/Same-origin_policy_for_file:_URIs\n      return \"null\";\n    default:\n      // serializing an opaque origin returns \"null\"\n      return \"null\";\n  }\n};\n\nmodule.exports.basicURLParse = function (input, options) {\n  if (options === undefined) {\n    options = {};\n  }\n\n  const usm = new URLStateMachine(input, options.baseURL, options.encodingOverride, options.url, options.stateOverride);\n  if (usm.failure) {\n    return null;\n  }\n\n  return usm.url;\n};\n\nmodule.exports.setTheUsername = function (url, username) {\n  url.username = utf8PercentEncodeString(username, isUserinfoPercentEncode);\n};\n\nmodule.exports.setThePassword = function (url, password) {\n  url.password = utf8PercentEncodeString(password, isUserinfoPercentEncode);\n};\n\nmodule.exports.serializeHost = serializeHost;\n\nmodule.exports.cannotHaveAUsernamePasswordPort = cannotHaveAUsernamePasswordPort;\n\nmodule.exports.hasAnOpaquePath = hasAnOpaquePath;\n\nmodule.exports.serializeInteger = function (integer) {\n  return String(integer);\n};\n\nmodule.exports.parseURL = function (input, options) {\n  if (options === undefined) {\n    options = {};\n  }\n\n  // We don't handle blobs, so this just delegates:\n  return module.exports.basicURLParse(input, { baseURL: options.baseURL, encodingOverride: options.encodingOverride });\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/whatwg-url/lib/url-state-machine.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/lib/urlencoded.js":
/*!***************************************************!*\
  !*** ./node_modules/whatwg-url/lib/urlencoded.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst { utf8Encode, utf8DecodeWithoutBOM } = __webpack_require__(/*! ./encoding */ \"./node_modules/whatwg-url/lib/encoding.js\");\nconst { percentDecodeBytes, utf8PercentEncodeString, isURLEncodedPercentEncode } = __webpack_require__(/*! ./percent-encoding */ \"./node_modules/whatwg-url/lib/percent-encoding.js\");\n\nfunction p(char) {\n  return char.codePointAt(0);\n}\n\n// https://url.spec.whatwg.org/#concept-urlencoded-parser\nfunction parseUrlencoded(input) {\n  const sequences = strictlySplitByteSequence(input, p(\"&\"));\n  const output = [];\n  for (const bytes of sequences) {\n    if (bytes.length === 0) {\n      continue;\n    }\n\n    let name, value;\n    const indexOfEqual = bytes.indexOf(p(\"=\"));\n\n    if (indexOfEqual >= 0) {\n      name = bytes.slice(0, indexOfEqual);\n      value = bytes.slice(indexOfEqual + 1);\n    } else {\n      name = bytes;\n      value = new Uint8Array(0);\n    }\n\n    name = replaceByteInByteSequence(name, 0x2B, 0x20);\n    value = replaceByteInByteSequence(value, 0x2B, 0x20);\n\n    const nameString = utf8DecodeWithoutBOM(percentDecodeBytes(name));\n    const valueString = utf8DecodeWithoutBOM(percentDecodeBytes(value));\n\n    output.push([nameString, valueString]);\n  }\n  return output;\n}\n\n// https://url.spec.whatwg.org/#concept-urlencoded-string-parser\nfunction parseUrlencodedString(input) {\n  return parseUrlencoded(utf8Encode(input));\n}\n\n// https://url.spec.whatwg.org/#concept-urlencoded-serializer\nfunction serializeUrlencoded(tuples, encodingOverride = undefined) {\n  let encoding = \"utf-8\";\n  if (encodingOverride !== undefined) {\n    // TODO \"get the output encoding\", i.e. handle encoding labels vs. names.\n    encoding = encodingOverride;\n  }\n\n  let output = \"\";\n  for (const [i, tuple] of tuples.entries()) {\n    // TODO: handle encoding override\n\n    const name = utf8PercentEncodeString(tuple[0], isURLEncodedPercentEncode, true);\n\n    let value = tuple[1];\n    if (tuple.length > 2 && tuple[2] !== undefined) {\n      if (tuple[2] === \"hidden\" && name === \"_charset_\") {\n        value = encoding;\n      } else if (tuple[2] === \"file\") {\n        // value is a File object\n        value = value.name;\n      }\n    }\n\n    value = utf8PercentEncodeString(value, isURLEncodedPercentEncode, true);\n\n    if (i !== 0) {\n      output += \"&\";\n    }\n    output += `${name}=${value}`;\n  }\n  return output;\n}\n\nfunction strictlySplitByteSequence(buf, cp) {\n  const list = [];\n  let last = 0;\n  let i = buf.indexOf(cp);\n  while (i >= 0) {\n    list.push(buf.slice(last, i));\n    last = i + 1;\n    i = buf.indexOf(cp, last);\n  }\n  if (last !== buf.length) {\n    list.push(buf.slice(last));\n  }\n  return list;\n}\n\nfunction replaceByteInByteSequence(buf, from, to) {\n  let i = buf.indexOf(from);\n  while (i >= 0) {\n    buf[i] = to;\n    i = buf.indexOf(from, i + 1);\n  }\n  return buf;\n}\n\nmodule.exports = {\n  parseUrlencodedString,\n  serializeUrlencoded\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/whatwg-url/lib/urlencoded.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/lib/utils.js":
/*!**********************************************!*\
  !*** ./node_modules/whatwg-url/lib/utils.js ***!
  \**********************************************/
/***/ ((module, exports) => {

"use strict";
eval("\n\n// Returns \"Type(value) is Object\" in ES terminology.\nfunction isObject(value) {\n  return (typeof value === \"object\" && value !== null) || typeof value === \"function\";\n}\n\nconst hasOwn = Function.prototype.call.bind(Object.prototype.hasOwnProperty);\n\n// Like `Object.assign`, but using `[[GetOwnProperty]]` and `[[DefineOwnProperty]]`\n// instead of `[[Get]]` and `[[Set]]` and only allowing objects\nfunction define(target, source) {\n  for (const key of Reflect.ownKeys(source)) {\n    const descriptor = Reflect.getOwnPropertyDescriptor(source, key);\n    if (descriptor && !Reflect.defineProperty(target, key, descriptor)) {\n      throw new TypeError(`Cannot redefine property: ${String(key)}`);\n    }\n  }\n}\n\nfunction newObjectInRealm(globalObject, object) {\n  const ctorRegistry = initCtorRegistry(globalObject);\n  return Object.defineProperties(\n    Object.create(ctorRegistry[\"%Object.prototype%\"]),\n    Object.getOwnPropertyDescriptors(object)\n  );\n}\n\nconst wrapperSymbol = Symbol(\"wrapper\");\nconst implSymbol = Symbol(\"impl\");\nconst sameObjectCaches = Symbol(\"SameObject caches\");\nconst ctorRegistrySymbol = Symbol.for(\"[webidl2js] constructor registry\");\n\nconst AsyncIteratorPrototype = Object.getPrototypeOf(Object.getPrototypeOf(async function* () {}).prototype);\n\nfunction initCtorRegistry(globalObject) {\n  if (hasOwn(globalObject, ctorRegistrySymbol)) {\n    return globalObject[ctorRegistrySymbol];\n  }\n\n  const ctorRegistry = Object.create(null);\n\n  // In addition to registering all the WebIDL2JS-generated types in the constructor registry,\n  // we also register a few intrinsics that we make use of in generated code, since they are not\n  // easy to grab from the globalObject variable.\n  ctorRegistry[\"%Object.prototype%\"] = globalObject.Object.prototype;\n  ctorRegistry[\"%IteratorPrototype%\"] = Object.getPrototypeOf(\n    Object.getPrototypeOf(new globalObject.Array()[Symbol.iterator]())\n  );\n\n  try {\n    ctorRegistry[\"%AsyncIteratorPrototype%\"] = Object.getPrototypeOf(\n      Object.getPrototypeOf(\n        globalObject.eval(\"(async function* () {})\").prototype\n      )\n    );\n  } catch {\n    ctorRegistry[\"%AsyncIteratorPrototype%\"] = AsyncIteratorPrototype;\n  }\n\n  globalObject[ctorRegistrySymbol] = ctorRegistry;\n  return ctorRegistry;\n}\n\nfunction getSameObject(wrapper, prop, creator) {\n  if (!wrapper[sameObjectCaches]) {\n    wrapper[sameObjectCaches] = Object.create(null);\n  }\n\n  if (prop in wrapper[sameObjectCaches]) {\n    return wrapper[sameObjectCaches][prop];\n  }\n\n  wrapper[sameObjectCaches][prop] = creator();\n  return wrapper[sameObjectCaches][prop];\n}\n\nfunction wrapperForImpl(impl) {\n  return impl ? impl[wrapperSymbol] : null;\n}\n\nfunction implForWrapper(wrapper) {\n  return wrapper ? wrapper[implSymbol] : null;\n}\n\nfunction tryWrapperForImpl(impl) {\n  const wrapper = wrapperForImpl(impl);\n  return wrapper ? wrapper : impl;\n}\n\nfunction tryImplForWrapper(wrapper) {\n  const impl = implForWrapper(wrapper);\n  return impl ? impl : wrapper;\n}\n\nconst iterInternalSymbol = Symbol(\"internal\");\n\nfunction isArrayIndexPropName(P) {\n  if (typeof P !== \"string\") {\n    return false;\n  }\n  const i = P >>> 0;\n  if (i === 2 ** 32 - 1) {\n    return false;\n  }\n  const s = `${i}`;\n  if (P !== s) {\n    return false;\n  }\n  return true;\n}\n\nconst byteLengthGetter =\n    Object.getOwnPropertyDescriptor(ArrayBuffer.prototype, \"byteLength\").get;\nfunction isArrayBuffer(value) {\n  try {\n    byteLengthGetter.call(value);\n    return true;\n  } catch (e) {\n    return false;\n  }\n}\n\nfunction iteratorResult([key, value], kind) {\n  let result;\n  switch (kind) {\n    case \"key\":\n      result = key;\n      break;\n    case \"value\":\n      result = value;\n      break;\n    case \"key+value\":\n      result = [key, value];\n      break;\n  }\n  return { value: result, done: false };\n}\n\nconst supportsPropertyIndex = Symbol(\"supports property index\");\nconst supportedPropertyIndices = Symbol(\"supported property indices\");\nconst supportsPropertyName = Symbol(\"supports property name\");\nconst supportedPropertyNames = Symbol(\"supported property names\");\nconst indexedGet = Symbol(\"indexed property get\");\nconst indexedSetNew = Symbol(\"indexed property set new\");\nconst indexedSetExisting = Symbol(\"indexed property set existing\");\nconst namedGet = Symbol(\"named property get\");\nconst namedSetNew = Symbol(\"named property set new\");\nconst namedSetExisting = Symbol(\"named property set existing\");\nconst namedDelete = Symbol(\"named property delete\");\n\nconst asyncIteratorNext = Symbol(\"async iterator get the next iteration result\");\nconst asyncIteratorReturn = Symbol(\"async iterator return steps\");\nconst asyncIteratorInit = Symbol(\"async iterator initialization steps\");\nconst asyncIteratorEOI = Symbol(\"async iterator end of iteration\");\n\nmodule.exports = exports = {\n  isObject,\n  hasOwn,\n  define,\n  newObjectInRealm,\n  wrapperSymbol,\n  implSymbol,\n  getSameObject,\n  ctorRegistrySymbol,\n  initCtorRegistry,\n  wrapperForImpl,\n  implForWrapper,\n  tryWrapperForImpl,\n  tryImplForWrapper,\n  iterInternalSymbol,\n  isArrayBuffer,\n  isArrayIndexPropName,\n  supportsPropertyIndex,\n  supportedPropertyIndices,\n  supportsPropertyName,\n  supportedPropertyNames,\n  indexedGet,\n  indexedSetNew,\n  indexedSetExisting,\n  namedGet,\n  namedSetNew,\n  namedSetExisting,\n  namedDelete,\n  asyncIteratorNext,\n  asyncIteratorReturn,\n  asyncIteratorInit,\n  asyncIteratorEOI,\n  iteratorResult\n};\n\n\n//# sourceURL=webpack://experimento/./node_modules/whatwg-url/lib/utils.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/webidl2js-wrapper.js":
/*!******************************************************!*\
  !*** ./node_modules/whatwg-url/webidl2js-wrapper.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nconst URL = __webpack_require__(/*! ./lib/URL */ \"./node_modules/whatwg-url/lib/URL.js\");\nconst URLSearchParams = __webpack_require__(/*! ./lib/URLSearchParams */ \"./node_modules/whatwg-url/lib/URLSearchParams.js\");\n\nexports.URL = URL;\nexports.URLSearchParams = URLSearchParams;\n\n\n//# sourceURL=webpack://experimento/./node_modules/whatwg-url/webidl2js-wrapper.js?");

/***/ }),

/***/ "assert":
/*!*************************!*\
  !*** external "assert" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("assert");

/***/ }),

/***/ "child_process":
/*!********************************!*\
  !*** external "child_process" ***!
  \********************************/
/***/ ((module) => {

"use strict";
module.exports = require("child_process");

/***/ }),

/***/ "crypto":
/*!*************************!*\
  !*** external "crypto" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("crypto");

/***/ }),

/***/ "dns":
/*!**********************!*\
  !*** external "dns" ***!
  \**********************/
/***/ ((module) => {

"use strict";
module.exports = require("dns");

/***/ }),

/***/ "electron":
/*!***************************!*\
  !*** external "electron" ***!
  \***************************/
/***/ ((module) => {

"use strict";
module.exports = require("electron");

/***/ }),

/***/ "events":
/*!*************************!*\
  !*** external "events" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("events");

/***/ }),

/***/ "fs":
/*!*********************!*\
  !*** external "fs" ***!
  \*********************/
/***/ ((module) => {

"use strict";
module.exports = require("fs");

/***/ }),

/***/ "fs/promises":
/*!******************************!*\
  !*** external "fs/promises" ***!
  \******************************/
/***/ ((module) => {

"use strict";
module.exports = require("fs/promises");

/***/ }),

/***/ "http":
/*!***********************!*\
  !*** external "http" ***!
  \***********************/
/***/ ((module) => {

"use strict";
module.exports = require("http");

/***/ }),

/***/ "net":
/*!**********************!*\
  !*** external "net" ***!
  \**********************/
/***/ ((module) => {

"use strict";
module.exports = require("net");

/***/ }),

/***/ "node:async_hooks":
/*!***********************************!*\
  !*** external "node:async_hooks" ***!
  \***********************************/
/***/ ((module) => {

"use strict";
module.exports = require("node:async_hooks");

/***/ }),

/***/ "os":
/*!*********************!*\
  !*** external "os" ***!
  \*********************/
/***/ ((module) => {

"use strict";
module.exports = require("os");

/***/ }),

/***/ "path":
/*!***********************!*\
  !*** external "path" ***!
  \***********************/
/***/ ((module) => {

"use strict";
module.exports = require("path");

/***/ }),

/***/ "process":
/*!**************************!*\
  !*** external "process" ***!
  \**************************/
/***/ ((module) => {

"use strict";
module.exports = require("process");

/***/ }),

/***/ "stream":
/*!*************************!*\
  !*** external "stream" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("stream");

/***/ }),

/***/ "timers":
/*!*************************!*\
  !*** external "timers" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("timers");

/***/ }),

/***/ "timers/promises":
/*!**********************************!*\
  !*** external "timers/promises" ***!
  \**********************************/
/***/ ((module) => {

"use strict";
module.exports = require("timers/promises");

/***/ }),

/***/ "tls":
/*!**********************!*\
  !*** external "tls" ***!
  \**********************/
/***/ ((module) => {

"use strict";
module.exports = require("tls");

/***/ }),

/***/ "tty":
/*!**********************!*\
  !*** external "tty" ***!
  \**********************/
/***/ ((module) => {

"use strict";
module.exports = require("tty");

/***/ }),

/***/ "url":
/*!**********************!*\
  !*** external "url" ***!
  \**********************/
/***/ ((module) => {

"use strict";
module.exports = require("url");

/***/ }),

/***/ "util":
/*!***********************!*\
  !*** external "util" ***!
  \***********************/
/***/ ((module) => {

"use strict";
module.exports = require("util");

/***/ }),

/***/ "zlib":
/*!***********************!*\
  !*** external "zlib" ***!
  \***********************/
/***/ ((module) => {

"use strict";
module.exports = require("zlib");

/***/ }),

/***/ "./node_modules/bson/lib/bson.cjs":
/*!****************************************!*\
  !*** ./node_modules/bson/lib/bson.cjs ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nfunction isAnyArrayBuffer(value) {\n    return ['[object ArrayBuffer]', '[object SharedArrayBuffer]'].includes(Object.prototype.toString.call(value));\n}\nfunction isUint8Array(value) {\n    return Object.prototype.toString.call(value) === '[object Uint8Array]';\n}\nfunction isRegExp(d) {\n    return Object.prototype.toString.call(d) === '[object RegExp]';\n}\nfunction isMap(d) {\n    return Object.prototype.toString.call(d) === '[object Map]';\n}\nfunction isDate(d) {\n    return Object.prototype.toString.call(d) === '[object Date]';\n}\nfunction defaultInspect(x, _options) {\n    return JSON.stringify(x, (k, v) => {\n        if (typeof v === 'bigint') {\n            return { $numberLong: `${v}` };\n        }\n        else if (isMap(v)) {\n            return Object.fromEntries(v);\n        }\n        return v;\n    });\n}\nfunction getStylizeFunction(options) {\n    const stylizeExists = options != null &&\n        typeof options === 'object' &&\n        'stylize' in options &&\n        typeof options.stylize === 'function';\n    if (stylizeExists) {\n        return options.stylize;\n    }\n}\n\nconst BSON_MAJOR_VERSION = 6;\nconst BSON_INT32_MAX = 0x7fffffff;\nconst BSON_INT32_MIN = -0x80000000;\nconst BSON_INT64_MAX = Math.pow(2, 63) - 1;\nconst BSON_INT64_MIN = -Math.pow(2, 63);\nconst JS_INT_MAX = Math.pow(2, 53);\nconst JS_INT_MIN = -Math.pow(2, 53);\nconst BSON_DATA_NUMBER = 1;\nconst BSON_DATA_STRING = 2;\nconst BSON_DATA_OBJECT = 3;\nconst BSON_DATA_ARRAY = 4;\nconst BSON_DATA_BINARY = 5;\nconst BSON_DATA_UNDEFINED = 6;\nconst BSON_DATA_OID = 7;\nconst BSON_DATA_BOOLEAN = 8;\nconst BSON_DATA_DATE = 9;\nconst BSON_DATA_NULL = 10;\nconst BSON_DATA_REGEXP = 11;\nconst BSON_DATA_DBPOINTER = 12;\nconst BSON_DATA_CODE = 13;\nconst BSON_DATA_SYMBOL = 14;\nconst BSON_DATA_CODE_W_SCOPE = 15;\nconst BSON_DATA_INT = 16;\nconst BSON_DATA_TIMESTAMP = 17;\nconst BSON_DATA_LONG = 18;\nconst BSON_DATA_DECIMAL128 = 19;\nconst BSON_DATA_MIN_KEY = 0xff;\nconst BSON_DATA_MAX_KEY = 0x7f;\nconst BSON_BINARY_SUBTYPE_DEFAULT = 0;\nconst BSON_BINARY_SUBTYPE_UUID_NEW = 4;\nconst BSONType = Object.freeze({\n    double: 1,\n    string: 2,\n    object: 3,\n    array: 4,\n    binData: 5,\n    undefined: 6,\n    objectId: 7,\n    bool: 8,\n    date: 9,\n    null: 10,\n    regex: 11,\n    dbPointer: 12,\n    javascript: 13,\n    symbol: 14,\n    javascriptWithScope: 15,\n    int: 16,\n    timestamp: 17,\n    long: 18,\n    decimal: 19,\n    minKey: -1,\n    maxKey: 127\n});\n\nclass BSONError extends Error {\n    get bsonError() {\n        return true;\n    }\n    get name() {\n        return 'BSONError';\n    }\n    constructor(message, options) {\n        super(message, options);\n    }\n    static isBSONError(value) {\n        return (value != null &&\n            typeof value === 'object' &&\n            'bsonError' in value &&\n            value.bsonError === true &&\n            'name' in value &&\n            'message' in value &&\n            'stack' in value);\n    }\n}\nclass BSONVersionError extends BSONError {\n    get name() {\n        return 'BSONVersionError';\n    }\n    constructor() {\n        super(`Unsupported BSON version, bson types must be from bson ${BSON_MAJOR_VERSION}.x.x`);\n    }\n}\nclass BSONRuntimeError extends BSONError {\n    get name() {\n        return 'BSONRuntimeError';\n    }\n    constructor(message) {\n        super(message);\n    }\n}\nclass BSONOffsetError extends BSONError {\n    get name() {\n        return 'BSONOffsetError';\n    }\n    constructor(message, offset, options) {\n        super(`${message}. offset: ${offset}`, options);\n        this.offset = offset;\n    }\n}\n\nlet TextDecoderFatal;\nlet TextDecoderNonFatal;\nfunction parseUtf8(buffer, start, end, fatal) {\n    if (fatal) {\n        TextDecoderFatal ??= new TextDecoder('utf8', { fatal: true });\n        try {\n            return TextDecoderFatal.decode(buffer.subarray(start, end));\n        }\n        catch (cause) {\n            throw new BSONError('Invalid UTF-8 string in BSON document', { cause });\n        }\n    }\n    TextDecoderNonFatal ??= new TextDecoder('utf8', { fatal: false });\n    return TextDecoderNonFatal.decode(buffer.subarray(start, end));\n}\n\nfunction tryReadBasicLatin(uint8array, start, end) {\n    if (uint8array.length === 0) {\n        return '';\n    }\n    const stringByteLength = end - start;\n    if (stringByteLength === 0) {\n        return '';\n    }\n    if (stringByteLength > 20) {\n        return null;\n    }\n    if (stringByteLength === 1 && uint8array[start] < 128) {\n        return String.fromCharCode(uint8array[start]);\n    }\n    if (stringByteLength === 2 && uint8array[start] < 128 && uint8array[start + 1] < 128) {\n        return String.fromCharCode(uint8array[start]) + String.fromCharCode(uint8array[start + 1]);\n    }\n    if (stringByteLength === 3 &&\n        uint8array[start] < 128 &&\n        uint8array[start + 1] < 128 &&\n        uint8array[start + 2] < 128) {\n        return (String.fromCharCode(uint8array[start]) +\n            String.fromCharCode(uint8array[start + 1]) +\n            String.fromCharCode(uint8array[start + 2]));\n    }\n    const latinBytes = [];\n    for (let i = start; i < end; i++) {\n        const byte = uint8array[i];\n        if (byte > 127) {\n            return null;\n        }\n        latinBytes.push(byte);\n    }\n    return String.fromCharCode(...latinBytes);\n}\nfunction tryWriteBasicLatin(destination, source, offset) {\n    if (source.length === 0)\n        return 0;\n    if (source.length > 25)\n        return null;\n    if (destination.length - offset < source.length)\n        return null;\n    for (let charOffset = 0, destinationOffset = offset; charOffset < source.length; charOffset++, destinationOffset++) {\n        const char = source.charCodeAt(charOffset);\n        if (char > 127)\n            return null;\n        destination[destinationOffset] = char;\n    }\n    return source.length;\n}\n\nfunction nodejsMathRandomBytes(byteLength) {\n    return nodeJsByteUtils.fromNumberArray(Array.from({ length: byteLength }, () => Math.floor(Math.random() * 256)));\n}\nconst nodejsRandomBytes = (() => {\n    try {\n        return (__webpack_require__(/*! crypto */ \"crypto\").randomBytes);\n    }\n    catch {\n        return nodejsMathRandomBytes;\n    }\n})();\nconst nodeJsByteUtils = {\n    toLocalBufferType(potentialBuffer) {\n        if (Buffer.isBuffer(potentialBuffer)) {\n            return potentialBuffer;\n        }\n        if (ArrayBuffer.isView(potentialBuffer)) {\n            return Buffer.from(potentialBuffer.buffer, potentialBuffer.byteOffset, potentialBuffer.byteLength);\n        }\n        const stringTag = potentialBuffer?.[Symbol.toStringTag] ?? Object.prototype.toString.call(potentialBuffer);\n        if (stringTag === 'ArrayBuffer' ||\n            stringTag === 'SharedArrayBuffer' ||\n            stringTag === '[object ArrayBuffer]' ||\n            stringTag === '[object SharedArrayBuffer]') {\n            return Buffer.from(potentialBuffer);\n        }\n        throw new BSONError(`Cannot create Buffer from ${String(potentialBuffer)}`);\n    },\n    allocate(size) {\n        return Buffer.alloc(size);\n    },\n    allocateUnsafe(size) {\n        return Buffer.allocUnsafe(size);\n    },\n    equals(a, b) {\n        return nodeJsByteUtils.toLocalBufferType(a).equals(b);\n    },\n    fromNumberArray(array) {\n        return Buffer.from(array);\n    },\n    fromBase64(base64) {\n        return Buffer.from(base64, 'base64');\n    },\n    toBase64(buffer) {\n        return nodeJsByteUtils.toLocalBufferType(buffer).toString('base64');\n    },\n    fromISO88591(codePoints) {\n        return Buffer.from(codePoints, 'binary');\n    },\n    toISO88591(buffer) {\n        return nodeJsByteUtils.toLocalBufferType(buffer).toString('binary');\n    },\n    fromHex(hex) {\n        return Buffer.from(hex, 'hex');\n    },\n    toHex(buffer) {\n        return nodeJsByteUtils.toLocalBufferType(buffer).toString('hex');\n    },\n    toUTF8(buffer, start, end, fatal) {\n        const basicLatin = end - start <= 20 ? tryReadBasicLatin(buffer, start, end) : null;\n        if (basicLatin != null) {\n            return basicLatin;\n        }\n        const string = nodeJsByteUtils.toLocalBufferType(buffer).toString('utf8', start, end);\n        if (fatal) {\n            for (let i = 0; i < string.length; i++) {\n                if (string.charCodeAt(i) === 0xfffd) {\n                    parseUtf8(buffer, start, end, true);\n                    break;\n                }\n            }\n        }\n        return string;\n    },\n    utf8ByteLength(input) {\n        return Buffer.byteLength(input, 'utf8');\n    },\n    encodeUTF8Into(buffer, source, byteOffset) {\n        const latinBytesWritten = tryWriteBasicLatin(buffer, source, byteOffset);\n        if (latinBytesWritten != null) {\n            return latinBytesWritten;\n        }\n        return nodeJsByteUtils.toLocalBufferType(buffer).write(source, byteOffset, undefined, 'utf8');\n    },\n    randomBytes: nodejsRandomBytes\n};\n\nfunction isReactNative() {\n    const { navigator } = globalThis;\n    return typeof navigator === 'object' && navigator.product === 'ReactNative';\n}\nfunction webMathRandomBytes(byteLength) {\n    if (byteLength < 0) {\n        throw new RangeError(`The argument 'byteLength' is invalid. Received ${byteLength}`);\n    }\n    return webByteUtils.fromNumberArray(Array.from({ length: byteLength }, () => Math.floor(Math.random() * 256)));\n}\nconst webRandomBytes = (() => {\n    const { crypto } = globalThis;\n    if (crypto != null && typeof crypto.getRandomValues === 'function') {\n        return (byteLength) => {\n            return crypto.getRandomValues(webByteUtils.allocate(byteLength));\n        };\n    }\n    else {\n        if (isReactNative()) {\n            const { console } = globalThis;\n            console?.warn?.('BSON: For React Native please polyfill crypto.getRandomValues, e.g. using: https://www.npmjs.com/package/react-native-get-random-values.');\n        }\n        return webMathRandomBytes;\n    }\n})();\nconst HEX_DIGIT = /(\\d|[a-f])/i;\nconst webByteUtils = {\n    toLocalBufferType(potentialUint8array) {\n        const stringTag = potentialUint8array?.[Symbol.toStringTag] ??\n            Object.prototype.toString.call(potentialUint8array);\n        if (stringTag === 'Uint8Array') {\n            return potentialUint8array;\n        }\n        if (ArrayBuffer.isView(potentialUint8array)) {\n            return new Uint8Array(potentialUint8array.buffer.slice(potentialUint8array.byteOffset, potentialUint8array.byteOffset + potentialUint8array.byteLength));\n        }\n        if (stringTag === 'ArrayBuffer' ||\n            stringTag === 'SharedArrayBuffer' ||\n            stringTag === '[object ArrayBuffer]' ||\n            stringTag === '[object SharedArrayBuffer]') {\n            return new Uint8Array(potentialUint8array);\n        }\n        throw new BSONError(`Cannot make a Uint8Array from ${String(potentialUint8array)}`);\n    },\n    allocate(size) {\n        if (typeof size !== 'number') {\n            throw new TypeError(`The \"size\" argument must be of type number. Received ${String(size)}`);\n        }\n        return new Uint8Array(size);\n    },\n    allocateUnsafe(size) {\n        return webByteUtils.allocate(size);\n    },\n    equals(a, b) {\n        if (a.byteLength !== b.byteLength) {\n            return false;\n        }\n        for (let i = 0; i < a.byteLength; i++) {\n            if (a[i] !== b[i]) {\n                return false;\n            }\n        }\n        return true;\n    },\n    fromNumberArray(array) {\n        return Uint8Array.from(array);\n    },\n    fromBase64(base64) {\n        return Uint8Array.from(atob(base64), c => c.charCodeAt(0));\n    },\n    toBase64(uint8array) {\n        return btoa(webByteUtils.toISO88591(uint8array));\n    },\n    fromISO88591(codePoints) {\n        return Uint8Array.from(codePoints, c => c.charCodeAt(0) & 0xff);\n    },\n    toISO88591(uint8array) {\n        return Array.from(Uint16Array.from(uint8array), b => String.fromCharCode(b)).join('');\n    },\n    fromHex(hex) {\n        const evenLengthHex = hex.length % 2 === 0 ? hex : hex.slice(0, hex.length - 1);\n        const buffer = [];\n        for (let i = 0; i < evenLengthHex.length; i += 2) {\n            const firstDigit = evenLengthHex[i];\n            const secondDigit = evenLengthHex[i + 1];\n            if (!HEX_DIGIT.test(firstDigit)) {\n                break;\n            }\n            if (!HEX_DIGIT.test(secondDigit)) {\n                break;\n            }\n            const hexDigit = Number.parseInt(`${firstDigit}${secondDigit}`, 16);\n            buffer.push(hexDigit);\n        }\n        return Uint8Array.from(buffer);\n    },\n    toHex(uint8array) {\n        return Array.from(uint8array, byte => byte.toString(16).padStart(2, '0')).join('');\n    },\n    toUTF8(uint8array, start, end, fatal) {\n        const basicLatin = end - start <= 20 ? tryReadBasicLatin(uint8array, start, end) : null;\n        if (basicLatin != null) {\n            return basicLatin;\n        }\n        return parseUtf8(uint8array, start, end, fatal);\n    },\n    utf8ByteLength(input) {\n        return new TextEncoder().encode(input).byteLength;\n    },\n    encodeUTF8Into(uint8array, source, byteOffset) {\n        const bytes = new TextEncoder().encode(source);\n        uint8array.set(bytes, byteOffset);\n        return bytes.byteLength;\n    },\n    randomBytes: webRandomBytes\n};\n\nconst hasGlobalBuffer = typeof Buffer === 'function' && Buffer.prototype?._isBuffer !== true;\nconst ByteUtils = hasGlobalBuffer ? nodeJsByteUtils : webByteUtils;\n\nclass BSONValue {\n    get [Symbol.for('@@mdb.bson.version')]() {\n        return BSON_MAJOR_VERSION;\n    }\n    [Symbol.for('nodejs.util.inspect.custom')](depth, options, inspect) {\n        return this.inspect(depth, options, inspect);\n    }\n}\n\nclass Binary extends BSONValue {\n    get _bsontype() {\n        return 'Binary';\n    }\n    constructor(buffer, subType) {\n        super();\n        if (!(buffer == null) &&\n            typeof buffer === 'string' &&\n            !ArrayBuffer.isView(buffer) &&\n            !isAnyArrayBuffer(buffer) &&\n            !Array.isArray(buffer)) {\n            throw new BSONError('Binary can only be constructed from Uint8Array or number[]');\n        }\n        this.sub_type = subType ?? Binary.BSON_BINARY_SUBTYPE_DEFAULT;\n        if (buffer == null) {\n            this.buffer = ByteUtils.allocate(Binary.BUFFER_SIZE);\n            this.position = 0;\n        }\n        else {\n            this.buffer = Array.isArray(buffer)\n                ? ByteUtils.fromNumberArray(buffer)\n                : ByteUtils.toLocalBufferType(buffer);\n            this.position = this.buffer.byteLength;\n        }\n    }\n    put(byteValue) {\n        if (typeof byteValue === 'string' && byteValue.length !== 1) {\n            throw new BSONError('only accepts single character String');\n        }\n        else if (typeof byteValue !== 'number' && byteValue.length !== 1)\n            throw new BSONError('only accepts single character Uint8Array or Array');\n        let decodedByte;\n        if (typeof byteValue === 'string') {\n            decodedByte = byteValue.charCodeAt(0);\n        }\n        else if (typeof byteValue === 'number') {\n            decodedByte = byteValue;\n        }\n        else {\n            decodedByte = byteValue[0];\n        }\n        if (decodedByte < 0 || decodedByte > 255) {\n            throw new BSONError('only accepts number in a valid unsigned byte range 0-255');\n        }\n        if (this.buffer.byteLength > this.position) {\n            this.buffer[this.position++] = decodedByte;\n        }\n        else {\n            const newSpace = ByteUtils.allocate(Binary.BUFFER_SIZE + this.buffer.length);\n            newSpace.set(this.buffer, 0);\n            this.buffer = newSpace;\n            this.buffer[this.position++] = decodedByte;\n        }\n    }\n    write(sequence, offset) {\n        offset = typeof offset === 'number' ? offset : this.position;\n        if (this.buffer.byteLength < offset + sequence.length) {\n            const newSpace = ByteUtils.allocate(this.buffer.byteLength + sequence.length);\n            newSpace.set(this.buffer, 0);\n            this.buffer = newSpace;\n        }\n        if (ArrayBuffer.isView(sequence)) {\n            this.buffer.set(ByteUtils.toLocalBufferType(sequence), offset);\n            this.position =\n                offset + sequence.byteLength > this.position ? offset + sequence.length : this.position;\n        }\n        else if (typeof sequence === 'string') {\n            throw new BSONError('input cannot be string');\n        }\n    }\n    read(position, length) {\n        length = length && length > 0 ? length : this.position;\n        return this.buffer.slice(position, position + length);\n    }\n    value() {\n        return this.buffer.length === this.position\n            ? this.buffer\n            : this.buffer.subarray(0, this.position);\n    }\n    length() {\n        return this.position;\n    }\n    toJSON() {\n        return ByteUtils.toBase64(this.buffer.subarray(0, this.position));\n    }\n    toString(encoding) {\n        if (encoding === 'hex')\n            return ByteUtils.toHex(this.buffer.subarray(0, this.position));\n        if (encoding === 'base64')\n            return ByteUtils.toBase64(this.buffer.subarray(0, this.position));\n        if (encoding === 'utf8' || encoding === 'utf-8')\n            return ByteUtils.toUTF8(this.buffer, 0, this.position, false);\n        return ByteUtils.toUTF8(this.buffer, 0, this.position, false);\n    }\n    toExtendedJSON(options) {\n        options = options || {};\n        const base64String = ByteUtils.toBase64(this.buffer);\n        const subType = Number(this.sub_type).toString(16);\n        if (options.legacy) {\n            return {\n                $binary: base64String,\n                $type: subType.length === 1 ? '0' + subType : subType\n            };\n        }\n        return {\n            $binary: {\n                base64: base64String,\n                subType: subType.length === 1 ? '0' + subType : subType\n            }\n        };\n    }\n    toUUID() {\n        if (this.sub_type === Binary.SUBTYPE_UUID) {\n            return new UUID(this.buffer.slice(0, this.position));\n        }\n        throw new BSONError(`Binary sub_type \"${this.sub_type}\" is not supported for converting to UUID. Only \"${Binary.SUBTYPE_UUID}\" is currently supported.`);\n    }\n    static createFromHexString(hex, subType) {\n        return new Binary(ByteUtils.fromHex(hex), subType);\n    }\n    static createFromBase64(base64, subType) {\n        return new Binary(ByteUtils.fromBase64(base64), subType);\n    }\n    static fromExtendedJSON(doc, options) {\n        options = options || {};\n        let data;\n        let type;\n        if ('$binary' in doc) {\n            if (options.legacy && typeof doc.$binary === 'string' && '$type' in doc) {\n                type = doc.$type ? parseInt(doc.$type, 16) : 0;\n                data = ByteUtils.fromBase64(doc.$binary);\n            }\n            else {\n                if (typeof doc.$binary !== 'string') {\n                    type = doc.$binary.subType ? parseInt(doc.$binary.subType, 16) : 0;\n                    data = ByteUtils.fromBase64(doc.$binary.base64);\n                }\n            }\n        }\n        else if ('$uuid' in doc) {\n            type = 4;\n            data = UUID.bytesFromString(doc.$uuid);\n        }\n        if (!data) {\n            throw new BSONError(`Unexpected Binary Extended JSON format ${JSON.stringify(doc)}`);\n        }\n        return type === BSON_BINARY_SUBTYPE_UUID_NEW ? new UUID(data) : new Binary(data, type);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        const base64 = ByteUtils.toBase64(this.buffer.subarray(0, this.position));\n        const base64Arg = inspect(base64, options);\n        const subTypeArg = inspect(this.sub_type, options);\n        return `Binary.createFromBase64(${base64Arg}, ${subTypeArg})`;\n    }\n}\nBinary.BSON_BINARY_SUBTYPE_DEFAULT = 0;\nBinary.BUFFER_SIZE = 256;\nBinary.SUBTYPE_DEFAULT = 0;\nBinary.SUBTYPE_FUNCTION = 1;\nBinary.SUBTYPE_BYTE_ARRAY = 2;\nBinary.SUBTYPE_UUID_OLD = 3;\nBinary.SUBTYPE_UUID = 4;\nBinary.SUBTYPE_MD5 = 5;\nBinary.SUBTYPE_ENCRYPTED = 6;\nBinary.SUBTYPE_COLUMN = 7;\nBinary.SUBTYPE_SENSITIVE = 8;\nBinary.SUBTYPE_USER_DEFINED = 128;\nconst UUID_BYTE_LENGTH = 16;\nconst UUID_WITHOUT_DASHES = /^[0-9A-F]{32}$/i;\nconst UUID_WITH_DASHES = /^[0-9A-F]{8}-[0-9A-F]{4}-[0-9A-F]{4}-[0-9A-F]{4}-[0-9A-F]{12}$/i;\nclass UUID extends Binary {\n    constructor(input) {\n        let bytes;\n        if (input == null) {\n            bytes = UUID.generate();\n        }\n        else if (input instanceof UUID) {\n            bytes = ByteUtils.toLocalBufferType(new Uint8Array(input.buffer));\n        }\n        else if (ArrayBuffer.isView(input) && input.byteLength === UUID_BYTE_LENGTH) {\n            bytes = ByteUtils.toLocalBufferType(input);\n        }\n        else if (typeof input === 'string') {\n            bytes = UUID.bytesFromString(input);\n        }\n        else {\n            throw new BSONError('Argument passed in UUID constructor must be a UUID, a 16 byte Buffer or a 32/36 character hex string (dashes excluded/included, format: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx).');\n        }\n        super(bytes, BSON_BINARY_SUBTYPE_UUID_NEW);\n    }\n    get id() {\n        return this.buffer;\n    }\n    set id(value) {\n        this.buffer = value;\n    }\n    toHexString(includeDashes = true) {\n        if (includeDashes) {\n            return [\n                ByteUtils.toHex(this.buffer.subarray(0, 4)),\n                ByteUtils.toHex(this.buffer.subarray(4, 6)),\n                ByteUtils.toHex(this.buffer.subarray(6, 8)),\n                ByteUtils.toHex(this.buffer.subarray(8, 10)),\n                ByteUtils.toHex(this.buffer.subarray(10, 16))\n            ].join('-');\n        }\n        return ByteUtils.toHex(this.buffer);\n    }\n    toString(encoding) {\n        if (encoding === 'hex')\n            return ByteUtils.toHex(this.id);\n        if (encoding === 'base64')\n            return ByteUtils.toBase64(this.id);\n        return this.toHexString();\n    }\n    toJSON() {\n        return this.toHexString();\n    }\n    equals(otherId) {\n        if (!otherId) {\n            return false;\n        }\n        if (otherId instanceof UUID) {\n            return ByteUtils.equals(otherId.id, this.id);\n        }\n        try {\n            return ByteUtils.equals(new UUID(otherId).id, this.id);\n        }\n        catch {\n            return false;\n        }\n    }\n    toBinary() {\n        return new Binary(this.id, Binary.SUBTYPE_UUID);\n    }\n    static generate() {\n        const bytes = ByteUtils.randomBytes(UUID_BYTE_LENGTH);\n        bytes[6] = (bytes[6] & 0x0f) | 0x40;\n        bytes[8] = (bytes[8] & 0x3f) | 0x80;\n        return bytes;\n    }\n    static isValid(input) {\n        if (!input) {\n            return false;\n        }\n        if (typeof input === 'string') {\n            return UUID.isValidUUIDString(input);\n        }\n        if (isUint8Array(input)) {\n            return input.byteLength === UUID_BYTE_LENGTH;\n        }\n        return (input._bsontype === 'Binary' &&\n            input.sub_type === this.SUBTYPE_UUID &&\n            input.buffer.byteLength === 16);\n    }\n    static createFromHexString(hexString) {\n        const buffer = UUID.bytesFromString(hexString);\n        return new UUID(buffer);\n    }\n    static createFromBase64(base64) {\n        return new UUID(ByteUtils.fromBase64(base64));\n    }\n    static bytesFromString(representation) {\n        if (!UUID.isValidUUIDString(representation)) {\n            throw new BSONError('UUID string representation must be 32 hex digits or canonical hyphenated representation');\n        }\n        return ByteUtils.fromHex(representation.replace(/-/g, ''));\n    }\n    static isValidUUIDString(representation) {\n        return UUID_WITHOUT_DASHES.test(representation) || UUID_WITH_DASHES.test(representation);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        return `new UUID(${inspect(this.toHexString(), options)})`;\n    }\n}\n\nclass Code extends BSONValue {\n    get _bsontype() {\n        return 'Code';\n    }\n    constructor(code, scope) {\n        super();\n        this.code = code.toString();\n        this.scope = scope ?? null;\n    }\n    toJSON() {\n        if (this.scope != null) {\n            return { code: this.code, scope: this.scope };\n        }\n        return { code: this.code };\n    }\n    toExtendedJSON() {\n        if (this.scope) {\n            return { $code: this.code, $scope: this.scope };\n        }\n        return { $code: this.code };\n    }\n    static fromExtendedJSON(doc) {\n        return new Code(doc.$code, doc.$scope);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        let parametersString = inspect(this.code, options);\n        const multiLineFn = parametersString.includes('\\n');\n        if (this.scope != null) {\n            parametersString += `,${multiLineFn ? '\\n' : ' '}${inspect(this.scope, options)}`;\n        }\n        const endingNewline = multiLineFn && this.scope === null;\n        return `new Code(${multiLineFn ? '\\n' : ''}${parametersString}${endingNewline ? '\\n' : ''})`;\n    }\n}\n\nfunction isDBRefLike(value) {\n    return (value != null &&\n        typeof value === 'object' &&\n        '$id' in value &&\n        value.$id != null &&\n        '$ref' in value &&\n        typeof value.$ref === 'string' &&\n        (!('$db' in value) || ('$db' in value && typeof value.$db === 'string')));\n}\nclass DBRef extends BSONValue {\n    get _bsontype() {\n        return 'DBRef';\n    }\n    constructor(collection, oid, db, fields) {\n        super();\n        const parts = collection.split('.');\n        if (parts.length === 2) {\n            db = parts.shift();\n            collection = parts.shift();\n        }\n        this.collection = collection;\n        this.oid = oid;\n        this.db = db;\n        this.fields = fields || {};\n    }\n    get namespace() {\n        return this.collection;\n    }\n    set namespace(value) {\n        this.collection = value;\n    }\n    toJSON() {\n        const o = Object.assign({\n            $ref: this.collection,\n            $id: this.oid\n        }, this.fields);\n        if (this.db != null)\n            o.$db = this.db;\n        return o;\n    }\n    toExtendedJSON(options) {\n        options = options || {};\n        let o = {\n            $ref: this.collection,\n            $id: this.oid\n        };\n        if (options.legacy) {\n            return o;\n        }\n        if (this.db)\n            o.$db = this.db;\n        o = Object.assign(o, this.fields);\n        return o;\n    }\n    static fromExtendedJSON(doc) {\n        const copy = Object.assign({}, doc);\n        delete copy.$ref;\n        delete copy.$id;\n        delete copy.$db;\n        return new DBRef(doc.$ref, doc.$id, doc.$db, copy);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        const args = [\n            inspect(this.namespace, options),\n            inspect(this.oid, options),\n            ...(this.db ? [inspect(this.db, options)] : []),\n            ...(Object.keys(this.fields).length > 0 ? [inspect(this.fields, options)] : [])\n        ];\n        args[1] = inspect === defaultInspect ? `new ObjectId(${args[1]})` : args[1];\n        return `new DBRef(${args.join(', ')})`;\n    }\n}\n\nfunction removeLeadingZerosAndExplicitPlus(str) {\n    if (str === '') {\n        return str;\n    }\n    let startIndex = 0;\n    const isNegative = str[startIndex] === '-';\n    const isExplicitlyPositive = str[startIndex] === '+';\n    if (isExplicitlyPositive || isNegative) {\n        startIndex += 1;\n    }\n    let foundInsignificantZero = false;\n    for (; startIndex < str.length && str[startIndex] === '0'; ++startIndex) {\n        foundInsignificantZero = true;\n    }\n    if (!foundInsignificantZero) {\n        return isExplicitlyPositive ? str.slice(1) : str;\n    }\n    return `${isNegative ? '-' : ''}${str.length === startIndex ? '0' : str.slice(startIndex)}`;\n}\nfunction validateStringCharacters(str, radix) {\n    radix = radix ?? 10;\n    const validCharacters = '0123456789abcdefghijklmnopqrstuvwxyz'.slice(0, radix);\n    const regex = new RegExp(`[^-+${validCharacters}]`, 'i');\n    return regex.test(str) ? false : str;\n}\n\nlet wasm = undefined;\ntry {\n    wasm = new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 13, 2, 96, 0, 1, 127, 96, 4, 127, 127, 127, 127, 1, 127, 3, 7, 6, 0, 1, 1, 1, 1, 1, 6, 6, 1, 127, 1, 65, 0, 11, 7, 50, 6, 3, 109, 117, 108, 0, 1, 5, 100, 105, 118, 95, 115, 0, 2, 5, 100, 105, 118, 95, 117, 0, 3, 5, 114, 101, 109, 95, 115, 0, 4, 5, 114, 101, 109, 95, 117, 0, 5, 8, 103, 101, 116, 95, 104, 105, 103, 104, 0, 0, 10, 191, 1, 6, 4, 0, 35, 0, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 126, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 127, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 128, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 129, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 130, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11])), {}).exports;\n}\ncatch {\n}\nconst TWO_PWR_16_DBL = 1 << 16;\nconst TWO_PWR_24_DBL = 1 << 24;\nconst TWO_PWR_32_DBL = TWO_PWR_16_DBL * TWO_PWR_16_DBL;\nconst TWO_PWR_64_DBL = TWO_PWR_32_DBL * TWO_PWR_32_DBL;\nconst TWO_PWR_63_DBL = TWO_PWR_64_DBL / 2;\nconst INT_CACHE = {};\nconst UINT_CACHE = {};\nconst MAX_INT64_STRING_LENGTH = 20;\nconst DECIMAL_REG_EX = /^(\\+?0|(\\+|-)?[1-9][0-9]*)$/;\nclass Long extends BSONValue {\n    get _bsontype() {\n        return 'Long';\n    }\n    get __isLong__() {\n        return true;\n    }\n    constructor(lowOrValue = 0, highOrUnsigned, unsigned) {\n        super();\n        const unsignedBool = typeof highOrUnsigned === 'boolean' ? highOrUnsigned : Boolean(unsigned);\n        const high = typeof highOrUnsigned === 'number' ? highOrUnsigned : 0;\n        const res = typeof lowOrValue === 'string'\n            ? Long.fromString(lowOrValue, unsignedBool)\n            : typeof lowOrValue === 'bigint'\n                ? Long.fromBigInt(lowOrValue, unsignedBool)\n                : { low: lowOrValue | 0, high: high | 0, unsigned: unsignedBool };\n        this.low = res.low;\n        this.high = res.high;\n        this.unsigned = res.unsigned;\n    }\n    static fromBits(lowBits, highBits, unsigned) {\n        return new Long(lowBits, highBits, unsigned);\n    }\n    static fromInt(value, unsigned) {\n        let obj, cachedObj, cache;\n        if (unsigned) {\n            value >>>= 0;\n            if ((cache = 0 <= value && value < 256)) {\n                cachedObj = UINT_CACHE[value];\n                if (cachedObj)\n                    return cachedObj;\n            }\n            obj = Long.fromBits(value, (value | 0) < 0 ? -1 : 0, true);\n            if (cache)\n                UINT_CACHE[value] = obj;\n            return obj;\n        }\n        else {\n            value |= 0;\n            if ((cache = -128 <= value && value < 128)) {\n                cachedObj = INT_CACHE[value];\n                if (cachedObj)\n                    return cachedObj;\n            }\n            obj = Long.fromBits(value, value < 0 ? -1 : 0, false);\n            if (cache)\n                INT_CACHE[value] = obj;\n            return obj;\n        }\n    }\n    static fromNumber(value, unsigned) {\n        if (isNaN(value))\n            return unsigned ? Long.UZERO : Long.ZERO;\n        if (unsigned) {\n            if (value < 0)\n                return Long.UZERO;\n            if (value >= TWO_PWR_64_DBL)\n                return Long.MAX_UNSIGNED_VALUE;\n        }\n        else {\n            if (value <= -TWO_PWR_63_DBL)\n                return Long.MIN_VALUE;\n            if (value + 1 >= TWO_PWR_63_DBL)\n                return Long.MAX_VALUE;\n        }\n        if (value < 0)\n            return Long.fromNumber(-value, unsigned).neg();\n        return Long.fromBits(value % TWO_PWR_32_DBL | 0, (value / TWO_PWR_32_DBL) | 0, unsigned);\n    }\n    static fromBigInt(value, unsigned) {\n        const FROM_BIGINT_BIT_MASK = BigInt(0xffffffff);\n        const FROM_BIGINT_BIT_SHIFT = BigInt(32);\n        return new Long(Number(value & FROM_BIGINT_BIT_MASK), Number((value >> FROM_BIGINT_BIT_SHIFT) & FROM_BIGINT_BIT_MASK), unsigned);\n    }\n    static _fromString(str, unsigned, radix) {\n        if (str.length === 0)\n            throw new BSONError('empty string');\n        if (radix < 2 || 36 < radix)\n            throw new BSONError('radix');\n        let p;\n        if ((p = str.indexOf('-')) > 0)\n            throw new BSONError('interior hyphen');\n        else if (p === 0) {\n            return Long._fromString(str.substring(1), unsigned, radix).neg();\n        }\n        const radixToPower = Long.fromNumber(Math.pow(radix, 8));\n        let result = Long.ZERO;\n        for (let i = 0; i < str.length; i += 8) {\n            const size = Math.min(8, str.length - i), value = parseInt(str.substring(i, i + size), radix);\n            if (size < 8) {\n                const power = Long.fromNumber(Math.pow(radix, size));\n                result = result.mul(power).add(Long.fromNumber(value));\n            }\n            else {\n                result = result.mul(radixToPower);\n                result = result.add(Long.fromNumber(value));\n            }\n        }\n        result.unsigned = unsigned;\n        return result;\n    }\n    static fromStringStrict(str, unsignedOrRadix, radix) {\n        let unsigned = false;\n        if (typeof unsignedOrRadix === 'number') {\n            (radix = unsignedOrRadix), (unsignedOrRadix = false);\n        }\n        else {\n            unsigned = !!unsignedOrRadix;\n        }\n        radix ??= 10;\n        if (str.trim() !== str) {\n            throw new BSONError(`Input: '${str}' contains leading and/or trailing whitespace`);\n        }\n        if (!validateStringCharacters(str, radix)) {\n            throw new BSONError(`Input: '${str}' contains invalid characters for radix: ${radix}`);\n        }\n        const cleanedStr = removeLeadingZerosAndExplicitPlus(str);\n        const result = Long._fromString(cleanedStr, unsigned, radix);\n        if (result.toString(radix).toLowerCase() !== cleanedStr.toLowerCase()) {\n            throw new BSONError(`Input: ${str} is not representable as ${result.unsigned ? 'an unsigned' : 'a signed'} 64-bit Long ${radix != null ? `with radix: ${radix}` : ''}`);\n        }\n        return result;\n    }\n    static fromString(str, unsignedOrRadix, radix) {\n        let unsigned = false;\n        if (typeof unsignedOrRadix === 'number') {\n            (radix = unsignedOrRadix), (unsignedOrRadix = false);\n        }\n        else {\n            unsigned = !!unsignedOrRadix;\n        }\n        radix ??= 10;\n        if (str === 'NaN' && radix < 24) {\n            return Long.ZERO;\n        }\n        else if ((str === 'Infinity' || str === '+Infinity' || str === '-Infinity') && radix < 35) {\n            return Long.ZERO;\n        }\n        return Long._fromString(str, unsigned, radix);\n    }\n    static fromBytes(bytes, unsigned, le) {\n        return le ? Long.fromBytesLE(bytes, unsigned) : Long.fromBytesBE(bytes, unsigned);\n    }\n    static fromBytesLE(bytes, unsigned) {\n        return new Long(bytes[0] | (bytes[1] << 8) | (bytes[2] << 16) | (bytes[3] << 24), bytes[4] | (bytes[5] << 8) | (bytes[6] << 16) | (bytes[7] << 24), unsigned);\n    }\n    static fromBytesBE(bytes, unsigned) {\n        return new Long((bytes[4] << 24) | (bytes[5] << 16) | (bytes[6] << 8) | bytes[7], (bytes[0] << 24) | (bytes[1] << 16) | (bytes[2] << 8) | bytes[3], unsigned);\n    }\n    static isLong(value) {\n        return (value != null &&\n            typeof value === 'object' &&\n            '__isLong__' in value &&\n            value.__isLong__ === true);\n    }\n    static fromValue(val, unsigned) {\n        if (typeof val === 'number')\n            return Long.fromNumber(val, unsigned);\n        if (typeof val === 'string')\n            return Long.fromString(val, unsigned);\n        return Long.fromBits(val.low, val.high, typeof unsigned === 'boolean' ? unsigned : val.unsigned);\n    }\n    add(addend) {\n        if (!Long.isLong(addend))\n            addend = Long.fromValue(addend);\n        const a48 = this.high >>> 16;\n        const a32 = this.high & 0xffff;\n        const a16 = this.low >>> 16;\n        const a00 = this.low & 0xffff;\n        const b48 = addend.high >>> 16;\n        const b32 = addend.high & 0xffff;\n        const b16 = addend.low >>> 16;\n        const b00 = addend.low & 0xffff;\n        let c48 = 0, c32 = 0, c16 = 0, c00 = 0;\n        c00 += a00 + b00;\n        c16 += c00 >>> 16;\n        c00 &= 0xffff;\n        c16 += a16 + b16;\n        c32 += c16 >>> 16;\n        c16 &= 0xffff;\n        c32 += a32 + b32;\n        c48 += c32 >>> 16;\n        c32 &= 0xffff;\n        c48 += a48 + b48;\n        c48 &= 0xffff;\n        return Long.fromBits((c16 << 16) | c00, (c48 << 16) | c32, this.unsigned);\n    }\n    and(other) {\n        if (!Long.isLong(other))\n            other = Long.fromValue(other);\n        return Long.fromBits(this.low & other.low, this.high & other.high, this.unsigned);\n    }\n    compare(other) {\n        if (!Long.isLong(other))\n            other = Long.fromValue(other);\n        if (this.eq(other))\n            return 0;\n        const thisNeg = this.isNegative(), otherNeg = other.isNegative();\n        if (thisNeg && !otherNeg)\n            return -1;\n        if (!thisNeg && otherNeg)\n            return 1;\n        if (!this.unsigned)\n            return this.sub(other).isNegative() ? -1 : 1;\n        return other.high >>> 0 > this.high >>> 0 ||\n            (other.high === this.high && other.low >>> 0 > this.low >>> 0)\n            ? -1\n            : 1;\n    }\n    comp(other) {\n        return this.compare(other);\n    }\n    divide(divisor) {\n        if (!Long.isLong(divisor))\n            divisor = Long.fromValue(divisor);\n        if (divisor.isZero())\n            throw new BSONError('division by zero');\n        if (wasm) {\n            if (!this.unsigned &&\n                this.high === -0x80000000 &&\n                divisor.low === -1 &&\n                divisor.high === -1) {\n                return this;\n            }\n            const low = (this.unsigned ? wasm.div_u : wasm.div_s)(this.low, this.high, divisor.low, divisor.high);\n            return Long.fromBits(low, wasm.get_high(), this.unsigned);\n        }\n        if (this.isZero())\n            return this.unsigned ? Long.UZERO : Long.ZERO;\n        let approx, rem, res;\n        if (!this.unsigned) {\n            if (this.eq(Long.MIN_VALUE)) {\n                if (divisor.eq(Long.ONE) || divisor.eq(Long.NEG_ONE))\n                    return Long.MIN_VALUE;\n                else if (divisor.eq(Long.MIN_VALUE))\n                    return Long.ONE;\n                else {\n                    const halfThis = this.shr(1);\n                    approx = halfThis.div(divisor).shl(1);\n                    if (approx.eq(Long.ZERO)) {\n                        return divisor.isNegative() ? Long.ONE : Long.NEG_ONE;\n                    }\n                    else {\n                        rem = this.sub(divisor.mul(approx));\n                        res = approx.add(rem.div(divisor));\n                        return res;\n                    }\n                }\n            }\n            else if (divisor.eq(Long.MIN_VALUE))\n                return this.unsigned ? Long.UZERO : Long.ZERO;\n            if (this.isNegative()) {\n                if (divisor.isNegative())\n                    return this.neg().div(divisor.neg());\n                return this.neg().div(divisor).neg();\n            }\n            else if (divisor.isNegative())\n                return this.div(divisor.neg()).neg();\n            res = Long.ZERO;\n        }\n        else {\n            if (!divisor.unsigned)\n                divisor = divisor.toUnsigned();\n            if (divisor.gt(this))\n                return Long.UZERO;\n            if (divisor.gt(this.shru(1)))\n                return Long.UONE;\n            res = Long.UZERO;\n        }\n        rem = this;\n        while (rem.gte(divisor)) {\n            approx = Math.max(1, Math.floor(rem.toNumber() / divisor.toNumber()));\n            const log2 = Math.ceil(Math.log(approx) / Math.LN2);\n            const delta = log2 <= 48 ? 1 : Math.pow(2, log2 - 48);\n            let approxRes = Long.fromNumber(approx);\n            let approxRem = approxRes.mul(divisor);\n            while (approxRem.isNegative() || approxRem.gt(rem)) {\n                approx -= delta;\n                approxRes = Long.fromNumber(approx, this.unsigned);\n                approxRem = approxRes.mul(divisor);\n            }\n            if (approxRes.isZero())\n                approxRes = Long.ONE;\n            res = res.add(approxRes);\n            rem = rem.sub(approxRem);\n        }\n        return res;\n    }\n    div(divisor) {\n        return this.divide(divisor);\n    }\n    equals(other) {\n        if (!Long.isLong(other))\n            other = Long.fromValue(other);\n        if (this.unsigned !== other.unsigned && this.high >>> 31 === 1 && other.high >>> 31 === 1)\n            return false;\n        return this.high === other.high && this.low === other.low;\n    }\n    eq(other) {\n        return this.equals(other);\n    }\n    getHighBits() {\n        return this.high;\n    }\n    getHighBitsUnsigned() {\n        return this.high >>> 0;\n    }\n    getLowBits() {\n        return this.low;\n    }\n    getLowBitsUnsigned() {\n        return this.low >>> 0;\n    }\n    getNumBitsAbs() {\n        if (this.isNegative()) {\n            return this.eq(Long.MIN_VALUE) ? 64 : this.neg().getNumBitsAbs();\n        }\n        const val = this.high !== 0 ? this.high : this.low;\n        let bit;\n        for (bit = 31; bit > 0; bit--)\n            if ((val & (1 << bit)) !== 0)\n                break;\n        return this.high !== 0 ? bit + 33 : bit + 1;\n    }\n    greaterThan(other) {\n        return this.comp(other) > 0;\n    }\n    gt(other) {\n        return this.greaterThan(other);\n    }\n    greaterThanOrEqual(other) {\n        return this.comp(other) >= 0;\n    }\n    gte(other) {\n        return this.greaterThanOrEqual(other);\n    }\n    ge(other) {\n        return this.greaterThanOrEqual(other);\n    }\n    isEven() {\n        return (this.low & 1) === 0;\n    }\n    isNegative() {\n        return !this.unsigned && this.high < 0;\n    }\n    isOdd() {\n        return (this.low & 1) === 1;\n    }\n    isPositive() {\n        return this.unsigned || this.high >= 0;\n    }\n    isZero() {\n        return this.high === 0 && this.low === 0;\n    }\n    lessThan(other) {\n        return this.comp(other) < 0;\n    }\n    lt(other) {\n        return this.lessThan(other);\n    }\n    lessThanOrEqual(other) {\n        return this.comp(other) <= 0;\n    }\n    lte(other) {\n        return this.lessThanOrEqual(other);\n    }\n    modulo(divisor) {\n        if (!Long.isLong(divisor))\n            divisor = Long.fromValue(divisor);\n        if (wasm) {\n            const low = (this.unsigned ? wasm.rem_u : wasm.rem_s)(this.low, this.high, divisor.low, divisor.high);\n            return Long.fromBits(low, wasm.get_high(), this.unsigned);\n        }\n        return this.sub(this.div(divisor).mul(divisor));\n    }\n    mod(divisor) {\n        return this.modulo(divisor);\n    }\n    rem(divisor) {\n        return this.modulo(divisor);\n    }\n    multiply(multiplier) {\n        if (this.isZero())\n            return Long.ZERO;\n        if (!Long.isLong(multiplier))\n            multiplier = Long.fromValue(multiplier);\n        if (wasm) {\n            const low = wasm.mul(this.low, this.high, multiplier.low, multiplier.high);\n            return Long.fromBits(low, wasm.get_high(), this.unsigned);\n        }\n        if (multiplier.isZero())\n            return Long.ZERO;\n        if (this.eq(Long.MIN_VALUE))\n            return multiplier.isOdd() ? Long.MIN_VALUE : Long.ZERO;\n        if (multiplier.eq(Long.MIN_VALUE))\n            return this.isOdd() ? Long.MIN_VALUE : Long.ZERO;\n        if (this.isNegative()) {\n            if (multiplier.isNegative())\n                return this.neg().mul(multiplier.neg());\n            else\n                return this.neg().mul(multiplier).neg();\n        }\n        else if (multiplier.isNegative())\n            return this.mul(multiplier.neg()).neg();\n        if (this.lt(Long.TWO_PWR_24) && multiplier.lt(Long.TWO_PWR_24))\n            return Long.fromNumber(this.toNumber() * multiplier.toNumber(), this.unsigned);\n        const a48 = this.high >>> 16;\n        const a32 = this.high & 0xffff;\n        const a16 = this.low >>> 16;\n        const a00 = this.low & 0xffff;\n        const b48 = multiplier.high >>> 16;\n        const b32 = multiplier.high & 0xffff;\n        const b16 = multiplier.low >>> 16;\n        const b00 = multiplier.low & 0xffff;\n        let c48 = 0, c32 = 0, c16 = 0, c00 = 0;\n        c00 += a00 * b00;\n        c16 += c00 >>> 16;\n        c00 &= 0xffff;\n        c16 += a16 * b00;\n        c32 += c16 >>> 16;\n        c16 &= 0xffff;\n        c16 += a00 * b16;\n        c32 += c16 >>> 16;\n        c16 &= 0xffff;\n        c32 += a32 * b00;\n        c48 += c32 >>> 16;\n        c32 &= 0xffff;\n        c32 += a16 * b16;\n        c48 += c32 >>> 16;\n        c32 &= 0xffff;\n        c32 += a00 * b32;\n        c48 += c32 >>> 16;\n        c32 &= 0xffff;\n        c48 += a48 * b00 + a32 * b16 + a16 * b32 + a00 * b48;\n        c48 &= 0xffff;\n        return Long.fromBits((c16 << 16) | c00, (c48 << 16) | c32, this.unsigned);\n    }\n    mul(multiplier) {\n        return this.multiply(multiplier);\n    }\n    negate() {\n        if (!this.unsigned && this.eq(Long.MIN_VALUE))\n            return Long.MIN_VALUE;\n        return this.not().add(Long.ONE);\n    }\n    neg() {\n        return this.negate();\n    }\n    not() {\n        return Long.fromBits(~this.low, ~this.high, this.unsigned);\n    }\n    notEquals(other) {\n        return !this.equals(other);\n    }\n    neq(other) {\n        return this.notEquals(other);\n    }\n    ne(other) {\n        return this.notEquals(other);\n    }\n    or(other) {\n        if (!Long.isLong(other))\n            other = Long.fromValue(other);\n        return Long.fromBits(this.low | other.low, this.high | other.high, this.unsigned);\n    }\n    shiftLeft(numBits) {\n        if (Long.isLong(numBits))\n            numBits = numBits.toInt();\n        if ((numBits &= 63) === 0)\n            return this;\n        else if (numBits < 32)\n            return Long.fromBits(this.low << numBits, (this.high << numBits) | (this.low >>> (32 - numBits)), this.unsigned);\n        else\n            return Long.fromBits(0, this.low << (numBits - 32), this.unsigned);\n    }\n    shl(numBits) {\n        return this.shiftLeft(numBits);\n    }\n    shiftRight(numBits) {\n        if (Long.isLong(numBits))\n            numBits = numBits.toInt();\n        if ((numBits &= 63) === 0)\n            return this;\n        else if (numBits < 32)\n            return Long.fromBits((this.low >>> numBits) | (this.high << (32 - numBits)), this.high >> numBits, this.unsigned);\n        else\n            return Long.fromBits(this.high >> (numBits - 32), this.high >= 0 ? 0 : -1, this.unsigned);\n    }\n    shr(numBits) {\n        return this.shiftRight(numBits);\n    }\n    shiftRightUnsigned(numBits) {\n        if (Long.isLong(numBits))\n            numBits = numBits.toInt();\n        numBits &= 63;\n        if (numBits === 0)\n            return this;\n        else {\n            const high = this.high;\n            if (numBits < 32) {\n                const low = this.low;\n                return Long.fromBits((low >>> numBits) | (high << (32 - numBits)), high >>> numBits, this.unsigned);\n            }\n            else if (numBits === 32)\n                return Long.fromBits(high, 0, this.unsigned);\n            else\n                return Long.fromBits(high >>> (numBits - 32), 0, this.unsigned);\n        }\n    }\n    shr_u(numBits) {\n        return this.shiftRightUnsigned(numBits);\n    }\n    shru(numBits) {\n        return this.shiftRightUnsigned(numBits);\n    }\n    subtract(subtrahend) {\n        if (!Long.isLong(subtrahend))\n            subtrahend = Long.fromValue(subtrahend);\n        return this.add(subtrahend.neg());\n    }\n    sub(subtrahend) {\n        return this.subtract(subtrahend);\n    }\n    toInt() {\n        return this.unsigned ? this.low >>> 0 : this.low;\n    }\n    toNumber() {\n        if (this.unsigned)\n            return (this.high >>> 0) * TWO_PWR_32_DBL + (this.low >>> 0);\n        return this.high * TWO_PWR_32_DBL + (this.low >>> 0);\n    }\n    toBigInt() {\n        return BigInt(this.toString());\n    }\n    toBytes(le) {\n        return le ? this.toBytesLE() : this.toBytesBE();\n    }\n    toBytesLE() {\n        const hi = this.high, lo = this.low;\n        return [\n            lo & 0xff,\n            (lo >>> 8) & 0xff,\n            (lo >>> 16) & 0xff,\n            lo >>> 24,\n            hi & 0xff,\n            (hi >>> 8) & 0xff,\n            (hi >>> 16) & 0xff,\n            hi >>> 24\n        ];\n    }\n    toBytesBE() {\n        const hi = this.high, lo = this.low;\n        return [\n            hi >>> 24,\n            (hi >>> 16) & 0xff,\n            (hi >>> 8) & 0xff,\n            hi & 0xff,\n            lo >>> 24,\n            (lo >>> 16) & 0xff,\n            (lo >>> 8) & 0xff,\n            lo & 0xff\n        ];\n    }\n    toSigned() {\n        if (!this.unsigned)\n            return this;\n        return Long.fromBits(this.low, this.high, false);\n    }\n    toString(radix) {\n        radix = radix || 10;\n        if (radix < 2 || 36 < radix)\n            throw new BSONError('radix');\n        if (this.isZero())\n            return '0';\n        if (this.isNegative()) {\n            if (this.eq(Long.MIN_VALUE)) {\n                const radixLong = Long.fromNumber(radix), div = this.div(radixLong), rem1 = div.mul(radixLong).sub(this);\n                return div.toString(radix) + rem1.toInt().toString(radix);\n            }\n            else\n                return '-' + this.neg().toString(radix);\n        }\n        const radixToPower = Long.fromNumber(Math.pow(radix, 6), this.unsigned);\n        let rem = this;\n        let result = '';\n        while (true) {\n            const remDiv = rem.div(radixToPower);\n            const intval = rem.sub(remDiv.mul(radixToPower)).toInt() >>> 0;\n            let digits = intval.toString(radix);\n            rem = remDiv;\n            if (rem.isZero()) {\n                return digits + result;\n            }\n            else {\n                while (digits.length < 6)\n                    digits = '0' + digits;\n                result = '' + digits + result;\n            }\n        }\n    }\n    toUnsigned() {\n        if (this.unsigned)\n            return this;\n        return Long.fromBits(this.low, this.high, true);\n    }\n    xor(other) {\n        if (!Long.isLong(other))\n            other = Long.fromValue(other);\n        return Long.fromBits(this.low ^ other.low, this.high ^ other.high, this.unsigned);\n    }\n    eqz() {\n        return this.isZero();\n    }\n    le(other) {\n        return this.lessThanOrEqual(other);\n    }\n    toExtendedJSON(options) {\n        if (options && options.relaxed)\n            return this.toNumber();\n        return { $numberLong: this.toString() };\n    }\n    static fromExtendedJSON(doc, options) {\n        const { useBigInt64 = false, relaxed = true } = { ...options };\n        if (doc.$numberLong.length > MAX_INT64_STRING_LENGTH) {\n            throw new BSONError('$numberLong string is too long');\n        }\n        if (!DECIMAL_REG_EX.test(doc.$numberLong)) {\n            throw new BSONError(`$numberLong string \"${doc.$numberLong}\" is in an invalid format`);\n        }\n        if (useBigInt64) {\n            const bigIntResult = BigInt(doc.$numberLong);\n            return BigInt.asIntN(64, bigIntResult);\n        }\n        const longResult = Long.fromString(doc.$numberLong);\n        if (relaxed) {\n            return longResult.toNumber();\n        }\n        return longResult;\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        const longVal = inspect(this.toString(), options);\n        const unsignedVal = this.unsigned ? `, ${inspect(this.unsigned, options)}` : '';\n        return `new Long(${longVal}${unsignedVal})`;\n    }\n}\nLong.TWO_PWR_24 = Long.fromInt(TWO_PWR_24_DBL);\nLong.MAX_UNSIGNED_VALUE = Long.fromBits(0xffffffff | 0, 0xffffffff | 0, true);\nLong.ZERO = Long.fromInt(0);\nLong.UZERO = Long.fromInt(0, true);\nLong.ONE = Long.fromInt(1);\nLong.UONE = Long.fromInt(1, true);\nLong.NEG_ONE = Long.fromInt(-1);\nLong.MAX_VALUE = Long.fromBits(0xffffffff | 0, 0x7fffffff | 0, false);\nLong.MIN_VALUE = Long.fromBits(0, 0x80000000 | 0, false);\n\nconst PARSE_STRING_REGEXP = /^(\\+|-)?(\\d+|(\\d*\\.\\d*))?(E|e)?([-+])?(\\d+)?$/;\nconst PARSE_INF_REGEXP = /^(\\+|-)?(Infinity|inf)$/i;\nconst PARSE_NAN_REGEXP = /^(\\+|-)?NaN$/i;\nconst EXPONENT_MAX = 6111;\nconst EXPONENT_MIN = -6176;\nconst EXPONENT_BIAS = 6176;\nconst MAX_DIGITS = 34;\nconst NAN_BUFFER = ByteUtils.fromNumberArray([\n    0x7c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00\n].reverse());\nconst INF_NEGATIVE_BUFFER = ByteUtils.fromNumberArray([\n    0xf8, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00\n].reverse());\nconst INF_POSITIVE_BUFFER = ByteUtils.fromNumberArray([\n    0x78, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00\n].reverse());\nconst EXPONENT_REGEX = /^([-+])?(\\d+)?$/;\nconst COMBINATION_MASK = 0x1f;\nconst EXPONENT_MASK = 0x3fff;\nconst COMBINATION_INFINITY = 30;\nconst COMBINATION_NAN = 31;\nfunction isDigit(value) {\n    return !isNaN(parseInt(value, 10));\n}\nfunction divideu128(value) {\n    const DIVISOR = Long.fromNumber(1000 * 1000 * 1000);\n    let _rem = Long.fromNumber(0);\n    if (!value.parts[0] && !value.parts[1] && !value.parts[2] && !value.parts[3]) {\n        return { quotient: value, rem: _rem };\n    }\n    for (let i = 0; i <= 3; i++) {\n        _rem = _rem.shiftLeft(32);\n        _rem = _rem.add(new Long(value.parts[i], 0));\n        value.parts[i] = _rem.div(DIVISOR).low;\n        _rem = _rem.modulo(DIVISOR);\n    }\n    return { quotient: value, rem: _rem };\n}\nfunction multiply64x2(left, right) {\n    if (!left && !right) {\n        return { high: Long.fromNumber(0), low: Long.fromNumber(0) };\n    }\n    const leftHigh = left.shiftRightUnsigned(32);\n    const leftLow = new Long(left.getLowBits(), 0);\n    const rightHigh = right.shiftRightUnsigned(32);\n    const rightLow = new Long(right.getLowBits(), 0);\n    let productHigh = leftHigh.multiply(rightHigh);\n    let productMid = leftHigh.multiply(rightLow);\n    const productMid2 = leftLow.multiply(rightHigh);\n    let productLow = leftLow.multiply(rightLow);\n    productHigh = productHigh.add(productMid.shiftRightUnsigned(32));\n    productMid = new Long(productMid.getLowBits(), 0)\n        .add(productMid2)\n        .add(productLow.shiftRightUnsigned(32));\n    productHigh = productHigh.add(productMid.shiftRightUnsigned(32));\n    productLow = productMid.shiftLeft(32).add(new Long(productLow.getLowBits(), 0));\n    return { high: productHigh, low: productLow };\n}\nfunction lessThan(left, right) {\n    const uhleft = left.high >>> 0;\n    const uhright = right.high >>> 0;\n    if (uhleft < uhright) {\n        return true;\n    }\n    else if (uhleft === uhright) {\n        const ulleft = left.low >>> 0;\n        const ulright = right.low >>> 0;\n        if (ulleft < ulright)\n            return true;\n    }\n    return false;\n}\nfunction invalidErr(string, message) {\n    throw new BSONError(`\"${string}\" is not a valid Decimal128 string - ${message}`);\n}\nclass Decimal128 extends BSONValue {\n    get _bsontype() {\n        return 'Decimal128';\n    }\n    constructor(bytes) {\n        super();\n        if (typeof bytes === 'string') {\n            this.bytes = Decimal128.fromString(bytes).bytes;\n        }\n        else if (isUint8Array(bytes)) {\n            if (bytes.byteLength !== 16) {\n                throw new BSONError('Decimal128 must take a Buffer of 16 bytes');\n            }\n            this.bytes = bytes;\n        }\n        else {\n            throw new BSONError('Decimal128 must take a Buffer or string');\n        }\n    }\n    static fromString(representation) {\n        return Decimal128._fromString(representation, { allowRounding: false });\n    }\n    static fromStringWithRounding(representation) {\n        return Decimal128._fromString(representation, { allowRounding: true });\n    }\n    static _fromString(representation, options) {\n        let isNegative = false;\n        let sawSign = false;\n        let sawRadix = false;\n        let foundNonZero = false;\n        let significantDigits = 0;\n        let nDigitsRead = 0;\n        let nDigits = 0;\n        let radixPosition = 0;\n        let firstNonZero = 0;\n        const digits = [0];\n        let nDigitsStored = 0;\n        let digitsInsert = 0;\n        let lastDigit = 0;\n        let exponent = 0;\n        let significandHigh = new Long(0, 0);\n        let significandLow = new Long(0, 0);\n        let biasedExponent = 0;\n        let index = 0;\n        if (representation.length >= 7000) {\n            throw new BSONError('' + representation + ' not a valid Decimal128 string');\n        }\n        const stringMatch = representation.match(PARSE_STRING_REGEXP);\n        const infMatch = representation.match(PARSE_INF_REGEXP);\n        const nanMatch = representation.match(PARSE_NAN_REGEXP);\n        if ((!stringMatch && !infMatch && !nanMatch) || representation.length === 0) {\n            throw new BSONError('' + representation + ' not a valid Decimal128 string');\n        }\n        if (stringMatch) {\n            const unsignedNumber = stringMatch[2];\n            const e = stringMatch[4];\n            const expSign = stringMatch[5];\n            const expNumber = stringMatch[6];\n            if (e && expNumber === undefined)\n                invalidErr(representation, 'missing exponent power');\n            if (e && unsignedNumber === undefined)\n                invalidErr(representation, 'missing exponent base');\n            if (e === undefined && (expSign || expNumber)) {\n                invalidErr(representation, 'missing e before exponent');\n            }\n        }\n        if (representation[index] === '+' || representation[index] === '-') {\n            sawSign = true;\n            isNegative = representation[index++] === '-';\n        }\n        if (!isDigit(representation[index]) && representation[index] !== '.') {\n            if (representation[index] === 'i' || representation[index] === 'I') {\n                return new Decimal128(isNegative ? INF_NEGATIVE_BUFFER : INF_POSITIVE_BUFFER);\n            }\n            else if (representation[index] === 'N') {\n                return new Decimal128(NAN_BUFFER);\n            }\n        }\n        while (isDigit(representation[index]) || representation[index] === '.') {\n            if (representation[index] === '.') {\n                if (sawRadix)\n                    invalidErr(representation, 'contains multiple periods');\n                sawRadix = true;\n                index = index + 1;\n                continue;\n            }\n            if (nDigitsStored < MAX_DIGITS) {\n                if (representation[index] !== '0' || foundNonZero) {\n                    if (!foundNonZero) {\n                        firstNonZero = nDigitsRead;\n                    }\n                    foundNonZero = true;\n                    digits[digitsInsert++] = parseInt(representation[index], 10);\n                    nDigitsStored = nDigitsStored + 1;\n                }\n            }\n            if (foundNonZero)\n                nDigits = nDigits + 1;\n            if (sawRadix)\n                radixPosition = radixPosition + 1;\n            nDigitsRead = nDigitsRead + 1;\n            index = index + 1;\n        }\n        if (sawRadix && !nDigitsRead)\n            throw new BSONError('' + representation + ' not a valid Decimal128 string');\n        if (representation[index] === 'e' || representation[index] === 'E') {\n            const match = representation.substr(++index).match(EXPONENT_REGEX);\n            if (!match || !match[2])\n                return new Decimal128(NAN_BUFFER);\n            exponent = parseInt(match[0], 10);\n            index = index + match[0].length;\n        }\n        if (representation[index])\n            return new Decimal128(NAN_BUFFER);\n        if (!nDigitsStored) {\n            digits[0] = 0;\n            nDigits = 1;\n            nDigitsStored = 1;\n            significantDigits = 0;\n        }\n        else {\n            lastDigit = nDigitsStored - 1;\n            significantDigits = nDigits;\n            if (significantDigits !== 1) {\n                while (representation[firstNonZero + significantDigits - 1 + Number(sawSign) + Number(sawRadix)] === '0') {\n                    significantDigits = significantDigits - 1;\n                }\n            }\n        }\n        if (exponent <= radixPosition && radixPosition > exponent + (1 << 14)) {\n            exponent = EXPONENT_MIN;\n        }\n        else {\n            exponent = exponent - radixPosition;\n        }\n        while (exponent > EXPONENT_MAX) {\n            lastDigit = lastDigit + 1;\n            if (lastDigit >= MAX_DIGITS) {\n                if (significantDigits === 0) {\n                    exponent = EXPONENT_MAX;\n                    break;\n                }\n                invalidErr(representation, 'overflow');\n            }\n            exponent = exponent - 1;\n        }\n        if (options.allowRounding) {\n            while (exponent < EXPONENT_MIN || nDigitsStored < nDigits) {\n                if (lastDigit === 0 && significantDigits < nDigitsStored) {\n                    exponent = EXPONENT_MIN;\n                    significantDigits = 0;\n                    break;\n                }\n                if (nDigitsStored < nDigits) {\n                    nDigits = nDigits - 1;\n                }\n                else {\n                    lastDigit = lastDigit - 1;\n                }\n                if (exponent < EXPONENT_MAX) {\n                    exponent = exponent + 1;\n                }\n                else {\n                    const digitsString = digits.join('');\n                    if (digitsString.match(/^0+$/)) {\n                        exponent = EXPONENT_MAX;\n                        break;\n                    }\n                    invalidErr(representation, 'overflow');\n                }\n            }\n            if (lastDigit + 1 < significantDigits) {\n                let endOfString = nDigitsRead;\n                if (sawRadix) {\n                    firstNonZero = firstNonZero + 1;\n                    endOfString = endOfString + 1;\n                }\n                if (sawSign) {\n                    firstNonZero = firstNonZero + 1;\n                    endOfString = endOfString + 1;\n                }\n                const roundDigit = parseInt(representation[firstNonZero + lastDigit + 1], 10);\n                let roundBit = 0;\n                if (roundDigit >= 5) {\n                    roundBit = 1;\n                    if (roundDigit === 5) {\n                        roundBit = digits[lastDigit] % 2 === 1 ? 1 : 0;\n                        for (let i = firstNonZero + lastDigit + 2; i < endOfString; i++) {\n                            if (parseInt(representation[i], 10)) {\n                                roundBit = 1;\n                                break;\n                            }\n                        }\n                    }\n                }\n                if (roundBit) {\n                    let dIdx = lastDigit;\n                    for (; dIdx >= 0; dIdx--) {\n                        if (++digits[dIdx] > 9) {\n                            digits[dIdx] = 0;\n                            if (dIdx === 0) {\n                                if (exponent < EXPONENT_MAX) {\n                                    exponent = exponent + 1;\n                                    digits[dIdx] = 1;\n                                }\n                                else {\n                                    return new Decimal128(isNegative ? INF_NEGATIVE_BUFFER : INF_POSITIVE_BUFFER);\n                                }\n                            }\n                        }\n                        else {\n                            break;\n                        }\n                    }\n                }\n            }\n        }\n        else {\n            while (exponent < EXPONENT_MIN || nDigitsStored < nDigits) {\n                if (lastDigit === 0) {\n                    if (significantDigits === 0) {\n                        exponent = EXPONENT_MIN;\n                        break;\n                    }\n                    invalidErr(representation, 'exponent underflow');\n                }\n                if (nDigitsStored < nDigits) {\n                    if (representation[nDigits - 1 + Number(sawSign) + Number(sawRadix)] !== '0' &&\n                        significantDigits !== 0) {\n                        invalidErr(representation, 'inexact rounding');\n                    }\n                    nDigits = nDigits - 1;\n                }\n                else {\n                    if (digits[lastDigit] !== 0) {\n                        invalidErr(representation, 'inexact rounding');\n                    }\n                    lastDigit = lastDigit - 1;\n                }\n                if (exponent < EXPONENT_MAX) {\n                    exponent = exponent + 1;\n                }\n                else {\n                    invalidErr(representation, 'overflow');\n                }\n            }\n            if (lastDigit + 1 < significantDigits) {\n                if (sawRadix) {\n                    firstNonZero = firstNonZero + 1;\n                }\n                if (sawSign) {\n                    firstNonZero = firstNonZero + 1;\n                }\n                const roundDigit = parseInt(representation[firstNonZero + lastDigit + 1], 10);\n                if (roundDigit !== 0) {\n                    invalidErr(representation, 'inexact rounding');\n                }\n            }\n        }\n        significandHigh = Long.fromNumber(0);\n        significandLow = Long.fromNumber(0);\n        if (significantDigits === 0) {\n            significandHigh = Long.fromNumber(0);\n            significandLow = Long.fromNumber(0);\n        }\n        else if (lastDigit < 17) {\n            let dIdx = 0;\n            significandLow = Long.fromNumber(digits[dIdx++]);\n            significandHigh = new Long(0, 0);\n            for (; dIdx <= lastDigit; dIdx++) {\n                significandLow = significandLow.multiply(Long.fromNumber(10));\n                significandLow = significandLow.add(Long.fromNumber(digits[dIdx]));\n            }\n        }\n        else {\n            let dIdx = 0;\n            significandHigh = Long.fromNumber(digits[dIdx++]);\n            for (; dIdx <= lastDigit - 17; dIdx++) {\n                significandHigh = significandHigh.multiply(Long.fromNumber(10));\n                significandHigh = significandHigh.add(Long.fromNumber(digits[dIdx]));\n            }\n            significandLow = Long.fromNumber(digits[dIdx++]);\n            for (; dIdx <= lastDigit; dIdx++) {\n                significandLow = significandLow.multiply(Long.fromNumber(10));\n                significandLow = significandLow.add(Long.fromNumber(digits[dIdx]));\n            }\n        }\n        const significand = multiply64x2(significandHigh, Long.fromString('100000000000000000'));\n        significand.low = significand.low.add(significandLow);\n        if (lessThan(significand.low, significandLow)) {\n            significand.high = significand.high.add(Long.fromNumber(1));\n        }\n        biasedExponent = exponent + EXPONENT_BIAS;\n        const dec = { low: Long.fromNumber(0), high: Long.fromNumber(0) };\n        if (significand.high.shiftRightUnsigned(49).and(Long.fromNumber(1)).equals(Long.fromNumber(1))) {\n            dec.high = dec.high.or(Long.fromNumber(0x3).shiftLeft(61));\n            dec.high = dec.high.or(Long.fromNumber(biasedExponent).and(Long.fromNumber(0x3fff).shiftLeft(47)));\n            dec.high = dec.high.or(significand.high.and(Long.fromNumber(0x7fffffffffff)));\n        }\n        else {\n            dec.high = dec.high.or(Long.fromNumber(biasedExponent & 0x3fff).shiftLeft(49));\n            dec.high = dec.high.or(significand.high.and(Long.fromNumber(0x1ffffffffffff)));\n        }\n        dec.low = significand.low;\n        if (isNegative) {\n            dec.high = dec.high.or(Long.fromString('9223372036854775808'));\n        }\n        const buffer = ByteUtils.allocateUnsafe(16);\n        index = 0;\n        buffer[index++] = dec.low.low & 0xff;\n        buffer[index++] = (dec.low.low >> 8) & 0xff;\n        buffer[index++] = (dec.low.low >> 16) & 0xff;\n        buffer[index++] = (dec.low.low >> 24) & 0xff;\n        buffer[index++] = dec.low.high & 0xff;\n        buffer[index++] = (dec.low.high >> 8) & 0xff;\n        buffer[index++] = (dec.low.high >> 16) & 0xff;\n        buffer[index++] = (dec.low.high >> 24) & 0xff;\n        buffer[index++] = dec.high.low & 0xff;\n        buffer[index++] = (dec.high.low >> 8) & 0xff;\n        buffer[index++] = (dec.high.low >> 16) & 0xff;\n        buffer[index++] = (dec.high.low >> 24) & 0xff;\n        buffer[index++] = dec.high.high & 0xff;\n        buffer[index++] = (dec.high.high >> 8) & 0xff;\n        buffer[index++] = (dec.high.high >> 16) & 0xff;\n        buffer[index++] = (dec.high.high >> 24) & 0xff;\n        return new Decimal128(buffer);\n    }\n    toString() {\n        let biased_exponent;\n        let significand_digits = 0;\n        const significand = new Array(36);\n        for (let i = 0; i < significand.length; i++)\n            significand[i] = 0;\n        let index = 0;\n        let is_zero = false;\n        let significand_msb;\n        let significand128 = { parts: [0, 0, 0, 0] };\n        let j, k;\n        const string = [];\n        index = 0;\n        const buffer = this.bytes;\n        const low = buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24);\n        const midl = buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24);\n        const midh = buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24);\n        const high = buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24);\n        index = 0;\n        const dec = {\n            low: new Long(low, midl),\n            high: new Long(midh, high)\n        };\n        if (dec.high.lessThan(Long.ZERO)) {\n            string.push('-');\n        }\n        const combination = (high >> 26) & COMBINATION_MASK;\n        if (combination >> 3 === 3) {\n            if (combination === COMBINATION_INFINITY) {\n                return string.join('') + 'Infinity';\n            }\n            else if (combination === COMBINATION_NAN) {\n                return 'NaN';\n            }\n            else {\n                biased_exponent = (high >> 15) & EXPONENT_MASK;\n                significand_msb = 0x08 + ((high >> 14) & 0x01);\n            }\n        }\n        else {\n            significand_msb = (high >> 14) & 0x07;\n            biased_exponent = (high >> 17) & EXPONENT_MASK;\n        }\n        const exponent = biased_exponent - EXPONENT_BIAS;\n        significand128.parts[0] = (high & 0x3fff) + ((significand_msb & 0xf) << 14);\n        significand128.parts[1] = midh;\n        significand128.parts[2] = midl;\n        significand128.parts[3] = low;\n        if (significand128.parts[0] === 0 &&\n            significand128.parts[1] === 0 &&\n            significand128.parts[2] === 0 &&\n            significand128.parts[3] === 0) {\n            is_zero = true;\n        }\n        else {\n            for (k = 3; k >= 0; k--) {\n                let least_digits = 0;\n                const result = divideu128(significand128);\n                significand128 = result.quotient;\n                least_digits = result.rem.low;\n                if (!least_digits)\n                    continue;\n                for (j = 8; j >= 0; j--) {\n                    significand[k * 9 + j] = least_digits % 10;\n                    least_digits = Math.floor(least_digits / 10);\n                }\n            }\n        }\n        if (is_zero) {\n            significand_digits = 1;\n            significand[index] = 0;\n        }\n        else {\n            significand_digits = 36;\n            while (!significand[index]) {\n                significand_digits = significand_digits - 1;\n                index = index + 1;\n            }\n        }\n        const scientific_exponent = significand_digits - 1 + exponent;\n        if (scientific_exponent >= 34 || scientific_exponent <= -7 || exponent > 0) {\n            if (significand_digits > 34) {\n                string.push(`${0}`);\n                if (exponent > 0)\n                    string.push(`E+${exponent}`);\n                else if (exponent < 0)\n                    string.push(`E${exponent}`);\n                return string.join('');\n            }\n            string.push(`${significand[index++]}`);\n            significand_digits = significand_digits - 1;\n            if (significand_digits) {\n                string.push('.');\n            }\n            for (let i = 0; i < significand_digits; i++) {\n                string.push(`${significand[index++]}`);\n            }\n            string.push('E');\n            if (scientific_exponent > 0) {\n                string.push(`+${scientific_exponent}`);\n            }\n            else {\n                string.push(`${scientific_exponent}`);\n            }\n        }\n        else {\n            if (exponent >= 0) {\n                for (let i = 0; i < significand_digits; i++) {\n                    string.push(`${significand[index++]}`);\n                }\n            }\n            else {\n                let radix_position = significand_digits + exponent;\n                if (radix_position > 0) {\n                    for (let i = 0; i < radix_position; i++) {\n                        string.push(`${significand[index++]}`);\n                    }\n                }\n                else {\n                    string.push('0');\n                }\n                string.push('.');\n                while (radix_position++ < 0) {\n                    string.push('0');\n                }\n                for (let i = 0; i < significand_digits - Math.max(radix_position - 1, 0); i++) {\n                    string.push(`${significand[index++]}`);\n                }\n            }\n        }\n        return string.join('');\n    }\n    toJSON() {\n        return { $numberDecimal: this.toString() };\n    }\n    toExtendedJSON() {\n        return { $numberDecimal: this.toString() };\n    }\n    static fromExtendedJSON(doc) {\n        return Decimal128.fromString(doc.$numberDecimal);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        const d128string = inspect(this.toString(), options);\n        return `new Decimal128(${d128string})`;\n    }\n}\n\nclass Double extends BSONValue {\n    get _bsontype() {\n        return 'Double';\n    }\n    constructor(value) {\n        super();\n        if (value instanceof Number) {\n            value = value.valueOf();\n        }\n        this.value = +value;\n    }\n    static fromString(value) {\n        const coercedValue = Number(value);\n        if (value === 'NaN')\n            return new Double(NaN);\n        if (value === 'Infinity')\n            return new Double(Infinity);\n        if (value === '-Infinity')\n            return new Double(-Infinity);\n        if (!Number.isFinite(coercedValue)) {\n            throw new BSONError(`Input: ${value} is not representable as a Double`);\n        }\n        if (value.trim() !== value) {\n            throw new BSONError(`Input: '${value}' contains whitespace`);\n        }\n        if (value === '') {\n            throw new BSONError(`Input is an empty string`);\n        }\n        if (/[^-0-9.+eE]/.test(value)) {\n            throw new BSONError(`Input: '${value}' is not in decimal or exponential notation`);\n        }\n        return new Double(coercedValue);\n    }\n    valueOf() {\n        return this.value;\n    }\n    toJSON() {\n        return this.value;\n    }\n    toString(radix) {\n        return this.value.toString(radix);\n    }\n    toExtendedJSON(options) {\n        if (options && (options.legacy || (options.relaxed && isFinite(this.value)))) {\n            return this.value;\n        }\n        if (Object.is(Math.sign(this.value), -0)) {\n            return { $numberDouble: '-0.0' };\n        }\n        return {\n            $numberDouble: Number.isInteger(this.value) ? this.value.toFixed(1) : this.value.toString()\n        };\n    }\n    static fromExtendedJSON(doc, options) {\n        const doubleValue = parseFloat(doc.$numberDouble);\n        return options && options.relaxed ? doubleValue : new Double(doubleValue);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        return `new Double(${inspect(this.value, options)})`;\n    }\n}\n\nclass Int32 extends BSONValue {\n    get _bsontype() {\n        return 'Int32';\n    }\n    constructor(value) {\n        super();\n        if (value instanceof Number) {\n            value = value.valueOf();\n        }\n        this.value = +value | 0;\n    }\n    static fromString(value) {\n        const cleanedValue = removeLeadingZerosAndExplicitPlus(value);\n        const coercedValue = Number(value);\n        if (BSON_INT32_MAX < coercedValue) {\n            throw new BSONError(`Input: '${value}' is larger than the maximum value for Int32`);\n        }\n        else if (BSON_INT32_MIN > coercedValue) {\n            throw new BSONError(`Input: '${value}' is smaller than the minimum value for Int32`);\n        }\n        else if (!Number.isSafeInteger(coercedValue)) {\n            throw new BSONError(`Input: '${value}' is not a safe integer`);\n        }\n        else if (coercedValue.toString() !== cleanedValue) {\n            throw new BSONError(`Input: '${value}' is not a valid Int32 string`);\n        }\n        return new Int32(coercedValue);\n    }\n    valueOf() {\n        return this.value;\n    }\n    toString(radix) {\n        return this.value.toString(radix);\n    }\n    toJSON() {\n        return this.value;\n    }\n    toExtendedJSON(options) {\n        if (options && (options.relaxed || options.legacy))\n            return this.value;\n        return { $numberInt: this.value.toString() };\n    }\n    static fromExtendedJSON(doc, options) {\n        return options && options.relaxed ? parseInt(doc.$numberInt, 10) : new Int32(doc.$numberInt);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        return `new Int32(${inspect(this.value, options)})`;\n    }\n}\n\nclass MaxKey extends BSONValue {\n    get _bsontype() {\n        return 'MaxKey';\n    }\n    toExtendedJSON() {\n        return { $maxKey: 1 };\n    }\n    static fromExtendedJSON() {\n        return new MaxKey();\n    }\n    inspect() {\n        return 'new MaxKey()';\n    }\n}\n\nclass MinKey extends BSONValue {\n    get _bsontype() {\n        return 'MinKey';\n    }\n    toExtendedJSON() {\n        return { $minKey: 1 };\n    }\n    static fromExtendedJSON() {\n        return new MinKey();\n    }\n    inspect() {\n        return 'new MinKey()';\n    }\n}\n\nconst FLOAT = new Float64Array(1);\nconst FLOAT_BYTES = new Uint8Array(FLOAT.buffer, 0, 8);\nFLOAT[0] = -1;\nconst isBigEndian = FLOAT_BYTES[7] === 0;\nconst NumberUtils = {\n    getNonnegativeInt32LE(source, offset) {\n        if (source[offset + 3] > 127) {\n            throw new RangeError(`Size cannot be negative at offset: ${offset}`);\n        }\n        return (source[offset] |\n            (source[offset + 1] << 8) |\n            (source[offset + 2] << 16) |\n            (source[offset + 3] << 24));\n    },\n    getInt32LE(source, offset) {\n        return (source[offset] |\n            (source[offset + 1] << 8) |\n            (source[offset + 2] << 16) |\n            (source[offset + 3] << 24));\n    },\n    getUint32LE(source, offset) {\n        return (source[offset] +\n            source[offset + 1] * 256 +\n            source[offset + 2] * 65536 +\n            source[offset + 3] * 16777216);\n    },\n    getUint32BE(source, offset) {\n        return (source[offset + 3] +\n            source[offset + 2] * 256 +\n            source[offset + 1] * 65536 +\n            source[offset] * 16777216);\n    },\n    getBigInt64LE(source, offset) {\n        const lo = NumberUtils.getUint32LE(source, offset);\n        const hi = NumberUtils.getUint32LE(source, offset + 4);\n        return (BigInt(hi) << BigInt(32)) + BigInt(lo);\n    },\n    getFloat64LE: isBigEndian\n        ? (source, offset) => {\n            FLOAT_BYTES[7] = source[offset];\n            FLOAT_BYTES[6] = source[offset + 1];\n            FLOAT_BYTES[5] = source[offset + 2];\n            FLOAT_BYTES[4] = source[offset + 3];\n            FLOAT_BYTES[3] = source[offset + 4];\n            FLOAT_BYTES[2] = source[offset + 5];\n            FLOAT_BYTES[1] = source[offset + 6];\n            FLOAT_BYTES[0] = source[offset + 7];\n            return FLOAT[0];\n        }\n        : (source, offset) => {\n            FLOAT_BYTES[0] = source[offset];\n            FLOAT_BYTES[1] = source[offset + 1];\n            FLOAT_BYTES[2] = source[offset + 2];\n            FLOAT_BYTES[3] = source[offset + 3];\n            FLOAT_BYTES[4] = source[offset + 4];\n            FLOAT_BYTES[5] = source[offset + 5];\n            FLOAT_BYTES[6] = source[offset + 6];\n            FLOAT_BYTES[7] = source[offset + 7];\n            return FLOAT[0];\n        },\n    setInt32BE(destination, offset, value) {\n        destination[offset + 3] = value;\n        value >>>= 8;\n        destination[offset + 2] = value;\n        value >>>= 8;\n        destination[offset + 1] = value;\n        value >>>= 8;\n        destination[offset] = value;\n        return 4;\n    },\n    setInt32LE(destination, offset, value) {\n        destination[offset] = value;\n        value >>>= 8;\n        destination[offset + 1] = value;\n        value >>>= 8;\n        destination[offset + 2] = value;\n        value >>>= 8;\n        destination[offset + 3] = value;\n        return 4;\n    },\n    setBigInt64LE(destination, offset, value) {\n        const mask32bits = BigInt(4294967295);\n        let lo = Number(value & mask32bits);\n        destination[offset] = lo;\n        lo >>= 8;\n        destination[offset + 1] = lo;\n        lo >>= 8;\n        destination[offset + 2] = lo;\n        lo >>= 8;\n        destination[offset + 3] = lo;\n        let hi = Number((value >> BigInt(32)) & mask32bits);\n        destination[offset + 4] = hi;\n        hi >>= 8;\n        destination[offset + 5] = hi;\n        hi >>= 8;\n        destination[offset + 6] = hi;\n        hi >>= 8;\n        destination[offset + 7] = hi;\n        return 8;\n    },\n    setFloat64LE: isBigEndian\n        ? (destination, offset, value) => {\n            FLOAT[0] = value;\n            destination[offset] = FLOAT_BYTES[7];\n            destination[offset + 1] = FLOAT_BYTES[6];\n            destination[offset + 2] = FLOAT_BYTES[5];\n            destination[offset + 3] = FLOAT_BYTES[4];\n            destination[offset + 4] = FLOAT_BYTES[3];\n            destination[offset + 5] = FLOAT_BYTES[2];\n            destination[offset + 6] = FLOAT_BYTES[1];\n            destination[offset + 7] = FLOAT_BYTES[0];\n            return 8;\n        }\n        : (destination, offset, value) => {\n            FLOAT[0] = value;\n            destination[offset] = FLOAT_BYTES[0];\n            destination[offset + 1] = FLOAT_BYTES[1];\n            destination[offset + 2] = FLOAT_BYTES[2];\n            destination[offset + 3] = FLOAT_BYTES[3];\n            destination[offset + 4] = FLOAT_BYTES[4];\n            destination[offset + 5] = FLOAT_BYTES[5];\n            destination[offset + 6] = FLOAT_BYTES[6];\n            destination[offset + 7] = FLOAT_BYTES[7];\n            return 8;\n        }\n};\n\nconst checkForHexRegExp = new RegExp('^[0-9a-fA-F]{24}$');\nlet PROCESS_UNIQUE = null;\nclass ObjectId extends BSONValue {\n    get _bsontype() {\n        return 'ObjectId';\n    }\n    constructor(inputId) {\n        super();\n        let workingId;\n        if (typeof inputId === 'object' && inputId && 'id' in inputId) {\n            if (typeof inputId.id !== 'string' && !ArrayBuffer.isView(inputId.id)) {\n                throw new BSONError('Argument passed in must have an id that is of type string or Buffer');\n            }\n            if ('toHexString' in inputId && typeof inputId.toHexString === 'function') {\n                workingId = ByteUtils.fromHex(inputId.toHexString());\n            }\n            else {\n                workingId = inputId.id;\n            }\n        }\n        else {\n            workingId = inputId;\n        }\n        if (workingId == null || typeof workingId === 'number') {\n            this.buffer = ObjectId.generate(typeof workingId === 'number' ? workingId : undefined);\n        }\n        else if (ArrayBuffer.isView(workingId) && workingId.byteLength === 12) {\n            this.buffer = ByteUtils.toLocalBufferType(workingId);\n        }\n        else if (typeof workingId === 'string') {\n            if (workingId.length === 24 && checkForHexRegExp.test(workingId)) {\n                this.buffer = ByteUtils.fromHex(workingId);\n            }\n            else {\n                throw new BSONError('input must be a 24 character hex string, 12 byte Uint8Array, or an integer');\n            }\n        }\n        else {\n            throw new BSONError('Argument passed in does not match the accepted types');\n        }\n        if (ObjectId.cacheHexString) {\n            this.__id = ByteUtils.toHex(this.id);\n        }\n    }\n    get id() {\n        return this.buffer;\n    }\n    set id(value) {\n        this.buffer = value;\n        if (ObjectId.cacheHexString) {\n            this.__id = ByteUtils.toHex(value);\n        }\n    }\n    toHexString() {\n        if (ObjectId.cacheHexString && this.__id) {\n            return this.__id;\n        }\n        const hexString = ByteUtils.toHex(this.id);\n        if (ObjectId.cacheHexString && !this.__id) {\n            this.__id = hexString;\n        }\n        return hexString;\n    }\n    static getInc() {\n        return (ObjectId.index = (ObjectId.index + 1) % 0xffffff);\n    }\n    static generate(time) {\n        if ('number' !== typeof time) {\n            time = Math.floor(Date.now() / 1000);\n        }\n        const inc = ObjectId.getInc();\n        const buffer = ByteUtils.allocateUnsafe(12);\n        NumberUtils.setInt32BE(buffer, 0, time);\n        if (PROCESS_UNIQUE === null) {\n            PROCESS_UNIQUE = ByteUtils.randomBytes(5);\n        }\n        buffer[4] = PROCESS_UNIQUE[0];\n        buffer[5] = PROCESS_UNIQUE[1];\n        buffer[6] = PROCESS_UNIQUE[2];\n        buffer[7] = PROCESS_UNIQUE[3];\n        buffer[8] = PROCESS_UNIQUE[4];\n        buffer[11] = inc & 0xff;\n        buffer[10] = (inc >> 8) & 0xff;\n        buffer[9] = (inc >> 16) & 0xff;\n        return buffer;\n    }\n    toString(encoding) {\n        if (encoding === 'base64')\n            return ByteUtils.toBase64(this.id);\n        if (encoding === 'hex')\n            return this.toHexString();\n        return this.toHexString();\n    }\n    toJSON() {\n        return this.toHexString();\n    }\n    static is(variable) {\n        return (variable != null &&\n            typeof variable === 'object' &&\n            '_bsontype' in variable &&\n            variable._bsontype === 'ObjectId');\n    }\n    equals(otherId) {\n        if (otherId === undefined || otherId === null) {\n            return false;\n        }\n        if (ObjectId.is(otherId)) {\n            return (this.buffer[11] === otherId.buffer[11] && ByteUtils.equals(this.buffer, otherId.buffer));\n        }\n        if (typeof otherId === 'string') {\n            return otherId.toLowerCase() === this.toHexString();\n        }\n        if (typeof otherId === 'object' && typeof otherId.toHexString === 'function') {\n            const otherIdString = otherId.toHexString();\n            const thisIdString = this.toHexString();\n            return typeof otherIdString === 'string' && otherIdString.toLowerCase() === thisIdString;\n        }\n        return false;\n    }\n    getTimestamp() {\n        const timestamp = new Date();\n        const time = NumberUtils.getUint32BE(this.buffer, 0);\n        timestamp.setTime(Math.floor(time) * 1000);\n        return timestamp;\n    }\n    static createPk() {\n        return new ObjectId();\n    }\n    serializeInto(uint8array, index) {\n        uint8array[index] = this.buffer[0];\n        uint8array[index + 1] = this.buffer[1];\n        uint8array[index + 2] = this.buffer[2];\n        uint8array[index + 3] = this.buffer[3];\n        uint8array[index + 4] = this.buffer[4];\n        uint8array[index + 5] = this.buffer[5];\n        uint8array[index + 6] = this.buffer[6];\n        uint8array[index + 7] = this.buffer[7];\n        uint8array[index + 8] = this.buffer[8];\n        uint8array[index + 9] = this.buffer[9];\n        uint8array[index + 10] = this.buffer[10];\n        uint8array[index + 11] = this.buffer[11];\n        return 12;\n    }\n    static createFromTime(time) {\n        const buffer = ByteUtils.allocate(12);\n        for (let i = 11; i >= 4; i--)\n            buffer[i] = 0;\n        NumberUtils.setInt32BE(buffer, 0, time);\n        return new ObjectId(buffer);\n    }\n    static createFromHexString(hexString) {\n        if (hexString?.length !== 24) {\n            throw new BSONError('hex string must be 24 characters');\n        }\n        return new ObjectId(ByteUtils.fromHex(hexString));\n    }\n    static createFromBase64(base64) {\n        if (base64?.length !== 16) {\n            throw new BSONError('base64 string must be 16 characters');\n        }\n        return new ObjectId(ByteUtils.fromBase64(base64));\n    }\n    static isValid(id) {\n        if (id == null)\n            return false;\n        try {\n            new ObjectId(id);\n            return true;\n        }\n        catch {\n            return false;\n        }\n    }\n    toExtendedJSON() {\n        if (this.toHexString)\n            return { $oid: this.toHexString() };\n        return { $oid: this.toString('hex') };\n    }\n    static fromExtendedJSON(doc) {\n        return new ObjectId(doc.$oid);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        return `new ObjectId(${inspect(this.toHexString(), options)})`;\n    }\n}\nObjectId.index = Math.floor(Math.random() * 0xffffff);\n\nfunction internalCalculateObjectSize(object, serializeFunctions, ignoreUndefined) {\n    let totalLength = 4 + 1;\n    if (Array.isArray(object)) {\n        for (let i = 0; i < object.length; i++) {\n            totalLength += calculateElement(i.toString(), object[i], serializeFunctions, true, ignoreUndefined);\n        }\n    }\n    else {\n        if (typeof object?.toBSON === 'function') {\n            object = object.toBSON();\n        }\n        for (const key of Object.keys(object)) {\n            totalLength += calculateElement(key, object[key], serializeFunctions, false, ignoreUndefined);\n        }\n    }\n    return totalLength;\n}\nfunction calculateElement(name, value, serializeFunctions = false, isArray = false, ignoreUndefined = false) {\n    if (typeof value?.toBSON === 'function') {\n        value = value.toBSON();\n    }\n    switch (typeof value) {\n        case 'string':\n            return 1 + ByteUtils.utf8ByteLength(name) + 1 + 4 + ByteUtils.utf8ByteLength(value) + 1;\n        case 'number':\n            if (Math.floor(value) === value &&\n                value >= JS_INT_MIN &&\n                value <= JS_INT_MAX) {\n                if (value >= BSON_INT32_MIN && value <= BSON_INT32_MAX) {\n                    return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (4 + 1);\n                }\n                else {\n                    return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (8 + 1);\n                }\n            }\n            else {\n                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (8 + 1);\n            }\n        case 'undefined':\n            if (isArray || !ignoreUndefined)\n                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + 1;\n            return 0;\n        case 'boolean':\n            return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (1 + 1);\n        case 'object':\n            if (value != null &&\n                typeof value._bsontype === 'string' &&\n                value[Symbol.for('@@mdb.bson.version')] !== BSON_MAJOR_VERSION) {\n                throw new BSONVersionError();\n            }\n            else if (value == null || value._bsontype === 'MinKey' || value._bsontype === 'MaxKey') {\n                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + 1;\n            }\n            else if (value._bsontype === 'ObjectId') {\n                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (12 + 1);\n            }\n            else if (value instanceof Date || isDate(value)) {\n                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (8 + 1);\n            }\n            else if (ArrayBuffer.isView(value) ||\n                value instanceof ArrayBuffer ||\n                isAnyArrayBuffer(value)) {\n                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (1 + 4 + 1) + value.byteLength);\n            }\n            else if (value._bsontype === 'Long' ||\n                value._bsontype === 'Double' ||\n                value._bsontype === 'Timestamp') {\n                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (8 + 1);\n            }\n            else if (value._bsontype === 'Decimal128') {\n                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (16 + 1);\n            }\n            else if (value._bsontype === 'Code') {\n                if (value.scope != null && Object.keys(value.scope).length > 0) {\n                    return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                        1 +\n                        4 +\n                        4 +\n                        ByteUtils.utf8ByteLength(value.code.toString()) +\n                        1 +\n                        internalCalculateObjectSize(value.scope, serializeFunctions, ignoreUndefined));\n                }\n                else {\n                    return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                        1 +\n                        4 +\n                        ByteUtils.utf8ByteLength(value.code.toString()) +\n                        1);\n                }\n            }\n            else if (value._bsontype === 'Binary') {\n                const binary = value;\n                if (binary.sub_type === Binary.SUBTYPE_BYTE_ARRAY) {\n                    return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                        (binary.position + 1 + 4 + 1 + 4));\n                }\n                else {\n                    return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (binary.position + 1 + 4 + 1));\n                }\n            }\n            else if (value._bsontype === 'Symbol') {\n                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                    ByteUtils.utf8ByteLength(value.value) +\n                    4 +\n                    1 +\n                    1);\n            }\n            else if (value._bsontype === 'DBRef') {\n                const ordered_values = Object.assign({\n                    $ref: value.collection,\n                    $id: value.oid\n                }, value.fields);\n                if (value.db != null) {\n                    ordered_values['$db'] = value.db;\n                }\n                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                    1 +\n                    internalCalculateObjectSize(ordered_values, serializeFunctions, ignoreUndefined));\n            }\n            else if (value instanceof RegExp || isRegExp(value)) {\n                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                    1 +\n                    ByteUtils.utf8ByteLength(value.source) +\n                    1 +\n                    (value.global ? 1 : 0) +\n                    (value.ignoreCase ? 1 : 0) +\n                    (value.multiline ? 1 : 0) +\n                    1);\n            }\n            else if (value._bsontype === 'BSONRegExp') {\n                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                    1 +\n                    ByteUtils.utf8ByteLength(value.pattern) +\n                    1 +\n                    ByteUtils.utf8ByteLength(value.options) +\n                    1);\n            }\n            else {\n                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                    internalCalculateObjectSize(value, serializeFunctions, ignoreUndefined) +\n                    1);\n            }\n        case 'function':\n            if (serializeFunctions) {\n                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                    1 +\n                    4 +\n                    ByteUtils.utf8ByteLength(value.toString()) +\n                    1);\n            }\n    }\n    return 0;\n}\n\nfunction alphabetize(str) {\n    return str.split('').sort().join('');\n}\nclass BSONRegExp extends BSONValue {\n    get _bsontype() {\n        return 'BSONRegExp';\n    }\n    constructor(pattern, options) {\n        super();\n        this.pattern = pattern;\n        this.options = alphabetize(options ?? '');\n        if (this.pattern.indexOf('\\x00') !== -1) {\n            throw new BSONError(`BSON Regex patterns cannot contain null bytes, found: ${JSON.stringify(this.pattern)}`);\n        }\n        if (this.options.indexOf('\\x00') !== -1) {\n            throw new BSONError(`BSON Regex options cannot contain null bytes, found: ${JSON.stringify(this.options)}`);\n        }\n        for (let i = 0; i < this.options.length; i++) {\n            if (!(this.options[i] === 'i' ||\n                this.options[i] === 'm' ||\n                this.options[i] === 'x' ||\n                this.options[i] === 'l' ||\n                this.options[i] === 's' ||\n                this.options[i] === 'u')) {\n                throw new BSONError(`The regular expression option [${this.options[i]}] is not supported`);\n            }\n        }\n    }\n    static parseOptions(options) {\n        return options ? options.split('').sort().join('') : '';\n    }\n    toExtendedJSON(options) {\n        options = options || {};\n        if (options.legacy) {\n            return { $regex: this.pattern, $options: this.options };\n        }\n        return { $regularExpression: { pattern: this.pattern, options: this.options } };\n    }\n    static fromExtendedJSON(doc) {\n        if ('$regex' in doc) {\n            if (typeof doc.$regex !== 'string') {\n                if (doc.$regex._bsontype === 'BSONRegExp') {\n                    return doc;\n                }\n            }\n            else {\n                return new BSONRegExp(doc.$regex, BSONRegExp.parseOptions(doc.$options));\n            }\n        }\n        if ('$regularExpression' in doc) {\n            return new BSONRegExp(doc.$regularExpression.pattern, BSONRegExp.parseOptions(doc.$regularExpression.options));\n        }\n        throw new BSONError(`Unexpected BSONRegExp EJSON object form: ${JSON.stringify(doc)}`);\n    }\n    inspect(depth, options, inspect) {\n        const stylize = getStylizeFunction(options) ?? (v => v);\n        inspect ??= defaultInspect;\n        const pattern = stylize(inspect(this.pattern), 'regexp');\n        const flags = stylize(inspect(this.options), 'regexp');\n        return `new BSONRegExp(${pattern}, ${flags})`;\n    }\n}\n\nclass BSONSymbol extends BSONValue {\n    get _bsontype() {\n        return 'BSONSymbol';\n    }\n    constructor(value) {\n        super();\n        this.value = value;\n    }\n    valueOf() {\n        return this.value;\n    }\n    toString() {\n        return this.value;\n    }\n    toJSON() {\n        return this.value;\n    }\n    toExtendedJSON() {\n        return { $symbol: this.value };\n    }\n    static fromExtendedJSON(doc) {\n        return new BSONSymbol(doc.$symbol);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        return `new BSONSymbol(${inspect(this.value, options)})`;\n    }\n}\n\nconst LongWithoutOverridesClass = Long;\nclass Timestamp extends LongWithoutOverridesClass {\n    get _bsontype() {\n        return 'Timestamp';\n    }\n    constructor(low) {\n        if (low == null) {\n            super(0, 0, true);\n        }\n        else if (typeof low === 'bigint') {\n            super(low, true);\n        }\n        else if (Long.isLong(low)) {\n            super(low.low, low.high, true);\n        }\n        else if (typeof low === 'object' && 't' in low && 'i' in low) {\n            if (typeof low.t !== 'number' && (typeof low.t !== 'object' || low.t._bsontype !== 'Int32')) {\n                throw new BSONError('Timestamp constructed from { t, i } must provide t as a number');\n            }\n            if (typeof low.i !== 'number' && (typeof low.i !== 'object' || low.i._bsontype !== 'Int32')) {\n                throw new BSONError('Timestamp constructed from { t, i } must provide i as a number');\n            }\n            const t = Number(low.t);\n            const i = Number(low.i);\n            if (t < 0 || Number.isNaN(t)) {\n                throw new BSONError('Timestamp constructed from { t, i } must provide a positive t');\n            }\n            if (i < 0 || Number.isNaN(i)) {\n                throw new BSONError('Timestamp constructed from { t, i } must provide a positive i');\n            }\n            if (t > 4294967295) {\n                throw new BSONError('Timestamp constructed from { t, i } must provide t equal or less than uint32 max');\n            }\n            if (i > 4294967295) {\n                throw new BSONError('Timestamp constructed from { t, i } must provide i equal or less than uint32 max');\n            }\n            super(i, t, true);\n        }\n        else {\n            throw new BSONError('A Timestamp can only be constructed with: bigint, Long, or { t: number; i: number }');\n        }\n    }\n    toJSON() {\n        return {\n            $timestamp: this.toString()\n        };\n    }\n    static fromInt(value) {\n        return new Timestamp(Long.fromInt(value, true));\n    }\n    static fromNumber(value) {\n        return new Timestamp(Long.fromNumber(value, true));\n    }\n    static fromBits(lowBits, highBits) {\n        return new Timestamp({ i: lowBits, t: highBits });\n    }\n    static fromString(str, optRadix) {\n        return new Timestamp(Long.fromString(str, true, optRadix));\n    }\n    toExtendedJSON() {\n        return { $timestamp: { t: this.high >>> 0, i: this.low >>> 0 } };\n    }\n    static fromExtendedJSON(doc) {\n        const i = Long.isLong(doc.$timestamp.i)\n            ? doc.$timestamp.i.getLowBitsUnsigned()\n            : doc.$timestamp.i;\n        const t = Long.isLong(doc.$timestamp.t)\n            ? doc.$timestamp.t.getLowBitsUnsigned()\n            : doc.$timestamp.t;\n        return new Timestamp({ t, i });\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        const t = inspect(this.high >>> 0, options);\n        const i = inspect(this.low >>> 0, options);\n        return `new Timestamp({ t: ${t}, i: ${i} })`;\n    }\n}\nTimestamp.MAX_VALUE = Long.MAX_UNSIGNED_VALUE;\n\nconst JS_INT_MAX_LONG = Long.fromNumber(JS_INT_MAX);\nconst JS_INT_MIN_LONG = Long.fromNumber(JS_INT_MIN);\nfunction internalDeserialize(buffer, options, isArray) {\n    options = options == null ? {} : options;\n    const index = options && options.index ? options.index : 0;\n    const size = NumberUtils.getInt32LE(buffer, index);\n    if (size < 5) {\n        throw new BSONError(`bson size must be >= 5, is ${size}`);\n    }\n    if (options.allowObjectSmallerThanBufferSize && buffer.length < size) {\n        throw new BSONError(`buffer length ${buffer.length} must be >= bson size ${size}`);\n    }\n    if (!options.allowObjectSmallerThanBufferSize && buffer.length !== size) {\n        throw new BSONError(`buffer length ${buffer.length} must === bson size ${size}`);\n    }\n    if (size + index > buffer.byteLength) {\n        throw new BSONError(`(bson size ${size} + options.index ${index} must be <= buffer length ${buffer.byteLength})`);\n    }\n    if (buffer[index + size - 1] !== 0) {\n        throw new BSONError(\"One object, sized correctly, with a spot for an EOO, but the EOO isn't 0x00\");\n    }\n    return deserializeObject(buffer, index, options, isArray);\n}\nconst allowedDBRefKeys = /^\\$ref$|^\\$id$|^\\$db$/;\nfunction deserializeObject(buffer, index, options, isArray = false) {\n    const fieldsAsRaw = options['fieldsAsRaw'] == null ? null : options['fieldsAsRaw'];\n    const raw = options['raw'] == null ? false : options['raw'];\n    const bsonRegExp = typeof options['bsonRegExp'] === 'boolean' ? options['bsonRegExp'] : false;\n    const promoteBuffers = options.promoteBuffers ?? false;\n    const promoteLongs = options.promoteLongs ?? true;\n    const promoteValues = options.promoteValues ?? true;\n    const useBigInt64 = options.useBigInt64 ?? false;\n    if (useBigInt64 && !promoteValues) {\n        throw new BSONError('Must either request bigint or Long for int64 deserialization');\n    }\n    if (useBigInt64 && !promoteLongs) {\n        throw new BSONError('Must either request bigint or Long for int64 deserialization');\n    }\n    const validation = options.validation == null ? { utf8: true } : options.validation;\n    let globalUTFValidation = true;\n    let validationSetting;\n    let utf8KeysSet;\n    const utf8ValidatedKeys = validation.utf8;\n    if (typeof utf8ValidatedKeys === 'boolean') {\n        validationSetting = utf8ValidatedKeys;\n    }\n    else {\n        globalUTFValidation = false;\n        const utf8ValidationValues = Object.keys(utf8ValidatedKeys).map(function (key) {\n            return utf8ValidatedKeys[key];\n        });\n        if (utf8ValidationValues.length === 0) {\n            throw new BSONError('UTF-8 validation setting cannot be empty');\n        }\n        if (typeof utf8ValidationValues[0] !== 'boolean') {\n            throw new BSONError('Invalid UTF-8 validation option, must specify boolean values');\n        }\n        validationSetting = utf8ValidationValues[0];\n        if (!utf8ValidationValues.every(item => item === validationSetting)) {\n            throw new BSONError('Invalid UTF-8 validation option - keys must be all true or all false');\n        }\n    }\n    if (!globalUTFValidation) {\n        utf8KeysSet = new Set();\n        for (const key of Object.keys(utf8ValidatedKeys)) {\n            utf8KeysSet.add(key);\n        }\n    }\n    const startIndex = index;\n    if (buffer.length < 5)\n        throw new BSONError('corrupt bson message < 5 bytes long');\n    const size = NumberUtils.getInt32LE(buffer, index);\n    index += 4;\n    if (size < 5 || size > buffer.length)\n        throw new BSONError('corrupt bson message');\n    const object = isArray ? [] : {};\n    let arrayIndex = 0;\n    const done = false;\n    let isPossibleDBRef = isArray ? false : null;\n    while (!done) {\n        const elementType = buffer[index++];\n        if (elementType === 0)\n            break;\n        let i = index;\n        while (buffer[i] !== 0x00 && i < buffer.length) {\n            i++;\n        }\n        if (i >= buffer.byteLength)\n            throw new BSONError('Bad BSON Document: illegal CString');\n        const name = isArray ? arrayIndex++ : ByteUtils.toUTF8(buffer, index, i, false);\n        let shouldValidateKey = true;\n        if (globalUTFValidation || utf8KeysSet?.has(name)) {\n            shouldValidateKey = validationSetting;\n        }\n        else {\n            shouldValidateKey = !validationSetting;\n        }\n        if (isPossibleDBRef !== false && name[0] === '$') {\n            isPossibleDBRef = allowedDBRefKeys.test(name);\n        }\n        let value;\n        index = i + 1;\n        if (elementType === BSON_DATA_STRING) {\n            const stringSize = NumberUtils.getInt32LE(buffer, index);\n            index += 4;\n            if (stringSize <= 0 ||\n                stringSize > buffer.length - index ||\n                buffer[index + stringSize - 1] !== 0) {\n                throw new BSONError('bad string length in bson');\n            }\n            value = ByteUtils.toUTF8(buffer, index, index + stringSize - 1, shouldValidateKey);\n            index = index + stringSize;\n        }\n        else if (elementType === BSON_DATA_OID) {\n            const oid = ByteUtils.allocateUnsafe(12);\n            for (let i = 0; i < 12; i++)\n                oid[i] = buffer[index + i];\n            value = new ObjectId(oid);\n            index = index + 12;\n        }\n        else if (elementType === BSON_DATA_INT && promoteValues === false) {\n            value = new Int32(NumberUtils.getInt32LE(buffer, index));\n            index += 4;\n        }\n        else if (elementType === BSON_DATA_INT) {\n            value = NumberUtils.getInt32LE(buffer, index);\n            index += 4;\n        }\n        else if (elementType === BSON_DATA_NUMBER) {\n            value = NumberUtils.getFloat64LE(buffer, index);\n            index += 8;\n            if (promoteValues === false)\n                value = new Double(value);\n        }\n        else if (elementType === BSON_DATA_DATE) {\n            const lowBits = NumberUtils.getInt32LE(buffer, index);\n            const highBits = NumberUtils.getInt32LE(buffer, index + 4);\n            index += 8;\n            value = new Date(new Long(lowBits, highBits).toNumber());\n        }\n        else if (elementType === BSON_DATA_BOOLEAN) {\n            if (buffer[index] !== 0 && buffer[index] !== 1)\n                throw new BSONError('illegal boolean type value');\n            value = buffer[index++] === 1;\n        }\n        else if (elementType === BSON_DATA_OBJECT) {\n            const _index = index;\n            const objectSize = NumberUtils.getInt32LE(buffer, index);\n            if (objectSize <= 0 || objectSize > buffer.length - index)\n                throw new BSONError('bad embedded document length in bson');\n            if (raw) {\n                value = buffer.slice(index, index + objectSize);\n            }\n            else {\n                let objectOptions = options;\n                if (!globalUTFValidation) {\n                    objectOptions = { ...options, validation: { utf8: shouldValidateKey } };\n                }\n                value = deserializeObject(buffer, _index, objectOptions, false);\n            }\n            index = index + objectSize;\n        }\n        else if (elementType === BSON_DATA_ARRAY) {\n            const _index = index;\n            const objectSize = NumberUtils.getInt32LE(buffer, index);\n            let arrayOptions = options;\n            const stopIndex = index + objectSize;\n            if (fieldsAsRaw && fieldsAsRaw[name]) {\n                arrayOptions = { ...options, raw: true };\n            }\n            if (!globalUTFValidation) {\n                arrayOptions = { ...arrayOptions, validation: { utf8: shouldValidateKey } };\n            }\n            value = deserializeObject(buffer, _index, arrayOptions, true);\n            index = index + objectSize;\n            if (buffer[index - 1] !== 0)\n                throw new BSONError('invalid array terminator byte');\n            if (index !== stopIndex)\n                throw new BSONError('corrupted array bson');\n        }\n        else if (elementType === BSON_DATA_UNDEFINED) {\n            value = undefined;\n        }\n        else if (elementType === BSON_DATA_NULL) {\n            value = null;\n        }\n        else if (elementType === BSON_DATA_LONG) {\n            if (useBigInt64) {\n                value = NumberUtils.getBigInt64LE(buffer, index);\n                index += 8;\n            }\n            else {\n                const lowBits = NumberUtils.getInt32LE(buffer, index);\n                const highBits = NumberUtils.getInt32LE(buffer, index + 4);\n                index += 8;\n                const long = new Long(lowBits, highBits);\n                if (promoteLongs && promoteValues === true) {\n                    value =\n                        long.lessThanOrEqual(JS_INT_MAX_LONG) && long.greaterThanOrEqual(JS_INT_MIN_LONG)\n                            ? long.toNumber()\n                            : long;\n                }\n                else {\n                    value = long;\n                }\n            }\n        }\n        else if (elementType === BSON_DATA_DECIMAL128) {\n            const bytes = ByteUtils.allocateUnsafe(16);\n            for (let i = 0; i < 16; i++)\n                bytes[i] = buffer[index + i];\n            index = index + 16;\n            value = new Decimal128(bytes);\n        }\n        else if (elementType === BSON_DATA_BINARY) {\n            let binarySize = NumberUtils.getInt32LE(buffer, index);\n            index += 4;\n            const totalBinarySize = binarySize;\n            const subType = buffer[index++];\n            if (binarySize < 0)\n                throw new BSONError('Negative binary type element size found');\n            if (binarySize > buffer.byteLength)\n                throw new BSONError('Binary type size larger than document size');\n            if (buffer['slice'] != null) {\n                if (subType === Binary.SUBTYPE_BYTE_ARRAY) {\n                    binarySize = NumberUtils.getInt32LE(buffer, index);\n                    index += 4;\n                    if (binarySize < 0)\n                        throw new BSONError('Negative binary type element size found for subtype 0x02');\n                    if (binarySize > totalBinarySize - 4)\n                        throw new BSONError('Binary type with subtype 0x02 contains too long binary size');\n                    if (binarySize < totalBinarySize - 4)\n                        throw new BSONError('Binary type with subtype 0x02 contains too short binary size');\n                }\n                if (promoteBuffers && promoteValues) {\n                    value = ByteUtils.toLocalBufferType(buffer.slice(index, index + binarySize));\n                }\n                else {\n                    value = new Binary(buffer.slice(index, index + binarySize), subType);\n                    if (subType === BSON_BINARY_SUBTYPE_UUID_NEW && UUID.isValid(value)) {\n                        value = value.toUUID();\n                    }\n                }\n            }\n            else {\n                if (subType === Binary.SUBTYPE_BYTE_ARRAY) {\n                    binarySize = NumberUtils.getInt32LE(buffer, index);\n                    index += 4;\n                    if (binarySize < 0)\n                        throw new BSONError('Negative binary type element size found for subtype 0x02');\n                    if (binarySize > totalBinarySize - 4)\n                        throw new BSONError('Binary type with subtype 0x02 contains too long binary size');\n                    if (binarySize < totalBinarySize - 4)\n                        throw new BSONError('Binary type with subtype 0x02 contains too short binary size');\n                }\n                if (promoteBuffers && promoteValues) {\n                    value = ByteUtils.allocateUnsafe(binarySize);\n                    for (i = 0; i < binarySize; i++) {\n                        value[i] = buffer[index + i];\n                    }\n                }\n                else {\n                    value = new Binary(buffer.slice(index, index + binarySize), subType);\n                    if (subType === BSON_BINARY_SUBTYPE_UUID_NEW && UUID.isValid(value)) {\n                        value = value.toUUID();\n                    }\n                }\n            }\n            index = index + binarySize;\n        }\n        else if (elementType === BSON_DATA_REGEXP && bsonRegExp === false) {\n            i = index;\n            while (buffer[i] !== 0x00 && i < buffer.length) {\n                i++;\n            }\n            if (i >= buffer.length)\n                throw new BSONError('Bad BSON Document: illegal CString');\n            const source = ByteUtils.toUTF8(buffer, index, i, false);\n            index = i + 1;\n            i = index;\n            while (buffer[i] !== 0x00 && i < buffer.length) {\n                i++;\n            }\n            if (i >= buffer.length)\n                throw new BSONError('Bad BSON Document: illegal CString');\n            const regExpOptions = ByteUtils.toUTF8(buffer, index, i, false);\n            index = i + 1;\n            const optionsArray = new Array(regExpOptions.length);\n            for (i = 0; i < regExpOptions.length; i++) {\n                switch (regExpOptions[i]) {\n                    case 'm':\n                        optionsArray[i] = 'm';\n                        break;\n                    case 's':\n                        optionsArray[i] = 'g';\n                        break;\n                    case 'i':\n                        optionsArray[i] = 'i';\n                        break;\n                }\n            }\n            value = new RegExp(source, optionsArray.join(''));\n        }\n        else if (elementType === BSON_DATA_REGEXP && bsonRegExp === true) {\n            i = index;\n            while (buffer[i] !== 0x00 && i < buffer.length) {\n                i++;\n            }\n            if (i >= buffer.length)\n                throw new BSONError('Bad BSON Document: illegal CString');\n            const source = ByteUtils.toUTF8(buffer, index, i, false);\n            index = i + 1;\n            i = index;\n            while (buffer[i] !== 0x00 && i < buffer.length) {\n                i++;\n            }\n            if (i >= buffer.length)\n                throw new BSONError('Bad BSON Document: illegal CString');\n            const regExpOptions = ByteUtils.toUTF8(buffer, index, i, false);\n            index = i + 1;\n            value = new BSONRegExp(source, regExpOptions);\n        }\n        else if (elementType === BSON_DATA_SYMBOL) {\n            const stringSize = NumberUtils.getInt32LE(buffer, index);\n            index += 4;\n            if (stringSize <= 0 ||\n                stringSize > buffer.length - index ||\n                buffer[index + stringSize - 1] !== 0) {\n                throw new BSONError('bad string length in bson');\n            }\n            const symbol = ByteUtils.toUTF8(buffer, index, index + stringSize - 1, shouldValidateKey);\n            value = promoteValues ? symbol : new BSONSymbol(symbol);\n            index = index + stringSize;\n        }\n        else if (elementType === BSON_DATA_TIMESTAMP) {\n            value = new Timestamp({\n                i: NumberUtils.getUint32LE(buffer, index),\n                t: NumberUtils.getUint32LE(buffer, index + 4)\n            });\n            index += 8;\n        }\n        else if (elementType === BSON_DATA_MIN_KEY) {\n            value = new MinKey();\n        }\n        else if (elementType === BSON_DATA_MAX_KEY) {\n            value = new MaxKey();\n        }\n        else if (elementType === BSON_DATA_CODE) {\n            const stringSize = NumberUtils.getInt32LE(buffer, index);\n            index += 4;\n            if (stringSize <= 0 ||\n                stringSize > buffer.length - index ||\n                buffer[index + stringSize - 1] !== 0) {\n                throw new BSONError('bad string length in bson');\n            }\n            const functionString = ByteUtils.toUTF8(buffer, index, index + stringSize - 1, shouldValidateKey);\n            value = new Code(functionString);\n            index = index + stringSize;\n        }\n        else if (elementType === BSON_DATA_CODE_W_SCOPE) {\n            const totalSize = NumberUtils.getInt32LE(buffer, index);\n            index += 4;\n            if (totalSize < 4 + 4 + 4 + 1) {\n                throw new BSONError('code_w_scope total size shorter minimum expected length');\n            }\n            const stringSize = NumberUtils.getInt32LE(buffer, index);\n            index += 4;\n            if (stringSize <= 0 ||\n                stringSize > buffer.length - index ||\n                buffer[index + stringSize - 1] !== 0) {\n                throw new BSONError('bad string length in bson');\n            }\n            const functionString = ByteUtils.toUTF8(buffer, index, index + stringSize - 1, shouldValidateKey);\n            index = index + stringSize;\n            const _index = index;\n            const objectSize = NumberUtils.getInt32LE(buffer, index);\n            const scopeObject = deserializeObject(buffer, _index, options, false);\n            index = index + objectSize;\n            if (totalSize < 4 + 4 + objectSize + stringSize) {\n                throw new BSONError('code_w_scope total size is too short, truncating scope');\n            }\n            if (totalSize > 4 + 4 + objectSize + stringSize) {\n                throw new BSONError('code_w_scope total size is too long, clips outer document');\n            }\n            value = new Code(functionString, scopeObject);\n        }\n        else if (elementType === BSON_DATA_DBPOINTER) {\n            const stringSize = NumberUtils.getInt32LE(buffer, index);\n            index += 4;\n            if (stringSize <= 0 ||\n                stringSize > buffer.length - index ||\n                buffer[index + stringSize - 1] !== 0)\n                throw new BSONError('bad string length in bson');\n            const namespace = ByteUtils.toUTF8(buffer, index, index + stringSize - 1, shouldValidateKey);\n            index = index + stringSize;\n            const oidBuffer = ByteUtils.allocateUnsafe(12);\n            for (let i = 0; i < 12; i++)\n                oidBuffer[i] = buffer[index + i];\n            const oid = new ObjectId(oidBuffer);\n            index = index + 12;\n            value = new DBRef(namespace, oid);\n        }\n        else {\n            throw new BSONError(`Detected unknown BSON type ${elementType.toString(16)} for fieldname \"${name}\"`);\n        }\n        if (name === '__proto__') {\n            Object.defineProperty(object, name, {\n                value,\n                writable: true,\n                enumerable: true,\n                configurable: true\n            });\n        }\n        else {\n            object[name] = value;\n        }\n    }\n    if (size !== index - startIndex) {\n        if (isArray)\n            throw new BSONError('corrupt array bson');\n        throw new BSONError('corrupt object bson');\n    }\n    if (!isPossibleDBRef)\n        return object;\n    if (isDBRefLike(object)) {\n        const copy = Object.assign({}, object);\n        delete copy.$ref;\n        delete copy.$id;\n        delete copy.$db;\n        return new DBRef(object.$ref, object.$id, object.$db, copy);\n    }\n    return object;\n}\n\nconst regexp = /\\x00/;\nconst ignoreKeys = new Set(['$db', '$ref', '$id', '$clusterTime']);\nfunction serializeString(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_STRING;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes + 1;\n    buffer[index - 1] = 0;\n    const size = ByteUtils.encodeUTF8Into(buffer, value, index + 4);\n    NumberUtils.setInt32LE(buffer, index, size + 1);\n    index = index + 4 + size;\n    buffer[index++] = 0;\n    return index;\n}\nfunction serializeNumber(buffer, key, value, index) {\n    const isNegativeZero = Object.is(value, -0);\n    const type = !isNegativeZero &&\n        Number.isSafeInteger(value) &&\n        value <= BSON_INT32_MAX &&\n        value >= BSON_INT32_MIN\n        ? BSON_DATA_INT\n        : BSON_DATA_NUMBER;\n    buffer[index++] = type;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0x00;\n    if (type === BSON_DATA_INT) {\n        index += NumberUtils.setInt32LE(buffer, index, value);\n    }\n    else {\n        index += NumberUtils.setFloat64LE(buffer, index, value);\n    }\n    return index;\n}\nfunction serializeBigInt(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_LONG;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index += numberOfWrittenBytes;\n    buffer[index++] = 0;\n    index += NumberUtils.setBigInt64LE(buffer, index, value);\n    return index;\n}\nfunction serializeNull(buffer, key, _, index) {\n    buffer[index++] = BSON_DATA_NULL;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    return index;\n}\nfunction serializeBoolean(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_BOOLEAN;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    buffer[index++] = value ? 1 : 0;\n    return index;\n}\nfunction serializeDate(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_DATE;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    const dateInMilis = Long.fromNumber(value.getTime());\n    const lowBits = dateInMilis.getLowBits();\n    const highBits = dateInMilis.getHighBits();\n    index += NumberUtils.setInt32LE(buffer, index, lowBits);\n    index += NumberUtils.setInt32LE(buffer, index, highBits);\n    return index;\n}\nfunction serializeRegExp(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_REGEXP;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    if (value.source && value.source.match(regexp) != null) {\n        throw new BSONError('value ' + value.source + ' must not contain null bytes');\n    }\n    index = index + ByteUtils.encodeUTF8Into(buffer, value.source, index);\n    buffer[index++] = 0x00;\n    if (value.ignoreCase)\n        buffer[index++] = 0x69;\n    if (value.global)\n        buffer[index++] = 0x73;\n    if (value.multiline)\n        buffer[index++] = 0x6d;\n    buffer[index++] = 0x00;\n    return index;\n}\nfunction serializeBSONRegExp(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_REGEXP;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    if (value.pattern.match(regexp) != null) {\n        throw new BSONError('pattern ' + value.pattern + ' must not contain null bytes');\n    }\n    index = index + ByteUtils.encodeUTF8Into(buffer, value.pattern, index);\n    buffer[index++] = 0x00;\n    const sortedOptions = value.options.split('').sort().join('');\n    index = index + ByteUtils.encodeUTF8Into(buffer, sortedOptions, index);\n    buffer[index++] = 0x00;\n    return index;\n}\nfunction serializeMinMax(buffer, key, value, index) {\n    if (value === null) {\n        buffer[index++] = BSON_DATA_NULL;\n    }\n    else if (value._bsontype === 'MinKey') {\n        buffer[index++] = BSON_DATA_MIN_KEY;\n    }\n    else {\n        buffer[index++] = BSON_DATA_MAX_KEY;\n    }\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    return index;\n}\nfunction serializeObjectId(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_OID;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    index += value.serializeInto(buffer, index);\n    return index;\n}\nfunction serializeBuffer(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_BINARY;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    const size = value.length;\n    index += NumberUtils.setInt32LE(buffer, index, size);\n    buffer[index++] = BSON_BINARY_SUBTYPE_DEFAULT;\n    if (size <= 16) {\n        for (let i = 0; i < size; i++)\n            buffer[index + i] = value[i];\n    }\n    else {\n        buffer.set(value, index);\n    }\n    index = index + size;\n    return index;\n}\nfunction serializeObject(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path) {\n    if (path.has(value)) {\n        throw new BSONError('Cannot convert circular structure to BSON');\n    }\n    path.add(value);\n    buffer[index++] = Array.isArray(value) ? BSON_DATA_ARRAY : BSON_DATA_OBJECT;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    const endIndex = serializeInto(buffer, value, checkKeys, index, depth + 1, serializeFunctions, ignoreUndefined, path);\n    path.delete(value);\n    return endIndex;\n}\nfunction serializeDecimal128(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_DECIMAL128;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    for (let i = 0; i < 16; i++)\n        buffer[index + i] = value.bytes[i];\n    return index + 16;\n}\nfunction serializeLong(buffer, key, value, index) {\n    buffer[index++] =\n        value._bsontype === 'Long' ? BSON_DATA_LONG : BSON_DATA_TIMESTAMP;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    const lowBits = value.getLowBits();\n    const highBits = value.getHighBits();\n    index += NumberUtils.setInt32LE(buffer, index, lowBits);\n    index += NumberUtils.setInt32LE(buffer, index, highBits);\n    return index;\n}\nfunction serializeInt32(buffer, key, value, index) {\n    value = value.valueOf();\n    buffer[index++] = BSON_DATA_INT;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    index += NumberUtils.setInt32LE(buffer, index, value);\n    return index;\n}\nfunction serializeDouble(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_NUMBER;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    index += NumberUtils.setFloat64LE(buffer, index, value.value);\n    return index;\n}\nfunction serializeFunction(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_CODE;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    const functionString = value.toString();\n    const size = ByteUtils.encodeUTF8Into(buffer, functionString, index + 4) + 1;\n    NumberUtils.setInt32LE(buffer, index, size);\n    index = index + 4 + size - 1;\n    buffer[index++] = 0;\n    return index;\n}\nfunction serializeCode(buffer, key, value, index, checkKeys = false, depth = 0, serializeFunctions = false, ignoreUndefined = true, path) {\n    if (value.scope && typeof value.scope === 'object') {\n        buffer[index++] = BSON_DATA_CODE_W_SCOPE;\n        const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n        index = index + numberOfWrittenBytes;\n        buffer[index++] = 0;\n        let startIndex = index;\n        const functionString = value.code;\n        index = index + 4;\n        const codeSize = ByteUtils.encodeUTF8Into(buffer, functionString, index + 4) + 1;\n        NumberUtils.setInt32LE(buffer, index, codeSize);\n        buffer[index + 4 + codeSize - 1] = 0;\n        index = index + codeSize + 4;\n        const endIndex = serializeInto(buffer, value.scope, checkKeys, index, depth + 1, serializeFunctions, ignoreUndefined, path);\n        index = endIndex - 1;\n        const totalSize = endIndex - startIndex;\n        startIndex += NumberUtils.setInt32LE(buffer, startIndex, totalSize);\n        buffer[index++] = 0;\n    }\n    else {\n        buffer[index++] = BSON_DATA_CODE;\n        const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n        index = index + numberOfWrittenBytes;\n        buffer[index++] = 0;\n        const functionString = value.code.toString();\n        const size = ByteUtils.encodeUTF8Into(buffer, functionString, index + 4) + 1;\n        NumberUtils.setInt32LE(buffer, index, size);\n        index = index + 4 + size - 1;\n        buffer[index++] = 0;\n    }\n    return index;\n}\nfunction serializeBinary(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_BINARY;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    const data = value.buffer;\n    let size = value.position;\n    if (value.sub_type === Binary.SUBTYPE_BYTE_ARRAY)\n        size = size + 4;\n    index += NumberUtils.setInt32LE(buffer, index, size);\n    buffer[index++] = value.sub_type;\n    if (value.sub_type === Binary.SUBTYPE_BYTE_ARRAY) {\n        size = size - 4;\n        index += NumberUtils.setInt32LE(buffer, index, size);\n    }\n    if (size <= 16) {\n        for (let i = 0; i < size; i++)\n            buffer[index + i] = data[i];\n    }\n    else {\n        buffer.set(data, index);\n    }\n    index = index + value.position;\n    return index;\n}\nfunction serializeSymbol(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_SYMBOL;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    const size = ByteUtils.encodeUTF8Into(buffer, value.value, index + 4) + 1;\n    NumberUtils.setInt32LE(buffer, index, size);\n    index = index + 4 + size - 1;\n    buffer[index++] = 0;\n    return index;\n}\nfunction serializeDBRef(buffer, key, value, index, depth, serializeFunctions, path) {\n    buffer[index++] = BSON_DATA_OBJECT;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    let startIndex = index;\n    let output = {\n        $ref: value.collection || value.namespace,\n        $id: value.oid\n    };\n    if (value.db != null) {\n        output.$db = value.db;\n    }\n    output = Object.assign(output, value.fields);\n    const endIndex = serializeInto(buffer, output, false, index, depth + 1, serializeFunctions, true, path);\n    const size = endIndex - startIndex;\n    startIndex += NumberUtils.setInt32LE(buffer, index, size);\n    return endIndex;\n}\nfunction serializeInto(buffer, object, checkKeys, startingIndex, depth, serializeFunctions, ignoreUndefined, path) {\n    if (path == null) {\n        if (object == null) {\n            buffer[0] = 0x05;\n            buffer[1] = 0x00;\n            buffer[2] = 0x00;\n            buffer[3] = 0x00;\n            buffer[4] = 0x00;\n            return 5;\n        }\n        if (Array.isArray(object)) {\n            throw new BSONError('serialize does not support an array as the root input');\n        }\n        if (typeof object !== 'object') {\n            throw new BSONError('serialize does not support non-object as the root input');\n        }\n        else if ('_bsontype' in object && typeof object._bsontype === 'string') {\n            throw new BSONError(`BSON types cannot be serialized as a document`);\n        }\n        else if (isDate(object) ||\n            isRegExp(object) ||\n            isUint8Array(object) ||\n            isAnyArrayBuffer(object)) {\n            throw new BSONError(`date, regexp, typedarray, and arraybuffer cannot be BSON documents`);\n        }\n        path = new Set();\n    }\n    path.add(object);\n    let index = startingIndex + 4;\n    if (Array.isArray(object)) {\n        for (let i = 0; i < object.length; i++) {\n            const key = `${i}`;\n            let value = object[i];\n            if (typeof value?.toBSON === 'function') {\n                value = value.toBSON();\n            }\n            if (typeof value === 'string') {\n                index = serializeString(buffer, key, value, index);\n            }\n            else if (typeof value === 'number') {\n                index = serializeNumber(buffer, key, value, index);\n            }\n            else if (typeof value === 'bigint') {\n                index = serializeBigInt(buffer, key, value, index);\n            }\n            else if (typeof value === 'boolean') {\n                index = serializeBoolean(buffer, key, value, index);\n            }\n            else if (value instanceof Date || isDate(value)) {\n                index = serializeDate(buffer, key, value, index);\n            }\n            else if (value === undefined) {\n                index = serializeNull(buffer, key, value, index);\n            }\n            else if (value === null) {\n                index = serializeNull(buffer, key, value, index);\n            }\n            else if (isUint8Array(value)) {\n                index = serializeBuffer(buffer, key, value, index);\n            }\n            else if (value instanceof RegExp || isRegExp(value)) {\n                index = serializeRegExp(buffer, key, value, index);\n            }\n            else if (typeof value === 'object' && value._bsontype == null) {\n                index = serializeObject(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path);\n            }\n            else if (typeof value === 'object' &&\n                value[Symbol.for('@@mdb.bson.version')] !== BSON_MAJOR_VERSION) {\n                throw new BSONVersionError();\n            }\n            else if (value._bsontype === 'ObjectId') {\n                index = serializeObjectId(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Decimal128') {\n                index = serializeDecimal128(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Long' || value._bsontype === 'Timestamp') {\n                index = serializeLong(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Double') {\n                index = serializeDouble(buffer, key, value, index);\n            }\n            else if (typeof value === 'function' && serializeFunctions) {\n                index = serializeFunction(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Code') {\n                index = serializeCode(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path);\n            }\n            else if (value._bsontype === 'Binary') {\n                index = serializeBinary(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'BSONSymbol') {\n                index = serializeSymbol(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'DBRef') {\n                index = serializeDBRef(buffer, key, value, index, depth, serializeFunctions, path);\n            }\n            else if (value._bsontype === 'BSONRegExp') {\n                index = serializeBSONRegExp(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Int32') {\n                index = serializeInt32(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'MinKey' || value._bsontype === 'MaxKey') {\n                index = serializeMinMax(buffer, key, value, index);\n            }\n            else if (typeof value._bsontype !== 'undefined') {\n                throw new BSONError(`Unrecognized or invalid _bsontype: ${String(value._bsontype)}`);\n            }\n        }\n    }\n    else if (object instanceof Map || isMap(object)) {\n        const iterator = object.entries();\n        let done = false;\n        while (!done) {\n            const entry = iterator.next();\n            done = !!entry.done;\n            if (done)\n                continue;\n            const key = entry.value[0];\n            let value = entry.value[1];\n            if (typeof value?.toBSON === 'function') {\n                value = value.toBSON();\n            }\n            const type = typeof value;\n            if (typeof key === 'string' && !ignoreKeys.has(key)) {\n                if (key.match(regexp) != null) {\n                    throw new BSONError('key ' + key + ' must not contain null bytes');\n                }\n                if (checkKeys) {\n                    if ('$' === key[0]) {\n                        throw new BSONError('key ' + key + \" must not start with '$'\");\n                    }\n                    else if (key.includes('.')) {\n                        throw new BSONError('key ' + key + \" must not contain '.'\");\n                    }\n                }\n            }\n            if (type === 'string') {\n                index = serializeString(buffer, key, value, index);\n            }\n            else if (type === 'number') {\n                index = serializeNumber(buffer, key, value, index);\n            }\n            else if (type === 'bigint') {\n                index = serializeBigInt(buffer, key, value, index);\n            }\n            else if (type === 'boolean') {\n                index = serializeBoolean(buffer, key, value, index);\n            }\n            else if (value instanceof Date || isDate(value)) {\n                index = serializeDate(buffer, key, value, index);\n            }\n            else if (value === null || (value === undefined && ignoreUndefined === false)) {\n                index = serializeNull(buffer, key, value, index);\n            }\n            else if (isUint8Array(value)) {\n                index = serializeBuffer(buffer, key, value, index);\n            }\n            else if (value instanceof RegExp || isRegExp(value)) {\n                index = serializeRegExp(buffer, key, value, index);\n            }\n            else if (type === 'object' && value._bsontype == null) {\n                index = serializeObject(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path);\n            }\n            else if (typeof value === 'object' &&\n                value[Symbol.for('@@mdb.bson.version')] !== BSON_MAJOR_VERSION) {\n                throw new BSONVersionError();\n            }\n            else if (value._bsontype === 'ObjectId') {\n                index = serializeObjectId(buffer, key, value, index);\n            }\n            else if (type === 'object' && value._bsontype === 'Decimal128') {\n                index = serializeDecimal128(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Long' || value._bsontype === 'Timestamp') {\n                index = serializeLong(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Double') {\n                index = serializeDouble(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Code') {\n                index = serializeCode(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path);\n            }\n            else if (typeof value === 'function' && serializeFunctions) {\n                index = serializeFunction(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Binary') {\n                index = serializeBinary(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'BSONSymbol') {\n                index = serializeSymbol(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'DBRef') {\n                index = serializeDBRef(buffer, key, value, index, depth, serializeFunctions, path);\n            }\n            else if (value._bsontype === 'BSONRegExp') {\n                index = serializeBSONRegExp(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Int32') {\n                index = serializeInt32(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'MinKey' || value._bsontype === 'MaxKey') {\n                index = serializeMinMax(buffer, key, value, index);\n            }\n            else if (typeof value._bsontype !== 'undefined') {\n                throw new BSONError(`Unrecognized or invalid _bsontype: ${String(value._bsontype)}`);\n            }\n        }\n    }\n    else {\n        if (typeof object?.toBSON === 'function') {\n            object = object.toBSON();\n            if (object != null && typeof object !== 'object') {\n                throw new BSONError('toBSON function did not return an object');\n            }\n        }\n        for (const key of Object.keys(object)) {\n            let value = object[key];\n            if (typeof value?.toBSON === 'function') {\n                value = value.toBSON();\n            }\n            const type = typeof value;\n            if (typeof key === 'string' && !ignoreKeys.has(key)) {\n                if (key.match(regexp) != null) {\n                    throw new BSONError('key ' + key + ' must not contain null bytes');\n                }\n                if (checkKeys) {\n                    if ('$' === key[0]) {\n                        throw new BSONError('key ' + key + \" must not start with '$'\");\n                    }\n                    else if (key.includes('.')) {\n                        throw new BSONError('key ' + key + \" must not contain '.'\");\n                    }\n                }\n            }\n            if (type === 'string') {\n                index = serializeString(buffer, key, value, index);\n            }\n            else if (type === 'number') {\n                index = serializeNumber(buffer, key, value, index);\n            }\n            else if (type === 'bigint') {\n                index = serializeBigInt(buffer, key, value, index);\n            }\n            else if (type === 'boolean') {\n                index = serializeBoolean(buffer, key, value, index);\n            }\n            else if (value instanceof Date || isDate(value)) {\n                index = serializeDate(buffer, key, value, index);\n            }\n            else if (value === undefined) {\n                if (ignoreUndefined === false)\n                    index = serializeNull(buffer, key, value, index);\n            }\n            else if (value === null) {\n                index = serializeNull(buffer, key, value, index);\n            }\n            else if (isUint8Array(value)) {\n                index = serializeBuffer(buffer, key, value, index);\n            }\n            else if (value instanceof RegExp || isRegExp(value)) {\n                index = serializeRegExp(buffer, key, value, index);\n            }\n            else if (type === 'object' && value._bsontype == null) {\n                index = serializeObject(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path);\n            }\n            else if (typeof value === 'object' &&\n                value[Symbol.for('@@mdb.bson.version')] !== BSON_MAJOR_VERSION) {\n                throw new BSONVersionError();\n            }\n            else if (value._bsontype === 'ObjectId') {\n                index = serializeObjectId(buffer, key, value, index);\n            }\n            else if (type === 'object' && value._bsontype === 'Decimal128') {\n                index = serializeDecimal128(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Long' || value._bsontype === 'Timestamp') {\n                index = serializeLong(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Double') {\n                index = serializeDouble(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Code') {\n                index = serializeCode(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path);\n            }\n            else if (typeof value === 'function' && serializeFunctions) {\n                index = serializeFunction(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Binary') {\n                index = serializeBinary(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'BSONSymbol') {\n                index = serializeSymbol(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'DBRef') {\n                index = serializeDBRef(buffer, key, value, index, depth, serializeFunctions, path);\n            }\n            else if (value._bsontype === 'BSONRegExp') {\n                index = serializeBSONRegExp(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Int32') {\n                index = serializeInt32(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'MinKey' || value._bsontype === 'MaxKey') {\n                index = serializeMinMax(buffer, key, value, index);\n            }\n            else if (typeof value._bsontype !== 'undefined') {\n                throw new BSONError(`Unrecognized or invalid _bsontype: ${String(value._bsontype)}`);\n            }\n        }\n    }\n    path.delete(object);\n    buffer[index++] = 0x00;\n    const size = index - startingIndex;\n    startingIndex += NumberUtils.setInt32LE(buffer, startingIndex, size);\n    return index;\n}\n\nfunction isBSONType(value) {\n    return (value != null &&\n        typeof value === 'object' &&\n        '_bsontype' in value &&\n        typeof value._bsontype === 'string');\n}\nconst keysToCodecs = {\n    $oid: ObjectId,\n    $binary: Binary,\n    $uuid: Binary,\n    $symbol: BSONSymbol,\n    $numberInt: Int32,\n    $numberDecimal: Decimal128,\n    $numberDouble: Double,\n    $numberLong: Long,\n    $minKey: MinKey,\n    $maxKey: MaxKey,\n    $regex: BSONRegExp,\n    $regularExpression: BSONRegExp,\n    $timestamp: Timestamp\n};\nfunction deserializeValue(value, options = {}) {\n    if (typeof value === 'number') {\n        const in32BitRange = value <= BSON_INT32_MAX && value >= BSON_INT32_MIN;\n        const in64BitRange = value <= BSON_INT64_MAX && value >= BSON_INT64_MIN;\n        if (options.relaxed || options.legacy) {\n            return value;\n        }\n        if (Number.isInteger(value) && !Object.is(value, -0)) {\n            if (in32BitRange) {\n                return new Int32(value);\n            }\n            if (in64BitRange) {\n                if (options.useBigInt64) {\n                    return BigInt(value);\n                }\n                return Long.fromNumber(value);\n            }\n        }\n        return new Double(value);\n    }\n    if (value == null || typeof value !== 'object')\n        return value;\n    if (value.$undefined)\n        return null;\n    const keys = Object.keys(value).filter(k => k.startsWith('$') && value[k] != null);\n    for (let i = 0; i < keys.length; i++) {\n        const c = keysToCodecs[keys[i]];\n        if (c)\n            return c.fromExtendedJSON(value, options);\n    }\n    if (value.$date != null) {\n        const d = value.$date;\n        const date = new Date();\n        if (options.legacy) {\n            if (typeof d === 'number')\n                date.setTime(d);\n            else if (typeof d === 'string')\n                date.setTime(Date.parse(d));\n            else if (typeof d === 'bigint')\n                date.setTime(Number(d));\n            else\n                throw new BSONRuntimeError(`Unrecognized type for EJSON date: ${typeof d}`);\n        }\n        else {\n            if (typeof d === 'string')\n                date.setTime(Date.parse(d));\n            else if (Long.isLong(d))\n                date.setTime(d.toNumber());\n            else if (typeof d === 'number' && options.relaxed)\n                date.setTime(d);\n            else if (typeof d === 'bigint')\n                date.setTime(Number(d));\n            else\n                throw new BSONRuntimeError(`Unrecognized type for EJSON date: ${typeof d}`);\n        }\n        return date;\n    }\n    if (value.$code != null) {\n        const copy = Object.assign({}, value);\n        if (value.$scope) {\n            copy.$scope = deserializeValue(value.$scope);\n        }\n        return Code.fromExtendedJSON(value);\n    }\n    if (isDBRefLike(value) || value.$dbPointer) {\n        const v = value.$ref ? value : value.$dbPointer;\n        if (v instanceof DBRef)\n            return v;\n        const dollarKeys = Object.keys(v).filter(k => k.startsWith('$'));\n        let valid = true;\n        dollarKeys.forEach(k => {\n            if (['$ref', '$id', '$db'].indexOf(k) === -1)\n                valid = false;\n        });\n        if (valid)\n            return DBRef.fromExtendedJSON(v);\n    }\n    return value;\n}\nfunction serializeArray(array, options) {\n    return array.map((v, index) => {\n        options.seenObjects.push({ propertyName: `index ${index}`, obj: null });\n        try {\n            return serializeValue(v, options);\n        }\n        finally {\n            options.seenObjects.pop();\n        }\n    });\n}\nfunction getISOString(date) {\n    const isoStr = date.toISOString();\n    return date.getUTCMilliseconds() !== 0 ? isoStr : isoStr.slice(0, -5) + 'Z';\n}\nfunction serializeValue(value, options) {\n    if (value instanceof Map || isMap(value)) {\n        const obj = Object.create(null);\n        for (const [k, v] of value) {\n            if (typeof k !== 'string') {\n                throw new BSONError('Can only serialize maps with string keys');\n            }\n            obj[k] = v;\n        }\n        return serializeValue(obj, options);\n    }\n    if ((typeof value === 'object' || typeof value === 'function') && value !== null) {\n        const index = options.seenObjects.findIndex(entry => entry.obj === value);\n        if (index !== -1) {\n            const props = options.seenObjects.map(entry => entry.propertyName);\n            const leadingPart = props\n                .slice(0, index)\n                .map(prop => `${prop} -> `)\n                .join('');\n            const alreadySeen = props[index];\n            const circularPart = ' -> ' +\n                props\n                    .slice(index + 1, props.length - 1)\n                    .map(prop => `${prop} -> `)\n                    .join('');\n            const current = props[props.length - 1];\n            const leadingSpace = ' '.repeat(leadingPart.length + alreadySeen.length / 2);\n            const dashes = '-'.repeat(circularPart.length + (alreadySeen.length + current.length) / 2 - 1);\n            throw new BSONError('Converting circular structure to EJSON:\\n' +\n                `    ${leadingPart}${alreadySeen}${circularPart}${current}\\n` +\n                `    ${leadingSpace}\\\\${dashes}/`);\n        }\n        options.seenObjects[options.seenObjects.length - 1].obj = value;\n    }\n    if (Array.isArray(value))\n        return serializeArray(value, options);\n    if (value === undefined)\n        return null;\n    if (value instanceof Date || isDate(value)) {\n        const dateNum = value.getTime(), inRange = dateNum > -1 && dateNum < 253402318800000;\n        if (options.legacy) {\n            return options.relaxed && inRange\n                ? { $date: value.getTime() }\n                : { $date: getISOString(value) };\n        }\n        return options.relaxed && inRange\n            ? { $date: getISOString(value) }\n            : { $date: { $numberLong: value.getTime().toString() } };\n    }\n    if (typeof value === 'number' && (!options.relaxed || !isFinite(value))) {\n        if (Number.isInteger(value) && !Object.is(value, -0)) {\n            if (value >= BSON_INT32_MIN && value <= BSON_INT32_MAX) {\n                return { $numberInt: value.toString() };\n            }\n            if (value >= BSON_INT64_MIN && value <= BSON_INT64_MAX) {\n                return { $numberLong: value.toString() };\n            }\n        }\n        return { $numberDouble: Object.is(value, -0) ? '-0.0' : value.toString() };\n    }\n    if (typeof value === 'bigint') {\n        if (!options.relaxed) {\n            return { $numberLong: BigInt.asIntN(64, value).toString() };\n        }\n        return Number(BigInt.asIntN(64, value));\n    }\n    if (value instanceof RegExp || isRegExp(value)) {\n        let flags = value.flags;\n        if (flags === undefined) {\n            const match = value.toString().match(/[gimuy]*$/);\n            if (match) {\n                flags = match[0];\n            }\n        }\n        const rx = new BSONRegExp(value.source, flags);\n        return rx.toExtendedJSON(options);\n    }\n    if (value != null && typeof value === 'object')\n        return serializeDocument(value, options);\n    return value;\n}\nconst BSON_TYPE_MAPPINGS = {\n    Binary: (o) => new Binary(o.value(), o.sub_type),\n    Code: (o) => new Code(o.code, o.scope),\n    DBRef: (o) => new DBRef(o.collection || o.namespace, o.oid, o.db, o.fields),\n    Decimal128: (o) => new Decimal128(o.bytes),\n    Double: (o) => new Double(o.value),\n    Int32: (o) => new Int32(o.value),\n    Long: (o) => Long.fromBits(o.low != null ? o.low : o.low_, o.low != null ? o.high : o.high_, o.low != null ? o.unsigned : o.unsigned_),\n    MaxKey: () => new MaxKey(),\n    MinKey: () => new MinKey(),\n    ObjectId: (o) => new ObjectId(o),\n    BSONRegExp: (o) => new BSONRegExp(o.pattern, o.options),\n    BSONSymbol: (o) => new BSONSymbol(o.value),\n    Timestamp: (o) => Timestamp.fromBits(o.low, o.high)\n};\nfunction serializeDocument(doc, options) {\n    if (doc == null || typeof doc !== 'object')\n        throw new BSONError('not an object instance');\n    const bsontype = doc._bsontype;\n    if (typeof bsontype === 'undefined') {\n        const _doc = {};\n        for (const name of Object.keys(doc)) {\n            options.seenObjects.push({ propertyName: name, obj: null });\n            try {\n                const value = serializeValue(doc[name], options);\n                if (name === '__proto__') {\n                    Object.defineProperty(_doc, name, {\n                        value,\n                        writable: true,\n                        enumerable: true,\n                        configurable: true\n                    });\n                }\n                else {\n                    _doc[name] = value;\n                }\n            }\n            finally {\n                options.seenObjects.pop();\n            }\n        }\n        return _doc;\n    }\n    else if (doc != null &&\n        typeof doc === 'object' &&\n        typeof doc._bsontype === 'string' &&\n        doc[Symbol.for('@@mdb.bson.version')] !== BSON_MAJOR_VERSION) {\n        throw new BSONVersionError();\n    }\n    else if (isBSONType(doc)) {\n        let outDoc = doc;\n        if (typeof outDoc.toExtendedJSON !== 'function') {\n            const mapper = BSON_TYPE_MAPPINGS[doc._bsontype];\n            if (!mapper) {\n                throw new BSONError('Unrecognized or invalid _bsontype: ' + doc._bsontype);\n            }\n            outDoc = mapper(outDoc);\n        }\n        if (bsontype === 'Code' && outDoc.scope) {\n            outDoc = new Code(outDoc.code, serializeValue(outDoc.scope, options));\n        }\n        else if (bsontype === 'DBRef' && outDoc.oid) {\n            outDoc = new DBRef(serializeValue(outDoc.collection, options), serializeValue(outDoc.oid, options), serializeValue(outDoc.db, options), serializeValue(outDoc.fields, options));\n        }\n        return outDoc.toExtendedJSON(options);\n    }\n    else {\n        throw new BSONError('_bsontype must be a string, but was: ' + typeof bsontype);\n    }\n}\nfunction parse(text, options) {\n    const ejsonOptions = {\n        useBigInt64: options?.useBigInt64 ?? false,\n        relaxed: options?.relaxed ?? true,\n        legacy: options?.legacy ?? false\n    };\n    return JSON.parse(text, (key, value) => {\n        if (key.indexOf('\\x00') !== -1) {\n            throw new BSONError(`BSON Document field names cannot contain null bytes, found: ${JSON.stringify(key)}`);\n        }\n        return deserializeValue(value, ejsonOptions);\n    });\n}\nfunction stringify(value, replacer, space, options) {\n    if (space != null && typeof space === 'object') {\n        options = space;\n        space = 0;\n    }\n    if (replacer != null && typeof replacer === 'object' && !Array.isArray(replacer)) {\n        options = replacer;\n        replacer = undefined;\n        space = 0;\n    }\n    const serializeOptions = Object.assign({ relaxed: true, legacy: false }, options, {\n        seenObjects: [{ propertyName: '(root)', obj: null }]\n    });\n    const doc = serializeValue(value, serializeOptions);\n    return JSON.stringify(doc, replacer, space);\n}\nfunction EJSONserialize(value, options) {\n    options = options || {};\n    return JSON.parse(stringify(value, options));\n}\nfunction EJSONdeserialize(ejson, options) {\n    options = options || {};\n    return parse(JSON.stringify(ejson), options);\n}\nconst EJSON = Object.create(null);\nEJSON.parse = parse;\nEJSON.stringify = stringify;\nEJSON.serialize = EJSONserialize;\nEJSON.deserialize = EJSONdeserialize;\nObject.freeze(EJSON);\n\nfunction getSize(source, offset) {\n    try {\n        return NumberUtils.getNonnegativeInt32LE(source, offset);\n    }\n    catch (cause) {\n        throw new BSONOffsetError('BSON size cannot be negative', offset, { cause });\n    }\n}\nfunction findNull(bytes, offset) {\n    let nullTerminatorOffset = offset;\n    for (; bytes[nullTerminatorOffset] !== 0x00; nullTerminatorOffset++)\n        ;\n    if (nullTerminatorOffset === bytes.length - 1) {\n        throw new BSONOffsetError('Null terminator not found', offset);\n    }\n    return nullTerminatorOffset;\n}\nfunction parseToElements(bytes, startOffset = 0) {\n    startOffset ??= 0;\n    if (bytes.length < 5) {\n        throw new BSONOffsetError(`Input must be at least 5 bytes, got ${bytes.length} bytes`, startOffset);\n    }\n    const documentSize = getSize(bytes, startOffset);\n    if (documentSize > bytes.length - startOffset) {\n        throw new BSONOffsetError(`Parsed documentSize (${documentSize} bytes) does not match input length (${bytes.length} bytes)`, startOffset);\n    }\n    if (bytes[startOffset + documentSize - 1] !== 0x00) {\n        throw new BSONOffsetError('BSON documents must end in 0x00', startOffset + documentSize);\n    }\n    const elements = [];\n    let offset = startOffset + 4;\n    while (offset <= documentSize + startOffset) {\n        const type = bytes[offset];\n        offset += 1;\n        if (type === 0) {\n            if (offset - startOffset !== documentSize) {\n                throw new BSONOffsetError(`Invalid 0x00 type byte`, offset);\n            }\n            break;\n        }\n        const nameOffset = offset;\n        const nameLength = findNull(bytes, offset) - nameOffset;\n        offset += nameLength + 1;\n        let length;\n        if (type === 1 ||\n            type === 18 ||\n            type === 9 ||\n            type === 17) {\n            length = 8;\n        }\n        else if (type === 16) {\n            length = 4;\n        }\n        else if (type === 7) {\n            length = 12;\n        }\n        else if (type === 19) {\n            length = 16;\n        }\n        else if (type === 8) {\n            length = 1;\n        }\n        else if (type === 10 ||\n            type === 6 ||\n            type === 127 ||\n            type === 255) {\n            length = 0;\n        }\n        else if (type === 11) {\n            length = findNull(bytes, findNull(bytes, offset) + 1) + 1 - offset;\n        }\n        else if (type === 3 ||\n            type === 4 ||\n            type === 15) {\n            length = getSize(bytes, offset);\n        }\n        else if (type === 2 ||\n            type === 5 ||\n            type === 12 ||\n            type === 13 ||\n            type === 14) {\n            length = getSize(bytes, offset) + 4;\n            if (type === 5) {\n                length += 1;\n            }\n            if (type === 12) {\n                length += 12;\n            }\n        }\n        else {\n            throw new BSONOffsetError(`Invalid 0x${type.toString(16).padStart(2, '0')} type byte`, offset);\n        }\n        if (length > documentSize) {\n            throw new BSONOffsetError('value reports length larger than document', offset);\n        }\n        elements.push([type, nameOffset, nameLength, offset, length]);\n        offset += length;\n    }\n    return elements;\n}\n\nconst onDemand = Object.create(null);\nonDemand.parseToElements = parseToElements;\nonDemand.ByteUtils = ByteUtils;\nonDemand.NumberUtils = NumberUtils;\nObject.freeze(onDemand);\n\nconst MAXSIZE = 1024 * 1024 * 17;\nlet buffer = ByteUtils.allocate(MAXSIZE);\nfunction setInternalBufferSize(size) {\n    if (buffer.length < size) {\n        buffer = ByteUtils.allocate(size);\n    }\n}\nfunction serialize(object, options = {}) {\n    const checkKeys = typeof options.checkKeys === 'boolean' ? options.checkKeys : false;\n    const serializeFunctions = typeof options.serializeFunctions === 'boolean' ? options.serializeFunctions : false;\n    const ignoreUndefined = typeof options.ignoreUndefined === 'boolean' ? options.ignoreUndefined : true;\n    const minInternalBufferSize = typeof options.minInternalBufferSize === 'number' ? options.minInternalBufferSize : MAXSIZE;\n    if (buffer.length < minInternalBufferSize) {\n        buffer = ByteUtils.allocate(minInternalBufferSize);\n    }\n    const serializationIndex = serializeInto(buffer, object, checkKeys, 0, 0, serializeFunctions, ignoreUndefined, null);\n    const finishedBuffer = ByteUtils.allocateUnsafe(serializationIndex);\n    finishedBuffer.set(buffer.subarray(0, serializationIndex), 0);\n    return finishedBuffer;\n}\nfunction serializeWithBufferAndIndex(object, finalBuffer, options = {}) {\n    const checkKeys = typeof options.checkKeys === 'boolean' ? options.checkKeys : false;\n    const serializeFunctions = typeof options.serializeFunctions === 'boolean' ? options.serializeFunctions : false;\n    const ignoreUndefined = typeof options.ignoreUndefined === 'boolean' ? options.ignoreUndefined : true;\n    const startIndex = typeof options.index === 'number' ? options.index : 0;\n    const serializationIndex = serializeInto(buffer, object, checkKeys, 0, 0, serializeFunctions, ignoreUndefined, null);\n    finalBuffer.set(buffer.subarray(0, serializationIndex), startIndex);\n    return startIndex + serializationIndex - 1;\n}\nfunction deserialize(buffer, options = {}) {\n    return internalDeserialize(ByteUtils.toLocalBufferType(buffer), options);\n}\nfunction calculateObjectSize(object, options = {}) {\n    options = options || {};\n    const serializeFunctions = typeof options.serializeFunctions === 'boolean' ? options.serializeFunctions : false;\n    const ignoreUndefined = typeof options.ignoreUndefined === 'boolean' ? options.ignoreUndefined : true;\n    return internalCalculateObjectSize(object, serializeFunctions, ignoreUndefined);\n}\nfunction deserializeStream(data, startIndex, numberOfDocuments, documents, docStartIndex, options) {\n    const internalOptions = Object.assign({ allowObjectSmallerThanBufferSize: true, index: 0 }, options);\n    const bufferData = ByteUtils.toLocalBufferType(data);\n    let index = startIndex;\n    for (let i = 0; i < numberOfDocuments; i++) {\n        const size = NumberUtils.getInt32LE(bufferData, index);\n        internalOptions.index = index;\n        documents[docStartIndex + i] = internalDeserialize(bufferData, internalOptions);\n        index = index + size;\n    }\n    return index;\n}\n\nvar bson = /*#__PURE__*/Object.freeze({\n    __proto__: null,\n    BSONError: BSONError,\n    BSONOffsetError: BSONOffsetError,\n    BSONRegExp: BSONRegExp,\n    BSONRuntimeError: BSONRuntimeError,\n    BSONSymbol: BSONSymbol,\n    BSONType: BSONType,\n    BSONValue: BSONValue,\n    BSONVersionError: BSONVersionError,\n    Binary: Binary,\n    Code: Code,\n    DBRef: DBRef,\n    Decimal128: Decimal128,\n    Double: Double,\n    EJSON: EJSON,\n    Int32: Int32,\n    Long: Long,\n    MaxKey: MaxKey,\n    MinKey: MinKey,\n    ObjectId: ObjectId,\n    Timestamp: Timestamp,\n    UUID: UUID,\n    calculateObjectSize: calculateObjectSize,\n    deserialize: deserialize,\n    deserializeStream: deserializeStream,\n    onDemand: onDemand,\n    serialize: serialize,\n    serializeWithBufferAndIndex: serializeWithBufferAndIndex,\n    setInternalBufferSize: setInternalBufferSize\n});\n\nexports.BSON = bson;\nexports.BSONError = BSONError;\nexports.BSONOffsetError = BSONOffsetError;\nexports.BSONRegExp = BSONRegExp;\nexports.BSONRuntimeError = BSONRuntimeError;\nexports.BSONSymbol = BSONSymbol;\nexports.BSONType = BSONType;\nexports.BSONValue = BSONValue;\nexports.BSONVersionError = BSONVersionError;\nexports.Binary = Binary;\nexports.Code = Code;\nexports.DBRef = DBRef;\nexports.Decimal128 = Decimal128;\nexports.Double = Double;\nexports.EJSON = EJSON;\nexports.Int32 = Int32;\nexports.Long = Long;\nexports.MaxKey = MaxKey;\nexports.MinKey = MinKey;\nexports.ObjectId = ObjectId;\nexports.Timestamp = Timestamp;\nexports.UUID = UUID;\nexports.calculateObjectSize = calculateObjectSize;\nexports.deserialize = deserialize;\nexports.deserializeStream = deserializeStream;\nexports.onDemand = onDemand;\nexports.serialize = serialize;\nexports.serializeWithBufferAndIndex = serializeWithBufferAndIndex;\nexports.setInternalBufferSize = setInternalBufferSize;\n//# sourceMappingURL=bson.cjs.map\n\n\n//# sourceURL=webpack://experimento/./node_modules/bson/lib/bson.cjs?");

/***/ }),

/***/ "./node_modules/mongodb/package.json":
/*!*******************************************!*\
  !*** ./node_modules/mongodb/package.json ***!
  \*******************************************/
/***/ ((module) => {

"use strict";
eval("module.exports = /*#__PURE__*/JSON.parse('{\"name\":\"mongodb\",\"version\":\"6.7.0\",\"description\":\"The official MongoDB driver for Node.js\",\"main\":\"lib/index.js\",\"files\":[\"lib\",\"src\",\"etc/prepare.js\",\"mongodb.d.ts\",\"tsconfig.json\"],\"types\":\"mongodb.d.ts\",\"repository\":{\"type\":\"git\",\"url\":\"git@github.com:mongodb/node-mongodb-native.git\"},\"keywords\":[\"mongodb\",\"driver\",\"official\"],\"author\":{\"name\":\"The MongoDB NodeJS Team\",\"email\":\"dbx-node@mongodb.com\"},\"dependencies\":{\"@mongodb-js/saslprep\":\"^1.1.5\",\"bson\":\"^6.7.0\",\"mongodb-connection-string-url\":\"^3.0.0\"},\"peerDependencies\":{\"@aws-sdk/credential-providers\":\"^3.188.0\",\"@mongodb-js/zstd\":\"^1.1.0\",\"gcp-metadata\":\"^5.2.0\",\"kerberos\":\"^2.0.1\",\"mongodb-client-encryption\":\">=6.0.0 <7\",\"snappy\":\"^7.2.2\",\"socks\":\"^2.7.1\"},\"peerDependenciesMeta\":{\"@aws-sdk/credential-providers\":{\"optional\":true},\"@mongodb-js/zstd\":{\"optional\":true},\"kerberos\":{\"optional\":true},\"snappy\":{\"optional\":true},\"mongodb-client-encryption\":{\"optional\":true},\"gcp-metadata\":{\"optional\":true},\"socks\":{\"optional\":true}},\"devDependencies\":{\"@aws-sdk/credential-providers\":\"^3.515.0\",\"@iarna/toml\":\"^2.2.5\",\"@istanbuljs/nyc-config-typescript\":\"^1.0.2\",\"@microsoft/api-extractor\":\"^7.43.1\",\"@microsoft/tsdoc-config\":\"^0.16.2\",\"@mongodb-js/zstd\":\"^1.2.0\",\"@types/chai\":\"^4.3.14\",\"@types/chai-subset\":\"^1.3.5\",\"@types/express\":\"^4.17.21\",\"@types/kerberos\":\"^1.1.5\",\"@types/mocha\":\"^10.0.6\",\"@types/node\":\"^20.12.7\",\"@types/saslprep\":\"^1.0.3\",\"@types/semver\":\"^7.5.8\",\"@types/sinon\":\"^17.0.3\",\"@types/sinon-chai\":\"^3.2.12\",\"@types/whatwg-url\":\"^11.0.4\",\"@typescript-eslint/eslint-plugin\":\"^5.62.0\",\"@typescript-eslint/parser\":\"^5.62.0\",\"chai\":\"^4.4.1\",\"chai-subset\":\"^1.6.0\",\"chalk\":\"^4.1.2\",\"eslint\":\"^8.56.0\",\"eslint-config-prettier\":\"^8.10.0\",\"eslint-plugin-github\":\"^4.10.2\",\"eslint-plugin-import\":\"^2.29.1\",\"eslint-plugin-mocha\":\"^10.4.1\",\"eslint-plugin-prettier\":\"^4.2.1\",\"eslint-plugin-simple-import-sort\":\"^10.0.0\",\"eslint-plugin-tsdoc\":\"^0.2.17\",\"eslint-plugin-unused-imports\":\"^2.0.0\",\"express\":\"^4.19.2\",\"gcp-metadata\":\"^5.3.0\",\"js-yaml\":\"^4.1.0\",\"mocha\":\"^10.4.0\",\"mocha-sinon\":\"^2.1.2\",\"mongodb-client-encryption\":\"^6.0.0\",\"mongodb-legacy\":\"^6.0.1\",\"nyc\":\"^15.1.0\",\"prettier\":\"^2.8.8\",\"semver\":\"^7.6.0\",\"sinon\":\"^17.0.1\",\"sinon-chai\":\"^3.7.0\",\"snappy\":\"^7.2.2\",\"socks\":\"^2.8.1\",\"source-map-support\":\"^0.5.21\",\"ts-node\":\"^10.9.2\",\"tsd\":\"^0.31.0\",\"typescript\":\"5.0\",\"typescript-cached-transpile\":\"^0.0.6\",\"v8-heapsnapshot\":\"^1.3.1\",\"yargs\":\"^17.7.2\"},\"license\":\"Apache-2.0\",\"engines\":{\"node\":\">=16.20.1\"},\"bugs\":{\"url\":\"https://jira.mongodb.org/projects/NODE/issues/\"},\"homepage\":\"https://github.com/mongodb/node-mongodb-native\",\"scripts\":{\"build:evergreen\":\"node .evergreen/generate_evergreen_tasks.js\",\"build:ts\":\"node ./node_modules/typescript/bin/tsc\",\"build:dts\":\"npm run build:ts && api-extractor run && node etc/clean_definition_files.cjs && eslint mongodb.d.ts --fix\",\"build:docs\":\"./etc/docs/build.ts\",\"build:typedoc\":\"typedoc\",\"build:nightly\":\"node ./.github/scripts/nightly.mjs\",\"check:bench\":\"node test/benchmarks/driverBench\",\"check:coverage\":\"nyc npm run test:all\",\"check:integration-coverage\":\"nyc npm run check:test\",\"check:lambda\":\"mocha --config test/mocha_lambda.json test/integration/node-specific/examples/handler.test.js\",\"check:lambda:aws\":\"mocha --config test/mocha_lambda.json test/integration/node-specific/examples/aws_handler.test.js\",\"check:lint\":\"npm run build:dts && npm run check:dts && npm run check:eslint && npm run check:tsd\",\"check:eslint\":\"eslint -v && eslint --max-warnings=0 --ext \\'.js,.ts\\' src test\",\"check:tsd\":\"tsd --version && tsd\",\"check:dependencies\":\"mocha test/action/dependency.test.ts\",\"check:dts\":\"node ./node_modules/typescript/bin/tsc --noEmit mongodb.d.ts && tsd\",\"check:search-indexes\":\"nyc mocha --config test/mocha_mongodb.json test/manual/search-index-management.prose.test.ts\",\"check:test\":\"mocha --config test/mocha_mongodb.json test/integration\",\"check:unit\":\"mocha test/unit\",\"check:ts\":\"node ./node_modules/typescript/bin/tsc -v && node ./node_modules/typescript/bin/tsc --noEmit\",\"check:atlas\":\"mocha --config test/manual/mocharc.json test/manual/atlas_connectivity.test.ts\",\"check:drivers-atlas-testing\":\"mocha --config test/mocha_mongodb.json test/atlas/drivers_atlas_testing.test.ts\",\"check:adl\":\"mocha --config test/mocha_mongodb.json test/manual/atlas-data-lake-testing\",\"check:aws\":\"nyc mocha --config test/mocha_mongodb.json test/integration/auth/mongodb_aws.test.ts\",\"check:oidc-auth\":\"mocha --config test/mocha_mongodb.json test/integration/auth/auth.spec.test.ts\",\"check:oidc-test\":\"mocha --config test/mocha_mongodb.json test/integration/auth/mongodb_oidc.prose.test.ts\",\"check:oidc-azure\":\"mocha --config test/mocha_mongodb.json test/integration/auth/mongodb_oidc_azure.prose.05.test.ts\",\"check:oidc-gcp\":\"mocha --config test/mocha_mongodb.json test/integration/auth/mongodb_oidc_gcp.prose.06.test.ts\",\"check:ocsp\":\"mocha --config test/manual/mocharc.json test/manual/ocsp_support.test.js\",\"check:kerberos\":\"nyc mocha --config test/manual/mocharc.json test/manual/kerberos.test.ts\",\"check:tls\":\"mocha --config test/manual/mocharc.json test/manual/tls_support.test.ts\",\"check:ldap\":\"nyc mocha --config test/manual/mocharc.json test/manual/ldap.test.js\",\"check:socks5\":\"mocha --config test/manual/mocharc.json test/manual/socks5.test.ts\",\"check:csfle\":\"mocha --config test/mocha_mongodb.json test/integration/client-side-encryption\",\"check:snappy\":\"mocha test/unit/assorted/snappy.test.js\",\"check:x509\":\"mocha test/manual/x509_auth.test.ts\",\"fix:eslint\":\"npm run check:eslint -- --fix\",\"prepare\":\"node etc/prepare.js\",\"preview:docs\":\"ts-node etc/docs/preview.ts\",\"test\":\"npm run check:lint && npm run test:all\",\"test:all\":\"npm run check:unit && npm run check:test\",\"update:docs\":\"npm run build:docs -- --yes\"},\"tsd\":{\"directory\":\"test/types\",\"compilerOptions\":{\"strict\":true,\"target\":\"esnext\",\"module\":\"commonjs\",\"moduleResolution\":\"node\"}}}');\n\n//# sourceURL=webpack://experimento/./node_modules/mongodb/package.json?");

/***/ }),

/***/ "./node_modules/mongoose/package.json":
/*!********************************************!*\
  !*** ./node_modules/mongoose/package.json ***!
  \********************************************/
/***/ ((module) => {

"use strict";
eval("module.exports = /*#__PURE__*/JSON.parse('{\"name\":\"mongoose\",\"description\":\"Mongoose MongoDB ODM\",\"version\":\"8.5.3\",\"author\":\"Guillermo Rauch <guillermo@learnboost.com>\",\"keywords\":[\"mongodb\",\"document\",\"model\",\"schema\",\"database\",\"odm\",\"data\",\"datastore\",\"query\",\"nosql\",\"orm\",\"db\"],\"license\":\"MIT\",\"dependencies\":{\"bson\":\"^6.7.0\",\"kareem\":\"2.6.3\",\"mongodb\":\"6.7.0\",\"mpath\":\"0.9.0\",\"mquery\":\"5.0.0\",\"ms\":\"2.1.3\",\"sift\":\"17.1.3\"},\"devDependencies\":{\"@babel/core\":\"7.24.7\",\"@babel/preset-env\":\"7.25.3\",\"@typescript-eslint/eslint-plugin\":\"^6.21.0\",\"@typescript-eslint/parser\":\"^6.21.0\",\"acquit\":\"1.3.0\",\"acquit-ignore\":\"0.2.1\",\"acquit-require\":\"0.1.1\",\"assert-browserify\":\"2.0.0\",\"axios\":\"1.1.3\",\"babel-loader\":\"8.2.5\",\"broken-link-checker\":\"^0.7.8\",\"buffer\":\"^5.6.0\",\"cheerio\":\"1.0.0-rc.12\",\"crypto-browserify\":\"3.12.0\",\"dotenv\":\"16.4.5\",\"dox\":\"1.0.0\",\"eslint\":\"8.57.0\",\"eslint-plugin-markdown\":\"^5.0.0\",\"eslint-plugin-mocha-no-only\":\"1.2.0\",\"express\":\"^4.19.2\",\"fs-extra\":\"~11.2.0\",\"highlight.js\":\"11.10.0\",\"lodash.isequal\":\"4.5.0\",\"lodash.isequalwith\":\"4.4.0\",\"markdownlint-cli2\":\"^0.13.0\",\"marked\":\"4.3.0\",\"mkdirp\":\"^3.0.1\",\"mocha\":\"10.7.0\",\"moment\":\"2.30.1\",\"mongodb-memory-server\":\"10.0.0\",\"ncp\":\"^2.0.0\",\"nyc\":\"15.1.0\",\"pug\":\"3.0.3\",\"q\":\"1.5.1\",\"sinon\":\"18.0.0\",\"stream-browserify\":\"3.0.0\",\"tsd\":\"0.31.1\",\"typescript\":\"5.5.4\",\"uuid\":\"10.0.0\",\"webpack\":\"5.93.0\"},\"directories\":{\"lib\":\"./lib/mongoose\"},\"scripts\":{\"docs:clean\":\"npm run docs:clean:stable\",\"docs:clean:stable\":\"rimraf index.html && rimraf -rf ./docs/*.html  && rimraf -rf ./docs/api && rimraf -rf ./docs/tutorials/*.html && rimraf -rf ./docs/typescript/*.html && rimraf -rf ./docs/*.html && rimraf -rf ./docs/source/_docs && rimraf -rf ./tmp\",\"docs:clean:5x\":\"rimraf index.html && rimraf -rf ./docs/5.x && rimraf -rf ./docs/source/_docs && rimraf -rf ./tmp\",\"docs:clean:6x\":\"rimraf index.html && rimraf -rf ./docs/6.x && rimraf -rf ./docs/source/_docs && rimraf -rf ./tmp\",\"docs:copy:tmp\":\"mkdirp ./tmp/docs/css && mkdirp ./tmp/docs/js && mkdirp ./tmp/docs/images && mkdirp ./tmp/docs/tutorials && mkdirp ./tmp/docs/typescript && mkdirp ./tmp/docs/api && ncp ./docs/css ./tmp/docs/css --filter=.css$ && ncp ./docs/js ./tmp/docs/js --filter=.js$ && ncp ./docs/images ./tmp/docs/images && ncp ./docs/tutorials ./tmp/docs/tutorials && ncp ./docs/typescript ./tmp/docs/typescript && ncp ./docs/api ./tmp/docs/api && cp index.html ./tmp && cp docs/*.html ./tmp/docs/\",\"docs:copy:tmp:5x\":\"rimraf ./docs/5.x && ncp ./tmp ./docs/5.x\",\"docs:copy:tmp:6x\":\"rimraf ./docs/6.x && ncp ./tmp ./docs/6.x\",\"docs:generate\":\"node ./scripts/website.js\",\"docs:generate:sponsorData\":\"node ./scripts/loadSponsorData.js\",\"docs:test\":\"npm run docs:generate\",\"docs:view\":\"node ./scripts/static.js\",\"docs:prepare:publish:stable\":\"git checkout gh-pages && git merge master && npm run docs:generate\",\"docs:prepare:publish:5x\":\"git checkout 5.x && git merge 5.x && npm run docs:clean:stable && npm run docs:generate && npm run docs:copy:tmp && git checkout gh-pages && npm run docs:copy:tmp:5x\",\"docs:prepare:publish:6x\":\"git checkout 6.x && git merge 6.x && npm run docs:clean:stable && env DOCS_DEPLOY=true npm run docs:generate && mv ./docs/6.x ./tmp && git checkout gh-pages && npm run docs:copy:tmp:6x\",\"docs:prepare:publish:7x\":\"env DOCS_DEPLOY=true npm run docs:generate && git checkout gh-pages && rimraf ./docs/7.x && mv ./tmp ./docs/7.x\",\"docs:check-links\":\"blc http://127.0.0.1:8089 -ro\",\"lint\":\"eslint .\",\"lint-js\":\"eslint . --ext .js --ext .cjs\",\"lint-ts\":\"eslint . --ext .ts\",\"lint-md\":\"markdownlint-cli2 \\\\\"**/*.md\\\\\"\",\"build-browser\":\"(rm ./dist/* || true) && node ./scripts/build-browser.js\",\"prepublishOnly\":\"npm run build-browser\",\"release\":\"git pull && git push origin master --tags && npm publish\",\"release-5x\":\"git pull origin 5.x && git push origin 5.x && git push origin 5.x --tags && npm publish --tag 5x\",\"release-6x\":\"git pull origin 6.x && git push origin 6.x && git push origin 6.x --tags && npm publish --tag 6x\",\"mongo\":\"node ./tools/repl.js\",\"publish-7x\":\"npm publish --tag 7x\",\"test\":\"mocha --exit ./test/*.test.js\",\"test-deno\":\"deno run --allow-env --allow-read --allow-net --allow-run --allow-sys --allow-write ./test/deno.js\",\"test-rs\":\"START_REPLICA_SET=1 mocha --timeout 30000 --exit ./test/*.test.js\",\"test-tsd\":\"node ./test/types/check-types-filename && tsd\",\"tdd\":\"mocha ./test/*.test.js --inspect --watch --recursive --watch-files ./**/*.{js,ts}\",\"test-coverage\":\"nyc --reporter=html --reporter=text npm test\",\"ts-benchmark\":\"cd ./benchmarks/typescript/simple && npm install && npm run benchmark | node ../../../scripts/tsc-diagnostics-check\"},\"main\":\"./index.js\",\"types\":\"./types/index.d.ts\",\"engines\":{\"node\":\">=16.20.1\"},\"bugs\":{\"url\":\"https://github.com/Automattic/mongoose/issues/new\"},\"repository\":{\"type\":\"git\",\"url\":\"git://github.com/Automattic/mongoose.git\"},\"homepage\":\"https://mongoosejs.com\",\"browser\":\"./dist/browser.umd.js\",\"config\":{\"mongodbMemoryServer\":{\"disablePostinstall\":true}},\"funding\":{\"type\":\"opencollective\",\"url\":\"https://opencollective.com/mongoose\"},\"tsd\":{\"directory\":\"test/types\",\"compilerOptions\":{\"esModuleInterop\":false,\"strict\":true,\"allowSyntheticDefaultImports\":true,\"strictPropertyInitialization\":false,\"noImplicitAny\":false,\"strictNullChecks\":true,\"module\":\"commonjs\",\"target\":\"ES2017\"}}}');\n\n//# sourceURL=webpack://experimento/./node_modules/mongoose/package.json?");

/***/ }),

/***/ "./node_modules/tr46/lib/mappingTable.json":
/*!*************************************************!*\
  !*** ./node_modules/tr46/lib/mappingTable.json ***!
  \*************************************************/
/***/ ((module) => {

"use strict";
eval("module.exports = /*#__PURE__*/JSON.parse('[[[0,44],4],[[45,46],2],[47,4],[[48,57],2],[[58,64],4],[65,1,\"a\"],[66,1,\"b\"],[67,1,\"c\"],[68,1,\"d\"],[69,1,\"e\"],[70,1,\"f\"],[71,1,\"g\"],[72,1,\"h\"],[73,1,\"i\"],[74,1,\"j\"],[75,1,\"k\"],[76,1,\"l\"],[77,1,\"m\"],[78,1,\"n\"],[79,1,\"o\"],[80,1,\"p\"],[81,1,\"q\"],[82,1,\"r\"],[83,1,\"s\"],[84,1,\"t\"],[85,1,\"u\"],[86,1,\"v\"],[87,1,\"w\"],[88,1,\"x\"],[89,1,\"y\"],[90,1,\"z\"],[[91,96],4],[[97,122],2],[[123,127],4],[[128,159],3],[160,5,\" \"],[[161,167],2],[168,5,\" \"],[169,2],[170,1,\"a\"],[[171,172],2],[173,7],[174,2],[175,5,\" \"],[[176,177],2],[178,1,\"2\"],[179,1,\"3\"],[180,5,\" \"],[181,1,\"\"],[182,2],[183,2],[184,5,\" \"],[185,1,\"1\"],[186,1,\"o\"],[187,2],[188,1,\"14\"],[189,1,\"12\"],[190,1,\"34\"],[191,2],[192,1,\"\"],[193,1,\"\"],[194,1,\"\"],[195,1,\"\"],[196,1,\"\"],[197,1,\"\"],[198,1,\"\"],[199,1,\"\"],[200,1,\"\"],[201,1,\"\"],[202,1,\"\"],[203,1,\"\"],[204,1,\"\"],[205,1,\"\"],[206,1,\"\"],[207,1,\"\"],[208,1,\"\"],[209,1,\"\"],[210,1,\"\"],[211,1,\"\"],[212,1,\"\"],[213,1,\"\"],[214,1,\"\"],[215,2],[216,1,\"\"],[217,1,\"\"],[218,1,\"\"],[219,1,\"\"],[220,1,\"\"],[221,1,\"\"],[222,1,\"\"],[223,6,\"ss\"],[[224,246],2],[247,2],[[248,255],2],[256,1,\"\"],[257,2],[258,1,\"\"],[259,2],[260,1,\"\"],[261,2],[262,1,\"\"],[263,2],[264,1,\"\"],[265,2],[266,1,\"\"],[267,2],[268,1,\"\"],[269,2],[270,1,\"\"],[271,2],[272,1,\"\"],[273,2],[274,1,\"\"],[275,2],[276,1,\"\"],[277,2],[278,1,\"\"],[279,2],[280,1,\"\"],[281,2],[282,1,\"\"],[283,2],[284,1,\"\"],[285,2],[286,1,\"\"],[287,2],[288,1,\"\"],[289,2],[290,1,\"\"],[291,2],[292,1,\"\"],[293,2],[294,1,\"\"],[295,2],[296,1,\"\"],[297,2],[298,1,\"\"],[299,2],[300,1,\"\"],[301,2],[302,1,\"\"],[303,2],[304,1,\"i\"],[305,2],[[306,307],1,\"ij\"],[308,1,\"\"],[309,2],[310,1,\"\"],[[311,312],2],[313,1,\"\"],[314,2],[315,1,\"\"],[316,2],[317,1,\"\"],[318,2],[[319,320],1,\"l\"],[321,1,\"\"],[322,2],[323,1,\"\"],[324,2],[325,1,\"\"],[326,2],[327,1,\"\"],[328,2],[329,1,\"n\"],[330,1,\"\"],[331,2],[332,1,\"\"],[333,2],[334,1,\"\"],[335,2],[336,1,\"\"],[337,2],[338,1,\"\"],[339,2],[340,1,\"\"],[341,2],[342,1,\"\"],[343,2],[344,1,\"\"],[345,2],[346,1,\"\"],[347,2],[348,1,\"\"],[349,2],[350,1,\"\"],[351,2],[352,1,\"\"],[353,2],[354,1,\"\"],[355,2],[356,1,\"\"],[357,2],[358,1,\"\"],[359,2],[360,1,\"\"],[361,2],[362,1,\"\"],[363,2],[364,1,\"\"],[365,2],[366,1,\"\"],[367,2],[368,1,\"\"],[369,2],[370,1,\"\"],[371,2],[372,1,\"\"],[373,2],[374,1,\"\"],[375,2],[376,1,\"\"],[377,1,\"\"],[378,2],[379,1,\"\"],[380,2],[381,1,\"\"],[382,2],[383,1,\"s\"],[384,2],[385,1,\"\"],[386,1,\"\"],[387,2],[388,1,\"\"],[389,2],[390,1,\"\"],[391,1,\"\"],[392,2],[393,1,\"\"],[394,1,\"\"],[395,1,\"\"],[[396,397],2],[398,1,\"\"],[399,1,\"\"],[400,1,\"\"],[401,1,\"\"],[402,2],[403,1,\"\"],[404,1,\"\"],[405,2],[406,1,\"\"],[407,1,\"\"],[408,1,\"\"],[[409,411],2],[412,1,\"\"],[413,1,\"\"],[414,2],[415,1,\"\"],[416,1,\"\"],[417,2],[418,1,\"\"],[419,2],[420,1,\"\"],[421,2],[422,1,\"\"],[423,1,\"\"],[424,2],[425,1,\"\"],[[426,427],2],[428,1,\"\"],[429,2],[430,1,\"\"],[431,1,\"\"],[432,2],[433,1,\"\"],[434,1,\"\"],[435,1,\"\"],[436,2],[437,1,\"\"],[438,2],[439,1,\"\"],[440,1,\"\"],[[441,443],2],[444,1,\"\"],[[445,451],2],[[452,454],1,\"d\"],[[455,457],1,\"lj\"],[[458,460],1,\"nj\"],[461,1,\"\"],[462,2],[463,1,\"\"],[464,2],[465,1,\"\"],[466,2],[467,1,\"\"],[468,2],[469,1,\"\"],[470,2],[471,1,\"\"],[472,2],[473,1,\"\"],[474,2],[475,1,\"\"],[[476,477],2],[478,1,\"\"],[479,2],[480,1,\"\"],[481,2],[482,1,\"\"],[483,2],[484,1,\"\"],[485,2],[486,1,\"\"],[487,2],[488,1,\"\"],[489,2],[490,1,\"\"],[491,2],[492,1,\"\"],[493,2],[494,1,\"\"],[[495,496],2],[[497,499],1,\"dz\"],[500,1,\"\"],[501,2],[502,1,\"\"],[503,1,\"\"],[504,1,\"\"],[505,2],[506,1,\"\"],[507,2],[508,1,\"\"],[509,2],[510,1,\"\"],[511,2],[512,1,\"\"],[513,2],[514,1,\"\"],[515,2],[516,1,\"\"],[517,2],[518,1,\"\"],[519,2],[520,1,\"\"],[521,2],[522,1,\"\"],[523,2],[524,1,\"\"],[525,2],[526,1,\"\"],[527,2],[528,1,\"\"],[529,2],[530,1,\"\"],[531,2],[532,1,\"\"],[533,2],[534,1,\"\"],[535,2],[536,1,\"\"],[537,2],[538,1,\"\"],[539,2],[540,1,\"\"],[541,2],[542,1,\"\"],[543,2],[544,1,\"\"],[545,2],[546,1,\"\"],[547,2],[548,1,\"\"],[549,2],[550,1,\"\"],[551,2],[552,1,\"\"],[553,2],[554,1,\"\"],[555,2],[556,1,\"\"],[557,2],[558,1,\"\"],[559,2],[560,1,\"\"],[561,2],[562,1,\"\"],[563,2],[[564,566],2],[[567,569],2],[570,1,\"\"],[571,1,\"\"],[572,2],[573,1,\"\"],[574,1,\"\"],[[575,576],2],[577,1,\"\"],[578,2],[579,1,\"\"],[580,1,\"\"],[581,1,\"\"],[582,1,\"\"],[583,2],[584,1,\"\"],[585,2],[586,1,\"\"],[587,2],[588,1,\"\"],[589,2],[590,1,\"\"],[591,2],[[592,680],2],[[681,685],2],[[686,687],2],[688,1,\"h\"],[689,1,\"\"],[690,1,\"j\"],[691,1,\"r\"],[692,1,\"\"],[693,1,\"\"],[694,1,\"\"],[695,1,\"w\"],[696,1,\"y\"],[[697,705],2],[[706,709],2],[[710,721],2],[[722,727],2],[728,5,\" \"],[729,5,\" \"],[730,5,\" \"],[731,5,\" \"],[732,5,\" \"],[733,5,\" \"],[734,2],[735,2],[736,1,\"\"],[737,1,\"l\"],[738,1,\"s\"],[739,1,\"x\"],[740,1,\"\"],[[741,745],2],[[746,747],2],[748,2],[749,2],[750,2],[[751,767],2],[[768,831],2],[832,1,\"\"],[833,1,\"\"],[834,2],[835,1,\"\"],[836,1,\"\"],[837,1,\"\"],[[838,846],2],[847,7],[[848,855],2],[[856,860],2],[[861,863],2],[[864,865],2],[866,2],[[867,879],2],[880,1,\"\"],[881,2],[882,1,\"\"],[883,2],[884,1,\"\"],[885,2],[886,1,\"\"],[887,2],[[888,889],3],[890,5,\" \"],[[891,893],2],[894,5,\";\"],[895,1,\"\"],[[896,899],3],[900,5,\" \"],[901,5,\" \"],[902,1,\"\"],[903,1,\"\"],[904,1,\"\"],[905,1,\"\"],[906,1,\"\"],[907,3],[908,1,\"\"],[909,3],[910,1,\"\"],[911,1,\"\"],[912,2],[913,1,\"\"],[914,1,\"\"],[915,1,\"\"],[916,1,\"\"],[917,1,\"\"],[918,1,\"\"],[919,1,\"\"],[920,1,\"\"],[921,1,\"\"],[922,1,\"\"],[923,1,\"\"],[924,1,\"\"],[925,1,\"\"],[926,1,\"\"],[927,1,\"\"],[928,1,\"\"],[929,1,\"\"],[930,3],[931,1,\"\"],[932,1,\"\"],[933,1,\"\"],[934,1,\"\"],[935,1,\"\"],[936,1,\"\"],[937,1,\"\"],[938,1,\"\"],[939,1,\"\"],[[940,961],2],[962,6,\"\"],[[963,974],2],[975,1,\"\"],[976,1,\"\"],[977,1,\"\"],[978,1,\"\"],[979,1,\"\"],[980,1,\"\"],[981,1,\"\"],[982,1,\"\"],[983,2],[984,1,\"\"],[985,2],[986,1,\"\"],[987,2],[988,1,\"\"],[989,2],[990,1,\"\"],[991,2],[992,1,\"\"],[993,2],[994,1,\"\"],[995,2],[996,1,\"\"],[997,2],[998,1,\"\"],[999,2],[1000,1,\"\"],[1001,2],[1002,1,\"\"],[1003,2],[1004,1,\"\"],[1005,2],[1006,1,\"\"],[1007,2],[1008,1,\"\"],[1009,1,\"\"],[1010,1,\"\"],[1011,2],[1012,1,\"\"],[1013,1,\"\"],[1014,2],[1015,1,\"\"],[1016,2],[1017,1,\"\"],[1018,1,\"\"],[1019,2],[1020,2],[1021,1,\"\"],[1022,1,\"\"],[1023,1,\"\"],[1024,1,\"\"],[1025,1,\"\"],[1026,1,\"\"],[1027,1,\"\"],[1028,1,\"\"],[1029,1,\"\"],[1030,1,\"\"],[1031,1,\"\"],[1032,1,\"\"],[1033,1,\"\"],[1034,1,\"\"],[1035,1,\"\"],[1036,1,\"\"],[1037,1,\"\"],[1038,1,\"\"],[1039,1,\"\"],[1040,1,\"\"],[1041,1,\"\"],[1042,1,\"\"],[1043,1,\"\"],[1044,1,\"\"],[1045,1,\"\"],[1046,1,\"\"],[1047,1,\"\"],[1048,1,\"\"],[1049,1,\"\"],[1050,1,\"\"],[1051,1,\"\"],[1052,1,\"\"],[1053,1,\"\"],[1054,1,\"\"],[1055,1,\"\"],[1056,1,\"\"],[1057,1,\"\"],[1058,1,\"\"],[1059,1,\"\"],[1060,1,\"\"],[1061,1,\"\"],[1062,1,\"\"],[1063,1,\"\"],[1064,1,\"\"],[1065,1,\"\"],[1066,1,\"\"],[1067,1,\"\"],[1068,1,\"\"],[1069,1,\"\"],[1070,1,\"\"],[1071,1,\"\"],[[1072,1103],2],[1104,2],[[1105,1116],2],[1117,2],[[1118,1119],2],[1120,1,\"\"],[1121,2],[1122,1,\"\"],[1123,2],[1124,1,\"\"],[1125,2],[1126,1,\"\"],[1127,2],[1128,1,\"\"],[1129,2],[1130,1,\"\"],[1131,2],[1132,1,\"\"],[1133,2],[1134,1,\"\"],[1135,2],[1136,1,\"\"],[1137,2],[1138,1,\"\"],[1139,2],[1140,1,\"\"],[1141,2],[1142,1,\"\"],[1143,2],[1144,1,\"\"],[1145,2],[1146,1,\"\"],[1147,2],[1148,1,\"\"],[1149,2],[1150,1,\"\"],[1151,2],[1152,1,\"\"],[1153,2],[1154,2],[[1155,1158],2],[1159,2],[[1160,1161],2],[1162,1,\"\"],[1163,2],[1164,1,\"\"],[1165,2],[1166,1,\"\"],[1167,2],[1168,1,\"\"],[1169,2],[1170,1,\"\"],[1171,2],[1172,1,\"\"],[1173,2],[1174,1,\"\"],[1175,2],[1176,1,\"\"],[1177,2],[1178,1,\"\"],[1179,2],[1180,1,\"\"],[1181,2],[1182,1,\"\"],[1183,2],[1184,1,\"\"],[1185,2],[1186,1,\"\"],[1187,2],[1188,1,\"\"],[1189,2],[1190,1,\"\"],[1191,2],[1192,1,\"\"],[1193,2],[1194,1,\"\"],[1195,2],[1196,1,\"\"],[1197,2],[1198,1,\"\"],[1199,2],[1200,1,\"\"],[1201,2],[1202,1,\"\"],[1203,2],[1204,1,\"\"],[1205,2],[1206,1,\"\"],[1207,2],[1208,1,\"\"],[1209,2],[1210,1,\"\"],[1211,2],[1212,1,\"\"],[1213,2],[1214,1,\"\"],[1215,2],[1216,3],[1217,1,\"\"],[1218,2],[1219,1,\"\"],[1220,2],[1221,1,\"\"],[1222,2],[1223,1,\"\"],[1224,2],[1225,1,\"\"],[1226,2],[1227,1,\"\"],[1228,2],[1229,1,\"\"],[1230,2],[1231,2],[1232,1,\"\"],[1233,2],[1234,1,\"\"],[1235,2],[1236,1,\"\"],[1237,2],[1238,1,\"\"],[1239,2],[1240,1,\"\"],[1241,2],[1242,1,\"\"],[1243,2],[1244,1,\"\"],[1245,2],[1246,1,\"\"],[1247,2],[1248,1,\"\"],[1249,2],[1250,1,\"\"],[1251,2],[1252,1,\"\"],[1253,2],[1254,1,\"\"],[1255,2],[1256,1,\"\"],[1257,2],[1258,1,\"\"],[1259,2],[1260,1,\"\"],[1261,2],[1262,1,\"\"],[1263,2],[1264,1,\"\"],[1265,2],[1266,1,\"\"],[1267,2],[1268,1,\"\"],[1269,2],[1270,1,\"\"],[1271,2],[1272,1,\"\"],[1273,2],[1274,1,\"\"],[1275,2],[1276,1,\"\"],[1277,2],[1278,1,\"\"],[1279,2],[1280,1,\"\"],[1281,2],[1282,1,\"\"],[1283,2],[1284,1,\"\"],[1285,2],[1286,1,\"\"],[1287,2],[1288,1,\"\"],[1289,2],[1290,1,\"\"],[1291,2],[1292,1,\"\"],[1293,2],[1294,1,\"\"],[1295,2],[1296,1,\"\"],[1297,2],[1298,1,\"\"],[1299,2],[1300,1,\"\"],[1301,2],[1302,1,\"\"],[1303,2],[1304,1,\"\"],[1305,2],[1306,1,\"\"],[1307,2],[1308,1,\"\"],[1309,2],[1310,1,\"\"],[1311,2],[1312,1,\"\"],[1313,2],[1314,1,\"\"],[1315,2],[1316,1,\"\"],[1317,2],[1318,1,\"\"],[1319,2],[1320,1,\"\"],[1321,2],[1322,1,\"\"],[1323,2],[1324,1,\"\"],[1325,2],[1326,1,\"\"],[1327,2],[1328,3],[1329,1,\"\"],[1330,1,\"\"],[1331,1,\"\"],[1332,1,\"\"],[1333,1,\"\"],[1334,1,\"\"],[1335,1,\"\"],[1336,1,\"\"],[1337,1,\"\"],[1338,1,\"\"],[1339,1,\"\"],[1340,1,\"\"],[1341,1,\"\"],[1342,1,\"\"],[1343,1,\"\"],[1344,1,\"\"],[1345,1,\"\"],[1346,1,\"\"],[1347,1,\"\"],[1348,1,\"\"],[1349,1,\"\"],[1350,1,\"\"],[1351,1,\"\"],[1352,1,\"\"],[1353,1,\"\"],[1354,1,\"\"],[1355,1,\"\"],[1356,1,\"\"],[1357,1,\"\"],[1358,1,\"\"],[1359,1,\"\"],[1360,1,\"\"],[1361,1,\"\"],[1362,1,\"\"],[1363,1,\"\"],[1364,1,\"\"],[1365,1,\"\"],[1366,1,\"\"],[[1367,1368],3],[1369,2],[[1370,1375],2],[1376,2],[[1377,1414],2],[1415,1,\"\"],[1416,2],[1417,2],[1418,2],[[1419,1420],3],[[1421,1422],2],[1423,2],[1424,3],[[1425,1441],2],[1442,2],[[1443,1455],2],[[1456,1465],2],[1466,2],[[1467,1469],2],[1470,2],[1471,2],[1472,2],[[1473,1474],2],[1475,2],[1476,2],[1477,2],[1478,2],[1479,2],[[1480,1487],3],[[1488,1514],2],[[1515,1518],3],[1519,2],[[1520,1524],2],[[1525,1535],3],[[1536,1539],3],[1540,3],[1541,3],[[1542,1546],2],[1547,2],[1548,2],[[1549,1551],2],[[1552,1557],2],[[1558,1562],2],[1563,2],[1564,3],[1565,2],[1566,2],[1567,2],[1568,2],[[1569,1594],2],[[1595,1599],2],[1600,2],[[1601,1618],2],[[1619,1621],2],[[1622,1624],2],[[1625,1630],2],[1631,2],[[1632,1641],2],[[1642,1645],2],[[1646,1647],2],[[1648,1652],2],[1653,1,\"\"],[1654,1,\"\"],[1655,1,\"\"],[1656,1,\"\"],[[1657,1719],2],[[1720,1721],2],[[1722,1726],2],[1727,2],[[1728,1742],2],[1743,2],[[1744,1747],2],[1748,2],[[1749,1756],2],[1757,3],[1758,2],[[1759,1768],2],[1769,2],[[1770,1773],2],[[1774,1775],2],[[1776,1785],2],[[1786,1790],2],[1791,2],[[1792,1805],2],[1806,3],[1807,3],[[1808,1836],2],[[1837,1839],2],[[1840,1866],2],[[1867,1868],3],[[1869,1871],2],[[1872,1901],2],[[1902,1919],2],[[1920,1968],2],[1969,2],[[1970,1983],3],[[1984,2037],2],[[2038,2042],2],[[2043,2044],3],[2045,2],[[2046,2047],2],[[2048,2093],2],[[2094,2095],3],[[2096,2110],2],[2111,3],[[2112,2139],2],[[2140,2141],3],[2142,2],[2143,3],[[2144,2154],2],[[2155,2159],3],[[2160,2183],2],[2184,2],[[2185,2190],2],[2191,3],[[2192,2193],3],[[2194,2199],3],[[2200,2207],2],[2208,2],[2209,2],[[2210,2220],2],[[2221,2226],2],[[2227,2228],2],[2229,2],[[2230,2237],2],[[2238,2247],2],[[2248,2258],2],[2259,2],[[2260,2273],2],[2274,3],[2275,2],[[2276,2302],2],[2303,2],[2304,2],[[2305,2307],2],[2308,2],[[2309,2361],2],[[2362,2363],2],[[2364,2381],2],[2382,2],[2383,2],[[2384,2388],2],[2389,2],[[2390,2391],2],[2392,1,\"\"],[2393,1,\"\"],[2394,1,\"\"],[2395,1,\"\"],[2396,1,\"\"],[2397,1,\"\"],[2398,1,\"\"],[2399,1,\"\"],[[2400,2403],2],[[2404,2405],2],[[2406,2415],2],[2416,2],[[2417,2418],2],[[2419,2423],2],[2424,2],[[2425,2426],2],[[2427,2428],2],[2429,2],[[2430,2431],2],[2432,2],[[2433,2435],2],[2436,3],[[2437,2444],2],[[2445,2446],3],[[2447,2448],2],[[2449,2450],3],[[2451,2472],2],[2473,3],[[2474,2480],2],[2481,3],[2482,2],[[2483,2485],3],[[2486,2489],2],[[2490,2491],3],[2492,2],[2493,2],[[2494,2500],2],[[2501,2502],3],[[2503,2504],2],[[2505,2506],3],[[2507,2509],2],[2510,2],[[2511,2518],3],[2519,2],[[2520,2523],3],[2524,1,\"\"],[2525,1,\"\"],[2526,3],[2527,1,\"\"],[[2528,2531],2],[[2532,2533],3],[[2534,2545],2],[[2546,2554],2],[2555,2],[2556,2],[2557,2],[2558,2],[[2559,2560],3],[2561,2],[2562,2],[2563,2],[2564,3],[[2565,2570],2],[[2571,2574],3],[[2575,2576],2],[[2577,2578],3],[[2579,2600],2],[2601,3],[[2602,2608],2],[2609,3],[2610,2],[2611,1,\"\"],[2612,3],[2613,2],[2614,1,\"\"],[2615,3],[[2616,2617],2],[[2618,2619],3],[2620,2],[2621,3],[[2622,2626],2],[[2627,2630],3],[[2631,2632],2],[[2633,2634],3],[[2635,2637],2],[[2638,2640],3],[2641,2],[[2642,2648],3],[2649,1,\"\"],[2650,1,\"\"],[2651,1,\"\"],[2652,2],[2653,3],[2654,1,\"\"],[[2655,2661],3],[[2662,2676],2],[2677,2],[2678,2],[[2679,2688],3],[[2689,2691],2],[2692,3],[[2693,2699],2],[2700,2],[2701,2],[2702,3],[[2703,2705],2],[2706,3],[[2707,2728],2],[2729,3],[[2730,2736],2],[2737,3],[[2738,2739],2],[2740,3],[[2741,2745],2],[[2746,2747],3],[[2748,2757],2],[2758,3],[[2759,2761],2],[2762,3],[[2763,2765],2],[[2766,2767],3],[2768,2],[[2769,2783],3],[2784,2],[[2785,2787],2],[[2788,2789],3],[[2790,2799],2],[2800,2],[2801,2],[[2802,2808],3],[2809,2],[[2810,2815],2],[2816,3],[[2817,2819],2],[2820,3],[[2821,2828],2],[[2829,2830],3],[[2831,2832],2],[[2833,2834],3],[[2835,2856],2],[2857,3],[[2858,2864],2],[2865,3],[[2866,2867],2],[2868,3],[2869,2],[[2870,2873],2],[[2874,2875],3],[[2876,2883],2],[2884,2],[[2885,2886],3],[[2887,2888],2],[[2889,2890],3],[[2891,2893],2],[[2894,2900],3],[2901,2],[[2902,2903],2],[[2904,2907],3],[2908,1,\"\"],[2909,1,\"\"],[2910,3],[[2911,2913],2],[[2914,2915],2],[[2916,2917],3],[[2918,2927],2],[2928,2],[2929,2],[[2930,2935],2],[[2936,2945],3],[[2946,2947],2],[2948,3],[[2949,2954],2],[[2955,2957],3],[[2958,2960],2],[2961,3],[[2962,2965],2],[[2966,2968],3],[[2969,2970],2],[2971,3],[2972,2],[2973,3],[[2974,2975],2],[[2976,2978],3],[[2979,2980],2],[[2981,2983],3],[[2984,2986],2],[[2987,2989],3],[[2990,2997],2],[2998,2],[[2999,3001],2],[[3002,3005],3],[[3006,3010],2],[[3011,3013],3],[[3014,3016],2],[3017,3],[[3018,3021],2],[[3022,3023],3],[3024,2],[[3025,3030],3],[3031,2],[[3032,3045],3],[3046,2],[[3047,3055],2],[[3056,3058],2],[[3059,3066],2],[[3067,3071],3],[3072,2],[[3073,3075],2],[3076,2],[[3077,3084],2],[3085,3],[[3086,3088],2],[3089,3],[[3090,3112],2],[3113,3],[[3114,3123],2],[3124,2],[[3125,3129],2],[[3130,3131],3],[3132,2],[3133,2],[[3134,3140],2],[3141,3],[[3142,3144],2],[3145,3],[[3146,3149],2],[[3150,3156],3],[[3157,3158],2],[3159,3],[[3160,3161],2],[3162,2],[[3163,3164],3],[3165,2],[[3166,3167],3],[[3168,3169],2],[[3170,3171],2],[[3172,3173],3],[[3174,3183],2],[[3184,3190],3],[3191,2],[[3192,3199],2],[3200,2],[3201,2],[[3202,3203],2],[3204,2],[[3205,3212],2],[3213,3],[[3214,3216],2],[3217,3],[[3218,3240],2],[3241,3],[[3242,3251],2],[3252,3],[[3253,3257],2],[[3258,3259],3],[[3260,3261],2],[[3262,3268],2],[3269,3],[[3270,3272],2],[3273,3],[[3274,3277],2],[[3278,3284],3],[[3285,3286],2],[[3287,3292],3],[3293,2],[3294,2],[3295,3],[[3296,3297],2],[[3298,3299],2],[[3300,3301],3],[[3302,3311],2],[3312,3],[[3313,3314],2],[3315,2],[[3316,3327],3],[3328,2],[3329,2],[[3330,3331],2],[3332,2],[[3333,3340],2],[3341,3],[[3342,3344],2],[3345,3],[[3346,3368],2],[3369,2],[[3370,3385],2],[3386,2],[[3387,3388],2],[3389,2],[[3390,3395],2],[3396,2],[3397,3],[[3398,3400],2],[3401,3],[[3402,3405],2],[3406,2],[3407,2],[[3408,3411],3],[[3412,3414],2],[3415,2],[[3416,3422],2],[3423,2],[[3424,3425],2],[[3426,3427],2],[[3428,3429],3],[[3430,3439],2],[[3440,3445],2],[[3446,3448],2],[3449,2],[[3450,3455],2],[3456,3],[3457,2],[[3458,3459],2],[3460,3],[[3461,3478],2],[[3479,3481],3],[[3482,3505],2],[3506,3],[[3507,3515],2],[3516,3],[3517,2],[[3518,3519],3],[[3520,3526],2],[[3527,3529],3],[3530,2],[[3531,3534],3],[[3535,3540],2],[3541,3],[3542,2],[3543,3],[[3544,3551],2],[[3552,3557],3],[[3558,3567],2],[[3568,3569],3],[[3570,3571],2],[3572,2],[[3573,3584],3],[[3585,3634],2],[3635,1,\"\"],[[3636,3642],2],[[3643,3646],3],[3647,2],[[3648,3662],2],[3663,2],[[3664,3673],2],[[3674,3675],2],[[3676,3712],3],[[3713,3714],2],[3715,3],[3716,2],[3717,3],[3718,2],[[3719,3720],2],[3721,2],[3722,2],[3723,3],[3724,2],[3725,2],[[3726,3731],2],[[3732,3735],2],[3736,2],[[3737,3743],2],[3744,2],[[3745,3747],2],[3748,3],[3749,2],[3750,3],[3751,2],[[3752,3753],2],[[3754,3755],2],[3756,2],[[3757,3762],2],[3763,1,\"\"],[[3764,3769],2],[3770,2],[[3771,3773],2],[[3774,3775],3],[[3776,3780],2],[3781,3],[3782,2],[3783,3],[[3784,3789],2],[3790,2],[3791,3],[[3792,3801],2],[[3802,3803],3],[3804,1,\"\"],[3805,1,\"\"],[[3806,3807],2],[[3808,3839],3],[3840,2],[[3841,3850],2],[3851,2],[3852,1,\"\"],[[3853,3863],2],[[3864,3865],2],[[3866,3871],2],[[3872,3881],2],[[3882,3892],2],[3893,2],[3894,2],[3895,2],[3896,2],[3897,2],[[3898,3901],2],[[3902,3906],2],[3907,1,\"\"],[[3908,3911],2],[3912,3],[[3913,3916],2],[3917,1,\"\"],[[3918,3921],2],[3922,1,\"\"],[[3923,3926],2],[3927,1,\"\"],[[3928,3931],2],[3932,1,\"\"],[[3933,3944],2],[3945,1,\"\"],[3946,2],[[3947,3948],2],[[3949,3952],3],[[3953,3954],2],[3955,1,\"\"],[3956,2],[3957,1,\"\"],[3958,1,\"\"],[3959,1,\"\"],[3960,1,\"\"],[3961,1,\"\"],[[3962,3968],2],[3969,1,\"\"],[[3970,3972],2],[3973,2],[[3974,3979],2],[[3980,3983],2],[[3984,3986],2],[3987,1,\"\"],[[3988,3989],2],[3990,2],[3991,2],[3992,3],[[3993,3996],2],[3997,1,\"\"],[[3998,4001],2],[4002,1,\"\"],[[4003,4006],2],[4007,1,\"\"],[[4008,4011],2],[4012,1,\"\"],[4013,2],[[4014,4016],2],[[4017,4023],2],[4024,2],[4025,1,\"\"],[[4026,4028],2],[4029,3],[[4030,4037],2],[4038,2],[[4039,4044],2],[4045,3],[4046,2],[4047,2],[[4048,4049],2],[[4050,4052],2],[[4053,4056],2],[[4057,4058],2],[[4059,4095],3],[[4096,4129],2],[4130,2],[[4131,4135],2],[4136,2],[[4137,4138],2],[4139,2],[[4140,4146],2],[[4147,4149],2],[[4150,4153],2],[[4154,4159],2],[[4160,4169],2],[[4170,4175],2],[[4176,4185],2],[[4186,4249],2],[[4250,4253],2],[[4254,4255],2],[[4256,4293],3],[4294,3],[4295,1,\"\"],[[4296,4300],3],[4301,1,\"\"],[[4302,4303],3],[[4304,4342],2],[[4343,4344],2],[[4345,4346],2],[4347,2],[4348,1,\"\"],[[4349,4351],2],[[4352,4441],2],[[4442,4446],2],[[4447,4448],3],[[4449,4514],2],[[4515,4519],2],[[4520,4601],2],[[4602,4607],2],[[4608,4614],2],[4615,2],[[4616,4678],2],[4679,2],[4680,2],[4681,3],[[4682,4685],2],[[4686,4687],3],[[4688,4694],2],[4695,3],[4696,2],[4697,3],[[4698,4701],2],[[4702,4703],3],[[4704,4742],2],[4743,2],[4744,2],[4745,3],[[4746,4749],2],[[4750,4751],3],[[4752,4782],2],[4783,2],[4784,2],[4785,3],[[4786,4789],2],[[4790,4791],3],[[4792,4798],2],[4799,3],[4800,2],[4801,3],[[4802,4805],2],[[4806,4807],3],[[4808,4814],2],[4815,2],[[4816,4822],2],[4823,3],[[4824,4846],2],[4847,2],[[4848,4878],2],[4879,2],[4880,2],[4881,3],[[4882,4885],2],[[4886,4887],3],[[4888,4894],2],[4895,2],[[4896,4934],2],[4935,2],[[4936,4954],2],[[4955,4956],3],[[4957,4958],2],[4959,2],[4960,2],[[4961,4988],2],[[4989,4991],3],[[4992,5007],2],[[5008,5017],2],[[5018,5023],3],[[5024,5108],2],[5109,2],[[5110,5111],3],[5112,1,\"\"],[5113,1,\"\"],[5114,1,\"\"],[5115,1,\"\"],[5116,1,\"\"],[5117,1,\"\"],[[5118,5119],3],[5120,2],[[5121,5740],2],[[5741,5742],2],[[5743,5750],2],[[5751,5759],2],[5760,3],[[5761,5786],2],[[5787,5788],2],[[5789,5791],3],[[5792,5866],2],[[5867,5872],2],[[5873,5880],2],[[5881,5887],3],[[5888,5900],2],[5901,2],[[5902,5908],2],[5909,2],[[5910,5918],3],[5919,2],[[5920,5940],2],[[5941,5942],2],[[5943,5951],3],[[5952,5971],2],[[5972,5983],3],[[5984,5996],2],[5997,3],[[5998,6000],2],[6001,3],[[6002,6003],2],[[6004,6015],3],[[6016,6067],2],[[6068,6069],3],[[6070,6099],2],[[6100,6102],2],[6103,2],[[6104,6107],2],[6108,2],[6109,2],[[6110,6111],3],[[6112,6121],2],[[6122,6127],3],[[6128,6137],2],[[6138,6143],3],[[6144,6149],2],[6150,3],[[6151,6154],2],[[6155,6157],7],[6158,3],[6159,7],[[6160,6169],2],[[6170,6175],3],[[6176,6263],2],[6264,2],[[6265,6271],3],[[6272,6313],2],[6314,2],[[6315,6319],3],[[6320,6389],2],[[6390,6399],3],[[6400,6428],2],[[6429,6430],2],[6431,3],[[6432,6443],2],[[6444,6447],3],[[6448,6459],2],[[6460,6463],3],[6464,2],[[6465,6467],3],[[6468,6469],2],[[6470,6509],2],[[6510,6511],3],[[6512,6516],2],[[6517,6527],3],[[6528,6569],2],[[6570,6571],2],[[6572,6575],3],[[6576,6601],2],[[6602,6607],3],[[6608,6617],2],[6618,2],[[6619,6621],3],[[6622,6623],2],[[6624,6655],2],[[6656,6683],2],[[6684,6685],3],[[6686,6687],2],[[6688,6750],2],[6751,3],[[6752,6780],2],[[6781,6782],3],[[6783,6793],2],[[6794,6799],3],[[6800,6809],2],[[6810,6815],3],[[6816,6822],2],[6823,2],[[6824,6829],2],[[6830,6831],3],[[6832,6845],2],[6846,2],[[6847,6848],2],[[6849,6862],2],[[6863,6911],3],[[6912,6987],2],[6988,2],[[6989,6991],3],[[6992,7001],2],[[7002,7018],2],[[7019,7027],2],[[7028,7036],2],[[7037,7038],2],[7039,3],[[7040,7082],2],[[7083,7085],2],[[7086,7097],2],[[7098,7103],2],[[7104,7155],2],[[7156,7163],3],[[7164,7167],2],[[7168,7223],2],[[7224,7226],3],[[7227,7231],2],[[7232,7241],2],[[7242,7244],3],[[7245,7293],2],[[7294,7295],2],[7296,1,\"\"],[7297,1,\"\"],[7298,1,\"\"],[7299,1,\"\"],[[7300,7301],1,\"\"],[7302,1,\"\"],[7303,1,\"\"],[7304,1,\"\"],[[7305,7311],3],[7312,1,\"\"],[7313,1,\"\"],[7314,1,\"\"],[7315,1,\"\"],[7316,1,\"\"],[7317,1,\"\"],[7318,1,\"\"],[7319,1,\"\"],[7320,1,\"\"],[7321,1,\"\"],[7322,1,\"\"],[7323,1,\"\"],[7324,1,\"\"],[7325,1,\"\"],[7326,1,\"\"],[7327,1,\"\"],[7328,1,\"\"],[7329,1,\"\"],[7330,1,\"\"],[7331,1,\"\"],[7332,1,\"\"],[7333,1,\"\"],[7334,1,\"\"],[7335,1,\"\"],[7336,1,\"\"],[7337,1,\"\"],[7338,1,\"\"],[7339,1,\"\"],[7340,1,\"\"],[7341,1,\"\"],[7342,1,\"\"],[7343,1,\"\"],[7344,1,\"\"],[7345,1,\"\"],[7346,1,\"\"],[7347,1,\"\"],[7348,1,\"\"],[7349,1,\"\"],[7350,1,\"\"],[7351,1,\"\"],[7352,1,\"\"],[7353,1,\"\"],[7354,1,\"\"],[[7355,7356],3],[7357,1,\"\"],[7358,1,\"\"],[7359,1,\"\"],[[7360,7367],2],[[7368,7375],3],[[7376,7378],2],[7379,2],[[7380,7410],2],[[7411,7414],2],[7415,2],[[7416,7417],2],[7418,2],[[7419,7423],3],[[7424,7467],2],[7468,1,\"a\"],[7469,1,\"\"],[7470,1,\"b\"],[7471,2],[7472,1,\"d\"],[7473,1,\"e\"],[7474,1,\"\"],[7475,1,\"g\"],[7476,1,\"h\"],[7477,1,\"i\"],[7478,1,\"j\"],[7479,1,\"k\"],[7480,1,\"l\"],[7481,1,\"m\"],[7482,1,\"n\"],[7483,2],[7484,1,\"o\"],[7485,1,\"\"],[7486,1,\"p\"],[7487,1,\"r\"],[7488,1,\"t\"],[7489,1,\"u\"],[7490,1,\"w\"],[7491,1,\"a\"],[7492,1,\"\"],[7493,1,\"\"],[7494,1,\"\"],[7495,1,\"b\"],[7496,1,\"d\"],[7497,1,\"e\"],[7498,1,\"\"],[7499,1,\"\"],[7500,1,\"\"],[7501,1,\"g\"],[7502,2],[7503,1,\"k\"],[7504,1,\"m\"],[7505,1,\"\"],[7506,1,\"o\"],[7507,1,\"\"],[7508,1,\"\"],[7509,1,\"\"],[7510,1,\"p\"],[7511,1,\"t\"],[7512,1,\"u\"],[7513,1,\"\"],[7514,1,\"\"],[7515,1,\"v\"],[7516,1,\"\"],[7517,1,\"\"],[7518,1,\"\"],[7519,1,\"\"],[7520,1,\"\"],[7521,1,\"\"],[7522,1,\"i\"],[7523,1,\"r\"],[7524,1,\"u\"],[7525,1,\"v\"],[7526,1,\"\"],[7527,1,\"\"],[7528,1,\"\"],[7529,1,\"\"],[7530,1,\"\"],[7531,2],[[7532,7543],2],[7544,1,\"\"],[[7545,7578],2],[7579,1,\"\"],[7580,1,\"c\"],[7581,1,\"\"],[7582,1,\"\"],[7583,1,\"\"],[7584,1,\"f\"],[7585,1,\"\"],[7586,1,\"\"],[7587,1,\"\"],[7588,1,\"\"],[7589,1,\"\"],[7590,1,\"\"],[7591,1,\"\"],[7592,1,\"\"],[7593,1,\"\"],[7594,1,\"\"],[7595,1,\"\"],[7596,1,\"\"],[7597,1,\"\"],[7598,1,\"\"],[7599,1,\"\"],[7600,1,\"\"],[7601,1,\"\"],[7602,1,\"\"],[7603,1,\"\"],[7604,1,\"\"],[7605,1,\"\"],[7606,1,\"\"],[7607,1,\"\"],[7608,1,\"\"],[7609,1,\"\"],[7610,1,\"\"],[7611,1,\"z\"],[7612,1,\"\"],[7613,1,\"\"],[7614,1,\"\"],[7615,1,\"\"],[[7616,7619],2],[[7620,7626],2],[[7627,7654],2],[[7655,7669],2],[[7670,7673],2],[7674,2],[7675,2],[7676,2],[7677,2],[[7678,7679],2],[7680,1,\"\"],[7681,2],[7682,1,\"\"],[7683,2],[7684,1,\"\"],[7685,2],[7686,1,\"\"],[7687,2],[7688,1,\"\"],[7689,2],[7690,1,\"\"],[7691,2],[7692,1,\"\"],[7693,2],[7694,1,\"\"],[7695,2],[7696,1,\"\"],[7697,2],[7698,1,\"\"],[7699,2],[7700,1,\"\"],[7701,2],[7702,1,\"\"],[7703,2],[7704,1,\"\"],[7705,2],[7706,1,\"\"],[7707,2],[7708,1,\"\"],[7709,2],[7710,1,\"\"],[7711,2],[7712,1,\"\"],[7713,2],[7714,1,\"\"],[7715,2],[7716,1,\"\"],[7717,2],[7718,1,\"\"],[7719,2],[7720,1,\"\"],[7721,2],[7722,1,\"\"],[7723,2],[7724,1,\"\"],[7725,2],[7726,1,\"\"],[7727,2],[7728,1,\"\"],[7729,2],[7730,1,\"\"],[7731,2],[7732,1,\"\"],[7733,2],[7734,1,\"\"],[7735,2],[7736,1,\"\"],[7737,2],[7738,1,\"\"],[7739,2],[7740,1,\"\"],[7741,2],[7742,1,\"\"],[7743,2],[7744,1,\"\"],[7745,2],[7746,1,\"\"],[7747,2],[7748,1,\"\"],[7749,2],[7750,1,\"\"],[7751,2],[7752,1,\"\"],[7753,2],[7754,1,\"\"],[7755,2],[7756,1,\"\"],[7757,2],[7758,1,\"\"],[7759,2],[7760,1,\"\"],[7761,2],[7762,1,\"\"],[7763,2],[7764,1,\"\"],[7765,2],[7766,1,\"\"],[7767,2],[7768,1,\"\"],[7769,2],[7770,1,\"\"],[7771,2],[7772,1,\"\"],[7773,2],[7774,1,\"\"],[7775,2],[7776,1,\"\"],[7777,2],[7778,1,\"\"],[7779,2],[7780,1,\"\"],[7781,2],[7782,1,\"\"],[7783,2],[7784,1,\"\"],[7785,2],[7786,1,\"\"],[7787,2],[7788,1,\"\"],[7789,2],[7790,1,\"\"],[7791,2],[7792,1,\"\"],[7793,2],[7794,1,\"\"],[7795,2],[7796,1,\"\"],[7797,2],[7798,1,\"\"],[7799,2],[7800,1,\"\"],[7801,2],[7802,1,\"\"],[7803,2],[7804,1,\"\"],[7805,2],[7806,1,\"\"],[7807,2],[7808,1,\"\"],[7809,2],[7810,1,\"\"],[7811,2],[7812,1,\"\"],[7813,2],[7814,1,\"\"],[7815,2],[7816,1,\"\"],[7817,2],[7818,1,\"\"],[7819,2],[7820,1,\"\"],[7821,2],[7822,1,\"\"],[7823,2],[7824,1,\"\"],[7825,2],[7826,1,\"\"],[7827,2],[7828,1,\"\"],[[7829,7833],2],[7834,1,\"a\"],[7835,1,\"\"],[[7836,7837],2],[7838,1,\"ss\"],[7839,2],[7840,1,\"\"],[7841,2],[7842,1,\"\"],[7843,2],[7844,1,\"\"],[7845,2],[7846,1,\"\"],[7847,2],[7848,1,\"\"],[7849,2],[7850,1,\"\"],[7851,2],[7852,1,\"\"],[7853,2],[7854,1,\"\"],[7855,2],[7856,1,\"\"],[7857,2],[7858,1,\"\"],[7859,2],[7860,1,\"\"],[7861,2],[7862,1,\"\"],[7863,2],[7864,1,\"\"],[7865,2],[7866,1,\"\"],[7867,2],[7868,1,\"\"],[7869,2],[7870,1,\"\"],[7871,2],[7872,1,\"\"],[7873,2],[7874,1,\"\"],[7875,2],[7876,1,\"\"],[7877,2],[7878,1,\"\"],[7879,2],[7880,1,\"\"],[7881,2],[7882,1,\"\"],[7883,2],[7884,1,\"\"],[7885,2],[7886,1,\"\"],[7887,2],[7888,1,\"\"],[7889,2],[7890,1,\"\"],[7891,2],[7892,1,\"\"],[7893,2],[7894,1,\"\"],[7895,2],[7896,1,\"\"],[7897,2],[7898,1,\"\"],[7899,2],[7900,1,\"\"],[7901,2],[7902,1,\"\"],[7903,2],[7904,1,\"\"],[7905,2],[7906,1,\"\"],[7907,2],[7908,1,\"\"],[7909,2],[7910,1,\"\"],[7911,2],[7912,1,\"\"],[7913,2],[7914,1,\"\"],[7915,2],[7916,1,\"\"],[7917,2],[7918,1,\"\"],[7919,2],[7920,1,\"\"],[7921,2],[7922,1,\"\"],[7923,2],[7924,1,\"\"],[7925,2],[7926,1,\"\"],[7927,2],[7928,1,\"\"],[7929,2],[7930,1,\"\"],[7931,2],[7932,1,\"\"],[7933,2],[7934,1,\"\"],[7935,2],[[7936,7943],2],[7944,1,\"\"],[7945,1,\"\"],[7946,1,\"\"],[7947,1,\"\"],[7948,1,\"\"],[7949,1,\"\"],[7950,1,\"\"],[7951,1,\"\"],[[7952,7957],2],[[7958,7959],3],[7960,1,\"\"],[7961,1,\"\"],[7962,1,\"\"],[7963,1,\"\"],[7964,1,\"\"],[7965,1,\"\"],[[7966,7967],3],[[7968,7975],2],[7976,1,\"\"],[7977,1,\"\"],[7978,1,\"\"],[7979,1,\"\"],[7980,1,\"\"],[7981,1,\"\"],[7982,1,\"\"],[7983,1,\"\"],[[7984,7991],2],[7992,1,\"\"],[7993,1,\"\"],[7994,1,\"\"],[7995,1,\"\"],[7996,1,\"\"],[7997,1,\"\"],[7998,1,\"\"],[7999,1,\"\"],[[8000,8005],2],[[8006,8007],3],[8008,1,\"\"],[8009,1,\"\"],[8010,1,\"\"],[8011,1,\"\"],[8012,1,\"\"],[8013,1,\"\"],[[8014,8015],3],[[8016,8023],2],[8024,3],[8025,1,\"\"],[8026,3],[8027,1,\"\"],[8028,3],[8029,1,\"\"],[8030,3],[8031,1,\"\"],[[8032,8039],2],[8040,1,\"\"],[8041,1,\"\"],[8042,1,\"\"],[8043,1,\"\"],[8044,1,\"\"],[8045,1,\"\"],[8046,1,\"\"],[8047,1,\"\"],[8048,2],[8049,1,\"\"],[8050,2],[8051,1,\"\"],[8052,2],[8053,1,\"\"],[8054,2],[8055,1,\"\"],[8056,2],[8057,1,\"\"],[8058,2],[8059,1,\"\"],[8060,2],[8061,1,\"\"],[[8062,8063],3],[8064,1,\"\"],[8065,1,\"\"],[8066,1,\"\"],[8067,1,\"\"],[8068,1,\"\"],[8069,1,\"\"],[8070,1,\"\"],[8071,1,\"\"],[8072,1,\"\"],[8073,1,\"\"],[8074,1,\"\"],[8075,1,\"\"],[8076,1,\"\"],[8077,1,\"\"],[8078,1,\"\"],[8079,1,\"\"],[8080,1,\"\"],[8081,1,\"\"],[8082,1,\"\"],[8083,1,\"\"],[8084,1,\"\"],[8085,1,\"\"],[8086,1,\"\"],[8087,1,\"\"],[8088,1,\"\"],[8089,1,\"\"],[8090,1,\"\"],[8091,1,\"\"],[8092,1,\"\"],[8093,1,\"\"],[8094,1,\"\"],[8095,1,\"\"],[8096,1,\"\"],[8097,1,\"\"],[8098,1,\"\"],[8099,1,\"\"],[8100,1,\"\"],[8101,1,\"\"],[8102,1,\"\"],[8103,1,\"\"],[8104,1,\"\"],[8105,1,\"\"],[8106,1,\"\"],[8107,1,\"\"],[8108,1,\"\"],[8109,1,\"\"],[8110,1,\"\"],[8111,1,\"\"],[[8112,8113],2],[8114,1,\"\"],[8115,1,\"\"],[8116,1,\"\"],[8117,3],[8118,2],[8119,1,\"\"],[8120,1,\"\"],[8121,1,\"\"],[8122,1,\"\"],[8123,1,\"\"],[8124,1,\"\"],[8125,5,\" \"],[8126,1,\"\"],[8127,5,\" \"],[8128,5,\" \"],[8129,5,\" \"],[8130,1,\"\"],[8131,1,\"\"],[8132,1,\"\"],[8133,3],[8134,2],[8135,1,\"\"],[8136,1,\"\"],[8137,1,\"\"],[8138,1,\"\"],[8139,1,\"\"],[8140,1,\"\"],[8141,5,\" \"],[8142,5,\" \"],[8143,5,\" \"],[[8144,8146],2],[8147,1,\"\"],[[8148,8149],3],[[8150,8151],2],[8152,1,\"\"],[8153,1,\"\"],[8154,1,\"\"],[8155,1,\"\"],[8156,3],[8157,5,\" \"],[8158,5,\" \"],[8159,5,\" \"],[[8160,8162],2],[8163,1,\"\"],[[8164,8167],2],[8168,1,\"\"],[8169,1,\"\"],[8170,1,\"\"],[8171,1,\"\"],[8172,1,\"\"],[8173,5,\" \"],[8174,5,\" \"],[8175,5,\"`\"],[[8176,8177],3],[8178,1,\"\"],[8179,1,\"\"],[8180,1,\"\"],[8181,3],[8182,2],[8183,1,\"\"],[8184,1,\"\"],[8185,1,\"\"],[8186,1,\"\"],[8187,1,\"\"],[8188,1,\"\"],[8189,5,\" \"],[8190,5,\" \"],[8191,3],[[8192,8202],5,\" \"],[8203,7],[[8204,8205],6,\"\"],[[8206,8207],3],[8208,2],[8209,1,\"\"],[[8210,8214],2],[8215,5,\" \"],[[8216,8227],2],[[8228,8230],3],[8231,2],[[8232,8238],3],[8239,5,\" \"],[[8240,8242],2],[8243,1,\"\"],[8244,1,\"\"],[8245,2],[8246,1,\"\"],[8247,1,\"\"],[[8248,8251],2],[8252,5,\"!!\"],[8253,2],[8254,5,\" \"],[[8255,8262],2],[8263,5,\"??\"],[8264,5,\"?!\"],[8265,5,\"!?\"],[[8266,8269],2],[[8270,8274],2],[[8275,8276],2],[[8277,8278],2],[8279,1,\"\"],[[8280,8286],2],[8287,5,\" \"],[8288,7],[[8289,8291],3],[8292,7],[8293,3],[[8294,8297],3],[[8298,8303],3],[8304,1,\"0\"],[8305,1,\"i\"],[[8306,8307],3],[8308,1,\"4\"],[8309,1,\"5\"],[8310,1,\"6\"],[8311,1,\"7\"],[8312,1,\"8\"],[8313,1,\"9\"],[8314,5,\"+\"],[8315,1,\"\"],[8316,5,\"=\"],[8317,5,\"(\"],[8318,5,\")\"],[8319,1,\"n\"],[8320,1,\"0\"],[8321,1,\"1\"],[8322,1,\"2\"],[8323,1,\"3\"],[8324,1,\"4\"],[8325,1,\"5\"],[8326,1,\"6\"],[8327,1,\"7\"],[8328,1,\"8\"],[8329,1,\"9\"],[8330,5,\"+\"],[8331,1,\"\"],[8332,5,\"=\"],[8333,5,\"(\"],[8334,5,\")\"],[8335,3],[8336,1,\"a\"],[8337,1,\"e\"],[8338,1,\"o\"],[8339,1,\"x\"],[8340,1,\"\"],[8341,1,\"h\"],[8342,1,\"k\"],[8343,1,\"l\"],[8344,1,\"m\"],[8345,1,\"n\"],[8346,1,\"p\"],[8347,1,\"s\"],[8348,1,\"t\"],[[8349,8351],3],[[8352,8359],2],[8360,1,\"rs\"],[[8361,8362],2],[8363,2],[8364,2],[[8365,8367],2],[[8368,8369],2],[[8370,8373],2],[[8374,8376],2],[8377,2],[8378,2],[[8379,8381],2],[8382,2],[8383,2],[8384,2],[[8385,8399],3],[[8400,8417],2],[[8418,8419],2],[[8420,8426],2],[8427,2],[[8428,8431],2],[8432,2],[[8433,8447],3],[8448,5,\"a/c\"],[8449,5,\"a/s\"],[8450,1,\"c\"],[8451,1,\"c\"],[8452,2],[8453,5,\"c/o\"],[8454,5,\"c/u\"],[8455,1,\"\"],[8456,2],[8457,1,\"f\"],[8458,1,\"g\"],[[8459,8462],1,\"h\"],[8463,1,\"\"],[[8464,8465],1,\"i\"],[[8466,8467],1,\"l\"],[8468,2],[8469,1,\"n\"],[8470,1,\"no\"],[[8471,8472],2],[8473,1,\"p\"],[8474,1,\"q\"],[[8475,8477],1,\"r\"],[[8478,8479],2],[8480,1,\"sm\"],[8481,1,\"tel\"],[8482,1,\"tm\"],[8483,2],[8484,1,\"z\"],[8485,2],[8486,1,\"\"],[8487,2],[8488,1,\"z\"],[8489,2],[8490,1,\"k\"],[8491,1,\"\"],[8492,1,\"b\"],[8493,1,\"c\"],[8494,2],[[8495,8496],1,\"e\"],[8497,1,\"f\"],[8498,3],[8499,1,\"m\"],[8500,1,\"o\"],[8501,1,\"\"],[8502,1,\"\"],[8503,1,\"\"],[8504,1,\"\"],[8505,1,\"i\"],[8506,2],[8507,1,\"fax\"],[8508,1,\"\"],[[8509,8510],1,\"\"],[8511,1,\"\"],[8512,1,\"\"],[[8513,8516],2],[[8517,8518],1,\"d\"],[8519,1,\"e\"],[8520,1,\"i\"],[8521,1,\"j\"],[[8522,8523],2],[8524,2],[8525,2],[8526,2],[8527,2],[8528,1,\"17\"],[8529,1,\"19\"],[8530,1,\"110\"],[8531,1,\"13\"],[8532,1,\"23\"],[8533,1,\"15\"],[8534,1,\"25\"],[8535,1,\"35\"],[8536,1,\"45\"],[8537,1,\"16\"],[8538,1,\"56\"],[8539,1,\"18\"],[8540,1,\"38\"],[8541,1,\"58\"],[8542,1,\"78\"],[8543,1,\"1\"],[8544,1,\"i\"],[8545,1,\"ii\"],[8546,1,\"iii\"],[8547,1,\"iv\"],[8548,1,\"v\"],[8549,1,\"vi\"],[8550,1,\"vii\"],[8551,1,\"viii\"],[8552,1,\"ix\"],[8553,1,\"x\"],[8554,1,\"xi\"],[8555,1,\"xii\"],[8556,1,\"l\"],[8557,1,\"c\"],[8558,1,\"d\"],[8559,1,\"m\"],[8560,1,\"i\"],[8561,1,\"ii\"],[8562,1,\"iii\"],[8563,1,\"iv\"],[8564,1,\"v\"],[8565,1,\"vi\"],[8566,1,\"vii\"],[8567,1,\"viii\"],[8568,1,\"ix\"],[8569,1,\"x\"],[8570,1,\"xi\"],[8571,1,\"xii\"],[8572,1,\"l\"],[8573,1,\"c\"],[8574,1,\"d\"],[8575,1,\"m\"],[[8576,8578],2],[8579,3],[8580,2],[[8581,8584],2],[8585,1,\"03\"],[[8586,8587],2],[[8588,8591],3],[[8592,8682],2],[[8683,8691],2],[[8692,8703],2],[[8704,8747],2],[8748,1,\"\"],[8749,1,\"\"],[8750,2],[8751,1,\"\"],[8752,1,\"\"],[[8753,8799],2],[8800,4],[[8801,8813],2],[[8814,8815],4],[[8816,8945],2],[[8946,8959],2],[8960,2],[8961,2],[[8962,9000],2],[9001,1,\"\"],[9002,1,\"\"],[[9003,9082],2],[9083,2],[9084,2],[[9085,9114],2],[[9115,9166],2],[[9167,9168],2],[[9169,9179],2],[[9180,9191],2],[9192,2],[[9193,9203],2],[[9204,9210],2],[[9211,9214],2],[9215,2],[[9216,9252],2],[[9253,9254],2],[[9255,9279],3],[[9280,9290],2],[[9291,9311],3],[9312,1,\"1\"],[9313,1,\"2\"],[9314,1,\"3\"],[9315,1,\"4\"],[9316,1,\"5\"],[9317,1,\"6\"],[9318,1,\"7\"],[9319,1,\"8\"],[9320,1,\"9\"],[9321,1,\"10\"],[9322,1,\"11\"],[9323,1,\"12\"],[9324,1,\"13\"],[9325,1,\"14\"],[9326,1,\"15\"],[9327,1,\"16\"],[9328,1,\"17\"],[9329,1,\"18\"],[9330,1,\"19\"],[9331,1,\"20\"],[9332,5,\"(1)\"],[9333,5,\"(2)\"],[9334,5,\"(3)\"],[9335,5,\"(4)\"],[9336,5,\"(5)\"],[9337,5,\"(6)\"],[9338,5,\"(7)\"],[9339,5,\"(8)\"],[9340,5,\"(9)\"],[9341,5,\"(10)\"],[9342,5,\"(11)\"],[9343,5,\"(12)\"],[9344,5,\"(13)\"],[9345,5,\"(14)\"],[9346,5,\"(15)\"],[9347,5,\"(16)\"],[9348,5,\"(17)\"],[9349,5,\"(18)\"],[9350,5,\"(19)\"],[9351,5,\"(20)\"],[[9352,9371],3],[9372,5,\"(a)\"],[9373,5,\"(b)\"],[9374,5,\"(c)\"],[9375,5,\"(d)\"],[9376,5,\"(e)\"],[9377,5,\"(f)\"],[9378,5,\"(g)\"],[9379,5,\"(h)\"],[9380,5,\"(i)\"],[9381,5,\"(j)\"],[9382,5,\"(k)\"],[9383,5,\"(l)\"],[9384,5,\"(m)\"],[9385,5,\"(n)\"],[9386,5,\"(o)\"],[9387,5,\"(p)\"],[9388,5,\"(q)\"],[9389,5,\"(r)\"],[9390,5,\"(s)\"],[9391,5,\"(t)\"],[9392,5,\"(u)\"],[9393,5,\"(v)\"],[9394,5,\"(w)\"],[9395,5,\"(x)\"],[9396,5,\"(y)\"],[9397,5,\"(z)\"],[9398,1,\"a\"],[9399,1,\"b\"],[9400,1,\"c\"],[9401,1,\"d\"],[9402,1,\"e\"],[9403,1,\"f\"],[9404,1,\"g\"],[9405,1,\"h\"],[9406,1,\"i\"],[9407,1,\"j\"],[9408,1,\"k\"],[9409,1,\"l\"],[9410,1,\"m\"],[9411,1,\"n\"],[9412,1,\"o\"],[9413,1,\"p\"],[9414,1,\"q\"],[9415,1,\"r\"],[9416,1,\"s\"],[9417,1,\"t\"],[9418,1,\"u\"],[9419,1,\"v\"],[9420,1,\"w\"],[9421,1,\"x\"],[9422,1,\"y\"],[9423,1,\"z\"],[9424,1,\"a\"],[9425,1,\"b\"],[9426,1,\"c\"],[9427,1,\"d\"],[9428,1,\"e\"],[9429,1,\"f\"],[9430,1,\"g\"],[9431,1,\"h\"],[9432,1,\"i\"],[9433,1,\"j\"],[9434,1,\"k\"],[9435,1,\"l\"],[9436,1,\"m\"],[9437,1,\"n\"],[9438,1,\"o\"],[9439,1,\"p\"],[9440,1,\"q\"],[9441,1,\"r\"],[9442,1,\"s\"],[9443,1,\"t\"],[9444,1,\"u\"],[9445,1,\"v\"],[9446,1,\"w\"],[9447,1,\"x\"],[9448,1,\"y\"],[9449,1,\"z\"],[9450,1,\"0\"],[[9451,9470],2],[9471,2],[[9472,9621],2],[[9622,9631],2],[[9632,9711],2],[[9712,9719],2],[[9720,9727],2],[[9728,9747],2],[[9748,9749],2],[[9750,9751],2],[9752,2],[9753,2],[[9754,9839],2],[[9840,9841],2],[[9842,9853],2],[[9854,9855],2],[[9856,9865],2],[[9866,9873],2],[[9874,9884],2],[9885,2],[[9886,9887],2],[[9888,9889],2],[[9890,9905],2],[9906,2],[[9907,9916],2],[[9917,9919],2],[[9920,9923],2],[[9924,9933],2],[9934,2],[[9935,9953],2],[9954,2],[9955,2],[[9956,9959],2],[[9960,9983],2],[9984,2],[[9985,9988],2],[9989,2],[[9990,9993],2],[[9994,9995],2],[[9996,10023],2],[10024,2],[[10025,10059],2],[10060,2],[10061,2],[10062,2],[[10063,10066],2],[[10067,10069],2],[10070,2],[10071,2],[[10072,10078],2],[[10079,10080],2],[[10081,10087],2],[[10088,10101],2],[[10102,10132],2],[[10133,10135],2],[[10136,10159],2],[10160,2],[[10161,10174],2],[10175,2],[[10176,10182],2],[[10183,10186],2],[10187,2],[10188,2],[10189,2],[[10190,10191],2],[[10192,10219],2],[[10220,10223],2],[[10224,10239],2],[[10240,10495],2],[[10496,10763],2],[10764,1,\"\"],[[10765,10867],2],[10868,5,\"::=\"],[10869,5,\"==\"],[10870,5,\"===\"],[[10871,10971],2],[10972,1,\"\"],[[10973,11007],2],[[11008,11021],2],[[11022,11027],2],[[11028,11034],2],[[11035,11039],2],[[11040,11043],2],[[11044,11084],2],[[11085,11087],2],[[11088,11092],2],[[11093,11097],2],[[11098,11123],2],[[11124,11125],3],[[11126,11157],2],[11158,3],[11159,2],[[11160,11193],2],[[11194,11196],2],[[11197,11208],2],[11209,2],[[11210,11217],2],[11218,2],[[11219,11243],2],[[11244,11247],2],[[11248,11262],2],[11263,2],[11264,1,\"\"],[11265,1,\"\"],[11266,1,\"\"],[11267,1,\"\"],[11268,1,\"\"],[11269,1,\"\"],[11270,1,\"\"],[11271,1,\"\"],[11272,1,\"\"],[11273,1,\"\"],[11274,1,\"\"],[11275,1,\"\"],[11276,1,\"\"],[11277,1,\"\"],[11278,1,\"\"],[11279,1,\"\"],[11280,1,\"\"],[11281,1,\"\"],[11282,1,\"\"],[11283,1,\"\"],[11284,1,\"\"],[11285,1,\"\"],[11286,1,\"\"],[11287,1,\"\"],[11288,1,\"\"],[11289,1,\"\"],[11290,1,\"\"],[11291,1,\"\"],[11292,1,\"\"],[11293,1,\"\"],[11294,1,\"\"],[11295,1,\"\"],[11296,1,\"\"],[11297,1,\"\"],[11298,1,\"\"],[11299,1,\"\"],[11300,1,\"\"],[11301,1,\"\"],[11302,1,\"\"],[11303,1,\"\"],[11304,1,\"\"],[11305,1,\"\"],[11306,1,\"\"],[11307,1,\"\"],[11308,1,\"\"],[11309,1,\"\"],[11310,1,\"\"],[11311,1,\"\"],[[11312,11358],2],[11359,2],[11360,1,\"\"],[11361,2],[11362,1,\"\"],[11363,1,\"\"],[11364,1,\"\"],[[11365,11366],2],[11367,1,\"\"],[11368,2],[11369,1,\"\"],[11370,2],[11371,1,\"\"],[11372,2],[11373,1,\"\"],[11374,1,\"\"],[11375,1,\"\"],[11376,1,\"\"],[11377,2],[11378,1,\"\"],[11379,2],[11380,2],[11381,1,\"\"],[[11382,11383],2],[[11384,11387],2],[11388,1,\"j\"],[11389,1,\"v\"],[11390,1,\"\"],[11391,1,\"\"],[11392,1,\"\"],[11393,2],[11394,1,\"\"],[11395,2],[11396,1,\"\"],[11397,2],[11398,1,\"\"],[11399,2],[11400,1,\"\"],[11401,2],[11402,1,\"\"],[11403,2],[11404,1,\"\"],[11405,2],[11406,1,\"\"],[11407,2],[11408,1,\"\"],[11409,2],[11410,1,\"\"],[11411,2],[11412,1,\"\"],[11413,2],[11414,1,\"\"],[11415,2],[11416,1,\"\"],[11417,2],[11418,1,\"\"],[11419,2],[11420,1,\"\"],[11421,2],[11422,1,\"\"],[11423,2],[11424,1,\"\"],[11425,2],[11426,1,\"\"],[11427,2],[11428,1,\"\"],[11429,2],[11430,1,\"\"],[11431,2],[11432,1,\"\"],[11433,2],[11434,1,\"\"],[11435,2],[11436,1,\"\"],[11437,2],[11438,1,\"\"],[11439,2],[11440,1,\"\"],[11441,2],[11442,1,\"\"],[11443,2],[11444,1,\"\"],[11445,2],[11446,1,\"\"],[11447,2],[11448,1,\"\"],[11449,2],[11450,1,\"\"],[11451,2],[11452,1,\"\"],[11453,2],[11454,1,\"\"],[11455,2],[11456,1,\"\"],[11457,2],[11458,1,\"\"],[11459,2],[11460,1,\"\"],[11461,2],[11462,1,\"\"],[11463,2],[11464,1,\"\"],[11465,2],[11466,1,\"\"],[11467,2],[11468,1,\"\"],[11469,2],[11470,1,\"\"],[11471,2],[11472,1,\"\"],[11473,2],[11474,1,\"\"],[11475,2],[11476,1,\"\"],[11477,2],[11478,1,\"\"],[11479,2],[11480,1,\"\"],[11481,2],[11482,1,\"\"],[11483,2],[11484,1,\"\"],[11485,2],[11486,1,\"\"],[11487,2],[11488,1,\"\"],[11489,2],[11490,1,\"\"],[[11491,11492],2],[[11493,11498],2],[11499,1,\"\"],[11500,2],[11501,1,\"\"],[[11502,11505],2],[11506,1,\"\"],[11507,2],[[11508,11512],3],[[11513,11519],2],[[11520,11557],2],[11558,3],[11559,2],[[11560,11564],3],[11565,2],[[11566,11567],3],[[11568,11621],2],[[11622,11623],2],[[11624,11630],3],[11631,1,\"\"],[11632,2],[[11633,11646],3],[11647,2],[[11648,11670],2],[[11671,11679],3],[[11680,11686],2],[11687,3],[[11688,11694],2],[11695,3],[[11696,11702],2],[11703,3],[[11704,11710],2],[11711,3],[[11712,11718],2],[11719,3],[[11720,11726],2],[11727,3],[[11728,11734],2],[11735,3],[[11736,11742],2],[11743,3],[[11744,11775],2],[[11776,11799],2],[[11800,11803],2],[[11804,11805],2],[[11806,11822],2],[11823,2],[11824,2],[11825,2],[[11826,11835],2],[[11836,11842],2],[[11843,11844],2],[[11845,11849],2],[[11850,11854],2],[11855,2],[[11856,11858],2],[[11859,11869],2],[[11870,11903],3],[[11904,11929],2],[11930,3],[[11931,11934],2],[11935,1,\"\"],[[11936,12018],2],[12019,1,\"\"],[[12020,12031],3],[12032,1,\"\"],[12033,1,\"\"],[12034,1,\"\"],[12035,1,\"\"],[12036,1,\"\"],[12037,1,\"\"],[12038,1,\"\"],[12039,1,\"\"],[12040,1,\"\"],[12041,1,\"\"],[12042,1,\"\"],[12043,1,\"\"],[12044,1,\"\"],[12045,1,\"\"],[12046,1,\"\"],[12047,1,\"\"],[12048,1,\"\"],[12049,1,\"\"],[12050,1,\"\"],[12051,1,\"\"],[12052,1,\"\"],[12053,1,\"\"],[12054,1,\"\"],[12055,1,\"\"],[12056,1,\"\"],[12057,1,\"\"],[12058,1,\"\"],[12059,1,\"\"],[12060,1,\"\"],[12061,1,\"\"],[12062,1,\"\"],[12063,1,\"\"],[12064,1,\"\"],[12065,1,\"\"],[12066,1,\"\"],[12067,1,\"\"],[12068,1,\"\"],[12069,1,\"\"],[12070,1,\"\"],[12071,1,\"\"],[12072,1,\"\"],[12073,1,\"\"],[12074,1,\"\"],[12075,1,\"\"],[12076,1,\"\"],[12077,1,\"\"],[12078,1,\"\"],[12079,1,\"\"],[12080,1,\"\"],[12081,1,\"\"],[12082,1,\"\"],[12083,1,\"\"],[12084,1,\"\"],[12085,1,\"\"],[12086,1,\"\"],[12087,1,\"\"],[12088,1,\"\"],[12089,1,\"\"],[12090,1,\"\"],[12091,1,\"\"],[12092,1,\"\"],[12093,1,\"\"],[12094,1,\"\"],[12095,1,\"\"],[12096,1,\"\"],[12097,1,\"\"],[12098,1,\"\"],[12099,1,\"\"],[12100,1,\"\"],[12101,1,\"\"],[12102,1,\"\"],[12103,1,\"\"],[12104,1,\"\"],[12105,1,\"\"],[12106,1,\"\"],[12107,1,\"\"],[12108,1,\"\"],[12109,1,\"\"],[12110,1,\"\"],[12111,1,\"\"],[12112,1,\"\"],[12113,1,\"\"],[12114,1,\"\"],[12115,1,\"\"],[12116,1,\"\"],[12117,1,\"\"],[12118,1,\"\"],[12119,1,\"\"],[12120,1,\"\"],[12121,1,\"\"],[12122,1,\"\"],[12123,1,\"\"],[12124,1,\"\"],[12125,1,\"\"],[12126,1,\"\"],[12127,1,\"\"],[12128,1,\"\"],[12129,1,\"\"],[12130,1,\"\"],[12131,1,\"\"],[12132,1,\"\"],[12133,1,\"\"],[12134,1,\"\"],[12135,1,\"\"],[12136,1,\"\"],[12137,1,\"\"],[12138,1,\"\"],[12139,1,\"\"],[12140,1,\"\"],[12141,1,\"\"],[12142,1,\"\"],[12143,1,\"\"],[12144,1,\"\"],[12145,1,\"\"],[12146,1,\"\"],[12147,1,\"\"],[12148,1,\"\"],[12149,1,\"\"],[12150,1,\"\"],[12151,1,\"\"],[12152,1,\"\"],[12153,1,\"\"],[12154,1,\"\"],[12155,1,\"\"],[12156,1,\"\"],[12157,1,\"\"],[12158,1,\"\"],[12159,1,\"\"],[12160,1,\"\"],[12161,1,\"\"],[12162,1,\"\"],[12163,1,\"\"],[12164,1,\"\"],[12165,1,\"\"],[12166,1,\"\"],[12167,1,\"\"],[12168,1,\"\"],[12169,1,\"\"],[12170,1,\"\"],[12171,1,\"\"],[12172,1,\"\"],[12173,1,\"\"],[12174,1,\"\"],[12175,1,\"\"],[12176,1,\"\"],[12177,1,\"\"],[12178,1,\"\"],[12179,1,\"\"],[12180,1,\"\"],[12181,1,\"\"],[12182,1,\"\"],[12183,1,\"\"],[12184,1,\"\"],[12185,1,\"\"],[12186,1,\"\"],[12187,1,\"\"],[12188,1,\"\"],[12189,1,\"\"],[12190,1,\"\"],[12191,1,\"\"],[12192,1,\"\"],[12193,1,\"\"],[12194,1,\"\"],[12195,1,\"\"],[12196,1,\"\"],[12197,1,\"\"],[12198,1,\"\"],[12199,1,\"\"],[12200,1,\"\"],[12201,1,\"\"],[12202,1,\"\"],[12203,1,\"\"],[12204,1,\"\"],[12205,1,\"\"],[12206,1,\"\"],[12207,1,\"\"],[12208,1,\"\"],[12209,1,\"\"],[12210,1,\"\"],[12211,1,\"\"],[12212,1,\"\"],[12213,1,\"\"],[12214,1,\"\"],[12215,1,\"\"],[12216,1,\"\"],[12217,1,\"\"],[12218,1,\"\"],[12219,1,\"\"],[12220,1,\"\"],[12221,1,\"\"],[12222,1,\"\"],[12223,1,\"\"],[12224,1,\"\"],[12225,1,\"\"],[12226,1,\"\"],[12227,1,\"\"],[12228,1,\"\"],[12229,1,\"\"],[12230,1,\"\"],[12231,1,\"\"],[12232,1,\"\"],[12233,1,\"\"],[12234,1,\"\"],[12235,1,\"\"],[12236,1,\"\"],[12237,1,\"\"],[12238,1,\"\"],[12239,1,\"\"],[12240,1,\"\"],[12241,1,\"\"],[12242,1,\"\"],[12243,1,\"\"],[12244,1,\"\"],[12245,1,\"\"],[[12246,12271],3],[[12272,12283],3],[[12284,12287],3],[12288,5,\" \"],[12289,2],[12290,1,\".\"],[[12291,12292],2],[[12293,12295],2],[[12296,12329],2],[[12330,12333],2],[[12334,12341],2],[12342,1,\"\"],[12343,2],[12344,1,\"\"],[12345,1,\"\"],[12346,1,\"\"],[12347,2],[12348,2],[12349,2],[12350,2],[12351,2],[12352,3],[[12353,12436],2],[[12437,12438],2],[[12439,12440],3],[[12441,12442],2],[12443,5,\" \"],[12444,5,\" \"],[[12445,12446],2],[12447,1,\"\"],[12448,2],[[12449,12542],2],[12543,1,\"\"],[[12544,12548],3],[[12549,12588],2],[12589,2],[12590,2],[12591,2],[12592,3],[12593,1,\"\"],[12594,1,\"\"],[12595,1,\"\"],[12596,1,\"\"],[12597,1,\"\"],[12598,1,\"\"],[12599,1,\"\"],[12600,1,\"\"],[12601,1,\"\"],[12602,1,\"\"],[12603,1,\"\"],[12604,1,\"\"],[12605,1,\"\"],[12606,1,\"\"],[12607,1,\"\"],[12608,1,\"\"],[12609,1,\"\"],[12610,1,\"\"],[12611,1,\"\"],[12612,1,\"\"],[12613,1,\"\"],[12614,1,\"\"],[12615,1,\"\"],[12616,1,\"\"],[12617,1,\"\"],[12618,1,\"\"],[12619,1,\"\"],[12620,1,\"\"],[12621,1,\"\"],[12622,1,\"\"],[12623,1,\"\"],[12624,1,\"\"],[12625,1,\"\"],[12626,1,\"\"],[12627,1,\"\"],[12628,1,\"\"],[12629,1,\"\"],[12630,1,\"\"],[12631,1,\"\"],[12632,1,\"\"],[12633,1,\"\"],[12634,1,\"\"],[12635,1,\"\"],[12636,1,\"\"],[12637,1,\"\"],[12638,1,\"\"],[12639,1,\"\"],[12640,1,\"\"],[12641,1,\"\"],[12642,1,\"\"],[12643,1,\"\"],[12644,3],[12645,1,\"\"],[12646,1,\"\"],[12647,1,\"\"],[12648,1,\"\"],[12649,1,\"\"],[12650,1,\"\"],[12651,1,\"\"],[12652,1,\"\"],[12653,1,\"\"],[12654,1,\"\"],[12655,1,\"\"],[12656,1,\"\"],[12657,1,\"\"],[12658,1,\"\"],[12659,1,\"\"],[12660,1,\"\"],[12661,1,\"\"],[12662,1,\"\"],[12663,1,\"\"],[12664,1,\"\"],[12665,1,\"\"],[12666,1,\"\"],[12667,1,\"\"],[12668,1,\"\"],[12669,1,\"\"],[12670,1,\"\"],[12671,1,\"\"],[12672,1,\"\"],[12673,1,\"\"],[12674,1,\"\"],[12675,1,\"\"],[12676,1,\"\"],[12677,1,\"\"],[12678,1,\"\"],[12679,1,\"\"],[12680,1,\"\"],[12681,1,\"\"],[12682,1,\"\"],[12683,1,\"\"],[12684,1,\"\"],[12685,1,\"\"],[12686,1,\"\"],[12687,3],[[12688,12689],2],[12690,1,\"\"],[12691,1,\"\"],[12692,1,\"\"],[12693,1,\"\"],[12694,1,\"\"],[12695,1,\"\"],[12696,1,\"\"],[12697,1,\"\"],[12698,1,\"\"],[12699,1,\"\"],[12700,1,\"\"],[12701,1,\"\"],[12702,1,\"\"],[12703,1,\"\"],[[12704,12727],2],[[12728,12730],2],[[12731,12735],2],[[12736,12751],2],[[12752,12771],2],[[12772,12783],3],[[12784,12799],2],[12800,5,\"()\"],[12801,5,\"()\"],[12802,5,\"()\"],[12803,5,\"()\"],[12804,5,\"()\"],[12805,5,\"()\"],[12806,5,\"()\"],[12807,5,\"()\"],[12808,5,\"()\"],[12809,5,\"()\"],[12810,5,\"()\"],[12811,5,\"()\"],[12812,5,\"()\"],[12813,5,\"()\"],[12814,5,\"()\"],[12815,5,\"()\"],[12816,5,\"()\"],[12817,5,\"()\"],[12818,5,\"()\"],[12819,5,\"()\"],[12820,5,\"()\"],[12821,5,\"()\"],[12822,5,\"()\"],[12823,5,\"()\"],[12824,5,\"()\"],[12825,5,\"()\"],[12826,5,\"()\"],[12827,5,\"()\"],[12828,5,\"()\"],[12829,5,\"()\"],[12830,5,\"()\"],[12831,3],[12832,5,\"()\"],[12833,5,\"()\"],[12834,5,\"()\"],[12835,5,\"()\"],[12836,5,\"()\"],[12837,5,\"()\"],[12838,5,\"()\"],[12839,5,\"()\"],[12840,5,\"()\"],[12841,5,\"()\"],[12842,5,\"()\"],[12843,5,\"()\"],[12844,5,\"()\"],[12845,5,\"()\"],[12846,5,\"()\"],[12847,5,\"()\"],[12848,5,\"()\"],[12849,5,\"()\"],[12850,5,\"()\"],[12851,5,\"()\"],[12852,5,\"()\"],[12853,5,\"()\"],[12854,5,\"()\"],[12855,5,\"()\"],[12856,5,\"()\"],[12857,5,\"()\"],[12858,5,\"()\"],[12859,5,\"()\"],[12860,5,\"()\"],[12861,5,\"()\"],[12862,5,\"()\"],[12863,5,\"()\"],[12864,5,\"()\"],[12865,5,\"()\"],[12866,5,\"()\"],[12867,5,\"()\"],[12868,1,\"\"],[12869,1,\"\"],[12870,1,\"\"],[12871,1,\"\"],[[12872,12879],2],[12880,1,\"pte\"],[12881,1,\"21\"],[12882,1,\"22\"],[12883,1,\"23\"],[12884,1,\"24\"],[12885,1,\"25\"],[12886,1,\"26\"],[12887,1,\"27\"],[12888,1,\"28\"],[12889,1,\"29\"],[12890,1,\"30\"],[12891,1,\"31\"],[12892,1,\"32\"],[12893,1,\"33\"],[12894,1,\"34\"],[12895,1,\"35\"],[12896,1,\"\"],[12897,1,\"\"],[12898,1,\"\"],[12899,1,\"\"],[12900,1,\"\"],[12901,1,\"\"],[12902,1,\"\"],[12903,1,\"\"],[12904,1,\"\"],[12905,1,\"\"],[12906,1,\"\"],[12907,1,\"\"],[12908,1,\"\"],[12909,1,\"\"],[12910,1,\"\"],[12911,1,\"\"],[12912,1,\"\"],[12913,1,\"\"],[12914,1,\"\"],[12915,1,\"\"],[12916,1,\"\"],[12917,1,\"\"],[12918,1,\"\"],[12919,1,\"\"],[12920,1,\"\"],[12921,1,\"\"],[12922,1,\"\"],[12923,1,\"\"],[12924,1,\"\"],[12925,1,\"\"],[12926,1,\"\"],[12927,2],[12928,1,\"\"],[12929,1,\"\"],[12930,1,\"\"],[12931,1,\"\"],[12932,1,\"\"],[12933,1,\"\"],[12934,1,\"\"],[12935,1,\"\"],[12936,1,\"\"],[12937,1,\"\"],[12938,1,\"\"],[12939,1,\"\"],[12940,1,\"\"],[12941,1,\"\"],[12942,1,\"\"],[12943,1,\"\"],[12944,1,\"\"],[12945,1,\"\"],[12946,1,\"\"],[12947,1,\"\"],[12948,1,\"\"],[12949,1,\"\"],[12950,1,\"\"],[12951,1,\"\"],[12952,1,\"\"],[12953,1,\"\"],[12954,1,\"\"],[12955,1,\"\"],[12956,1,\"\"],[12957,1,\"\"],[12958,1,\"\"],[12959,1,\"\"],[12960,1,\"\"],[12961,1,\"\"],[12962,1,\"\"],[12963,1,\"\"],[12964,1,\"\"],[12965,1,\"\"],[12966,1,\"\"],[12967,1,\"\"],[12968,1,\"\"],[12969,1,\"\"],[12970,1,\"\"],[12971,1,\"\"],[12972,1,\"\"],[12973,1,\"\"],[12974,1,\"\"],[12975,1,\"\"],[12976,1,\"\"],[12977,1,\"36\"],[12978,1,\"37\"],[12979,1,\"38\"],[12980,1,\"39\"],[12981,1,\"40\"],[12982,1,\"41\"],[12983,1,\"42\"],[12984,1,\"43\"],[12985,1,\"44\"],[12986,1,\"45\"],[12987,1,\"46\"],[12988,1,\"47\"],[12989,1,\"48\"],[12990,1,\"49\"],[12991,1,\"50\"],[12992,1,\"1\"],[12993,1,\"2\"],[12994,1,\"3\"],[12995,1,\"4\"],[12996,1,\"5\"],[12997,1,\"6\"],[12998,1,\"7\"],[12999,1,\"8\"],[13000,1,\"9\"],[13001,1,\"10\"],[13002,1,\"11\"],[13003,1,\"12\"],[13004,1,\"hg\"],[13005,1,\"erg\"],[13006,1,\"ev\"],[13007,1,\"ltd\"],[13008,1,\"\"],[13009,1,\"\"],[13010,1,\"\"],[13011,1,\"\"],[13012,1,\"\"],[13013,1,\"\"],[13014,1,\"\"],[13015,1,\"\"],[13016,1,\"\"],[13017,1,\"\"],[13018,1,\"\"],[13019,1,\"\"],[13020,1,\"\"],[13021,1,\"\"],[13022,1,\"\"],[13023,1,\"\"],[13024,1,\"\"],[13025,1,\"\"],[13026,1,\"\"],[13027,1,\"\"],[13028,1,\"\"],[13029,1,\"\"],[13030,1,\"\"],[13031,1,\"\"],[13032,1,\"\"],[13033,1,\"\"],[13034,1,\"\"],[13035,1,\"\"],[13036,1,\"\"],[13037,1,\"\"],[13038,1,\"\"],[13039,1,\"\"],[13040,1,\"\"],[13041,1,\"\"],[13042,1,\"\"],[13043,1,\"\"],[13044,1,\"\"],[13045,1,\"\"],[13046,1,\"\"],[13047,1,\"\"],[13048,1,\"\"],[13049,1,\"\"],[13050,1,\"\"],[13051,1,\"\"],[13052,1,\"\"],[13053,1,\"\"],[13054,1,\"\"],[13055,1,\"\"],[13056,1,\"\"],[13057,1,\"\"],[13058,1,\"\"],[13059,1,\"\"],[13060,1,\"\"],[13061,1,\"\"],[13062,1,\"\"],[13063,1,\"\"],[13064,1,\"\"],[13065,1,\"\"],[13066,1,\"\"],[13067,1,\"\"],[13068,1,\"\"],[13069,1,\"\"],[13070,1,\"\"],[13071,1,\"\"],[13072,1,\"\"],[13073,1,\"\"],[13074,1,\"\"],[13075,1,\"\"],[13076,1,\"\"],[13077,1,\"\"],[13078,1,\"\"],[13079,1,\"\"],[13080,1,\"\"],[13081,1,\"\"],[13082,1,\"\"],[13083,1,\"\"],[13084,1,\"\"],[13085,1,\"\"],[13086,1,\"\"],[13087,1,\"\"],[13088,1,\"\"],[13089,1,\"\"],[13090,1,\"\"],[13091,1,\"\"],[13092,1,\"\"],[13093,1,\"\"],[13094,1,\"\"],[13095,1,\"\"],[13096,1,\"\"],[13097,1,\"\"],[13098,1,\"\"],[13099,1,\"\"],[13100,1,\"\"],[13101,1,\"\"],[13102,1,\"\"],[13103,1,\"\"],[13104,1,\"\"],[13105,1,\"\"],[13106,1,\"\"],[13107,1,\"\"],[13108,1,\"\"],[13109,1,\"\"],[13110,1,\"\"],[13111,1,\"\"],[13112,1,\"\"],[13113,1,\"\"],[13114,1,\"\"],[13115,1,\"\"],[13116,1,\"\"],[13117,1,\"\"],[13118,1,\"\"],[13119,1,\"\"],[13120,1,\"\"],[13121,1,\"\"],[13122,1,\"\"],[13123,1,\"\"],[13124,1,\"\"],[13125,1,\"\"],[13126,1,\"\"],[13127,1,\"\"],[13128,1,\"\"],[13129,1,\"\"],[13130,1,\"\"],[13131,1,\"\"],[13132,1,\"\"],[13133,1,\"\"],[13134,1,\"\"],[13135,1,\"\"],[13136,1,\"\"],[13137,1,\"\"],[13138,1,\"\"],[13139,1,\"\"],[13140,1,\"\"],[13141,1,\"\"],[13142,1,\"\"],[13143,1,\"\"],[13144,1,\"0\"],[13145,1,\"1\"],[13146,1,\"2\"],[13147,1,\"3\"],[13148,1,\"4\"],[13149,1,\"5\"],[13150,1,\"6\"],[13151,1,\"7\"],[13152,1,\"8\"],[13153,1,\"9\"],[13154,1,\"10\"],[13155,1,\"11\"],[13156,1,\"12\"],[13157,1,\"13\"],[13158,1,\"14\"],[13159,1,\"15\"],[13160,1,\"16\"],[13161,1,\"17\"],[13162,1,\"18\"],[13163,1,\"19\"],[13164,1,\"20\"],[13165,1,\"21\"],[13166,1,\"22\"],[13167,1,\"23\"],[13168,1,\"24\"],[13169,1,\"hpa\"],[13170,1,\"da\"],[13171,1,\"au\"],[13172,1,\"bar\"],[13173,1,\"ov\"],[13174,1,\"pc\"],[13175,1,\"dm\"],[13176,1,\"dm2\"],[13177,1,\"dm3\"],[13178,1,\"iu\"],[13179,1,\"\"],[13180,1,\"\"],[13181,1,\"\"],[13182,1,\"\"],[13183,1,\"\"],[13184,1,\"pa\"],[13185,1,\"na\"],[13186,1,\"a\"],[13187,1,\"ma\"],[13188,1,\"ka\"],[13189,1,\"kb\"],[13190,1,\"mb\"],[13191,1,\"gb\"],[13192,1,\"cal\"],[13193,1,\"kcal\"],[13194,1,\"pf\"],[13195,1,\"nf\"],[13196,1,\"f\"],[13197,1,\"g\"],[13198,1,\"mg\"],[13199,1,\"kg\"],[13200,1,\"hz\"],[13201,1,\"khz\"],[13202,1,\"mhz\"],[13203,1,\"ghz\"],[13204,1,\"thz\"],[13205,1,\"l\"],[13206,1,\"ml\"],[13207,1,\"dl\"],[13208,1,\"kl\"],[13209,1,\"fm\"],[13210,1,\"nm\"],[13211,1,\"m\"],[13212,1,\"mm\"],[13213,1,\"cm\"],[13214,1,\"km\"],[13215,1,\"mm2\"],[13216,1,\"cm2\"],[13217,1,\"m2\"],[13218,1,\"km2\"],[13219,1,\"mm3\"],[13220,1,\"cm3\"],[13221,1,\"m3\"],[13222,1,\"km3\"],[13223,1,\"ms\"],[13224,1,\"ms2\"],[13225,1,\"pa\"],[13226,1,\"kpa\"],[13227,1,\"mpa\"],[13228,1,\"gpa\"],[13229,1,\"rad\"],[13230,1,\"rads\"],[13231,1,\"rads2\"],[13232,1,\"ps\"],[13233,1,\"ns\"],[13234,1,\"s\"],[13235,1,\"ms\"],[13236,1,\"pv\"],[13237,1,\"nv\"],[13238,1,\"v\"],[13239,1,\"mv\"],[13240,1,\"kv\"],[13241,1,\"mv\"],[13242,1,\"pw\"],[13243,1,\"nw\"],[13244,1,\"w\"],[13245,1,\"mw\"],[13246,1,\"kw\"],[13247,1,\"mw\"],[13248,1,\"k\"],[13249,1,\"m\"],[13250,3],[13251,1,\"bq\"],[13252,1,\"cc\"],[13253,1,\"cd\"],[13254,1,\"ckg\"],[13255,3],[13256,1,\"db\"],[13257,1,\"gy\"],[13258,1,\"ha\"],[13259,1,\"hp\"],[13260,1,\"in\"],[13261,1,\"kk\"],[13262,1,\"km\"],[13263,1,\"kt\"],[13264,1,\"lm\"],[13265,1,\"ln\"],[13266,1,\"log\"],[13267,1,\"lx\"],[13268,1,\"mb\"],[13269,1,\"mil\"],[13270,1,\"mol\"],[13271,1,\"ph\"],[13272,3],[13273,1,\"ppm\"],[13274,1,\"pr\"],[13275,1,\"sr\"],[13276,1,\"sv\"],[13277,1,\"wb\"],[13278,1,\"vm\"],[13279,1,\"am\"],[13280,1,\"1\"],[13281,1,\"2\"],[13282,1,\"3\"],[13283,1,\"4\"],[13284,1,\"5\"],[13285,1,\"6\"],[13286,1,\"7\"],[13287,1,\"8\"],[13288,1,\"9\"],[13289,1,\"10\"],[13290,1,\"11\"],[13291,1,\"12\"],[13292,1,\"13\"],[13293,1,\"14\"],[13294,1,\"15\"],[13295,1,\"16\"],[13296,1,\"17\"],[13297,1,\"18\"],[13298,1,\"19\"],[13299,1,\"20\"],[13300,1,\"21\"],[13301,1,\"22\"],[13302,1,\"23\"],[13303,1,\"24\"],[13304,1,\"25\"],[13305,1,\"26\"],[13306,1,\"27\"],[13307,1,\"28\"],[13308,1,\"29\"],[13309,1,\"30\"],[13310,1,\"31\"],[13311,1,\"gal\"],[[13312,19893],2],[[19894,19903],2],[[19904,19967],2],[[19968,40869],2],[[40870,40891],2],[[40892,40899],2],[[40900,40907],2],[40908,2],[[40909,40917],2],[[40918,40938],2],[[40939,40943],2],[[40944,40956],2],[[40957,40959],2],[[40960,42124],2],[[42125,42127],3],[[42128,42145],2],[[42146,42147],2],[[42148,42163],2],[42164,2],[[42165,42176],2],[42177,2],[[42178,42180],2],[42181,2],[42182,2],[[42183,42191],3],[[42192,42237],2],[[42238,42239],2],[[42240,42508],2],[[42509,42511],2],[[42512,42539],2],[[42540,42559],3],[42560,1,\"\"],[42561,2],[42562,1,\"\"],[42563,2],[42564,1,\"\"],[42565,2],[42566,1,\"\"],[42567,2],[42568,1,\"\"],[42569,2],[42570,1,\"\"],[42571,2],[42572,1,\"\"],[42573,2],[42574,1,\"\"],[42575,2],[42576,1,\"\"],[42577,2],[42578,1,\"\"],[42579,2],[42580,1,\"\"],[42581,2],[42582,1,\"\"],[42583,2],[42584,1,\"\"],[42585,2],[42586,1,\"\"],[42587,2],[42588,1,\"\"],[42589,2],[42590,1,\"\"],[42591,2],[42592,1,\"\"],[42593,2],[42594,1,\"\"],[42595,2],[42596,1,\"\"],[42597,2],[42598,1,\"\"],[42599,2],[42600,1,\"\"],[42601,2],[42602,1,\"\"],[42603,2],[42604,1,\"\"],[[42605,42607],2],[[42608,42611],2],[[42612,42619],2],[[42620,42621],2],[42622,2],[42623,2],[42624,1,\"\"],[42625,2],[42626,1,\"\"],[42627,2],[42628,1,\"\"],[42629,2],[42630,1,\"\"],[42631,2],[42632,1,\"\"],[42633,2],[42634,1,\"\"],[42635,2],[42636,1,\"\"],[42637,2],[42638,1,\"\"],[42639,2],[42640,1,\"\"],[42641,2],[42642,1,\"\"],[42643,2],[42644,1,\"\"],[42645,2],[42646,1,\"\"],[42647,2],[42648,1,\"\"],[42649,2],[42650,1,\"\"],[42651,2],[42652,1,\"\"],[42653,1,\"\"],[42654,2],[42655,2],[[42656,42725],2],[[42726,42735],2],[[42736,42737],2],[[42738,42743],2],[[42744,42751],3],[[42752,42774],2],[[42775,42778],2],[[42779,42783],2],[[42784,42785],2],[42786,1,\"\"],[42787,2],[42788,1,\"\"],[42789,2],[42790,1,\"\"],[42791,2],[42792,1,\"\"],[42793,2],[42794,1,\"\"],[42795,2],[42796,1,\"\"],[42797,2],[42798,1,\"\"],[[42799,42801],2],[42802,1,\"\"],[42803,2],[42804,1,\"\"],[42805,2],[42806,1,\"\"],[42807,2],[42808,1,\"\"],[42809,2],[42810,1,\"\"],[42811,2],[42812,1,\"\"],[42813,2],[42814,1,\"\"],[42815,2],[42816,1,\"\"],[42817,2],[42818,1,\"\"],[42819,2],[42820,1,\"\"],[42821,2],[42822,1,\"\"],[42823,2],[42824,1,\"\"],[42825,2],[42826,1,\"\"],[42827,2],[42828,1,\"\"],[42829,2],[42830,1,\"\"],[42831,2],[42832,1,\"\"],[42833,2],[42834,1,\"\"],[42835,2],[42836,1,\"\"],[42837,2],[42838,1,\"\"],[42839,2],[42840,1,\"\"],[42841,2],[42842,1,\"\"],[42843,2],[42844,1,\"\"],[42845,2],[42846,1,\"\"],[42847,2],[42848,1,\"\"],[42849,2],[42850,1,\"\"],[42851,2],[42852,1,\"\"],[42853,2],[42854,1,\"\"],[42855,2],[42856,1,\"\"],[42857,2],[42858,1,\"\"],[42859,2],[42860,1,\"\"],[42861,2],[42862,1,\"\"],[42863,2],[42864,1,\"\"],[[42865,42872],2],[42873,1,\"\"],[42874,2],[42875,1,\"\"],[42876,2],[42877,1,\"\"],[42878,1,\"\"],[42879,2],[42880,1,\"\"],[42881,2],[42882,1,\"\"],[42883,2],[42884,1,\"\"],[42885,2],[42886,1,\"\"],[[42887,42888],2],[[42889,42890],2],[42891,1,\"\"],[42892,2],[42893,1,\"\"],[42894,2],[42895,2],[42896,1,\"\"],[42897,2],[42898,1,\"\"],[42899,2],[[42900,42901],2],[42902,1,\"\"],[42903,2],[42904,1,\"\"],[42905,2],[42906,1,\"\"],[42907,2],[42908,1,\"\"],[42909,2],[42910,1,\"\"],[42911,2],[42912,1,\"\"],[42913,2],[42914,1,\"\"],[42915,2],[42916,1,\"\"],[42917,2],[42918,1,\"\"],[42919,2],[42920,1,\"\"],[42921,2],[42922,1,\"\"],[42923,1,\"\"],[42924,1,\"\"],[42925,1,\"\"],[42926,1,\"\"],[42927,2],[42928,1,\"\"],[42929,1,\"\"],[42930,1,\"\"],[42931,1,\"\"],[42932,1,\"\"],[42933,2],[42934,1,\"\"],[42935,2],[42936,1,\"\"],[42937,2],[42938,1,\"\"],[42939,2],[42940,1,\"\"],[42941,2],[42942,1,\"\"],[42943,2],[42944,1,\"\"],[42945,2],[42946,1,\"\"],[42947,2],[42948,1,\"\"],[42949,1,\"\"],[42950,1,\"\"],[42951,1,\"\"],[42952,2],[42953,1,\"\"],[42954,2],[[42955,42959],3],[42960,1,\"\"],[42961,2],[42962,3],[42963,2],[42964,3],[42965,2],[42966,1,\"\"],[42967,2],[42968,1,\"\"],[42969,2],[[42970,42993],3],[42994,1,\"c\"],[42995,1,\"f\"],[42996,1,\"q\"],[42997,1,\"\"],[42998,2],[42999,2],[43000,1,\"\"],[43001,1,\"\"],[43002,2],[[43003,43007],2],[[43008,43047],2],[[43048,43051],2],[43052,2],[[43053,43055],3],[[43056,43065],2],[[43066,43071],3],[[43072,43123],2],[[43124,43127],2],[[43128,43135],3],[[43136,43204],2],[43205,2],[[43206,43213],3],[[43214,43215],2],[[43216,43225],2],[[43226,43231],3],[[43232,43255],2],[[43256,43258],2],[43259,2],[43260,2],[43261,2],[[43262,43263],2],[[43264,43309],2],[[43310,43311],2],[[43312,43347],2],[[43348,43358],3],[43359,2],[[43360,43388],2],[[43389,43391],3],[[43392,43456],2],[[43457,43469],2],[43470,3],[[43471,43481],2],[[43482,43485],3],[[43486,43487],2],[[43488,43518],2],[43519,3],[[43520,43574],2],[[43575,43583],3],[[43584,43597],2],[[43598,43599],3],[[43600,43609],2],[[43610,43611],3],[[43612,43615],2],[[43616,43638],2],[[43639,43641],2],[[43642,43643],2],[[43644,43647],2],[[43648,43714],2],[[43715,43738],3],[[43739,43741],2],[[43742,43743],2],[[43744,43759],2],[[43760,43761],2],[[43762,43766],2],[[43767,43776],3],[[43777,43782],2],[[43783,43784],3],[[43785,43790],2],[[43791,43792],3],[[43793,43798],2],[[43799,43807],3],[[43808,43814],2],[43815,3],[[43816,43822],2],[43823,3],[[43824,43866],2],[43867,2],[43868,1,\"\"],[43869,1,\"\"],[43870,1,\"\"],[43871,1,\"\"],[[43872,43875],2],[[43876,43877],2],[[43878,43879],2],[43880,2],[43881,1,\"\"],[[43882,43883],2],[[43884,43887],3],[43888,1,\"\"],[43889,1,\"\"],[43890,1,\"\"],[43891,1,\"\"],[43892,1,\"\"],[43893,1,\"\"],[43894,1,\"\"],[43895,1,\"\"],[43896,1,\"\"],[43897,1,\"\"],[43898,1,\"\"],[43899,1,\"\"],[43900,1,\"\"],[43901,1,\"\"],[43902,1,\"\"],[43903,1,\"\"],[43904,1,\"\"],[43905,1,\"\"],[43906,1,\"\"],[43907,1,\"\"],[43908,1,\"\"],[43909,1,\"\"],[43910,1,\"\"],[43911,1,\"\"],[43912,1,\"\"],[43913,1,\"\"],[43914,1,\"\"],[43915,1,\"\"],[43916,1,\"\"],[43917,1,\"\"],[43918,1,\"\"],[43919,1,\"\"],[43920,1,\"\"],[43921,1,\"\"],[43922,1,\"\"],[43923,1,\"\"],[43924,1,\"\"],[43925,1,\"\"],[43926,1,\"\"],[43927,1,\"\"],[43928,1,\"\"],[43929,1,\"\"],[43930,1,\"\"],[43931,1,\"\"],[43932,1,\"\"],[43933,1,\"\"],[43934,1,\"\"],[43935,1,\"\"],[43936,1,\"\"],[43937,1,\"\"],[43938,1,\"\"],[43939,1,\"\"],[43940,1,\"\"],[43941,1,\"\"],[43942,1,\"\"],[43943,1,\"\"],[43944,1,\"\"],[43945,1,\"\"],[43946,1,\"\"],[43947,1,\"\"],[43948,1,\"\"],[43949,1,\"\"],[43950,1,\"\"],[43951,1,\"\"],[43952,1,\"\"],[43953,1,\"\"],[43954,1,\"\"],[43955,1,\"\"],[43956,1,\"\"],[43957,1,\"\"],[43958,1,\"\"],[43959,1,\"\"],[43960,1,\"\"],[43961,1,\"\"],[43962,1,\"\"],[43963,1,\"\"],[43964,1,\"\"],[43965,1,\"\"],[43966,1,\"\"],[43967,1,\"\"],[[43968,44010],2],[44011,2],[[44012,44013],2],[[44014,44015],3],[[44016,44025],2],[[44026,44031],3],[[44032,55203],2],[[55204,55215],3],[[55216,55238],2],[[55239,55242],3],[[55243,55291],2],[[55292,55295],3],[[55296,57343],3],[[57344,63743],3],[63744,1,\"\"],[63745,1,\"\"],[63746,1,\"\"],[63747,1,\"\"],[63748,1,\"\"],[63749,1,\"\"],[63750,1,\"\"],[[63751,63752],1,\"\"],[63753,1,\"\"],[63754,1,\"\"],[63755,1,\"\"],[63756,1,\"\"],[63757,1,\"\"],[63758,1,\"\"],[63759,1,\"\"],[63760,1,\"\"],[63761,1,\"\"],[63762,1,\"\"],[63763,1,\"\"],[63764,1,\"\"],[63765,1,\"\"],[63766,1,\"\"],[63767,1,\"\"],[63768,1,\"\"],[63769,1,\"\"],[63770,1,\"\"],[63771,1,\"\"],[63772,1,\"\"],[63773,1,\"\"],[63774,1,\"\"],[63775,1,\"\"],[63776,1,\"\"],[63777,1,\"\"],[63778,1,\"\"],[63779,1,\"\"],[63780,1,\"\"],[63781,1,\"\"],[63782,1,\"\"],[63783,1,\"\"],[63784,1,\"\"],[63785,1,\"\"],[63786,1,\"\"],[63787,1,\"\"],[63788,1,\"\"],[63789,1,\"\"],[63790,1,\"\"],[63791,1,\"\"],[63792,1,\"\"],[63793,1,\"\"],[63794,1,\"\"],[63795,1,\"\"],[63796,1,\"\"],[63797,1,\"\"],[63798,1,\"\"],[63799,1,\"\"],[63800,1,\"\"],[63801,1,\"\"],[63802,1,\"\"],[63803,1,\"\"],[63804,1,\"\"],[63805,1,\"\"],[63806,1,\"\"],[63807,1,\"\"],[63808,1,\"\"],[63809,1,\"\"],[63810,1,\"\"],[63811,1,\"\"],[63812,1,\"\"],[63813,1,\"\"],[63814,1,\"\"],[63815,1,\"\"],[63816,1,\"\"],[63817,1,\"\"],[63818,1,\"\"],[63819,1,\"\"],[63820,1,\"\"],[63821,1,\"\"],[63822,1,\"\"],[63823,1,\"\"],[63824,1,\"\"],[63825,1,\"\"],[63826,1,\"\"],[63827,1,\"\"],[63828,1,\"\"],[63829,1,\"\"],[63830,1,\"\"],[63831,1,\"\"],[63832,1,\"\"],[63833,1,\"\"],[63834,1,\"\"],[63835,1,\"\"],[63836,1,\"\"],[63837,1,\"\"],[63838,1,\"\"],[63839,1,\"\"],[63840,1,\"\"],[63841,1,\"\"],[63842,1,\"\"],[63843,1,\"\"],[63844,1,\"\"],[63845,1,\"\"],[63846,1,\"\"],[63847,1,\"\"],[63848,1,\"\"],[63849,1,\"\"],[63850,1,\"\"],[63851,1,\"\"],[63852,1,\"\"],[63853,1,\"\"],[63854,1,\"\"],[63855,1,\"\"],[63856,1,\"\"],[63857,1,\"\"],[63858,1,\"\"],[63859,1,\"\"],[63860,1,\"\"],[63861,1,\"\"],[63862,1,\"\"],[63863,1,\"\"],[63864,1,\"\"],[63865,1,\"\"],[63866,1,\"\"],[63867,1,\"\"],[63868,1,\"\"],[63869,1,\"\"],[63870,1,\"\"],[63871,1,\"\"],[63872,1,\"\"],[63873,1,\"\"],[63874,1,\"\"],[63875,1,\"\"],[63876,1,\"\"],[63877,1,\"\"],[63878,1,\"\"],[63879,1,\"\"],[63880,1,\"\"],[63881,1,\"\"],[63882,1,\"\"],[63883,1,\"\"],[63884,1,\"\"],[63885,1,\"\"],[63886,1,\"\"],[63887,1,\"\"],[63888,1,\"\"],[63889,1,\"\"],[63890,1,\"\"],[63891,1,\"\"],[63892,1,\"\"],[63893,1,\"\"],[63894,1,\"\"],[63895,1,\"\"],[63896,1,\"\"],[63897,1,\"\"],[63898,1,\"\"],[63899,1,\"\"],[63900,1,\"\"],[63901,1,\"\"],[63902,1,\"\"],[63903,1,\"\"],[63904,1,\"\"],[63905,1,\"\"],[63906,1,\"\"],[63907,1,\"\"],[63908,1,\"\"],[63909,1,\"\"],[63910,1,\"\"],[63911,1,\"\"],[63912,1,\"\"],[63913,1,\"\"],[63914,1,\"\"],[63915,1,\"\"],[63916,1,\"\"],[63917,1,\"\"],[63918,1,\"\"],[63919,1,\"\"],[63920,1,\"\"],[63921,1,\"\"],[63922,1,\"\"],[63923,1,\"\"],[63924,1,\"\"],[63925,1,\"\"],[63926,1,\"\"],[63927,1,\"\"],[63928,1,\"\"],[63929,1,\"\"],[63930,1,\"\"],[63931,1,\"\"],[63932,1,\"\"],[63933,1,\"\"],[63934,1,\"\"],[63935,1,\"\"],[63936,1,\"\"],[63937,1,\"\"],[63938,1,\"\"],[63939,1,\"\"],[63940,1,\"\"],[63941,1,\"\"],[63942,1,\"\"],[63943,1,\"\"],[63944,1,\"\"],[63945,1,\"\"],[63946,1,\"\"],[63947,1,\"\"],[63948,1,\"\"],[63949,1,\"\"],[63950,1,\"\"],[63951,1,\"\"],[63952,1,\"\"],[63953,1,\"\"],[63954,1,\"\"],[63955,1,\"\"],[63956,1,\"\"],[63957,1,\"\"],[63958,1,\"\"],[63959,1,\"\"],[63960,1,\"\"],[63961,1,\"\"],[63962,1,\"\"],[63963,1,\"\"],[63964,1,\"\"],[63965,1,\"\"],[63966,1,\"\"],[63967,1,\"\"],[63968,1,\"\"],[63969,1,\"\"],[63970,1,\"\"],[63971,1,\"\"],[63972,1,\"\"],[63973,1,\"\"],[63974,1,\"\"],[63975,1,\"\"],[63976,1,\"\"],[63977,1,\"\"],[63978,1,\"\"],[63979,1,\"\"],[63980,1,\"\"],[63981,1,\"\"],[63982,1,\"\"],[63983,1,\"\"],[63984,1,\"\"],[63985,1,\"\"],[63986,1,\"\"],[63987,1,\"\"],[63988,1,\"\"],[63989,1,\"\"],[63990,1,\"\"],[63991,1,\"\"],[63992,1,\"\"],[63993,1,\"\"],[63994,1,\"\"],[63995,1,\"\"],[63996,1,\"\"],[63997,1,\"\"],[63998,1,\"\"],[63999,1,\"\"],[64000,1,\"\"],[64001,1,\"\"],[64002,1,\"\"],[64003,1,\"\"],[64004,1,\"\"],[64005,1,\"\"],[64006,1,\"\"],[64007,1,\"\"],[64008,1,\"\"],[64009,1,\"\"],[64010,1,\"\"],[64011,1,\"\"],[64012,1,\"\"],[64013,1,\"\"],[[64014,64015],2],[64016,1,\"\"],[64017,2],[64018,1,\"\"],[[64019,64020],2],[64021,1,\"\"],[64022,1,\"\"],[64023,1,\"\"],[64024,1,\"\"],[64025,1,\"\"],[64026,1,\"\"],[64027,1,\"\"],[64028,1,\"\"],[64029,1,\"\"],[64030,1,\"\"],[64031,2],[64032,1,\"\"],[64033,2],[64034,1,\"\"],[[64035,64036],2],[64037,1,\"\"],[64038,1,\"\"],[[64039,64041],2],[64042,1,\"\"],[64043,1,\"\"],[64044,1,\"\"],[64045,1,\"\"],[64046,1,\"\"],[64047,1,\"\"],[64048,1,\"\"],[64049,1,\"\"],[64050,1,\"\"],[64051,1,\"\"],[64052,1,\"\"],[64053,1,\"\"],[64054,1,\"\"],[64055,1,\"\"],[64056,1,\"\"],[64057,1,\"\"],[64058,1,\"\"],[64059,1,\"\"],[64060,1,\"\"],[64061,1,\"\"],[64062,1,\"\"],[64063,1,\"\"],[64064,1,\"\"],[64065,1,\"\"],[64066,1,\"\"],[64067,1,\"\"],[64068,1,\"\"],[64069,1,\"\"],[64070,1,\"\"],[64071,1,\"\"],[64072,1,\"\"],[64073,1,\"\"],[64074,1,\"\"],[64075,1,\"\"],[64076,1,\"\"],[64077,1,\"\"],[64078,1,\"\"],[64079,1,\"\"],[64080,1,\"\"],[64081,1,\"\"],[64082,1,\"\"],[64083,1,\"\"],[64084,1,\"\"],[64085,1,\"\"],[64086,1,\"\"],[64087,1,\"\"],[64088,1,\"\"],[64089,1,\"\"],[64090,1,\"\"],[64091,1,\"\"],[64092,1,\"\"],[[64093,64094],1,\"\"],[64095,1,\"\"],[64096,1,\"\"],[64097,1,\"\"],[64098,1,\"\"],[64099,1,\"\"],[64100,1,\"\"],[64101,1,\"\"],[64102,1,\"\"],[64103,1,\"\"],[64104,1,\"\"],[64105,1,\"\"],[64106,1,\"\"],[64107,1,\"\"],[64108,1,\"\"],[64109,1,\"\"],[[64110,64111],3],[64112,1,\"\"],[64113,1,\"\"],[64114,1,\"\"],[64115,1,\"\"],[64116,1,\"\"],[64117,1,\"\"],[64118,1,\"\"],[64119,1,\"\"],[64120,1,\"\"],[64121,1,\"\"],[64122,1,\"\"],[64123,1,\"\"],[64124,1,\"\"],[64125,1,\"\"],[64126,1,\"\"],[64127,1,\"\"],[64128,1,\"\"],[64129,1,\"\"],[64130,1,\"\"],[64131,1,\"\"],[64132,1,\"\"],[64133,1,\"\"],[64134,1,\"\"],[64135,1,\"\"],[64136,1,\"\"],[64137,1,\"\"],[64138,1,\"\"],[64139,1,\"\"],[64140,1,\"\"],[64141,1,\"\"],[64142,1,\"\"],[64143,1,\"\"],[64144,1,\"\"],[64145,1,\"\"],[64146,1,\"\"],[64147,1,\"\"],[64148,1,\"\"],[64149,1,\"\"],[64150,1,\"\"],[64151,1,\"\"],[64152,1,\"\"],[64153,1,\"\"],[64154,1,\"\"],[64155,1,\"\"],[64156,1,\"\"],[64157,1,\"\"],[64158,1,\"\"],[64159,1,\"\"],[64160,1,\"\"],[64161,1,\"\"],[64162,1,\"\"],[64163,1,\"\"],[64164,1,\"\"],[64165,1,\"\"],[64166,1,\"\"],[64167,1,\"\"],[64168,1,\"\"],[64169,1,\"\"],[64170,1,\"\"],[64171,1,\"\"],[64172,1,\"\"],[64173,1,\"\"],[64174,1,\"\"],[64175,1,\"\"],[64176,1,\"\"],[64177,1,\"\"],[64178,1,\"\"],[64179,1,\"\"],[64180,1,\"\"],[64181,1,\"\"],[64182,1,\"\"],[64183,1,\"\"],[64184,1,\"\"],[64185,1,\"\"],[64186,1,\"\"],[64187,1,\"\"],[64188,1,\"\"],[64189,1,\"\"],[64190,1,\"\"],[64191,1,\"\"],[64192,1,\"\"],[64193,1,\"\"],[64194,1,\"\"],[64195,1,\"\"],[64196,1,\"\"],[64197,1,\"\"],[64198,1,\"\"],[64199,1,\"\"],[64200,1,\"\"],[64201,1,\"\"],[64202,1,\"\"],[64203,1,\"\"],[64204,1,\"\"],[64205,1,\"\"],[64206,1,\"\"],[64207,1,\"\"],[64208,1,\"\"],[64209,1,\"\"],[64210,1,\"\"],[64211,1,\"\"],[64212,1,\"\"],[64213,1,\"\"],[64214,1,\"\"],[64215,1,\"\"],[64216,1,\"\"],[64217,1,\"\"],[[64218,64255],3],[64256,1,\"ff\"],[64257,1,\"fi\"],[64258,1,\"fl\"],[64259,1,\"ffi\"],[64260,1,\"ffl\"],[[64261,64262],1,\"st\"],[[64263,64274],3],[64275,1,\"\"],[64276,1,\"\"],[64277,1,\"\"],[64278,1,\"\"],[64279,1,\"\"],[[64280,64284],3],[64285,1,\"\"],[64286,2],[64287,1,\"\"],[64288,1,\"\"],[64289,1,\"\"],[64290,1,\"\"],[64291,1,\"\"],[64292,1,\"\"],[64293,1,\"\"],[64294,1,\"\"],[64295,1,\"\"],[64296,1,\"\"],[64297,5,\"+\"],[64298,1,\"\"],[64299,1,\"\"],[64300,1,\"\"],[64301,1,\"\"],[64302,1,\"\"],[64303,1,\"\"],[64304,1,\"\"],[64305,1,\"\"],[64306,1,\"\"],[64307,1,\"\"],[64308,1,\"\"],[64309,1,\"\"],[64310,1,\"\"],[64311,3],[64312,1,\"\"],[64313,1,\"\"],[64314,1,\"\"],[64315,1,\"\"],[64316,1,\"\"],[64317,3],[64318,1,\"\"],[64319,3],[64320,1,\"\"],[64321,1,\"\"],[64322,3],[64323,1,\"\"],[64324,1,\"\"],[64325,3],[64326,1,\"\"],[64327,1,\"\"],[64328,1,\"\"],[64329,1,\"\"],[64330,1,\"\"],[64331,1,\"\"],[64332,1,\"\"],[64333,1,\"\"],[64334,1,\"\"],[64335,1,\"\"],[[64336,64337],1,\"\"],[[64338,64341],1,\"\"],[[64342,64345],1,\"\"],[[64346,64349],1,\"\"],[[64350,64353],1,\"\"],[[64354,64357],1,\"\"],[[64358,64361],1,\"\"],[[64362,64365],1,\"\"],[[64366,64369],1,\"\"],[[64370,64373],1,\"\"],[[64374,64377],1,\"\"],[[64378,64381],1,\"\"],[[64382,64385],1,\"\"],[[64386,64387],1,\"\"],[[64388,64389],1,\"\"],[[64390,64391],1,\"\"],[[64392,64393],1,\"\"],[[64394,64395],1,\"\"],[[64396,64397],1,\"\"],[[64398,64401],1,\"\"],[[64402,64405],1,\"\"],[[64406,64409],1,\"\"],[[64410,64413],1,\"\"],[[64414,64415],1,\"\"],[[64416,64419],1,\"\"],[[64420,64421],1,\"\"],[[64422,64425],1,\"\"],[[64426,64429],1,\"\"],[[64430,64431],1,\"\"],[[64432,64433],1,\"\"],[[64434,64449],2],[64450,2],[[64451,64466],3],[[64467,64470],1,\"\"],[[64471,64472],1,\"\"],[[64473,64474],1,\"\"],[[64475,64476],1,\"\"],[64477,1,\"\"],[[64478,64479],1,\"\"],[[64480,64481],1,\"\"],[[64482,64483],1,\"\"],[[64484,64487],1,\"\"],[[64488,64489],1,\"\"],[[64490,64491],1,\"\"],[[64492,64493],1,\"\"],[[64494,64495],1,\"\"],[[64496,64497],1,\"\"],[[64498,64499],1,\"\"],[[64500,64501],1,\"\"],[[64502,64504],1,\"\"],[[64505,64507],1,\"\"],[[64508,64511],1,\"\"],[64512,1,\"\"],[64513,1,\"\"],[64514,1,\"\"],[64515,1,\"\"],[64516,1,\"\"],[64517,1,\"\"],[64518,1,\"\"],[64519,1,\"\"],[64520,1,\"\"],[64521,1,\"\"],[64522,1,\"\"],[64523,1,\"\"],[64524,1,\"\"],[64525,1,\"\"],[64526,1,\"\"],[64527,1,\"\"],[64528,1,\"\"],[64529,1,\"\"],[64530,1,\"\"],[64531,1,\"\"],[64532,1,\"\"],[64533,1,\"\"],[64534,1,\"\"],[64535,1,\"\"],[64536,1,\"\"],[64537,1,\"\"],[64538,1,\"\"],[64539,1,\"\"],[64540,1,\"\"],[64541,1,\"\"],[64542,1,\"\"],[64543,1,\"\"],[64544,1,\"\"],[64545,1,\"\"],[64546,1,\"\"],[64547,1,\"\"],[64548,1,\"\"],[64549,1,\"\"],[64550,1,\"\"],[64551,1,\"\"],[64552,1,\"\"],[64553,1,\"\"],[64554,1,\"\"],[64555,1,\"\"],[64556,1,\"\"],[64557,1,\"\"],[64558,1,\"\"],[64559,1,\"\"],[64560,1,\"\"],[64561,1,\"\"],[64562,1,\"\"],[64563,1,\"\"],[64564,1,\"\"],[64565,1,\"\"],[64566,1,\"\"],[64567,1,\"\"],[64568,1,\"\"],[64569,1,\"\"],[64570,1,\"\"],[64571,1,\"\"],[64572,1,\"\"],[64573,1,\"\"],[64574,1,\"\"],[64575,1,\"\"],[64576,1,\"\"],[64577,1,\"\"],[64578,1,\"\"],[64579,1,\"\"],[64580,1,\"\"],[64581,1,\"\"],[64582,1,\"\"],[64583,1,\"\"],[64584,1,\"\"],[64585,1,\"\"],[64586,1,\"\"],[64587,1,\"\"],[64588,1,\"\"],[64589,1,\"\"],[64590,1,\"\"],[64591,1,\"\"],[64592,1,\"\"],[64593,1,\"\"],[64594,1,\"\"],[64595,1,\"\"],[64596,1,\"\"],[64597,1,\"\"],[64598,1,\"\"],[64599,1,\"\"],[64600,1,\"\"],[64601,1,\"\"],[64602,1,\"\"],[64603,1,\"\"],[64604,1,\"\"],[64605,1,\"\"],[64606,5,\" \"],[64607,5,\" \"],[64608,5,\" \"],[64609,5,\" \"],[64610,5,\" \"],[64611,5,\" \"],[64612,1,\"\"],[64613,1,\"\"],[64614,1,\"\"],[64615,1,\"\"],[64616,1,\"\"],[64617,1,\"\"],[64618,1,\"\"],[64619,1,\"\"],[64620,1,\"\"],[64621,1,\"\"],[64622,1,\"\"],[64623,1,\"\"],[64624,1,\"\"],[64625,1,\"\"],[64626,1,\"\"],[64627,1,\"\"],[64628,1,\"\"],[64629,1,\"\"],[64630,1,\"\"],[64631,1,\"\"],[64632,1,\"\"],[64633,1,\"\"],[64634,1,\"\"],[64635,1,\"\"],[64636,1,\"\"],[64637,1,\"\"],[64638,1,\"\"],[64639,1,\"\"],[64640,1,\"\"],[64641,1,\"\"],[64642,1,\"\"],[64643,1,\"\"],[64644,1,\"\"],[64645,1,\"\"],[64646,1,\"\"],[64647,1,\"\"],[64648,1,\"\"],[64649,1,\"\"],[64650,1,\"\"],[64651,1,\"\"],[64652,1,\"\"],[64653,1,\"\"],[64654,1,\"\"],[64655,1,\"\"],[64656,1,\"\"],[64657,1,\"\"],[64658,1,\"\"],[64659,1,\"\"],[64660,1,\"\"],[64661,1,\"\"],[64662,1,\"\"],[64663,1,\"\"],[64664,1,\"\"],[64665,1,\"\"],[64666,1,\"\"],[64667,1,\"\"],[64668,1,\"\"],[64669,1,\"\"],[64670,1,\"\"],[64671,1,\"\"],[64672,1,\"\"],[64673,1,\"\"],[64674,1,\"\"],[64675,1,\"\"],[64676,1,\"\"],[64677,1,\"\"],[64678,1,\"\"],[64679,1,\"\"],[64680,1,\"\"],[64681,1,\"\"],[64682,1,\"\"],[64683,1,\"\"],[64684,1,\"\"],[64685,1,\"\"],[64686,1,\"\"],[64687,1,\"\"],[64688,1,\"\"],[64689,1,\"\"],[64690,1,\"\"],[64691,1,\"\"],[64692,1,\"\"],[64693,1,\"\"],[64694,1,\"\"],[64695,1,\"\"],[64696,1,\"\"],[64697,1,\"\"],[64698,1,\"\"],[64699,1,\"\"],[64700,1,\"\"],[64701,1,\"\"],[64702,1,\"\"],[64703,1,\"\"],[64704,1,\"\"],[64705,1,\"\"],[64706,1,\"\"],[64707,1,\"\"],[64708,1,\"\"],[64709,1,\"\"],[64710,1,\"\"],[64711,1,\"\"],[64712,1,\"\"],[64713,1,\"\"],[64714,1,\"\"],[64715,1,\"\"],[64716,1,\"\"],[64717,1,\"\"],[64718,1,\"\"],[64719,1,\"\"],[64720,1,\"\"],[64721,1,\"\"],[64722,1,\"\"],[64723,1,\"\"],[64724,1,\"\"],[64725,1,\"\"],[64726,1,\"\"],[64727,1,\"\"],[64728,1,\"\"],[64729,1,\"\"],[64730,1,\"\"],[64731,1,\"\"],[64732,1,\"\"],[64733,1,\"\"],[64734,1,\"\"],[64735,1,\"\"],[64736,1,\"\"],[64737,1,\"\"],[64738,1,\"\"],[64739,1,\"\"],[64740,1,\"\"],[64741,1,\"\"],[64742,1,\"\"],[64743,1,\"\"],[64744,1,\"\"],[64745,1,\"\"],[64746,1,\"\"],[64747,1,\"\"],[64748,1,\"\"],[64749,1,\"\"],[64750,1,\"\"],[64751,1,\"\"],[64752,1,\"\"],[64753,1,\"\"],[64754,1,\"\"],[64755,1,\"\"],[64756,1,\"\"],[64757,1,\"\"],[64758,1,\"\"],[64759,1,\"\"],[64760,1,\"\"],[64761,1,\"\"],[64762,1,\"\"],[64763,1,\"\"],[64764,1,\"\"],[64765,1,\"\"],[64766,1,\"\"],[64767,1,\"\"],[64768,1,\"\"],[64769,1,\"\"],[64770,1,\"\"],[64771,1,\"\"],[64772,1,\"\"],[64773,1,\"\"],[64774,1,\"\"],[64775,1,\"\"],[64776,1,\"\"],[64777,1,\"\"],[64778,1,\"\"],[64779,1,\"\"],[64780,1,\"\"],[64781,1,\"\"],[64782,1,\"\"],[64783,1,\"\"],[64784,1,\"\"],[64785,1,\"\"],[64786,1,\"\"],[64787,1,\"\"],[64788,1,\"\"],[64789,1,\"\"],[64790,1,\"\"],[64791,1,\"\"],[64792,1,\"\"],[64793,1,\"\"],[64794,1,\"\"],[64795,1,\"\"],[64796,1,\"\"],[64797,1,\"\"],[64798,1,\"\"],[64799,1,\"\"],[64800,1,\"\"],[64801,1,\"\"],[64802,1,\"\"],[64803,1,\"\"],[64804,1,\"\"],[64805,1,\"\"],[64806,1,\"\"],[64807,1,\"\"],[64808,1,\"\"],[64809,1,\"\"],[64810,1,\"\"],[64811,1,\"\"],[64812,1,\"\"],[64813,1,\"\"],[64814,1,\"\"],[64815,1,\"\"],[64816,1,\"\"],[64817,1,\"\"],[64818,1,\"\"],[64819,1,\"\"],[64820,1,\"\"],[64821,1,\"\"],[64822,1,\"\"],[64823,1,\"\"],[64824,1,\"\"],[64825,1,\"\"],[64826,1,\"\"],[64827,1,\"\"],[[64828,64829],1,\"\"],[[64830,64831],2],[[64832,64847],2],[64848,1,\"\"],[[64849,64850],1,\"\"],[64851,1,\"\"],[64852,1,\"\"],[64853,1,\"\"],[64854,1,\"\"],[64855,1,\"\"],[[64856,64857],1,\"\"],[64858,1,\"\"],[64859,1,\"\"],[64860,1,\"\"],[64861,1,\"\"],[64862,1,\"\"],[[64863,64864],1,\"\"],[64865,1,\"\"],[[64866,64867],1,\"\"],[[64868,64869],1,\"\"],[64870,1,\"\"],[[64871,64872],1,\"\"],[64873,1,\"\"],[[64874,64875],1,\"\"],[[64876,64877],1,\"\"],[64878,1,\"\"],[[64879,64880],1,\"\"],[[64881,64882],1,\"\"],[64883,1,\"\"],[64884,1,\"\"],[64885,1,\"\"],[[64886,64887],1,\"\"],[64888,1,\"\"],[64889,1,\"\"],[64890,1,\"\"],[64891,1,\"\"],[[64892,64893],1,\"\"],[64894,1,\"\"],[64895,1,\"\"],[64896,1,\"\"],[64897,1,\"\"],[64898,1,\"\"],[[64899,64900],1,\"\"],[[64901,64902],1,\"\"],[[64903,64904],1,\"\"],[64905,1,\"\"],[64906,1,\"\"],[64907,1,\"\"],[64908,1,\"\"],[64909,1,\"\"],[64910,1,\"\"],[64911,1,\"\"],[[64912,64913],3],[64914,1,\"\"],[64915,1,\"\"],[64916,1,\"\"],[64917,1,\"\"],[64918,1,\"\"],[[64919,64920],1,\"\"],[64921,1,\"\"],[64922,1,\"\"],[64923,1,\"\"],[[64924,64925],1,\"\"],[64926,1,\"\"],[64927,1,\"\"],[64928,1,\"\"],[64929,1,\"\"],[64930,1,\"\"],[64931,1,\"\"],[64932,1,\"\"],[64933,1,\"\"],[64934,1,\"\"],[64935,1,\"\"],[64936,1,\"\"],[64937,1,\"\"],[64938,1,\"\"],[64939,1,\"\"],[64940,1,\"\"],[64941,1,\"\"],[64942,1,\"\"],[64943,1,\"\"],[64944,1,\"\"],[64945,1,\"\"],[64946,1,\"\"],[64947,1,\"\"],[64948,1,\"\"],[64949,1,\"\"],[64950,1,\"\"],[64951,1,\"\"],[64952,1,\"\"],[64953,1,\"\"],[64954,1,\"\"],[64955,1,\"\"],[64956,1,\"\"],[64957,1,\"\"],[64958,1,\"\"],[64959,1,\"\"],[64960,1,\"\"],[64961,1,\"\"],[64962,1,\"\"],[64963,1,\"\"],[64964,1,\"\"],[64965,1,\"\"],[64966,1,\"\"],[64967,1,\"\"],[[64968,64974],3],[64975,2],[[64976,65007],3],[65008,1,\"\"],[65009,1,\"\"],[65010,1,\"\"],[65011,1,\"\"],[65012,1,\"\"],[65013,1,\"\"],[65014,1,\"\"],[65015,1,\"\"],[65016,1,\"\"],[65017,1,\"\"],[65018,5,\"   \"],[65019,5,\" \"],[65020,1,\"\"],[65021,2],[[65022,65023],2],[[65024,65039],7],[65040,5,\",\"],[65041,1,\"\"],[65042,3],[65043,5,\":\"],[65044,5,\";\"],[65045,5,\"!\"],[65046,5,\"?\"],[65047,1,\"\"],[65048,1,\"\"],[65049,3],[[65050,65055],3],[[65056,65059],2],[[65060,65062],2],[[65063,65069],2],[[65070,65071],2],[65072,3],[65073,1,\"\"],[65074,1,\"\"],[[65075,65076],5,\"_\"],[65077,5,\"(\"],[65078,5,\")\"],[65079,5,\"{\"],[65080,5,\"}\"],[65081,1,\"\"],[65082,1,\"\"],[65083,1,\"\"],[65084,1,\"\"],[65085,1,\"\"],[65086,1,\"\"],[65087,1,\"\"],[65088,1,\"\"],[65089,1,\"\"],[65090,1,\"\"],[65091,1,\"\"],[65092,1,\"\"],[[65093,65094],2],[65095,5,\"[\"],[65096,5,\"]\"],[[65097,65100],5,\" \"],[[65101,65103],5,\"_\"],[65104,5,\",\"],[65105,1,\"\"],[65106,3],[65107,3],[65108,5,\";\"],[65109,5,\":\"],[65110,5,\"?\"],[65111,5,\"!\"],[65112,1,\"\"],[65113,5,\"(\"],[65114,5,\")\"],[65115,5,\"{\"],[65116,5,\"}\"],[65117,1,\"\"],[65118,1,\"\"],[65119,5,\"#\"],[65120,5,\"&\"],[65121,5,\"*\"],[65122,5,\"+\"],[65123,1,\"-\"],[65124,5,\"<\"],[65125,5,\">\"],[65126,5,\"=\"],[65127,3],[65128,5,\"\\\\\\\\\"],[65129,5,\"$\"],[65130,5,\"%\"],[65131,5,\"@\"],[[65132,65135],3],[65136,5,\" \"],[65137,1,\"\"],[65138,5,\" \"],[65139,2],[65140,5,\" \"],[65141,3],[65142,5,\" \"],[65143,1,\"\"],[65144,5,\" \"],[65145,1,\"\"],[65146,5,\" \"],[65147,1,\"\"],[65148,5,\" \"],[65149,1,\"\"],[65150,5,\" \"],[65151,1,\"\"],[65152,1,\"\"],[[65153,65154],1,\"\"],[[65155,65156],1,\"\"],[[65157,65158],1,\"\"],[[65159,65160],1,\"\"],[[65161,65164],1,\"\"],[[65165,65166],1,\"\"],[[65167,65170],1,\"\"],[[65171,65172],1,\"\"],[[65173,65176],1,\"\"],[[65177,65180],1,\"\"],[[65181,65184],1,\"\"],[[65185,65188],1,\"\"],[[65189,65192],1,\"\"],[[65193,65194],1,\"\"],[[65195,65196],1,\"\"],[[65197,65198],1,\"\"],[[65199,65200],1,\"\"],[[65201,65204],1,\"\"],[[65205,65208],1,\"\"],[[65209,65212],1,\"\"],[[65213,65216],1,\"\"],[[65217,65220],1,\"\"],[[65221,65224],1,\"\"],[[65225,65228],1,\"\"],[[65229,65232],1,\"\"],[[65233,65236],1,\"\"],[[65237,65240],1,\"\"],[[65241,65244],1,\"\"],[[65245,65248],1,\"\"],[[65249,65252],1,\"\"],[[65253,65256],1,\"\"],[[65257,65260],1,\"\"],[[65261,65262],1,\"\"],[[65263,65264],1,\"\"],[[65265,65268],1,\"\"],[[65269,65270],1,\"\"],[[65271,65272],1,\"\"],[[65273,65274],1,\"\"],[[65275,65276],1,\"\"],[[65277,65278],3],[65279,7],[65280,3],[65281,5,\"!\"],[65282,5,\"\\\\\"\"],[65283,5,\"#\"],[65284,5,\"$\"],[65285,5,\"%\"],[65286,5,\"&\"],[65287,5,\"\\'\"],[65288,5,\"(\"],[65289,5,\")\"],[65290,5,\"*\"],[65291,5,\"+\"],[65292,5,\",\"],[65293,1,\"-\"],[65294,1,\".\"],[65295,5,\"/\"],[65296,1,\"0\"],[65297,1,\"1\"],[65298,1,\"2\"],[65299,1,\"3\"],[65300,1,\"4\"],[65301,1,\"5\"],[65302,1,\"6\"],[65303,1,\"7\"],[65304,1,\"8\"],[65305,1,\"9\"],[65306,5,\":\"],[65307,5,\";\"],[65308,5,\"<\"],[65309,5,\"=\"],[65310,5,\">\"],[65311,5,\"?\"],[65312,5,\"@\"],[65313,1,\"a\"],[65314,1,\"b\"],[65315,1,\"c\"],[65316,1,\"d\"],[65317,1,\"e\"],[65318,1,\"f\"],[65319,1,\"g\"],[65320,1,\"h\"],[65321,1,\"i\"],[65322,1,\"j\"],[65323,1,\"k\"],[65324,1,\"l\"],[65325,1,\"m\"],[65326,1,\"n\"],[65327,1,\"o\"],[65328,1,\"p\"],[65329,1,\"q\"],[65330,1,\"r\"],[65331,1,\"s\"],[65332,1,\"t\"],[65333,1,\"u\"],[65334,1,\"v\"],[65335,1,\"w\"],[65336,1,\"x\"],[65337,1,\"y\"],[65338,1,\"z\"],[65339,5,\"[\"],[65340,5,\"\\\\\\\\\"],[65341,5,\"]\"],[65342,5,\"^\"],[65343,5,\"_\"],[65344,5,\"`\"],[65345,1,\"a\"],[65346,1,\"b\"],[65347,1,\"c\"],[65348,1,\"d\"],[65349,1,\"e\"],[65350,1,\"f\"],[65351,1,\"g\"],[65352,1,\"h\"],[65353,1,\"i\"],[65354,1,\"j\"],[65355,1,\"k\"],[65356,1,\"l\"],[65357,1,\"m\"],[65358,1,\"n\"],[65359,1,\"o\"],[65360,1,\"p\"],[65361,1,\"q\"],[65362,1,\"r\"],[65363,1,\"s\"],[65364,1,\"t\"],[65365,1,\"u\"],[65366,1,\"v\"],[65367,1,\"w\"],[65368,1,\"x\"],[65369,1,\"y\"],[65370,1,\"z\"],[65371,5,\"{\"],[65372,5,\"|\"],[65373,5,\"}\"],[65374,5,\"~\"],[65375,1,\"\"],[65376,1,\"\"],[65377,1,\".\"],[65378,1,\"\"],[65379,1,\"\"],[65380,1,\"\"],[65381,1,\"\"],[65382,1,\"\"],[65383,1,\"\"],[65384,1,\"\"],[65385,1,\"\"],[65386,1,\"\"],[65387,1,\"\"],[65388,1,\"\"],[65389,1,\"\"],[65390,1,\"\"],[65391,1,\"\"],[65392,1,\"\"],[65393,1,\"\"],[65394,1,\"\"],[65395,1,\"\"],[65396,1,\"\"],[65397,1,\"\"],[65398,1,\"\"],[65399,1,\"\"],[65400,1,\"\"],[65401,1,\"\"],[65402,1,\"\"],[65403,1,\"\"],[65404,1,\"\"],[65405,1,\"\"],[65406,1,\"\"],[65407,1,\"\"],[65408,1,\"\"],[65409,1,\"\"],[65410,1,\"\"],[65411,1,\"\"],[65412,1,\"\"],[65413,1,\"\"],[65414,1,\"\"],[65415,1,\"\"],[65416,1,\"\"],[65417,1,\"\"],[65418,1,\"\"],[65419,1,\"\"],[65420,1,\"\"],[65421,1,\"\"],[65422,1,\"\"],[65423,1,\"\"],[65424,1,\"\"],[65425,1,\"\"],[65426,1,\"\"],[65427,1,\"\"],[65428,1,\"\"],[65429,1,\"\"],[65430,1,\"\"],[65431,1,\"\"],[65432,1,\"\"],[65433,1,\"\"],[65434,1,\"\"],[65435,1,\"\"],[65436,1,\"\"],[65437,1,\"\"],[65438,1,\"\"],[65439,1,\"\"],[65440,3],[65441,1,\"\"],[65442,1,\"\"],[65443,1,\"\"],[65444,1,\"\"],[65445,1,\"\"],[65446,1,\"\"],[65447,1,\"\"],[65448,1,\"\"],[65449,1,\"\"],[65450,1,\"\"],[65451,1,\"\"],[65452,1,\"\"],[65453,1,\"\"],[65454,1,\"\"],[65455,1,\"\"],[65456,1,\"\"],[65457,1,\"\"],[65458,1,\"\"],[65459,1,\"\"],[65460,1,\"\"],[65461,1,\"\"],[65462,1,\"\"],[65463,1,\"\"],[65464,1,\"\"],[65465,1,\"\"],[65466,1,\"\"],[65467,1,\"\"],[65468,1,\"\"],[65469,1,\"\"],[65470,1,\"\"],[[65471,65473],3],[65474,1,\"\"],[65475,1,\"\"],[65476,1,\"\"],[65477,1,\"\"],[65478,1,\"\"],[65479,1,\"\"],[[65480,65481],3],[65482,1,\"\"],[65483,1,\"\"],[65484,1,\"\"],[65485,1,\"\"],[65486,1,\"\"],[65487,1,\"\"],[[65488,65489],3],[65490,1,\"\"],[65491,1,\"\"],[65492,1,\"\"],[65493,1,\"\"],[65494,1,\"\"],[65495,1,\"\"],[[65496,65497],3],[65498,1,\"\"],[65499,1,\"\"],[65500,1,\"\"],[[65501,65503],3],[65504,1,\"\"],[65505,1,\"\"],[65506,1,\"\"],[65507,5,\" \"],[65508,1,\"\"],[65509,1,\"\"],[65510,1,\"\"],[65511,3],[65512,1,\"\"],[65513,1,\"\"],[65514,1,\"\"],[65515,1,\"\"],[65516,1,\"\"],[65517,1,\"\"],[65518,1,\"\"],[[65519,65528],3],[[65529,65531],3],[65532,3],[65533,3],[[65534,65535],3],[[65536,65547],2],[65548,3],[[65549,65574],2],[65575,3],[[65576,65594],2],[65595,3],[[65596,65597],2],[65598,3],[[65599,65613],2],[[65614,65615],3],[[65616,65629],2],[[65630,65663],3],[[65664,65786],2],[[65787,65791],3],[[65792,65794],2],[[65795,65798],3],[[65799,65843],2],[[65844,65846],3],[[65847,65855],2],[[65856,65930],2],[[65931,65932],2],[[65933,65934],2],[65935,3],[[65936,65947],2],[65948,2],[[65949,65951],3],[65952,2],[[65953,65999],3],[[66000,66044],2],[66045,2],[[66046,66175],3],[[66176,66204],2],[[66205,66207],3],[[66208,66256],2],[[66257,66271],3],[66272,2],[[66273,66299],2],[[66300,66303],3],[[66304,66334],2],[66335,2],[[66336,66339],2],[[66340,66348],3],[[66349,66351],2],[[66352,66368],2],[66369,2],[[66370,66377],2],[66378,2],[[66379,66383],3],[[66384,66426],2],[[66427,66431],3],[[66432,66461],2],[66462,3],[66463,2],[[66464,66499],2],[[66500,66503],3],[[66504,66511],2],[[66512,66517],2],[[66518,66559],3],[66560,1,\"\"],[66561,1,\"\"],[66562,1,\"\"],[66563,1,\"\"],[66564,1,\"\"],[66565,1,\"\"],[66566,1,\"\"],[66567,1,\"\"],[66568,1,\"\"],[66569,1,\"\"],[66570,1,\"\"],[66571,1,\"\"],[66572,1,\"\"],[66573,1,\"\"],[66574,1,\"\"],[66575,1,\"\"],[66576,1,\"\"],[66577,1,\"\"],[66578,1,\"\"],[66579,1,\"\"],[66580,1,\"\"],[66581,1,\"\"],[66582,1,\"\"],[66583,1,\"\"],[66584,1,\"\"],[66585,1,\"\"],[66586,1,\"\"],[66587,1,\"\"],[66588,1,\"\"],[66589,1,\"\"],[66590,1,\"\"],[66591,1,\"\"],[66592,1,\"\"],[66593,1,\"\"],[66594,1,\"\"],[66595,1,\"\"],[66596,1,\"\"],[66597,1,\"\"],[66598,1,\"\"],[66599,1,\"\"],[[66600,66637],2],[[66638,66717],2],[[66718,66719],3],[[66720,66729],2],[[66730,66735],3],[66736,1,\"\"],[66737,1,\"\"],[66738,1,\"\"],[66739,1,\"\"],[66740,1,\"\"],[66741,1,\"\"],[66742,1,\"\"],[66743,1,\"\"],[66744,1,\"\"],[66745,1,\"\"],[66746,1,\"\"],[66747,1,\"\"],[66748,1,\"\"],[66749,1,\"\"],[66750,1,\"\"],[66751,1,\"\"],[66752,1,\"\"],[66753,1,\"\"],[66754,1,\"\"],[66755,1,\"\"],[66756,1,\"\"],[66757,1,\"\"],[66758,1,\"\"],[66759,1,\"\"],[66760,1,\"\"],[66761,1,\"\"],[66762,1,\"\"],[66763,1,\"\"],[66764,1,\"\"],[66765,1,\"\"],[66766,1,\"\"],[66767,1,\"\"],[66768,1,\"\"],[66769,1,\"\"],[66770,1,\"\"],[66771,1,\"\"],[[66772,66775],3],[[66776,66811],2],[[66812,66815],3],[[66816,66855],2],[[66856,66863],3],[[66864,66915],2],[[66916,66926],3],[66927,2],[66928,1,\"\"],[66929,1,\"\"],[66930,1,\"\"],[66931,1,\"\"],[66932,1,\"\"],[66933,1,\"\"],[66934,1,\"\"],[66935,1,\"\"],[66936,1,\"\"],[66937,1,\"\"],[66938,1,\"\"],[66939,3],[66940,1,\"\"],[66941,1,\"\"],[66942,1,\"\"],[66943,1,\"\"],[66944,1,\"\"],[66945,1,\"\"],[66946,1,\"\"],[66947,1,\"\"],[66948,1,\"\"],[66949,1,\"\"],[66950,1,\"\"],[66951,1,\"\"],[66952,1,\"\"],[66953,1,\"\"],[66954,1,\"\"],[66955,3],[66956,1,\"\"],[66957,1,\"\"],[66958,1,\"\"],[66959,1,\"\"],[66960,1,\"\"],[66961,1,\"\"],[66962,1,\"\"],[66963,3],[66964,1,\"\"],[66965,1,\"\"],[66966,3],[[66967,66977],2],[66978,3],[[66979,66993],2],[66994,3],[[66995,67001],2],[67002,3],[[67003,67004],2],[[67005,67071],3],[[67072,67382],2],[[67383,67391],3],[[67392,67413],2],[[67414,67423],3],[[67424,67431],2],[[67432,67455],3],[67456,2],[67457,1,\"\"],[67458,1,\"\"],[67459,1,\"\"],[67460,1,\"\"],[67461,1,\"\"],[67462,3],[67463,1,\"\"],[67464,1,\"\"],[67465,1,\"\"],[67466,1,\"\"],[67467,1,\"\"],[67468,1,\"\"],[67469,1,\"\"],[67470,1,\"\"],[67471,1,\"\"],[67472,1,\"\"],[67473,1,\"\"],[67474,1,\"\"],[67475,1,\"\"],[67476,1,\"\"],[67477,1,\"\"],[67478,1,\"\"],[67479,1,\"\"],[67480,1,\"\"],[67481,1,\"\"],[67482,1,\"\"],[67483,1,\"\"],[67484,1,\"\"],[67485,1,\"\"],[67486,1,\"\"],[67487,1,\"\"],[67488,1,\"\"],[67489,1,\"\"],[67490,1,\"\"],[67491,1,\"\"],[67492,1,\"\"],[67493,1,\"q\"],[67494,1,\"\"],[67495,1,\"\"],[67496,1,\"\"],[67497,1,\"\"],[67498,1,\"\"],[67499,1,\"\"],[67500,1,\"\"],[67501,1,\"\"],[67502,1,\"\"],[67503,1,\"\"],[67504,1,\"\"],[67505,3],[67506,1,\"\"],[67507,1,\"\"],[67508,1,\"\"],[67509,1,\"\"],[67510,1,\"\"],[67511,1,\"\"],[67512,1,\"\"],[67513,1,\"\"],[67514,1,\"\"],[[67515,67583],3],[[67584,67589],2],[[67590,67591],3],[67592,2],[67593,3],[[67594,67637],2],[67638,3],[[67639,67640],2],[[67641,67643],3],[67644,2],[[67645,67646],3],[67647,2],[[67648,67669],2],[67670,3],[[67671,67679],2],[[67680,67702],2],[[67703,67711],2],[[67712,67742],2],[[67743,67750],3],[[67751,67759],2],[[67760,67807],3],[[67808,67826],2],[67827,3],[[67828,67829],2],[[67830,67834],3],[[67835,67839],2],[[67840,67861],2],[[67862,67865],2],[[67866,67867],2],[[67868,67870],3],[67871,2],[[67872,67897],2],[[67898,67902],3],[67903,2],[[67904,67967],3],[[67968,68023],2],[[68024,68027],3],[[68028,68029],2],[[68030,68031],2],[[68032,68047],2],[[68048,68049],3],[[68050,68095],2],[[68096,68099],2],[68100,3],[[68101,68102],2],[[68103,68107],3],[[68108,68115],2],[68116,3],[[68117,68119],2],[68120,3],[[68121,68147],2],[[68148,68149],2],[[68150,68151],3],[[68152,68154],2],[[68155,68158],3],[68159,2],[[68160,68167],2],[68168,2],[[68169,68175],3],[[68176,68184],2],[[68185,68191],3],[[68192,68220],2],[[68221,68223],2],[[68224,68252],2],[[68253,68255],2],[[68256,68287],3],[[68288,68295],2],[68296,2],[[68297,68326],2],[[68327,68330],3],[[68331,68342],2],[[68343,68351],3],[[68352,68405],2],[[68406,68408],3],[[68409,68415],2],[[68416,68437],2],[[68438,68439],3],[[68440,68447],2],[[68448,68466],2],[[68467,68471],3],[[68472,68479],2],[[68480,68497],2],[[68498,68504],3],[[68505,68508],2],[[68509,68520],3],[[68521,68527],2],[[68528,68607],3],[[68608,68680],2],[[68681,68735],3],[68736,1,\"\"],[68737,1,\"\"],[68738,1,\"\"],[68739,1,\"\"],[68740,1,\"\"],[68741,1,\"\"],[68742,1,\"\"],[68743,1,\"\"],[68744,1,\"\"],[68745,1,\"\"],[68746,1,\"\"],[68747,1,\"\"],[68748,1,\"\"],[68749,1,\"\"],[68750,1,\"\"],[68751,1,\"\"],[68752,1,\"\"],[68753,1,\"\"],[68754,1,\"\"],[68755,1,\"\"],[68756,1,\"\"],[68757,1,\"\"],[68758,1,\"\"],[68759,1,\"\"],[68760,1,\"\"],[68761,1,\"\"],[68762,1,\"\"],[68763,1,\"\"],[68764,1,\"\"],[68765,1,\"\"],[68766,1,\"\"],[68767,1,\"\"],[68768,1,\"\"],[68769,1,\"\"],[68770,1,\"\"],[68771,1,\"\"],[68772,1,\"\"],[68773,1,\"\"],[68774,1,\"\"],[68775,1,\"\"],[68776,1,\"\"],[68777,1,\"\"],[68778,1,\"\"],[68779,1,\"\"],[68780,1,\"\"],[68781,1,\"\"],[68782,1,\"\"],[68783,1,\"\"],[68784,1,\"\"],[68785,1,\"\"],[68786,1,\"\"],[[68787,68799],3],[[68800,68850],2],[[68851,68857],3],[[68858,68863],2],[[68864,68903],2],[[68904,68911],3],[[68912,68921],2],[[68922,69215],3],[[69216,69246],2],[69247,3],[[69248,69289],2],[69290,3],[[69291,69292],2],[69293,2],[[69294,69295],3],[[69296,69297],2],[[69298,69372],3],[[69373,69375],2],[[69376,69404],2],[[69405,69414],2],[69415,2],[[69416,69423],3],[[69424,69456],2],[[69457,69465],2],[[69466,69487],3],[[69488,69509],2],[[69510,69513],2],[[69514,69551],3],[[69552,69572],2],[[69573,69579],2],[[69580,69599],3],[[69600,69622],2],[[69623,69631],3],[[69632,69702],2],[[69703,69709],2],[[69710,69713],3],[[69714,69733],2],[[69734,69743],2],[[69744,69749],2],[[69750,69758],3],[69759,2],[[69760,69818],2],[[69819,69820],2],[69821,3],[[69822,69825],2],[69826,2],[[69827,69836],3],[69837,3],[[69838,69839],3],[[69840,69864],2],[[69865,69871],3],[[69872,69881],2],[[69882,69887],3],[[69888,69940],2],[69941,3],[[69942,69951],2],[[69952,69955],2],[[69956,69958],2],[69959,2],[[69960,69967],3],[[69968,70003],2],[[70004,70005],2],[70006,2],[[70007,70015],3],[[70016,70084],2],[[70085,70088],2],[[70089,70092],2],[70093,2],[[70094,70095],2],[[70096,70105],2],[70106,2],[70107,2],[70108,2],[[70109,70111],2],[70112,3],[[70113,70132],2],[[70133,70143],3],[[70144,70161],2],[70162,3],[[70163,70199],2],[[70200,70205],2],[70206,2],[[70207,70209],2],[[70210,70271],3],[[70272,70278],2],[70279,3],[70280,2],[70281,3],[[70282,70285],2],[70286,3],[[70287,70301],2],[70302,3],[[70303,70312],2],[70313,2],[[70314,70319],3],[[70320,70378],2],[[70379,70383],3],[[70384,70393],2],[[70394,70399],3],[70400,2],[[70401,70403],2],[70404,3],[[70405,70412],2],[[70413,70414],3],[[70415,70416],2],[[70417,70418],3],[[70419,70440],2],[70441,3],[[70442,70448],2],[70449,3],[[70450,70451],2],[70452,3],[[70453,70457],2],[70458,3],[70459,2],[[70460,70468],2],[[70469,70470],3],[[70471,70472],2],[[70473,70474],3],[[70475,70477],2],[[70478,70479],3],[70480,2],[[70481,70486],3],[70487,2],[[70488,70492],3],[[70493,70499],2],[[70500,70501],3],[[70502,70508],2],[[70509,70511],3],[[70512,70516],2],[[70517,70655],3],[[70656,70730],2],[[70731,70735],2],[[70736,70745],2],[70746,2],[70747,2],[70748,3],[70749,2],[70750,2],[70751,2],[[70752,70753],2],[[70754,70783],3],[[70784,70853],2],[70854,2],[70855,2],[[70856,70863],3],[[70864,70873],2],[[70874,71039],3],[[71040,71093],2],[[71094,71095],3],[[71096,71104],2],[[71105,71113],2],[[71114,71127],2],[[71128,71133],2],[[71134,71167],3],[[71168,71232],2],[[71233,71235],2],[71236,2],[[71237,71247],3],[[71248,71257],2],[[71258,71263],3],[[71264,71276],2],[[71277,71295],3],[[71296,71351],2],[71352,2],[71353,2],[[71354,71359],3],[[71360,71369],2],[[71370,71423],3],[[71424,71449],2],[71450,2],[[71451,71452],3],[[71453,71467],2],[[71468,71471],3],[[71472,71481],2],[[71482,71487],2],[[71488,71494],2],[[71495,71679],3],[[71680,71738],2],[71739,2],[[71740,71839],3],[71840,1,\"\"],[71841,1,\"\"],[71842,1,\"\"],[71843,1,\"\"],[71844,1,\"\"],[71845,1,\"\"],[71846,1,\"\"],[71847,1,\"\"],[71848,1,\"\"],[71849,1,\"\"],[71850,1,\"\"],[71851,1,\"\"],[71852,1,\"\"],[71853,1,\"\"],[71854,1,\"\"],[71855,1,\"\"],[71856,1,\"\"],[71857,1,\"\"],[71858,1,\"\"],[71859,1,\"\"],[71860,1,\"\"],[71861,1,\"\"],[71862,1,\"\"],[71863,1,\"\"],[71864,1,\"\"],[71865,1,\"\"],[71866,1,\"\"],[71867,1,\"\"],[71868,1,\"\"],[71869,1,\"\"],[71870,1,\"\"],[71871,1,\"\"],[[71872,71913],2],[[71914,71922],2],[[71923,71934],3],[71935,2],[[71936,71942],2],[[71943,71944],3],[71945,2],[[71946,71947],3],[[71948,71955],2],[71956,3],[[71957,71958],2],[71959,3],[[71960,71989],2],[71990,3],[[71991,71992],2],[[71993,71994],3],[[71995,72003],2],[[72004,72006],2],[[72007,72015],3],[[72016,72025],2],[[72026,72095],3],[[72096,72103],2],[[72104,72105],3],[[72106,72151],2],[[72152,72153],3],[[72154,72161],2],[72162,2],[[72163,72164],2],[[72165,72191],3],[[72192,72254],2],[[72255,72262],2],[72263,2],[[72264,72271],3],[[72272,72323],2],[[72324,72325],2],[[72326,72345],2],[[72346,72348],2],[72349,2],[[72350,72354],2],[[72355,72367],3],[[72368,72383],2],[[72384,72440],2],[[72441,72447],3],[[72448,72457],2],[[72458,72703],3],[[72704,72712],2],[72713,3],[[72714,72758],2],[72759,3],[[72760,72768],2],[[72769,72773],2],[[72774,72783],3],[[72784,72793],2],[[72794,72812],2],[[72813,72815],3],[[72816,72817],2],[[72818,72847],2],[[72848,72849],3],[[72850,72871],2],[72872,3],[[72873,72886],2],[[72887,72959],3],[[72960,72966],2],[72967,3],[[72968,72969],2],[72970,3],[[72971,73014],2],[[73015,73017],3],[73018,2],[73019,3],[[73020,73021],2],[73022,3],[[73023,73031],2],[[73032,73039],3],[[73040,73049],2],[[73050,73055],3],[[73056,73061],2],[73062,3],[[73063,73064],2],[73065,3],[[73066,73102],2],[73103,3],[[73104,73105],2],[73106,3],[[73107,73112],2],[[73113,73119],3],[[73120,73129],2],[[73130,73439],3],[[73440,73462],2],[[73463,73464],2],[[73465,73471],3],[[73472,73488],2],[73489,3],[[73490,73530],2],[[73531,73533],3],[[73534,73538],2],[[73539,73551],2],[[73552,73561],2],[[73562,73647],3],[73648,2],[[73649,73663],3],[[73664,73713],2],[[73714,73726],3],[73727,2],[[73728,74606],2],[[74607,74648],2],[74649,2],[[74650,74751],3],[[74752,74850],2],[[74851,74862],2],[74863,3],[[74864,74867],2],[74868,2],[[74869,74879],3],[[74880,75075],2],[[75076,77711],3],[[77712,77808],2],[[77809,77810],2],[[77811,77823],3],[[77824,78894],2],[78895,2],[[78896,78904],3],[[78905,78911],3],[[78912,78933],2],[[78934,82943],3],[[82944,83526],2],[[83527,92159],3],[[92160,92728],2],[[92729,92735],3],[[92736,92766],2],[92767,3],[[92768,92777],2],[[92778,92781],3],[[92782,92783],2],[[92784,92862],2],[92863,3],[[92864,92873],2],[[92874,92879],3],[[92880,92909],2],[[92910,92911],3],[[92912,92916],2],[92917,2],[[92918,92927],3],[[92928,92982],2],[[92983,92991],2],[[92992,92995],2],[[92996,92997],2],[[92998,93007],3],[[93008,93017],2],[93018,3],[[93019,93025],2],[93026,3],[[93027,93047],2],[[93048,93052],3],[[93053,93071],2],[[93072,93759],3],[93760,1,\"\"],[93761,1,\"\"],[93762,1,\"\"],[93763,1,\"\"],[93764,1,\"\"],[93765,1,\"\"],[93766,1,\"\"],[93767,1,\"\"],[93768,1,\"\"],[93769,1,\"\"],[93770,1,\"\"],[93771,1,\"\"],[93772,1,\"\"],[93773,1,\"\"],[93774,1,\"\"],[93775,1,\"\"],[93776,1,\"\"],[93777,1,\"\"],[93778,1,\"\"],[93779,1,\"\"],[93780,1,\"\"],[93781,1,\"\"],[93782,1,\"\"],[93783,1,\"\"],[93784,1,\"\"],[93785,1,\"\"],[93786,1,\"\"],[93787,1,\"\"],[93788,1,\"\"],[93789,1,\"\"],[93790,1,\"\"],[93791,1,\"\"],[[93792,93823],2],[[93824,93850],2],[[93851,93951],3],[[93952,94020],2],[[94021,94026],2],[[94027,94030],3],[94031,2],[[94032,94078],2],[[94079,94087],2],[[94088,94094],3],[[94095,94111],2],[[94112,94175],3],[94176,2],[94177,2],[94178,2],[94179,2],[94180,2],[[94181,94191],3],[[94192,94193],2],[[94194,94207],3],[[94208,100332],2],[[100333,100337],2],[[100338,100343],2],[[100344,100351],3],[[100352,101106],2],[[101107,101589],2],[[101590,101631],3],[[101632,101640],2],[[101641,110575],3],[[110576,110579],2],[110580,3],[[110581,110587],2],[110588,3],[[110589,110590],2],[110591,3],[[110592,110593],2],[[110594,110878],2],[[110879,110882],2],[[110883,110897],3],[110898,2],[[110899,110927],3],[[110928,110930],2],[[110931,110932],3],[110933,2],[[110934,110947],3],[[110948,110951],2],[[110952,110959],3],[[110960,111355],2],[[111356,113663],3],[[113664,113770],2],[[113771,113775],3],[[113776,113788],2],[[113789,113791],3],[[113792,113800],2],[[113801,113807],3],[[113808,113817],2],[[113818,113819],3],[113820,2],[[113821,113822],2],[113823,2],[[113824,113827],7],[[113828,118527],3],[[118528,118573],2],[[118574,118575],3],[[118576,118598],2],[[118599,118607],3],[[118608,118723],2],[[118724,118783],3],[[118784,119029],2],[[119030,119039],3],[[119040,119078],2],[[119079,119080],3],[119081,2],[[119082,119133],2],[119134,1,\"\"],[119135,1,\"\"],[119136,1,\"\"],[119137,1,\"\"],[119138,1,\"\"],[119139,1,\"\"],[119140,1,\"\"],[[119141,119154],2],[[119155,119162],3],[[119163,119226],2],[119227,1,\"\"],[119228,1,\"\"],[119229,1,\"\"],[119230,1,\"\"],[119231,1,\"\"],[119232,1,\"\"],[[119233,119261],2],[[119262,119272],2],[[119273,119274],2],[[119275,119295],3],[[119296,119365],2],[[119366,119487],3],[[119488,119507],2],[[119508,119519],3],[[119520,119539],2],[[119540,119551],3],[[119552,119638],2],[[119639,119647],3],[[119648,119665],2],[[119666,119672],2],[[119673,119807],3],[119808,1,\"a\"],[119809,1,\"b\"],[119810,1,\"c\"],[119811,1,\"d\"],[119812,1,\"e\"],[119813,1,\"f\"],[119814,1,\"g\"],[119815,1,\"h\"],[119816,1,\"i\"],[119817,1,\"j\"],[119818,1,\"k\"],[119819,1,\"l\"],[119820,1,\"m\"],[119821,1,\"n\"],[119822,1,\"o\"],[119823,1,\"p\"],[119824,1,\"q\"],[119825,1,\"r\"],[119826,1,\"s\"],[119827,1,\"t\"],[119828,1,\"u\"],[119829,1,\"v\"],[119830,1,\"w\"],[119831,1,\"x\"],[119832,1,\"y\"],[119833,1,\"z\"],[119834,1,\"a\"],[119835,1,\"b\"],[119836,1,\"c\"],[119837,1,\"d\"],[119838,1,\"e\"],[119839,1,\"f\"],[119840,1,\"g\"],[119841,1,\"h\"],[119842,1,\"i\"],[119843,1,\"j\"],[119844,1,\"k\"],[119845,1,\"l\"],[119846,1,\"m\"],[119847,1,\"n\"],[119848,1,\"o\"],[119849,1,\"p\"],[119850,1,\"q\"],[119851,1,\"r\"],[119852,1,\"s\"],[119853,1,\"t\"],[119854,1,\"u\"],[119855,1,\"v\"],[119856,1,\"w\"],[119857,1,\"x\"],[119858,1,\"y\"],[119859,1,\"z\"],[119860,1,\"a\"],[119861,1,\"b\"],[119862,1,\"c\"],[119863,1,\"d\"],[119864,1,\"e\"],[119865,1,\"f\"],[119866,1,\"g\"],[119867,1,\"h\"],[119868,1,\"i\"],[119869,1,\"j\"],[119870,1,\"k\"],[119871,1,\"l\"],[119872,1,\"m\"],[119873,1,\"n\"],[119874,1,\"o\"],[119875,1,\"p\"],[119876,1,\"q\"],[119877,1,\"r\"],[119878,1,\"s\"],[119879,1,\"t\"],[119880,1,\"u\"],[119881,1,\"v\"],[119882,1,\"w\"],[119883,1,\"x\"],[119884,1,\"y\"],[119885,1,\"z\"],[119886,1,\"a\"],[119887,1,\"b\"],[119888,1,\"c\"],[119889,1,\"d\"],[119890,1,\"e\"],[119891,1,\"f\"],[119892,1,\"g\"],[119893,3],[119894,1,\"i\"],[119895,1,\"j\"],[119896,1,\"k\"],[119897,1,\"l\"],[119898,1,\"m\"],[119899,1,\"n\"],[119900,1,\"o\"],[119901,1,\"p\"],[119902,1,\"q\"],[119903,1,\"r\"],[119904,1,\"s\"],[119905,1,\"t\"],[119906,1,\"u\"],[119907,1,\"v\"],[119908,1,\"w\"],[119909,1,\"x\"],[119910,1,\"y\"],[119911,1,\"z\"],[119912,1,\"a\"],[119913,1,\"b\"],[119914,1,\"c\"],[119915,1,\"d\"],[119916,1,\"e\"],[119917,1,\"f\"],[119918,1,\"g\"],[119919,1,\"h\"],[119920,1,\"i\"],[119921,1,\"j\"],[119922,1,\"k\"],[119923,1,\"l\"],[119924,1,\"m\"],[119925,1,\"n\"],[119926,1,\"o\"],[119927,1,\"p\"],[119928,1,\"q\"],[119929,1,\"r\"],[119930,1,\"s\"],[119931,1,\"t\"],[119932,1,\"u\"],[119933,1,\"v\"],[119934,1,\"w\"],[119935,1,\"x\"],[119936,1,\"y\"],[119937,1,\"z\"],[119938,1,\"a\"],[119939,1,\"b\"],[119940,1,\"c\"],[119941,1,\"d\"],[119942,1,\"e\"],[119943,1,\"f\"],[119944,1,\"g\"],[119945,1,\"h\"],[119946,1,\"i\"],[119947,1,\"j\"],[119948,1,\"k\"],[119949,1,\"l\"],[119950,1,\"m\"],[119951,1,\"n\"],[119952,1,\"o\"],[119953,1,\"p\"],[119954,1,\"q\"],[119955,1,\"r\"],[119956,1,\"s\"],[119957,1,\"t\"],[119958,1,\"u\"],[119959,1,\"v\"],[119960,1,\"w\"],[119961,1,\"x\"],[119962,1,\"y\"],[119963,1,\"z\"],[119964,1,\"a\"],[119965,3],[119966,1,\"c\"],[119967,1,\"d\"],[[119968,119969],3],[119970,1,\"g\"],[[119971,119972],3],[119973,1,\"j\"],[119974,1,\"k\"],[[119975,119976],3],[119977,1,\"n\"],[119978,1,\"o\"],[119979,1,\"p\"],[119980,1,\"q\"],[119981,3],[119982,1,\"s\"],[119983,1,\"t\"],[119984,1,\"u\"],[119985,1,\"v\"],[119986,1,\"w\"],[119987,1,\"x\"],[119988,1,\"y\"],[119989,1,\"z\"],[119990,1,\"a\"],[119991,1,\"b\"],[119992,1,\"c\"],[119993,1,\"d\"],[119994,3],[119995,1,\"f\"],[119996,3],[119997,1,\"h\"],[119998,1,\"i\"],[119999,1,\"j\"],[120000,1,\"k\"],[120001,1,\"l\"],[120002,1,\"m\"],[120003,1,\"n\"],[120004,3],[120005,1,\"p\"],[120006,1,\"q\"],[120007,1,\"r\"],[120008,1,\"s\"],[120009,1,\"t\"],[120010,1,\"u\"],[120011,1,\"v\"],[120012,1,\"w\"],[120013,1,\"x\"],[120014,1,\"y\"],[120015,1,\"z\"],[120016,1,\"a\"],[120017,1,\"b\"],[120018,1,\"c\"],[120019,1,\"d\"],[120020,1,\"e\"],[120021,1,\"f\"],[120022,1,\"g\"],[120023,1,\"h\"],[120024,1,\"i\"],[120025,1,\"j\"],[120026,1,\"k\"],[120027,1,\"l\"],[120028,1,\"m\"],[120029,1,\"n\"],[120030,1,\"o\"],[120031,1,\"p\"],[120032,1,\"q\"],[120033,1,\"r\"],[120034,1,\"s\"],[120035,1,\"t\"],[120036,1,\"u\"],[120037,1,\"v\"],[120038,1,\"w\"],[120039,1,\"x\"],[120040,1,\"y\"],[120041,1,\"z\"],[120042,1,\"a\"],[120043,1,\"b\"],[120044,1,\"c\"],[120045,1,\"d\"],[120046,1,\"e\"],[120047,1,\"f\"],[120048,1,\"g\"],[120049,1,\"h\"],[120050,1,\"i\"],[120051,1,\"j\"],[120052,1,\"k\"],[120053,1,\"l\"],[120054,1,\"m\"],[120055,1,\"n\"],[120056,1,\"o\"],[120057,1,\"p\"],[120058,1,\"q\"],[120059,1,\"r\"],[120060,1,\"s\"],[120061,1,\"t\"],[120062,1,\"u\"],[120063,1,\"v\"],[120064,1,\"w\"],[120065,1,\"x\"],[120066,1,\"y\"],[120067,1,\"z\"],[120068,1,\"a\"],[120069,1,\"b\"],[120070,3],[120071,1,\"d\"],[120072,1,\"e\"],[120073,1,\"f\"],[120074,1,\"g\"],[[120075,120076],3],[120077,1,\"j\"],[120078,1,\"k\"],[120079,1,\"l\"],[120080,1,\"m\"],[120081,1,\"n\"],[120082,1,\"o\"],[120083,1,\"p\"],[120084,1,\"q\"],[120085,3],[120086,1,\"s\"],[120087,1,\"t\"],[120088,1,\"u\"],[120089,1,\"v\"],[120090,1,\"w\"],[120091,1,\"x\"],[120092,1,\"y\"],[120093,3],[120094,1,\"a\"],[120095,1,\"b\"],[120096,1,\"c\"],[120097,1,\"d\"],[120098,1,\"e\"],[120099,1,\"f\"],[120100,1,\"g\"],[120101,1,\"h\"],[120102,1,\"i\"],[120103,1,\"j\"],[120104,1,\"k\"],[120105,1,\"l\"],[120106,1,\"m\"],[120107,1,\"n\"],[120108,1,\"o\"],[120109,1,\"p\"],[120110,1,\"q\"],[120111,1,\"r\"],[120112,1,\"s\"],[120113,1,\"t\"],[120114,1,\"u\"],[120115,1,\"v\"],[120116,1,\"w\"],[120117,1,\"x\"],[120118,1,\"y\"],[120119,1,\"z\"],[120120,1,\"a\"],[120121,1,\"b\"],[120122,3],[120123,1,\"d\"],[120124,1,\"e\"],[120125,1,\"f\"],[120126,1,\"g\"],[120127,3],[120128,1,\"i\"],[120129,1,\"j\"],[120130,1,\"k\"],[120131,1,\"l\"],[120132,1,\"m\"],[120133,3],[120134,1,\"o\"],[[120135,120137],3],[120138,1,\"s\"],[120139,1,\"t\"],[120140,1,\"u\"],[120141,1,\"v\"],[120142,1,\"w\"],[120143,1,\"x\"],[120144,1,\"y\"],[120145,3],[120146,1,\"a\"],[120147,1,\"b\"],[120148,1,\"c\"],[120149,1,\"d\"],[120150,1,\"e\"],[120151,1,\"f\"],[120152,1,\"g\"],[120153,1,\"h\"],[120154,1,\"i\"],[120155,1,\"j\"],[120156,1,\"k\"],[120157,1,\"l\"],[120158,1,\"m\"],[120159,1,\"n\"],[120160,1,\"o\"],[120161,1,\"p\"],[120162,1,\"q\"],[120163,1,\"r\"],[120164,1,\"s\"],[120165,1,\"t\"],[120166,1,\"u\"],[120167,1,\"v\"],[120168,1,\"w\"],[120169,1,\"x\"],[120170,1,\"y\"],[120171,1,\"z\"],[120172,1,\"a\"],[120173,1,\"b\"],[120174,1,\"c\"],[120175,1,\"d\"],[120176,1,\"e\"],[120177,1,\"f\"],[120178,1,\"g\"],[120179,1,\"h\"],[120180,1,\"i\"],[120181,1,\"j\"],[120182,1,\"k\"],[120183,1,\"l\"],[120184,1,\"m\"],[120185,1,\"n\"],[120186,1,\"o\"],[120187,1,\"p\"],[120188,1,\"q\"],[120189,1,\"r\"],[120190,1,\"s\"],[120191,1,\"t\"],[120192,1,\"u\"],[120193,1,\"v\"],[120194,1,\"w\"],[120195,1,\"x\"],[120196,1,\"y\"],[120197,1,\"z\"],[120198,1,\"a\"],[120199,1,\"b\"],[120200,1,\"c\"],[120201,1,\"d\"],[120202,1,\"e\"],[120203,1,\"f\"],[120204,1,\"g\"],[120205,1,\"h\"],[120206,1,\"i\"],[120207,1,\"j\"],[120208,1,\"k\"],[120209,1,\"l\"],[120210,1,\"m\"],[120211,1,\"n\"],[120212,1,\"o\"],[120213,1,\"p\"],[120214,1,\"q\"],[120215,1,\"r\"],[120216,1,\"s\"],[120217,1,\"t\"],[120218,1,\"u\"],[120219,1,\"v\"],[120220,1,\"w\"],[120221,1,\"x\"],[120222,1,\"y\"],[120223,1,\"z\"],[120224,1,\"a\"],[120225,1,\"b\"],[120226,1,\"c\"],[120227,1,\"d\"],[120228,1,\"e\"],[120229,1,\"f\"],[120230,1,\"g\"],[120231,1,\"h\"],[120232,1,\"i\"],[120233,1,\"j\"],[120234,1,\"k\"],[120235,1,\"l\"],[120236,1,\"m\"],[120237,1,\"n\"],[120238,1,\"o\"],[120239,1,\"p\"],[120240,1,\"q\"],[120241,1,\"r\"],[120242,1,\"s\"],[120243,1,\"t\"],[120244,1,\"u\"],[120245,1,\"v\"],[120246,1,\"w\"],[120247,1,\"x\"],[120248,1,\"y\"],[120249,1,\"z\"],[120250,1,\"a\"],[120251,1,\"b\"],[120252,1,\"c\"],[120253,1,\"d\"],[120254,1,\"e\"],[120255,1,\"f\"],[120256,1,\"g\"],[120257,1,\"h\"],[120258,1,\"i\"],[120259,1,\"j\"],[120260,1,\"k\"],[120261,1,\"l\"],[120262,1,\"m\"],[120263,1,\"n\"],[120264,1,\"o\"],[120265,1,\"p\"],[120266,1,\"q\"],[120267,1,\"r\"],[120268,1,\"s\"],[120269,1,\"t\"],[120270,1,\"u\"],[120271,1,\"v\"],[120272,1,\"w\"],[120273,1,\"x\"],[120274,1,\"y\"],[120275,1,\"z\"],[120276,1,\"a\"],[120277,1,\"b\"],[120278,1,\"c\"],[120279,1,\"d\"],[120280,1,\"e\"],[120281,1,\"f\"],[120282,1,\"g\"],[120283,1,\"h\"],[120284,1,\"i\"],[120285,1,\"j\"],[120286,1,\"k\"],[120287,1,\"l\"],[120288,1,\"m\"],[120289,1,\"n\"],[120290,1,\"o\"],[120291,1,\"p\"],[120292,1,\"q\"],[120293,1,\"r\"],[120294,1,\"s\"],[120295,1,\"t\"],[120296,1,\"u\"],[120297,1,\"v\"],[120298,1,\"w\"],[120299,1,\"x\"],[120300,1,\"y\"],[120301,1,\"z\"],[120302,1,\"a\"],[120303,1,\"b\"],[120304,1,\"c\"],[120305,1,\"d\"],[120306,1,\"e\"],[120307,1,\"f\"],[120308,1,\"g\"],[120309,1,\"h\"],[120310,1,\"i\"],[120311,1,\"j\"],[120312,1,\"k\"],[120313,1,\"l\"],[120314,1,\"m\"],[120315,1,\"n\"],[120316,1,\"o\"],[120317,1,\"p\"],[120318,1,\"q\"],[120319,1,\"r\"],[120320,1,\"s\"],[120321,1,\"t\"],[120322,1,\"u\"],[120323,1,\"v\"],[120324,1,\"w\"],[120325,1,\"x\"],[120326,1,\"y\"],[120327,1,\"z\"],[120328,1,\"a\"],[120329,1,\"b\"],[120330,1,\"c\"],[120331,1,\"d\"],[120332,1,\"e\"],[120333,1,\"f\"],[120334,1,\"g\"],[120335,1,\"h\"],[120336,1,\"i\"],[120337,1,\"j\"],[120338,1,\"k\"],[120339,1,\"l\"],[120340,1,\"m\"],[120341,1,\"n\"],[120342,1,\"o\"],[120343,1,\"p\"],[120344,1,\"q\"],[120345,1,\"r\"],[120346,1,\"s\"],[120347,1,\"t\"],[120348,1,\"u\"],[120349,1,\"v\"],[120350,1,\"w\"],[120351,1,\"x\"],[120352,1,\"y\"],[120353,1,\"z\"],[120354,1,\"a\"],[120355,1,\"b\"],[120356,1,\"c\"],[120357,1,\"d\"],[120358,1,\"e\"],[120359,1,\"f\"],[120360,1,\"g\"],[120361,1,\"h\"],[120362,1,\"i\"],[120363,1,\"j\"],[120364,1,\"k\"],[120365,1,\"l\"],[120366,1,\"m\"],[120367,1,\"n\"],[120368,1,\"o\"],[120369,1,\"p\"],[120370,1,\"q\"],[120371,1,\"r\"],[120372,1,\"s\"],[120373,1,\"t\"],[120374,1,\"u\"],[120375,1,\"v\"],[120376,1,\"w\"],[120377,1,\"x\"],[120378,1,\"y\"],[120379,1,\"z\"],[120380,1,\"a\"],[120381,1,\"b\"],[120382,1,\"c\"],[120383,1,\"d\"],[120384,1,\"e\"],[120385,1,\"f\"],[120386,1,\"g\"],[120387,1,\"h\"],[120388,1,\"i\"],[120389,1,\"j\"],[120390,1,\"k\"],[120391,1,\"l\"],[120392,1,\"m\"],[120393,1,\"n\"],[120394,1,\"o\"],[120395,1,\"p\"],[120396,1,\"q\"],[120397,1,\"r\"],[120398,1,\"s\"],[120399,1,\"t\"],[120400,1,\"u\"],[120401,1,\"v\"],[120402,1,\"w\"],[120403,1,\"x\"],[120404,1,\"y\"],[120405,1,\"z\"],[120406,1,\"a\"],[120407,1,\"b\"],[120408,1,\"c\"],[120409,1,\"d\"],[120410,1,\"e\"],[120411,1,\"f\"],[120412,1,\"g\"],[120413,1,\"h\"],[120414,1,\"i\"],[120415,1,\"j\"],[120416,1,\"k\"],[120417,1,\"l\"],[120418,1,\"m\"],[120419,1,\"n\"],[120420,1,\"o\"],[120421,1,\"p\"],[120422,1,\"q\"],[120423,1,\"r\"],[120424,1,\"s\"],[120425,1,\"t\"],[120426,1,\"u\"],[120427,1,\"v\"],[120428,1,\"w\"],[120429,1,\"x\"],[120430,1,\"y\"],[120431,1,\"z\"],[120432,1,\"a\"],[120433,1,\"b\"],[120434,1,\"c\"],[120435,1,\"d\"],[120436,1,\"e\"],[120437,1,\"f\"],[120438,1,\"g\"],[120439,1,\"h\"],[120440,1,\"i\"],[120441,1,\"j\"],[120442,1,\"k\"],[120443,1,\"l\"],[120444,1,\"m\"],[120445,1,\"n\"],[120446,1,\"o\"],[120447,1,\"p\"],[120448,1,\"q\"],[120449,1,\"r\"],[120450,1,\"s\"],[120451,1,\"t\"],[120452,1,\"u\"],[120453,1,\"v\"],[120454,1,\"w\"],[120455,1,\"x\"],[120456,1,\"y\"],[120457,1,\"z\"],[120458,1,\"a\"],[120459,1,\"b\"],[120460,1,\"c\"],[120461,1,\"d\"],[120462,1,\"e\"],[120463,1,\"f\"],[120464,1,\"g\"],[120465,1,\"h\"],[120466,1,\"i\"],[120467,1,\"j\"],[120468,1,\"k\"],[120469,1,\"l\"],[120470,1,\"m\"],[120471,1,\"n\"],[120472,1,\"o\"],[120473,1,\"p\"],[120474,1,\"q\"],[120475,1,\"r\"],[120476,1,\"s\"],[120477,1,\"t\"],[120478,1,\"u\"],[120479,1,\"v\"],[120480,1,\"w\"],[120481,1,\"x\"],[120482,1,\"y\"],[120483,1,\"z\"],[120484,1,\"\"],[120485,1,\"\"],[[120486,120487],3],[120488,1,\"\"],[120489,1,\"\"],[120490,1,\"\"],[120491,1,\"\"],[120492,1,\"\"],[120493,1,\"\"],[120494,1,\"\"],[120495,1,\"\"],[120496,1,\"\"],[120497,1,\"\"],[120498,1,\"\"],[120499,1,\"\"],[120500,1,\"\"],[120501,1,\"\"],[120502,1,\"\"],[120503,1,\"\"],[120504,1,\"\"],[120505,1,\"\"],[120506,1,\"\"],[120507,1,\"\"],[120508,1,\"\"],[120509,1,\"\"],[120510,1,\"\"],[120511,1,\"\"],[120512,1,\"\"],[120513,1,\"\"],[120514,1,\"\"],[120515,1,\"\"],[120516,1,\"\"],[120517,1,\"\"],[120518,1,\"\"],[120519,1,\"\"],[120520,1,\"\"],[120521,1,\"\"],[120522,1,\"\"],[120523,1,\"\"],[120524,1,\"\"],[120525,1,\"\"],[120526,1,\"\"],[120527,1,\"\"],[120528,1,\"\"],[120529,1,\"\"],[120530,1,\"\"],[[120531,120532],1,\"\"],[120533,1,\"\"],[120534,1,\"\"],[120535,1,\"\"],[120536,1,\"\"],[120537,1,\"\"],[120538,1,\"\"],[120539,1,\"\"],[120540,1,\"\"],[120541,1,\"\"],[120542,1,\"\"],[120543,1,\"\"],[120544,1,\"\"],[120545,1,\"\"],[120546,1,\"\"],[120547,1,\"\"],[120548,1,\"\"],[120549,1,\"\"],[120550,1,\"\"],[120551,1,\"\"],[120552,1,\"\"],[120553,1,\"\"],[120554,1,\"\"],[120555,1,\"\"],[120556,1,\"\"],[120557,1,\"\"],[120558,1,\"\"],[120559,1,\"\"],[120560,1,\"\"],[120561,1,\"\"],[120562,1,\"\"],[120563,1,\"\"],[120564,1,\"\"],[120565,1,\"\"],[120566,1,\"\"],[120567,1,\"\"],[120568,1,\"\"],[120569,1,\"\"],[120570,1,\"\"],[120571,1,\"\"],[120572,1,\"\"],[120573,1,\"\"],[120574,1,\"\"],[120575,1,\"\"],[120576,1,\"\"],[120577,1,\"\"],[120578,1,\"\"],[120579,1,\"\"],[120580,1,\"\"],[120581,1,\"\"],[120582,1,\"\"],[120583,1,\"\"],[120584,1,\"\"],[120585,1,\"\"],[120586,1,\"\"],[120587,1,\"\"],[120588,1,\"\"],[[120589,120590],1,\"\"],[120591,1,\"\"],[120592,1,\"\"],[120593,1,\"\"],[120594,1,\"\"],[120595,1,\"\"],[120596,1,\"\"],[120597,1,\"\"],[120598,1,\"\"],[120599,1,\"\"],[120600,1,\"\"],[120601,1,\"\"],[120602,1,\"\"],[120603,1,\"\"],[120604,1,\"\"],[120605,1,\"\"],[120606,1,\"\"],[120607,1,\"\"],[120608,1,\"\"],[120609,1,\"\"],[120610,1,\"\"],[120611,1,\"\"],[120612,1,\"\"],[120613,1,\"\"],[120614,1,\"\"],[120615,1,\"\"],[120616,1,\"\"],[120617,1,\"\"],[120618,1,\"\"],[120619,1,\"\"],[120620,1,\"\"],[120621,1,\"\"],[120622,1,\"\"],[120623,1,\"\"],[120624,1,\"\"],[120625,1,\"\"],[120626,1,\"\"],[120627,1,\"\"],[120628,1,\"\"],[120629,1,\"\"],[120630,1,\"\"],[120631,1,\"\"],[120632,1,\"\"],[120633,1,\"\"],[120634,1,\"\"],[120635,1,\"\"],[120636,1,\"\"],[120637,1,\"\"],[120638,1,\"\"],[120639,1,\"\"],[120640,1,\"\"],[120641,1,\"\"],[120642,1,\"\"],[120643,1,\"\"],[120644,1,\"\"],[120645,1,\"\"],[120646,1,\"\"],[[120647,120648],1,\"\"],[120649,1,\"\"],[120650,1,\"\"],[120651,1,\"\"],[120652,1,\"\"],[120653,1,\"\"],[120654,1,\"\"],[120655,1,\"\"],[120656,1,\"\"],[120657,1,\"\"],[120658,1,\"\"],[120659,1,\"\"],[120660,1,\"\"],[120661,1,\"\"],[120662,1,\"\"],[120663,1,\"\"],[120664,1,\"\"],[120665,1,\"\"],[120666,1,\"\"],[120667,1,\"\"],[120668,1,\"\"],[120669,1,\"\"],[120670,1,\"\"],[120671,1,\"\"],[120672,1,\"\"],[120673,1,\"\"],[120674,1,\"\"],[120675,1,\"\"],[120676,1,\"\"],[120677,1,\"\"],[120678,1,\"\"],[120679,1,\"\"],[120680,1,\"\"],[120681,1,\"\"],[120682,1,\"\"],[120683,1,\"\"],[120684,1,\"\"],[120685,1,\"\"],[120686,1,\"\"],[120687,1,\"\"],[120688,1,\"\"],[120689,1,\"\"],[120690,1,\"\"],[120691,1,\"\"],[120692,1,\"\"],[120693,1,\"\"],[120694,1,\"\"],[120695,1,\"\"],[120696,1,\"\"],[120697,1,\"\"],[120698,1,\"\"],[120699,1,\"\"],[120700,1,\"\"],[120701,1,\"\"],[120702,1,\"\"],[120703,1,\"\"],[120704,1,\"\"],[[120705,120706],1,\"\"],[120707,1,\"\"],[120708,1,\"\"],[120709,1,\"\"],[120710,1,\"\"],[120711,1,\"\"],[120712,1,\"\"],[120713,1,\"\"],[120714,1,\"\"],[120715,1,\"\"],[120716,1,\"\"],[120717,1,\"\"],[120718,1,\"\"],[120719,1,\"\"],[120720,1,\"\"],[120721,1,\"\"],[120722,1,\"\"],[120723,1,\"\"],[120724,1,\"\"],[120725,1,\"\"],[120726,1,\"\"],[120727,1,\"\"],[120728,1,\"\"],[120729,1,\"\"],[120730,1,\"\"],[120731,1,\"\"],[120732,1,\"\"],[120733,1,\"\"],[120734,1,\"\"],[120735,1,\"\"],[120736,1,\"\"],[120737,1,\"\"],[120738,1,\"\"],[120739,1,\"\"],[120740,1,\"\"],[120741,1,\"\"],[120742,1,\"\"],[120743,1,\"\"],[120744,1,\"\"],[120745,1,\"\"],[120746,1,\"\"],[120747,1,\"\"],[120748,1,\"\"],[120749,1,\"\"],[120750,1,\"\"],[120751,1,\"\"],[120752,1,\"\"],[120753,1,\"\"],[120754,1,\"\"],[120755,1,\"\"],[120756,1,\"\"],[120757,1,\"\"],[120758,1,\"\"],[120759,1,\"\"],[120760,1,\"\"],[120761,1,\"\"],[120762,1,\"\"],[[120763,120764],1,\"\"],[120765,1,\"\"],[120766,1,\"\"],[120767,1,\"\"],[120768,1,\"\"],[120769,1,\"\"],[120770,1,\"\"],[120771,1,\"\"],[120772,1,\"\"],[120773,1,\"\"],[120774,1,\"\"],[120775,1,\"\"],[120776,1,\"\"],[120777,1,\"\"],[[120778,120779],1,\"\"],[[120780,120781],3],[120782,1,\"0\"],[120783,1,\"1\"],[120784,1,\"2\"],[120785,1,\"3\"],[120786,1,\"4\"],[120787,1,\"5\"],[120788,1,\"6\"],[120789,1,\"7\"],[120790,1,\"8\"],[120791,1,\"9\"],[120792,1,\"0\"],[120793,1,\"1\"],[120794,1,\"2\"],[120795,1,\"3\"],[120796,1,\"4\"],[120797,1,\"5\"],[120798,1,\"6\"],[120799,1,\"7\"],[120800,1,\"8\"],[120801,1,\"9\"],[120802,1,\"0\"],[120803,1,\"1\"],[120804,1,\"2\"],[120805,1,\"3\"],[120806,1,\"4\"],[120807,1,\"5\"],[120808,1,\"6\"],[120809,1,\"7\"],[120810,1,\"8\"],[120811,1,\"9\"],[120812,1,\"0\"],[120813,1,\"1\"],[120814,1,\"2\"],[120815,1,\"3\"],[120816,1,\"4\"],[120817,1,\"5\"],[120818,1,\"6\"],[120819,1,\"7\"],[120820,1,\"8\"],[120821,1,\"9\"],[120822,1,\"0\"],[120823,1,\"1\"],[120824,1,\"2\"],[120825,1,\"3\"],[120826,1,\"4\"],[120827,1,\"5\"],[120828,1,\"6\"],[120829,1,\"7\"],[120830,1,\"8\"],[120831,1,\"9\"],[[120832,121343],2],[[121344,121398],2],[[121399,121402],2],[[121403,121452],2],[[121453,121460],2],[121461,2],[[121462,121475],2],[121476,2],[[121477,121483],2],[[121484,121498],3],[[121499,121503],2],[121504,3],[[121505,121519],2],[[121520,122623],3],[[122624,122654],2],[[122655,122660],3],[[122661,122666],2],[[122667,122879],3],[[122880,122886],2],[122887,3],[[122888,122904],2],[[122905,122906],3],[[122907,122913],2],[122914,3],[[122915,122916],2],[122917,3],[[122918,122922],2],[[122923,122927],3],[122928,1,\"\"],[122929,1,\"\"],[122930,1,\"\"],[122931,1,\"\"],[122932,1,\"\"],[122933,1,\"\"],[122934,1,\"\"],[122935,1,\"\"],[122936,1,\"\"],[122937,1,\"\"],[122938,1,\"\"],[122939,1,\"\"],[122940,1,\"\"],[122941,1,\"\"],[122942,1,\"\"],[122943,1,\"\"],[122944,1,\"\"],[122945,1,\"\"],[122946,1,\"\"],[122947,1,\"\"],[122948,1,\"\"],[122949,1,\"\"],[122950,1,\"\"],[122951,1,\"\"],[122952,1,\"\"],[122953,1,\"\"],[122954,1,\"\"],[122955,1,\"\"],[122956,1,\"\"],[122957,1,\"\"],[122958,1,\"\"],[122959,1,\"\"],[122960,1,\"\"],[122961,1,\"\"],[122962,1,\"\"],[122963,1,\"\"],[122964,1,\"\"],[122965,1,\"\"],[122966,1,\"\"],[122967,1,\"\"],[122968,1,\"\"],[122969,1,\"\"],[122970,1,\"\"],[122971,1,\"\"],[122972,1,\"\"],[122973,1,\"\"],[122974,1,\"\"],[122975,1,\"\"],[122976,1,\"\"],[122977,1,\"\"],[122978,1,\"\"],[122979,1,\"\"],[122980,1,\"\"],[122981,1,\"\"],[122982,1,\"\"],[122983,1,\"\"],[122984,1,\"\"],[122985,1,\"\"],[122986,1,\"\"],[122987,1,\"\"],[122988,1,\"\"],[122989,1,\"\"],[[122990,123022],3],[123023,2],[[123024,123135],3],[[123136,123180],2],[[123181,123183],3],[[123184,123197],2],[[123198,123199],3],[[123200,123209],2],[[123210,123213],3],[123214,2],[123215,2],[[123216,123535],3],[[123536,123566],2],[[123567,123583],3],[[123584,123641],2],[[123642,123646],3],[123647,2],[[123648,124111],3],[[124112,124153],2],[[124154,124895],3],[[124896,124902],2],[124903,3],[[124904,124907],2],[124908,3],[[124909,124910],2],[124911,3],[[124912,124926],2],[124927,3],[[124928,125124],2],[[125125,125126],3],[[125127,125135],2],[[125136,125142],2],[[125143,125183],3],[125184,1,\"\"],[125185,1,\"\"],[125186,1,\"\"],[125187,1,\"\"],[125188,1,\"\"],[125189,1,\"\"],[125190,1,\"\"],[125191,1,\"\"],[125192,1,\"\"],[125193,1,\"\"],[125194,1,\"\"],[125195,1,\"\"],[125196,1,\"\"],[125197,1,\"\"],[125198,1,\"\"],[125199,1,\"\"],[125200,1,\"\"],[125201,1,\"\"],[125202,1,\"\"],[125203,1,\"\"],[125204,1,\"\"],[125205,1,\"\"],[125206,1,\"\"],[125207,1,\"\"],[125208,1,\"\"],[125209,1,\"\"],[125210,1,\"\"],[125211,1,\"\"],[125212,1,\"\"],[125213,1,\"\"],[125214,1,\"\"],[125215,1,\"\"],[125216,1,\"\"],[125217,1,\"\"],[[125218,125258],2],[125259,2],[[125260,125263],3],[[125264,125273],2],[[125274,125277],3],[[125278,125279],2],[[125280,126064],3],[[126065,126132],2],[[126133,126208],3],[[126209,126269],2],[[126270,126463],3],[126464,1,\"\"],[126465,1,\"\"],[126466,1,\"\"],[126467,1,\"\"],[126468,3],[126469,1,\"\"],[126470,1,\"\"],[126471,1,\"\"],[126472,1,\"\"],[126473,1,\"\"],[126474,1,\"\"],[126475,1,\"\"],[126476,1,\"\"],[126477,1,\"\"],[126478,1,\"\"],[126479,1,\"\"],[126480,1,\"\"],[126481,1,\"\"],[126482,1,\"\"],[126483,1,\"\"],[126484,1,\"\"],[126485,1,\"\"],[126486,1,\"\"],[126487,1,\"\"],[126488,1,\"\"],[126489,1,\"\"],[126490,1,\"\"],[126491,1,\"\"],[126492,1,\"\"],[126493,1,\"\"],[126494,1,\"\"],[126495,1,\"\"],[126496,3],[126497,1,\"\"],[126498,1,\"\"],[126499,3],[126500,1,\"\"],[[126501,126502],3],[126503,1,\"\"],[126504,3],[126505,1,\"\"],[126506,1,\"\"],[126507,1,\"\"],[126508,1,\"\"],[126509,1,\"\"],[126510,1,\"\"],[126511,1,\"\"],[126512,1,\"\"],[126513,1,\"\"],[126514,1,\"\"],[126515,3],[126516,1,\"\"],[126517,1,\"\"],[126518,1,\"\"],[126519,1,\"\"],[126520,3],[126521,1,\"\"],[126522,3],[126523,1,\"\"],[[126524,126529],3],[126530,1,\"\"],[[126531,126534],3],[126535,1,\"\"],[126536,3],[126537,1,\"\"],[126538,3],[126539,1,\"\"],[126540,3],[126541,1,\"\"],[126542,1,\"\"],[126543,1,\"\"],[126544,3],[126545,1,\"\"],[126546,1,\"\"],[126547,3],[126548,1,\"\"],[[126549,126550],3],[126551,1,\"\"],[126552,3],[126553,1,\"\"],[126554,3],[126555,1,\"\"],[126556,3],[126557,1,\"\"],[126558,3],[126559,1,\"\"],[126560,3],[126561,1,\"\"],[126562,1,\"\"],[126563,3],[126564,1,\"\"],[[126565,126566],3],[126567,1,\"\"],[126568,1,\"\"],[126569,1,\"\"],[126570,1,\"\"],[126571,3],[126572,1,\"\"],[126573,1,\"\"],[126574,1,\"\"],[126575,1,\"\"],[126576,1,\"\"],[126577,1,\"\"],[126578,1,\"\"],[126579,3],[126580,1,\"\"],[126581,1,\"\"],[126582,1,\"\"],[126583,1,\"\"],[126584,3],[126585,1,\"\"],[126586,1,\"\"],[126587,1,\"\"],[126588,1,\"\"],[126589,3],[126590,1,\"\"],[126591,3],[126592,1,\"\"],[126593,1,\"\"],[126594,1,\"\"],[126595,1,\"\"],[126596,1,\"\"],[126597,1,\"\"],[126598,1,\"\"],[126599,1,\"\"],[126600,1,\"\"],[126601,1,\"\"],[126602,3],[126603,1,\"\"],[126604,1,\"\"],[126605,1,\"\"],[126606,1,\"\"],[126607,1,\"\"],[126608,1,\"\"],[126609,1,\"\"],[126610,1,\"\"],[126611,1,\"\"],[126612,1,\"\"],[126613,1,\"\"],[126614,1,\"\"],[126615,1,\"\"],[126616,1,\"\"],[126617,1,\"\"],[126618,1,\"\"],[126619,1,\"\"],[[126620,126624],3],[126625,1,\"\"],[126626,1,\"\"],[126627,1,\"\"],[126628,3],[126629,1,\"\"],[126630,1,\"\"],[126631,1,\"\"],[126632,1,\"\"],[126633,1,\"\"],[126634,3],[126635,1,\"\"],[126636,1,\"\"],[126637,1,\"\"],[126638,1,\"\"],[126639,1,\"\"],[126640,1,\"\"],[126641,1,\"\"],[126642,1,\"\"],[126643,1,\"\"],[126644,1,\"\"],[126645,1,\"\"],[126646,1,\"\"],[126647,1,\"\"],[126648,1,\"\"],[126649,1,\"\"],[126650,1,\"\"],[126651,1,\"\"],[[126652,126703],3],[[126704,126705],2],[[126706,126975],3],[[126976,127019],2],[[127020,127023],3],[[127024,127123],2],[[127124,127135],3],[[127136,127150],2],[[127151,127152],3],[[127153,127166],2],[127167,2],[127168,3],[[127169,127183],2],[127184,3],[[127185,127199],2],[[127200,127221],2],[[127222,127231],3],[127232,3],[127233,5,\"0,\"],[127234,5,\"1,\"],[127235,5,\"2,\"],[127236,5,\"3,\"],[127237,5,\"4,\"],[127238,5,\"5,\"],[127239,5,\"6,\"],[127240,5,\"7,\"],[127241,5,\"8,\"],[127242,5,\"9,\"],[[127243,127244],2],[[127245,127247],2],[127248,5,\"(a)\"],[127249,5,\"(b)\"],[127250,5,\"(c)\"],[127251,5,\"(d)\"],[127252,5,\"(e)\"],[127253,5,\"(f)\"],[127254,5,\"(g)\"],[127255,5,\"(h)\"],[127256,5,\"(i)\"],[127257,5,\"(j)\"],[127258,5,\"(k)\"],[127259,5,\"(l)\"],[127260,5,\"(m)\"],[127261,5,\"(n)\"],[127262,5,\"(o)\"],[127263,5,\"(p)\"],[127264,5,\"(q)\"],[127265,5,\"(r)\"],[127266,5,\"(s)\"],[127267,5,\"(t)\"],[127268,5,\"(u)\"],[127269,5,\"(v)\"],[127270,5,\"(w)\"],[127271,5,\"(x)\"],[127272,5,\"(y)\"],[127273,5,\"(z)\"],[127274,1,\"s\"],[127275,1,\"c\"],[127276,1,\"r\"],[127277,1,\"cd\"],[127278,1,\"wz\"],[127279,2],[127280,1,\"a\"],[127281,1,\"b\"],[127282,1,\"c\"],[127283,1,\"d\"],[127284,1,\"e\"],[127285,1,\"f\"],[127286,1,\"g\"],[127287,1,\"h\"],[127288,1,\"i\"],[127289,1,\"j\"],[127290,1,\"k\"],[127291,1,\"l\"],[127292,1,\"m\"],[127293,1,\"n\"],[127294,1,\"o\"],[127295,1,\"p\"],[127296,1,\"q\"],[127297,1,\"r\"],[127298,1,\"s\"],[127299,1,\"t\"],[127300,1,\"u\"],[127301,1,\"v\"],[127302,1,\"w\"],[127303,1,\"x\"],[127304,1,\"y\"],[127305,1,\"z\"],[127306,1,\"hv\"],[127307,1,\"mv\"],[127308,1,\"sd\"],[127309,1,\"ss\"],[127310,1,\"ppv\"],[127311,1,\"wc\"],[[127312,127318],2],[127319,2],[[127320,127326],2],[127327,2],[[127328,127337],2],[127338,1,\"mc\"],[127339,1,\"md\"],[127340,1,\"mr\"],[[127341,127343],2],[[127344,127352],2],[127353,2],[127354,2],[[127355,127356],2],[[127357,127358],2],[127359,2],[[127360,127369],2],[[127370,127373],2],[[127374,127375],2],[127376,1,\"dj\"],[[127377,127386],2],[[127387,127404],2],[127405,2],[[127406,127461],3],[[127462,127487],2],[127488,1,\"\"],[127489,1,\"\"],[127490,1,\"\"],[[127491,127503],3],[127504,1,\"\"],[127505,1,\"\"],[127506,1,\"\"],[127507,1,\"\"],[127508,1,\"\"],[127509,1,\"\"],[127510,1,\"\"],[127511,1,\"\"],[127512,1,\"\"],[127513,1,\"\"],[127514,1,\"\"],[127515,1,\"\"],[127516,1,\"\"],[127517,1,\"\"],[127518,1,\"\"],[127519,1,\"\"],[127520,1,\"\"],[127521,1,\"\"],[127522,1,\"\"],[127523,1,\"\"],[127524,1,\"\"],[127525,1,\"\"],[127526,1,\"\"],[127527,1,\"\"],[127528,1,\"\"],[127529,1,\"\"],[127530,1,\"\"],[127531,1,\"\"],[127532,1,\"\"],[127533,1,\"\"],[127534,1,\"\"],[127535,1,\"\"],[127536,1,\"\"],[127537,1,\"\"],[127538,1,\"\"],[127539,1,\"\"],[127540,1,\"\"],[127541,1,\"\"],[127542,1,\"\"],[127543,1,\"\"],[127544,1,\"\"],[127545,1,\"\"],[127546,1,\"\"],[127547,1,\"\"],[[127548,127551],3],[127552,1,\"\"],[127553,1,\"\"],[127554,1,\"\"],[127555,1,\"\"],[127556,1,\"\"],[127557,1,\"\"],[127558,1,\"\"],[127559,1,\"\"],[127560,1,\"\"],[[127561,127567],3],[127568,1,\"\"],[127569,1,\"\"],[[127570,127583],3],[[127584,127589],2],[[127590,127743],3],[[127744,127776],2],[[127777,127788],2],[[127789,127791],2],[[127792,127797],2],[127798,2],[[127799,127868],2],[127869,2],[[127870,127871],2],[[127872,127891],2],[[127892,127903],2],[[127904,127940],2],[127941,2],[[127942,127946],2],[[127947,127950],2],[[127951,127955],2],[[127956,127967],2],[[127968,127984],2],[[127985,127991],2],[[127992,127999],2],[[128000,128062],2],[128063,2],[128064,2],[128065,2],[[128066,128247],2],[128248,2],[[128249,128252],2],[[128253,128254],2],[128255,2],[[128256,128317],2],[[128318,128319],2],[[128320,128323],2],[[128324,128330],2],[[128331,128335],2],[[128336,128359],2],[[128360,128377],2],[128378,2],[[128379,128419],2],[128420,2],[[128421,128506],2],[[128507,128511],2],[128512,2],[[128513,128528],2],[128529,2],[[128530,128532],2],[128533,2],[128534,2],[128535,2],[128536,2],[128537,2],[128538,2],[128539,2],[[128540,128542],2],[128543,2],[[128544,128549],2],[[128550,128551],2],[[128552,128555],2],[128556,2],[128557,2],[[128558,128559],2],[[128560,128563],2],[128564,2],[[128565,128576],2],[[128577,128578],2],[[128579,128580],2],[[128581,128591],2],[[128592,128639],2],[[128640,128709],2],[[128710,128719],2],[128720,2],[[128721,128722],2],[[128723,128724],2],[128725,2],[[128726,128727],2],[[128728,128731],3],[128732,2],[[128733,128735],2],[[128736,128748],2],[[128749,128751],3],[[128752,128755],2],[[128756,128758],2],[[128759,128760],2],[128761,2],[128762,2],[[128763,128764],2],[[128765,128767],3],[[128768,128883],2],[[128884,128886],2],[[128887,128890],3],[[128891,128895],2],[[128896,128980],2],[[128981,128984],2],[128985,2],[[128986,128991],3],[[128992,129003],2],[[129004,129007],3],[129008,2],[[129009,129023],3],[[129024,129035],2],[[129036,129039],3],[[129040,129095],2],[[129096,129103],3],[[129104,129113],2],[[129114,129119],3],[[129120,129159],2],[[129160,129167],3],[[129168,129197],2],[[129198,129199],3],[[129200,129201],2],[[129202,129279],3],[[129280,129291],2],[129292,2],[[129293,129295],2],[[129296,129304],2],[[129305,129310],2],[129311,2],[[129312,129319],2],[[129320,129327],2],[129328,2],[[129329,129330],2],[[129331,129342],2],[129343,2],[[129344,129355],2],[129356,2],[[129357,129359],2],[[129360,129374],2],[[129375,129387],2],[[129388,129392],2],[129393,2],[129394,2],[[129395,129398],2],[[129399,129400],2],[129401,2],[129402,2],[129403,2],[[129404,129407],2],[[129408,129412],2],[[129413,129425],2],[[129426,129431],2],[[129432,129442],2],[[129443,129444],2],[[129445,129450],2],[[129451,129453],2],[[129454,129455],2],[[129456,129465],2],[[129466,129471],2],[129472,2],[[129473,129474],2],[[129475,129482],2],[129483,2],[129484,2],[[129485,129487],2],[[129488,129510],2],[[129511,129535],2],[[129536,129619],2],[[129620,129631],3],[[129632,129645],2],[[129646,129647],3],[[129648,129651],2],[129652,2],[[129653,129655],2],[[129656,129658],2],[[129659,129660],2],[[129661,129663],3],[[129664,129666],2],[[129667,129670],2],[[129671,129672],2],[[129673,129679],3],[[129680,129685],2],[[129686,129704],2],[[129705,129708],2],[[129709,129711],2],[[129712,129718],2],[[129719,129722],2],[[129723,129725],2],[129726,3],[129727,2],[[129728,129730],2],[[129731,129733],2],[[129734,129741],3],[[129742,129743],2],[[129744,129750],2],[[129751,129753],2],[[129754,129755],2],[[129756,129759],3],[[129760,129767],2],[129768,2],[[129769,129775],3],[[129776,129782],2],[[129783,129784],2],[[129785,129791],3],[[129792,129938],2],[129939,3],[[129940,129994],2],[[129995,130031],3],[130032,1,\"0\"],[130033,1,\"1\"],[130034,1,\"2\"],[130035,1,\"3\"],[130036,1,\"4\"],[130037,1,\"5\"],[130038,1,\"6\"],[130039,1,\"7\"],[130040,1,\"8\"],[130041,1,\"9\"],[[130042,131069],3],[[131070,131071],3],[[131072,173782],2],[[173783,173789],2],[[173790,173791],2],[[173792,173823],3],[[173824,177972],2],[[177973,177976],2],[177977,2],[[177978,177983],3],[[177984,178205],2],[[178206,178207],3],[[178208,183969],2],[[183970,183983],3],[[183984,191456],2],[[191457,194559],3],[194560,1,\"\"],[194561,1,\"\"],[194562,1,\"\"],[194563,1,\"\"],[194564,1,\"\"],[194565,1,\"\"],[194566,1,\"\"],[194567,1,\"\"],[194568,1,\"\"],[194569,1,\"\"],[194570,1,\"\"],[194571,1,\"\"],[194572,1,\"\"],[194573,1,\"\"],[194574,1,\"\"],[194575,1,\"\"],[194576,1,\"\"],[194577,1,\"\"],[194578,1,\"\"],[194579,1,\"\"],[194580,1,\"\"],[194581,1,\"\"],[194582,1,\"\"],[194583,1,\"\"],[194584,1,\"\"],[194585,1,\"\"],[194586,1,\"\"],[194587,1,\"\"],[194588,1,\"\"],[194589,1,\"\"],[194590,1,\"\"],[194591,1,\"\"],[194592,1,\"\"],[194593,1,\"\"],[194594,1,\"\"],[194595,1,\"\"],[194596,1,\"\"],[194597,1,\"\"],[194598,1,\"\"],[194599,1,\"\"],[194600,1,\"\"],[194601,1,\"\"],[194602,1,\"\"],[194603,1,\"\"],[194604,1,\"\"],[194605,1,\"\"],[194606,1,\"\"],[194607,1,\"\"],[194608,1,\"\"],[[194609,194611],1,\"\"],[194612,1,\"\"],[194613,1,\"\"],[194614,1,\"\"],[194615,1,\"\"],[194616,1,\"\"],[194617,1,\"\"],[194618,1,\"\"],[194619,1,\"\"],[194620,1,\"\"],[194621,1,\"\"],[194622,1,\"\"],[194623,1,\"\"],[194624,1,\"\"],[194625,1,\"\"],[194626,1,\"\"],[194627,1,\"\"],[194628,1,\"\"],[[194629,194630],1,\"\"],[194631,1,\"\"],[194632,1,\"\"],[194633,1,\"\"],[194634,1,\"\"],[194635,1,\"\"],[194636,1,\"\"],[194637,1,\"\"],[194638,1,\"\"],[194639,1,\"\"],[194640,1,\"\"],[194641,1,\"\"],[194642,1,\"\"],[194643,1,\"\"],[194644,1,\"\"],[194645,1,\"\"],[194646,1,\"\"],[194647,1,\"\"],[194648,1,\"\"],[194649,1,\"\"],[194650,1,\"\"],[194651,1,\"\"],[194652,1,\"\"],[194653,1,\"\"],[194654,1,\"\"],[194655,1,\"\"],[194656,1,\"\"],[194657,1,\"\"],[194658,1,\"\"],[194659,1,\"\"],[194660,1,\"\"],[194661,1,\"\"],[194662,1,\"\"],[194663,1,\"\"],[194664,3],[194665,1,\"\"],[[194666,194667],1,\"\"],[194668,1,\"\"],[194669,1,\"\"],[194670,1,\"\"],[194671,1,\"\"],[194672,1,\"\"],[194673,1,\"\"],[194674,1,\"\"],[194675,1,\"\"],[194676,3],[194677,1,\"\"],[194678,1,\"\"],[194679,1,\"\"],[194680,1,\"\"],[194681,1,\"\"],[194682,1,\"\"],[194683,1,\"\"],[194684,1,\"\"],[194685,1,\"\"],[194686,1,\"\"],[194687,1,\"\"],[194688,1,\"\"],[194689,1,\"\"],[194690,1,\"\"],[194691,1,\"\"],[194692,1,\"\"],[194693,1,\"\"],[194694,1,\"\"],[194695,1,\"\"],[194696,1,\"\"],[194697,1,\"\"],[194698,1,\"\"],[194699,1,\"\"],[194700,1,\"\"],[194701,1,\"\"],[194702,1,\"\"],[194703,1,\"\"],[194704,1,\"\"],[[194705,194706],1,\"\"],[194707,1,\"\"],[[194708,194709],1,\"\"],[194710,1,\"\"],[194711,1,\"\"],[194712,1,\"\"],[194713,1,\"\"],[194714,1,\"\"],[194715,1,\"\"],[194716,1,\"\"],[194717,1,\"\"],[194718,1,\"\"],[194719,1,\"\"],[194720,1,\"\"],[194721,1,\"\"],[194722,1,\"\"],[194723,1,\"\"],[194724,1,\"\"],[194725,1,\"\"],[194726,1,\"\"],[194727,1,\"\"],[194728,1,\"\"],[194729,1,\"\"],[194730,1,\"\"],[194731,1,\"\"],[194732,1,\"\"],[194733,1,\"\"],[194734,1,\"\"],[194735,1,\"\"],[194736,1,\"\"],[194737,1,\"\"],[194738,1,\"\"],[194739,1,\"\"],[194740,1,\"\"],[194741,1,\"\"],[194742,1,\"\"],[194743,1,\"\"],[194744,1,\"\"],[194745,1,\"\"],[194746,1,\"\"],[194747,1,\"\"],[194748,1,\"\"],[194749,1,\"\"],[194750,1,\"\"],[194751,1,\"\"],[194752,1,\"\"],[194753,1,\"\"],[194754,1,\"\"],[194755,1,\"\"],[194756,1,\"\"],[194757,1,\"\"],[194758,1,\"\"],[194759,1,\"\"],[194760,1,\"\"],[194761,1,\"\"],[194762,1,\"\"],[194763,1,\"\"],[194764,1,\"\"],[194765,1,\"\"],[194766,1,\"\"],[194767,1,\"\"],[194768,1,\"\"],[194769,1,\"\"],[194770,1,\"\"],[194771,1,\"\"],[194772,1,\"\"],[194773,1,\"\"],[194774,1,\"\"],[194775,1,\"\"],[194776,1,\"\"],[194777,1,\"\"],[194778,1,\"\"],[194779,1,\"\"],[194780,1,\"\"],[194781,1,\"\"],[194782,1,\"\"],[194783,1,\"\"],[194784,1,\"\"],[194785,1,\"\"],[194786,1,\"\"],[194787,1,\"\"],[194788,1,\"\"],[194789,1,\"\"],[194790,1,\"\"],[194791,1,\"\"],[194792,1,\"\"],[194793,1,\"\"],[194794,1,\"\"],[194795,1,\"\"],[194796,1,\"\"],[194797,1,\"\"],[194798,1,\"\"],[194799,1,\"\"],[194800,1,\"\"],[194801,1,\"\"],[194802,1,\"\"],[194803,1,\"\"],[194804,1,\"\"],[194805,1,\"\"],[194806,1,\"\"],[194807,1,\"\"],[194808,1,\"\"],[194809,1,\"\"],[194810,1,\"\"],[194811,1,\"\"],[194812,1,\"\"],[194813,1,\"\"],[194814,1,\"\"],[194815,1,\"\"],[194816,1,\"\"],[194817,1,\"\"],[194818,1,\"\"],[194819,1,\"\"],[194820,1,\"\"],[194821,1,\"\"],[194822,1,\"\"],[194823,1,\"\"],[194824,1,\"\"],[194825,1,\"\"],[194826,1,\"\"],[194827,1,\"\"],[194828,1,\"\"],[194829,1,\"\"],[194830,1,\"\"],[194831,1,\"\"],[194832,1,\"\"],[194833,1,\"\"],[194834,1,\"\"],[194835,1,\"\"],[194836,1,\"\"],[194837,1,\"\"],[194838,1,\"\"],[194839,1,\"\"],[194840,1,\"\"],[194841,1,\"\"],[194842,1,\"\"],[194843,1,\"\"],[194844,1,\"\"],[194845,1,\"\"],[194846,1,\"\"],[194847,3],[194848,1,\"\"],[194849,1,\"\"],[194850,1,\"\"],[194851,1,\"\"],[194852,1,\"\"],[194853,1,\"\"],[194854,1,\"\"],[194855,1,\"\"],[194856,1,\"\"],[194857,1,\"\"],[194858,1,\"\"],[194859,1,\"\"],[[194860,194861],1,\"\"],[194862,1,\"\"],[194863,1,\"\"],[194864,1,\"\"],[194865,1,\"\"],[194866,1,\"\"],[194867,1,\"\"],[194868,1,\"\"],[194869,1,\"\"],[194870,1,\"\"],[194871,1,\"\"],[194872,1,\"\"],[194873,1,\"\"],[194874,1,\"\"],[194875,1,\"\"],[194876,1,\"\"],[194877,1,\"\"],[194878,1,\"\"],[194879,1,\"\"],[194880,1,\"\"],[194881,1,\"\"],[194882,1,\"\"],[194883,1,\"\"],[194884,1,\"\"],[194885,1,\"\"],[[194886,194887],1,\"\"],[194888,1,\"\"],[194889,1,\"\"],[194890,1,\"\"],[194891,1,\"\"],[194892,1,\"\"],[194893,1,\"\"],[194894,1,\"\"],[194895,1,\"\"],[194896,1,\"\"],[194897,1,\"\"],[194898,1,\"\"],[194899,1,\"\"],[194900,1,\"\"],[194901,1,\"\"],[194902,1,\"\"],[194903,1,\"\"],[194904,1,\"\"],[194905,1,\"\"],[194906,1,\"\"],[194907,1,\"\"],[194908,1,\"\"],[[194909,194910],1,\"\"],[194911,3],[194912,1,\"\"],[194913,1,\"\"],[194914,1,\"\"],[194915,1,\"\"],[194916,1,\"\"],[194917,1,\"\"],[194918,1,\"\"],[194919,1,\"\"],[194920,1,\"\"],[194921,1,\"\"],[194922,1,\"\"],[194923,1,\"\"],[194924,1,\"\"],[194925,1,\"\"],[194926,1,\"\"],[194927,1,\"\"],[194928,1,\"\"],[194929,1,\"\"],[194930,1,\"\"],[194931,1,\"\"],[194932,1,\"\"],[194933,1,\"\"],[194934,1,\"\"],[194935,1,\"\"],[194936,1,\"\"],[194937,1,\"\"],[194938,1,\"\"],[194939,1,\"\"],[194940,1,\"\"],[194941,1,\"\"],[194942,1,\"\"],[194943,1,\"\"],[194944,1,\"\"],[194945,1,\"\"],[194946,1,\"\"],[194947,1,\"\"],[194948,1,\"\"],[194949,1,\"\"],[194950,1,\"\"],[194951,1,\"\"],[194952,1,\"\"],[194953,1,\"\"],[194954,1,\"\"],[194955,1,\"\"],[194956,1,\"\"],[194957,1,\"\"],[194958,1,\"\"],[194959,1,\"\"],[194960,1,\"\"],[194961,1,\"\"],[194962,1,\"\"],[194963,1,\"\"],[194964,1,\"\"],[194965,1,\"\"],[194966,1,\"\"],[194967,1,\"\"],[194968,1,\"\"],[194969,1,\"\"],[194970,1,\"\"],[194971,1,\"\"],[194972,1,\"\"],[194973,1,\"\"],[194974,1,\"\"],[194975,1,\"\"],[194976,1,\"\"],[194977,1,\"\"],[194978,1,\"\"],[194979,1,\"\"],[194980,1,\"\"],[194981,1,\"\"],[194982,1,\"\"],[194983,1,\"\"],[194984,1,\"\"],[194985,1,\"\"],[194986,1,\"\"],[194987,1,\"\"],[194988,1,\"\"],[194989,1,\"\"],[194990,1,\"\"],[194991,1,\"\"],[194992,1,\"\"],[194993,1,\"\"],[194994,1,\"\"],[194995,1,\"\"],[194996,1,\"\"],[194997,1,\"\"],[194998,1,\"\"],[194999,1,\"\"],[195000,1,\"\"],[195001,1,\"\"],[195002,1,\"\"],[195003,1,\"\"],[195004,1,\"\"],[195005,1,\"\"],[195006,1,\"\"],[195007,3],[195008,1,\"\"],[195009,1,\"\"],[195010,1,\"\"],[195011,1,\"\"],[195012,1,\"\"],[195013,1,\"\"],[195014,1,\"\"],[195015,1,\"\"],[195016,1,\"\"],[195017,1,\"\"],[195018,1,\"\"],[195019,1,\"\"],[195020,1,\"\"],[195021,1,\"\"],[195022,1,\"\"],[195023,1,\"\"],[195024,1,\"\"],[195025,1,\"\"],[195026,1,\"\"],[195027,1,\"\"],[195028,1,\"\"],[195029,1,\"\"],[195030,1,\"\"],[195031,1,\"\"],[195032,1,\"\"],[195033,1,\"\"],[195034,1,\"\"],[195035,1,\"\"],[195036,1,\"\"],[195037,1,\"\"],[195038,1,\"\"],[195039,1,\"\"],[195040,1,\"\"],[195041,1,\"\"],[195042,1,\"\"],[195043,1,\"\"],[195044,1,\"\"],[195045,1,\"\"],[195046,1,\"\"],[195047,1,\"\"],[195048,1,\"\"],[195049,1,\"\"],[195050,1,\"\"],[195051,1,\"\"],[195052,1,\"\"],[195053,1,\"\"],[195054,1,\"\"],[195055,1,\"\"],[195056,1,\"\"],[195057,1,\"\"],[195058,1,\"\"],[195059,1,\"\"],[195060,1,\"\"],[195061,1,\"\"],[195062,1,\"\"],[195063,1,\"\"],[195064,1,\"\"],[195065,1,\"\"],[195066,1,\"\"],[195067,1,\"\"],[195068,1,\"\"],[195069,1,\"\"],[[195070,195071],1,\"\"],[195072,1,\"\"],[195073,1,\"\"],[195074,1,\"\"],[195075,1,\"\"],[195076,1,\"\"],[195077,1,\"\"],[195078,1,\"\"],[195079,1,\"\"],[195080,1,\"\"],[195081,1,\"\"],[195082,1,\"\"],[195083,1,\"\"],[195084,1,\"\"],[195085,1,\"\"],[195086,1,\"\"],[195087,1,\"\"],[195088,1,\"\"],[195089,1,\"\"],[195090,1,\"\"],[195091,1,\"\"],[195092,1,\"\"],[195093,1,\"\"],[195094,1,\"\"],[195095,1,\"\"],[195096,1,\"\"],[195097,1,\"\"],[195098,1,\"\"],[195099,1,\"\"],[195100,1,\"\"],[195101,1,\"\"],[[195102,196605],3],[[196606,196607],3],[[196608,201546],2],[[201547,201551],3],[[201552,205743],2],[[205744,262141],3],[[262142,262143],3],[[262144,327677],3],[[327678,327679],3],[[327680,393213],3],[[393214,393215],3],[[393216,458749],3],[[458750,458751],3],[[458752,524285],3],[[524286,524287],3],[[524288,589821],3],[[589822,589823],3],[[589824,655357],3],[[655358,655359],3],[[655360,720893],3],[[720894,720895],3],[[720896,786429],3],[[786430,786431],3],[[786432,851965],3],[[851966,851967],3],[[851968,917501],3],[[917502,917503],3],[917504,3],[917505,3],[[917506,917535],3],[[917536,917631],3],[[917632,917759],3],[[917760,917999],7],[[918000,983037],3],[[983038,983039],3],[[983040,1048573],3],[[1048574,1048575],3],[[1048576,1114109],3],[[1114110,1114111],3]]');\n\n//# sourceURL=webpack://experimento/./node_modules/tr46/lib/mappingTable.json?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/compat get default export */
/******/ 	(() => {
/******/ 		// getDefaultExport function for compatibility with non-harmony modules
/******/ 		__webpack_require__.n = (module) => {
/******/ 			var getter = module && module.__esModule ?
/******/ 				() => (module['default']) :
/******/ 				() => (module);
/******/ 			__webpack_require__.d(getter, { a: getter });
/******/ 			return getter;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./src/main/main.ts");
/******/ 	
/******/ })()
;